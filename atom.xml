<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Karobben</title>
  
  <subtitle>Engjoy~</subtitle>
  <link href="https://karobben.github.io/atom.xml" rel="self"/>
  
  <link href="https://karobben.github.io/"/>
  <updated>2023-12-18T19:29:45.204Z</updated>
  <id>https://karobben.github.io/</id>
  
  <author>
    <name>Karobben</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Phylogenetic Tree</title>
    <link href="https://karobben.github.io/2023/12/18/Bioinfor/phylogenetic/"/>
    <id>https://karobben.github.io/2023/12/18/Bioinfor/phylogenetic/</id>
    <published>2023-12-18T17:26:46.000Z</published>
    <updated>2023-12-18T19:29:45.204Z</updated>
    
    <content type="html"><![CDATA[<h2 id="What-is-Phylogenetic-Tree">What is Phylogenetic Tree</h2><blockquote><p>A phylogenetic tree is a diagram representing the evolutionary relationships among species or other entities based on their genetic or physical characteristics. The branches of the tree indicate how these species have evolved from common ancestors. The tree can be rooted, showing the most recent common ancestor, or unrooted, illustrating relationships without a common origin point. Constructed using data like DNA sequences or morphological traits, these trees are essential in studying evolutionary biology, tracking disease evolution, and in conservation efforts. They provide a visual representation of the evolutionary history and connections between different forms of life.<br>(GPT4)</p></blockquote><h2 id="General-Ideas-of-Phylogenetic-Tree">General Ideas of Phylogenetic Tree</h2><p>Source: <a href="https://evolution.berkeley.edu/evolution-101/the-history-of-life-looking-at-the-patterns/understanding-phylogenies/">Evo 101, Berkeley</a></p><table><thead><tr><th style="text-align:center"><img src="https://evolution.berkeley.edu/wp-content/uploads/2021/11/understanding_phylos_Understanding-phylo1-500x185.png" alt=""></th><th style="text-align:center"><img src="https://evolution.berkeley.edu/wp-content/uploads/2021/11/understanding_phylos_speciation-event-500x184.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center"><img src="https://evolution.berkeley.edu/wp-content/uploads/2021/11/understanding_phylos_unique-history-500x185.png" alt=""></td><td style="text-align:center"><img src="https://evolution.berkeley.edu/wp-content/uploads/2021/11/understanding_phylos_unique-ancestor-500x184.png" alt=""></td></tr></tbody></table><h2 id="Distance-Matrix-GPT4">Distance Matrix (GPT4)</h2><p>More related source could be found at <a href="https://academic-accelerator.com/encyclopedia/distance-matrix">academic accelerator</a></p><p>A distance matrix, in general, is a table used to show the distance between elements in a set. In the context of phylogenetics, it represents the genetic distance between various species or sequences.<br>A distance matrix in phylogenetics is a tool to quantify and visualize the genetic distances between different species or sequences. This matrix forms the basis for constructing phylogenetic trees, which depict the evolutionary relationships and history among the species studied.</p><details><summary>1. <b>General Distance Matrix</b></summary><ul><li>This is a square matrix where the elements represent the distances between pairs of objects.</li><li>In the matrix, each row and column represents an object, and each cell in the matrix shows the distance between the two objects.</li><li>The distances can be based on various metrics, depending on the context (e.g., physical distance, similarity in characteristics, etc.).</li></ul></details><details><summary>2. <b>Distance Matrix in Phylogenetics</b></summary><ul><li>In phylogenetics, the distance matrix represents genetic distances between different species or DNA sequences.</li><li>The genetic distance can be based on differences in DNA, RNA, or protein sequences, indicating how much genetic change has occurred between the sequences.</li><li>The distances are often calculated using methods that count the number of differences between sequences (like nucleotide substitutions) or more complex models that account for the rate of evolution and types of mutations.</li></ul></details><details><summary>3. <b>How it Works in Phylogenetics</b></summary><ul><li><strong>Data Collection</strong>: First, genetic data (like DNA sequences) from different species or organisms are collected.</li><li><strong>Distance Calculation</strong>: Algorithms calculate the genetic distance between each pair of sequences. These calculations can be straightforward (like counting differences) or complex (accounting for evolutionary models).</li><li><strong>Matrix Formation</strong>: These distances are then arranged in a matrix format, where each row and column represents a species or sequence, and each cell shows the genetic distance between them.</li><li><strong>Tree Construction</strong>: Phylogenetic trees can be constructed using this matrix. Methods like UPGMA (Unweighted Pair Group Method with Arithmetic mean) or neighbor-joining are used to create trees that best reflect the distances in the matrix.</li><li><strong>Analysis</strong>: The resulting tree is analyzed to understand evolutionary relationships, like which species are more closely related based on the genetic distances.</li></ul></details><br><table><thead><tr><th style="text-align:center"><img src="https://upload.wikimedia.org/wikipedia/commons/8/80/Additive_distance_matrix.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://academic-accelerator.com/encyclopedia/distance-matrix">© academic accelerator</a></td></tr><tr><td style="text-align:center">This graph illustrates the distance matrix and how it gives sense to the phylogenetic tree. According to the tree, the distance between <strong>b</strong> and <strong>c</strong> is 1+2=3. Similarly, we can deduce from the tree that the distance between <strong>a</strong> and <strong>d</strong> is 4+4+1=9.</td></tr></tbody></table><h3 id="Methods-for-Calculating-the-Distance-Matrix-GPT4">Methods for Calculating the Distance Matrix (GPT4)</h3><p>In phylogenetics, there are several methods to calculate the distance matrix, each with its own approach to measuring genetic distances between sequences. These methods vary in complexity and the types of evolutionary changes they consider. Here are some commonly used methods:</p><details><summary>1. <b>Simple Counting Methods</b></summary><ul><li>These involve counting the number of differences (e.g., nucleotide or amino acid substitutions) between each pair of sequences.</li><li>One example is the Hamming distance, which is simply the number of positions at which the corresponding elements (nucleotides or amino acids) are different.</li></ul></details><details><summary>2. <b>Corrected Distance Methods</b></summary><ul><li>These methods account for multiple changes at the same site and unseen changes due to evolutionary processes.</li><li>An example is the Jukes-Cantor model, which corrects for multiple substitutions at the same site by assuming that all changes occur at the same rate.</li></ul></details><details><summary>3. <b>Model-Based Methods</b></summary><ul><li>These use complex models of sequence evolution, accounting for factors like different rates of substitution between different nucleotides or amino acids, transition/transversion bias, and others.</li><li>Examples include the Kimura 2-parameter model and the Tamura-Nei model, which provide more sophisticated ways to estimate genetic distances by incorporating specific evolutionary assumptions.</li></ul></details><details><summary>4. <b>Maximum Likelihood and Bayesian Methods</b></summary><ul><li>These are more computationally intensive methods that use probabilistic models of sequence evolution.</li><li>They estimate the likelihood of observing the data given various possible evolutionary histories and can provide more accurate estimates of genetic distances.</li></ul></details><br><p>Each of these methods has its own strengths and limitations, and the choice of method often depends on the specifics of the data and the research question. Simple counting methods are straightforward but may underestimate distances, especially when sequences have diverged significantly. Corrected distance and model-based methods provide more accurate estimates by considering the complexities of molecular evolution, but they require more computational resources and deeper understanding of evolutionary models. Maximum likelihood and Bayesian methods are highly accurate but computationally demanding.</p><p>In practice, the choice of method is often a balance between the need for accuracy and the availability of computational resources, as well as the evolutionary characteristics of the organisms being studied.</p><h2 id="Different-Ways-to-Illustrate-the-Tree-By-GGTREE">Different Ways to Illustrate the Tree (By GGTREE)</h2><table><thead><tr><th style="text-align:center"><img src="https://yulab-smu.top/treedata-book/treedata_files/figure-html/layout-1.svg" alt="ggtree"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://yulab-smu.top/treedata-book/chapter4.html">© YuLab@SMU</a></td></tr></tbody></table><h2 id="Something-You’d-Like-to-Know-About-Phylogenetic-Trees-Chat4">Something You’d Like to Know About Phylogenetic Trees (Chat4)</h2><p>When working with phylogenetic trees, there are several key points and common misconceptions to be aware of:</p><details><summary>1. <b>Tree Topology Matters More Than Branch Length</b></summary>The branching pattern (topology) of the tree indicates the evolutionary relationships among the species or genes in the tree. However, unless explicitly stated, the length of the branches might not represent evolutionary time or genetic distance.</details><details><summary>2. <b>Branch Points (Nodes) Represent Common Ancestors</b></summary>Each node where branches diverge represents the most recent common ancestor of the groups branching off from that node.</details><details><summary>3. <b>Reading the Tree Correctly</b></summary>A common misunderstanding is the way to interpret the tree's layout. The tree should be read as a series of branching events, not as a left-to-right progression. The order of groups along the tips of the branches doesn't necessarily indicate any specific type of progression or superiority.</details><details><summary>4. <b>Phylogenetic Trees Are Hypothetical</b></summary>These trees are based on the best available data and the most accurate methods at the time. As new data emerge, the tree might be modified.</details><details><summary>5. <b>Rooted vs. Unrooted Trees</b></summary>Rooted trees have a single ancestral lineage (usually at the base) that serves as a common ancestor for all the entities in the tree. Unrooted trees do not show an ancestral root and are used to illustrate the relationships between different lineages without assuming their descent from a common ancestor.</details><details><summary>6. <b>Monophyletic, Paraphyletic, and Polyphyletic Groups</b></summary>Misunderstanding these terms can lead to confusion. Monophyletic groups include an ancestor and all its descendants, paraphyletic groups include an ancestor and some but not all descendants, and polyphyletic groups are characterized by members that do not share a recent common ancestor in the context of the tree.</details><details><summary>7. <b>Convergent Evolution Can Be Misleading</b></summary>Sometimes, unrelated species may appear closely related due to similar selective pressures rather than shared ancestry, a phenomenon known as convergent evolution.</details><details><summary>8. <b>Horizontal Gene Transfer</b></summary>Especially in bacterial phylogenetics, horizontal gene transfer can complicate the interpretation of evolutionary relationships.</details><br><p>Understanding these points can help in correctly interpreting phylogenetic trees and avoiding common misconceptions. It’s also important to remember that phylogenetics is a constantly evolving field, with new methods and data continually refining our understanding of evolutionary relationships.</p><h2 id="Beyond-the-Distance-Matrix-Chat4">Beyond the Distance Matrix (Chat4)</h2><p>Phylogenetic trees can also be constructed without using a distance matrix. The construction of phylogenetic trees can be broadly categorized into two main approaches: distance-based methods and character-based methods. While distance-based methods do rely on distance matrices, character-based methods do not. Here’s a brief overview of these approaches:</p><ol><li><p><strong>Distance-Based Methods</strong>: These methods, such as UPGMA (Unweighted Pair Group Method with Arithmetic Mean) and Neighbor-Joining (exp, <code>-QUICKTREE</code> from <code>clustalW</code>), <mark>rely on a distance matrix</mark> that represents the genetic distance (differences) between pairs of taxa. The matrix is used to construct a tree that represents these distances as accurately as possible.</p></li><li><p><strong>Character-Based Methods</strong>: These methods do not use a distance matrix. Instead, they directly analyze the character states (such as DNA, RNA, or protein sequences) of the taxa being studied. There are two primary types of character-based methods:</p><ul><li><p><strong>Maximum Parsimony</strong>: This method identifies the tree that requires the smallest number of evolutionary changes. It looks for the tree that explains the data with the least amount of complexity, without involving a distance matrix.</p></li><li><p><strong>Maximum Likelihood and Bayesian Methods</strong>: These are statistical methods that evaluate different possible phylogenetic trees and choose the tree that is most likely to have produced the observed set of data. These methods are based on explicit models of evolutionary change and do not rely on a pre-calculated distance matrix.</p></li></ul></li></ol><p>Each method has its advantages and limitations, and the choice of method can depend on the type of data available, the computational resources, and the specific objectives of the study. Character-based methods, especially those involving statistical approaches like Maximum Likelihood and Bayesian Inference, have become increasingly popular due to their ability to incorporate complex models of evolutionary change and handle large datasets effectively.</p><h2 id="The-Difference-Between-NJ-Tree-and-ML-Tree-Chat4">The Difference Between NJ-Tree and ML-Tree (Chat4)</h2><p>The popularity and suitability of the Neighbor-Joining (NJ) and Maximum Likelihood (ML) methods for constructing phylogenetic trees depend on the specific requirements and constraints of the research being conducted. Both methods have their advantages and limitations, and their appropriateness can vary based on factors like data complexity, computational resources, and the level of accuracy needed.</p><h3 id="Popularity">Popularity</h3><ol><li><p><strong>Neighbor-Joining (NJ)</strong>: <mark>Historically</mark>, NJ has been very popular, particularly in earlier studies, due to its computational efficiency. It’s well-suited for large datasets where quick, preliminary analyses are needed. NJ’s simplicity and speed made it a go-to method for many researchers, especially before the widespread availability of powerful computational resources.</p></li><li><p><strong>Maximum Likelihood (ML)</strong>: With the increase in computational power and the development of more sophisticated software, ML has gained substantial popularity, especially in more recent studies. It is often preferred for its ability to provide <mark>more accurate and statistically robust trees</mark>, especially for complex datasets.</p></li></ol><table><thead><tr><th>Feature</th><th>Neighbor-Joining (NJ)</th><th>Maximum Likelihood (ML)</th></tr></thead><tbody><tr><td><strong>Speed and Efficiency</strong></td><td>Fast and efficient, ideal for large datasets and quick analyses.</td><td>Slower and computationally intensive, especially with larger datasets.</td></tr><tr><td><strong>Accuracy</strong></td><td>Less accurate for complex evolutionary models; sensitive to rate variation and sampling errors.</td><td>More accurate and statistically robust across a wide range of datasets.</td></tr><tr><td><strong>Evolutionary Models</strong></td><td>Does not explicitly model evolutionary processes.</td><td>Incorporates explicit models of sequence evolution, handling varying rates of evolution better.</td></tr><tr><td><strong>Computational Resources</strong></td><td>Less demanding, suitable for limited computational resources.</td><td>Requires significant computational power for large and complex datasets.</td></tr><tr><td><strong>Statistical Support</strong></td><td>Limited statistical measures for tree support.</td><td>Provides robust statistical measures (like bootstrap values) for tree support.</td></tr><tr><td><strong>Use Case</strong></td><td>Suitable for preliminary or rapid analyses when computational resources are limited.</td><td>Preferred for detailed, accurate phylogenetic analyses where computational resources are available.</td></tr><tr><td><strong>Complexity and Understanding</strong></td><td>Simpler to understand and use.</td><td>Requires a good understanding of evolutionary models and statistical methods.</td></tr></tbody></table><h3 id="Conclusion">Conclusion</h3><p>The choice between NJ and ML largely depends on the specific requirements of your phylogenetic analysis. For preliminary or rapid analyses with large datasets, NJ remains popular due to its speed. However, for in-depth studies where accuracy and model-based statistical rigor are crucial, ML is often considered superior, albeit at the cost of greater computational demand. With ongoing advancements in computational methods and resources, ML is becoming increasingly accessible and popular in phylogenetic studies.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Phylogenetic Tree</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="others" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/others/"/>
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="Biology" scheme="https://karobben.github.io/tags/Biology/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://karobben.github.io/2023/12/13/Bioinfor/cdhit/"/>
    <id>https://karobben.github.io/2023/12/13/Bioinfor/cdhit/</id>
    <published>2023-12-13T21:21:40.000Z</published>
    <updated>2023-12-14T17:04:35.763Z</updated>
    
    <content type="html"><![CDATA[<h2 id="CD-HIT">CD-HIT</h2><p>Documentation: <a href="https://www.bioinformatics.org/cd-hit/cd-hit-user-guide">CD-HIT</a></p><p>CD-HIT (Cluster Database at High Identity with Tolerance) is a widely used bioinformatics tool designed to cluster biological sequences (such as DNA, RNA, or proteins) to reduce sequence redundancy and improve the efficiency of other sequence analyses. It’s particularly useful when dealing with large datasets, such as those frequently encountered in genomics and proteomics studies.</p><p>Here are some key features and uses of CD-HIT:</p><ol><li><p><strong>Sequence Clustering</strong>: CD-HIT efficiently clusters similar sequences together based on a user-defined similarity threshold. For example, if you set a threshold of 90%, the tool will group sequences that are 90% identical into the same cluster.</p></li><li><p><strong>Reduction of Redundancy</strong>: By clustering similar sequences, CD-HIT helps in reducing redundancy in the dataset. This is particularly important when creating sequence databases or when analyzing large datasets where many sequences may be very similar or nearly identical.</p></li><li><p><strong>Speed and Efficiency</strong>: CD-HIT is known for its speed and low memory usage, making it suitable for handling very large datasets that are common in modern high-throughput sequencing projects.</p></li><li><p><strong>Multiple Applications</strong>: It’s used in a variety of applications, such as creating non-redundant sequence databases, preparing datasets for further analyses (like phylogenetic studies), or in metagenomics for analyzing diversity and similarity of species.</p></li><li><p><strong>Customizable Parameters</strong>: Users can customize several parameters, such as the identity threshold for clustering, the word size for initial comparisons, and memory usage, allowing for flexibility depending on the specific requirements of the data or the analysis.</p></li><li><p><strong>Output Files</strong>: CD-HIT generates two main types of output files - one containing the clustered sequences and another (<code>.clstr</code> file) detailing the composition of each cluster.</p></li></ol><p>CD-HIT is a command-line tool, which means it is run from a terminal or command prompt and offers great flexibility in scripting and automation within bioinformatics pipelines. The tool is an essential part of the toolkit for biologists and bioinformaticians dealing with large-scale sequence data.</p><h2 id="Example">Example</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">cd-hit -i Trunked.fa -o cdhit/Trunked_<span class="hljs-variable">$x</span>.fa -c <span class="hljs-variable">$x</span> -M 32000 -d 0 -T 8 -n 5 -aL 0.8 -s 0.95  -uS 0.2  -sc 1 -sf 1<br></code></pre></td></tr></table></figure></div><p>The command you’ve provided is for CD-HIT, a widely used bioinformatics tool for clustering and comparing protein or nucleotide sequences. CD-HIT helps to significantly reduce the redundancy of large datasets by clustering similar sequences together based on a specified sequence identity threshold. This is particularly useful in tasks like constructing databases or preparing datasets for other analyses where redundancy might be an issue.</p><p>Let’s break down the components of your command:</p><ul><li><p><code>cd-hit</code>: This invokes the CD-HIT program.</p></li><li><p><code>-i Trunked.fa</code>: The <code>-i</code> option specifies the input file. Here, the input file is <code>Trunked.fa</code>, which likely contains a collection of nucleotide or protein sequences in FASTA format.</p></li><li><p><code>-o cdhit/Trunked_$x.fa</code>: The <code>-o</code> option specifies the output file. This command will create an output file in the <code>cdhit</code> directory with a name based on the value of the variable <code>$x</code>. The <code>$x</code> seems to be a shell variable that would be replaced with its value when the command runs.</p></li><li><p><code>-c $x</code>: The <code>-c</code> option sets the sequence identity threshold. Sequences are clustered together if they are similar to each other above this threshold. The exact value is determined by the variable <code>$x</code>.</p></li><li><p><code>-M 32000</code>: This sets the maximum available memory (in MB). <code>32000</code> here means 32,000 MB, or 32 GB of RAM.</p></li><li><p><code>-d 0</code>: The <code>-d</code> option is for the description length to show in the <code>.clstr</code> output file. <code>0</code> means it will show the full sequence defline.</p></li><li><p><code>-T 8</code>: This specifies the number of threads to use. <code>8</code> means the program will run on 8 threads, enabling parallel computation for faster processing.</p></li><li><p><code>-n 5</code>: For protein sequences, this sets the word length for the initial match. <code>5</code> is typically used for thresholds between 0.7 and 0.8.</p></li><li><p><code>-aL 0.8</code>: This sets the alignment coverage for the longer sequence. <code>0.8</code> means 80% of the longer sequence must be covered in the alignment.</p></li><li><p><code>-s 0.95</code>: This sets the alignment coverage for the shorter sequence. <code>0.95</code> means 95% of the shorter sequence must be included in the alignment.</p></li><li><p><code>-uS 0.2</code>: This specifies the maximum unmatched percentage of the shorter sequence. <code>0.2</code> means up to 20% of the shorter sequence can be unmatched.</p></li><li><p><code>-sc 1</code>: This option, when set to <code>1</code>, sorts clusters by decreasing size.</p></li><li><p><code>-sf 1</code>: This option, when set to <code>1</code>, sorts fasta sequence by cluster size.</p></li></ul><p>Each of these options tailors the behavior of CD-HIT to your specific requirements, influencing how sequences are clustered and how the output is formatted and organized. The use of shell variables (like <code>$x</code>) suggests that this command is part of a script where the value of <code>$x</code> is dynamically set, allowing for flexible application of the command with different parameters.</p><h2 id="Read-the-cd-hit-Result-as-pandas-dataframe">Read the cd-hit Result as pandas dataframe</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br><span class="hljs-comment"># Initialize lists to store data</span><br>sequence_names = []<br>cluster_ids = []<br><br><span class="hljs-comment"># Open the .clstr file and parse it</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;your_file.clstr&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> file:<br>    current_cluster_id = <span class="hljs-literal">None</span><br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> file:<br>        <span class="hljs-keyword">if</span> line.startswith(<span class="hljs-string">&#x27;&gt;Cluster &#x27;</span>):<br>            current_cluster_id = line.split()[<span class="hljs-number">1</span>]<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># Extracting sequence name</span><br>            parts = line.split()<br>            seq_name = parts[<span class="hljs-number">2</span>].strip(<span class="hljs-string">&#x27;&gt;&#x27;</span>).split(<span class="hljs-string">&#x27;...&#x27;</span>)[<span class="hljs-number">0</span>]<br>            sequence_names.append(seq_name)<br>            cluster_ids.append(current_cluster_id)<br><br><span class="hljs-comment"># Create a DataFrame</span><br>df = pd.DataFrame(&#123;<span class="hljs-string">&#x27;Sequence Name&#x27;</span>: sequence_names, <span class="hljs-string">&#x27;Cluster ID&#x27;</span>: cluster_ids&#125;)<br><br><span class="hljs-comment"># Display the DataFrame</span><br>print(df)<br></code></pre></td></tr></table></figure></div><h2 id="Trouble-Shooting">Trouble Shooting</h2><pre>Fatal Error:Too low cluster threshold for the word length.Increase the threshold or the tolerance, or decrease the word length.Program halted !!</pre><p>The error message you’re encountering, “Fatal Error: Too low cluster threshold for the word length. Increase the threshold or the tolerance, or decrease the word length. Program halted !!”, indicates a conflict between the parameters you’ve set in CD-HIT, particularly relating to the sequence identity threshold and the word length.</p><p>In CD-HIT, the “word length” refers to the length of the initial exact match that the algorithm looks for when comparing sequences. The “cluster threshold” is the percentage similarity required for two sequences to be clustered together. When the cluster threshold is set too low relative to the word length, the program cannot effectively perform the initial sequence matching, leading to this error.</p><p>To resolve this issue, you can:</p><ol><li><p><strong>Increase the Threshold</strong>: Increase the sequence identity threshold (<code>-c</code> parameter). If it’s currently very low, increasing it will make the clustering less stringent. For instance, if you have set <code>-c 0.6</code> (60% identity), try increasing it to 0.7 or higher.</p></li><li><p><strong>Decrease the Word Length</strong>: Decrease the word length (<code>-n</code> parameter). A lower word length means the program will look for shorter exact matches in the initial step, which can be more tolerant of low similarity thresholds. However, be cautious, as too low a word length might make the process slower and less efficient.</p></li><li><p><strong>Adjust Tolerance</strong>: If your dataset includes very diverse sequences and you need to maintain a low threshold, you might have to adjust other parameters to balance the sensitivity and specificity of the clustering.</p></li></ol><p>Remember that the appropriate values for these parameters can vary depending on your specific dataset and the objectives of your analysis. It might require some experimentation to find the right balance for your needs.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">CD-HIT, a protein/nuclear</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Software" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Software/"/>
    
    <category term="more" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Software/more/"/>
    
    
    <category term="Cluster" scheme="https://karobben.github.io/tags/Cluster/"/>
    
    <category term="Software" scheme="https://karobben.github.io/tags/Software/"/>
    
    <category term="NGS" scheme="https://karobben.github.io/tags/NGS/"/>
    
  </entry>
  
  <entry>
    <title>Extract Information from PDB and Visualize with Pyvista</title>
    <link href="https://karobben.github.io/2023/12/08/Bioinfor/pdbpyvista/"/>
    <id>https://karobben.github.io/2023/12/08/Bioinfor/pdbpyvista/</id>
    <published>2023-12-08T15:26:56.000Z</published>
    <updated>2023-12-08T22:00:58.764Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Quick-Codes">Quick Codes</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> Bio.PDB <span class="hljs-keyword">import</span> PDBParser<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pyvista <span class="hljs-keyword">as</span> pv<br><br><span class="hljs-comment"># Parse the PDB file</span><br>parser = PDBParser()<br>structure = parser.get_structure(<span class="hljs-string">&quot;1nnc&quot;</span>, <span class="hljs-string">&quot;PDB/1nnc.pdb&quot;</span>)<br><br><span class="hljs-comment"># Extract 3D coordinates and print atom names</span><br>points = []<br><span class="hljs-keyword">for</span> model <span class="hljs-keyword">in</span> structure:<br>    <span class="hljs-keyword">for</span> chain <span class="hljs-keyword">in</span> model:<br>        <span class="hljs-keyword">for</span> residue <span class="hljs-keyword">in</span> chain:<br>            <span class="hljs-keyword">for</span> atom <span class="hljs-keyword">in</span> residue:<br>                points.append(atom.get_coord())<br>                print(<span class="hljs-string">f&quot;Atom Name: <span class="hljs-subst">&#123;atom.get_name()&#125;</span>, Coordinates: <span class="hljs-subst">&#123;atom.get_coord()&#125;</span>&quot;</span>)<br><br><span class="hljs-comment"># Convert to a numpy array</span><br>points_array = np.array(points)<br><br><span class="hljs-comment"># Create a PyVista point cloud</span><br>point_cloud = pv.PolyData(points_array)<br>point_cloud.plot(point_size=<span class="hljs-number">5</span>, color=<span class="hljs-string">&#x27;red&#x27;</span>)<br></code></pre></td></tr></table></figure></div><p>In this updated script:</p><ul><li>The <code>print</code> statement within the innermost loop (<code>for atom in residue:</code>) prints the name of each atom and its coordinates.</li><li><code>atom.get_name()</code> retrieves the name of the atom.</li><li><code>atom.get_coord()</code> retrieves the 3D coordinates of the atom.</li></ul><p>Remember to replace <code>&quot;protein_id&quot;</code> and <code>&quot;path_to_your_pdb_file.pdb&quot;</code> with the appropriate identifiers and file path for your PDB file.</p><p>This script will print the name and coordinates of each atom in the console and plot the points in 3D using PyVista. You can further modify this script to include more details or to format the output as per your requirement.</p><h2 id="The-Name-of-Atoms">The Name of Atoms</h2><p>Certainly! In the context of a Protein Data Bank (PDB) file, atoms within proteins are named according to standard conventions that reflect their chemical properties and their position within the protein structure. Here’s a breakdown of what different atom names typically signify:</p><ol><li><p><strong>Element Symbol</strong>: The first part of an atom’s name usually represents its element symbol from the periodic table. For example, “C” stands for Carbon, “N” for Nitrogen, “O” for Oxygen, “S” for Sulfur, and so on.</p></li><li><p><strong>Amino Acid Context</strong>: Atoms are part of amino acids in proteins. Each amino acid has a specific set of atoms. For instance, in the amino acid glycine, you might find atoms named “CA” (alpha carbon), “N” (amino nitrogen), “O” (carbonyl oxygen), etc.</p></li><li><p><strong>Position in Amino Acid</strong>:</p><ul><li><strong>Alpha Carbon (CA)</strong>: This is the central carbon atom to which the amino group (NH2), carboxyl group (COOH), hydrogen (H), and the R group (side chain) are attached in amino acids.</li><li><strong>Backbone Atoms</strong>: These include “N” (the amide nitrogen), “CA” (alpha carbon), and “C” (the carbonyl carbon). These atoms form the backbone of the protein chain.</li><li><strong>Side Chain Atoms</strong>: Atoms in the side chain (or R group) of an amino acid are denoted by different names depending on their position and chemical nature. For example, in the amino acid lysine, you might see names like “CG”, “CD”, “CE” - these are carbon atoms in the side chain, labeled in order from the alpha carbon.</li></ul></li><li><p><strong>Hydrogen Atoms</strong>: These are often denoted by “H” followed by additional characters to specify their position. For example, “HA” might be a hydrogen attached to the alpha carbon.</p></li><li><p><strong>Prosthetic Groups or Non-standard Residues</strong>: In addition to standard amino acids, proteins may have non-standard residues or prosthetic groups like heme in hemoglobin. These will have their own unique naming conventions based on their molecular structure.</p></li><li><p><strong>Alternate Locations</strong>: Sometimes an atom can occupy multiple positions due to structural flexibility. These are often indicated by an additional character like “A” or “B” following the atom name.</p></li></ol><p>Understanding these naming conventions can help in interpreting the structure and function of the protein, as the 3D arrangement of these atoms determines the protein’s shape and reactive sites. In practical use, this information is crucial for tasks like modeling protein-ligand interactions, understanding enzyme active sites, or studying protein folding and dynamics.</p><h2 id="Show-the-Alpha-Carbon-Only">Show the Alpha Carbon Only</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> Bio.PDB <span class="hljs-keyword">import</span> PDBParser<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pyvista <span class="hljs-keyword">as</span> pv<br><br><span class="hljs-comment"># Parse the PDB file</span><br>parser = PDBParser()<br>structure = parser.get_structure(<span class="hljs-string">&quot;Mos99&quot;</span>, <span class="hljs-string">&quot;PDB/Mos99_WT_NA_monomer.pdb&quot;</span>)<br><br><span class="hljs-comment"># Extract 3D coordinates and print atom names</span><br>points = []<br><span class="hljs-keyword">for</span> model <span class="hljs-keyword">in</span> structure:<br>    <span class="hljs-keyword">for</span> chain <span class="hljs-keyword">in</span> model:<br>        <span class="hljs-keyword">for</span> residue <span class="hljs-keyword">in</span> chain:<br>            <span class="hljs-keyword">for</span> atom <span class="hljs-keyword">in</span> residue:<br>              <span class="hljs-keyword">if</span> atom.get_name() == <span class="hljs-string">&quot;CA&quot;</span>:<br>                points.append(atom.get_coord())<br>                <span class="hljs-comment">#print(f&quot;Atom Name: &#123;atom.get_name()&#125;, Coordinates: &#123;atom.get_coord()&#125;&quot;)</span><br><br><span class="hljs-comment"># Convert to a numpy array</span><br>points_array = np.array(points)<br><br><span class="hljs-comment"># Create a PyVista point cloud</span><br>point_cloud = pv.PolyData(points_array)<br>point_cloud.plot(point_size=<span class="hljs-number">5</span>, color=<span class="hljs-string">&#x27;red&#x27;</span>)<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://imgur.com/bdjsps4.png" alt=""></th></tr></thead><tbody></tbody></table><h2 id="Convert-it-into-Mesh">Convert it into Mesh</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># select the dots on the surface</span><br><span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> NearestNeighbors<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><br><span class="hljs-comment"># Assuming &#x27;points_array&#x27; is your numpy array of 3D points</span><br>points = points_array.copy()<br><br><span class="hljs-comment"># Use KNN to find the nearest neighbors</span><br>nbrs = NearestNeighbors(n_neighbors=<span class="hljs-number">10</span>).fit(points)<br>distances, indices = nbrs.kneighbors(points)<br><br><span class="hljs-comment"># Determine a threshold distance for surface points</span><br>threshold_distance = np.percentile(distances, <span class="hljs-number">90</span>)  <span class="hljs-comment"># adjust as needed</span><br><br><span class="hljs-comment"># Identify surface points</span><br>surface_points = points[np.<span class="hljs-built_in">max</span>(distances, axis=<span class="hljs-number">1</span>) &gt; threshold_distance]<br><br>point_cloud = pv.PolyData(surface_points)<br><span class="hljs-comment">#point_cloud = pv.PolyData(points_array)</span><br>volume = point_cloud.delaunay_3d(alpha = <span class="hljs-number">4</span>)<br>shell = volume.extract_geometry()<br>shell.plot(show_edges=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://imgur.com/QbP7pRg.png" alt="Mesh Surface of Alpha Carbon"></th></tr></thead><tbody></tbody></table><h2 id="Visualize-a-Single-Amino-Acid">Visualize a Single Amino Acid</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">chain_id = <span class="hljs-string">&#x27;A&#x27;</span>  <span class="hljs-comment"># Replace with the relevant chain ID</span><br>residue_number = <span class="hljs-number">100</span>  <span class="hljs-comment"># Replace with the residue number of the amino acid</span><br><br><span class="hljs-comment"># Extract coordinates</span><br>amino_acid_data = []<br><span class="hljs-keyword">for</span> model <span class="hljs-keyword">in</span> structure:<br>    <span class="hljs-keyword">for</span> chain <span class="hljs-keyword">in</span> model:<br>        <span class="hljs-keyword">if</span> chain.get_id() == chain_id:<br>            <span class="hljs-keyword">for</span> residue <span class="hljs-keyword">in</span> chain:<br>                <span class="hljs-keyword">if</span> residue.get_id()[<span class="hljs-number">1</span>] == residue_number:<br>                    <span class="hljs-keyword">for</span> atom <span class="hljs-keyword">in</span> residue:<br>                        amino_acid_data.append((atom.get_coord(), atom.element, atom.get_id()))<br>                    tmp = residue<br>                    print(residue.get_full_id(), residue.get_resname())<br><br><span class="hljs-comment"># Separate coordinates, elements, and atom names</span><br>coordinates, elements, atom_names = <span class="hljs-built_in">zip</span>(*amino_acid_data)<br>coordinates = np.array(coordinates)<br><br><br><span class="hljs-comment"># find bounds:</span><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">infer_bonds</span>(<span class="hljs-params">coords, max_bond_length=<span class="hljs-number">2</span></span>):</span><br>    bonds = []<br>    num_atoms = <span class="hljs-built_in">len</span>(coords)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_atoms):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(i+<span class="hljs-number">1</span>, num_atoms):<br>            <span class="hljs-keyword">if</span> np.linalg.norm(coords[i] - coords[j]) &lt; max_bond_length:<br>                bonds.append((i, j))<br>    <span class="hljs-keyword">return</span> bonds<br><br><span class="hljs-comment"># Infer bonds</span><br>bonds = infer_bonds(coordinates)<br><br><br><span class="hljs-comment"># Plot all</span><br><span class="hljs-comment"># Map elements to RGB colors (customize this as needed)</span><br>element_colors = &#123;<br>    <span class="hljs-string">&quot;C&quot;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],  <span class="hljs-comment"># Carbon (black)</span><br>    <span class="hljs-string">&quot;N&quot;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">255</span>],  <span class="hljs-comment"># Nitrogen (blue)</span><br>    <span class="hljs-string">&quot;O&quot;</span>: [<span class="hljs-number">255</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],  <span class="hljs-comment"># Oxygen (red)</span><br>    <span class="hljs-string">&quot;S&quot;</span>: [<span class="hljs-number">255</span>, <span class="hljs-number">255</span>, <span class="hljs-number">0</span>],  <span class="hljs-comment"># Sulfur (yellow)</span><br>    <span class="hljs-comment"># Add more elements and colors as required</span><br>&#125;<br><br><span class="hljs-comment"># Create an array to store RGB colors</span><br>rgb_colors = np.array([element_colors.get(element, [<span class="hljs-number">125</span>, <span class="hljs-number">125</span>, <span class="hljs-number">125</span>]) <span class="hljs-keyword">for</span> element <span class="hljs-keyword">in</span> elements])  <span class="hljs-comment"># Default grey</span><br><br><span class="hljs-comment"># Create a PyVista plotter</span><br>plotter = pv.Plotter()<br><br><span class="hljs-comment"># Plot atoms</span><br><span class="hljs-keyword">for</span> coord, color <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(coordinates, rgb_colors):<br>    sphere = pv.Sphere(radius=<span class="hljs-number">0.5</span>, center=coord)<br>    plotter.add_mesh(sphere, color=color)<br><br><span class="hljs-comment"># Plot bonds</span><br><span class="hljs-keyword">for</span> bond <span class="hljs-keyword">in</span> bonds:<br>    start, end = coordinates[bond[<span class="hljs-number">0</span>]], coordinates[bond[<span class="hljs-number">1</span>]]<br>    line = pv.Line(start, end)<br>    plotter.add_mesh(line, color=<span class="hljs-string">&#x27;grey&#x27;</span>, line_width=<span class="hljs-number">3</span>)<br><br><span class="hljs-comment"># Show plot</span><br>plotter.show()<br></code></pre></td></tr></table></figure></div><p><img src="https://imgur.com/E3f8WPj.png" alt=""></p><p>In this case, in the atom_names:</p><ul><li>CA: alpha carbon</li><li>C: the carbon from C<sub>α</sub>-COOH</li><li>N: The N from C<sub>α</sub>-NH<sub>3</sub></li></ul><p>rest of atoms are coming from side chain.</p><h2 id="Turn-IT-into-Dictionary">Turn IT into Dictionary</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">Protein_dic = &#123;&#125;<br><span class="hljs-keyword">for</span> model <span class="hljs-keyword">in</span> structure:<br>  <span class="hljs-keyword">for</span> chain <span class="hljs-keyword">in</span> model:<br>    chain_dic = &#123;&#125; <br>    <span class="hljs-keyword">for</span> residue <span class="hljs-keyword">in</span> chain:<br>      chain_dic.update(&#123;residue.get_id()[<span class="hljs-number">1</span>]: residue&#125;)<br>    Protein_dic.update(&#123;chain.get_id(): chain_dic&#125;)<br></code></pre></td></tr></table></figure></div><h2 id="Check-the-Adjacent-Side-Chain-by-Side-Chain">Check the Adjacent Side Chain by Side Chain</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">Get_atom</span>(<span class="hljs-params">Res</span>):</span><br>  R = []<br>  <span class="hljs-keyword">for</span> atom <span class="hljs-keyword">in</span> Res:<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(Res) == <span class="hljs-number">4</span>:<br>      R += [atom.get_coord()]<br>    <span class="hljs-keyword">else</span>:      <br>      <span class="hljs-keyword">if</span> atom.get_id() <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;N&#x27;</span>, <span class="hljs-string">&#x27;CA&#x27;</span>, <span class="hljs-string">&quot;C&quot;</span>, <span class="hljs-string">&quot;O&quot;</span>]:<br>        R += [atom.get_coord()]<br>  R = np.array(R)<br>  <span class="hljs-keyword">return</span> R<br><br>AA_list = [<span class="hljs-string">&#x27;ALA&#x27;</span>, <span class="hljs-string">&#x27;ARG&#x27;</span>, <span class="hljs-string">&#x27;ASN&#x27;</span>, <span class="hljs-string">&#x27;ASP&#x27;</span>, <span class="hljs-string">&#x27;CYS&#x27;</span>, <span class="hljs-string">&#x27;GLN&#x27;</span>, <span class="hljs-string">&#x27;GLU&#x27;</span>, <span class="hljs-string">&#x27;GLY&#x27;</span>, <span class="hljs-string">&#x27;HIS&#x27;</span>, <span class="hljs-string">&#x27;ILE&#x27;</span>, <span class="hljs-string">&#x27;LEU&#x27;</span>, <span class="hljs-string">&#x27;LYS&#x27;</span>, <span class="hljs-string">&#x27;MET&#x27;</span>, <span class="hljs-string">&#x27;PHE&#x27;</span>, <span class="hljs-string">&#x27;PRO&#x27;</span>, <span class="hljs-string">&#x27;SER&#x27;</span>, <span class="hljs-string">&#x27;THR&#x27;</span>, <span class="hljs-string">&#x27;TRP&#x27;</span>, <span class="hljs-string">&#x27;TYR&#x27;</span>, <span class="hljs-string">&#x27;VAL&#x27;</span>]<br><br>Residues = []<br><span class="hljs-keyword">for</span> chain <span class="hljs-keyword">in</span> Protein_dic.keys():<br>  <span class="hljs-keyword">for</span> pos <span class="hljs-keyword">in</span> Protein_dic[chain]:<br>    <span class="hljs-keyword">if</span> Protein_dic[chain][pos].get_resname() <span class="hljs-keyword">in</span> AA_list:<br>      Residues += [[chain, pos, Protein_dic[chain][pos].get_resname(), <br>                  np.mean(Get_atom(Protein_dic[chain][pos]), axis=<span class="hljs-number">0</span>)]]<br><br><br><br><span class="hljs-comment"># plot hte residues position</span><br><span class="hljs-comment"># Convert to a numpy array</span><br>points_array = np.array([i[-<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> Residues])<br><br><span class="hljs-comment"># Create a PyVista point cloud</span><br>point_cloud = pv.PolyData(points_array)<br><br>point_cloud.plot(point_size=<span class="hljs-number">5</span>, color=<span class="hljs-string">&#x27;red&#x27;</span>)<br><br><br><span class="hljs-comment"># mesh</span><br><br><span class="hljs-comment"># Assuming &#x27;points_array&#x27; is your numpy array of 3D points</span><br>points = points_array.copy()<br><br><span class="hljs-comment"># Use KNN to find the nearest neighbors</span><br>nbrs = NearestNeighbors(n_neighbors=<span class="hljs-number">5</span>).fit(points)<br>distances, indices = nbrs.kneighbors(points)<br><br><span class="hljs-comment"># Determine a threshold distance for surface points</span><br>threshold_distance = np.percentile(distances, <span class="hljs-number">90</span>)  <span class="hljs-comment"># adjust as needed</span><br><br><span class="hljs-comment"># Identify surface points</span><br>surface_points = points[np.<span class="hljs-built_in">max</span>(distances, axis=<span class="hljs-number">1</span>) &gt; threshold_distance]<br>surface_res = np.array(Residues)[np.<span class="hljs-built_in">max</span>(distances, axis=<span class="hljs-number">1</span>) &gt; threshold_distance]<br><br>point_cloud = pv.PolyData(surface_points)<br><span class="hljs-comment">#point_cloud = pv.PolyData(points_array)</span><br>volume = point_cloud.delaunay_3d(alpha = <span class="hljs-number">10</span>)<br>shell = volume.extract_geometry()<br>shell.plot(show_edges=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure></div><p><img src="https://imgur.com/c0OUROW.png" alt=""></p><h2 id="Check-the-Residua-Local-environment">Check the Residua Local environment</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">nbrs = NearestNeighbors(n_neighbors=<span class="hljs-number">6</span>).fit(surface_points)<br>distances, indices = nbrs.kneighbors(surface_points)<br><br>Loc_res = &#123;&#125;; [Loc_res.update(&#123;i[<span class="hljs-number">1</span>]:i[<span class="hljs-number">2</span>]&#125;) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> Residues <span class="hljs-keyword">if</span> i [<span class="hljs-number">0</span>]==<span class="hljs-string">&#x27;A&#x27;</span>]<br><span class="hljs-comment"># rm duplicated</span><br><br>Net_charge = &#123;<span class="hljs-string">&quot;ALA&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;ARG&quot;</span>:+<span class="hljs-number">1</span>, <span class="hljs-string">&quot;ASN&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;ASP&quot;</span>:-<span class="hljs-number">1</span>, <span class="hljs-string">&quot;CYS&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;GLN&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;GLU&quot;</span>:-<span class="hljs-number">1</span>, <span class="hljs-string">&quot;GLY&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;HIS&quot;</span>:+<span class="hljs-number">1</span>, <span class="hljs-string">&quot;ILE&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;LEU&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;LYS&quot;</span>:+<span class="hljs-number">1</span>, <span class="hljs-string">&quot;MET&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;PHE&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;PRO&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;SER&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;THR&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;TRP&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;TYR&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;VAL&quot;</span>:<span class="hljs-number">0</span>&#125;<br><br><br>res_pos  = np.array([[surface_res[ii][<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> ii <span class="hljs-keyword">in</span> i[:<span class="hljs-number">5</span>]] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> indices])<br>res_pos = np.unique(res_pos, axis= <span class="hljs-number">0</span>)<br><br>res_name = [[Loc_res[ii] <span class="hljs-keyword">for</span> ii <span class="hljs-keyword">in</span> i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> res_pos]<br>Charge_av = [<span class="hljs-built_in">sum</span>([Net_charge[ii] <span class="hljs-keyword">for</span> ii <span class="hljs-keyword">in</span> i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> res_name]<br><br><br>Loc_net = &#123;&#125;<br>[Loc_net.update(&#123;i[<span class="hljs-number">0</span>]:ii&#125;) <span class="hljs-keyword">for</span> i,ii <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(res_pos, Charge_av)]<br>values = [Loc_net[i[<span class="hljs-number">1</span>]] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> surface_res]<br><br>point_cloud = pv.PolyData(surface_points)<br>point_cloud[<span class="hljs-string">&quot;values&quot;</span>] = values<br><br><span class="hljs-comment">#point_cloud = pv.PolyData(points_array)</span><br>volume = point_cloud.delaunay_3d(alpha = <span class="hljs-number">10</span>)<br>shell = volume.extract_geometry()<br><br>plotter = pv.Plotter()<br>plotter.add_mesh(volume, scalars=<span class="hljs-string">&quot;values&quot;</span>, cmap=<span class="hljs-string">&quot;coolwarm&quot;</span>)<br>plotter.add_scalar_bar(color=<span class="hljs-string">&#x27;black&#x27;</span>)  <span class="hljs-comment"># Set scalar bar font color to black</span><br>plotter.set_background(color=<span class="hljs-string">&#x27;white&#x27;</span>)<br>plotter.show()<br><br><br>shell.plot(show_edges=<span class="hljs-literal">True</span>, scalars=<span class="hljs-string">&quot;values&quot;</span>, cmap=<span class="hljs-string">&quot;coolwarm&quot;</span>)<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://imgur.com/ZKPfTRr.png" alt=""></th></tr></thead><tbody></tbody></table><h2 id="Camera-Position">Camera Position</h2><p>In PyVista, you can easily get and set the camera position to ensure a consistent view across different plots. The camera position in PyVista is defined by a tuple of three elements:</p><ol><li><strong>Camera Position</strong>: The location of the camera in the 3D space.</li><li><strong>Focal Point</strong>: The point in the 3D space that the camera is looking at.</li><li><strong>View Up</strong>: A vector that defines the ‘up’ direction in the view of the camera.</li></ol><p>Here’s how you can get and then set the camera position:</p><h3 id="Getting-the-Camera-Position">Getting the Camera Position</h3><p>After you have displayed your plot once, you can retrieve the camera position:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pyvista <span class="hljs-keyword">as</span> pv<br><br><span class="hljs-comment"># [Your code to create and display the mesh]</span><br><br><span class="hljs-comment"># Create a plotter and add the mesh</span><br>plotter = pv.Plotter()<br>plotter.add_mesh(mesh)<br>plotter.show()<br><br><span class="hljs-comment"># Q to quite the polt</span><br><span class="hljs-comment"># Get the camera position</span><br>camera_position = plotter.camera_position<br></code></pre></td></tr></table></figure></div><h3 id="Setting-the-Camera-Position">Setting the Camera Position</h3><p>When you create a new plot and want to use the same camera position, you can set it like this:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Create a new plotter</span><br>plotter = pv.Plotter()<br><span class="hljs-comment"># Add the mesh to the new plotter</span><br>plotter.add_mesh(mesh)<br><span class="hljs-comment"># Set the camera position to the saved one</span><br>plotter.camera_position = camera_position<br><span class="hljs-comment"># Show the plot with the set camera position</span><br>plotter.show()<br></code></pre></td></tr></table></figure></div><p>Remember, you should retrieve and set the camera position after and before calling <code>show()</code>, respectively. This method ensures that every time you plot your mesh, the view will be identical, assuming the mesh and other plot settings remain the same.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Extract Information from PDB by using Biopython, rebuild the model and Visualize it with Pyvista</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Protein Structure" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Protein-Structure/"/>
    
    
    <category term="Software" scheme="https://karobben.github.io/tags/Software/"/>
    
    <category term="3D" scheme="https://karobben.github.io/tags/3D/"/>
    
    <category term="Protein Structure" scheme="https://karobben.github.io/tags/Protein-Structure/"/>
    
    <category term="Pyvista" scheme="https://karobben.github.io/tags/Pyvista/"/>
    
  </entry>
  
  <entry>
    <title>Neuraminidase (NA) protein, a Quick View</title>
    <link href="https://karobben.github.io/2023/12/07/LearnNotes/h3n2na/"/>
    <id>https://karobben.github.io/2023/12/07/LearnNotes/h3n2na/</id>
    <published>2023-12-07T19:00:02.000Z</published>
    <updated>2023-12-18T19:28:48.224Z</updated>
    
    <content type="html"><![CDATA[<h2 id="NA-protein">NA protein</h2><p>The influenza NA protein, or neuraminidase, is a critical component of the influenza virus and plays a vital role in the virus’s life cycle. Here’s an overview of its function and structure:</p><h3 id="Function-of-Influenza-NA-Protein">Function of Influenza NA Protein</h3><ol><li><p><strong>Viral Release</strong>: Neuraminidase is primarily responsible for facilitating the release of newly formed virus particles from the host cell. It cleaves sialic acid residues on the host cell surface and on the viral envelope, which otherwise bind the emerging viral particles and prevent their release.</p></li><li><p><strong>Virus Spread</strong>: By cleaving sialic acid, NA protein aids in the spread of the virus. This cleavage prevents the aggregation of virus particles, enabling them to spread more efficiently from cell to cell.</p></li><li><p><strong>Role in Infection</strong>: It helps the virus penetrate the mucus layer of the respiratory tract, enhancing the virus’s ability to infect the host cells.</p></li></ol><h3 id="Structure-of-Influenza-NA-Protein">Structure of Influenza NA Protein</h3><table><thead><tr><th style="text-align:center"><img src="https://www.frontiersin.org/files/Articles/432609/fmicb-10-00039-HTML/image_m/fmicb-10-00039-g001.jpg" alt="Structure of Influenza NA Protein"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.frontiersin.org/articles/10.3389/fmicb.2019.00039/full">© Julie L. McAuley1; 19</a></td></tr></tbody></table><ol><li><p><strong>Cytoplasmic Tail</strong>: Suggesting that the NA cytoplasmic tail is involved in critical viral functions, the N-terminal domain sequence is nearly 100% conserved across all IAV subtypes and consists of the sequence MNPNQK<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>. A complete loss of the tail domain<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup> resulted in a 50% reduction in the amount of NA in infected cells.</p></li><li><p><strong>Transmembrane Domain</strong>: It contains a variable sequence of amino acids spanning residue numbers 7–29 and is predicted to form an alpha helix<sup class="footnote-ref"><a href="#fn1" id="fnref1:1">[1:1]</a></sup><sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup> with interspersed polar residues driving subunit-subunit interactions<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>.</p></li><li><p><strong>Stalk Region</strong>: Depending on the length of the stalk region, the NA may protrude slightly more or less above the viral envelope than the HA, which may influence the overall enzymatic activity of the virus<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup><sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup>. The number and sequence of amino acid residues can vary considerably<sup class="footnote-ref"><a href="#fn1" id="fnref1:2">[1:2]</a></sup>.  NA stalk truncation mutants of the 2009 pandemic virus A(H1N1)pdm09 showed greater lethality in mice and virulence in ferrets than the untruncated counterpart<sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup>.</p></li><li><p><strong>Head Domain</strong>: These catalytic sites are characterized by a large cavity with an unusually large number of charged residues in the pocket and around its rim<sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup><sup class="footnote-ref"><a href="#fn9" id="fnref9">[9]</a></sup>. The tetrameric form of NA is considered optimal for enzyme activity, and mutations that lead to instability of the tetramer lead to decreased enzyme activity [<sup>McKimm_96b][</sup>Fujisaki_12][^McKimm_13]. While it has been reported that monomers alone have no enzyme activity<sup class="footnote-ref"><a href="#fn3" id="fnref3:1">[3:1]</a></sup> and usually expression of recombinant soluble NA heads requires a synthetic tetramerization domain for active NA<sup class="footnote-ref"><a href="#fn10" id="fnref10">[10]</a></sup>.</p><ul><li>Active site: Arg118, Asp151, Arg152, Arg224, Glu276, Arg292, Arg371, and Tyr406</li><li>Framework residues: Glu119, Arg156, Trp178, Ser179, Asp198, Ile222, Glu227, Glu277, Asn294, and Glu425</li></ul></li></ol><ol><li><p><strong>Tetrameric Structure</strong>: The neuraminidase protein typically forms a tetramer, meaning four NA molecules join together to function.</p></li><li><p><strong>Head and Stalk Regions</strong>: The NA protein has two distinct regions: the head, which contains the active site for sialic acid cleavage, and the stalk, which anchors the protein to the viral envelope.</p></li><li><p><strong>Active Site</strong>: The active site is located in a pocket in the head region and is responsible for the enzyme’s sialic acid cleavage activity.</p></li><li><p><strong>Glycosylation Sites</strong>: These sites are present on the head region, where carbohydrate chains are attached. This glycosylation can affect the antigenicity and activity of the NA protein.</p></li><li><p><strong>Subtypes</strong>: There are several different subtypes of neuraminidase, categorized based on slight variations in their amino acid sequences. These variations can affect the protein’s function and its recognition by the immune system.</p></li></ol><p>Understanding the function and structure of the influenza NA protein is crucial for developing antiviral drugs and vaccines. Neuraminidase inhibitors, for example, are a class of antiviral drugs that block the activity of this protein, effectively preventing the virus from spreading within the host.</p><h2 id="Leading-Research">Leading Research</h2><p>A paper<sup class="footnote-ref"><a href="#fn11" id="fnref11">[11]</a></sup> investigates the antigenic evolution of the neuraminidase (NA) protein in the H3N2 influenza virus. Using combinatorial mutagenesis and next-generation sequencing, the study focuses on seven specific residues in an antigenic region of NA. It finds that the local fitness landscape of this region is highly correlated across different H3N2 strains and reveals that <mark>local net charge balancing</mark> is a significant constraint in NA antigenic evolution. The study also demonstrates a correlation between epistasis and residue coevolution in naturally circulating influenza strains, providing important insights into the biophysical constraints on NA antigenic evolution.</p><table><thead><tr><th style="text-align:center"><img src="https://iiif.elifesciences.org/lax/72516%2Felife-72516-fig1-v2.tif/full/1500,/0/default.jpg" alt=""></th></tr></thead><tbody><tr><td style="text-align:center">© Wang Y; 2021<sup class="footnote-ref"><a href="#fn11" id="fnref11:1">[11:1]</a></sup></td></tr></tbody></table><h2 id="Features-from-Other-NA-protein">Features from Other NA protein</h2><p>H1N1:</p><ul><li>K253R could reduce the 75% of virion-associated NA activity<sup class="footnote-ref"><a href="#fn12" id="fnref12">[12]</a></sup>.</li></ul><style>pre {  background-color:#38393d;  color: #5fd381;}</style><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>Blok, J., and Air, G. M. (1982). Variation in the membrane-insertion and “stalk” sequences in eight subtypes of influenza type A virus neuraminidase. Biochemistry 21, 4001–4007. <a href="#fnref1" class="footnote-backref">↩︎</a> <a href="#fnref1:1" class="footnote-backref">↩︎</a> <a href="#fnref1:2" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>Garcia-Sastre, A., and Palese, P. (1995). The cytoplasmic tail of the neuraminidase protein of influenza A virus does not play an important role in the packaging of this protein into viral envelopes. Virus Res. 37, 37–47. doi: 10.1016/0168-1702(95)00017-K <a href="#fnref2" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>Air, G. M. (2012). Influenza neuraminidase. Influenza Other Respir. Viruses 6, 245–256. doi: 10.1111/j.1750-2659.2011.00304.x <a href="#fnref3" class="footnote-backref">↩︎</a> <a href="#fnref3:1" class="footnote-backref">↩︎</a></p></li><li id="fn4" class="footnote-item"><p>Nordholm, J., Da Silva, D. V., Damjanovic, J., Dou, D., and Daniels, R. (2013). Polar residues and their positional context dictate the transmembrane domain interactions of influenza A neuraminidases. J. Biol. Chem. 288, 10652–10660. doi: 10.1074/jbc.M112.440230 <a href="#fnref4" class="footnote-backref">↩︎</a></p></li><li id="fn5" class="footnote-item"><p>Harris, A., Cardone, G., Winkler, D. C., Heymann, J. B., Brecher, M., White, J. M., et al. (2006). Influenza virus pleiomorphy characterized by cryoelectron tomography. Proc. Natl. Acad. Sci. U. S. A. 103, 19123–19127. doi: 10.1073/pnas.0607614103 <a href="#fnref5" class="footnote-backref">↩︎</a></p></li><li id="fn6" class="footnote-item"><p>Matsuoka, Y., Swayne, D. E., Thomas, C., Rameix-Welti, M. A., Naffakh, N., Warnes, C., et al. (2009). Neuraminidase stalk length and additional glycosylation of the hemagglutinin influence the virulence of influenza H5N1 viruses for mice. J. Virol. 83, 4704–4708. doi: 10.1128/JVI.01987-08 <a href="#fnref6" class="footnote-backref">↩︎</a></p></li><li id="fn7" class="footnote-item"><p>Park, S., Il Kim, J., Lee, I., Bae, J. Y., Yoo, K., Nam, M., et al. (2017). Adaptive mutations of neuraminidase stalk truncation and deglycosylation confer enhanced pathogenicity of influenza A viruses. Sci. Rep. 7:10928. doi: 10.1038/s41598-017-11348-0 <a href="#fnref7" class="footnote-backref">↩︎</a></p></li><li id="fn8" class="footnote-item"><p>Colman, P. M., Varghese, J. N., and Laver, W. G. (1983). Structure of the catalytic and antigenic sites in influenza virus neuraminidase. Nature 303, 41–44. doi: 10.1038/303041a0 <a href="#fnref8" class="footnote-backref">↩︎</a></p></li><li id="fn9" class="footnote-item"><p>Varghese, J. N., McKimm-Breschkin, J. L., Caldwell, J. B., Kortt, A. A., and Colman, P. M. (1992). The structure of the complex between influenza virus neuraminidase and sialic acid, the viral receptor. Proteins 14, 327–332. doi: 10.1002/prot.340140302 <a href="#fnref9" class="footnote-backref">↩︎</a></p></li><li id="fn10" class="footnote-item"><p>Schmidt, P. M., Attwood, R. M., Mohr, P. G., Barrett, S. A., and McKimm-Breschkin, J. L. (2011). A generic system for the expression and purification of soluble and stable influenza neuraminidase. PLoS One 6:e16284. doi: 10.1371/journal.pone.0016284<br>[^McKimm_13]McKimm-Breschkin, J. L., Williams, J., Barrett, S., Jachno, K., McDonald, M., Mohr, P. G., et al. (2013). Reduced susceptibility to all neuraminidase inhibitors of influenza H1N1 viruses with haemagglutinin mutations and mutations in non-conserved residues of the neuraminidase. J. Antimicrob. Chemother. 68, 2210–2221. doi: 10.1093/jac/dkt205<br>[^Fujisaki_12]Fujisaki, S., Takashita, E., Yokoyama, M., Taniwaki, T., Xu, H., Kishida, N., et al. (2012). A single E105K mutation far from the active site of influenza B virus neuraminidase contributes to reduced susceptibility to multiple neuraminidase-inhibitor drugs. Biochem. Biophys. Res. Commun. 429, 51–56. doi: 10.1016/j.bbrc.2012.10.095<br>[^McKimm_96b]McKimm-Breschkin, J. L., McDonald, M., Blick, T. J., and Colman, P. M. (1996b). Mutation in the influenza virus neuraminidase gene resulting in decreased sensitivity to the neuraminidase inhibitor 4-guanidino-Neu5Ac2en leads to instability of the enzyme. Virology 225, 240–242. <a href="#fnref10" class="footnote-backref">↩︎</a></p></li><li id="fn11" class="footnote-item"><p>Wang Y, Lei R, Nourmohammad A, et al. Antigenic evolution of human influenza H3N2 neuraminidase is constrained by charge balancing[J]. Elife, 2021, 10: e72516. <a href="#fnref11" class="footnote-backref">↩︎</a> <a href="#fnref11:1" class="footnote-backref">↩︎</a></p></li><li id="fn12" class="footnote-item"><p>Liu T, Wang Y, Tan T J C, et al. The evolutionary potential of influenza A virus hemagglutinin is highly constrained by epistatic interactions with neuraminidase[J]. Cell Host &amp; Microbe, 2022, 30(10): 1363-1369. e4. <a href="#fnref12" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">Basic Knowledge of Neuraminidase (NA) protein</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Notes/Biology/"/>
    
    <category term="Immunity" scheme="https://karobben.github.io/categories/Notes/Biology/Immunity/"/>
    
    
    <category term="Biology" scheme="https://karobben.github.io/tags/Biology/"/>
    
    <category term="Immunology" scheme="https://karobben.github.io/tags/Immunology/"/>
    
    <category term="Antibody" scheme="https://karobben.github.io/tags/Antibody/"/>
    
  </entry>
  
  <entry>
    <title>Understanding False Discovery Rate (FDR) and the Benjamini-Hochberg Method</title>
    <link href="https://karobben.github.io/2023/12/07/LearnNotes/fdr/"/>
    <id>https://karobben.github.io/2023/12/07/LearnNotes/fdr/</id>
    <published>2023-12-07T18:13:35.000Z</published>
    <updated>2023-12-07T18:46:09.881Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Understanding-False-Discovery-Rate-FDR-and-the-Benjamini-Hochberg-Method">Understanding False Discovery Rate (FDR) and the Benjamini-Hochberg Method</h2><div class="admonition note"><p class="admonition-title">Warning</p><p>This Passages is completely composed by ChatGPT4</p></div><p>In the realm of statistical analysis, particularly in fields inundated with vast datasets like genomics, neuroscience, and social sciences, the concept of False Discovery Rate (FDR) has become pivotal. This post delves into the essence of FDR, its significance in multiple hypothesis testing, and the widely adopted Benjamini-Hochberg (BH) method for FDR control.</p><h2 id="What-is-False-Discovery-Rate-FDR">What is False Discovery Rate (FDR)?</h2><p>False Discovery Rate is a statistical measure used in multiple hypothesis testing to identify the proportion of false positives (incorrectly rejected null hypotheses) among all rejected hypotheses. In simpler terms, it represents the expected ratio of erroneous discoveries to the total number of discoveries.</p><h3 id="Importance-of-FDR">Importance of FDR:</h3><ul><li><strong>Multiple Comparisons Problem</strong>: When testing multiple hypotheses simultaneously, the likelihood of encountering false positives increases.</li><li><strong>Balancing Sensitivity and Specificity</strong>: FDR provides a balanced approach, controlling the rate of false discoveries while maintaining the ability to detect true effects.</li></ul><h2 id="The-Benjamini-Hochberg-BH-Method">The Benjamini-Hochberg (BH) Method:</h2><p>Developed by Yoav Benjamini and Yosef Hochberg in 1995, the BH method is a practical approach to controlling the FDR in multiple testing scenarios.</p><h3 id="How-the-BH-Method-Works">How the BH Method Works:</h3><ol><li><p><strong>Rank P-values</strong>: Arrange the p-values from individual hypothesis tests in ascending order.</p></li><li><p><strong>Calculate Adjusted P-values</strong>: Compute adjusted p-values using the formula:</p><p>$$ \text{Adjusted p-value} = \min\left(\frac{\text{Original p-value} \times N}{\text{Rank}}, 1\right) $$</p><p>Here, $N$ is the total number of tests, and ‘Rank’ is the position of the original p-value in the ordered list.</p></li><li><p><strong>Interpretation</strong>: Compare these adjusted p-values with a pre-defined FDR threshold (e.g., 0.05). Tests with adjusted p-values below this threshold are deemed statistically significant.</p></li></ol><h3 id="Advantages-of-the-BH-Method">Advantages of the BH Method:</h3><ul><li><strong>Less Conservative</strong>: Unlike methods that control the family-wise error rate (FWER), the BH method is less stringent, leading to greater statistical power in detecting true effects.</li><li><strong>Adaptability</strong>: Works well across various disciplines where multiple hypothesis testing is common.</li></ul><h3 id="Limitations">Limitations:</h3><ul><li><strong>Assumption of Independence</strong>: The method assumes that tests are independent or positively dependent. Its effectiveness may diminish if this assumption is violated.</li><li><strong>FDR, Not FWER</strong>: It controls the rate of false discoveries, not the probability of making any Type I error.</li></ul><h2 id="Application-in-R">Application in R:</h2><p>In R, the <code>p.adjust</code> function is used for FDR adjustment, specifically with the “BH” method. This function modifies the original p-values from your tests, providing adjusted values that can be compared to your FDR threshold.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r">p_values &lt;- <span class="hljs-built_in">c</span>(<span class="hljs-number">0.01</span>, <span class="hljs-number">0.04</span>, <span class="hljs-number">0.03</span>, <span class="hljs-number">0.05</span>, <span class="hljs-number">0.20</span>)<br>adjusted_p_values &lt;- p.adjust(p_values, method = <span class="hljs-string">&quot;BH&quot;</span>)<br><br>print(adjusted_p_values)<br></code></pre></td></tr></table></figure></div><h2 id="Other-Adjustment-Methods">Other Adjustment Methods</h2><p>Here’s a comparison of various p-value adjustment methods in a tabular format:</p><table><thead><tr><th>Method</th><th>Description</th><th>Advantages</th><th>Limitations</th><th>Suitable Data</th></tr></thead><tbody><tr><td><strong>Bonferroni Correction</strong></td><td>Divides alpha level by the number of tests.</td><td>Simple, very conservative, controls FWER.</td><td>Too conservative, higher Type II error risk.</td><td>Small number of hypotheses.</td></tr><tr><td><strong>Benjamini-Yekutieli (BY)</strong></td><td>Generalization of BH, works under any dependency.</td><td>Controls FDR under any dependency structure.</td><td>More conservative than BH.</td><td>Tests with unknown dependencies.</td></tr><tr><td><strong>Holm-Bonferroni</strong></td><td>Sequentially compares p-values to adjusted alpha.</td><td>Less conservative than Bonferroni, controls FWER.</td><td>Still quite conservative with many tests.</td><td>Moderately sized numbers of hypotheses.</td></tr><tr><td><strong>Šidák Correction</strong></td><td>Similar to Bonferroni, assumes independence.</td><td>Less conservative than Bonferroni for independent tests.</td><td>Assumes independence among tests.</td><td>Independent hypotheses.</td></tr><tr><td><strong>False Discovery Rate (FDR) - BH Method</strong></td><td>Controls the expected proportion of false discoveries.</td><td>Less conservative than FWER methods, more power.</td><td>May not control FWER, assumes some test independence.</td><td>Large-scale testing like genomics.</td></tr></tbody></table><p>This table provides an overview of the key features, advantages, limitations, and suitable applications for each method. The choice of method depends on the balance between the risk of false positives and the need for statistical power, as well as the nature and scale of the data being analyzed.</p><h2 id="Other-than-FDR">Other than FDR</h2><p>Besides False Discovery Rate (FDR) methods like the Benjamini-Hochberg procedure, there are several other methods for adjusting p-values in the context of multiple hypothesis testing. These methods primarily aim to control different types of error rates. Here are some of the key methods:</p><ol><li><p><strong>Family-Wise Error Rate (FWER) Methods</strong>:</p><ul><li><strong>Bonferroni Correction</strong>: The simplest and most conservative method, which multiplies each p-value by the number of tests (or compares each p-value against the significance level divided by the number of tests).</li><li><strong>Holm-Bonferroni Method</strong>: A stepwise adjustment method that sequentially adjusts p-values in ascending order, slightly less conservative than the Bonferroni correction.</li><li><strong>Šidák Correction</strong>: Similar to Bonferroni but slightly less conservative, assuming that all tests are independent.</li><li><strong>Hochberg’s Method</strong>: Another step-up procedure that is less conservative than the Holm-Bonferroni method.</li></ul></li><li><p><strong>Permutation Tests</strong>:</p><ul><li><strong>Permutation-Based Adjustments</strong>: These involve recalculating p-values by comparing observed test statistics to their distribution under permutations of the data. This approach is particularly useful for complex or non-standard data structures.</li></ul></li><li><p><strong>Bayesian Methods</strong>:</p><ul><li><strong>Bayesian Adjustments</strong>: These involve using Bayesian statistics to adjust p-values, which can incorporate prior information and provide a different perspective on significance.</li></ul></li><li><p><strong>False Coverage Rate (FCR) Procedures</strong>:</p><ul><li><strong>Benjamini-Hochberg-Yekutieli Procedure</strong>: An extension of the BH procedure that controls the FCR, the expected proportion of incorrect coverage statements among all coverage statements made.</li></ul></li><li><p><strong>Local False Discovery Rate (LFDR)</strong>:</p><ul><li><strong>LFDR Adjustments</strong>: Focuses on the probability that a particular null hypothesis is true given the observed p-value, providing a local (individual) measure of significance.</li></ul></li></ol><p>Each of these methods has its strengths and weaknesses, and the choice of method depends on the specific goals of the analysis, the nature of the data, and the type of error control desired. For example, FWER methods are typically used when it’s crucial to minimize the chance of any false positives, while FDR methods are more appropriate when dealing with large numbers of tests and when some false positives can be tolerated to gain higher statistical power.</p><h2 id="Conclusion">Conclusion</h2><p>In conclusion, the landscape of statistical analysis, particularly in the context of multiple hypothesis testing, has been significantly enriched and diversified through various p-value adjustment methods. Among these, the Benjamini-Hochberg (BH) method stands out as a revolutionary approach. It offers a balanced and less conservative alternative for statistical inference, adeptly addressing the challenges posed by large-scale data analyses. The BH method, by controlling the False Discovery Rate (FDR), allows researchers to manage the trade-off between discovering true effects and limiting false positives effectively.</p><p>Simultaneously, the existence of other methods such as the Bonferroni correction, Holm-Bonferroni, and Šidák adjustments, along with more complex procedures like permutation tests and Bayesian methods, underscores the diversity of tools available to researchers. Each method comes with its unique strengths and limitations, catering to different types of data and research objectives. For instance, FWER-controlling methods like the Bonferroni correction are invaluable in scenarios where even a single false positive is unacceptable, while FDR-controlling approaches like the BH method are more suitable for exploratory analyses with large datasets.</p><p>The integration of these methods into statistical software such as R has further democratized access to sophisticated statistical tools, enabling researchers from various fields to apply the most appropriate methods to their data. This accessibility ensures that research findings are both robust and reliable, despite the inherent challenges of multiple comparisons.</p><p>In essence, the BH method, along with other p-value adjustment techniques, equips researchers with the necessary tools to navigate the complexities of modern data landscapes confidently. They collectively ensure that researchers can uncover meaningful insights without the risk of being misled by false discoveries, thereby advancing the pursuit of knowledge across various scientific disciplines.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">A comprehensive guide on False Discovery Rate (FDR) and the Benjamini-Hochberg Method, detailing their importance in statistical analysis for multiple hypothesis testing.</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Statistic" scheme="https://karobben.github.io/categories/Notes/Statistic/"/>
    
    <category term="others" scheme="https://karobben.github.io/categories/Notes/Statistic/others/"/>
    
    
    <category term="Statistic" scheme="https://karobben.github.io/tags/Statistic/"/>
    
  </entry>
  
  <entry>
    <title>Visualize the Protein Mesh with pyvista</title>
    <link href="https://karobben.github.io/2023/12/06/Bioinfor/pymol2pyvista/"/>
    <id>https://karobben.github.io/2023/12/06/Bioinfor/pymol2pyvista/</id>
    <published>2023-12-06T19:46:30.000Z</published>
    <updated>2023-12-08T22:26:19.309Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Prerrequirement">Prerrequirement</h2><pre>pymolcolladapyvista</pre><p>All libraries could be installed by <code>pip</code></p><h2 id="Save-the-Mesh-Information-with-Pymol">Save the Mesh Information with Pymol</h2><p>after loaded your model:</p><p>Example file: 2a6d<br>Target: Extract the mesh information of CDR region from a antibody<br>PS: output may takes a while.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><code class="hljs pymol">bg_color white<br>color deepblue, 2a6d<br><br>select CDR1, 2a6d and chain B and resi 31-35<br>select CDR2, 2a6d and chain B and resi 50-66<br>select CDR3, 2a6d and chain B and resi 99-110<br>create cdr, CDR1 CDR2 CDR3<br><br>show mesh, cdr<br>color hotpink, cdr<br><br>hide all<br>show surface, cdr<br>save object.stl, cdr<br></code></pre></td></tr></table></figure></div><p><img src="https://imgur.com/bNjPfcD.png" alt="Select a target area from pymol"></p><h2 id="Load-It-with-pyvista">Load It with pyvista</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pyvista <span class="hljs-keyword">as</span> pv<br>mesh = pv.read(<span class="hljs-string">&#x27;object.stl&#x27;</span>)<br><br>mesh.plot()<br><br>plotter = pv.Plotter(off_screen=<span class="hljs-literal">True</span>)<br>plotter.add_mesh(mesh)<br>plotter.show(screenshot=<span class="hljs-string">&quot;myscreenshot.png&quot;</span>)<br></code></pre></td></tr></table></figure></div><p><img src="https://imgur.com/kH46OTm.png" alt="stl file visualize by pyvista"></p><h2 id="Model-Manipulation">Model Manipulation</h2><h3 id="Rotate-the-Model">Rotate the Model</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Rotate the mesh</span><br>angle = <span class="hljs-number">45</span>  <span class="hljs-comment"># Angle in degrees</span><br><br>mesh.rotate_x(angle)  <span class="hljs-comment"># Rotate 45 degrees around the x-axis</span><br><span class="hljs-comment"># mesh.rotate_y(angle)  # Rotate around the y-axis</span><br><span class="hljs-comment"># mesh.rotate_z(angle)  # Rotate around the z-axis</span><br><br><span class="hljs-comment"># For rotation around an arbitrary axis (e.g., [1, 1, 1]), use:</span><br><span class="hljs-comment"># mesh.rotate_vector([1, 1, 1], angle)</span><br><br><span class="hljs-comment"># Now you can plot the rotated mesh</span><br>plotter = pv.Plotter()<br>plotter.add_mesh(mesh)<br>plotter.show()<br></code></pre></td></tr></table></figure></div><h3 id="Move-the-Model">Move the Model</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pyvista <span class="hljs-keyword">as</span> pv<br><br><span class="hljs-comment"># Assume &#x27;mesh&#x27; is your PyVista mesh</span><br><span class="hljs-comment"># ...</span><br><br><span class="hljs-comment"># Translate the mesh</span><br>translation_vector = [<span class="hljs-number">10</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]  <span class="hljs-comment"># This will move the mesh 10 units along the x-axis</span><br>mesh.translate(translation_vector)<br><br><span class="hljs-comment"># Now you can plot the translated mesh</span><br>plotter = pv.Plotter()<br>plotter.add_mesh(mesh)<br>plotter.show()<br></code></pre></td></tr></table></figure></div><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">seamlessly bridges PyMOL and Python: read PyMOL result to python</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Protein Structure" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Protein-Structure/"/>
    
    
    <category term="Software" scheme="https://karobben.github.io/tags/Software/"/>
    
    <category term="3D" scheme="https://karobben.github.io/tags/3D/"/>
    
    <category term="Protein Structure" scheme="https://karobben.github.io/tags/Protein-Structure/"/>
    
    <category term="Pyvista" scheme="https://karobben.github.io/tags/Pyvista/"/>
    
    <category term="PyMol" scheme="https://karobben.github.io/tags/PyMol/"/>
    
  </entry>
  
  <entry>
    <title>CR9114</title>
    <link href="https://karobben.github.io/2023/11/22/LearnNotes/panHA/"/>
    <id>https://karobben.github.io/2023/11/22/LearnNotes/panHA/</id>
    <published>2023-11-23T03:38:28.000Z</published>
    <updated>2023-12-18T19:28:54.100Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Pan-fluenza-family">Pan fluenza family</h2><ul><li>CR9114 from V<sub>H</sub>1-69<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>: <ai>This antibody, derived from the V<sub>H</sub>1-69 gene segment, is known for its broad reactivity against both group 1 and group 2 influenza A viruses. CR9114 binds to a highly conserved epitope in the HA stem region. This region is involved in the fusion of the viral and host cell membranes, a critical step in the viral infection process. By binding to this region, CR9114 can block the conformational changes required for membrane fusion, thereby inhibiting viral entry into host cells.</ai></li><li>CR6261 from V<sub>H</sub>1-69<sup class="footnote-ref"><a href="#fn1" id="fnref1:1">[1:1]</a></sup>: <ai>Also originating from the V<sub>H</sub>1-69 gene segment, CR6261 specifically targets group 1 influenza A viruses. Like CR9114, CR6261 binds to the stem region of HA, but its binding is more restricted to group 1 viruses. This antibody stabilizes the pre-fusion form of HA, preventing the structural rearrangements necessary for the virus to fuse with the host cell membrane.</ai></li><li>FI6v3 from V<sub>H</sub>3-30<sup class="footnote-ref"><a href="#fn1" id="fnref1:2">[1:2]</a></sup>: <ai>Derived from the V<sub>H</sub>3-30 gene segment, FI6v3 is notable for its broad neutralizing activity against all known subtypes of influenza A viruses. This broad reactivity is achieved through its binding to a conserved epitope in the HA stem region, similar to CR9114 and CR6261. However, the precise mode of binding and the epitope details might differ, contributing to its unique broad-spectrum activity.</ai></li><li>CR8020<sup class="footnote-ref"><a href="#fn1" id="fnref1:3">[1:3]</a></sup>: <ai>CR8020’s mode of binding is distinct from the others. It targets a specific epitope in the HA stem region that is predominantly present in group 2 influenza A viruses. By binding to this site, CR8020 can inhibit the necessary conformational changes in the HA protein during the virus’s entry into the host cell, thereby neutralizing the virus.</ai></li></ul><p>Five important hydrophobic pockets.</p><table><thead><tr><th style="text-align:center"><img src="https://perspectivesinmedicine.cshlp.org/content/10/8/a038778/F4.large.jpg" alt="HA"></th></tr></thead><tbody><tr><td style="text-align:center">© Wu, 2020<sup class="footnote-ref"><a href="#fn1" id="fnref1:4">[1:4]</a></sup></td></tr></tbody></table><h2 id="CR9114">CR9114</h2><h3 id="Light-Chain">Light Chain</h3><p><ai>The CR9114 light chain contains a specific sequence motif in its CDR L3 region that is important for binding to the HA stem of the influenza A virus. The motif consists of two aromatic amino acids, Trp91 and Trp96, which are positioned toward the heavy chain with limited space in between. These aromatic residues participate in π-π stacking interactions with the HA protein, specifically with the tryptophan residue at position 91, which is located in the CDR L3 region.</ai><sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup></p><ul><li>Importance of CR9114 light-chain residues 91 and 96<sup class="footnote-ref"><a href="#fn2" id="fnref2:1">[2:1]</a></sup><ul><li>Trp91: <ai>This tryptophan residue is located in the CDR L3 region of CR9114 and has been identified as a key residue for HA binding. It forms a π-π stacking interaction with the tryptophan residues in the HA stem, which is stabilized by hydrogen bonds between the amide and carbonyl groups.<ai></li><li>Small amino acid Ala at VL residue 96, which points toward the heavy chain with limited space in between</li><li><ai>The binding activity of CR9114 to the HA stem was found to be abolished when the non-aromatic amino acids threonine (T), arginine ®, or alanine (A) were substituted for the aromatic residue tryptophan at position 91. Similarly, substitution with aromatic amino acids tyrosine (Y) or phenylalanine (F) did not disrupt binding activity. This suggests that the presence of an aromatic residue at position 91 is essential for CR9114 binding to the HA stem.<ai><sup class="footnote-ref"><a href="#fn2" id="fnref2:2">[2:2]</a></sup></li></ul></li></ul><h3 id="Heavy-Chain">Heavy Chain</h3><ul><li><strong>Y98</strong>, <strong>Y99</strong>, <strong>Y100</strong>, and <strong>Y100a</strong> in CDR H3 (heavy chain)<sup class="footnote-ref"><a href="#fn2" id="fnref2:3">[2:3]</a></sup></li><li><strong>H95</strong> and <strong>N97</strong>: the side chains of both VH H95 and VH N97 are not interacting with the HA stem epitope. Instead, both VH H95 and VH N97 form intramolecular interactions to stabilize the CDR H3 conformation.<ul><li><strong>H95</strong> H-bonds with VH <strong>S100b</strong> and VH <strong>S35</strong> as well as interacts with VH <strong>Y100</strong> via T-shaped p-p stacking</li><li><strong>N97</strong> H-bonds with VH <strong>Y99</strong> and VH S100b<sup class="footnote-ref"><a href="#fn2" id="fnref2:4">[2:4]</a></sup></li></ul></li><li>Most CDR H3 variants are incompatible with CR9114 for HA stem binding<sup class="footnote-ref"><a href="#fn2" id="fnref2:5">[2:5]</a></sup></li></ul><table><thead><tr><th style="text-align:center"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S2211124723014225-gr4.jpg" alt=""></th></tr></thead><tbody><tr><td style="text-align:center">H95 and VH N97 stabilize the CDR H3 conformation<sup class="footnote-ref"><a href="#fn2" id="fnref2:6">[2:6]</a></sup></td></tr><tr><td style="text-align:center"><img src="https://imgur.com/iWELcwB.png" alt=""></td></tr><tr><td style="text-align:center">light chain 91, 96, and 98 insert into the hydrophobic pocket<sup class="footnote-ref"><a href="#fn2" id="fnref2:7">[2:7]</a></sup></td></tr></tbody></table><blockquote><p><img src="https://www.frontiersin.org/files/Articles/1049134/fviro-02-1049134-HTML-r4/image_m/fviro-02-1049134-g004.jpg" alt="CR9114 key amino acid"><br>Structure of CR9114, indicating the 16 AAs that differ between the germline and the somatic variant. Mutated residues (53) (16 positions) are shown in orange sticks. Residues IDs as labelled in orange are converted to the somatic sequence as in the PDB structure (table). Mutated residues required (53) for gaining affinity for H1, H3, and B HA are indicated in the table (+ required mutation, *mutation improves binding). Some key residues, such as F54 (HCDR2) and a quadruplet “YYYY” in HCDR3, are additionally displayed in magenta sticks. The heavy and light chains are shown in magenta and yellow, respectively.<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup></p></blockquote><h2 id="CR9114-and-CR6261">CR9114 and CR6261</h2><p>CDR1:</p><ul><li>CR9114: The <strong>I73</strong> in the FR3 loop allows CR9114 to ﬂip into the hydrophobic groove of inﬂuenza H5 (Figure 3C) and H3</li><li>CR6261: <strong>D73</strong>: Its side chain has a different conformation and ﬂips out of the hydrophobic groove of H5.<ul><li><strong>R30—D73</strong> form a stable and preferable internal H-bond</li><li><strong>D73(FR3)—R30 (HCDR1) —Y32 (HCDR1)</strong> and <strong>A33(HCDR1)—G97 (HCDR3)</strong>: expanded HCDR1 loop brings <strong>F29</strong> into the groove nearby for interacting with the hydrophobic pocket of H5</li></ul></li></ul><p>CDR2:</p><ul><li>CR9114: polar <strong>S52</strong><ul><li>internal H-bond with <strong>Y98</strong> (HCRD3) which can induce enlargement of the HCDR2 loop</li><li>HCDR2 loop of CR9114 can block a larger space at the binding groove of HAs, and several residues at this loop can interact with H3 HA F54-W21(H3),</li></ul></li><li>CR6261: hydrophobic <strong>I52</strong><ul><li>backbone atoms of <strong>I52</strong>-<strong>G55</strong>/<strong>T56</strong> and <strong>P52A</strong>-<strong>F54</strong> pair form H-bonds → small and rigid HCDR2 loop of CR6261</li></ul></li></ul><p>CDR3:</p><ul><li>CR9114: <sup>96</sup>GNYYYYSG<sup>100C</sup><ul><li>It establishes crucial H-bonds with H5 HA (<strong>Y98</strong>-Q42, <strong>Y98</strong>/<strong>Y100A</strong>-D19) and H3 HA (<strong>Y98</strong>-T41/Q42, <strong>Y100A</strong>-D19)</li><li>A short distance between <strong>Y99</strong> (CR9114) to the backbone atom of V18 can induce a strong charge-charge interaction between CR9114 and HAs</li></ul></li><li>CR6261: <sup>96</sup>MGYQVRET<sup>100C</sup><ul><li>only <strong>Y98</strong> can form an H-bond with a residue</li><li>Longer distances between CR6261 residues and HA residues V18 and D19 result in very weak interactions: 7-8 Å for <strong>Q99</strong>–V18 and 11 Å for <strong>R100A</strong>-D19</li></ul></li></ul><table><thead><tr><th style="text-align:center">Binding preference between CR9114 and CR6261</th></tr></thead><tbody><tr><td style="text-align:center"><img src="https://imgur.com/GCMw6iZ.png" alt="CR9114 and CR6261"></td></tr><tr><td style="text-align:center"><img src="https://imgur.com/3otr25H.png" alt="CR9114 and CR6261"></td></tr><tr><td style="text-align:center">Anna L. Beukenhorst; 2022<sup class="footnote-ref"><a href="#fn3" id="fnref3:1">[3:1]</a></sup></td></tr></tbody></table><ol start="6"><li>W62 and W65 in the heavy-chain framework region 2</li></ol><style>pre {  background-color: #38393d;  color: #5fd381;}ai {   color:  #3572A8;}</style><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>Wu N C, Wilson I A. Influenza hemagglutinin structures and antibody recognition[J]. Cold Spring Harbor perspectives in medicine, 2020, 10(8): a038778. <a href="#fnref1" class="footnote-backref">↩︎</a> <a href="#fnref1:1" class="footnote-backref">↩︎</a> <a href="#fnref1:2" class="footnote-backref">↩︎</a> <a href="#fnref1:3" class="footnote-backref">↩︎</a> <a href="#fnref1:4" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>Teo Q W, Wang Y, Lv H, et al. Stringent and complex sequence constraints of an IGHV1-69 broadly neutralizing antibody to influenza HA stem[J]. Cell Reports, 2023, 42(11). <a href="#fnref2" class="footnote-backref">↩︎</a> <a href="#fnref2:1" class="footnote-backref">↩︎</a> <a href="#fnref2:2" class="footnote-backref">↩︎</a> <a href="#fnref2:3" class="footnote-backref">↩︎</a> <a href="#fnref2:4" class="footnote-backref">↩︎</a> <a href="#fnref2:5" class="footnote-backref">↩︎</a> <a href="#fnref2:6" class="footnote-backref">↩︎</a> <a href="#fnref2:7" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>Beukenhorst A L, Frallicciardi J, Koch C M, et al. The influenza hemagglutinin stem antibody CR9114: Evidence for a narrow evolutionary path towards universal protection[J]. Frontiers in Virology, 2022, 2: 1049134. <a href="#fnref3" class="footnote-backref">↩︎</a> <a href="#fnref3:1" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">A concise overview of the CR9114 antibody&#39;s binding to influenza A viruses, highlighting its effectiveness and comparison with other antibodies.</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Notes/Biology/"/>
    
    <category term="Immunity" scheme="https://karobben.github.io/categories/Notes/Biology/Immunity/"/>
    
    
    <category term="Biology" scheme="https://karobben.github.io/tags/Biology/"/>
    
    <category term="Immunology" scheme="https://karobben.github.io/tags/Immunology/"/>
    
    <category term="Antibody" scheme="https://karobben.github.io/tags/Antibody/"/>
    
  </entry>
  
  <entry>
    <title>Understanding Antibodies and Phage Display: A Deep Dive</title>
    <link href="https://karobben.github.io/2023/10/31/LearnNotes/immun/"/>
    <id>https://karobben.github.io/2023/10/31/LearnNotes/immun/</id>
    <published>2023-10-31T18:45:08.000Z</published>
    <updated>2023-12-18T19:28:28.448Z</updated>
    
    <content type="html"><![CDATA[<h2 id="The-Magnificent-World-of-Antibodies"><strong>The Magnificent World of Antibodies</strong></h2><p>Antibodies, also known as immunoglobulins, are Y-shaped proteins produced by the immune system to neutralize foreign substances like bacteria and viruses. Let’s break down the components:</p><h3 id="Heavy-Chain-Light-Chain"><strong>Heavy Chain &amp; Light Chain</strong></h3><p>The basic structure of an antibody is composed of two identical heavy chains and two identical light chains. Each chain is a sequence of amino acids, which fold into a specific three-dimensional shape.</p><ul><li><p><strong>Heavy Chain (H)</strong>: The heavy chains are the larger of the two, and they form the base of the Y-shape. They play a pivotal role in determining the class of an antibody (like IgG, IgM, IgA, etc.).</p></li><li><p><strong>Light Chain (L)</strong>: The light chains pair with the heavy chains to form the arms of the Y-shaped antibody. Each antibody has one of two types of light chains - either kappa (κ) or lambda (λ).</p></li></ul><h3 id="Complementarity-Determining-Regions-CDR"><strong>Complementarity-Determining Regions (CDR)</strong></h3><table><thead><tr><th style="text-align:center"><img src="https://www.rapidnovor.com/wp-content/uploads/2022/04/Antibody-CDR-600x273.png" alt="CDR"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.rapidnovor.com/identifying-cdrs-antibody-sequencing/">Yuning Wang, PhD</a></td></tr></tbody></table><p>The tips of the “Y” arms contain a special region known as the CDR. This region is responsible for recognizing and binding to specific parts of foreign invaders, called antigens. Each antibody has six CDRs (three from the light chain and three from the heavy chain), which collectively determine its specificity. It’s like the “lock and key” model; the CDR is the lock, and the antigen is the key.</p><h2 id="The-Magic-of-Phage-Display"><strong>The Magic of Phage Display</strong></h2><p>Phage display is a high-throughput technology used to study protein-protein, protein-peptide, and protein-DNA interactions. It’s like a library, but instead of books, we have bacteriophages - viruses that infect bacteria.</p><h3 id="Basics-of-Phage-Display"><strong>Basics of Phage Display</strong></h3><table><thead><tr><th style="text-align:center"><img src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3656071/bin/hvi-8-1817-g1.jpg" alt="Different types of phage"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3656071/">© Justyna Bazan</a></td></tr></tbody></table><p>In phage display, a gene encoding a protein or peptide of interest is fused to a coat protein gene of a bacteriophage, causing the displayed protein to be expressed on the outside of the phage particle. This allows the protein to be physically linked to the genetic information that encodes it.</p><h3 id="Display-of-antibody-fragments"><strong>Display of antibody fragments</strong></h3><p>Typically, antibodies comprise two heavy chains and a pair of light chains interconnected through noncovalent bonds and disulfide bridges. However, unique antibodies without light chains, found in Camelidae serum, bind antigens using a specific V<sub>H</sub>H fragment. This fragment can recognize distinctive conformational epitopes due to its extended complementary-determining region 3 (CDR3).</p><p>Antibody fragments’ expression in E. coli necessitates in vivo refolding to maintain their activity and function. A method for soluble recombinant protein expression in the cytoplasm of the Origami DE3 E. coli strain has been introduced. This method enhances the folding of heterologous proteins dependent on disulfide bonds. Intriguingly, scFv expressed in the bacterial cytoplasm displayed superior binding characteristics compared to periplasmic expression. While periplasmic expression offers suitable conditions for V<sub>H</sub> and V<sub>L</sub> pairing, co-expression of periplasmic chaperones has shown to significantly impact soluble scFv productivity.</p><p>Various antibody fragments, including Fab, Fv, scFv, and their modifications, are employed in phage display technology. These fragments, particularly scFv, have been expressed on the phage surface without compromising antibody affinity. The CRAbs construct, comprising two scFv fragments targeting adjacent epitopes, is one notable example.</p><table><thead><tr><th style="text-align:center"><img src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3656071/bin/hvi-8-1817-g2.jpg" alt="Schematic presentation of antibody fragments"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3656071/">© Justyna Bazan</a>; Fab (the antigen-binding fragment), scFab (the single chain antigen-binding fragment), scFabΔC (the scFab variant without cysteins), scFv (the single chain fragment variable), Fv (the fragment variable), VHdAb (the antibody with one variable heavy chain domain), CRAb (the construct specific to adjacent epitopes on the antigen)</td></tr></tbody></table><table><thead><tr><th>Antibody Fragment</th><th>Description</th></tr></thead><tbody><tr><td><strong>Fab</strong></td><td>VH-CH and VL-CL segments linked by disulfide bonds. Used in tumor imaging.</td></tr><tr><td><strong>Fv</strong></td><td>Comprises only the VL and VH regions.</td></tr><tr><td><strong>scFv</strong></td><td>A commonly used antibody fragment consisting of VL and VH regions stabilized by (Gly4Ser)3 linker.</td></tr><tr><td><strong>VHH</strong></td><td>Unique fragment found in Camelidae serum antibodies, targeting unique conformational epitopes.</td></tr><tr><td><strong>CRAbs</strong></td><td>Construct with two scFv fragments specific to adjacent epitopes of the same antigen.</td></tr><tr><td><strong>Diabodies</strong></td><td>Formed by dimerization of molecules and connection of antibody fragments.</td></tr></tbody></table><h3 id="Technical-Details-of-Phage-Display"><strong>Technical Details of Phage Display</strong></h3><h4 id="1-Phage-Biology-Basics"><strong>1. Phage Biology Basics:</strong></h4><ul><li><strong>Bacteriophages</strong>, or phages, are viruses that infect bacteria. They are composed of a protein coat that encases their genetic material, which can be either DNA or RNA.</li><li>The life cycle of a phage includes attaching to a bacterial cell, injecting its genetic material, and then using the host’s machinery to replicate and produce new phage particles.</li></ul><h4 id="2-Fusion-Proteins-in-Phage-Display"><strong>2. Fusion Proteins in Phage Display:</strong></h4><ul><li>The principle behind phage display is the creation of <strong>fusion proteins</strong>. A gene of interest (encoding the protein or peptide to be displayed) is inserted into a phage coat protein gene, leading to the expression of a fusion protein on the phage surface.</li><li>Commonly used coat proteins for display include <strong>pIII</strong> and <strong>pVIII</strong> of the M13 filamentous phage.</li></ul><h4 id="3-Constructing-the-Library"><strong>3. Constructing the Library:</strong></h4><ul><li>A diverse collection of DNA sequences is cloned into phage vectors to produce a <strong>library</strong>. This library represents a vast array of different peptides or proteins displayed on the phage surface.</li><li>The library’s diversity can range from millions to billions of unique sequences, making it a powerful tool for screening.</li></ul><h4 id="4-Biopanning-and-Selection"><strong>4. Biopanning and Selection:</strong></h4><ul><li><strong>Biopanning</strong> is the iterative process of enriching phages that bind to a specific target from a diverse library.</li><li>The process involves incubating the phage library with a target (e.g., a protein, cell, or tissue), washing away non-binding phages, and then amplifying the bound phages by infecting bacteria. This cycle is typically repeated several times to enrich for high-affinity binders.</li></ul><h4 id="5-Elution-and-Analysis"><strong>5. Elution and Analysis:</strong></h4><ul><li>After the final round of biopanning, bound phages are eluted, often by changing pH or adding a competitive ligand.</li><li>The DNA from these phages is then sequenced to identify the displayed peptides or proteins. Modern techniques like <strong>next-generation sequencing</strong> can be used to analyze vast numbers of sequences simultaneously.</li></ul><h4 id="6-Applications-in-Drug-Discovery"><strong>6. Applications in Drug Discovery:</strong></h4><ul><li>Phage display is instrumental in <strong>antibody engineering</strong>. Therapeutic antibodies like adalimumab (Humira) were discovered using phage display.</li><li>It’s also used to discover peptide ligands for various targets, which can lead to the development of new drugs or diagnostic tools.</li></ul><h4 id="7-Challenges-and-Considerations"><strong>7. Challenges and Considerations:</strong></h4><ul><li>While phage display is a powerful tool, it’s essential to consider factors like the library’s quality and diversity, the stringency of washing steps during biopanning, and potential biases introduced during phage amplification.</li><li>Some proteins or peptides may not be displayed well on the phage surface due to folding issues or interference with phage assembly.</li></ul><h3 id="Advanced-Insights"><strong>Advanced Insights</strong></h3><ul><li><p><strong>Library Creation</strong>: Scientists can create vast libraries of phages displaying a diverse array of peptides or proteins. When looking for a needle in a haystack (like a specific antibody for a new disease), this library becomes invaluable.</p></li><li><p><strong>Biopanning</strong>: This is the process of selecting phages that bind to a specific target. The library is exposed to a target (like a protein receptor), and non-binding phages are washed away. Those that bind are amplified, creating a pool of potential candidates.</p></li><li><p><strong>Applications</strong>: Phage display has revolutionized medicine, especially in the field of drug discovery. It’s instrumental in identifying therapeutic antibodies, understanding disease mechanisms, and even vaccine development.</p></li></ul><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Understanding Antibodies and Phage Display: A Deep Dive</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Notes/Biology/"/>
    
    <category term="Immunity" scheme="https://karobben.github.io/categories/Notes/Biology/Immunity/"/>
    
    
    <category term="Biology" scheme="https://karobben.github.io/tags/Biology/"/>
    
    <category term="Immunology" scheme="https://karobben.github.io/tags/Immunology/"/>
    
    <category term="Antibody" scheme="https://karobben.github.io/tags/Antibody/"/>
    
  </entry>
  
  <entry>
    <title>Understanding PacBio Sequencing: A Deep Dive for RNA-Seq Enthusiasts</title>
    <link href="https://karobben.github.io/2023/10/30/Bioinfor/PacBio/"/>
    <id>https://karobben.github.io/2023/10/30/Bioinfor/PacBio/</id>
    <published>2023-10-30T21:02:46.000Z</published>
    <updated>2023-10-31T16:44:50.974Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><strong>Introduction</strong>:</h2><p>For the seasoned RNA-Seq explorer, diving into the intricate realms of next-generation sequencing might be routine. But have you paused to marvel at PacBio sequencing, weighing its merits against other sequencing champions? Join us as we unravel PacBio’s mysteries, juxtapose it with its peers, and delve into its data analysis intricacies.</p><h2 id="What-is-PacBio-Sequencing"><strong>What is PacBio Sequencing?</strong></h2><table><thead><tr><th style="text-align:center"><img src="https://www.liebertpub.com/cms/10.1089/gen.36.20.03/asset/images/medium/gen.36.20.03.g001.png" alt="PacBio Sequencing"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.liebertpub.com/doi/10.1089/gen.36.20.03">© </a></td></tr></tbody></table><p>Pacific Biosciences, fondly termed PacBio, is the stalwart behind the long-read sequencing revolution. Standing distinct from short-read sequencers, PacBio devices unfurl considerably elongated reads, paving the path for precise assembly and a simplified data analysis voyage.</p><h2 id="PacBio-vs-Other-Sequencing-Technologies"><strong>PacBio vs. Other Sequencing Technologies</strong>:</h2><ul><li><p><strong>Short-Read Sequencing (e.g., Illumina)</strong>:</p><ul><li><em>Advantages</em>: High-throughput capabilities, economical for grand-scale endeavors, and a rich arsenal of tried-and-tested data tools.</li><li><em>Disadvantages</em>: The brevity of reads can muddle the assembly of repetitive domains and hinder the detection of structural variants.</li></ul></li><li><p><strong>PacBio (Long-Read Sequencing)</strong>:</p><ul><li><em>Advantages</em>: Its prowess in reading extensive DNA fragments simplifies genome assembly and eases the identification of structural variants. A boon, particularly for genomes riddled with repetitive sequences.</li><li><em>Disadvantages</em>: A compromise on throughput in comparison to short-read sequencing and a heftier price tag.</li></ul></li><li><p><strong>Nanopore Sequencing (e.g., Oxford Nanopore Technologies)</strong>:</p><ul><li><em>Advantages</em>: Astoundingly long reads, compact devices, and real-time sequencing insights.</li><li><em>Disadvantages</em>: A trade-off in accuracy vis-à-vis PacBio and an evolving, thus unpredictable, tech landscape.</li></ul></li></ul><h2 id="PacBio-Sequencing-Process">PacBio Sequencing Process</h2><table><thead><tr><th style="text-align:center"><img src="https://www.researchgate.net/profile/Chloe-Baum/publication/357946568/figure/fig2/AS:1114137841143808@1642642569421/Principle-of-Single-molecule-real-time-SMRT-sequencing-from-PacBio-Goodwin-McPherson.png" alt="PacBio"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.researchgate.net/publication/357946568_New_approaches_and_concepts_to_study_complex_microbial_communities?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6Il9kaXJlY3QiLCJwYWdlIjoicHVibGljYXRpb24iLCJwcmV2aW91c1BhZ2UiOiJfZGlyZWN0In19">© Chloé Baum</a></td></tr></tbody></table><p>Video Tutorial:<br>- <a href="https://www.youtube.com/watch?v=_lD8JyAbwEo">PacBio</a><br>- <a href="https://www.youtube.com/watch?v=-nOr5B_bF3A">RobEdwards; SDSU</a></p><p><strong>1. SMRTbell Template Preparation</strong>:</p><ul><li>DNA is fragmented to the desired length, typically ranging from a few kilobases to over 20 kb.</li><li>Fragmented DNA is treated to create blunt ends.</li><li>Hairpin adaptors, called SMRTbell adaptors, are ligated to these blunt ends. This results in the formation of SMRTbell templates which are essentially circular molecules of DNA.</li></ul><p><strong>2. Primer Annealing and DNA Polymerase Binding</strong>:</p><ul><li>A sequencing primer is annealed to the SMRTbell template.</li><li>High-fidelity DNA polymerase is then bound to the primer-annealed SMRTbell template.</li></ul><p><strong>3. Loading onto SMRT Cells</strong>:</p><ul><li>The polymerase-bound SMRTbell templates are loaded onto SMRT Cells. A SMRT Cell contains up to millions of zero-mode waveguides (ZMWs).</li><li>Only a fraction of ZMWs capture a polymerase-bound SMRTbell, ensuring each ZMW contains a single molecule.</li></ul><p><strong>4. Zero-Mode Waveguides (ZMWs)</strong>:</p><ul><li>ZMWs are nanophotonic structures that allow observation of individual fluorophores attached to nucleotides.</li><li>They work by confining the observation volume to a zeptoliter level, thereby enabling the detection of single-molecule fluorescence while excluding background fluorescence.</li></ul><p><strong>5. Sequencing by Synthesis</strong>:</p><ul><li>The sequencing reaction involves the incorporation of fluorescently labeled nucleotides by the DNA polymerase.</li><li>Each of the four DNA bases (A, T, C, G) is attached to a distinct fluorescent dye. As the polymerase adds a nucleotide to the growing DNA strand, the attached dye briefly fluoresces.</li><li>The order in which these dyes fluoresce, as observed in real-time from the bottom of ZMWs, corresponds to the sequence of the template.</li></ul><p><strong>6. Continuous Long Reads</strong>:</p><ul><li>Due to the circular nature of the SMRTbell templates, the DNA polymerase can continue to sequence in a rolling-circle manner, producing long continuous reads from the same template.</li></ul><p><strong>7. Pulse Detection and Base Calling</strong>:</p><ul><li>The raw output from the sequencing process is a series of fluorescence pulses over time.</li><li>Sophisticated algorithms analyze these pulses to detect and differentiate the fluorescent signals from each other and from the background noise.</li><li>These detected pulses are then converted into a sequence of nucleotide bases, resulting in raw sequence reads.</li></ul><p><strong>8. Circular Consensus Sequencing (CCS)</strong>:</p><ul><li>Since the polymerase can sequence the same SMRTbell template multiple times, it generates several subreads from the same molecule.</li><li>These subreads are aligned and a consensus sequence is called, enhancing the accuracy of the read by averaging out the random errors.</li></ul><h2 id="PacBio-Data-Analysis-Pipeline"><strong>PacBio Data Analysis Pipeline</strong>:</h2><p>From raw data collation on PacBio devices to insightful report generation, the pipeline comprises:</p><hr><p><strong>PacBio Data Analysis Pipeline: A Detailed Overview</strong></p><ol><li><p><strong>Raw Data Collection</strong>:</p><ul><li><em>Process</em>: The sequencing run on a PacBio machine produces raw data files.</li><li><em>Output</em>: Files in formats like <code>.h5</code> or <code>.bam</code> which encapsulate raw sequence reads, quality scores, and other metadata.</li></ul></li><li><p><strong>Read Filtering and Quality Control</strong>:</p><ul><li><em>Process</em>: Before analysis, raw reads undergo filtering to remove unwanted sequences.</li><li><em>Tools</em>: <code>pbccs</code> (Circular Consensus Sequencing) refines raw subreads to generate high-quality consensus sequences.</li><li><em>Output</em>: Filtered and high-quality sequence reads ready for further analysis.</li></ul></li><li><p><strong>Genome Assembly (if de novo sequencing)</strong>:</p><ul><li><em>Process</em>: Assembling the filtered reads into contiguous sequences or “contigs”.</li><li><em>Tools</em>:<ul><li><code>Canu</code>: Corrects, trims, and assembles in one go.</li><li><code>Flye</code>: Known for speed and scalability.</li><li><code>HGAP</code>: PacBio’s native assembler, optimized for their data.</li></ul></li><li><em>Output</em>: Genome assembly in the form of contigs or scaffolds.</li></ul></li><li><p><strong>Mapping (if resequencing)</strong>:</p><ul><li><em>Process</em>: Aligning or “mapping” the reads to a reference genome.</li><li><em>Tools</em>:<ul><li><code>pbmm2</code>: Tailored for PacBio data.</li><li><code>minimap2</code>: Versatile and can align both PacBio and Oxford Nanopore data.</li></ul></li><li><em>Output</em>: Alignment file, typically in BAM or SAM format.</li></ul></li><li><p><strong>Variant Calling</strong>:</p><ul><li><em>Process</em>: Post alignment, identify differences or “variants” between the sequenced data and the reference genome.</li><li><em>Tools</em>:<ul><li><code>DeepVariant</code>: Uses deep learning for interpretation.</li><li><code>PBSV</code>: PacBio’s variant caller, adept at detecting larger structural variants.</li></ul></li><li><em>Output</em>: List of variants, typically in VCF format.</li></ul></li><li><p><strong>Annotation and Analysis</strong>:</p><ul><li><em>Process</em>: Predicting genes, proteins, and other genomic elements in the assembled genome or called variants.</li><li><em>Tools</em>:<ul><li><code>Prokka</code> (for prokaryotes)</li><li><code>AUGUSTUS</code> (for eukaryotes)</li></ul></li><li><em>Output</em>: Annotated genome with predicted genes, regulatory elements, and other features.</li></ul></li><li><p><strong>Visualization</strong>:</p><ul><li><em>Process</em>: Visual representation of the data for easier interpretation.</li><li><em>Tools</em>:<ul><li><code>IGV</code> (Integrative Genomics Viewer)</li><li><code>GenomeBrowse</code></li><li><code>Circos</code></li></ul></li><li><em>Output</em>: Graphical representation of the data, such as genome maps, variant plots, etc.</li></ul></li><li><p><strong>Downstream Analysis</strong>:</p><ul><li><em>Process</em>: Additional analyses based on the research question.<ul><li>Comparative genomics: Comparing with other genomes.</li><li>Transcriptomics: Gene expression analysis.</li><li>Metagenomics: Analyzing community composition in mixed samples.</li></ul></li><li><em>Output</em>: Specific insights or findings related to the research question.</li></ul></li><li><p><strong>Report Generation</strong>:</p><ul><li><em>Process</em>: Compiling all findings, methodologies, and conclusions into a comprehensive report.</li><li><em>Output</em>: Detailed report ready for review, publication, or sharing with stakeholders.</li></ul></li></ol><hr><p>This detailed pipeline provides a roadmap for PacBio data analysis, guiding researchers through each stage and ensuring that they obtain meaningful and actionable insights from their data.</p><h2 id="The-different-output-formats">The different output formats</h2><table><thead><tr><th><strong>Dimension</strong></th><th><strong>.h5 Format</strong></th><th><strong>.bam Format</strong></th></tr></thead><tbody><tr><td><strong>Definition</strong></td><td>A hierarchical data format designed to store and organize large amounts of data.</td><td>The binary version of a Sequence Alignment/Map (SAM) format, used to store aligned sequence data.</td></tr><tr><td><strong>Usage in PacBio</strong></td><td>Earlier PacBio sequencing runs produced <code>.h5</code> files as raw output.</td><td>Used as a standard format for storing aligned PacBio reads.</td></tr><tr><td><strong>File Size</strong></td><td>Generally larger due to the comprehensive information it contains about the sequencing run, including raw pulse and signal data.</td><td>Compressed and therefore more compact than its SAM counterpart. Size depends on the depth of sequencing.</td></tr><tr><td><strong>Content</strong></td><td>Contains raw sequence data, quality metrics, and other metadata about the sequencing run.</td><td>Contains aligned sequence reads, quality scores, and alignment information against a reference genome.</td></tr><tr><td><strong>Advantages</strong></td><td>Comprehensive: Contains raw data and additional metadata which can be useful for in-depth analysis.</td><td>Standardized: Widely accepted in bioinformatics pipelines and tools. Efficient storage with indexed access to alignments.</td></tr><tr><td><strong>Disadvantages</strong></td><td>File size can be substantial. Requires specific tools to extract relevant data.</td><td>Does not contain the raw signal or pulse data, only the resultant sequence and its alignment.</td></tr><tr><td><strong>Associated Tools</strong></td><td>PacBio’s SMRT Analysis software can work with <code>.h5</code> files.</td><td>Numerous tools available, e.g., <code>SAMtools</code>, <code>Picard</code>, and many bioinformatics pipelines accept <code>.bam</code> files.</td></tr><tr><td><strong>Interoperability</strong></td><td>More specific to PacBio’s technology and less commonly used in generic bioinformatics pipelines.</td><td>Highly interoperable and recognized as a standard format in genomics.</td></tr></tbody></table><p>Both <code>.h5</code> and <code>.bam</code> formats have their specific utilities in the realm of PacBio sequencing. While <code>.h5</code> offers a deeper dive into the raw data and sequencing intricacies, <code>.bam</code> provides a streamlined, standardized format for aligned sequence data, making it more amenable to various bioinformatics analyses.</p><h2 id="Spotlight-on-Tools-A-Comparative-Table"><strong>Spotlight on Tools: A Comparative Table</strong></h2><table><thead><tr><th><strong>Tool</strong></th><th><strong>Type</strong></th><th><strong>Advantages</strong></th><th><strong>Disadvantages</strong></th></tr></thead><tbody><tr><td><strong>Canu</strong></td><td>Genome Assembler</td><td>Tailored for high-noise single-molecule sequencing. All-in-one: corrects, trims, and assembles.</td><td>Resource-intensive; demands hefty computational power.</td></tr><tr><td><strong>Flye</strong></td><td>Genome Assembler</td><td>Efficient for PacBio &amp; Oxford Nanopore. Speedy and scalable.</td><td>Might struggle with highly repetitive genomes.</td></tr><tr><td><strong>HGAP</strong></td><td>Genome Assembler</td><td>PacBio’s native. Stellar for microbial genomes.</td><td>Challenges with mammoth genomes. Demands high coverage.</td></tr><tr><td><strong>pbmm2</strong></td><td>Mapping Tool</td><td>Custom-made for PacBio data. Handles long-read errors well.</td><td>PacBio-specific; lacks versatility.</td></tr><tr><td><strong>minimap2</strong></td><td>Mapping Tool</td><td>Swift and versatile. Aligns both PacBio and Oxford Nanopore data.</td><td>Optimal results might need parameter fine-tuning.</td></tr><tr><td><strong>DeepVariant</strong></td><td>Variant Caller</td><td>Harnesses deep learning for high accuracy. Adapted for long-reads.</td><td>Computationally taxing. Might be overwhelming for ML novices.</td></tr><tr><td><strong>PBSV</strong></td><td>Variant Caller</td><td>Fine-tuned for PacBio. Excels in detecting large structural variants.</td><td>Exclusively for PacBio data.</td></tr></tbody></table><hr><h2 id="Conclusion"><strong>Conclusion</strong>:</h2><p>While RNA-Seq has its allure, navigating the PacBio seas can offer refreshing insights. With its long-read capabilities, PacBio emerges as a formidable contender in the sequencing arena. As with every tech marvel, it presents both opportunities and challenges. Yet, armed with the right tools and insights, one can sail smoothly through the PacBio waters, discovering genomic treasures along the way.</p><p>To sequencing and beyond!</p><h2 id="More-to-know">More to know</h2><h3 id="What-is-flank-sequence">What is flank sequence</h3><p>In the context of PacBio sequencing, “flanking sequences” or “flanks” often refer to the sequences on <mark>either side of a particular region of interest within the DNA</mark>. These regions can be particularly important in various analyses such as structural variation detection, insertions, deletions, or when identifying the context of a specific mutation or sequence feature.</p><p>However, when referring to “flank sequences” in relation to PacBio’s SMRTbell library preparation, it has a more specific meaning. For PacBio SMRT sequencing, the DNA of interest is ligated to hairpin adapters at both ends, creating a SMRTbell template. These hairpin adapters allow the DNA polymerase to read the same molecule multiple times, moving in a circular fashion. <mark>The sequences directly adjacent to these adapters on the SMRTbell template are often referred to as the “flanking sequences”.</mark></p><p>These flanking sequences are typically removed during data processing to retain only the sequence of interest. In the context of the raw PacBio reads, you might sometimes see remnants of these adapter sequences or the flanking regions, especially if there was any inefficiency in the adapter trimming process.</p><p>If you’re dealing with PacBio data and want to identify or remove such sequences, tools and workflows provided by PacBio, such as the SMRT Link software suite, can help in the adapter trimming and filtering process.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Deep dive into PacBio sequencing, its comparison with other methods, and an in-depth look into its data analysis pipeline.</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="NGS" scheme="https://karobben.github.io/tags/NGS/"/>
    
    <category term="PacBio" scheme="https://karobben.github.io/tags/PacBio/"/>
    
  </entry>
  
  <entry>
    <title>ATAC-seq: A Powerful Tool for Mapping Gene Regulation</title>
    <link href="https://karobben.github.io/2023/10/20/Bioinfor/ATAC-Seq/"/>
    <id>https://karobben.github.io/2023/10/20/Bioinfor/ATAC-Seq/</id>
    <published>2023-10-20T17:18:48.000Z</published>
    <updated>2023-10-30T21:46:45.529Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction">Introduction:</h2><p>The regulation of gene expression is a complex process that involves the interplay of various factors, including transcription factors, enhancers, promoters, and silencers. Understanding the dynamics of gene regulation is essential for unraveling the mysteries of cellular development, differentiation, and disease progression. To address this challenge, researchers have developed a powerful tool called ATAC-seq, which enables the mapping of gene regulation at an unprecedented scale and resolution. In this blog, we will delve into the world of ATAC-seq and explore its applications, advantages, and limitations.<br>What is ATAC-seq?</p><p>ATAC-seq (Assay for Transposase-Accessible Chromatin sequencing) is a genomic technique that allows researchers to profile the open chromatin regions in a given cell type. Open chromatin regions are those that are accessible to a transposase enzyme, which is used to fragment the chromatin into smaller pieces. The resulting fragments are then sequenced, producing a map of open chromatin regions across the genome.</p><p><img src="https://imgur.com/SL59NJU.png" alt="ATAC-Seq"></p><h3 id="Principle">Principle:</h3><p>The principle behind ATAC-seq is straightforward. The assay involves the following steps:</p><ol><li>Crosslinking: Cells are fixed with formaldehyde to create covalent bonds between proteins and DNA.</li><li>Shearing: Chromatin is sheared into smaller fragments using a transposase enzyme.</li><li>End repair and A-tailing: The 3’ ends of the fragmented DNA are repaired and modified to generate blunt ends.</li><li>Sequencing library preparation: The modified DNA fragments are then prepared for sequencing using standard library preparation protocols.</li><li>Sequencing: The sequencing step generates millions of reads that are then mapped back to the reference genome.</li></ol><h3 id="Advantages">Advantages:</h3><ol><li><strong>High resolution</strong>: ATAC-seq offers high resolution mapping of open chromatin regions, allowing researchers to identify regulatory elements at a genomic scale.</li><li><strong>Sensitivity</strong>: The technique is highly sensitive, capable of detecting rare regulatory elements that would be missed by other methods.</li><li><strong>Cost-effective</strong>: ATAC-seq is relatively cost-effective compared to other techniques such as ChIP-seq, which requires expensive antibodies and specialized equipment.</li><li><strong>Genome-wide analysis</strong>: ATAC-seq allows for genome-wide analysis of open chromatin regions, enabling researchers to identify patterns and trends in gene regulation.</li><li><strong>Identification of novel regulatory elements</strong>: ATAC-seq can identify novel regulatory elements that were previously unknown or unannotated, providing new insights into gene regulation.</li><li><strong>Investigation of gene regulation in specific cell types or tissues</strong>: ATAC-seq can be used to study gene regulation in specific cell types or tissues, providing valuable insights into cellular differentiation and development.</li><li><strong>Identification of disease-associated regulatory elements</strong>: ATAC-seq can be used to identify regulatory elements that are associated with diseases, providing new targets for therapeutic intervention.</li><li><strong>Monitoring of gene regulation changes over time</strong>: ATAC-seq can be used to monitor changes in gene regulation over time, providing insights into how gene regulation dynamics contribute to cellular processes.</li></ol><h3 id="Limitations">Limitations:</h3><ol><li>Limited to accessible chromatin regions: ATAC-seq only maps open chromatin regions that are accessible to the transposase enzyme, which means that closed chromatin regions remain unmapped.</li><li>Biases in sequencing libraries: Sequencing libraries can introduce biases in the form of overrepresented or underrepresented regions, which can impact downstream analyses.</li><li><mark>Interpretation challenges</mark>: Interpreting ATAC-seq data requires advanced computational skills and knowledge of bioinformatics tools and methods.</li><li>Limited spatial resolution: ATAC-seq provides a snapshot of open chromatin regions at a particular time point, but does not provide information on the <mark>spatial organization</mark> of regulatory elements.</li></ol><h3 id="Applications">Applications:</h3><ol><li>Stem cell biology: ATAC-seq has been used to study the gene regulation landscape in stem cells, providing insights into <mark>pluripotency</mark> and <mark>lineage commitment</mark>.</li><li>Cancer research: ATAC-seq has been applied to cancer research, identifying regulatory elements that are associated with tumor progression and metastasis.</li><li><strong>Developmental biology</strong>: ATAC-seq has been used to study the gene regulation landscape in the brain, providing insights into neural development, synaptic plasticity, and neurological disorders.</li><li>Immunology: ATAC-seq has been applied to the study of immune cells, revealing regulatory elements that control immune cell function and differentiation.</li><li>Plant biology: ATAC-seq has been used to study gene regulation in plants, providing insights into plant development, stress response, and photosynthesis.</li><li>Microbiology: ATAC-seq has been used to study gene regulation in microbes, including bacteria and yeast, providing insights into the regulation of virulence factors and drug resistance.</li><li>Drug discovery: ATAC-seq can be used to identify potential drug targets by analyzing the regulatory elements that control gene expression in diseased cells.</li><li>Personalized medicine: ATAC-seq can be used to study gene regulation in individual patients, providing insights into personalized therapies and treatment strategies.</li><li>Synthetic biology: ATAC-seq can be used to design and engineer gene circuits for synthetic biology applications, such as biofuels, drugs, and other valuable compounds.</li></ol><h2 id="Summary">Summary</h2><p>In summary, ATAC-seq is a powerful tool for studying gene regulation and has a wide range of applications in various fields, from basic research to drug discovery and personalized medicine.</p><h2 id="Pipelines-for-ATAC-Seq">Pipelines for ATAC-Seq</h2><ul><li><a href="https://www.encodeproject.org/atac-seq/#overview">Encodeproject: ATAC-seq Data Standards and Processing Pipeline</a></li><li><a href="https://github.com/ENCODE-DCC/atac-seq-pipeline">ENCODE-DCC/atac-seq-pipeline</a></li><li><a href="https://yiweiniu.github.io/blog/2019/03/ATAC-seq-data-analysis-from-FASTQ-to-peaks/">Yiwei niu; 2019: ATAC-seq data analysis: from FASTQ to peaks</a></li><li><a href="https://informatics.fas.harvard.edu/atac-seq-guidelines.html">John M. Gaspar; 2019; ATAC-seq Guidelines</a></li><li><a href="https://training.galaxyproject.org/training-material/topics/epigenetics/tutorials/atac-seq/tutorial.html">Lucille Delisle; 2023; ATAC-Seq data analysis</a></li></ul><h3 id="Data-Analysis-Pipeline">Data Analysis Pipeline</h3><p>According to Fen Yan<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup></p><ul><li><strong>pre-analysis</strong>: quality check and alignment</li><li><strong>core analysis</strong>: peak calling</li><li><strong>advanced analysis</strong>:<ul><li>peak differential analysis and annotation<ul><li>no differential peak analysis tools have been specifically developed</li></ul></li><li>motif enrichment</li><li>footprinting</li><li>nucleosome position analysis</li></ul></li></ul><table><thead><tr><th style="text-align:center"><img src="https://media.springernature.com/full/springer-static/image/art%3A10.1186%2Fs13059-020-1929-3/MediaObjects/13059_2020_1929_Fig4_HTML.png" alt="ATAC-Seq"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-1929-3/figures/4">Fen Yan</a></td></tr></tbody></table><style>pre {  background-color:#38393d;  color: #5fd381;}</style><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>Yan, F., Powell, D.R., Curtis, D.J. et al. From reads to insight: a hitchhiker’s guide to ATAC-seq data analysis. Genome Biol 21, 22 (2020). <a href="https://doi.org/10.1186/s13059-020-1929-3">https://doi.org/10.1186/s13059-020-1929-3</a> <a href="#fnref1" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">ATAC-seq: A powerful tool for studying gene regulation and its applications in various fields, including stem cell biology, cancer research, neurobiology, immunology, plant biology, microbiology, drug discovery, personalized medicine, and synthetic biology.</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="NGS" scheme="https://karobben.github.io/tags/NGS/"/>
    
    <category term="ATAC-Seq" scheme="https://karobben.github.io/tags/ATAC-Seq/"/>
    
  </entry>
  
  <entry>
    <title>Pseudotime Analysis with Monocle: A Beginner&#39;s Guide</title>
    <link href="https://karobben.github.io/2023/10/19/Bioinfor/scMonocle/"/>
    <id>https://karobben.github.io/2023/10/19/Bioinfor/scMonocle/</id>
    <published>2023-10-20T03:11:22.000Z</published>
    <updated>2023-10-22T00:27:31.459Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Psudotime-Analysis">Psudotime Analysis</h2><h3 id="Introduction">Introduction</h3><p>In the complex world of cellular dynamics and differentiation, tracking the progression of individual cells can seem like tracking a grain of sand on a beach. Fortunately, pseudotime analysis using tools like Monocle has made it more accessible. But what is pseudotime? And why should we use Monocle for it? Let’s dive in.</p><h3 id="What-is-Pseudotime">What is Pseudotime?</h3><p>Pseudotime is a computational concept used to order cells based on their progression in a particular process, like differentiation. Rather than relying on actual time (which isn’t available in static single-cell datasets), pseudotime arranges cells in a continuum that reflects their progression state. In simple words, it’s like retracing the journey of a cell from its starting point to its destination, based on markers or genes it expresses.</p><h3 id="Why-Do-We-Use-Pseudotime-Analysis">Why Do We Use Pseudotime Analysis?</h3><p>Mode details in <a href="https://cole-trapnell-lab.github.io/monocle-release/docs/#constructing-single-cell-trajectories">Monocle</a></p><ol><li><p><strong>Choosing Genes for Trajectory</strong>: Monocle selects genes that define cellular progress for its machine learning approach. This feature selection is vital as it impacts the trajectory shape. While some low-expressed genes can be noisy, they might hold essential cellular information. Monocle identifies genes with meaningful variations to structure the data. Users can either let Monocle autonomously choose genes (unsupervised) or input known genes to guide the trajectory (semi-supervised).</p></li><li><p><strong>Dimensionality Reduction</strong>: After gene selection, Monocle reduces the data’s dimensionality using the Reversed Graph Embedding algorithm.</p></li><li><p><strong>Pseudotime Cell Ordering</strong>: Monocle projects expression data into a reduced dimension space to determine the cellular trajectory. It presumes a tree-structured trajectory with a root and leaves. Monocle’s objective is to best fit this tree to the data. Cells begin at the root and move along the trajectory, making decisions at branches until reaching a leaf. A cell’s pseudotime is the distance from its position back to the root.</p></li></ol><h3 id="How-Does-Monocle-Work">How Does Monocle Work?</h3><p>Monocle stands out in the world of pseudotime analysis because of its robustness and flexibility. Here’s a simplified overview of how it functions:</p><ol><li><p><strong>Expression Data Input</strong>: Monocle takes in single-cell RNA-sequencing data. Each cell’s gene expression profile serves as a unique identifier of its state.</p></li><li><p><strong>Dimensionality Reduction</strong>: The vastness of gene expression data is reduced into manageable dimensions using techniques like DDRTree or UMAP.</p></li><li><p><strong>Trajectory Construction</strong>: Using the reduced dimensions, Monocle constructs a trajectory that orders cells based on their progression.</p></li><li><p><strong>Pseudotime Assignment</strong>: Cells are then assigned a pseudotime value based on their position in the trajectory.</p></li></ol><h3 id="What-Makes-Monocle-Special">What Makes Monocle Special?</h3><p>Several tools offer pseudotime analysis, but Monocle has some distinct advantages:</p><ol><li><p><strong>Handling Complex Trajectories</strong>: Monocle can discern branched trajectories, which is crucial when cells can differentiate into multiple types.</p></li><li><p><strong>Flexibility</strong>: It is amenable to various types of analyses beyond just pseudotime, such as differential expression analysis across trajectories.</p></li></ol><h3 id="Comparison-with-Other-Techniques">Comparison with Other Techniques</h3><ul><li><p><strong>Monocle vs. Wanderlust</strong>: While both are used for trajectory analysis, Wanderlust was primarily designed for mass cytometry data. Monocle offers a more generalized approach, suitable for scRNA-seq data.</p></li><li><p><strong>Monocle vs. Slingshot</strong>: Slingshot is another tool for pseudotime analysis of scRNA-seq data. While Slingshot excels in simplicity and user-friendly plotting functions, Monocle’s capability to handle more complex trajectories gives it an edge in certain scenarios.</p></li></ul><h3 id="Pros-and-Cons-of-Using-Monocle">Pros and Cons of Using Monocle</h3><p><strong>Advantages</strong>:</p><ul><li>Robust in handling complex cellular trajectories.</li><li>Suitable for various analyses.</li><li>Well-documented and supported by an active community.</li></ul><p><strong>Disadvantages</strong>:</p><ul><li>Might have a steeper learning curve for beginners.</li><li>Certain computations can be time-intensive.</li></ul><h3 id="Conclusion">Conclusion</h3><p>Pseudotime analysis using Monocle offers a deep dive into cellular dynamics, helping researchers unravel mysteries of cell fate decisions, disease progression, and more. While it’s one of many tools available, its capability to deal with complexity makes it a choice worth considering. Like any tool, its efficacy is determined by the skill and knowledge of the user, so if you’re looking to use Monocle, investing time in understanding its nuances will be immensely rewarding.</p><h2 id="Pepeline-from-Seurat-to-Monocle">Pepeline from Seurat to Monocle</h2><p>First, we need to use the <code>SeuratWrappers</code> library to conver the Seurat object into Monocle manageble data<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r"><span class="hljs-comment"># remotes::install_github(&#x27;cole-trapnell-lab/monocle3&#x27;)</span><br>library(Signac)<br>library(Seurat)<br>library(SeuratWrappers)<br>library(monocle3)<br>library(Matrix)<br>library(ggplot2)<br>library(patchwork)<br><br>erythroid.cds &lt;- as.cell_data_set(seurat_object)<br>erythroid.cds &lt;- cluster_cells(cds = erythroid.cds, reduction_method = <span class="hljs-string">&quot;UMAP&quot;</span>)<br><span class="hljs-comment"># try a subset if R is killed due to lack of RAM </span><br>erythroid.cds &lt;- learn_graph(erythroid.cds, use_partition = <span class="hljs-literal">TRUE</span>)<br><br><span class="hljs-comment"># select the root cell (a list of cell tags)</span><br>hsc &lt;- readLines(<span class="hljs-string">&quot;../vignette_data/hsc_cells.txt&quot;</span>)<br>erythroid.cds &lt;- order_cells(erythroid.cds, reduction_method = <span class="hljs-string">&quot;UMAP&quot;</span>, root_cells = hsc)<br><br><br>plot_cells(<br>  cds = erythroid.cds,<br>  color_cells_by = <span class="hljs-string">&quot;pseudotime&quot;</span>,<br>  show_trajectory_graph = <span class="hljs-literal">TRUE</span><br>)<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://stuartlab.org/signac/articles/monocle_files/figure-html/unnamed-chunk-18-1.png" alt="Psudotime Analysis"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://stuartlab.org/signac/articles/monocle">MonoCle</a></td></tr></tbody></table><style>pre {  background-color:#38393d;  color: #5fd381;}</style><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p><a href="https://stuartlab.org/signac/articles/monocle">2023; <code>Signac</code>; Building trajectories with Monocle 3<br></a> <a href="#fnref1" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">Introductory guide to pseudotime analysis using Monocle. Explore the significance of cellular trajectories in single-cell RNA-sequencing data and compare Monocle&#39;s capabilities with other tools.</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Single Cell" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Single-Cell/"/>
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="RNA-Seq" scheme="https://karobben.github.io/tags/RNA-Seq/"/>
    
    <category term="scRNA-Seq" scheme="https://karobben.github.io/tags/scRNA-Seq/"/>
    
  </entry>
  
  <entry>
    <title>Integrating scRNA-Seq and scATAC-Seq Data: A Primer</title>
    <link href="https://karobben.github.io/2023/10/16/Bioinfor/scATAC/"/>
    <id>https://karobben.github.io/2023/10/16/Bioinfor/scATAC/</id>
    <published>2023-10-16T18:43:24.000Z</published>
    <updated>2023-10-22T00:51:02.511Z</updated>
    
    <content type="html"><![CDATA[<p>Single-cell sequencing technologies have revolutionized our understanding of cellular heterogeneity. Among these technologies, scRNA-Seq and scATAC-Seq stand out for their ability to profile gene expression and chromatin accessibility, respectively. But how can we integrate these two types of data to gain a more comprehensive view of cellular states? Let’s dive in!</p><p>Other tutorial: <a href="https://satijalab.org/seurat/articles/atacseq_integration_vignette">Seurat tutorial</a></p><h2 id="Understanding-the-Data"><strong>Understanding the Data</strong></h2><ul><li><p><strong>scRNA-Seq</strong>: Provides gene expression levels in individual cells. The resulting matrix has genes as rows and cells as columns, with values representing gene expression levels.</p></li><li><p><strong>scATAC-Seq</strong>: Profiles chromatin accessibility at specific genomic regions. The resulting matrix has genomic regions (peaks) as rows and cells as columns, with binary values indicating accessibility.</p></li></ul><h3 id="The-Challenge"><strong>The Challenge</strong></h3><p>At first glance, these matrices seem incompatible. One provides gene-centric information, while the other is focused on genomic regions. So, how can we integrate them?</p><h3 id="From-Peaks-to-Genes"><strong>From Peaks to Genes</strong></h3><p>A common approach is to associate scATAC-Seq peaks with nearby genes. This can transform the scATAC-Seq matrix into a gene-by-cell matrix, similar to scRNA-Seq. Strategies include:</p><ul><li>Assigning each peak to the nearest gene’s transcription start site (TSS).</li><li>Using tools that provide more sophisticated peak-to-gene assignment methods.</li></ul><h2 id="Integration-Using-Latent-Spaces"><strong>Integration Using Latent Spaces</strong></h2><p>Tools like Seurat don’t directly merge the matrices. Instead, they:</p><ol><li>Identify shared “latent spaces” or underlying patterns in the data.</li><li>Find features (genes) that are highly variable in both datasets to serve as “anchors.”</li><li>Use these anchors to align the datasets in a shared latent space.</li></ol><p>Once integrated, joint analyses, such as clustering, can identify cell types present in both datasets.</p><h2 id="Example-Integration-Workflow"><strong>Example Integration Workflow</strong></h2><h3 id="From-Peak-to-Seurat-Object">From Peak to Seurat Object</h3><p>A Seurat Object for ATAC data need more things than RNA matrix.</p><ul><li>Except peak matrix as the <code>ChromatinAssay</code> object,</li><li>we still need to ready the Chromosome annatation file for gene activity estimation.</li><li>We also need the <code>Fragment</code> Object.</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r">library(Signac)<br>library(Seurat)<br><br><span class="hljs-comment"># read the peak counts matrix</span><br>peaks &lt;- readRDS(<span class="hljs-string">&#x27;norm_peak_counts.rds&#x27;</span>)<br><span class="hljs-comment"># convert it as ChromatinAssay object. We can define the type of genome here. But I chooce not.</span><br>chromatinassay &lt;- CreateChromatinAssay(counts = peaks)<span class="hljs-comment">#, genome = &quot;dm6&quot;)</span><br>atac_seurat &lt;- CreateSeuratObject(counts = chromatinassay, assay = <span class="hljs-string">&quot;ATAC&quot;</span>)<br><br><span class="hljs-comment"># read meta infors for the cells if you have</span><br>cell_predictions &lt;- readRDS(<span class="hljs-string">&quot;cell_predictions.rds&quot;</span>)<br>atac_seurat@meta.data &lt;- cbind(atac_seurat@meta.data, cell_info_all)<br><br><span class="hljs-comment"># if you have pre-ran demention redundance data like UMAP</span><br>atac_seurat[[<span class="hljs-string">&quot;UMAP&quot;</span>]] &lt;- CreateDimReducObject(embeddings = as.matrix(cell_info_all[<span class="hljs-built_in">c</span>(<span class="hljs-string">&quot;UMAP_1&quot;</span>, <span class="hljs-string">&quot;UMAP_2&quot;</span>)]), key = <span class="hljs-string">&quot;UMAP_&quot;</span>, assay = DefaultAssay(atac_seurat))<br><br>atac_seurat &lt;- NormalizeData(atac_seurat)<br>atac_seurat &lt;- FindVariableFeatures(atac_seurat)<br><br><span class="hljs-comment"># add Fragments object for gene activity counting</span><br>fragments &lt;- CreateFragmentObject(<span class="hljs-string">&#x27;fragments.tsv.gz&#x27;</span>, cells = colnames(x = atac_seurat), verbose = <span class="hljs-literal">FALSE</span>, tolerance = <span class="hljs-number">0.5</span>)<br>Fragments(atac_seurat) &lt;- fragments<br><br><span class="hljs-comment"># Annotation information</span><br><span class="hljs-comment"># cite: https://github.com/stuart-lab/signac/discussions/1088</span><br>library(AnnotationHub)<br>ah &lt;- AnnotationHub()<br>query(ah, <span class="hljs-string">&quot;EnsDb&quot;</span>)<br>ahDb &lt;- query(ah, pattern = <span class="hljs-built_in">c</span>(<span class="hljs-string">&quot;Drosophila&quot;</span>, <span class="hljs-string">&quot;EnsDb&quot;</span>))<br>flygenome &lt;- ahDb[[<span class="hljs-number">19</span>]]<br>annotations &lt;- GetGRangesFromEnsDb(ensdb = flygenome)<br>seqlevelsStyle(annotations) &lt;- <span class="hljs-string">&#x27;NCBI&#x27;</span><br>Annotation(atac_seurat) &lt;- annotations<br><br><span class="hljs-comment"># save the ATAC Seurat object to avoid the creating again</span><br>saveRDS(atac_seurat, <span class="hljs-string">&#x27;scATAC.rds&#x27;</span>)<br></code></pre></td></tr></table></figure></div><h3 id="Integration">Integration</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R"><span class="hljs-comment"># Normalize and find variable features for both datasets</span><br>atac_seurat &lt;- NormalizeData(atac_seurat)<br>atac_seurat &lt;- FindVariableFeatures(atac_seurat)<br><br>rna_seurat &lt;- NormalizeData(rna_seurat)<br>rna_seurat &lt;- FindVariableFeatures(rna_seurat)<br><br><span class="hljs-comment"># run the lsi demaintion dungration</span><br>pbmc.atac &lt;- RunTFIDF(pbmc.atac)<br>pbmc.atac &lt;- FindTopFeatures(pbmc.atac, min.cutoff = <span class="hljs-string">&quot;q0&quot;</span>)<br>pbmc.atac &lt;- RunSVD(pbmc.atac)<br><br><br><span class="hljs-comment"># estimate the gene activities of the feature genes </span><br>gene.activities &lt;- GeneActivity(pbmc.atac, features = VariableFeatures(pbmc.rna))<br><br>pbmc.atac[[<span class="hljs-string">&quot;ACTIVITY&quot;</span>]] &lt;- CreateAssayObject(counts = gene.activities)<br>DefaultAssay(pbmc.atac) &lt;- <span class="hljs-string">&quot;ACTIVITY&quot;</span><br>pbmc.atac &lt;- NormalizeData(pbmc.atac)<br>pbmc.atac &lt;- ScaleData(pbmc.atac, features = rownames(pbmc.atac))<br></code></pre></td></tr></table></figure></div><h3 id="Anchors-identifycation">Anchors identifycation</h3><p>This step would take lots of time.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r"><span class="hljs-comment"># Identify anchors</span><br>transfer.anchors &lt;- FindTransferAnchors(reference = rna_seurat, query = atac_seurat, features = VariableFeatures(object = rna_seurat),<br>    reference.assay = <span class="hljs-string">&quot;RNA&quot;</span>, query.assay = <span class="hljs-string">&quot;ACTIVITY&quot;</span>, reduction = <span class="hljs-string">&quot;cca&quot;</span>)<br></code></pre></td></tr></table></figure></div><h3 id="Label-transfer">Label transfer</h3><p>After identifying anchors, we can transfer annotations from the scRNA-seq dataset onto the scATAC-seq cells. The annotations are stored in the <code>seurat_annotations</code> field, and are provided as input to the <code>refdata</code> parameter. The output will contain a matrix with predictions and confidence scores for each ATAC-seq cell.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r">celltype.predictions &lt;- TransferData(anchorset = transfer.anchors, refdata = rna_seurat$seurat_annotations,<br>    weight.reduction = atac_seurat[[<span class="hljs-string">&quot;lsi&quot;</span>]], dims = <span class="hljs-number">2</span>:<span class="hljs-number">30</span>)<br><br>atac_seurat &lt;- AddMetaData(atac_seurat, metadata = celltype.predictions)<br><br></code></pre></td></tr></table></figure></div><h3 id="Co-embedding-scRNA-seq-and-scATAC-seq-datasets">Co-embedding scRNA-seq and scATAC-seq datasets</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r"><span class="hljs-comment"># note that we restrict the imputation to variable genes from scRNA-seq, but could impute the</span><br><span class="hljs-comment"># full transcriptome if we wanted to</span><br>genes.use &lt;- VariableFeatures(rna_seurat)<br><br><span class="hljs-comment"># if your rna_seurat is integrated result, I believe you&#x27;ld prefer use `assay = &quot;integrated&quot;`</span><br>refdata &lt;- GetAssayData(rna_seurat, assay = <span class="hljs-string">&quot;RNA&quot;</span>, slot = <span class="hljs-string">&quot;data&quot;</span>)[genes.use, ]<br><br><span class="hljs-comment"># refdata (input) contains a scRNA-seq expression matrix for the scRNA-seq cells.  imputation</span><br><span class="hljs-comment"># (output) will contain an imputed scRNA-seq matrix for each of the ATAC cells</span><br>imputation &lt;- TransferData(anchorset = transfer.anchors, refdata = refdata, weight.reduction = atac_seurat[[<span class="hljs-string">&quot;lsi&quot;</span>]],<br>    dims = <span class="hljs-number">2</span>:<span class="hljs-number">30</span>)<br>atac_seurat[[<span class="hljs-string">&quot;RNA&quot;</span>]] &lt;- imputation<br><br>coembed &lt;- merge(x = rna_seurat, y = atac_seurat)<br><br><span class="hljs-comment"># Finally, we run PCA and UMAP on this combined object, to visualize the co-embedding of both</span><br><span class="hljs-comment"># datasets</span><br>coembed &lt;- ScaleData(coembed, features = genes.use, do.scale = <span class="hljs-literal">FALSE</span>)<br>coembed &lt;- RunPCA(coembed, features = genes.use, verbose = <span class="hljs-literal">FALSE</span>)<br>coembed &lt;- RunUMAP(coembed, dims = <span class="hljs-number">1</span>:<span class="hljs-number">30</span>)<br><br>DimPlot(coembed, group.by = <span class="hljs-built_in">c</span>(<span class="hljs-string">&quot;orig.ident&quot;</span>, <span class="hljs-string">&quot;seurat_annotations&quot;</span>))<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://satijalab.org/seurat/articles/atacseq_integration_vignette_files/figure-html/coembed-1.png" alt="Seruat: ATAC-RNA data integration"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://satijalab.org/seurat/articles/atacseq_integration_vignette">© Seurat</a></td></tr></tbody></table><h3 id="Conclusion"><strong>Conclusion</strong></h3><p>Integrating scRNA-Seq and scATAC-Seq data provides a holistic view of cellular states, combining gene expression and chromatin accessibility information. While the integration process might seem daunting, understanding the underlying principles and using the right tools can make it achievable and insightful.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Guide to integrating scRNA-Seq and scATAC-Seq data: Transforming chromatin accessibility and gene expression datasets for a holistic view of cellular states.</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Single Cell" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Single-Cell/"/>
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="RNA-Seq" scheme="https://karobben.github.io/tags/RNA-Seq/"/>
    
    <category term="scRNA-Seq" scheme="https://karobben.github.io/tags/scRNA-Seq/"/>
    
    <category term="scATAC-Seq" scheme="https://karobben.github.io/tags/scATAC-Seq/"/>
    
  </entry>
  
  <entry>
    <title>Evaluating the quality of classification</title>
    <link href="https://karobben.github.io/2023/10/06/Blog/spacial-disEvl/"/>
    <id>https://karobben.github.io/2023/10/06/Blog/spacial-disEvl/</id>
    <published>2023-10-06T17:40:48.000Z</published>
    <updated>2023-10-16T18:42:14.599Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Situation">Situation</h2><p>I have a large, sparse dataset that I’ve analyzed using a neural network model borrowed from previous research. After classifying the data using this model, I applied dimensionality reduction, resulting in well-defined groups. To assess the quality of this classification, I’m considering evaluating the sparsity of classes in the reduced dimension space. One method I’m contemplating is examining the standard deviation in relation to the mean/median value for each group. Are there other effective methods to evaluate the classification based on the distribution in the reduced space?</p><h2 id="How-to-start">How to start</h2><p>Evaluating the quality of classification, especially in the context of redundancy and sparsity, can be a nuanced task. It sounds like you’re interested in understanding how well-separated or distinct the groups are after applying redundancy techniques on the classification results.</p><p>Here’s a structured approach to evaluate your classification results based on redundancy distribution:</p><ol><li><p><strong>Descriptive Statistics</strong>:</p><ul><li><strong>Mean/Median</strong>: Understand the central tendency of each group.</li><li><strong>Standard Deviation (SD)</strong>: Check the spread or variability within each group. A lower SD indicates that the data points are closer to the mean, suggesting tighter clusters or classes.</li><li><strong>Skewness</strong>: Understand the symmetry of your distribution. Positive skewness indicates a long tail on the right, while negative skewness indicates a long tail on the left.<ul><li><code>skewness(X)</code></li></ul></li></ul></li><li><p><strong>Visualization</strong>:</p><ul><li><strong>Heatmaps</strong>: These can help you visualize the density and sparsity of your classes in the redundancy map.</li><li><strong>Histograms/Box-plots</strong>: To visually inspect the distribution of each group.</li></ul></li><li><p><strong>Quantifying Sparsity</strong>:</p><ul><li><strong>Sparsity Ratio</strong>: It’s the ratio of the number of zero (or near-zero, depending on the threshold you set) elements to the total number of elements. A higher sparsity ratio indicates that the classes are more distinct in the redundancy map.</li><li><strong>Gini Coefficient</strong>: Used in economics to measure inequality, it can also measure the inequality of the distribution of classes in a redundancy map. A Gini coefficient of 0 indicates perfect equality, while a Gini coefficient of 1 indicates maximum inequality.</li></ul></li><li><p><strong>Comparative Metrics</strong>:</p><ul><li><strong>Silhouette Score</strong>: Measures how close each sample in one cluster is to the samples in the neighboring clusters. Values range from -1 to 1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters.</li><li><strong>Davies-Bouldin Index</strong>: The lower the value, the better the clustering result. It evaluates intra-cluster similarity and inter-cluster differences.</li></ul></li><li><p><strong>Stability Analysis</strong>:</p><ul><li>If possible, perform the same classification and redundancy process on different subsets of your data. If the results are consistent across different subsets, it adds to the validity of your analysis.</li></ul></li><li><p><strong>Ground Truth Comparison</strong>:</p><ul><li>If there’s a “ground truth” or some external benchmark dataset that you can compare with, it can provide a clear evaluation of how well your classification aligns with known standards.</li></ul></li><li><p><strong>Entropy</strong>:</p><ul><li>For each group or cluster, you can compute its entropy to gauge the randomness or unpredictability of its classification assignments. Lower entropy indicates that a cluster is predominantly made up of one class, whereas higher entropy indicates a mix of classes.</li></ul></li></ol><p>Lastly, remember that no single metric can fully capture the quality and nuances of your classification, especially in the context of redundancy and sparsity. Use a combination of metrics and visualizations to get a comprehensive view of the quality and then base your conclusions on the collective evidence.</p><p>Consider also cross-referencing your results with domain experts or literature in the field to ensure that your evaluations and conclusions align with the underlying phenomena you’re studying.</p><h2 id="Skewness">Skewness</h2><h3 id="run-PCA">run PCA</h3><p>We use the <code>wine</code> data as the example data. The classes information is in <code>wine.class</code></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r"><span class="hljs-comment">## install ggbioplot</span><br><span class="hljs-comment">## remotes::install_github(&quot;vqv/ggbiplot&quot;)</span><br><span class="hljs-comment">## install.packages(&#x27;plyr&#x27;)</span><br>library(plyr)<br>library(ggbiplot)<br>library(ggplot2)<br>data(wine)<br>wine.pca &lt;- prcomp(wine, scale. = <span class="hljs-literal">TRUE</span>)<br><span class="hljs-comment">## bioplot</span><br>ggbiplot(wine.pca, obs.scale = <span class="hljs-number">1</span>, var.scale = <span class="hljs-number">1</span>,<br>         groups = wine.class, ellipse = <span class="hljs-literal">TRUE</span>, circle = <span class="hljs-literal">TRUE</span>) +<br>  scale_color_discrete(name = <span class="hljs-string">&#x27;&#x27;</span>) +<br>  theme_light()+ theme(axis.title = element_text(size=<span class="hljs-number">10</span>))<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://s1.ax1x.com/2020/06/20/NlbAKJ.png" alt="PCA results"></th></tr></thead><tbody></tbody></table><h3 id="Check-the-Skewness">Check the Skewness</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r">library(e1071) <span class="hljs-comment"># for function skewness</span><br><br>score &lt;- wine.pca<br>wine_types &lt;- unique(wine.class)<br><br>skew_TB &lt;- data.frame()<br><span class="hljs-keyword">for</span>(type <span class="hljs-keyword">in</span> wine_types)&#123;<br>  subset_scores &lt;- scores[wine.class == type, ]<br>  <br>  skewness_PC1 &lt;- skewness(subset_scores[, <span class="hljs-number">1</span>])<br>  skewness_PC2 &lt;- skewness(subset_scores[, <span class="hljs-number">2</span>])<br>  <br>  skew_TB &lt;- rbind(skew_TB, data.frame(sk1 = skewness_PC1, sk2 = skewness_PC2, Type = type))<br>&#125;<br><br><span class="hljs-comment"># visualization</span><br><br>ggplot(skew_TB, aes(sk1, sk2, color = Type)) + geom_point() + <br>  theme_bw() + coord_polar(theta = <span class="hljs-string">&#x27;x&#x27;</span>)<br><br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://z1.ax1x.com/2023/10/07/pPjV71s.png" alt="Skewness of the PCA results"></th></tr></thead><tbody><tr><td style="text-align:center">By polarizing the x-axis, the points closer to the center exhibit reduced skewness in both PC components, resulting in decreased sparsity.</td></tr></tbody></table><h2 id="Sparsity-Ratio-and-Gini-Coefficient">Sparsity Ratio and Gini Coefficient</h2><ul><li><p><strong>Sparsity Ratio</strong>: To compute the sparsity ratio for the PCA scores, you’d typically set a threshold (e.g., a value close to 0) below which a score is considered as ‘sparse’ or ‘zero’. The sparsity ratio is then calculated as the number of scores below this threshold divided by the total number of scores.</p></li><li><p><strong>Gini Coefficient</strong>: This measures inequality among values. For the PCA scores, a Gini Coefficient close to 1 indicates high inequality (i.e., few scores dominate), whereas a value close to 0 indicates more equality among scores.</p></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r"><span class="hljs-comment"># following the code above</span><br><br>compute_sparsity_ratio &lt;- <span class="hljs-keyword">function</span>(data, threshold = <span class="hljs-number">0.1</span>)&#123;<br>  <span class="hljs-built_in">return</span>(<span class="hljs-built_in">sum</span>(<span class="hljs-built_in">abs</span>(data) &lt; threshold) / <span class="hljs-built_in">length</span>(data))<br>&#125;<br><br>SG_TB = data.frame()<br><br><span class="hljs-keyword">for</span>(type <span class="hljs-keyword">in</span> wine_types)&#123;<br>  subset_scores_PC1 &lt;- scores[wine.class == type, <span class="hljs-number">1</span>]<br>  subset_scores_PC2 &lt;- scores[wine.class == type, <span class="hljs-number">2</span>]<br>  <br>  <span class="hljs-comment"># Sparsity ratio for PC1 and PC2</span><br>  sparsity_PC1 &lt;- compute_sparsity_ratio(subset_scores_PC1)<br>  sparsity_PC2 &lt;- compute_sparsity_ratio(subset_scores_PC2)<br>  <br>  <span class="hljs-comment"># Gini coefficient for PC1 and PC2</span><br>  gini_PC1 &lt;- ineq::Gini(subset_scores_PC1)<br>  gini_PC2 &lt;- ineq::Gini(subset_scores_PC2)<br><br>  SG_TB &lt;- rbind(SG_TB, data.frame(Type = type, <br>                                   index1 = <span class="hljs-built_in">c</span>(sparsity_PC1, gini_PC1),<br>                                   index2 = <span class="hljs-built_in">c</span>(sparsity_PC2, gini_PC2),<br>                                   index = <span class="hljs-built_in">c</span>(<span class="hljs-string">&#x27;Sparsity&#x27;</span>, <span class="hljs-string">&quot;gigi&quot;</span>)))<br>&#125;<br></code></pre></td></tr></table></figure></div><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Evaluating the quality of classification</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Statistic" scheme="https://karobben.github.io/categories/Notes/Statistic/"/>
    
    <category term="Data Scientists" scheme="https://karobben.github.io/categories/Notes/Statistic/Data-Scientists/"/>
    
    
    <category term="Data" scheme="https://karobben.github.io/tags/Data/"/>
    
    <category term="Machine Learning. Data Preprocessing" scheme="https://karobben.github.io/tags/Machine-Learning-Data-Preprocessing/"/>
    
  </entry>
  
  <entry>
    <title>scRNA-Seq: makers explore</title>
    <link href="https://karobben.github.io/2023/10/04/Bioinfor/scRNA-marker/"/>
    <id>https://karobben.github.io/2023/10/04/Bioinfor/scRNA-marker/</id>
    <published>2023-10-04T18:16:57.000Z</published>
    <updated>2023-10-20T17:25:10.204Z</updated>
    
    <content type="html"><![CDATA[<p>Seurat is a popular R package for single-cell RNA sequencing (scRNA-seq) data analysis. If you’ve already processed your data and assigned cell identities (classes), then finding differentially expressed genes (DEGs) between two different classes is a common next step.</p><p>Here’s a brief step-by-step guide on how to identify DEGs between two cell types or classes using Seurat:</p><ol><li><p><strong>Setup</strong>:<br>First, make sure you have the Seurat library loaded.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">library(Seurat)<br></code></pre></td></tr></table></figure></div></li><li><p><strong>Differential Expression</strong>:<br>Use the <code>FindMarkers</code> function in Seurat to identify DEGs. You can specify the two groups you are interested in by setting the <code>ident.1</code> and <code>ident.2</code> parameters.</p><p>For example, if you have two classes named “ClassA” and “ClassB”, you can identify DEGs between these two classes as follows:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">de_genes &lt;- FindMarkers(object = your_seurat_object, <br>             ident.1 = <span class="hljs-string">&quot;ClassA&quot;</span>, <br>             ident.2 = <span class="hljs-string">&quot;ClassB&quot;</span>, <br>             min.pct = <span class="hljs-number">0.25</span>,<br>             logfc.threshold = <span class="hljs-number">0.25</span>,<br>             group.by = <span class="hljs-string">&quot;Final_id&quot;</span>)<br></code></pre></td></tr></table></figure></div><pre> |++++++++++++++++++++++++++++++++++++++++++++++++++| 100% elapsed=29s  </pre><ul><li><code>your_seurat_object</code> is your Seurat object.</li><li><code>min.pct</code> is the minimum percentage of cells where the gene must be detected in either of the two groups.</li><li><code>logfc.threshold</code> is the minimum log-fold change threshold.</li><li><code>group.by</code> is the colname from <code>metadata</code></li></ul></li><li><p><strong>Inspect Results</strong>:<br>The resulting <code>de_genes</code> data frame will contain differentially expressed genes between “ClassA” and “ClassB”. It will include columns for the average expression in each class, the percentage of cells expressing the gene in each class, the log fold-change, and the adjusted p-value (among other metrics).</p></li><li><p><strong>Filter Based on Significance</strong>:<br>You might want to filter out genes based on a significance threshold, for instance, an adjusted p-value less than 0.05:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">significant_genes &lt;- de_genes[de_genes$p_val_adj &lt; <span class="hljs-number">0.05</span>, ]<br></code></pre></td></tr></table></figure></div></li><li><p><strong>Visualize</strong>:<br>You can also visualize the expression of significant genes across different classes using feature plots or violin plots in Seurat.</p></li></ol><p>Remember, the parameters like <code>min.pct</code>, <code>logfc.threshold</code>, and the p-value cutoff should be chosen based on your specific dataset and research questions. Adjust them as necessary to balance sensitivity and specificity.</p><h2 id="Violin-Plot">Violin Plot</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r">VlnPlot(OL3, <br>  idents =  <span class="hljs-built_in">c</span>(<span class="hljs-string">&quot;GMC1&quot;</span>, <span class="hljs-string">&quot;GMC2&quot;</span>, <span class="hljs-string">&quot;GMC3*&quot;</span>), <br>  features = <span class="hljs-string">&quot;N&quot;</span>, <br>  group.by = <span class="hljs-string">&quot;Pred_cl&quot;</span>)<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://z1.ax1x.com/2023/10/05/pPOzURU.png" alt="Show apart of Cells"></th></tr></thead><tbody></tbody></table><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r">VlnPlot(OL3, <br>  idents =  <span class="hljs-built_in">c</span>(<span class="hljs-string">&quot;GMC1&quot;</span>, <span class="hljs-string">&quot;GMC2&quot;</span>, <span class="hljs-string">&quot;GMC3*&quot;</span>), <br>  features = row.names(de_genes), <br>  group.by = <span class="hljs-string">&quot;Pred_cl&quot;</span>)<br></code></pre></td></tr></table></figure></div><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">scRNA-Seq: makers explore</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Single Cell" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Single-Cell/"/>
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="RNA-Seq" scheme="https://karobben.github.io/tags/RNA-Seq/"/>
    
    <category term="NGS" scheme="https://karobben.github.io/tags/NGS/"/>
    
    <category term="scRNA-Seq" scheme="https://karobben.github.io/tags/scRNA-Seq/"/>
    
  </entry>
  
  <entry>
    <title>Understanding the geom_point Function in ggplot2</title>
    <link href="https://karobben.github.io/2023/10/04/R/geom-point/"/>
    <id>https://karobben.github.io/2023/10/04/R/geom-point/</id>
    <published>2023-10-04T15:54:55.000Z</published>
    <updated>2023-10-04T16:54:32.099Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><strong>Introduction</strong></h2><p>Data visualization is an essential aspect of data analysis, allowing us to understand patterns, trends, and relationships in our data. In R, one of the most popular packages for data visualization is <code>ggplot2</code>. Among its many functions, <code>geom_point</code> stands out as a fundamental tool for creating scatter plots. In this blog post, we’ll delve deep into the <code>geom_point</code> function, exploring its basic grammar and how to customize the appearance of points in your plots.</p><h2 id="Basic-Grammar-and-Code-Example"><strong>Basic Grammar and Code Example</strong></h2><p>The basic grammar of <code>geom_point</code> is straightforward. At its core, you need a dataset and aesthetic mappings. The x and y aesthetics are the most common mappings used with <code>geom_point</code>.</p><p>Here’s a simple example:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">library(ggplot2)<br><br><span class="hljs-comment"># Sample data</span><br>data &lt;- data.frame(<br>  x = rnorm(<span class="hljs-number">100</span>),<br>  y = rnorm(<span class="hljs-number">100</span>)<br>)<br><br><span class="hljs-comment"># Basic scatter plot</span><br>ggplot(data, aes(x=x, y=y)) + <br>  geom_point()<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://z1.ax1x.com/2023/10/04/pPOvQfS.png" alt="geom_point"></th></tr></thead><tbody></tbody></table><p>This code will produce a scatter plot with the x and y values from our sample data.</p><h2 id="Customizing-Point-Appearance"><strong>Customizing Point Appearance</strong></h2><ol><li><strong>Changing Point Color</strong></li></ol><p>You can change the color of the points using the <code>color</code> argument inside the <code>aes()</code> function:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">ggplot(data, aes(x=x, y=y, color=<span class="hljs-string">&quot;white&quot;</span>)) + <br>  geom_point()<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://z1.ax1x.com/2023/10/05/pPOv1Sg.png" alt="geom_point assign a group by color"></th></tr></thead><tbody></tbody></table><p>If you want to color points based on a variable, you can do so by mapping that variable to the <code>color</code> aesthetic:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">data$group &lt;- sample(<span class="hljs-built_in">c</span>(<span class="hljs-string">&quot;A&quot;</span>, <span class="hljs-string">&quot;B&quot;</span>), <span class="hljs-number">100</span>, replace = <span class="hljs-literal">TRUE</span>)<br><br>ggplot(data, aes(x=x, y=y, color=group)) + <br>  geom_point() + theme_bw()<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://z1.ax1x.com/2023/10/05/pPOv3lQ.png" alt="geom_point color by group"></th></tr></thead><tbody></tbody></table><h2 id="Show-the-name-of-group-on-the-center-of-scatter-points">Show the name of group on the center of scatter points</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r">data_group &lt;- aggregate(cbind(x, y) ~ group, data=data, FUN=median)<br>ggplot(data, aes(x=x, y=y, color=group)) + <br>  geom_point() + theme_bw() + geom_label(data = data_group, aes( label = group))<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://z1.ax1x.com/2023/10/05/pPOvYmn.png" alt="geom_point label"></th></tr></thead><tbody></tbody></table><h2 id="Changing-Point-Size"><strong>Changing Point Size</strong></h2><p>To change the size of the points, use the <code>size</code> argument:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">ggplot(data, aes(x=x, y=y)) + <br>  geom_point(size=<span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://z1.ax1x.com/2023/10/05/pPOvtwq.png" alt="geom_point point size"></th></tr></thead><tbody></tbody></table><h2 id="Changing-Point-Shape"><strong>Changing Point Shape</strong></h2><p><code>ggplot2</code> provides various shapes for points. You can change the shape using the <code>shape</code> argument:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">ggplot(data, aes(x=x, y=y)) + <br>  geom_point(shape=<span class="hljs-number">17</span>)<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://z1.ax1x.com/2023/10/05/pPOvNT0.png" alt="geom_point point shapes"></th></tr></thead><tbody></tbody></table><p>Shapes are represented by numbers. For example, 16 is a solid circle, 17 is a triangle, and so on. You can explore the <code>?points</code> documentation in R to see a list of available shapes.</p><h2 id="Conclusion"><strong>Conclusion</strong></h2><p>The <code>geom_point</code> function in <code>ggplot2</code> offers a flexible and powerful way to create scatter plots in R. With just a few lines of code, you can produce a basic plot, and with a few more tweaks, you can customize it to your liking. As you continue your data visualization journey, remember that the key is not just to make plots look good, but to make them convey the right information effectively.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">geom_point Function in ggplot2 for scatter plot</summary>
    
    
    
    <category term="R" scheme="https://karobben.github.io/categories/R/"/>
    
    <category term="Plot" scheme="https://karobben.github.io/categories/R/Plot/"/>
    
    <category term="GGPLOT" scheme="https://karobben.github.io/categories/R/Plot/GGPLOT/"/>
    
    
    <category term="Plot" scheme="https://karobben.github.io/tags/Plot/"/>
    
    <category term="R" scheme="https://karobben.github.io/tags/R/"/>
    
    <category term="ggplot" scheme="https://karobben.github.io/tags/ggplot/"/>
    
  </entry>
  
  <entry>
    <title>A Beginner&#39;s Guide to scRNA-Seq Data Integration</title>
    <link href="https://karobben.github.io/2023/10/03/Bioinfor/scRNA-integration/"/>
    <id>https://karobben.github.io/2023/10/03/Bioinfor/scRNA-integration/</id>
    <published>2023-10-03T18:12:39.000Z</published>
    <updated>2023-10-04T21:47:19.941Z</updated>
    
    <content type="html"><![CDATA[<p>Single-cell RNA sequencing (scRNA-seq) has revolutionized our understanding of cellular heterogeneity and function. However, integrating datasets, especially from different labs or experiments, can be challenging. In this guide, we’ll walk through the process of integrating scRNA-seq datasets using Seurat and provide tips for newcomers to the field.</p><h2 id="Why-Integrate-scRNA-Seq-Data"><strong>Why Integrate scRNA-Seq Data?</strong></h2><p>Integrating multiple scRNA-seq datasets allows researchers to compare or combine data from different experiments, conditions, or labs. This is crucial when aiming to:</p><ul><li>Combine datasets to increase sample size.</li><li>Compare conditions across different experiments.</li><li>Mitigate batch effects arising from different experimental conditions.</li></ul><h2 id="The-Seurat-Integration-Workflow"><strong>The Seurat Integration Workflow</strong></h2><p>Seurat, a popular R package for scRNA-seq data analysis, provides a robust framework for data integration. Here’s a step-by-step guide:</p><h3 id="Preprocessing"><strong>Preprocessing</strong></h3><p>Before integration, preprocess each dataset separately. This includes:</p><ul><li>Filtering cells.</li><li>Normalizing data.</li><li>Identifying variable features.</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">library(Seurat)<br><span class="hljs-comment">#DefaultAssay(seurat_obj1) &lt;- &quot;RNA&quot;</span><br><span class="hljs-comment">#DefaultAssay(seurat_obj2) &lt;- &quot;RNA&quot;</span><br>seurat_obj1 &lt;- NormalizeData(seurat_obj1)<br>seurat_obj2 &lt;- NormalizeData(seurat_obj2)<br>seurat_obj1 &lt;- FindVariableFeatures(seurat_obj1, selection.method = <span class="hljs-string">&quot;vst&quot;</span>, nfeatures = <span class="hljs-number">2000</span>)<br>seurat_obj2 &lt;- FindVariableFeatures(seurat_obj2, selection.method = <span class="hljs-string">&quot;vst&quot;</span>, nfeatures = <span class="hljs-number">2000</span>)<br></code></pre></td></tr></table></figure></div><pre>Performing log-normalization0%   10   20   30   40   50   60   70   80   90   100%[----|----|----|----|----|----|----|----|----|----|**************************************************|Calculating gene variances0%   10   20   30   40   50   60   70   80   90   100%[----|----|----|----|----|----|----|----|----|----|**************************************************|Calculating feature variances of standardized and clipped values0%   10   20   30   40   50   60   70   80   90   100%[----|----|----|----|----|----|----|----|----|----|**************************************************|</pre><h4 id="Why-nfeatures-2000">Why nfeatures = 2000</h4><p>The <code>nfeatures</code> parameter, when set to <code>2000</code> in the context of Seurat functions like <code>FindVariableFeatures</code>, specifies that the function should identify the top 2,000 most variable genes in the dataset. These variable genes are often used in downstream analyses, such as PCA, because they capture significant biological and technical variability that can help differentiate cell populations.</p><p>The choice of <code>2000</code> as the number of variable features is somewhat arbitrary but has become a common default in many scRNA-seq workflows. Here’s why:</p><ol><li><p><strong>Historical Precedence</strong>: Early scRNA-seq datasets were smaller, and selecting the top 2,000 variable genes was found to be a good balance between computational efficiency and capturing meaningful biological variability.</p></li><li><p><strong>Computational Efficiency</strong>: Using a subset of genes (like the top 2,000 variable genes) instead of the entire transcriptome makes downstream computations (like PCA, clustering, and UMAP/t-SNE embedding) faster and more memory-efficient.</p></li><li><p><strong>Biological Relevance</strong>: Genes that are variably expressed across cells often represent key markers that can differentiate cell types or states. By focusing on these genes, one can often capture the major axes of variation in the data.</p></li></ol><p>However, it’s essential to understand that <code>2000</code> is not a magic number, and depending on the specific dataset and research question, a different number might be more appropriate. Here are some considerations:</p><ul><li><p><strong>Dataset Size</strong>: For larger datasets with more cells, you might benefit from selecting more than 2,000 variable genes. Conversely, for smaller datasets, a smaller number might suffice.</p></li><li><p><strong>Biological Question</strong>: If you’re interested in subtle subpopulations or rare cell types, you might need to consider more genes to capture this granularity.</p></li><li><p><strong>Exploration</strong>: It’s often beneficial to experiment with different numbers of variable features to see how it impacts downstream analyses. For instance, you can try 1,000, 2,000, 3,000, etc., and observe how it affects clustering or the resolution of cell populations in UMAP/t-SNE plots.</p></li></ul><p>In summary, while <code>nfeatures = 2000</code> is a commonly used default, it’s crucial to understand its implications and adjust it as needed based on the specifics of your dataset and research goals.</p><p>The method <code>'vst'</code> refers to “Variance Stabilizing Transformation.” In the context of Seurat and scRNA-seq data analysis, the VST method is used to identify highly variable genes across single cells.</p><p>Here’s a brief overview of the VST method:</p><h4 id="Variance-Stabilizing-Transformation-VST"><strong>Variance Stabilizing Transformation (VST)</strong>:</h4><ol><li><p><strong>Purpose</strong>: The main goal of VST is to stabilize the variance across the mean of the data. In the context of gene expression data, this means making the variance of gene expression values more consistent across different expression levels.</p></li><li><p><strong>Why It’s Important</strong>: In raw count data, the variance often increases with the mean. This means that highly expressed genes naturally have higher variability just due to the nature of the data. VST aims to correct for this, allowing for the identification of genes that are genuinely variable across cells, not just because of their expression level.</p></li><li><p><strong>How It Works</strong>: Without diving too deep into the math, VST uses a transformation that makes the variance of the data approximately constant across different mean values. This transformation is data-driven and is estimated from the data itself.</p></li><li><p><strong>Application in Seurat</strong>: In Seurat’s <code>FindVariableFeatures</code> function, when the method is set to <code>'vst'</code>, the function will use the VST approach to identify genes that are highly variable after accounting for the relationship between variance and mean expression.</p></li><li><p><strong>Comparison to Other Methods</strong>: Another common method used in Seurat for identifying variable genes is <code>'mean.var.plot'</code>, which fits a loess curve to the relationship between variance and mean expression. The VST method is often more robust, especially for larger datasets, but it’s always a good idea to understand and consider the implications of the method you’re using.</p></li></ol><p>In summary, the VST method in Seurat is a way to identify highly variable genes in a manner that accounts for and corrects the relationship between variance and mean expression. This helps in pinpointing genes that are genuinely variable across cells, which can be crucial for downstream analyses like clustering and dimensionality reduction.</p><h3 id="Identify-Anchors">Identify Anchors</h3><p>Seurat uses the concept of “anchors” to identify correspondences between cells in different datasets. These anchors are then used for data integration.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r"><span class="hljs-comment"># FindIntegrationAnchors is really time consuming. Active per</span><br><br>anchor.features &lt;- SelectIntegrationFeatures(object.list = <span class="hljs-built_in">list</span>(seurat_obj1, seurat_obj2), nfeatures = <span class="hljs-number">2000</span>)<br>anchor.set &lt;- FindIntegrationAnchors(object.list = <span class="hljs-built_in">list</span>(seurat_obj1, seurat_obj2), anchor.features = anchor.features)<br></code></pre></td></tr></table></figure></div><pre>Scaling features for provided objects  |++++++++++++++++++++++++++++++++++++++++++++++++++| 100% elapsed=11s  Finding all pairwise anchors  |                                                  | 0 % ~calculating  Running CCAMerging objectsFinding neighborhoodsFinding anchorsFound 55971 anchorsFiltering anchorsRetained 18262 anchors|++++++++++++++++++++++++++++++++++++++++++++++++++| 100% elapsed=04h 16m 22s</pre><h3 id="Integration"><strong>Integration</strong></h3><p>Seurat uses “anchors” to identify correspondences between cells in different datasets. These anchors are then used for data integration.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">integrated.data &lt;- IntegrateData(anchorset = anchor.set)<br>saveRDS(integrated.data, <span class="hljs-string">&quot;integrated.rds&quot;</span>)<br></code></pre></td></tr></table></figure></div><pre>Merging dataset 2 into 1Extracting anchors for merged samplesFinding integration vectorsFinding integration vector weights0%   10   20   30   40   50   60   70   80   90   100%[----|----|----|----|----|----|----|----|----|----|**************************************************|Integrating data</pre><p>Here, the integration steps are done. The following steps is for checking the integration quality and results.</p><h3 id="Downstream-Analysis"><strong>Downstream Analysis</strong></h3><p>After integration, you can proceed with:</p><ul><li>Scaling the data.</li><li>Running PCA.</li><li>Clustering cells.</li><li>Visualizing data using UMAP or t-SNE.</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">integrated.data &lt;- ScaleData(integrated.data, verbose = <span class="hljs-literal">FALSE</span>)<br>integrated.data &lt;- RunPCA(integrated.data, npcs = <span class="hljs-number">30</span>, verbose = <span class="hljs-literal">FALSE</span>)<br>integrated.data &lt;- FindNeighbors(integrated.data, dims = <span class="hljs-number">1</span>:<span class="hljs-number">30</span>)<br>integrated.data &lt;- FindClusters(integrated.data, resolution = <span class="hljs-number">0.5</span>)<br>integrated.data &lt;- RunUMAP(integrated.data, dims = <span class="hljs-number">1</span>:<span class="hljs-number">30</span>)<br>DimPlot(integrated.data, group.by = <span class="hljs-string">&quot;orig.ident&quot;</span>)<br></code></pre></td></tr></table></figure></div><h2 id="3-Tips-for-Newbies-in-scRNA-Seq-Integration"><strong>3. Tips for Newbies in scRNA-Seq Integration</strong></h2><p>For those new to scRNA-seq integration, here are some essential tips:</p><ul><li><strong>Quality Control</strong>: Ensure thorough QC on each dataset before and after integration.</li><li><strong>Visual Inspection</strong>: Use UMAP/t-SNE plots and heatmaps to visually inspect your data.</li><li><strong>Parameter Tuning</strong>: Adjust parameters based on your specific datasets.</li><li><strong>Biological Validation</strong>: Validate your findings with external data or experimental validation.</li><li><strong>Computational Considerations</strong>: Ensure you have enough memory and computational resources.</li><li><strong>Documentation</strong>: Keep detailed notes and consider using tools like R Markdown.</li><li><strong>Stay Updated</strong>: The field of scRNA-seq is rapidly evolving. Stay updated with the latest methods and best practices.</li><li><strong>Seek Feedback</strong>: Discuss your results with colleagues or experts in the field.</li></ul><h2 id="4-Conclusion"><strong>4. Conclusion</strong></h2><p>Integrating scRNA-seq datasets can be challenging, especially for newcomers. However, with the right tools, a systematic approach, and a focus on the underlying biology, it’s possible to derive meaningful insights from integrated datasets. As with all bioinformatics tasks, continuous learning and practice are key to mastering scRNA-seq data integration.</p><h2 id="Errors">Errors</h2><h3 id="Error-when-running-normalization">Error when running normalization:</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r">NormalizeData(seurat_obj1)                                             <br></code></pre></td></tr></table></figure></div><pre>Performing log-normalization0%   10   20   30   40   50   60   70   80   90   100%[----|----|----|----|----|----|----|----|----|----|**************************************************|Error: Cannot add a different number of cells than already present</pre><p>Solution:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r">seurat_obj1[[<span class="hljs-string">&quot;RNA&quot;</span>]] &lt;- NormalizeData(seurat_obj1[[<span class="hljs-string">&quot;RNA&quot;</span>]])<br></code></pre></td></tr></table></figure></div><h3 id="duplicated-cell-name">duplicated cell-name</h3><pre>In CheckDuplicateCellNames(object.list = object.list) :  Some cell names are duplicated across objects provided. Renaming to enforce unique cell names.</pre><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r">new.names1 &lt;- paste0(colnames(seurat_obj1), <span class="hljs-string">&quot;_P40&quot;</span>)<br>seurat_obj1 &lt;- RenameCells(object = seurat_obj1, new.names = new.names1)<br><br><span class="hljs-comment"># For seurat_obj2, add &quot;_batch2&quot; as a suffix</span><br>new.names2 &lt;- paste0(colnames(seurat_obj2), <span class="hljs-string">&quot;_P50&quot;</span>)<br>seurat_obj2 &lt;- RenameCells(object = seurat_obj2, new.names = new.names2)<br></code></pre></td></tr></table></figure></div><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">A Beginner&#39;s Guide to scRNA-Seq Data Integration</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Single Cell" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Single-Cell/"/>
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="RNA-Seq" scheme="https://karobben.github.io/tags/RNA-Seq/"/>
    
    <category term="scRNA-Seq" scheme="https://karobben.github.io/tags/scRNA-Seq/"/>
    
  </entry>
  
  <entry>
    <title>Understanding and Tackling Batch Effects in Single-Cell RNA-Seq Analysis</title>
    <link href="https://karobben.github.io/2023/10/03/Bioinfor/scRNA-batch/"/>
    <id>https://karobben.github.io/2023/10/03/Bioinfor/scRNA-batch/</id>
    <published>2023-10-03T16:39:22.000Z</published>
    <updated>2023-10-03T18:13:34.068Z</updated>
    
    <content type="html"><![CDATA[<h2 id="The-Challenge-of-Batch-Effects">The Challenge of Batch Effects</h2><p>In the world of single-cell RNA sequencing (scRNA-seq), one of the most prevailing challenges is the presence of batch effects. These are technical non-biological variations that arise when samples are processed in separate runs or under slightly different conditions. If not accounted for, batch effects can overshadow true biological differences, leading to misinterpretations.</p><h2 id="Why-Remove-Batch-Effects">Why Remove Batch Effects?</h2><p>Imagine studying the effects of a drug on cell populations, with samples processed both before and after treatment. If the ‘before’ samples were processed in one batch and the ‘after’ samples in another, any difference you observe might be due to this batch variation rather than the drug effect.</p><p>Removing batch effects ensures that:</p><ul><li>Biological variations are distinguishable from technical variations.</li><li>Combined data from multiple batches can be analyzed together without biases.</li><li>Results are consistent, reproducible, and truly reflective of biological phenomena.</li></ul><h2 id="Approaches-to-Counter-Batch-Effects">Approaches to Counter Batch Effects</h2><p>Several methods have been developed to correct for batch effects. Here, we’ll delve into three popular methods used within the Seurat package: <strong>Harmony</strong>, <strong>fastMNN</strong>, and <strong>SCTransform</strong>.</p><h2 id="A-Comparative-Glimpse">A Comparative Glimpse:</h2><table><thead><tr><th>Feature</th><th><strong>Harmony</strong></th><th><strong>fastMNN (batchelor)</strong></th><th><strong>SCTransform</strong></th></tr></thead><tbody><tr><td>Method</td><td>Operates in PCA space to adjust principal components.</td><td>Uses Mutual Nearest Neighbors to align cells.</td><td>Regresses out unwanted variation and stabilizes variance.</td></tr><tr><td>Use Cases</td><td>Integrating datasets from different conditions, protocols, or platforms.</td><td>Integrating datasets with batch effects. Faster than original MNN.</td><td>Alternative to traditional normalization in Seurat. Prepares data for analysis.</td></tr><tr><td>Advantages</td><td>Preserves biological structures well; robust to complex batch effects.</td><td>Designed for scRNA-seq batch correction; faster than original MNN; corrects severe batch effects.</td><td>Stabilizes variance; can handle large datasets efficiently.</td></tr><tr><td>Disadvantages</td><td>Can be computationally intensive with large datasets.</td><td>Requires a good selection of mutual nearest neighbors.</td><td>Not specifically a batch correction method; often combined with other methods.</td></tr></tbody></table><h2 id="Deep-Dive-into-the-Methods">Deep Dive into the Methods:</h2><ol><li><p><strong>Harmony:</strong> Ideal for integrating multiple scRNA-seq datasets. Harmony adjusts the principal components of the data such that inter-batch differences are minimized while retaining biological variation.</p></li><li><p><strong>fastMNN (from the batchelor package):</strong> This method identifies mutual nearest neighbors between batches, assuming that these pairs of cells represent the same cell type across batches. It’s an optimized and faster variant of the original MNN algorithm.</p></li><li><p><strong>SCTransform:</strong> More than a batch correction technique, SCTransform is a robust normalization method. It prepares the data for downstream analysis, including batch correction, by regressing out unwanted sources of variation.</p></li></ol><h2 id="Final-Thoughts">Final Thoughts:</h2><p>Batch effect correction is a crucial step in scRNA-seq data processing. By choosing the right method tailored to your dataset’s needs, you can unveil genuine biological insights without being misdirected by technical noises. Always visualize and interpret results at each step, ensuring that biological variation remains the highlight of your study.</p><h2 id="In-Action">In Action</h2><p>Seurat offers several methods to correct for batch effects, ensuring that variations across batches don’t obscure the biological signals you’re interested in. Here’s a step-by-step guide to remove batch effects using Seurat:</p><ol><li><p><strong>Install and Load Seurat:</strong></p><p>First, ensure you’ve installed and loaded the Seurat package.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">install.packages(<span class="hljs-string">&#x27;Seurat&#x27;</span>)<br>library(Seurat)<br></code></pre></td></tr></table></figure></div></li><li><p><strong>Data Integration (Using Harmony, SCTransform, and others):</strong></p><p>Seurat offers various integration methods like Harmony, fastMNN, and SCTransform. Here, I’ll showcase using <code>SCTransform</code> followed by <code>RunPCA</code> and <code>Harmony</code>:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R"><span class="hljs-comment"># List of Seurat Objects from different batches</span><br>seurat_list &lt;- <span class="hljs-built_in">list</span>(batch1_seurat, batch2_seurat, ...)<br><br><span class="hljs-comment"># SCTransform normalization</span><br>seurat_list &lt;- lapply(seurat_list, <span class="hljs-keyword">function</span>(x) &#123;<br>  x &lt;- SCTransform(x, verbose = <span class="hljs-literal">FALSE</span>)<br>&#125;)<br><br><span class="hljs-comment"># Identify anchors for integration</span><br>anchors &lt;- FindIntegrationAnchors(object.list = seurat_list, normalization.method = <span class="hljs-string">&quot;SCT&quot;</span>, <br>                                  anchor.features = <span class="hljs-number">2000</span>, verbose = <span class="hljs-literal">FALSE</span>)<br><br><span class="hljs-comment"># Integrate data</span><br>integrated_data &lt;- IntegrateData(anchorset = anchors, normalization.method = <span class="hljs-string">&quot;SCT&quot;</span>, verbose = <span class="hljs-literal">FALSE</span>)<br></code></pre></td></tr></table></figure></div><p>If you prefer using <code>Harmony</code> specifically:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">library(harmony)<br>integrated_data &lt;- RunPCA(integrated_data, features = VariableFeatures(object = integrated_data))<br>integrated_data &lt;- RunHarmony(integrated_data, group.by.vars = <span class="hljs-string">&quot;batch&quot;</span>)<br></code></pre></td></tr></table></figure></div></li><li><p><strong>Scale and Run Linear Dimensional Reduction:</strong></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">integrated_data &lt;- ScaleData(integrated_data, verbose = <span class="hljs-literal">FALSE</span>)<br>integrated_data &lt;- RunPCA(integrated_data, verbose = <span class="hljs-literal">FALSE</span>)<br></code></pre></td></tr></table></figure></div></li><li><p><strong>Cluster and Visualize Integrated Data:</strong></p><p>Using UMAP or t-SNE to visualize the integrated data is a great way to confirm if the batch effects have been mitigated.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">integrated_data &lt;- RunUMAP(integrated_data, reduction = <span class="hljs-string">&quot;harmony&quot;</span>, dims = <span class="hljs-number">1</span>:<span class="hljs-number">30</span>)<br>DimPlot(integrated_data, group.by = <span class="hljs-string">&quot;batch&quot;</span>)<br></code></pre></td></tr></table></figure></div></li><li><p><strong>Optional - Regression of unwanted sources of variation:</strong></p><p>If you are aware of specific unwanted sources of variation, you can regress them out using the <code>vars.to.regress</code> parameter in the <code>ScaleData</code> function.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">seurat_object &lt;- ScaleData(seurat_object, vars.to.regress = <span class="hljs-string">&quot;batch&quot;</span>)<br></code></pre></td></tr></table></figure></div></li></ol><p>Remember, the removal of batch effects should be done carefully. Overcorrection might lead to loss of genuine biological variation. It’s always a good practice to visualize and interpret the results at each step, ensuring the intended correction.</p><p>Lastly, Seurat’s integration methods and their parameters might evolve with time, so always consult the latest Seurat documentation or vignettes to ensure you’re using the most effective and up-to-date approaches.</p><p>Harmony, fastMNN, and SCTransform are all methods to handle batch effects and data normalization in single-cell RNA-seq data, but they operate based on different principles and have distinct purposes.</p><p><strong>In summary:</strong></p><ul><li><strong>Harmony</strong> and <strong>fastMNN</strong> are batch-correction methods that work to align datasets from different batches or conditions.</li><li><strong>SCTransform</strong> is a normalization method that prepares the data for further analysis, including batch correction.</li></ul><p>When dealing with batch effects, researchers often first normalize the data using <strong>SCTransform</strong> and then apply batch correction methods like <strong>Harmony</strong> or <strong>fastMNN</strong> to the transformed data. This two-step approach ensures that the data is both normalized and free of batch effects, making downstream analyses like clustering and differential expression more reliable.</p><p>Other tutorial:</p><ul><li><a href="https://www.10xgenomics.com/resources/analysis-guides/introduction-batch-effect-correction">2023; X10 Genomics: Batch Effect Correction</a></li><li><a href="https://satijalab.org/seurat/articles/integration_introduction.html">2023; Seurat: Introduction to scRNA-seq integration<br></a></li></ul><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Remove Batch Effects in Single-Cell RNA-Seq</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Single Cell" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Single-Cell/"/>
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="RNA-Seq" scheme="https://karobben.github.io/tags/RNA-Seq/"/>
    
    <category term="scRNA-Seq" scheme="https://karobben.github.io/tags/scRNA-Seq/"/>
    
  </entry>
  
  <entry>
    <title>Diving Into Single-Cell RNA-Seq Analysis: A Beginner’s Guide</title>
    <link href="https://karobben.github.io/2023/09/28/Bioinfor/scRNA-start/"/>
    <id>https://karobben.github.io/2023/09/28/Bioinfor/scRNA-start/</id>
    <published>2023-09-28T18:03:14.000Z</published>
    <updated>2023-10-20T17:24:15.004Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to the fascinating world of single-cell RNA-Seq analysis! If you’re a budding scientist, curious learner, or someone looking to understand the intricacies of cellular biology, you’re in for a treat. This guide is tailored for newbies and aims to make the complex world of single-cell RNA-Seq analysis approachable and intriguing.</p><h2 id="What-is-Single-Cell-RNA-Seq-Analysis">What is Single-Cell RNA-Seq Analysis?</h2><table><thead><tr><th style="text-align:center"><img src="https://www.rebuildingakidney.org/assets/img/news/little-tsne.png" alt="Example of scRNA-Seq"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.rebuildingakidney.org/2019/03/12/sc-visualizations/">© rebuildingakidney.org</a></td></tr></tbody></table><p>RNA-Seq stands for RNA sequencing, a revolutionary technique that helps scientists understand the expression of genes within a cell. In traditional RNA-Seq, we study the averaged gene expression of thousands of cells, but this approach has its limitations. It’s like trying to understand the flavor profile of a smoothie by tasting it – you know the overall taste, but you can’t pinpoint the individual fruits that contribute to it.</p><p>This is where Single-Cell RNA-Seq (scRNA-Seq) analysis steps in! It allows scientists to examine the gene expression at the individual cell level, unraveling the unique role and state of each cell, akin to tasting each fruit separately!</p><h2 id="Why-Should-You-Learn-It">Why Should You Learn It?</h2><p><strong>1. Unveiling Cellular Diversity:</strong><br>scRNA-Seq analysis reveals the immense diversity and specialization of cells in an organism, helping us understand how different cells contribute to the function and development of tissues and organs.</p><p><strong>2. Disease Understanding &amp; Treatment:</strong><br>It plays a crucial role in understanding various diseases at the cellular level, thereby aiding in the development of targeted treatments and personalized medicine.</p><p><strong>3. Cutting-Edge Research:</strong><br>By learning scRNA-Seq analysis, you’re diving into a field at the forefront of biological and medical research, opening doors to various career and research opportunities.</p><h2 id="How-to-Learn-Single-Cell-RNA-Seq-Analysis">How to Learn Single-Cell RNA-Seq Analysis</h2><p><strong>1. Online Courses &amp; Tutorials:</strong><br>Many platforms offer specialized courses in scRNA-Seq analysis. Websites like Coursera, edX, and LinkedIn Learning host beginner-friendly courses to help you understand the basics and get hands-on experience.</p><p><strong>2. Workshops &amp; Seminars:</strong><br>Keep an eye out for workshops, webinars, and seminars conducted by universities, research institutions, and organizations. These events often provide insights into the latest developments and practical applications of scRNA-Seq analysis.</p><p><strong>3. Research Papers &amp; Journals:</strong><br>Scientific journals and publications are treasure troves of information. Websites like PubMed and Google Scholar can be your go-to resources for the latest research papers on scRNA-Seq analysis.</p><p><strong>4. Join Online Communities:</strong><br>Platforms like Reddit, Stack Overflow, and Biostars have dedicated forums for scRNA-Seq where you can ask questions, share knowledge, and connect with other learners and experts.</p><p><strong>5. Practical Experience:</strong><br>Nothing beats hands-on experience! Use publicly available datasets to practice and apply what you’ve learned. Websites like NCBI’s GEO or EMBL-EBI’s ArrayExpress are great places to find datasets.</p><p><strong>6. Coding Skills:</strong><br>Familiarity with programming languages like R and Python can be extremely beneficial. If you’re new to coding, consider taking introductory courses available on Codecademy, Kaggle, or DataCamp.</p><h2 id="Integration-Analysis">Integration Analysis</h2><p>The <code>FindTransferAnchors()</code> and <code>TransferData()</code> functions were introduced in Seurat v3. Seurat v3 was a significant release that incorporated many new methods, especially for the integration and alignment of multiple datasets. Before Seurat v3, data integration and label transfer were more cumbersome and less streamlined.</p><p>If you’re using an older version of Seurat and want to leverage these functions, you should consider upgrading to at least Seurat v3 or the latest available version. Always refer to the official Seurat documentation and changelogs for detailed information about function availability and updates across different versions.</p><p>Integrating <mark>scRNA-Seq and scATAC-Seq</mark> data is one of the powerful applications of <code>FindTransferAnchors()</code> and <code>TransferData()</code> in Seurat v3 and later. Despite being two distinct types of sequencing data – one capturing gene expression (scRNA-Seq) and the other capturing chromatin accessibility (scATAC-Seq) – the underlying assumption is that similar cell types/states in both datasets should have correlated patterns in gene expression and chromatin accessibility.</p><p>Here’s how it generally works:</p><ol><li><p><strong>Representation in a Shared Space</strong>: Before finding anchors, both scRNA-Seq and scATAC-Seq data are transformed into a lower-dimensional space (like PCA space). For scRNA-Seq, this is straightforward. For scATAC-Seq, peak (or gene activity) scores can be used, which summarize the chromatin accessibility signals into a gene-centric score.</p></li><li><p><strong>Finding Anchors</strong>: <code>FindTransferAnchors()</code> is then used to find anchors between the datasets. Despite the data’s different origins, the method identifies mutual nearest neighbors in the shared reduced-dimensional space.</p></li><li><p><strong>Data Transfer</strong>: Once anchors are identified, <code>TransferData()</code> can be used to transfer labels (like cell type annotations) from scRNA-Seq data to scATAC-Seq data or vice versa. This transfer can also be used to infer gene activity scores in scATAC-Seq data based on scRNA-Seq data.</p></li><li><p><strong>Integrative Analysis</strong>: After the data transfer, one can perform joint analyses on the two datasets, leveraging the strengths of both data types. For instance, a certain cell type identified in scRNA-Seq data can be examined in scATAC-Seq data to understand the regulatory elements (enhancers, promoters) that might be driving its gene expression patterns.</p></li></ol><p>A few things to note:</p><ul><li>The integration doesn’t mean that the two datasets are forced to look identical. Instead, the goal is to identify and leverage the shared structure between them.</li><li>Appropriate preprocessing is crucial. For scATAC-Seq, one typically uses a “gene activity matrix”, which provides an estimation of gene activity based on nearby chromatin accessibility.</li><li>This integration can be powerful, but like all methods, it requires careful interpretation and validation.</li></ul><p>The Seurat team has provided vignettes and tutorials on this topic, demonstrating how to integrate scRNA-Seq and scATAC-Seq data using their toolkit. If you’re planning to apply this to your data, it’s a good idea to refer to their official resources for step-by-step guidance.</p><h2 id="Final-Thoughts">Final Thoughts</h2><p>Diving into single-cell RNA-Seq analysis can seem daunting initially, but remember, every expert was once a beginner. Be patient, stay curious, and don’t hesitate to ask questions. The journey might be challenging, but the rewards, insights, and knowledge you’ll gain along the way are incredibly fulfilling.</p><p>Happy learning!</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Diving Into Single-Cell RNA-Seq Analysis: A Beginner’s Guide</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Single Cell" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Single-Cell/"/>
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="RNA-Seq" scheme="https://karobben.github.io/tags/RNA-Seq/"/>
    
    <category term="NGS" scheme="https://karobben.github.io/tags/NGS/"/>
    
    <category term="scRNA-Seq" scheme="https://karobben.github.io/tags/scRNA-Seq/"/>
    
  </entry>
  
  <entry>
    <title>Navigating the Challenges of Sparse Datasets in Machine Learning</title>
    <link href="https://karobben.github.io/2023/09/27/Python/sparse-datasets/"/>
    <id>https://karobben.github.io/2023/09/27/Python/sparse-datasets/</id>
    <published>2023-09-27T18:26:37.000Z</published>
    <updated>2023-10-07T19:41:32.849Z</updated>
    
    <content type="html"><![CDATA[<p>Sparse datasets are ubiquitous in the machine learning landscape, and navigating the challenges they present is crucial for developing robust and efficient models. In this blog post, we’ll delve into why sparse datasets can cause poor performance in some machine learning algorithms, explore solutions to overcome these challenges, and provide code snippets for a hands-on understanding.</p><h2 id="Understanding-Sparse-Datasets">Understanding Sparse Datasets</h2><p>Sparse datasets are characterized by having a large proportion of missing or zero values. This sparsity can result from various scenarios, such as user-item interactions in recommendation systems or word occurrences in text data. While handling sparse data can be intricate, understanding its challenges is the first step towards crafting efficient solutions.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-comment"># Example of a sparse matrix</span><br>num_rows = <span class="hljs-number">100</span><br>num_cols = <span class="hljs-number">100</span><br><br><span class="hljs-comment"># Define the density of the sparse matrix</span><br><span class="hljs-comment"># Density is the proportion of non-zero elements in the matrix</span><br>density = <span class="hljs-number">0.05</span><br><br><span class="hljs-comment"># Generate a random sparse matrix</span><br>sparse_matrix = np.random.choice([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], size=(num_rows, num_cols), p=[<span class="hljs-number">1</span>-density, density])<br><br><span class="hljs-comment"># Visualizing the sparse matrix</span><br>plt.spy(sparse_matrix, marker=<span class="hljs-string">&#x27;.&#x27;</span>, color=<span class="hljs-string">&#x27;salmon&#x27;</span>)<br>plt.title(<span class="hljs-string">&#x27;Visualization of a Sparse Matrix&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://z1.ax1x.com/2023/09/28/pPblU8H.png" alt="a sparse dataset"></th></tr></thead><tbody></tbody></table><h2 id="Challenges-Posed-by-Sparse-Datasets">Challenges Posed by Sparse Datasets</h2><ol><li><p><strong>Insufficient Information</strong>: Learning meaningful patterns becomes difficult due to the scarcity of non-zero values.</p></li><li><p><strong>High Dimensionality</strong>: The curse of dimensionality can affect distance-based algorithms by distorting the meaningfulness of distances between data points.</p></li><li><p><strong>Overfitting</strong>: The model might capture noise as patterns, resulting in poor generalization to unseen data.</p></li><li><p><strong>Computational Inefficiency</strong>: Some algorithms struggle with processing high-dimensional sparse data efficiently.</p></li><li><p><strong>Imbalance</strong>: Sparse datasets might introduce class imbalance, leading to biased models.</p></li><li><p><strong>Feature Importance</strong>: Determining which features are informative is challenging in sparse scenarios.</p></li><li><p><strong>Distance Measures</strong>: For algorithms that rely on distance measures, such as k-nearest neighbors (KNN) or support vector machines (SVM), sparse datasets can distort distances between data points, making it difficult to find similarities and differences.</p></li></ol><h2 id="Strategies-to-Overcome-the-Challenges">Strategies to Overcome the Challenges</h2><h3 id="Dimensionality-Reduction">Dimensionality Reduction</h3><p>PCA (Principal Component Analysis) can help in reducing the feature space while retaining the most important information.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.decomposition <span class="hljs-keyword">import</span> PCA<br><br><span class="hljs-comment"># Initializing PCA and fitting on the sparse data</span><br>pca = PCA(n_components=<span class="hljs-number">2</span>)<br>reduced_data = pca.fit_transform(sparse_matrix)<br><br><span class="hljs-comment"># Visualizing the reduced data</span><br>plt.scatter(reduced_data[:, <span class="hljs-number">0</span>], reduced_data[:, <span class="hljs-number">1</span>], marker=<span class="hljs-string">&#x27;o&#x27;</span>, color=<span class="hljs-string">&#x27;b&#x27;</span>)<br>plt.title(<span class="hljs-string">&#x27;Visualization of Reduced Data&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure></div><h3 id="Imputation">Imputation</h3><p>Filling missing values based on certain strategies, such as mean imputation, can mitigate the impact of sparsity.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.impute <span class="hljs-keyword">import</span> SimpleImputer<br><br><span class="hljs-comment"># Initializing the imputer and performing imputation</span><br>imputer = SimpleImputer(strategy=<span class="hljs-string">&#x27;mean&#x27;</span>)<br>imputed_data = imputer.fit_transform(sparse_matrix)<br></code></pre></td></tr></table></figure></div><h3 id="Feature-Selection">Feature Selection</h3><p>Retaining only the most informative features can lead to improved model robustness.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> SelectKBest, chi2<br><br><span class="hljs-comment"># Define target_variable for the sake of example</span><br><span class="hljs-comment"># It could be any array of labels corresponding to each data point (row) in your sparse_matrix</span><br><span class="hljs-comment"># For instance, it can be created as follows (assuming a classification task with two classes, 0 and 1):</span><br><br>target_variable = np.random.choice([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], size=(num_rows,), p=[<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>])<br><br><span class="hljs-comment"># Initializing feature selection method and selecting the best features</span><br>selector = SelectKBest(chi2, k=<span class="hljs-number">2</span>)<br>selected_data = selector.fit_transform(sparse_matrix, target_variable)<br></code></pre></td></tr></table></figure></div><p>The <code>target_variable</code> is the dependent variable we are trying to predict in a supervised learning task. In the context of the code snippet, it should be the label or the output corresponding to each data point (row) in your <code>sparse_matrix</code>.</p><p>In this example, <code>target_variable</code> is generated randomly, assuming a binary classification task. In a real-world scenario, <code>target_variable</code> would contain the actual labels of your data points. For each row in your <code>sparse_matrix</code>, there should be a corresponding label in <code>target_variable</code>.</p><h3 id="Regularization">Regularization</h3><p>L1 and L2 regularization can prevent overfitting by penalizing large coefficients.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> Lasso<br><br><span class="hljs-comment"># Initializing Lasso with L1 regularization</span><br>lasso_model = Lasso(alpha=<span class="hljs-number">0.1</span>)<br>lasso_model.fit(features, target_variable)<br></code></pre></td></tr></table></figure></div><h3 id="Ensemble-Methods">Ensemble Methods</h3><p>Random Forests, an ensemble method, can aid in improving generalization and managing overfitting.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier<br><br><span class="hljs-comment"># Initializing and training a RandomForest Classifier</span><br>rf_model = RandomForestClassifier(n_estimators=<span class="hljs-number">100</span>, random_state=<span class="hljs-number">42</span>)<br>rf_model.fit(features, target_variable)<br></code></pre></td></tr></table></figure></div><h2 id="Conclusion">Conclusion</h2><p>While sparse datasets pose several challenges in machine learning, ranging from high dimensionality to overfitting, a variety of strategies and techniques exist to navigate these issues. By adopting appropriate methods such as dimensionality reduction, imputation, and regularization, we can harness the potential of sparse data and build effective and robust machine learning models.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Explore strategies to navigate sparse datasets in machine learning with practical Python code examples and solutions.</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Statistic" scheme="https://karobben.github.io/categories/Notes/Statistic/"/>
    
    <category term="Data Scientists" scheme="https://karobben.github.io/categories/Notes/Statistic/Data-Scientists/"/>
    
    
    <category term="Data" scheme="https://karobben.github.io/tags/Data/"/>
    
    <category term="Machine Learning. Data Preprocessing" scheme="https://karobben.github.io/tags/Machine-Learning-Data-Preprocessing/"/>
    
  </entry>
  
  <entry>
    <title>Molecule and Cellular Biology 6</title>
    <link href="https://karobben.github.io/2023/09/07/LearnNotes/UIUC-AdMC-6/"/>
    <id>https://karobben.github.io/2023/09/07/LearnNotes/UIUC-AdMC-6/</id>
    <published>2023-09-07T13:09:04.000Z</published>
    <updated>2023-09-10T03:47:42.535Z</updated>
    
    <content type="html"><![CDATA[<div class="admonition info"><p class="admonition-title">Points for the lecture:</p><ul><li>λ life cycle is regulated through molecular events</li><li>Events are ‘tuned’ for propagation of the phage</li><li>Competition between factors dictates activity state</li></ul></div><h2 id="λ-Phage">λ Phage</h2><h3 id="How-λ-Gets-In">How λ Gets In</h3><ul><li><p><strong>Components and Structure</strong></p><ul><li><strong>Genome:</strong> 48,502 bp of double-stranded DNA (dsDNA).</li><li><strong>Chromosome in the capsid:</strong><ul><li><strong>Structure:</strong> Linear dsDNA.</li><li><strong>Special Feature:</strong> 12 nt single-stranded DNA (ssDNA) cohesive termini.</li></ul></li><li><strong>Capsid:</strong><ul><li><strong>Head:</strong> Comprises products of B, C, Nu3, D, and E genes.</li><li><strong>Tail:</strong> Formed by products of J and H genes.</li></ul></li></ul></li><li><p><strong>Infection Process</strong></p><ol><li><strong>Attachment:</strong> The phage attaches to the host cell’s maltose receptor, a product of the E. coli lamB gene.</li><li><strong>Injection:</strong> Injects its linear dsDNA chromosome into the host cell.</li><li><strong>Circularization:</strong></li></ol><ul><li><strong>Mechanism:</strong> Annealing occurs between complementary 3’ overhanging cos sites.</li><li><strong>Outcome:</strong> Linear dsDNA transforms into a circular form, facilitating the integration into the host’s genome.</li></ul></li><li><p><strong>Notes</strong></p><ul><li>The cohesive termini and the specific structure of the capsid play crucial roles in the bacteriophage’s ability to infect and integrate into the host genome.</li><li>Understanding the precise infection mechanism can offer insights into bacterial immunity and potential applications in bacterial genetics research.</li></ul></li></ul><h3 id="Life-Choice-Depends-on-Genetic-Switch">Life Choice Depends on Genetic Switch</h3><h4 id="1-Lytic-Mode">1. Lytic Mode</h4><ul><li><strong>Initial Phase:</strong><ul><li><strong>DNA Entry:</strong> Phage DNA enters the host cell.</li><li><strong>Transcription:</strong> Host RNA polymerase transcribes phage DNA.</li><li><strong>Translation:</strong> Phage mRNAs are translated to produce phage proteins.</li></ul></li><li><strong>Replication Phase:</strong><ul><li><strong>DNA Replication:</strong> Phage DNA replicates.</li><li><strong>Assembly:</strong> New phages are assembled from DNA and protein components.</li></ul></li><li><strong>Final Phase:</strong><ul><li><strong>Lysis:</strong> The host cell undergoes lysis, releasing progeny phages.</li><li><strong>Result:</strong> The host cell is killed.</li></ul></li></ul><h4 id="2-Lysogenic-Mode">2. Lysogenic Mode</h4><ul><li><strong>Initial Phase:</strong><ul><li><strong>DNA Entry:</strong> Phage DNA enters the cell.</li><li><strong>Early Gene Expression:</strong> Early genes are transcribed and translated.</li></ul></li><li><strong>Repressor Role:</strong><ul><li><strong>λ Repressor (CI) Appearance:</strong> A 27-kD phage protein appears.</li><li><strong>Binding:</strong> CI binds to two phage operator regions.</li><li><strong>Effect:</strong> It shuts down transcription of all phage genes except for cI (gene coding for λ repressor).</li></ul></li><li><strong>Integration Phase:</strong><ul><li><strong>Integration:</strong> Phage DNA integrates into the host genome.</li><li><strong>Lysogen Formation:</strong> The host with integrated phage DNA is termed a lysogen.</li><li><strong>Prophage:</strong> The integrated DNA is referred to as a prophage.</li></ul></li><li><strong>Maintenance Phase:</strong><ul><li><strong>Reproduction:</strong> The phage DNA replicates alongside host DNA.</li><li><strong>Advantage:</strong> Allows the phage to multiply without creating new phage particles, giving it a “free ride.”</li></ul></li><li><strong>Induction Phase (Conditional):</strong><ul><li><strong>Trigger:</strong> Exposure to mutagenic chemicals or radiation.</li><li><strong>Effect:</strong> The lysogenic cycle can be broken, shifting the phage into the lytic phase.</li></ul></li></ul><h4 id="Notes">Notes</h4><ul><li><strong>λ Phage Characteristics:</strong> It is a temperate phage, meaning it can follow both lytic and lysogenic paths.</li><li><strong>Versatility:</strong> λ phage showcases more versatility compared to virulent phages like T2, T4, T7, and SPO1, which always follow the lytic path.</li><li><strong>Lysogenic Stability:</strong> The lysogenic state can be stable indefinitely, beneficial for the phage as it ensures its survival and replication without killing the host.</li></ul><h3 id="λ-Genome-is-Organized-By-Function">λ Genome is Organized By Function</h3><table><thead><tr><th style="text-align:center"><img src="https://www.bx.psu.edu/~ross/workmg/TxnlRegLambdaCh17_files/image011.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.bx.psu.edu/~ross/workmg/TxnlRegLambdaCh17.htm">© bx.psu.edu</a></td></tr></tbody></table><ol><li><p><strong>HEAD &amp; TAIL Region</strong> (left side of the <strong>RECOMBINATION Region</strong>)</p><ul><li><strong>Structure:</strong> Encodes for the structural proteins constituting the phage’s capsid.</li><li><strong>Terminase Enzyme:</strong> Required for processing rolling circle multimers into unit genome-length pieces during DNA packaging.</li></ul></li><li><p><strong>RECOMBINATION Region</strong></p><ul><li><strong>Genes:</strong><ul><li><strong>Int:</strong> Necessary for the integration of the phage into the bacterial host chromosome during lysogenic growth.</li><li><strong>Xis:</strong> Facilitates the excision of the phage from the host chromosome during induction.</li><li><strong>Others:</strong> A variety of other genes facilitating integration and excision processes.</li></ul></li></ul></li><li><p><strong>REGULATION Region</strong></p><ul><li><strong>Immunity Region:</strong> Involved in the phage’s self-immunity processes.</li><li><strong>Switch Control:</strong> Houses genes controlling the switch between lysogenic and lytic growth.</li><li><strong>Q Antiterminator Protein:</strong> Part of the regulatory mechanism.</li><li><strong>Anti-Q RNA:</strong> Works alongside the Q protein in regulation.</li><li><strong>PR’:</strong> Constitutes a secondary regulation region, working in conjunction with Q protein and Anti-Q RNA.</li></ul></li><li><p><strong>REPLICATION Region</strong></p><ul><li><strong>Genes:</strong><ul><li><strong>O:</strong> Replication protein gene.</li><li><strong>P:</strong> Another gene involved in replication.</li></ul></li><li><strong>Origin of Replication:</strong> The starting point for the DNA replication process.</li></ul></li><li><p><strong>LYSIS Region</strong></p><ul><li><strong>Gene Count:</strong> Contains four genes.</li><li><strong>Function:</strong> The genes in this region are generally involved in the lysis of the host cell, facilitating the release of new phage particles.</li></ul></li></ol><h4 id="Note">Note</h4><ul><li><strong>Different Regions:</strong> Each region in the bacteriophage genome is designated for a different function, playing a crucial role in the phage’s life cycle, either helping in its replication, regulation of its life cycle, or in the processes leading to the integration into or excision from the host genome.</li></ul><h3 id="λ-Inserts-into-the-Host-Genome-by-Recombination">λ Inserts into the Host Genome by Recombination</h3><h3 id="λ-has-7-Promoters">λ has 7 Promoters</h3><ul><li>P<sub>R</sub> expresses the replication genes as well as the anti-repressor, Cro, the transcriptional activator cII, and the anti-terminator, Q protein.</li><li>P<sub>L</sub>expresses the recombination genes as well as the anti-terminator, N, and the cIII protein.</li><li>P<sub>R’</sub> expresses the lysis proteins, and the head and tail proteins.</li><li>P<sub>RE</sub> expresses the repressor gene, cI, to establish lysogeny.</li><li>P<sub>RM</sub> expresses the repressor gene, cI, to maintain lysogeny.</li><li>P<sub>I</sub> expresses the int gene to synthesize the Integrase protein.</li><li>P<sub>aQ</sub> drives synthesis of a short anti-sense RNA which blocks translation of Q gene mRNA.</li></ul><h3 id="Protein-Expression-is-Stage-Dependent">Protein Expression is Stage Dependent</h3><table><thead><tr><th>Event</th><th>l Gene Expressed</th><th>Comment</th></tr></thead><tbody><tr><td>Initial infection</td><td>Cro, N</td><td>Only N and Cro are synthesized until the decision point is reached</td></tr><tr><td>Lytic pathway</td><td>Cro, N, Q, late genes</td><td>Cro predominates at operators, N and Q are antiterminators</td></tr><tr><td>Lysogenic pathway</td><td>cI, cII, cIII, int</td><td>cII and cIII collaborate to establish cI synthesis; after genome integration, only cI is expressed during maintenance of lysogeny.</td></tr></tbody></table><h3 id="Consequences-of-Early-Gene-Expression">Consequences of Early Gene Expression</h3><ol><li>Cro repressor mRNA made from PR and translated.</li><li>N antiterminator mRNA made from PL and translated.  Allows transcription and translation of cII and cIII.</li><li>cII/cIII proteins activate PRE, causing transcription of cI</li><li>Concentrations of cI and Cro proteins build up</li></ol><h2 id="Initial-Events">Initial Events</h2><h3 id="Molecular-Decision-Making-Choice-between-Lysis-Lysogeny">Molecular Decision-Making: Choice between Lysis &amp; Lysogeny</h3><ul><li>Determined by relative concentrations of cI and Cro, which act oppositely on P<sub>RM</sub> the promoter for <strong>Repressor Maintenance</strong></li><li>P<sub>RM</sub> <strong>requires cI protein</strong>, therefore not active just after infection. <strong>Inhibited by Cro</strong>.</li><li>Cro lower affinity for PRM but is made earlier.</li><li>Cro binds same operator sites as cI, but not as efficiently or stably. At low levels, will slow down, but not stop expression of N , cIII (P<sub>L</sub>) or cII, P, Q (P<sub>R</sub>).  At high levels, cII and cIII are prevented from being transcribed, so no cI.</li></ul><h3 id="λ-Immunity-Region">λ Immunity Region</h3><table><thead><tr><th style="text-align:center"><img src="http://genes.atspace.org/Figs/G313.gif" alt=""></th></tr></thead><tbody><tr><td style="text-align:center"><a href="http://genes.atspace.org/11.5.html">© genes.atspace.org</a></td></tr></tbody></table><h2 id="Lysogeny">Lysogeny</h2><table><thead><tr><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/10/pPc3ztS.png" alt="Lysogeny"></th></tr></thead><tbody><tr><td style="text-align:center">Unknown</td></tr></tbody></table><h3 id="N-is-an-Anti-Terminator">N is an Anti-Terminator</h3><table><thead><tr><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/10/pPc89pQ.png" alt="N is an Anti-Terminator"></th><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/10/pPc8Clj.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center">Molecular Biology; Weaver, Robert: Fifth edition; P206</td><td style="text-align:center">P207; Figure 8.14</td></tr></tbody></table><ul><li><p><strong>Physical and Functional Layout</strong></p><ul><li><strong>Location</strong>: Situated downstream of the PL promoter and its respective operator, OL.</li><li><strong>Nut Site</strong>: Contains specific sequences, box A and box B, which play crucial roles in the functioning of the N protein.</li></ul></li><li><p><strong>Functionality in the Absence of N Protein</strong></p><ul><li><strong>Transcription Start</strong>: Commences at the PL promoter.</li><li><strong>Transcription Termination</strong>: Occurs at a terminator site situated downstream of the N gene. The RNA polymerase releases the N mRNA here.</li></ul></li><li><p><strong>Functionality in the Presence of N Protein</strong></p><ul><li><strong>N Protein Synthesis</strong>: Once the N gene has been transcribed, the N protein materializes.</li><li><strong>Binding to Nut Site</strong>: The N protein binds to the nut site on the transcript.</li><li><strong>Alteration of RNA Polymerase</strong>: The N protein collaborates with a complex of host proteins, altering the RNA polymerase to overlook the terminator site and proceed with transcription into the delayed early genes.</li></ul></li><li><p><strong>Involvement of Host Proteins</strong></p><ul><li><strong>Nus Proteins</strong>: These include NusA, NusB, and NusG, which have roles in both the phage and host cell processes.</li><li><strong>Ribosomal S10 Protein</strong>: Participates in protein synthesis in the host cell.</li><li><strong>Antitermination</strong>: N and NusA can facilitate antitermination in close proximity to the nut site, forming a short-range antitermination complex with the RNA polymerase.</li></ul></li><li><p><strong>Processive Antitermination</strong></p><ul><li><strong>Long-Range Effect</strong>: In natural circumstances, antitermination occurs hundreds of base pairs downstream of nut sites, requiring the involvement of all Nus proteins and S10 for stability.</li><li><strong>Persistent Complex</strong>: A stable complex is formed, continuing until reaching the terminator.</li></ul></li><li><p><strong>Nut Site Interaction</strong></p><ul><li><strong>RNA Interaction</strong>: Rather than interacting with the nut site itself, the complex interacts with its transcript.</li><li><strong>RNA-binding Domain</strong>: The region in N essential for nut recognition features an arginine-rich domain akin to RNA-binding domains.</li><li><strong>Protection from RNase</strong>: A full assembly of the five proteins in the complex shields both boxes A and B from RNase attacks.</li></ul></li><li><p><strong>RNA Loop Formation</strong></p><ul><li><strong>Sustained Signal</strong>: The RNA between the nut site transcript and the RNA polymerase forms a loop, maintaining the association of N with both, thus providing a continuous signal to the polymerase until it reaches the terminator.</li><li><strong>Evidence</strong>: Experiments have indicated that alterations in the RNA polymerase b-subunit gene can obstruct N-mediated antitermination, suggesting a potential association between the RNA polymerase, N, and the nut site transcript during transcription.</li></ul></li><li><p><strong>Conclusion</strong><br>The gene N encodes for the N protein which plays a pivotal role in the antitermination process during the phage lifecycle. It acts by binding to the nut site of the transcript and altering RNA polymerase activity, facilitating transcription beyond the terminator site. This mechanism leverages both short-range and processive antitermination, guided by a complex interplay of different proteins and the intricate structure of the nut site and its transcript. The stability and sustained activity of this system are central to its function, maintaining a persistent signal through RNA loop formations that guide the RNA polymerase over substantial distances.</p></li></ul><h3 id="N-Prevents-Stem-loop-Formation">N Prevents Stem-loop Formation</h3><table><thead><tr><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/10/pPc8Mc9.png" alt="N Prevents Stem-loop Formation"></th></tr></thead><tbody><tr><td style="text-align:center">P208; Figure 8.15</td></tr></tbody></table><ul><li><p><strong>Background</strong></p><ul><li><strong>Initial Hypothesis</strong>: N restricts the RNA polymerase pausing vital for termination.</li><li><strong>Research by Gusarov and Nudler (2001)</strong>: Contradicted the initial hypothesis, highlighting that N doesn’t significantly affect pausing but instead influences the formation of the terminator hairpin.</li></ul></li><li><p><strong>Mechanism</strong></p><ol><li><strong>N Binding to RNA</strong>: N binds to the portion of RNA supposed to form the upstream part of the terminator hairpin, thereby slowing down its formation.</li><li><strong>Preventing Hairpin Formation</strong>: Without the hairpin structure, the termination process cannot proceed, a mechanism somewhat similar to overriding transcription attenuation seen in the trp operon.</li></ol></li><li><p><strong>Role of NusA</strong></p><ol><li><strong>Interaction with Elongation Complex (EC)</strong>: As EC synthesizes a string of U’s, it pauses after adding the seventh nucleotide, positioning the potential upstream part of the hairpin to bind to the RNA polymerase’s upstream binding site (UBS).</li><li><strong>Time Constraint</strong>: The pause lasts for about 2 seconds, within which the hairpin should form to ensure termination; otherwise, the polymerase progresses without terminating.</li><li><strong>Stimulation of Termination</strong>: NusA weakens the connection between the potential upstream part of the hairpin and the UBS, encouraging quick hairpin formation and subsequently promoting termination.</li></ol></li><li><p><strong>Comprehensive Model (Gusarov and Nudler, 2001)</strong></p><ol><li><strong>Dual Binding</strong>: Both N and NusA bind to the RNA segment meant to form the upstream part of the hairpin.</li><li><strong>Blocking Hairpin Formation</strong>: By binding to the RNA segment, N prevents the quick formation of the hairpin.</li><li><strong>NusA’s Role</strong>: While connected to N, NusA also associates with the RNA segment, further slowing down the hairpin formation.</li><li><strong>Outcome</strong>: Due to the hindered hairpin formation, RNA polymerase moves forward without engaging in the termination process.</li></ol></li><li><p><strong>Conclusion</strong><br>N prevents termination not by limiting RNA polymerase pausing but by binding to the RNA segment that is crucial for forming the terminator hairpin, consequently slowing down its formation. NusA plays a dual role, both facilitating and slowing down hairpin formation depending on its interactions with either the RNA or N. The intricate interaction between N, NusA, and the RNA orchestrates whether the termination proceeds or not.</p></li></ul><h3 id="PL">P<sub>L</sub></h3><table><thead><tr><th style="text-align:center"><img src="https://upload.wikimedia.org/wikipedia/commons/a/a7/Phage_Lambda_int_xis_Retroregulation.jpg" alt=""></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://en.wikipedia.org/wiki/Lambda_phage">source: wiki</a></td></tr></tbody></table><p>In addition to N, the <mark>early transcript</mark> of PL codes for:</p><ul><li>cIII<br>required to protect the activator protein, cII</li><li>Xis<br>normally required for excision of a prophage</li><li>Int<br>normally required for integration of a prophage.</li></ul><h4 id="Background"><strong>Background</strong></h4><ul><li><strong>Context</strong>: Early lytic growth phase of bacteriophages.</li><li><strong>Concerned Molecules</strong>: Xis and Int proteins.</li><li><strong>Primary Regulator</strong>: N protein.</li></ul><h4 id="Mechanism"><strong>Mechanism</strong></h4><ol><li><strong>Role of N Protein</strong>:<ul><li><strong>Transcriptional Impact</strong>: Influences RNA polymerase to bypass the tI transcription terminator and continue transcription through the sib region.</li><li><strong>Attachment</strong>: Remains attached to the ternary transcription complex.</li></ul></li><li><strong>Sib Region</strong>:<ul><li><strong>Characteristic</strong>: Houses the signal for an RNase III processing site.</li><li><strong>Effect on mRNA</strong>: Transcripts passing through this region undergo structural changes to form a hairpin configuration.</li></ul></li><li><strong>Action of RNase III</strong>:<ul><li><strong>Recognition</strong>: Identifies the hairpin structure in the transcripts.</li><li><strong>Cleavage</strong>: Splits the transcript at the identified site, leaving free 3’ ends.</li></ul></li><li><strong>Exonuclease Activity</strong>:<ul><li><strong>Degradation</strong>: Enzymes present in the cell degrade the free 3’ ends further.</li><li><strong>Impact on Xis and Int</strong>: The coding regions for Xis and Int largely get destroyed before translation can occur, reducing their expression significantly.</li></ul></li></ol><h4 id="Retroregulation"><strong>Retroregulation</strong></h4><ul><li><strong>Definition</strong>: A regulatory mechanism where the stability and translatability of mRNA are controlled post-transcriptionally, affecting the subsequent expression of certain genes (in this case, Xis and Int).</li><li><strong>Outcome in the Context</strong>: Ensures limited expression of Xis and Int during the early lytic growth phase, maintaining control over the developmental pathway of the bacteriophage through intricate regulation at the RNA level.</li></ul><h4 id="Conclusion"><strong>Conclusion</strong></h4><ul><li><strong>Efficiency in Regulation</strong>: Retroregulation efficiently controls the expression of Xis and Int proteins during early lytic growth through a series of RNA modifications and processing, preventing their significant expression and translation during this phase.</li><li><strong>Regulatory Network</strong>: The process involves a network of actions including the N protein’s influence on RNA polymerase, hairpin formation guided by the sib region signal, RNase III-mediated cleavage, and exonuclease-induced degradation, demonstrating a tight regulatory mechanism at work during bacteriophage development.</li></ul><h3 id="cIII-Inhibits-Proteolysis-of-cII">cIII Inhibits Proteolysis of cII</h3><p><mark>cII half-life alone is &lt; 1min but with cIII it is ~ 5 min</mark></p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Molecule and Cellular Biology 6</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Class" scheme="https://karobben.github.io/categories/Notes/Class/"/>
    
    <category term="UIUC" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/"/>
    
    <category term="Cell Biology" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/Cell-Biology/"/>
    
    
    <category term="Classes" scheme="https://karobben.github.io/tags/Classes/"/>
    
    <category term="UIUC Classes" scheme="https://karobben.github.io/tags/UIUC-Classes/"/>
    
    <category term="Cell Biology" scheme="https://karobben.github.io/tags/Cell-Biology/"/>
    
  </entry>
  
</feed>
