<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Karobben</title>
  
  <subtitle>Engjoy~</subtitle>
  <link href="https://karobben.github.io/atom.xml" rel="self"/>
  
  <link href="https://karobben.github.io/"/>
  <updated>2023-12-22T03:11:28.813Z</updated>
  <id>https://karobben.github.io/</id>
  
  <author>
    <name>Karobben</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Immunoglobulin BLAST (Igblast), a Blast Tool Specific for Antibodies</title>
    <link href="https://karobben.github.io/2023/12/21/Bioinfor/igblast/"/>
    <id>https://karobben.github.io/2023/12/21/Bioinfor/igblast/</id>
    <published>2023-12-22T02:21:23.000Z</published>
    <updated>2023-12-22T03:11:28.813Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Key-Features-of-IgBLAST">Key Features of IgBLAST</h2><ol><li><p><strong>Identification of V(D)J segments</strong>: IgBLAST can identify variable (V), diversity (D), and joining (J) gene segments in IG or TCR sequences.</p></li><li><p><strong>Clonotype Analysis</strong>: It helps in determining clonotypes based on V(D)J segment usage, providing insights into the diversity and clonality of IG or TCR repertoires.</p></li><li><p><strong>Somatic Hypermutation Analysis</strong>: It identifies somatic hypermutations in IG sequences and can compare these to germline sequences, which is critical in understanding adaptive immune responses.</p></li><li><p><strong>Flexible Input Options</strong>: IgBLAST can process both nucleotide and protein sequences, and it supports various input formats.</p></li><li><p><strong>Detailed Alignment Information</strong>: It provides detailed alignment results that include information about gene segments, framework regions, complementarity-determining regions (CDRs), and mutations.</p></li><li><p><strong>Integration with Other Databases</strong>: The results can be linked to other NCBI databases for additional information and analysis.</p></li></ol><p>IgBLAST is widely used in immunology and related fields for studying B cell and T cell receptor repertoire, which is crucial for understanding immune responses, vaccine development, and in the study of autoimmune diseases and cancer.</p><h2 id="Local-Set-Up">Local Set Up</h2><ul><li>Basically, you can use the online service: <a href="https://www.ncbi.nlm.nih.gov/igblast/">NCBI igblast</a></li><li>Set up by following the official documentation: <a href="https://ncbi.github.io/igblast/cook/How-to-set-up.html">NCBI igblast set up</a></li></ul><p>Here is an example of set up by using conda from <a href="https://github.com/nicwulab/SARS-CoV-2_Abs#local-igblast-setup">nicwulab/SARS-CoV-2_Abs</a></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">conda create -n Abs -c bioconda \<br>  python=3.9 \<br>  igblast<br><br>conda activate Abs<br><span class="hljs-comment"># install pyir and use it to set up the blast database</span><br>pip3 install crowelab_pyir<br>pyir setup<br></code></pre></td></tr></table></figure></div><p>In the <code>pyir</code>, it is using ‘http’ and download the data failed. By following the error code, we could find the script and alter the ‘http’ to ‘https’. It should solving the problem.</p><p>An example of running the program:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">igblastn -query result/test.fasta \<br>  -germline_db_V imgt_database/human_nuc/IGV.fasta \<br>  -germline_db_J imgt_database/human_nuc/IGJ.fasta \<br>  -germline_db_D imgt_database/human_nuc/IGD.fasta \<br>  -organism human -domain_system kabat \<br>  -auxiliary_data imgt_database/optional_file/human_gl.aux \<br>  -out result/igblast_output<br></code></pre></td></tr></table></figure></div><h2 id="Q-A">Q&amp;A</h2><div class="admonition question"><p class="admonition-title">Can I annotate the light chain and heavy chain simultaneously?</p><p>IgBLAST is designed to analyze immunoglobulin (IG) sequences, including both heavy and light chains. However, it typically processes and analyzes these chains separately. When you input a sequence that contains both heavy and light chains, IgBLAST might only process the first recognizable sequence, which in your case appears to be the heavy chain.</p><p>To analyze both heavy and light chains using IgBLAST, you generally need to input them as separate sequences. This means splitting your combined sequence into two parts - one for the heavy chain and the other for the light chain - and then running IgBLAST for each part individually.</p><p>There isn't a parameter in IgBLAST that allows for the simultaneous analysis of both heavy and light chains when they are combined into a single sequence. The tool's algorithm is designed to identify and annotate the V(D)J segments of a single chain at a time, as the structure and sequence features of heavy and light chains are distinct.</p><p>If you are consistently working with sequences that contain both chains, you may need to develop a preprocessing step in your workflow to separate these chains before analysis. Alternatively, if such a tool is essential for your work, you might need to look into other bioinformatics tools or custom scripting to first identify and separate the heavy and light chain sequences before feeding them into IgBLAST.</p></div><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Igblast, a Blast Tool Specific for Antibodies</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Software" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Software/"/>
    
    <category term="Align" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Software/Align/"/>
    
    
    <category term="Software" scheme="https://karobben.github.io/tags/Software/"/>
    
    <category term="Database" scheme="https://karobben.github.io/tags/Database/"/>
    
    <category term="Align" scheme="https://karobben.github.io/tags/Align/"/>
    
  </entry>
  
  <entry>
    <title>scVDJ-Seq Pipeline (CellRanger)</title>
    <link href="https://karobben.github.io/2023/12/21/Bioinfor/scvdj-seq/"/>
    <id>https://karobben.github.io/2023/12/21/Bioinfor/scvdj-seq/</id>
    <published>2023-12-21T20:52:46.000Z</published>
    <updated>2023-12-21T21:14:25.261Z</updated>
    
    <content type="html"><![CDATA[<h2 id="scVDJ-Seq">scVDJ-Seq</h2><table><thead><tr><th style="text-align:center"><img src="https://imgur.com/PxRTphj.png" alt="scVDJ-Seq"></th></tr></thead><tbody><tr><td style="text-align:center">V(D)J Library Construction</td></tr></tbody></table><ol><li><p><font style="background-color: red">V</font> (Variable): These are gene segments that code for the variable region of an antibody or T-cell receptor. The variable region is responsible for binding to antigens.</p></li><li><p><font style="background-color: gold">D</font> (Diversity): These segments are found in some classes of antibodies and in T-cell receptors. They provide an additional level of diversity to the antigen-binding region.</p></li><li><p><font style="background-color: green">J</font> (Joining): These gene segments join with the V (and D, where present) segments to complete the variable region of the receptor.</p></li><li><p><font style="background-color: royalblue">C</font> (Constant): The constant region of the antibody or T-cell receptor is encoded by these segments. This region does not vary much between different antibodies and is responsible for the effector functions of the antibody, such as recruiting other parts of the immune system.</p></li></ol><h2 id="Pipeline">Pipeline</h2><table><thead><tr><th style="text-align:center"><img src="https://cdn.10xgenomics.com/image/upload/v1654273213/software-support/vdj/algorithms/algorithm-workflow.png" alt="Cell Ranger's V(D)J Algorithm"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.10xgenomics.com/cn/support/software/cell-ranger/algorithms-overview/cr-5p-vdj-algorithm">© 10X Genomics</a></td></tr></tbody></table><h2 id="Install-CellRanger">Install CellRanger</h2><p>Click the <a href="https://www.10xgenomics.com/support/software/cell-ranger/downloads">Link</a> and fill out the information and you could get the download page</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># download the software (expired)</span><br>curl -o cellranger-7.2.0.tar.gz <span class="hljs-string">&quot;https://cf.10xgenomics.com/releases/cell-exp/cellranger-7.2.0.tar.gz?Expires=1703232056&amp;Key-Pair-Id=APKAI7S6A5RYOXBWRPDA&amp;Signature=hm5oQoPrhuNznBtqCREVSaH34WF-Fute6XHYRDUIvIsajK~sFKYuonBEUQsxRJ1oKmxuuAhmtJg3N-mEQU2dr223oXTTr9e70gFlx9-3qgR7cvAhbZXMMGPMhOVVixoEF2GaE1~x0LA4KLXG3xu4mDGsBn4u870Ql~~OfhYBF5bHcqV6hf8X-YPXNG8TbRZMe-dqcogRTPYpeOpfKBtvPs63CDJ3YgC2Bahci4jYuo2v7MZDTR018C~X-3qwgRMIPKCMZFInEjpkfds34TJ0yP3uwAprvpR~S3WCngKKzSmAQszkDMqSB2eXZw6~FF~6oFIIYV~-DmPV~a7DO416nQ__&quot;</span><br><br><span class="hljs-comment"># decompress and install</span><br>tar -zxvf cellranger-7.2.0.tar.gz<br><br><span class="hljs-comment"># add this directory in your path</span><br><span class="hljs-built_in">export</span> PATH=$(<span class="hljs-built_in">pwd</span>):<span class="hljs-variable">$PATH</span><br><span class="hljs-comment"># You may wish to add this command to your ~/.bashrc or ~/.zshrc for convenience.</span><br><span class="hljs-comment"># for get the full command, you can run `echo export PATH=$(pwd):\$PATH` and add the print out result at the end of the ~/.bashrc or ~/.zshrc</span><br></code></pre></td></tr></table></figure></div><div class="admonition note"><p class="admonition-title">Reference</p><p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Download the reference</span><br><span class="hljs-comment">## Human reference (GRCh38) - 2020-A</span><br>curl -O <span class="hljs-string">&quot;https://cf.10xgenomics.com/supp/cell-exp/refdata-gex-GRCh38-2020-A.tar.gz&quot;</span><br><span class="hljs-comment">## Mouse reference (mm10) - 2020-A</span><br>curl -O <span class="hljs-string">&quot;https://cf.10xgenomics.com/supp/cell-exp/refdata-gex-mm10-2020-A.tar.gz&quot;</span><br><span class="hljs-comment">## Human (GRCh38) and mouse (mm10) reference - 2020-A</span><br>curl -O <span class="hljs-string">&quot;https://cf.10xgenomics.com/supp/cell-exp/refdata-gex-GRCh38-and-mm10-2020-A.tar.gz&quot;</span><br><br><span class="hljs-comment">## Human V(D)J reference (GRCh38)</span><br>curl -O <span class="hljs-string">&quot;https://cf.10xgenomics.com/supp/cell-vdj/refdata-cellranger-vdj-GRCh38-alts-ensembl-7.1.0.tar.gz&quot;</span><br><span class="hljs-comment">## Mouse V(D)J reference (GRCm38)</span><br>curl -O <span class="hljs-string">&quot;https://cf.10xgenomics.com/supp/cell-vdj/refdata-cellranger-vdj-GRCm38-alts-ensembl-7.0.0.tar.gz&quot;</span><br></code></pre></td></tr></table></figure></div></p></div><h3 id="Run">Run</h3><p>Documentation: <a href="https://www.10xgenomics.com/cn/support/software/cell-ranger/algorithms-overview/cr-5p-vdj-algorithm">10X Genomics</a></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">cellranger vdj --id=sample345 \<br>         --reference=/opt/refdata-cellranger-vdj-GRCh38-alts-ensembl-7.1.0 \<br>         --fastqs=/home/jdoe/runs/HAWT7ADXX/outs/fastq_path \<br>         --sample=mysample \<br>         --localcores=8 \<br>         --localmem=64<br></code></pre></td></tr></table></figure></div><ul><li><strong>Command and Arguments</strong>:</li></ul><pre>cellranger vdj:     This is the main command being run. `cellranger` is the software package, and `vdj` specifies that you are running the V(D)J analysis pipeline, which is used for assembling and annotating V(D)J sequences from single-cell RNA-Seq data.--id=sample345:     This sets the unique identifier for the run. Here, the identifier is `sample345`. This ID is used to name the output directory.--reference=...:    This specifies the reference dataset to be used for the analysis. The provided path (`/opt/refdata-cellranger-vdj-GRCh38-alts-ensembl-7.1.0`) points to a reference dataset for human V(D)J sequences.--fastqs=...:       This indicates the directory where the FASTQ files are located. FASTQ files are the input files for the Cell Ranger software, containing the sequenced reads.--sample=mysample:  This specifies the name of the sample to be analyzed. It should match the sample name in the FASTQ files.--localcores=8:     This parameter tells Cell Ranger to use 8 CPU cores for the computation. This setting helps to optimize the use of available computational resources.--localmem=64:      This allocates 64 GB of memory (RAM) for the run. This parameter is crucial for ensuring the software has enough memory to process the data without crashing.</pre><h2 id="When-the-Job-is-Done">When the Job is Done</h2><p>A successful <code>cellranger vdj</code> run should conclude with a message similar to this:</p><pre>Outputs:- Run summary HTML:                                 /home/jdoe/runs/sample345/outs/web_summary.html- Run summary CSV:                                  /home/jdoe/runs/sample345/outs/metrics_summary.csv- Clonotype info:                                   /home/jdoe/runs/sample345/outs/clonotypes.csv- Filtered contig sequences FASTA:                  /home/jdoe/runs/sample345/outs/filtered_contig.fasta- Filtered contig sequences FASTQ:                  /home/jdoe/runs/sample345/outs/filtered_contig.fastq- Filtered contigs (CSV):                           /home/jdoe/runs/sample345/outs/filtered_contig_annotations.csv- All-contig FASTA:                                 /home/jdoe/runs/sample345/outs/all_contig.fasta- All-contig FASTA index:                           /home/jdoe/runs/sample345/outs/all_contig.fasta.fai- All-contig FASTQ:                                 /home/jdoe/runs/sample345/outs/all_contig.fastq- Read-contig alignments:                           /home/jdoe/runs/sample345/outs/all_contig.bam- Read-contig alignment index:                      /home/jdoe/runs/sample345/outs/all_contig.bam.bai- All contig annotations (JSON):                    /home/jdoe/runs/sample345/outs/all_contig_annotations.json- All contig annotations (BED):                     /home/jdoe/runs/sample345/outs/all_contig_annotations.bed- All contig annotations (CSV):                     /home/jdoe/runs/sample345/outs/all_contig_annotations.csv- Barcodes that are declared to be targetted cells: /home/jdoe/runs/sample345/outs/cell_barcodes.json- Clonotype consensus FASTA:                        /home/jdoe/runs/sample345/outs/consensus.fasta- Clonotype consensus FASTA index:                  /home/jdoe/runs/sample345/outs/consensus.fasta.fai- Contig-consensus alignments:                      /home/jdoe/runs/sample345/outs/consensus.bam- Contig-consensus alignment index:                 /home/jdoe/runs/sample345/outs/consensus.bam.bai- Clonotype consensus annotations (CSV):            /home/jdoe/runs/sample345/outs/consensus_annotations.csv- Concatenated reference sequences:                 /home/jdoe/runs/sample345/outs/concat_ref.fasta- Concatenated reference index:                     /home/jdoe/runs/sample345/outs/concat_ref.fasta.fai- Contig-reference alignments:                      /home/jdoe/runs/sample345/outs/concat_ref.bam- Contig-reference alignment index:                 /home/jdoe/runs/sample345/outs/concat_ref.bam.bai- Loupe V(D)J Browser file:                         /home/jdoe/runs/sample345/outs/vloupe.vloupe- V(D)J reference:fasta:regions:       /home/jdoe/runs/sample345/outs/vdj_reference/fasta/regions.fadonor_regions: /home/jdoe/runs/sample345/outs/vdj_reference/fasta/donor_regions.fareference: /home/jdoe/runs/sample345/outs/vdj_reference/reference.json- AIRR Rearrangement TSV:                           /home/jdoe/runs/sample345/outs/airr_rearrangement.tsv- All contig info (ProtoBuf format):                /home/jdoe/runs/sample345/outs/vdj_contig_info.pbWaiting 6 seconds for UI to do final refresh.Pipestance completed successfully!</pre><p>Once <code>cellranger vdj</code> has successfully completed, you can browse the resulting summary HTML file in any supported web browser, open the <code>.vloupe</code> file in Loupe V(D)J Browser, or refer to the Understanding Output section to explore the data by hand.</p><h2 id="Trouble-Shoot">Trouble Shoot</h2><h3 id="Too-Low-to-Meet-the-Required-Threshold">Too Low to Meet the Required Threshold</h3><pre>[error] Pipestance failed. Error log at:MockC_cs/SC_VDJ_ASSEMBLER_CS/SC_MULTI_CORE/MULTI_CHEMISTRY_DETECTOR/VDJ_CHEMISTRY_DETECTOR/DETECT_VDJ_RECEPTOR/fork0/chnk0-u22ea849f77/_errorsLog message:V(D)J Chain detection failed for Sample VDJ-B-293-redo-1 in "/raid/home/wenkanl2/MokC_sc/1_primary_seq".Total Reads          = 1000000Reads mapped to TR   = 30Reads mapped to IG   = 28665In order to distinguish between the TR and the IG chain the following conditions need to be satisfied:- A minimum of 10000 total reads- A minimum of 5.0% of the total reads needs to map to TR or IG- The number of reads mapped to TR should be at least 3.0x compared to the number of reads mapped to IG or vice versaPlease check the input data and/or specify the chain via the --chain argument.</pre><p>The problem here is with the proportion of reads mapping to TR and IG. Even though you have a significant number of reads mapped to IG, the number of reads mapped to TR is <mark>too low to meet the required thresholds</mark>.</p><div class="admonition note"><p class="admonition-title">Resolution:</p><p>The message suggests checking the input data or specifying the chain via the --chain argument. Explicitly specify whether you are analyzing T-cell receptors (TR) or Immunoglobulins (IG) by using the --chain flag in your Cell Ranger command.For example, assume that it is B cell data, we could add <code>--chain IG</code> to solve this problem</p></div><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">scVDJ-Seq Pipeline</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Single Cell" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Single-Cell/"/>
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="RNA-Seq" scheme="https://karobben.github.io/tags/RNA-Seq/"/>
    
    <category term="NGS" scheme="https://karobben.github.io/tags/NGS/"/>
    
    <category term="scRNA-Seq" scheme="https://karobben.github.io/tags/scRNA-Seq/"/>
    
  </entry>
  
  <entry>
    <title>Secure Shell (SSH)</title>
    <link href="https://karobben.github.io/2023/12/20/Linux/ssh/"/>
    <id>https://karobben.github.io/2023/12/20/Linux/ssh/</id>
    <published>2023-12-20T17:59:14.000Z</published>
    <updated>2023-12-20T18:27:20.875Z</updated>
    
    <content type="html"><![CDATA[<h2 id="SSH">SSH</h2><p>SSH, short for Secure Shell, is a network protocol used to securely access and manage a computer over an unsecured network. It provides a secure channel over an unencrypted network, like the internet, allowing users to log into another computer, execute commands remotely, and move files. SSH uses strong encryption to protect the data being transmitted, ensuring confidentiality and integrity of the data against eavesdropping and interception. It’s commonly used by system administrators and IT professionals for managing systems and applications remotely.</p><h2 id="How-to-Use-It">How to Use It</h2><p>Using SSH typically involves two primary components: an SSH client and an SSH server. The server runs on the machine you want to connect to, while the client runs on the machine you’re connecting from. Here’s a basic guide on how to use SSH:</p><h3 id="Setting-Up-an-SSH-Server">Setting Up an SSH Server</h3><ol><li><p><strong>Install SSH Server</strong>: On the remote machine (the one you want to access), you need to install an SSH server. For Linux systems, this is often done using the <code>openssh-server</code> package.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo apt update<br>sudo apt install openssh-server<br></code></pre></td></tr></table></figure></div><p>This example is for Debian-based systems (like Ubuntu). The commands might vary for other systems.</p></li><li><p><strong>Start and Enable SSH Service</strong>: Ensure that the SSH service is started and enabled to start on boot.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo systemctl start ssh<br>sudo systemctl <span class="hljs-built_in">enable</span> ssh<br></code></pre></td></tr></table></figure></div></li><li><p><strong>Configure SSH Server (Optional)</strong>: You can configure your SSH server by editing the <code>/etc/ssh/sshd_config</code> file. This step is optional and typically only necessary for advanced configurations.</p></li></ol><h3 id="Connecting-Using-an-SSH-Client">Connecting Using an SSH Client</h3><ol><li><p><strong>Install SSH Client</strong>: Most Unix-like systems (Linux, macOS) come with an SSH client pre-installed. For Windows, you can use clients like PuTTY or use the built-in SSH client in Windows 10/11.</p></li><li><p><strong>Establish an SSH Connection</strong>: To connect to the SSH server, you need the IP address or hostname of the server and the username on that system. The basic command is:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">ssh [username]@[host]<br></code></pre></td></tr></table></figure></div><p>For example, if your username is <code>user</code> and the server’s IP address is <code>192.168.1.100</code>, you would use:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">ssh user@192.168.1.100<br></code></pre></td></tr></table></figure></div></li><li><p><strong>Authenticate</strong>: When you connect for the first time, you’ll be asked to verify the identity of the server. After accepting, you’ll be prompted for the password of the user account you are logging into on the remote machine.</p></li><li><p><strong>Using SSH</strong>: Once connected, you can execute commands on the remote machine as if you were physically present.</p></li><li><p><strong>Transferring Files (Optional)</strong>: SSH also allows for secure file transfer using SCP or SFTP.</p><ul><li>To copy a file from your local machine to the remote machine:<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">scp /path/to/<span class="hljs-built_in">local</span>/file user@192.168.1.100:/path/to/remote/directory<br></code></pre></td></tr></table></figure></div></li><li>To copy a file from the remote machine to your local machine:<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">scp user@192.168.1.100:/path/to/remote/file /path/to/<span class="hljs-built_in">local</span>/directory<br></code></pre></td></tr></table></figure></div></li></ul></li><li><p><strong>Exiting SSH</strong>: To end your SSH session, simply type <code>exit</code> or press <code>Ctrl+D</code>.</p></li></ol><h3 id="Security-Considerations">Security Considerations</h3><ul><li><p><strong>SSH Keys</strong>: For better security, it’s recommended to use SSH keys instead of passwords. SSH keys are a pair of cryptographic keys that can be used to authenticate to an SSH server as an alternative to password-based logins.</p></li><li><p><strong>Firewall Settings</strong>: Make sure your firewall settings allow SSH connections (usually on port 22).</p></li><li><p><strong>Regular Updates</strong>: Keep the SSH server software up to date for security.</p></li></ul><p>SSH is a powerful tool for remote administration, but it’s important to use it securely to protect your systems and data.</p><h2 id="SSH-Key">SSH Key</h2><p>Generating an SSH key is a security practice for authenticating to an SSH server more securely than using just a password. Here’s why you should do it and how to generate an SSH key:</p><h3 id="Why-Use-SSH-Keys">Why Use SSH Keys?</h3><ol><li><p><strong>Enhanced Security</strong>: SSH keys are cryptographic keys that are much more secure than passwords. They are almost impossible to decipher using brute force methods.</p></li><li><p><strong>No Need for Passwords</strong>: When you use SSH keys, you don’t need to enter your password every time you connect, which reduces the risk of password theft.</p></li><li><p><strong>Automation Friendly</strong>: SSH keys are ideal for automated processes. Scripts and applications can authenticate without manual password entry.</p></li><li><p><strong>Access Control</strong>: SSH keys can be used to control who can access a server. Only users with the matching private key can access the server configured with the public key.</p></li></ol><h3 id="How-to-Generate-an-SSH-Key">How to Generate an SSH Key</h3><h4 id="On-Linux-or-macOS">On Linux or macOS:</h4><ol><li><p><strong>Open Terminal</strong>: Launch the terminal application.</p></li><li><p><strong>Generate Key Pair</strong>: Use the <code>ssh-keygen</code> command to generate a new SSH key pair.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">ssh-keygen -t rsa -b 4096<br></code></pre></td></tr></table></figure></div><p>This command creates a new SSH key using the RSA algorithm with a key size of 4096 bits, providing a good balance between security and compatibility. You can choose other algorithms like <code>ed25519</code> which is considered more secure but may not be compatible with older systems.</p></li><li><p><strong>Specify File to Save the Key</strong>: By default, <code>ssh-keygen</code> will save the key in the <code>~/.ssh/id_rsa</code> file. You can specify a different file if you want.</p></li><li><p><strong>Enter a Passphrase (Optional)</strong>: For additional security, you can enter a passphrase when prompted. This passphrase will be required whenever the private key is used.</p></li></ol><h3 id="Adding-the-SSH-Key-to-Your-SSH-Server">Adding the SSH Key to Your SSH Server</h3><ol><li><p><strong>Copy Public Key</strong>: After generating your SSH key, you need to add the public key to the <code>~/.ssh/authorized_keys</code> file on your SSH server.</p></li><li><p><strong>Use <code>ssh-copy-id</code> on Linux/macOS</strong>: If you’re using Linux or macOS, you can use <code>ssh-copy-id</code> to copy your public key to the server easily.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">ssh-copy-id user@server-address<br></code></pre></td></tr></table></figure></div></li><li><p><strong>Manual Copying</strong>: If <code>ssh-copy-id</code> isn’t available or you’re using Windows, you can manually copy the public key text and append it to <code>~/.ssh/authorized_keys</code> on the server.</p></li></ol><p>Remember, never share your private key. The public key is what you distribute or add to servers, while the private key should be securely stored and kept private.</p><h2 id="Trouble-Shooting-Public-Key-Doesn’t-Work">Trouble Shooting: Public Key Doesn’t Work</h2><p>If your SSH public key authentication isn’t working, there could be several reasons. Here’s a troubleshooting guide to help you resolve common issues:</p><h3 id="1-Check-File-Permissions">1. Check File Permissions</h3><ul><li><strong>On the Server</strong>: SSH is particular about file permissions for the <code>~/.ssh</code> directory and the <code>authorized_keys</code> file. Incorrect permissions can prevent SSH from authenticating using keys.<ul><li>The <code>~/.ssh</code> directory should have permissions set to <code>700</code> (drwx------).</li><li>The <code>authorized_keys</code> file should have permissions set to <code>600</code> (-rw-------).</li><li>Use the <code>chmod</code> command to set these permissions:</li></ul></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">chmod 700 ~/.ssh<br>chmod 600 ~/.ssh/authorized_keys<br></code></pre></td></tr></table></figure></div><h3 id="2-Ensure-Correct-Ownership">2. Ensure Correct Ownership</h3><p>The <code>.ssh</code> directory and the <code>authorized_keys</code> file should be owned by the user, not root or any other user. Use the <code>chown</code> command to set the ownership:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">chown -R your_username:your_username ~/.ssh<br></code></pre></td></tr></table></figure></div><p>You can also make sure that the home directory permissions are restricted to the user. I think it could do the same thing.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">chmod -R u+rwX,go-rwx /home/your_username<br></code></pre></td></tr></table></figure></div><h3 id="3-Verify-the-Public-Key-Format">3. Verify the Public Key Format</h3><p>Ensure that the public key in <code>authorized_keys</code> is in the correct format. It should be a single line starting with <code>ssh-rsa</code> or <code>ssh-ed25519</code>, followed by the key, and optionally a comment.</p><h3 id="4-Check-the-SSH-Server-Configuration">4. Check the SSH Server Configuration</h3><p>The SSH server configuration file (<code>/etc/ssh/sshd_config</code>) on the server might restrict public key authentication. Check the following settings:</p><ul><li><code>PubkeyAuthentication yes</code> should be set to allow public key authentication.</li><li><code>AuthorizedKeysFile</code> should point to the correct path, typically <code>.ssh/authorized_keys</code>.</li><li>If <code>PasswordAuthentication</code> is set to <code>no</code>, the server will not fall back to password authentication if key authentication fails.</li><li>After making changes, restart the SSH service:</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo systemctl restart ssh<br></code></pre></td></tr></table></figure></div><h3 id="5-Check-SSH-Client-Configuration">5. Check SSH Client Configuration</h3><p>On your client machine, ensure you’re specifying the correct private key. If you’re using a key with a non-default name or location, specify it with the <code>-i</code> option:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">ssh -i /path/to/private_key user@server<br></code></pre></td></tr></table></figure></div><h3 id="6-Look-at-Server-Logs">6. Look at Server Logs</h3><p>SSH server logs can provide details on why the key authentication is failing. Check the logs for relevant error messages:</p><ul><li>On most Linux systems, SSH logs are located in <code>/var/log/auth.log</code> or <code>/var/log/secure</code>.</li></ul><h3 id="7-Validate-Key-Pair">7. Validate Key Pair</h3><p>Ensure that the public and private keys are a matching pair. If you have regenerated or changed keys, make sure the server has the corresponding public key.</p><h3 id="8-Check-Passphrase">8. Check Passphrase</h3><p>If your private key is protected with a passphrase, ensure you’re entering the correct passphrase when prompted.</p><h3 id="9-Network-Issues">9. Network Issues</h3><p>Confirm there are no network issues preventing SSH access. Firewall settings on either the client or server side can block SSH connections.</p><h3 id="10-Client-Side-Debugging">10. Client-Side Debugging</h3><p>Use SSH with the <code>-vvv</code> option for verbose output, which can give more insights:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">ssh -vvv -i /path/to/private_key user@server<br></code></pre></td></tr></table></figure></div><p>This will provide detailed debug information about each step of the SSH connection process, potentially highlighting where the issue lies.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Secure Shell (SSH) installation, usage, and trouble shooting</summary>
    
    
    
    <category term="Linux" scheme="https://karobben.github.io/categories/Linux/"/>
    
    <category term="System" scheme="https://karobben.github.io/categories/Linux/System/"/>
    
    
    <category term="Linux" scheme="https://karobben.github.io/tags/Linux/"/>
    
    <category term="bash" scheme="https://karobben.github.io/tags/bash/"/>
    
  </entry>
  
  <entry>
    <title>Phylogenetic Tree</title>
    <link href="https://karobben.github.io/2023/12/18/Bioinfor/phylogenetic/"/>
    <id>https://karobben.github.io/2023/12/18/Bioinfor/phylogenetic/</id>
    <published>2023-12-18T17:26:46.000Z</published>
    <updated>2023-12-20T20:28:41.089Z</updated>
    
    <content type="html"><![CDATA[<h2 id="What-is-Phylogenetic-Tree">What is Phylogenetic Tree</h2><blockquote><p>A phylogenetic tree is a diagram representing the evolutionary relationships among species or other entities based on their genetic or physical characteristics. The branches of the tree indicate how these species have evolved from common ancestors. The tree can be rooted, showing the most recent common ancestor, or unrooted, illustrating relationships without a common origin point. Constructed using data like DNA sequences or morphological traits, these trees are essential in studying evolutionary biology, tracking disease evolution, and in conservation efforts. They provide a visual representation of the evolutionary history and connections between different forms of life.<br>(GPT4)</p></blockquote><h2 id="General-Ideas-of-Phylogenetic-Tree">General Ideas of Phylogenetic Tree</h2><p>Source: <a href="https://evolution.berkeley.edu/evolution-101/the-history-of-life-looking-at-the-patterns/understanding-phylogenies/">Evo 101, Berkeley</a></p><table><thead><tr><th style="text-align:center"><img src="https://evolution.berkeley.edu/wp-content/uploads/2021/11/understanding_phylos_Understanding-phylo1-500x185.png" alt=""></th><th style="text-align:center"><img src="https://evolution.berkeley.edu/wp-content/uploads/2021/11/understanding_phylos_speciation-event-500x184.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center"><img src="https://evolution.berkeley.edu/wp-content/uploads/2021/11/understanding_phylos_unique-history-500x185.png" alt=""></td><td style="text-align:center"><img src="https://evolution.berkeley.edu/wp-content/uploads/2021/11/understanding_phylos_unique-ancestor-500x184.png" alt=""></td></tr></tbody></table><h2 id="Distance-Matrix-GPT4">Distance Matrix (GPT4)</h2><p>More related source could be found at <a href="https://academic-accelerator.com/encyclopedia/distance-matrix">academic accelerator</a></p><p>A distance matrix, in general, is a table used to show the distance between elements in a set. In the context of phylogenetics, it represents the genetic distance between various species or sequences.<br>A distance matrix in phylogenetics is a tool to quantify and visualize the genetic distances between different species or sequences. This matrix forms the basis for constructing phylogenetic trees, which depict the evolutionary relationships and history among the species studied.</p><details><summary>1. <b>General Distance Matrix</b></summary><ul><li>This is a square matrix where the elements represent the distances between pairs of objects.</li><li>In the matrix, each row and column represents an object, and each cell in the matrix shows the distance between the two objects.</li><li>The distances can be based on various metrics, depending on the context (e.g., physical distance, similarity in characteristics, etc.).</li></ul></details><details><summary>2. <b>Distance Matrix in Phylogenetics</b></summary><ul><li>In phylogenetics, the distance matrix represents genetic distances between different species or DNA sequences.</li><li>The genetic distance can be based on differences in DNA, RNA, or protein sequences, indicating how much genetic change has occurred between the sequences.</li><li>The distances are often calculated using methods that count the number of differences between sequences (like nucleotide substitutions) or more complex models that account for the rate of evolution and types of mutations.</li></ul></details><details><summary>3. <b>How it Works in Phylogenetics</b></summary><ul><li><strong>Data Collection</strong>: First, genetic data (like DNA sequences) from different species or organisms are collected.</li><li><strong>Distance Calculation</strong>: Algorithms calculate the genetic distance between each pair of sequences. These calculations can be straightforward (like counting differences) or complex (accounting for evolutionary models).</li><li><strong>Matrix Formation</strong>: These distances are then arranged in a matrix format, where each row and column represents a species or sequence, and each cell shows the genetic distance between them.</li><li><strong>Tree Construction</strong>: Phylogenetic trees can be constructed using this matrix. Methods like UPGMA (Unweighted Pair Group Method with Arithmetic mean) or neighbor-joining are used to create trees that best reflect the distances in the matrix.</li><li><strong>Analysis</strong>: The resulting tree is analyzed to understand evolutionary relationships, like which species are more closely related based on the genetic distances.</li></ul></details><br><table><thead><tr><th style="text-align:center"><img src="https://upload.wikimedia.org/wikipedia/commons/8/80/Additive_distance_matrix.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://academic-accelerator.com/encyclopedia/distance-matrix">© academic accelerator</a></td></tr></tbody></table><div class="admonition note"><p class="admonition-title">How to make the sense of the  dendrogram?</p><p>This graph illustrates the distance matrix and how it gives sense to the phylogenetic tree. According to the tree, the distance between <strong>b</strong> and <strong>c</strong> is 1+2=3. Similarly, we can deduce from the tree that the distance between <strong>a</strong> and <strong>d</strong> is 4+4+1=9.</p></div><h3 id="Methods-for-Calculating-the-Distance-Matrix-GPT4">Methods for Calculating the Distance Matrix (GPT4)</h3><p>In phylogenetics, there are several methods to calculate the distance matrix, each with its own approach to measuring genetic distances between sequences. These methods vary in complexity and the types of evolutionary changes they consider. Here are some commonly used methods:</p><details><summary>1. <b>Simple Counting Methods</b></summary><ul><li>These involve counting the number of differences (e.g., nucleotide or amino acid substitutions) between each pair of sequences.</li><li>One example is the Hamming distance, which is simply the number of positions at which the corresponding elements (nucleotides or amino acids) are different.</li></ul></details><details><summary>2. <b>Corrected Distance Methods</b></summary><ul><li>These methods account for multiple changes at the same site and unseen changes due to evolutionary processes.</li><li>An example is the Jukes-Cantor model, which corrects for multiple substitutions at the same site by assuming that all changes occur at the same rate.</li></ul></details><details><summary>3. <b>Model-Based Methods</b></summary><ul><li>These use complex models of sequence evolution, accounting for factors like different rates of substitution between different nucleotides or amino acids, transition/transversion bias, and others.</li><li>Examples include the Kimura 2-parameter model and the Tamura-Nei model, which provide more sophisticated ways to estimate genetic distances by incorporating specific evolutionary assumptions.</li></ul></details><details><summary>4. <b>Maximum Likelihood and Bayesian Methods</b></summary><ul><li>These are more computationally intensive methods that use probabilistic models of sequence evolution.</li><li>They estimate the likelihood of observing the data given various possible evolutionary histories and can provide more accurate estimates of genetic distances.</li></ul></details><br><p>Each of these methods has its own strengths and limitations, and the choice of method often depends on the specifics of the data and the research question. Simple counting methods are straightforward but may underestimate distances, especially when sequences have diverged significantly. Corrected distance and model-based methods provide more accurate estimates by considering the complexities of molecular evolution, but they require more computational resources and deeper understanding of evolutionary models. Maximum likelihood and Bayesian methods are highly accurate but computationally demanding.</p><p>In practice, the choice of method is often a balance between the need for accuracy and the availability of computational resources, as well as the evolutionary characteristics of the organisms being studied.</p><h2 id="Different-Ways-to-Illustrate-the-Tree-By-GGTREE">Different Ways to Illustrate the Tree (By GGTREE)</h2><table><thead><tr><th style="text-align:center"><img src="https://yulab-smu.top/treedata-book/treedata_files/figure-html/layout-1.svg" alt="ggtree"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://yulab-smu.top/treedata-book/chapter4.html">© YuLab@SMU</a></td></tr></tbody></table><h2 id="Something-You’d-Like-to-Know-About-Phylogenetic-Trees-Chat4">Something You’d Like to Know About Phylogenetic Trees (Chat4)</h2><p>When working with phylogenetic trees, there are several key points and common misconceptions to be aware of:</p><details><summary>1. <b>Tree Topology Matters More Than Branch Length</b></summary>The branching pattern (topology) of the tree indicates the evolutionary relationships among the species or genes in the tree. However, unless explicitly stated, the length of the branches might not represent evolutionary time or genetic distance.</details><details><summary>2. <b>Branch Points (Nodes) Represent Common Ancestors</b></summary>Each node where branches diverge represents the most recent common ancestor of the groups branching off from that node.</details><details><summary>3. <b>Reading the Tree Correctly</b></summary>A common misunderstanding is the way to interpret the tree's layout. The tree should be read as a series of branching events, not as a left-to-right progression. The order of groups along the tips of the branches doesn't necessarily indicate any specific type of progression or superiority.</details><details><summary>4. <b>Phylogenetic Trees Are Hypothetical</b></summary>These trees are based on the best available data and the most accurate methods at the time. As new data emerge, the tree might be modified.</details><details><summary>5. <b>Rooted vs. Unrooted Trees</b></summary>Rooted trees have a single ancestral lineage (usually at the base) that serves as a common ancestor for all the entities in the tree. Unrooted trees do not show an ancestral root and are used to illustrate the relationships between different lineages without assuming their descent from a common ancestor.</details><details><summary>6. <b>Monophyletic, Paraphyletic, and Polyphyletic Groups</b></summary>Misunderstanding these terms can lead to confusion. Monophyletic groups include an ancestor and all its descendants, paraphyletic groups include an ancestor and some but not all descendants, and polyphyletic groups are characterized by members that do not share a recent common ancestor in the context of the tree.</details><details><summary>7. <b>Convergent Evolution Can Be Misleading</b></summary>Sometimes, unrelated species may appear closely related due to similar selective pressures rather than shared ancestry, a phenomenon known as convergent evolution.</details><details><summary>8. <b>Horizontal Gene Transfer</b></summary>Especially in bacterial phylogenetics, horizontal gene transfer can complicate the interpretation of evolutionary relationships.</details><br><p>Understanding these points can help in correctly interpreting phylogenetic trees and avoiding common misconceptions. It’s also important to remember that phylogenetics is a constantly evolving field, with new methods and data continually refining our understanding of evolutionary relationships.</p><h2 id="Beyond-the-Distance-Matrix-Chat4">Beyond the Distance Matrix (Chat4)</h2><p>Phylogenetic trees can also be constructed without using a distance matrix. The construction of phylogenetic trees can be broadly categorized into two main approaches: distance-based methods and character-based methods. While distance-based methods do rely on distance matrices, character-based methods do not. Here’s a brief overview of these approaches:</p><ol><li><p><strong>Distance-Based Methods</strong>: These methods, such as UPGMA (Unweighted Pair Group Method with Arithmetic Mean) and Neighbor-Joining (exp, <code>-QUICKTREE</code> from <code>clustalW</code>), <mark>rely on a distance matrix</mark> that represents the genetic distance (differences) between pairs of taxa. The matrix is used to construct a tree that represents these distances as accurately as possible.</p></li><li><p><strong>Character-Based Methods</strong>: These methods do not use a distance matrix. Instead, they directly analyze the character states (such as DNA, RNA, or protein sequences) of the taxa being studied. There are two primary types of character-based methods:</p><ul><li><p><strong>Maximum Parsimony</strong>: This method identifies the tree that requires the smallest number of evolutionary changes. It looks for the tree that explains the data with the least amount of complexity, without involving a distance matrix.</p></li><li><p><strong>Maximum Likelihood and Bayesian Methods</strong>: These are statistical methods that evaluate different possible phylogenetic trees and choose the tree that is most likely to have produced the observed set of data. These methods are based on explicit models of evolutionary change and do not rely on a pre-calculated distance matrix.</p></li></ul></li></ol><p>Each method has its advantages and limitations, and the choice of method can depend on the type of data available, the computational resources, and the specific objectives of the study. Character-based methods, especially those involving statistical approaches like Maximum Likelihood and Bayesian Inference, have become increasingly popular due to their ability to incorporate complex models of evolutionary change and handle large datasets effectively.</p><h2 id="The-Difference-Between-NJ-Tree-and-ML-Tree-Chat4">The Difference Between NJ-Tree and ML-Tree (Chat4)</h2><p>The popularity and suitability of the Neighbor-Joining (NJ) and Maximum Likelihood (ML) methods for constructing phylogenetic trees depend on the specific requirements and constraints of the research being conducted. Both methods have their advantages and limitations, and their appropriateness can vary based on factors like data complexity, computational resources, and the level of accuracy needed.</p><h3 id="Popularity">Popularity</h3><ol><li><p><strong>Neighbor-Joining (NJ)</strong>: <mark>Historically</mark>, NJ has been very popular, particularly in earlier studies, due to its computational efficiency. It’s well-suited for large datasets where quick, preliminary analyses are needed. NJ’s simplicity and speed made it a go-to method for many researchers, especially before the widespread availability of powerful computational resources.</p></li><li><p><strong>Maximum Likelihood (ML)</strong>: With the increase in computational power and the development of more sophisticated software, ML has gained substantial popularity, especially in more recent studies. It is often preferred for its ability to provide <mark>more accurate and statistically robust trees</mark>, especially for complex datasets.</p></li></ol><table><thead><tr><th>Feature</th><th>Neighbor-Joining (NJ)</th><th>Maximum Likelihood (ML)</th></tr></thead><tbody><tr><td><strong>Speed and Efficiency</strong></td><td>Fast and efficient, ideal for large datasets and quick analyses.</td><td>Slower and computationally intensive, especially with larger datasets.</td></tr><tr><td><strong>Accuracy</strong></td><td>Less accurate for complex evolutionary models; sensitive to rate variation and sampling errors.</td><td>More accurate and statistically robust across a wide range of datasets.</td></tr><tr><td><strong>Evolutionary Models</strong></td><td>Does not explicitly model evolutionary processes.</td><td>Incorporates explicit models of sequence evolution, handling varying rates of evolution better.</td></tr><tr><td><strong>Computational Resources</strong></td><td>Less demanding, suitable for limited computational resources.</td><td>Requires significant computational power for large and complex datasets.</td></tr><tr><td><strong>Statistical Support</strong></td><td>Limited statistical measures for tree support.</td><td>Provides robust statistical measures (like bootstrap values) for tree support.</td></tr><tr><td><strong>Use Case</strong></td><td>Suitable for preliminary or rapid analyses when computational resources are limited.</td><td>Preferred for detailed, accurate phylogenetic analyses where computational resources are available.</td></tr><tr><td><strong>Complexity and Understanding</strong></td><td>Simpler to understand and use.</td><td>Requires a good understanding of evolutionary models and statistical methods.</td></tr></tbody></table><h3 id="Conclusion">Conclusion</h3><p>The choice between NJ and ML largely depends on the specific requirements of your phylogenetic analysis. For preliminary or rapid analyses with large datasets, NJ remains popular due to its speed. However, for in-depth studies where accuracy and model-based statistical rigor are crucial, ML is often considered superior, albeit at the cost of greater computational demand. With ongoing advancements in computational methods and resources, ML is becoming increasingly accessible and popular in phylogenetic studies.</p><h2 id="Maximum-Likelihood">Maximum Likelihood</h2><p>Maximum Likelihood (ML) is a statistical method used in the construction of phylogenetic trees, which represent the evolutionary relationships among various species or genetic sequences. This method is based on the principle of finding the tree topology (i.e., the arrangement of branches and nodes) that has the highest probability of producing the observed set of genetic data. Here’s a simplified explanation of how it works:</p><ol><li><p><strong>Model of Sequence Evolution</strong>: ML requires a model of sequence evolution. This model includes parameters such as the rates of different types of mutations (e.g., transitions and transversions in nucleotide sequences), the frequency of each nucleotide or amino acid, and potentially other factors like the rate at which different parts of the sequence evolve. These models attempt to approximate the real biological processes that lead to changes in genetic sequences over time.</p></li><li><p><strong>Tree Topologies</strong>: The algorithm considers different possible tree topologies. A topology is a specific arrangement of species or sequences on a tree, indicating how they are related to each other.</p></li><li><p><strong>Calculating Likelihoods</strong>: For each tree topology, the likelihood that the observed data (genetic sequences of the species or taxa being studied) would evolve according to the specified model is calculated. This involves complex computations where the algorithm assesses the probability of changes occurring along the branches of the tree to result in the observed sequences at the tree’s tips (leaves).</p></li><li><p><strong>Comparing Trees</strong>: The likelihoods of different tree topologies are compared. The tree with the highest likelihood is considered the best estimate of the true evolutionary relationships among the sequences. This is because, under the chosen model, this tree would be the most likely to produce the observed data.</p></li><li><p><strong>Optimization and Searching</strong>: Because there are usually an extraordinarily large number of possible tree topologies (increasing exponentially with the number of sequences), it’s impractical to evaluate every possible tree. Therefore, heuristic algorithms are used to search tree space efficiently, focusing on those areas where higher likelihood trees are more likely to be found.</p></li><li><p><strong>Statistical Testing</strong>: Often, statistical methods such as bootstrap analysis are used to test the reliability of the tree. This involves resampling the data and recalculating trees to see how often certain groupings appear, providing a measure of confidence in the tree’s branches.</p></li></ol><p>Maximum Likelihood is favored for its statistical rigor and its ability to provide a clear criterion (likelihood) for choosing among trees. However, it is computationally intensive, especially for large datasets, and the results can be sensitive to the choice of the evolutionary model. Despite these challenges, ML remains a popular and powerful method in phylogenetic analysis.</p><h3 id="A-Simple-Practice">A Simple Practice</h3><p>In this practice, we generated genetic data for two species and their common ancestor. We then used the Jukes-Cantor model to calculate the likelihood of the observed sequences given a tree topology and a mutation rate. Here’s a summary of the process and results:</p><ul><li>Generated Data: We created random genetic sequences for a common ancestor and two descendant species.</li><li>Jukes-Cantor Model: This model was used to estimate the likelihood of one sequence evolving into another under a uniform mutation rate.</li><li>Initial Likelihood Calculation: For the given tree topology (where the common ancestor is the parent of both species), we calculated the likelihood of this tree using a mutation rate of 0.1. The likelihood was found to be approximately 20.46.</li><li>Optimization: We used an optimization algorithm to find the mutation rate that maximizes the likelihood of the observed data given the tree structure. The optimal mutation rate was found to be 1.0.</li><li>Optimized Likelihood: Recalculating the likelihood with the optimized mutation rate, we obtained an improved likelihood of approximately 7.05.</li></ul><p>This demonstration shows how Maximum Likelihood is used in phylogenetics to find the most likely tree structure and parameters (like mutation rate) that explain the observed genetic data. In real-world scenarios, the data and models are much more complex, and the computations are more intensive, but the underlying principles remain the same. ​</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Corrected implementation for demonstrating Maximum Likelihood in phylogenetics</span><br><br><span class="hljs-comment"># Generate a simple example dataset with direct ancestor-descendant relationships</span><br>np.random.seed(<span class="hljs-number">0</span>)<br><span class="hljs-comment"># Assume we have two species and their common ancestor</span><br>data = &#123;<br>    <span class="hljs-string">&quot;Common_Ancestor&quot;</span>: np.random.choice([<span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;T&#x27;</span>, <span class="hljs-string">&#x27;G&#x27;</span>, <span class="hljs-string">&#x27;C&#x27;</span>], <span class="hljs-number">10</span>),<br>    <span class="hljs-string">&quot;Species_A&quot;</span>: np.random.choice([<span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;T&#x27;</span>, <span class="hljs-string">&#x27;G&#x27;</span>, <span class="hljs-string">&#x27;C&#x27;</span>], <span class="hljs-number">10</span>),<br>    <span class="hljs-string">&quot;Species_B&quot;</span>: np.random.choice([<span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;T&#x27;</span>, <span class="hljs-string">&#x27;G&#x27;</span>, <span class="hljs-string">&#x27;C&#x27;</span>], <span class="hljs-number">10</span>)<br>&#125;<br>df = pd.DataFrame(data)<br>print(<span class="hljs-string">&quot;Generated Genetic Data:\n&quot;</span>, df)<br><br><span class="hljs-comment"># Define a simple model of sequence evolution</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">jukes_cantor_model</span>(<span class="hljs-params">seq1, seq2, mu</span>):</span><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Jukes-Cantor model to calculate the likelihood of seq2 evolving from seq1</span><br><span class="hljs-string">    under a uniform mutation rate mu.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    diff = <span class="hljs-built_in">sum</span>(c1 != c2 <span class="hljs-keyword">for</span> c1, c2 <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(seq1, seq2))<br>    same = <span class="hljs-built_in">len</span>(seq1) - diff<br>    p_diff = <span class="hljs-number">3</span>/<span class="hljs-number">4</span> * (<span class="hljs-number">1</span> - np.exp(-<span class="hljs-number">4</span>/<span class="hljs-number">3</span> * mu))<br>    p_same = <span class="hljs-number">1</span>/<span class="hljs-number">4</span> + <span class="hljs-number">1</span>/<span class="hljs-number">4</span> * np.exp(-<span class="hljs-number">4</span>/<span class="hljs-number">3</span> * mu)<br><br>    likelihood = (p_diff ** diff) * (p_same ** same)<br>    <span class="hljs-keyword">return</span> likelihood<br><br><span class="hljs-comment"># Function to calculate the likelihood of a tree given the data</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">tree_likelihood</span>(<span class="hljs-params">tree, data, mu</span>):</span><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Calculate the likelihood of a given tree topology.</span><br><span class="hljs-string">    The tree is represented as a dictionary where keys are nodes and values are the sequences.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    likelihood = <span class="hljs-number">1.0</span><br>    <span class="hljs-keyword">for</span> parent, child <span class="hljs-keyword">in</span> tree.items():<br>        parent_seq = data[parent]<br>        child_seq = data[child]<br>        likelihood *= jukes_cantor_model(parent_seq, child_seq, mu)<br>    <span class="hljs-keyword">return</span> -log(likelihood)  <span class="hljs-comment"># negative log-likelihood for optimization</span><br><br><span class="hljs-comment"># Example tree topology (parent: child)</span><br>tree_example = &#123;<br>    <span class="hljs-string">&quot;Common_Ancestor&quot;</span>: <span class="hljs-string">&quot;Species_A&quot;</span>,<br>    <span class="hljs-string">&quot;Common_Ancestor&quot;</span>: <span class="hljs-string">&quot;Species_B&quot;</span>,<br>&#125;<br><br><span class="hljs-comment"># Assume a mutation rate (mu)</span><br>mu = <span class="hljs-number">0.1</span><br><br><span class="hljs-comment"># Calculate the likelihood of this tree</span><br>likelihood = tree_likelihood(tree_example, df, mu)<br>print(<span class="hljs-string">&quot;\nLikelihood of the tree:&quot;</span>, likelihood)<br><br><span class="hljs-comment"># Now we will use optimization to find the mutation rate that maximizes the likelihood</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">optimize_mu</span>(<span class="hljs-params">mu, tree, data</span>):</span><br>    <span class="hljs-keyword">return</span> tree_likelihood(tree, data, mu)<br><br>result = minimize(optimize_mu, x0=mu, args=(tree_example, df), bounds=[(<span class="hljs-number">0.001</span>, <span class="hljs-number">1</span>)])<br>optimal_mu = result.x[<span class="hljs-number">0</span>]<br>print(<span class="hljs-string">&quot;\nOptimal mutation rate:&quot;</span>, optimal_mu)<br><br><span class="hljs-comment"># Recalculate the likelihood with the optimized mutation rate</span><br>optimized_likelihood = tree_likelihood(tree_example, df, optimal_mu)<br>print(<span class="hljs-string">&quot;\nOptimized likelihood of the tree:&quot;</span>, optimized_likelihood)<br></code></pre></td></tr></table></figure></div><pre>Generated Genetic Data:   Common_Ancestor Species_A Species_B0               A         T         G1               C         G         C2               T         A         C3               A         C         G4               C         G         A5               C         A         T6               C         A         T7               C         A         T8               T         G         T9               C         T         ALikelihood of the tree: 20.463275567320334Optimal mutation rate: 1.0Optimized likelihood of the tree: 7.05394379820434</pre><h3 id="Things-You’d-Like-to-Know">Things You’d Like to Know</h3><ol><li><p><strong>Pairwise Comparisons</strong>: In the ML approach, the focus is <mark>not typically on pairwise comparisons between sequences</mark> (as it is in methods like distance matrix or neighbor-joining). Instead, ML <mark>evaluates the likelihood of entire tree topologies</mark>. It looks at how likely it is for a given tree structure, with its branching pattern and lengths, to have produced the observed set of genetic sequences under a specific evolutionary model.</p></li><li><p><strong>Likelihood Calculations</strong>: For each possible tree topology, ML calculates the likelihood that the proposed tree would result in the observed data (e.g., DNA, RNA, or protein sequences). This calculation involves estimating the probability of changes in the sequences along each branch of the tree. The likelihood depends on both the tree topology (how the branches are arranged) and the model parameters (like mutation rates).</p></li><li><p><strong>Optimization</strong>: The <mark>goal</mark> is to find the tree topology (and associated model parameters) that <mark>maximizes the likelihood</mark>. Due to the vast number of possible trees, especially with larger datasets, <mark>heuristic search</mark> algorithms are used to navigate the space of possible trees efficiently.</p></li><li><p><strong>Likelihood Matrix</strong>: Unlike methods that rely on a distance matrix, <mark>ML doesn’t typically produce a matrix of pairwise likelihoods</mark>. Instead, it directly evaluates the likelihood of entire tree topologies.</p></li><li><p><strong>Resulting Tree</strong>: The end result of an ML analysis is <mark>a single tree</mark> (or sometimes a set of trees) that has the highest likelihood given the data and the chosen model. This tree represents the estimated evolutionary relationships among the sequences.</p></li><li><p><strong>Dendrogram/Phylogenetic Tree</strong>: The final output is a phylogenetic tree (often visualized as a dendrogram) that represents the <mark>hypothesized evolutionary relationships</mark> among the species or sequences analyzed. This tree is based on the topology that provided the highest likelihood.</p></li></ol><p>In summary, while ML involves complex calculations involving the entire tree, it doesn’t use a pairwise likelihood matrix in the same way that distance-based methods use a distance matrix. The primary focus of ML is on evaluating and comparing the likelihoods of different tree topologies to find the one that best explains the observed data under a given evolutionary model.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Phylogenetic Tree</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="others" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/others/"/>
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="Biology" scheme="https://karobben.github.io/tags/Biology/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://karobben.github.io/2023/12/13/Bioinfor/cdhit/"/>
    <id>https://karobben.github.io/2023/12/13/Bioinfor/cdhit/</id>
    <published>2023-12-13T21:21:40.000Z</published>
    <updated>2023-12-14T17:04:35.763Z</updated>
    
    <content type="html"><![CDATA[<h2 id="CD-HIT">CD-HIT</h2><p>Documentation: <a href="https://www.bioinformatics.org/cd-hit/cd-hit-user-guide">CD-HIT</a></p><p>CD-HIT (Cluster Database at High Identity with Tolerance) is a widely used bioinformatics tool designed to cluster biological sequences (such as DNA, RNA, or proteins) to reduce sequence redundancy and improve the efficiency of other sequence analyses. It’s particularly useful when dealing with large datasets, such as those frequently encountered in genomics and proteomics studies.</p><p>Here are some key features and uses of CD-HIT:</p><ol><li><p><strong>Sequence Clustering</strong>: CD-HIT efficiently clusters similar sequences together based on a user-defined similarity threshold. For example, if you set a threshold of 90%, the tool will group sequences that are 90% identical into the same cluster.</p></li><li><p><strong>Reduction of Redundancy</strong>: By clustering similar sequences, CD-HIT helps in reducing redundancy in the dataset. This is particularly important when creating sequence databases or when analyzing large datasets where many sequences may be very similar or nearly identical.</p></li><li><p><strong>Speed and Efficiency</strong>: CD-HIT is known for its speed and low memory usage, making it suitable for handling very large datasets that are common in modern high-throughput sequencing projects.</p></li><li><p><strong>Multiple Applications</strong>: It’s used in a variety of applications, such as creating non-redundant sequence databases, preparing datasets for further analyses (like phylogenetic studies), or in metagenomics for analyzing diversity and similarity of species.</p></li><li><p><strong>Customizable Parameters</strong>: Users can customize several parameters, such as the identity threshold for clustering, the word size for initial comparisons, and memory usage, allowing for flexibility depending on the specific requirements of the data or the analysis.</p></li><li><p><strong>Output Files</strong>: CD-HIT generates two main types of output files - one containing the clustered sequences and another (<code>.clstr</code> file) detailing the composition of each cluster.</p></li></ol><p>CD-HIT is a command-line tool, which means it is run from a terminal or command prompt and offers great flexibility in scripting and automation within bioinformatics pipelines. The tool is an essential part of the toolkit for biologists and bioinformaticians dealing with large-scale sequence data.</p><h2 id="Example">Example</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">cd-hit -i Trunked.fa -o cdhit/Trunked_<span class="hljs-variable">$x</span>.fa -c <span class="hljs-variable">$x</span> -M 32000 -d 0 -T 8 -n 5 -aL 0.8 -s 0.95  -uS 0.2  -sc 1 -sf 1<br></code></pre></td></tr></table></figure></div><p>The command you’ve provided is for CD-HIT, a widely used bioinformatics tool for clustering and comparing protein or nucleotide sequences. CD-HIT helps to significantly reduce the redundancy of large datasets by clustering similar sequences together based on a specified sequence identity threshold. This is particularly useful in tasks like constructing databases or preparing datasets for other analyses where redundancy might be an issue.</p><p>Let’s break down the components of your command:</p><ul><li><p><code>cd-hit</code>: This invokes the CD-HIT program.</p></li><li><p><code>-i Trunked.fa</code>: The <code>-i</code> option specifies the input file. Here, the input file is <code>Trunked.fa</code>, which likely contains a collection of nucleotide or protein sequences in FASTA format.</p></li><li><p><code>-o cdhit/Trunked_$x.fa</code>: The <code>-o</code> option specifies the output file. This command will create an output file in the <code>cdhit</code> directory with a name based on the value of the variable <code>$x</code>. The <code>$x</code> seems to be a shell variable that would be replaced with its value when the command runs.</p></li><li><p><code>-c $x</code>: The <code>-c</code> option sets the sequence identity threshold. Sequences are clustered together if they are similar to each other above this threshold. The exact value is determined by the variable <code>$x</code>.</p></li><li><p><code>-M 32000</code>: This sets the maximum available memory (in MB). <code>32000</code> here means 32,000 MB, or 32 GB of RAM.</p></li><li><p><code>-d 0</code>: The <code>-d</code> option is for the description length to show in the <code>.clstr</code> output file. <code>0</code> means it will show the full sequence defline.</p></li><li><p><code>-T 8</code>: This specifies the number of threads to use. <code>8</code> means the program will run on 8 threads, enabling parallel computation for faster processing.</p></li><li><p><code>-n 5</code>: For protein sequences, this sets the word length for the initial match. <code>5</code> is typically used for thresholds between 0.7 and 0.8.</p></li><li><p><code>-aL 0.8</code>: This sets the alignment coverage for the longer sequence. <code>0.8</code> means 80% of the longer sequence must be covered in the alignment.</p></li><li><p><code>-s 0.95</code>: This sets the alignment coverage for the shorter sequence. <code>0.95</code> means 95% of the shorter sequence must be included in the alignment.</p></li><li><p><code>-uS 0.2</code>: This specifies the maximum unmatched percentage of the shorter sequence. <code>0.2</code> means up to 20% of the shorter sequence can be unmatched.</p></li><li><p><code>-sc 1</code>: This option, when set to <code>1</code>, sorts clusters by decreasing size.</p></li><li><p><code>-sf 1</code>: This option, when set to <code>1</code>, sorts fasta sequence by cluster size.</p></li></ul><p>Each of these options tailors the behavior of CD-HIT to your specific requirements, influencing how sequences are clustered and how the output is formatted and organized. The use of shell variables (like <code>$x</code>) suggests that this command is part of a script where the value of <code>$x</code> is dynamically set, allowing for flexible application of the command with different parameters.</p><h2 id="Read-the-cd-hit-Result-as-pandas-dataframe">Read the cd-hit Result as pandas dataframe</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br><span class="hljs-comment"># Initialize lists to store data</span><br>sequence_names = []<br>cluster_ids = []<br><br><span class="hljs-comment"># Open the .clstr file and parse it</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;your_file.clstr&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> file:<br>    current_cluster_id = <span class="hljs-literal">None</span><br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> file:<br>        <span class="hljs-keyword">if</span> line.startswith(<span class="hljs-string">&#x27;&gt;Cluster &#x27;</span>):<br>            current_cluster_id = line.split()[<span class="hljs-number">1</span>]<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># Extracting sequence name</span><br>            parts = line.split()<br>            seq_name = parts[<span class="hljs-number">2</span>].strip(<span class="hljs-string">&#x27;&gt;&#x27;</span>).split(<span class="hljs-string">&#x27;...&#x27;</span>)[<span class="hljs-number">0</span>]<br>            sequence_names.append(seq_name)<br>            cluster_ids.append(current_cluster_id)<br><br><span class="hljs-comment"># Create a DataFrame</span><br>df = pd.DataFrame(&#123;<span class="hljs-string">&#x27;Sequence Name&#x27;</span>: sequence_names, <span class="hljs-string">&#x27;Cluster ID&#x27;</span>: cluster_ids&#125;)<br><br><span class="hljs-comment"># Display the DataFrame</span><br>print(df)<br></code></pre></td></tr></table></figure></div><h2 id="Trouble-Shooting">Trouble Shooting</h2><pre>Fatal Error:Too low cluster threshold for the word length.Increase the threshold or the tolerance, or decrease the word length.Program halted !!</pre><p>The error message you’re encountering, “Fatal Error: Too low cluster threshold for the word length. Increase the threshold or the tolerance, or decrease the word length. Program halted !!”, indicates a conflict between the parameters you’ve set in CD-HIT, particularly relating to the sequence identity threshold and the word length.</p><p>In CD-HIT, the “word length” refers to the length of the initial exact match that the algorithm looks for when comparing sequences. The “cluster threshold” is the percentage similarity required for two sequences to be clustered together. When the cluster threshold is set too low relative to the word length, the program cannot effectively perform the initial sequence matching, leading to this error.</p><p>To resolve this issue, you can:</p><ol><li><p><strong>Increase the Threshold</strong>: Increase the sequence identity threshold (<code>-c</code> parameter). If it’s currently very low, increasing it will make the clustering less stringent. For instance, if you have set <code>-c 0.6</code> (60% identity), try increasing it to 0.7 or higher.</p></li><li><p><strong>Decrease the Word Length</strong>: Decrease the word length (<code>-n</code> parameter). A lower word length means the program will look for shorter exact matches in the initial step, which can be more tolerant of low similarity thresholds. However, be cautious, as too low a word length might make the process slower and less efficient.</p></li><li><p><strong>Adjust Tolerance</strong>: If your dataset includes very diverse sequences and you need to maintain a low threshold, you might have to adjust other parameters to balance the sensitivity and specificity of the clustering.</p></li></ol><p>Remember that the appropriate values for these parameters can vary depending on your specific dataset and the objectives of your analysis. It might require some experimentation to find the right balance for your needs.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">CD-HIT, a protein/nuclear</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Software" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Software/"/>
    
    <category term="more" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Software/more/"/>
    
    
    <category term="Cluster" scheme="https://karobben.github.io/tags/Cluster/"/>
    
    <category term="Software" scheme="https://karobben.github.io/tags/Software/"/>
    
    <category term="NGS" scheme="https://karobben.github.io/tags/NGS/"/>
    
  </entry>
  
  <entry>
    <title>Extract Information from PDB and Visualize with Pyvista</title>
    <link href="https://karobben.github.io/2023/12/08/Bioinfor/pdbpyvista/"/>
    <id>https://karobben.github.io/2023/12/08/Bioinfor/pdbpyvista/</id>
    <published>2023-12-08T15:26:56.000Z</published>
    <updated>2023-12-19T22:56:00.935Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Quick-Codes">Quick Codes</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> Bio.PDB <span class="hljs-keyword">import</span> PDBParser<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pyvista <span class="hljs-keyword">as</span> pv<br><br><span class="hljs-comment"># Parse the PDB file</span><br>parser = PDBParser()<br>structure = parser.get_structure(<span class="hljs-string">&quot;1nnc&quot;</span>, <span class="hljs-string">&quot;PDB/1nnc.pdb&quot;</span>)<br><br><span class="hljs-comment"># Extract 3D coordinates and print atom names</span><br>points = []<br><span class="hljs-keyword">for</span> model <span class="hljs-keyword">in</span> structure:<br>    <span class="hljs-keyword">for</span> chain <span class="hljs-keyword">in</span> model:<br>        <span class="hljs-keyword">for</span> residue <span class="hljs-keyword">in</span> chain:<br>            <span class="hljs-keyword">for</span> atom <span class="hljs-keyword">in</span> residue:<br>                points.append(atom.get_coord())<br>                print(<span class="hljs-string">f&quot;Atom Name: <span class="hljs-subst">&#123;atom.get_name()&#125;</span>, Coordinates: <span class="hljs-subst">&#123;atom.get_coord()&#125;</span>&quot;</span>)<br><br><span class="hljs-comment"># Convert to a numpy array</span><br>points_array = np.array(points)<br><br><span class="hljs-comment"># Create a PyVista point cloud</span><br>point_cloud = pv.PolyData(points_array)<br>point_cloud.plot(point_size=<span class="hljs-number">5</span>, color=<span class="hljs-string">&#x27;red&#x27;</span>)<br></code></pre></td></tr></table></figure></div><p>In this updated script:</p><ul><li>The <code>print</code> statement within the innermost loop (<code>for atom in residue:</code>) prints the name of each atom and its coordinates.</li><li><code>atom.get_name()</code> retrieves the name of the atom.</li><li><code>atom.get_coord()</code> retrieves the 3D coordinates of the atom.</li></ul><p>Remember to replace <code>&quot;protein_id&quot;</code> and <code>&quot;path_to_your_pdb_file.pdb&quot;</code> with the appropriate identifiers and file path for your PDB file.</p><p>This script will print the name and coordinates of each atom in the console and plot the points in 3D using PyVista. You can further modify this script to include more details or to format the output as per your requirement.</p><h2 id="The-Name-of-Atoms">The Name of Atoms</h2><p>Certainly! In the context of a Protein Data Bank (PDB) file, atoms within proteins are named according to standard conventions that reflect their chemical properties and their position within the protein structure. Here’s a breakdown of what different atom names typically signify:</p><ol><li><p><strong>Element Symbol</strong>: The first part of an atom’s name usually represents its element symbol from the periodic table. For example, “C” stands for Carbon, “N” for Nitrogen, “O” for Oxygen, “S” for Sulfur, and so on.</p></li><li><p><strong>Amino Acid Context</strong>: Atoms are part of amino acids in proteins. Each amino acid has a specific set of atoms. For instance, in the amino acid glycine, you might find atoms named “CA” (alpha carbon), “N” (amino nitrogen), “O” (carbonyl oxygen), etc.</p></li><li><p><strong>Position in Amino Acid</strong>:</p><ul><li><strong>Alpha Carbon (CA)</strong>: This is the central carbon atom to which the amino group (NH2), carboxyl group (COOH), hydrogen (H), and the R group (side chain) are attached in amino acids.</li><li><strong>Backbone Atoms</strong>: These include “N” (the amide nitrogen), “CA” (alpha carbon), and “C” (the carbonyl carbon). These atoms form the backbone of the protein chain.</li><li><strong>Side Chain Atoms</strong>: Atoms in the side chain (or R group) of an amino acid are denoted by different names depending on their position and chemical nature. For example, in the amino acid lysine, you might see names like “CG”, “CD”, “CE” - these are carbon atoms in the side chain, labeled in order from the alpha carbon.</li></ul></li><li><p><strong>Hydrogen Atoms</strong>: These are often denoted by “H” followed by additional characters to specify their position. For example, “HA” might be a hydrogen attached to the alpha carbon.</p></li><li><p><strong>Prosthetic Groups or Non-standard Residues</strong>: In addition to standard amino acids, proteins may have non-standard residues or prosthetic groups like heme in hemoglobin. These will have their own unique naming conventions based on their molecular structure.</p></li><li><p><strong>Alternate Locations</strong>: Sometimes an atom can occupy multiple positions due to structural flexibility. These are often indicated by an additional character like “A” or “B” following the atom name.</p></li></ol><p>Understanding these naming conventions can help in interpreting the structure and function of the protein, as the 3D arrangement of these atoms determines the protein’s shape and reactive sites. In practical use, this information is crucial for tasks like modeling protein-ligand interactions, understanding enzyme active sites, or studying protein folding and dynamics.</p><h2 id="Show-the-Alpha-Carbon-Only">Show the Alpha Carbon Only</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> Bio.PDB <span class="hljs-keyword">import</span> PDBParser<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pyvista <span class="hljs-keyword">as</span> pv<br><br><span class="hljs-comment"># Parse the PDB file</span><br>parser = PDBParser()<br>structure = parser.get_structure(<span class="hljs-string">&quot;Mos99&quot;</span>, <span class="hljs-string">&quot;PDB/Mos99_WT_NA_monomer.pdb&quot;</span>)<br><br><span class="hljs-comment"># Extract 3D coordinates and print atom names</span><br>points = []<br><span class="hljs-keyword">for</span> model <span class="hljs-keyword">in</span> structure:<br>    <span class="hljs-keyword">for</span> chain <span class="hljs-keyword">in</span> model:<br>        <span class="hljs-keyword">for</span> residue <span class="hljs-keyword">in</span> chain:<br>            <span class="hljs-keyword">for</span> atom <span class="hljs-keyword">in</span> residue:<br>              <span class="hljs-keyword">if</span> atom.get_name() == <span class="hljs-string">&quot;CA&quot;</span>:<br>                points.append(atom.get_coord())<br>                <span class="hljs-comment">#print(f&quot;Atom Name: &#123;atom.get_name()&#125;, Coordinates: &#123;atom.get_coord()&#125;&quot;)</span><br><br><span class="hljs-comment"># Convert to a numpy array</span><br>points_array = np.array(points)<br><br><span class="hljs-comment"># Create a PyVista point cloud</span><br>point_cloud = pv.PolyData(points_array)<br>point_cloud.plot(point_size=<span class="hljs-number">5</span>, color=<span class="hljs-string">&#x27;red&#x27;</span>)<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://imgur.com/bdjsps4.png" alt=""></th></tr></thead><tbody></tbody></table><h2 id="Convert-it-into-Mesh">Convert it into Mesh</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># select the dots on the surface</span><br><span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> NearestNeighbors<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><br><span class="hljs-comment"># Assuming &#x27;points_array&#x27; is your numpy array of 3D points</span><br>points = points_array.copy()<br><br><span class="hljs-comment"># Use KNN to find the nearest neighbors</span><br>nbrs = NearestNeighbors(n_neighbors=<span class="hljs-number">10</span>).fit(points)<br>distances, indices = nbrs.kneighbors(points)<br><br><span class="hljs-comment"># Determine a threshold distance for surface points</span><br>threshold_distance = np.percentile(distances, <span class="hljs-number">90</span>)  <span class="hljs-comment"># adjust as needed</span><br><br><span class="hljs-comment"># Identify surface points</span><br>surface_points = points[np.<span class="hljs-built_in">max</span>(distances, axis=<span class="hljs-number">1</span>) &gt; threshold_distance]<br><br>point_cloud = pv.PolyData(surface_points)<br><span class="hljs-comment">#point_cloud = pv.PolyData(points_array)</span><br>volume = point_cloud.delaunay_3d(alpha = <span class="hljs-number">4</span>)<br>shell = volume.extract_geometry()<br>shell.plot(show_edges=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://imgur.com/QbP7pRg.png" alt="Mesh Surface of Alpha Carbon"></th></tr></thead><tbody></tbody></table><h2 id="Visualize-a-Single-Amino-Acid">Visualize a Single Amino Acid</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">chain_id = <span class="hljs-string">&#x27;A&#x27;</span>  <span class="hljs-comment"># Replace with the relevant chain ID</span><br>residue_number = <span class="hljs-number">100</span>  <span class="hljs-comment"># Replace with the residue number of the amino acid</span><br><br><span class="hljs-comment"># Extract coordinates</span><br>amino_acid_data = []<br><span class="hljs-keyword">for</span> model <span class="hljs-keyword">in</span> structure:<br>    <span class="hljs-keyword">for</span> chain <span class="hljs-keyword">in</span> model:<br>        <span class="hljs-keyword">if</span> chain.get_id() == chain_id:<br>            <span class="hljs-keyword">for</span> residue <span class="hljs-keyword">in</span> chain:<br>                <span class="hljs-keyword">if</span> residue.get_id()[<span class="hljs-number">1</span>] == residue_number:<br>                    <span class="hljs-keyword">for</span> atom <span class="hljs-keyword">in</span> residue:<br>                        amino_acid_data.append((atom.get_coord(), atom.element, atom.get_id()))<br>                    tmp = residue<br>                    print(residue.get_full_id(), residue.get_resname())<br><br><span class="hljs-comment"># Separate coordinates, elements, and atom names</span><br>coordinates, elements, atom_names = <span class="hljs-built_in">zip</span>(*amino_acid_data)<br>coordinates = np.array(coordinates)<br><br><br><span class="hljs-comment"># find bounds:</span><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">infer_bonds</span>(<span class="hljs-params">coords, max_bond_length=<span class="hljs-number">2</span></span>):</span><br>    bonds = []<br>    num_atoms = <span class="hljs-built_in">len</span>(coords)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_atoms):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(i+<span class="hljs-number">1</span>, num_atoms):<br>            <span class="hljs-keyword">if</span> np.linalg.norm(coords[i] - coords[j]) &lt; max_bond_length:<br>                bonds.append((i, j))<br>    <span class="hljs-keyword">return</span> bonds<br><br><span class="hljs-comment"># Infer bonds</span><br>bonds = infer_bonds(coordinates)<br><br><br><span class="hljs-comment"># Plot all</span><br><span class="hljs-comment"># Map elements to RGB colors (customize this as needed)</span><br>element_colors = &#123;<br>    <span class="hljs-string">&quot;C&quot;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],  <span class="hljs-comment"># Carbon (black)</span><br>    <span class="hljs-string">&quot;N&quot;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">255</span>],  <span class="hljs-comment"># Nitrogen (blue)</span><br>    <span class="hljs-string">&quot;O&quot;</span>: [<span class="hljs-number">255</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],  <span class="hljs-comment"># Oxygen (red)</span><br>    <span class="hljs-string">&quot;S&quot;</span>: [<span class="hljs-number">255</span>, <span class="hljs-number">255</span>, <span class="hljs-number">0</span>],  <span class="hljs-comment"># Sulfur (yellow)</span><br>    <span class="hljs-comment"># Add more elements and colors as required</span><br>&#125;<br><br><span class="hljs-comment"># Create an array to store RGB colors</span><br>rgb_colors = np.array([element_colors.get(element, [<span class="hljs-number">125</span>, <span class="hljs-number">125</span>, <span class="hljs-number">125</span>]) <span class="hljs-keyword">for</span> element <span class="hljs-keyword">in</span> elements])  <span class="hljs-comment"># Default grey</span><br><br><span class="hljs-comment"># Create a PyVista plotter</span><br>plotter = pv.Plotter()<br><br><span class="hljs-comment"># Plot atoms</span><br><span class="hljs-keyword">for</span> coord, color <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(coordinates, rgb_colors):<br>    sphere = pv.Sphere(radius=<span class="hljs-number">0.5</span>, center=coord)<br>    plotter.add_mesh(sphere, color=color)<br><br><span class="hljs-comment"># Plot bonds</span><br><span class="hljs-keyword">for</span> bond <span class="hljs-keyword">in</span> bonds:<br>    start, end = coordinates[bond[<span class="hljs-number">0</span>]], coordinates[bond[<span class="hljs-number">1</span>]]<br>    line = pv.Line(start, end)<br>    plotter.add_mesh(line, color=<span class="hljs-string">&#x27;grey&#x27;</span>, line_width=<span class="hljs-number">3</span>)<br><br><span class="hljs-comment"># Show plot</span><br>plotter.show()<br></code></pre></td></tr></table></figure></div><p><img src="https://imgur.com/E3f8WPj.png" alt=""></p><p>In this case, in the atom_names:</p><ul><li>CA: alpha carbon</li><li>C: the carbon from C<sub>α</sub>-COOH</li><li>N: The N from C<sub>α</sub>-NH<sub>3</sub></li></ul><p>rest of atoms are coming from side chain.</p><h2 id="Turn-IT-into-Dictionary">Turn IT into Dictionary</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">Protein_dic = &#123;&#125;<br><span class="hljs-keyword">for</span> model <span class="hljs-keyword">in</span> structure:<br>  <span class="hljs-keyword">for</span> chain <span class="hljs-keyword">in</span> model:<br>    chain_dic = &#123;&#125; <br>    <span class="hljs-keyword">for</span> residue <span class="hljs-keyword">in</span> chain:<br>      chain_dic.update(&#123;residue.get_id()[<span class="hljs-number">1</span>]: residue&#125;)<br>    Protein_dic.update(&#123;chain.get_id(): chain_dic&#125;)<br></code></pre></td></tr></table></figure></div><h2 id="Check-the-Adjacent-Side-Chain-by-Side-Chain">Check the Adjacent Side Chain by Side Chain</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">Get_atom</span>(<span class="hljs-params">Res</span>):</span><br>  R = []<br>  <span class="hljs-keyword">for</span> atom <span class="hljs-keyword">in</span> Res:<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(Res) == <span class="hljs-number">4</span>:<br>      R += [atom.get_coord()]<br>    <span class="hljs-keyword">else</span>:      <br>      <span class="hljs-keyword">if</span> atom.get_id() <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;N&#x27;</span>, <span class="hljs-string">&#x27;CA&#x27;</span>, <span class="hljs-string">&quot;C&quot;</span>, <span class="hljs-string">&quot;O&quot;</span>]:<br>        R += [atom.get_coord()]<br>  R = np.array(R)<br>  <span class="hljs-keyword">return</span> R<br><br>AA_list = [<span class="hljs-string">&#x27;ALA&#x27;</span>, <span class="hljs-string">&#x27;ARG&#x27;</span>, <span class="hljs-string">&#x27;ASN&#x27;</span>, <span class="hljs-string">&#x27;ASP&#x27;</span>, <span class="hljs-string">&#x27;CYS&#x27;</span>, <span class="hljs-string">&#x27;GLN&#x27;</span>, <span class="hljs-string">&#x27;GLU&#x27;</span>, <span class="hljs-string">&#x27;GLY&#x27;</span>, <span class="hljs-string">&#x27;HIS&#x27;</span>, <span class="hljs-string">&#x27;ILE&#x27;</span>, <span class="hljs-string">&#x27;LEU&#x27;</span>, <span class="hljs-string">&#x27;LYS&#x27;</span>, <span class="hljs-string">&#x27;MET&#x27;</span>, <span class="hljs-string">&#x27;PHE&#x27;</span>, <span class="hljs-string">&#x27;PRO&#x27;</span>, <span class="hljs-string">&#x27;SER&#x27;</span>, <span class="hljs-string">&#x27;THR&#x27;</span>, <span class="hljs-string">&#x27;TRP&#x27;</span>, <span class="hljs-string">&#x27;TYR&#x27;</span>, <span class="hljs-string">&#x27;VAL&#x27;</span>]<br><br>Residues = []<br><span class="hljs-keyword">for</span> chain <span class="hljs-keyword">in</span> Protein_dic.keys():<br>  <span class="hljs-keyword">for</span> pos <span class="hljs-keyword">in</span> Protein_dic[chain]:<br>    <span class="hljs-keyword">if</span> Protein_dic[chain][pos].get_resname() <span class="hljs-keyword">in</span> AA_list:<br>      Residues += [[chain, pos, Protein_dic[chain][pos].get_resname(), <br>                  np.mean(Get_atom(Protein_dic[chain][pos]), axis=<span class="hljs-number">0</span>)]]<br><br><br><br><span class="hljs-comment"># plot hte residues position</span><br><span class="hljs-comment"># Convert to a numpy array</span><br>points_array = np.array([i[-<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> Residues])<br><br><span class="hljs-comment"># Create a PyVista point cloud</span><br>point_cloud = pv.PolyData(points_array)<br><br>point_cloud.plot(point_size=<span class="hljs-number">5</span>, color=<span class="hljs-string">&#x27;red&#x27;</span>)<br><br><br><span class="hljs-comment"># mesh</span><br><br><span class="hljs-comment"># Assuming &#x27;points_array&#x27; is your numpy array of 3D points</span><br>points = points_array.copy()<br><br><span class="hljs-comment"># Use KNN to find the nearest neighbors</span><br>nbrs = NearestNeighbors(n_neighbors=<span class="hljs-number">5</span>).fit(points)<br>distances, indices = nbrs.kneighbors(points)<br><br><span class="hljs-comment"># Determine a threshold distance for surface points</span><br>threshold_distance = np.percentile(distances, <span class="hljs-number">90</span>)  <span class="hljs-comment"># adjust as needed</span><br><br><span class="hljs-comment"># Identify surface points</span><br>surface_points = points[np.<span class="hljs-built_in">max</span>(distances, axis=<span class="hljs-number">1</span>) &gt; threshold_distance]<br>surface_res = np.array(Residues)[np.<span class="hljs-built_in">max</span>(distances, axis=<span class="hljs-number">1</span>) &gt; threshold_distance]<br><br>point_cloud = pv.PolyData(surface_points)<br><span class="hljs-comment">#point_cloud = pv.PolyData(points_array)</span><br>volume = point_cloud.delaunay_3d(alpha = <span class="hljs-number">10</span>)<br>shell = volume.extract_geometry()<br>shell.plot(show_edges=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure></div><p><img src="https://imgur.com/c0OUROW.png" alt=""></p><h2 id="Check-the-Residua-Local-environment">Check the Residua Local environment</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">nbrs = NearestNeighbors(n_neighbors=<span class="hljs-number">6</span>).fit(surface_points)<br>distances, indices = nbrs.kneighbors(surface_points)<br><br>Loc_res = &#123;&#125;; [Loc_res.update(&#123;i[<span class="hljs-number">1</span>]:i[<span class="hljs-number">2</span>]&#125;) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> Residues <span class="hljs-keyword">if</span> i [<span class="hljs-number">0</span>]==<span class="hljs-string">&#x27;A&#x27;</span>]<br><span class="hljs-comment"># rm duplicated</span><br><br>Net_charge = &#123;<span class="hljs-string">&quot;ALA&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;ARG&quot;</span>:+<span class="hljs-number">1</span>, <span class="hljs-string">&quot;ASN&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;ASP&quot;</span>:-<span class="hljs-number">1</span>, <span class="hljs-string">&quot;CYS&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;GLN&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;GLU&quot;</span>:-<span class="hljs-number">1</span>, <span class="hljs-string">&quot;GLY&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;HIS&quot;</span>:+<span class="hljs-number">1</span>, <span class="hljs-string">&quot;ILE&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;LEU&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;LYS&quot;</span>:+<span class="hljs-number">1</span>, <span class="hljs-string">&quot;MET&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;PHE&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;PRO&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;SER&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;THR&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;TRP&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;TYR&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;VAL&quot;</span>:<span class="hljs-number">0</span>&#125;<br><br><br>res_pos  = np.array([[surface_res[ii][<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> ii <span class="hljs-keyword">in</span> i[:<span class="hljs-number">5</span>]] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> indices])<br>res_pos = np.unique(res_pos, axis= <span class="hljs-number">0</span>)<br><br>res_name = [[Loc_res[ii] <span class="hljs-keyword">for</span> ii <span class="hljs-keyword">in</span> i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> res_pos]<br>Charge_av = [<span class="hljs-built_in">sum</span>([Net_charge[ii] <span class="hljs-keyword">for</span> ii <span class="hljs-keyword">in</span> i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> res_name]<br><br><br>Loc_net = &#123;&#125;<br>[Loc_net.update(&#123;i[<span class="hljs-number">0</span>]:ii&#125;) <span class="hljs-keyword">for</span> i,ii <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(res_pos, Charge_av)]<br>values = [Loc_net[i[<span class="hljs-number">1</span>]] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> surface_res]<br><br>point_cloud = pv.PolyData(surface_points)<br>point_cloud[<span class="hljs-string">&quot;values&quot;</span>] = values<br><br><span class="hljs-comment">#point_cloud = pv.PolyData(points_array)</span><br>volume = point_cloud.delaunay_3d(alpha = <span class="hljs-number">10</span>)<br>shell = volume.extract_geometry()<br><br>plotter = pv.Plotter()<br>plotter.add_mesh(volume, scalars=<span class="hljs-string">&quot;values&quot;</span>, cmap=<span class="hljs-string">&quot;coolwarm&quot;</span>)<br>plotter.add_scalar_bar(color=<span class="hljs-string">&#x27;black&#x27;</span>)  <span class="hljs-comment"># Set scalar bar font color to black</span><br>plotter.set_background(color=<span class="hljs-string">&#x27;white&#x27;</span>)<br>plotter.show()<br><br><br>shell.plot(show_edges=<span class="hljs-literal">True</span>, scalars=<span class="hljs-string">&quot;values&quot;</span>, cmap=<span class="hljs-string">&quot;coolwarm&quot;</span>)<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://imgur.com/ZKPfTRr.png" alt=""></th></tr></thead><tbody></tbody></table><h2 id="Camera-Position">Camera Position</h2><p>In PyVista, you can easily get and set the camera position to ensure a consistent view across different plots. The camera position in PyVista is defined by a tuple of three elements:</p><ol><li><strong>Camera Position</strong>: The location of the camera in the 3D space.</li><li><strong>Focal Point</strong>: The point in the 3D space that the camera is looking at.</li><li><strong>View Up</strong>: A vector that defines the ‘up’ direction in the view of the camera.</li></ol><p>Here’s how you can get and then set the camera position:</p><h3 id="Getting-the-Camera-Position">Getting the Camera Position</h3><p>After you have displayed your plot once, you can retrieve the camera position:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pyvista <span class="hljs-keyword">as</span> pv<br><br><span class="hljs-comment"># [Your code to create and display the mesh]</span><br><br><span class="hljs-comment"># Create a plotter and add the mesh</span><br>plotter = pv.Plotter()<br>plotter.add_mesh(mesh)<br>plotter.show()<br><br><span class="hljs-comment"># Q to quite the polt</span><br><span class="hljs-comment"># Get the camera position</span><br>camera_position = plotter.camera_position<br></code></pre></td></tr></table></figure></div><h3 id="Setting-the-Camera-Position">Setting the Camera Position</h3><p>When you create a new plot and want to use the same camera position, you can set it like this:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Create a new plotter</span><br>plotter = pv.Plotter()<br><span class="hljs-comment"># Add the mesh to the new plotter</span><br>plotter.add_mesh(mesh)<br><span class="hljs-comment"># Set the camera position to the saved one</span><br>plotter.camera_position = camera_position<br><span class="hljs-comment"># Show the plot with the set camera position</span><br>plotter.show()<br></code></pre></td></tr></table></figure></div><p>Remember, you should retrieve and set the camera position after and before calling <code>show()</code>, respectively. This method ensures that every time you plot your mesh, the view will be identical, assuming the mesh and other plot settings remain the same.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Extract Information from PDB by using Biopython, rebuild the model and Visualize it with Pyvista</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Protein Structure" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Protein-Structure/"/>
    
    
    <category term="Software" scheme="https://karobben.github.io/tags/Software/"/>
    
    <category term="3D" scheme="https://karobben.github.io/tags/3D/"/>
    
    <category term="Pyvista" scheme="https://karobben.github.io/tags/Pyvista/"/>
    
    <category term="Protein" scheme="https://karobben.github.io/tags/Protein/"/>
    
  </entry>
  
  <entry>
    <title>Neuraminidase (NA) protein, a Quick View</title>
    <link href="https://karobben.github.io/2023/12/07/LearnNotes/h3n2na/"/>
    <id>https://karobben.github.io/2023/12/07/LearnNotes/h3n2na/</id>
    <published>2023-12-07T19:00:02.000Z</published>
    <updated>2023-12-18T19:28:48.224Z</updated>
    
    <content type="html"><![CDATA[<h2 id="NA-protein">NA protein</h2><p>The influenza NA protein, or neuraminidase, is a critical component of the influenza virus and plays a vital role in the virus’s life cycle. Here’s an overview of its function and structure:</p><h3 id="Function-of-Influenza-NA-Protein">Function of Influenza NA Protein</h3><ol><li><p><strong>Viral Release</strong>: Neuraminidase is primarily responsible for facilitating the release of newly formed virus particles from the host cell. It cleaves sialic acid residues on the host cell surface and on the viral envelope, which otherwise bind the emerging viral particles and prevent their release.</p></li><li><p><strong>Virus Spread</strong>: By cleaving sialic acid, NA protein aids in the spread of the virus. This cleavage prevents the aggregation of virus particles, enabling them to spread more efficiently from cell to cell.</p></li><li><p><strong>Role in Infection</strong>: It helps the virus penetrate the mucus layer of the respiratory tract, enhancing the virus’s ability to infect the host cells.</p></li></ol><h3 id="Structure-of-Influenza-NA-Protein">Structure of Influenza NA Protein</h3><table><thead><tr><th style="text-align:center"><img src="https://www.frontiersin.org/files/Articles/432609/fmicb-10-00039-HTML/image_m/fmicb-10-00039-g001.jpg" alt="Structure of Influenza NA Protein"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.frontiersin.org/articles/10.3389/fmicb.2019.00039/full">© Julie L. McAuley1; 19</a></td></tr></tbody></table><ol><li><p><strong>Cytoplasmic Tail</strong>: Suggesting that the NA cytoplasmic tail is involved in critical viral functions, the N-terminal domain sequence is nearly 100% conserved across all IAV subtypes and consists of the sequence MNPNQK<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>. A complete loss of the tail domain<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup> resulted in a 50% reduction in the amount of NA in infected cells.</p></li><li><p><strong>Transmembrane Domain</strong>: It contains a variable sequence of amino acids spanning residue numbers 7–29 and is predicted to form an alpha helix<sup class="footnote-ref"><a href="#fn1" id="fnref1:1">[1:1]</a></sup><sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup> with interspersed polar residues driving subunit-subunit interactions<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>.</p></li><li><p><strong>Stalk Region</strong>: Depending on the length of the stalk region, the NA may protrude slightly more or less above the viral envelope than the HA, which may influence the overall enzymatic activity of the virus<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup><sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup>. The number and sequence of amino acid residues can vary considerably<sup class="footnote-ref"><a href="#fn1" id="fnref1:2">[1:2]</a></sup>.  NA stalk truncation mutants of the 2009 pandemic virus A(H1N1)pdm09 showed greater lethality in mice and virulence in ferrets than the untruncated counterpart<sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup>.</p></li><li><p><strong>Head Domain</strong>: These catalytic sites are characterized by a large cavity with an unusually large number of charged residues in the pocket and around its rim<sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup><sup class="footnote-ref"><a href="#fn9" id="fnref9">[9]</a></sup>. The tetrameric form of NA is considered optimal for enzyme activity, and mutations that lead to instability of the tetramer lead to decreased enzyme activity [<sup>McKimm_96b][</sup>Fujisaki_12][^McKimm_13]. While it has been reported that monomers alone have no enzyme activity<sup class="footnote-ref"><a href="#fn3" id="fnref3:1">[3:1]</a></sup> and usually expression of recombinant soluble NA heads requires a synthetic tetramerization domain for active NA<sup class="footnote-ref"><a href="#fn10" id="fnref10">[10]</a></sup>.</p><ul><li>Active site: Arg118, Asp151, Arg152, Arg224, Glu276, Arg292, Arg371, and Tyr406</li><li>Framework residues: Glu119, Arg156, Trp178, Ser179, Asp198, Ile222, Glu227, Glu277, Asn294, and Glu425</li></ul></li></ol><ol><li><p><strong>Tetrameric Structure</strong>: The neuraminidase protein typically forms a tetramer, meaning four NA molecules join together to function.</p></li><li><p><strong>Head and Stalk Regions</strong>: The NA protein has two distinct regions: the head, which contains the active site for sialic acid cleavage, and the stalk, which anchors the protein to the viral envelope.</p></li><li><p><strong>Active Site</strong>: The active site is located in a pocket in the head region and is responsible for the enzyme’s sialic acid cleavage activity.</p></li><li><p><strong>Glycosylation Sites</strong>: These sites are present on the head region, where carbohydrate chains are attached. This glycosylation can affect the antigenicity and activity of the NA protein.</p></li><li><p><strong>Subtypes</strong>: There are several different subtypes of neuraminidase, categorized based on slight variations in their amino acid sequences. These variations can affect the protein’s function and its recognition by the immune system.</p></li></ol><p>Understanding the function and structure of the influenza NA protein is crucial for developing antiviral drugs and vaccines. Neuraminidase inhibitors, for example, are a class of antiviral drugs that block the activity of this protein, effectively preventing the virus from spreading within the host.</p><h2 id="Leading-Research">Leading Research</h2><p>A paper<sup class="footnote-ref"><a href="#fn11" id="fnref11">[11]</a></sup> investigates the antigenic evolution of the neuraminidase (NA) protein in the H3N2 influenza virus. Using combinatorial mutagenesis and next-generation sequencing, the study focuses on seven specific residues in an antigenic region of NA. It finds that the local fitness landscape of this region is highly correlated across different H3N2 strains and reveals that <mark>local net charge balancing</mark> is a significant constraint in NA antigenic evolution. The study also demonstrates a correlation between epistasis and residue coevolution in naturally circulating influenza strains, providing important insights into the biophysical constraints on NA antigenic evolution.</p><table><thead><tr><th style="text-align:center"><img src="https://iiif.elifesciences.org/lax/72516%2Felife-72516-fig1-v2.tif/full/1500,/0/default.jpg" alt=""></th></tr></thead><tbody><tr><td style="text-align:center">© Wang Y; 2021<sup class="footnote-ref"><a href="#fn11" id="fnref11:1">[11:1]</a></sup></td></tr></tbody></table><h2 id="Features-from-Other-NA-protein">Features from Other NA protein</h2><p>H1N1:</p><ul><li>K253R could reduce the 75% of virion-associated NA activity<sup class="footnote-ref"><a href="#fn12" id="fnref12">[12]</a></sup>.</li></ul><style>pre {  background-color:#38393d;  color: #5fd381;}</style><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>Blok, J., and Air, G. M. (1982). Variation in the membrane-insertion and “stalk” sequences in eight subtypes of influenza type A virus neuraminidase. Biochemistry 21, 4001–4007. <a href="#fnref1" class="footnote-backref">↩︎</a> <a href="#fnref1:1" class="footnote-backref">↩︎</a> <a href="#fnref1:2" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>Garcia-Sastre, A., and Palese, P. (1995). The cytoplasmic tail of the neuraminidase protein of influenza A virus does not play an important role in the packaging of this protein into viral envelopes. Virus Res. 37, 37–47. doi: 10.1016/0168-1702(95)00017-K <a href="#fnref2" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>Air, G. M. (2012). Influenza neuraminidase. Influenza Other Respir. Viruses 6, 245–256. doi: 10.1111/j.1750-2659.2011.00304.x <a href="#fnref3" class="footnote-backref">↩︎</a> <a href="#fnref3:1" class="footnote-backref">↩︎</a></p></li><li id="fn4" class="footnote-item"><p>Nordholm, J., Da Silva, D. V., Damjanovic, J., Dou, D., and Daniels, R. (2013). Polar residues and their positional context dictate the transmembrane domain interactions of influenza A neuraminidases. J. Biol. Chem. 288, 10652–10660. doi: 10.1074/jbc.M112.440230 <a href="#fnref4" class="footnote-backref">↩︎</a></p></li><li id="fn5" class="footnote-item"><p>Harris, A., Cardone, G., Winkler, D. C., Heymann, J. B., Brecher, M., White, J. M., et al. (2006). Influenza virus pleiomorphy characterized by cryoelectron tomography. Proc. Natl. Acad. Sci. U. S. A. 103, 19123–19127. doi: 10.1073/pnas.0607614103 <a href="#fnref5" class="footnote-backref">↩︎</a></p></li><li id="fn6" class="footnote-item"><p>Matsuoka, Y., Swayne, D. E., Thomas, C., Rameix-Welti, M. A., Naffakh, N., Warnes, C., et al. (2009). Neuraminidase stalk length and additional glycosylation of the hemagglutinin influence the virulence of influenza H5N1 viruses for mice. J. Virol. 83, 4704–4708. doi: 10.1128/JVI.01987-08 <a href="#fnref6" class="footnote-backref">↩︎</a></p></li><li id="fn7" class="footnote-item"><p>Park, S., Il Kim, J., Lee, I., Bae, J. Y., Yoo, K., Nam, M., et al. (2017). Adaptive mutations of neuraminidase stalk truncation and deglycosylation confer enhanced pathogenicity of influenza A viruses. Sci. Rep. 7:10928. doi: 10.1038/s41598-017-11348-0 <a href="#fnref7" class="footnote-backref">↩︎</a></p></li><li id="fn8" class="footnote-item"><p>Colman, P. M., Varghese, J. N., and Laver, W. G. (1983). Structure of the catalytic and antigenic sites in influenza virus neuraminidase. Nature 303, 41–44. doi: 10.1038/303041a0 <a href="#fnref8" class="footnote-backref">↩︎</a></p></li><li id="fn9" class="footnote-item"><p>Varghese, J. N., McKimm-Breschkin, J. L., Caldwell, J. B., Kortt, A. A., and Colman, P. M. (1992). The structure of the complex between influenza virus neuraminidase and sialic acid, the viral receptor. Proteins 14, 327–332. doi: 10.1002/prot.340140302 <a href="#fnref9" class="footnote-backref">↩︎</a></p></li><li id="fn10" class="footnote-item"><p>Schmidt, P. M., Attwood, R. M., Mohr, P. G., Barrett, S. A., and McKimm-Breschkin, J. L. (2011). A generic system for the expression and purification of soluble and stable influenza neuraminidase. PLoS One 6:e16284. doi: 10.1371/journal.pone.0016284<br>[^McKimm_13]McKimm-Breschkin, J. L., Williams, J., Barrett, S., Jachno, K., McDonald, M., Mohr, P. G., et al. (2013). Reduced susceptibility to all neuraminidase inhibitors of influenza H1N1 viruses with haemagglutinin mutations and mutations in non-conserved residues of the neuraminidase. J. Antimicrob. Chemother. 68, 2210–2221. doi: 10.1093/jac/dkt205<br>[^Fujisaki_12]Fujisaki, S., Takashita, E., Yokoyama, M., Taniwaki, T., Xu, H., Kishida, N., et al. (2012). A single E105K mutation far from the active site of influenza B virus neuraminidase contributes to reduced susceptibility to multiple neuraminidase-inhibitor drugs. Biochem. Biophys. Res. Commun. 429, 51–56. doi: 10.1016/j.bbrc.2012.10.095<br>[^McKimm_96b]McKimm-Breschkin, J. L., McDonald, M., Blick, T. J., and Colman, P. M. (1996b). Mutation in the influenza virus neuraminidase gene resulting in decreased sensitivity to the neuraminidase inhibitor 4-guanidino-Neu5Ac2en leads to instability of the enzyme. Virology 225, 240–242. <a href="#fnref10" class="footnote-backref">↩︎</a></p></li><li id="fn11" class="footnote-item"><p>Wang Y, Lei R, Nourmohammad A, et al. Antigenic evolution of human influenza H3N2 neuraminidase is constrained by charge balancing[J]. Elife, 2021, 10: e72516. <a href="#fnref11" class="footnote-backref">↩︎</a> <a href="#fnref11:1" class="footnote-backref">↩︎</a></p></li><li id="fn12" class="footnote-item"><p>Liu T, Wang Y, Tan T J C, et al. The evolutionary potential of influenza A virus hemagglutinin is highly constrained by epistatic interactions with neuraminidase[J]. Cell Host &amp; Microbe, 2022, 30(10): 1363-1369. e4. <a href="#fnref12" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">Basic Knowledge of Neuraminidase (NA) protein</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Notes/Biology/"/>
    
    <category term="Immunity" scheme="https://karobben.github.io/categories/Notes/Biology/Immunity/"/>
    
    
    <category term="Biology" scheme="https://karobben.github.io/tags/Biology/"/>
    
    <category term="Immunology" scheme="https://karobben.github.io/tags/Immunology/"/>
    
    <category term="Antibody" scheme="https://karobben.github.io/tags/Antibody/"/>
    
  </entry>
  
  <entry>
    <title>Understanding False Discovery Rate (FDR) and the Benjamini-Hochberg Method</title>
    <link href="https://karobben.github.io/2023/12/07/LearnNotes/fdr/"/>
    <id>https://karobben.github.io/2023/12/07/LearnNotes/fdr/</id>
    <published>2023-12-07T18:13:35.000Z</published>
    <updated>2023-12-07T18:46:09.881Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Understanding-False-Discovery-Rate-FDR-and-the-Benjamini-Hochberg-Method">Understanding False Discovery Rate (FDR) and the Benjamini-Hochberg Method</h2><div class="admonition note"><p class="admonition-title">Warning</p><p>This Passages is completely composed by ChatGPT4</p></div><p>In the realm of statistical analysis, particularly in fields inundated with vast datasets like genomics, neuroscience, and social sciences, the concept of False Discovery Rate (FDR) has become pivotal. This post delves into the essence of FDR, its significance in multiple hypothesis testing, and the widely adopted Benjamini-Hochberg (BH) method for FDR control.</p><h2 id="What-is-False-Discovery-Rate-FDR">What is False Discovery Rate (FDR)?</h2><p>False Discovery Rate is a statistical measure used in multiple hypothesis testing to identify the proportion of false positives (incorrectly rejected null hypotheses) among all rejected hypotheses. In simpler terms, it represents the expected ratio of erroneous discoveries to the total number of discoveries.</p><h3 id="Importance-of-FDR">Importance of FDR:</h3><ul><li><strong>Multiple Comparisons Problem</strong>: When testing multiple hypotheses simultaneously, the likelihood of encountering false positives increases.</li><li><strong>Balancing Sensitivity and Specificity</strong>: FDR provides a balanced approach, controlling the rate of false discoveries while maintaining the ability to detect true effects.</li></ul><h2 id="The-Benjamini-Hochberg-BH-Method">The Benjamini-Hochberg (BH) Method:</h2><p>Developed by Yoav Benjamini and Yosef Hochberg in 1995, the BH method is a practical approach to controlling the FDR in multiple testing scenarios.</p><h3 id="How-the-BH-Method-Works">How the BH Method Works:</h3><ol><li><p><strong>Rank P-values</strong>: Arrange the p-values from individual hypothesis tests in ascending order.</p></li><li><p><strong>Calculate Adjusted P-values</strong>: Compute adjusted p-values using the formula:</p><p>$$ \text{Adjusted p-value} = \min\left(\frac{\text{Original p-value} \times N}{\text{Rank}}, 1\right) $$</p><p>Here, $N$ is the total number of tests, and ‘Rank’ is the position of the original p-value in the ordered list.</p></li><li><p><strong>Interpretation</strong>: Compare these adjusted p-values with a pre-defined FDR threshold (e.g., 0.05). Tests with adjusted p-values below this threshold are deemed statistically significant.</p></li></ol><h3 id="Advantages-of-the-BH-Method">Advantages of the BH Method:</h3><ul><li><strong>Less Conservative</strong>: Unlike methods that control the family-wise error rate (FWER), the BH method is less stringent, leading to greater statistical power in detecting true effects.</li><li><strong>Adaptability</strong>: Works well across various disciplines where multiple hypothesis testing is common.</li></ul><h3 id="Limitations">Limitations:</h3><ul><li><strong>Assumption of Independence</strong>: The method assumes that tests are independent or positively dependent. Its effectiveness may diminish if this assumption is violated.</li><li><strong>FDR, Not FWER</strong>: It controls the rate of false discoveries, not the probability of making any Type I error.</li></ul><h2 id="Application-in-R">Application in R:</h2><p>In R, the <code>p.adjust</code> function is used for FDR adjustment, specifically with the “BH” method. This function modifies the original p-values from your tests, providing adjusted values that can be compared to your FDR threshold.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r">p_values &lt;- <span class="hljs-built_in">c</span>(<span class="hljs-number">0.01</span>, <span class="hljs-number">0.04</span>, <span class="hljs-number">0.03</span>, <span class="hljs-number">0.05</span>, <span class="hljs-number">0.20</span>)<br>adjusted_p_values &lt;- p.adjust(p_values, method = <span class="hljs-string">&quot;BH&quot;</span>)<br><br>print(adjusted_p_values)<br></code></pre></td></tr></table></figure></div><h2 id="Other-Adjustment-Methods">Other Adjustment Methods</h2><p>Here’s a comparison of various p-value adjustment methods in a tabular format:</p><table><thead><tr><th>Method</th><th>Description</th><th>Advantages</th><th>Limitations</th><th>Suitable Data</th></tr></thead><tbody><tr><td><strong>Bonferroni Correction</strong></td><td>Divides alpha level by the number of tests.</td><td>Simple, very conservative, controls FWER.</td><td>Too conservative, higher Type II error risk.</td><td>Small number of hypotheses.</td></tr><tr><td><strong>Benjamini-Yekutieli (BY)</strong></td><td>Generalization of BH, works under any dependency.</td><td>Controls FDR under any dependency structure.</td><td>More conservative than BH.</td><td>Tests with unknown dependencies.</td></tr><tr><td><strong>Holm-Bonferroni</strong></td><td>Sequentially compares p-values to adjusted alpha.</td><td>Less conservative than Bonferroni, controls FWER.</td><td>Still quite conservative with many tests.</td><td>Moderately sized numbers of hypotheses.</td></tr><tr><td><strong>Šidák Correction</strong></td><td>Similar to Bonferroni, assumes independence.</td><td>Less conservative than Bonferroni for independent tests.</td><td>Assumes independence among tests.</td><td>Independent hypotheses.</td></tr><tr><td><strong>False Discovery Rate (FDR) - BH Method</strong></td><td>Controls the expected proportion of false discoveries.</td><td>Less conservative than FWER methods, more power.</td><td>May not control FWER, assumes some test independence.</td><td>Large-scale testing like genomics.</td></tr></tbody></table><p>This table provides an overview of the key features, advantages, limitations, and suitable applications for each method. The choice of method depends on the balance between the risk of false positives and the need for statistical power, as well as the nature and scale of the data being analyzed.</p><h2 id="Other-than-FDR">Other than FDR</h2><p>Besides False Discovery Rate (FDR) methods like the Benjamini-Hochberg procedure, there are several other methods for adjusting p-values in the context of multiple hypothesis testing. These methods primarily aim to control different types of error rates. Here are some of the key methods:</p><ol><li><p><strong>Family-Wise Error Rate (FWER) Methods</strong>:</p><ul><li><strong>Bonferroni Correction</strong>: The simplest and most conservative method, which multiplies each p-value by the number of tests (or compares each p-value against the significance level divided by the number of tests).</li><li><strong>Holm-Bonferroni Method</strong>: A stepwise adjustment method that sequentially adjusts p-values in ascending order, slightly less conservative than the Bonferroni correction.</li><li><strong>Šidák Correction</strong>: Similar to Bonferroni but slightly less conservative, assuming that all tests are independent.</li><li><strong>Hochberg’s Method</strong>: Another step-up procedure that is less conservative than the Holm-Bonferroni method.</li></ul></li><li><p><strong>Permutation Tests</strong>:</p><ul><li><strong>Permutation-Based Adjustments</strong>: These involve recalculating p-values by comparing observed test statistics to their distribution under permutations of the data. This approach is particularly useful for complex or non-standard data structures.</li></ul></li><li><p><strong>Bayesian Methods</strong>:</p><ul><li><strong>Bayesian Adjustments</strong>: These involve using Bayesian statistics to adjust p-values, which can incorporate prior information and provide a different perspective on significance.</li></ul></li><li><p><strong>False Coverage Rate (FCR) Procedures</strong>:</p><ul><li><strong>Benjamini-Hochberg-Yekutieli Procedure</strong>: An extension of the BH procedure that controls the FCR, the expected proportion of incorrect coverage statements among all coverage statements made.</li></ul></li><li><p><strong>Local False Discovery Rate (LFDR)</strong>:</p><ul><li><strong>LFDR Adjustments</strong>: Focuses on the probability that a particular null hypothesis is true given the observed p-value, providing a local (individual) measure of significance.</li></ul></li></ol><p>Each of these methods has its strengths and weaknesses, and the choice of method depends on the specific goals of the analysis, the nature of the data, and the type of error control desired. For example, FWER methods are typically used when it’s crucial to minimize the chance of any false positives, while FDR methods are more appropriate when dealing with large numbers of tests and when some false positives can be tolerated to gain higher statistical power.</p><h2 id="Conclusion">Conclusion</h2><p>In conclusion, the landscape of statistical analysis, particularly in the context of multiple hypothesis testing, has been significantly enriched and diversified through various p-value adjustment methods. Among these, the Benjamini-Hochberg (BH) method stands out as a revolutionary approach. It offers a balanced and less conservative alternative for statistical inference, adeptly addressing the challenges posed by large-scale data analyses. The BH method, by controlling the False Discovery Rate (FDR), allows researchers to manage the trade-off between discovering true effects and limiting false positives effectively.</p><p>Simultaneously, the existence of other methods such as the Bonferroni correction, Holm-Bonferroni, and Šidák adjustments, along with more complex procedures like permutation tests and Bayesian methods, underscores the diversity of tools available to researchers. Each method comes with its unique strengths and limitations, catering to different types of data and research objectives. For instance, FWER-controlling methods like the Bonferroni correction are invaluable in scenarios where even a single false positive is unacceptable, while FDR-controlling approaches like the BH method are more suitable for exploratory analyses with large datasets.</p><p>The integration of these methods into statistical software such as R has further democratized access to sophisticated statistical tools, enabling researchers from various fields to apply the most appropriate methods to their data. This accessibility ensures that research findings are both robust and reliable, despite the inherent challenges of multiple comparisons.</p><p>In essence, the BH method, along with other p-value adjustment techniques, equips researchers with the necessary tools to navigate the complexities of modern data landscapes confidently. They collectively ensure that researchers can uncover meaningful insights without the risk of being misled by false discoveries, thereby advancing the pursuit of knowledge across various scientific disciplines.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">A comprehensive guide on False Discovery Rate (FDR) and the Benjamini-Hochberg Method, detailing their importance in statistical analysis for multiple hypothesis testing.</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Statistic" scheme="https://karobben.github.io/categories/Notes/Statistic/"/>
    
    <category term="others" scheme="https://karobben.github.io/categories/Notes/Statistic/others/"/>
    
    
    <category term="Statistic" scheme="https://karobben.github.io/tags/Statistic/"/>
    
  </entry>
  
  <entry>
    <title>Visualize the Protein Mesh with pyvista</title>
    <link href="https://karobben.github.io/2023/12/06/Bioinfor/pymol2pyvista/"/>
    <id>https://karobben.github.io/2023/12/06/Bioinfor/pymol2pyvista/</id>
    <published>2023-12-06T19:46:30.000Z</published>
    <updated>2023-12-19T22:55:54.929Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Prerrequirement">Prerrequirement</h2><pre>pymolcolladapyvista</pre><p>All libraries could be installed by <code>pip</code></p><h2 id="Save-the-Mesh-Information-with-Pymol">Save the Mesh Information with Pymol</h2><p>after loaded your model:</p><p>Example file: 2a6d<br>Target: Extract the mesh information of CDR region from a antibody<br>PS: output may takes a while.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><code class="hljs pymol">bg_color white<br>color deepblue, 2a6d<br><br>select CDR1, 2a6d and chain B and resi 31-35<br>select CDR2, 2a6d and chain B and resi 50-66<br>select CDR3, 2a6d and chain B and resi 99-110<br>create cdr, CDR1 CDR2 CDR3<br><br>show mesh, cdr<br>color hotpink, cdr<br><br>hide all<br>show surface, cdr<br>save object.stl, cdr<br></code></pre></td></tr></table></figure></div><p><img src="https://imgur.com/bNjPfcD.png" alt="Select a target area from pymol"></p><h2 id="Load-It-with-pyvista">Load It with pyvista</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pyvista <span class="hljs-keyword">as</span> pv<br>mesh = pv.read(<span class="hljs-string">&#x27;object.stl&#x27;</span>)<br><br>mesh.plot()<br><br>plotter = pv.Plotter(off_screen=<span class="hljs-literal">True</span>)<br>plotter.add_mesh(mesh)<br>plotter.show(screenshot=<span class="hljs-string">&quot;myscreenshot.png&quot;</span>)<br></code></pre></td></tr></table></figure></div><p><img src="https://imgur.com/kH46OTm.png" alt="stl file visualize by pyvista"></p><h2 id="Model-Manipulation">Model Manipulation</h2><h3 id="Rotate-the-Model">Rotate the Model</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Rotate the mesh</span><br>angle = <span class="hljs-number">45</span>  <span class="hljs-comment"># Angle in degrees</span><br><br>mesh.rotate_x(angle)  <span class="hljs-comment"># Rotate 45 degrees around the x-axis</span><br><span class="hljs-comment"># mesh.rotate_y(angle)  # Rotate around the y-axis</span><br><span class="hljs-comment"># mesh.rotate_z(angle)  # Rotate around the z-axis</span><br><br><span class="hljs-comment"># For rotation around an arbitrary axis (e.g., [1, 1, 1]), use:</span><br><span class="hljs-comment"># mesh.rotate_vector([1, 1, 1], angle)</span><br><br><span class="hljs-comment"># Now you can plot the rotated mesh</span><br>plotter = pv.Plotter()<br>plotter.add_mesh(mesh)<br>plotter.show()<br></code></pre></td></tr></table></figure></div><h3 id="Move-the-Model">Move the Model</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pyvista <span class="hljs-keyword">as</span> pv<br><br><span class="hljs-comment"># Assume &#x27;mesh&#x27; is your PyVista mesh</span><br><span class="hljs-comment"># ...</span><br><br><span class="hljs-comment"># Translate the mesh</span><br>translation_vector = [<span class="hljs-number">10</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]  <span class="hljs-comment"># This will move the mesh 10 units along the x-axis</span><br>mesh.translate(translation_vector)<br><br><span class="hljs-comment"># Now you can plot the translated mesh</span><br>plotter = pv.Plotter()<br>plotter.add_mesh(mesh)<br>plotter.show()<br></code></pre></td></tr></table></figure></div><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">seamlessly bridges PyMOL and Python: read PyMOL result to python</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Protein Structure" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Protein-Structure/"/>
    
    
    <category term="Software" scheme="https://karobben.github.io/tags/Software/"/>
    
    <category term="3D" scheme="https://karobben.github.io/tags/3D/"/>
    
    <category term="Pyvista" scheme="https://karobben.github.io/tags/Pyvista/"/>
    
    <category term="PyMol" scheme="https://karobben.github.io/tags/PyMol/"/>
    
    <category term="Protein" scheme="https://karobben.github.io/tags/Protein/"/>
    
  </entry>
  
  <entry>
    <title>CR9114</title>
    <link href="https://karobben.github.io/2023/11/22/LearnNotes/panHA/"/>
    <id>https://karobben.github.io/2023/11/22/LearnNotes/panHA/</id>
    <published>2023-11-23T03:38:28.000Z</published>
    <updated>2023-12-18T19:28:54.100Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Pan-fluenza-family">Pan fluenza family</h2><ul><li>CR9114 from V<sub>H</sub>1-69<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>: <ai>This antibody, derived from the V<sub>H</sub>1-69 gene segment, is known for its broad reactivity against both group 1 and group 2 influenza A viruses. CR9114 binds to a highly conserved epitope in the HA stem region. This region is involved in the fusion of the viral and host cell membranes, a critical step in the viral infection process. By binding to this region, CR9114 can block the conformational changes required for membrane fusion, thereby inhibiting viral entry into host cells.</ai></li><li>CR6261 from V<sub>H</sub>1-69<sup class="footnote-ref"><a href="#fn1" id="fnref1:1">[1:1]</a></sup>: <ai>Also originating from the V<sub>H</sub>1-69 gene segment, CR6261 specifically targets group 1 influenza A viruses. Like CR9114, CR6261 binds to the stem region of HA, but its binding is more restricted to group 1 viruses. This antibody stabilizes the pre-fusion form of HA, preventing the structural rearrangements necessary for the virus to fuse with the host cell membrane.</ai></li><li>FI6v3 from V<sub>H</sub>3-30<sup class="footnote-ref"><a href="#fn1" id="fnref1:2">[1:2]</a></sup>: <ai>Derived from the V<sub>H</sub>3-30 gene segment, FI6v3 is notable for its broad neutralizing activity against all known subtypes of influenza A viruses. This broad reactivity is achieved through its binding to a conserved epitope in the HA stem region, similar to CR9114 and CR6261. However, the precise mode of binding and the epitope details might differ, contributing to its unique broad-spectrum activity.</ai></li><li>CR8020<sup class="footnote-ref"><a href="#fn1" id="fnref1:3">[1:3]</a></sup>: <ai>CR8020’s mode of binding is distinct from the others. It targets a specific epitope in the HA stem region that is predominantly present in group 2 influenza A viruses. By binding to this site, CR8020 can inhibit the necessary conformational changes in the HA protein during the virus’s entry into the host cell, thereby neutralizing the virus.</ai></li></ul><p>Five important hydrophobic pockets.</p><table><thead><tr><th style="text-align:center"><img src="https://perspectivesinmedicine.cshlp.org/content/10/8/a038778/F4.large.jpg" alt="HA"></th></tr></thead><tbody><tr><td style="text-align:center">© Wu, 2020<sup class="footnote-ref"><a href="#fn1" id="fnref1:4">[1:4]</a></sup></td></tr></tbody></table><h2 id="CR9114">CR9114</h2><h3 id="Light-Chain">Light Chain</h3><p><ai>The CR9114 light chain contains a specific sequence motif in its CDR L3 region that is important for binding to the HA stem of the influenza A virus. The motif consists of two aromatic amino acids, Trp91 and Trp96, which are positioned toward the heavy chain with limited space in between. These aromatic residues participate in π-π stacking interactions with the HA protein, specifically with the tryptophan residue at position 91, which is located in the CDR L3 region.</ai><sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup></p><ul><li>Importance of CR9114 light-chain residues 91 and 96<sup class="footnote-ref"><a href="#fn2" id="fnref2:1">[2:1]</a></sup><ul><li>Trp91: <ai>This tryptophan residue is located in the CDR L3 region of CR9114 and has been identified as a key residue for HA binding. It forms a π-π stacking interaction with the tryptophan residues in the HA stem, which is stabilized by hydrogen bonds between the amide and carbonyl groups.<ai></li><li>Small amino acid Ala at VL residue 96, which points toward the heavy chain with limited space in between</li><li><ai>The binding activity of CR9114 to the HA stem was found to be abolished when the non-aromatic amino acids threonine (T), arginine ®, or alanine (A) were substituted for the aromatic residue tryptophan at position 91. Similarly, substitution with aromatic amino acids tyrosine (Y) or phenylalanine (F) did not disrupt binding activity. This suggests that the presence of an aromatic residue at position 91 is essential for CR9114 binding to the HA stem.<ai><sup class="footnote-ref"><a href="#fn2" id="fnref2:2">[2:2]</a></sup></li></ul></li></ul><h3 id="Heavy-Chain">Heavy Chain</h3><ul><li><strong>Y98</strong>, <strong>Y99</strong>, <strong>Y100</strong>, and <strong>Y100a</strong> in CDR H3 (heavy chain)<sup class="footnote-ref"><a href="#fn2" id="fnref2:3">[2:3]</a></sup></li><li><strong>H95</strong> and <strong>N97</strong>: the side chains of both VH H95 and VH N97 are not interacting with the HA stem epitope. Instead, both VH H95 and VH N97 form intramolecular interactions to stabilize the CDR H3 conformation.<ul><li><strong>H95</strong> H-bonds with VH <strong>S100b</strong> and VH <strong>S35</strong> as well as interacts with VH <strong>Y100</strong> via T-shaped p-p stacking</li><li><strong>N97</strong> H-bonds with VH <strong>Y99</strong> and VH S100b<sup class="footnote-ref"><a href="#fn2" id="fnref2:4">[2:4]</a></sup></li></ul></li><li>Most CDR H3 variants are incompatible with CR9114 for HA stem binding<sup class="footnote-ref"><a href="#fn2" id="fnref2:5">[2:5]</a></sup></li></ul><table><thead><tr><th style="text-align:center"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S2211124723014225-gr4.jpg" alt=""></th></tr></thead><tbody><tr><td style="text-align:center">H95 and VH N97 stabilize the CDR H3 conformation<sup class="footnote-ref"><a href="#fn2" id="fnref2:6">[2:6]</a></sup></td></tr><tr><td style="text-align:center"><img src="https://imgur.com/iWELcwB.png" alt=""></td></tr><tr><td style="text-align:center">light chain 91, 96, and 98 insert into the hydrophobic pocket<sup class="footnote-ref"><a href="#fn2" id="fnref2:7">[2:7]</a></sup></td></tr></tbody></table><blockquote><p><img src="https://www.frontiersin.org/files/Articles/1049134/fviro-02-1049134-HTML-r4/image_m/fviro-02-1049134-g004.jpg" alt="CR9114 key amino acid"><br>Structure of CR9114, indicating the 16 AAs that differ between the germline and the somatic variant. Mutated residues (53) (16 positions) are shown in orange sticks. Residues IDs as labelled in orange are converted to the somatic sequence as in the PDB structure (table). Mutated residues required (53) for gaining affinity for H1, H3, and B HA are indicated in the table (+ required mutation, *mutation improves binding). Some key residues, such as F54 (HCDR2) and a quadruplet “YYYY” in HCDR3, are additionally displayed in magenta sticks. The heavy and light chains are shown in magenta and yellow, respectively.<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup></p></blockquote><h2 id="CR9114-and-CR6261">CR9114 and CR6261</h2><p>CDR1:</p><ul><li>CR9114: The <strong>I73</strong> in the FR3 loop allows CR9114 to ﬂip into the hydrophobic groove of inﬂuenza H5 (Figure 3C) and H3</li><li>CR6261: <strong>D73</strong>: Its side chain has a different conformation and ﬂips out of the hydrophobic groove of H5.<ul><li><strong>R30—D73</strong> form a stable and preferable internal H-bond</li><li><strong>D73(FR3)—R30 (HCDR1) —Y32 (HCDR1)</strong> and <strong>A33(HCDR1)—G97 (HCDR3)</strong>: expanded HCDR1 loop brings <strong>F29</strong> into the groove nearby for interacting with the hydrophobic pocket of H5</li></ul></li></ul><p>CDR2:</p><ul><li>CR9114: polar <strong>S52</strong><ul><li>internal H-bond with <strong>Y98</strong> (HCRD3) which can induce enlargement of the HCDR2 loop</li><li>HCDR2 loop of CR9114 can block a larger space at the binding groove of HAs, and several residues at this loop can interact with H3 HA F54-W21(H3),</li></ul></li><li>CR6261: hydrophobic <strong>I52</strong><ul><li>backbone atoms of <strong>I52</strong>-<strong>G55</strong>/<strong>T56</strong> and <strong>P52A</strong>-<strong>F54</strong> pair form H-bonds → small and rigid HCDR2 loop of CR6261</li></ul></li></ul><p>CDR3:</p><ul><li>CR9114: <sup>96</sup>GNYYYYSG<sup>100C</sup><ul><li>It establishes crucial H-bonds with H5 HA (<strong>Y98</strong>-Q42, <strong>Y98</strong>/<strong>Y100A</strong>-D19) and H3 HA (<strong>Y98</strong>-T41/Q42, <strong>Y100A</strong>-D19)</li><li>A short distance between <strong>Y99</strong> (CR9114) to the backbone atom of V18 can induce a strong charge-charge interaction between CR9114 and HAs</li></ul></li><li>CR6261: <sup>96</sup>MGYQVRET<sup>100C</sup><ul><li>only <strong>Y98</strong> can form an H-bond with a residue</li><li>Longer distances between CR6261 residues and HA residues V18 and D19 result in very weak interactions: 7-8 Å for <strong>Q99</strong>–V18 and 11 Å for <strong>R100A</strong>-D19</li></ul></li></ul><table><thead><tr><th style="text-align:center">Binding preference between CR9114 and CR6261</th></tr></thead><tbody><tr><td style="text-align:center"><img src="https://imgur.com/GCMw6iZ.png" alt="CR9114 and CR6261"></td></tr><tr><td style="text-align:center"><img src="https://imgur.com/3otr25H.png" alt="CR9114 and CR6261"></td></tr><tr><td style="text-align:center">Anna L. Beukenhorst; 2022<sup class="footnote-ref"><a href="#fn3" id="fnref3:1">[3:1]</a></sup></td></tr></tbody></table><ol start="6"><li>W62 and W65 in the heavy-chain framework region 2</li></ol><style>pre {  background-color: #38393d;  color: #5fd381;}ai {   color:  #3572A8;}</style><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>Wu N C, Wilson I A. Influenza hemagglutinin structures and antibody recognition[J]. Cold Spring Harbor perspectives in medicine, 2020, 10(8): a038778. <a href="#fnref1" class="footnote-backref">↩︎</a> <a href="#fnref1:1" class="footnote-backref">↩︎</a> <a href="#fnref1:2" class="footnote-backref">↩︎</a> <a href="#fnref1:3" class="footnote-backref">↩︎</a> <a href="#fnref1:4" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>Teo Q W, Wang Y, Lv H, et al. Stringent and complex sequence constraints of an IGHV1-69 broadly neutralizing antibody to influenza HA stem[J]. Cell Reports, 2023, 42(11). <a href="#fnref2" class="footnote-backref">↩︎</a> <a href="#fnref2:1" class="footnote-backref">↩︎</a> <a href="#fnref2:2" class="footnote-backref">↩︎</a> <a href="#fnref2:3" class="footnote-backref">↩︎</a> <a href="#fnref2:4" class="footnote-backref">↩︎</a> <a href="#fnref2:5" class="footnote-backref">↩︎</a> <a href="#fnref2:6" class="footnote-backref">↩︎</a> <a href="#fnref2:7" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>Beukenhorst A L, Frallicciardi J, Koch C M, et al. The influenza hemagglutinin stem antibody CR9114: Evidence for a narrow evolutionary path towards universal protection[J]. Frontiers in Virology, 2022, 2: 1049134. <a href="#fnref3" class="footnote-backref">↩︎</a> <a href="#fnref3:1" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">A concise overview of the CR9114 antibody&#39;s binding to influenza A viruses, highlighting its effectiveness and comparison with other antibodies.</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Notes/Biology/"/>
    
    <category term="Immunity" scheme="https://karobben.github.io/categories/Notes/Biology/Immunity/"/>
    
    
    <category term="Biology" scheme="https://karobben.github.io/tags/Biology/"/>
    
    <category term="Immunology" scheme="https://karobben.github.io/tags/Immunology/"/>
    
    <category term="Antibody" scheme="https://karobben.github.io/tags/Antibody/"/>
    
  </entry>
  
  <entry>
    <title>Understanding Antibodies and Phage Display: A Deep Dive</title>
    <link href="https://karobben.github.io/2023/10/31/LearnNotes/immun/"/>
    <id>https://karobben.github.io/2023/10/31/LearnNotes/immun/</id>
    <published>2023-10-31T18:45:08.000Z</published>
    <updated>2023-12-18T19:28:28.448Z</updated>
    
    <content type="html"><![CDATA[<h2 id="The-Magnificent-World-of-Antibodies"><strong>The Magnificent World of Antibodies</strong></h2><p>Antibodies, also known as immunoglobulins, are Y-shaped proteins produced by the immune system to neutralize foreign substances like bacteria and viruses. Let’s break down the components:</p><h3 id="Heavy-Chain-Light-Chain"><strong>Heavy Chain &amp; Light Chain</strong></h3><p>The basic structure of an antibody is composed of two identical heavy chains and two identical light chains. Each chain is a sequence of amino acids, which fold into a specific three-dimensional shape.</p><ul><li><p><strong>Heavy Chain (H)</strong>: The heavy chains are the larger of the two, and they form the base of the Y-shape. They play a pivotal role in determining the class of an antibody (like IgG, IgM, IgA, etc.).</p></li><li><p><strong>Light Chain (L)</strong>: The light chains pair with the heavy chains to form the arms of the Y-shaped antibody. Each antibody has one of two types of light chains - either kappa (κ) or lambda (λ).</p></li></ul><h3 id="Complementarity-Determining-Regions-CDR"><strong>Complementarity-Determining Regions (CDR)</strong></h3><table><thead><tr><th style="text-align:center"><img src="https://www.rapidnovor.com/wp-content/uploads/2022/04/Antibody-CDR-600x273.png" alt="CDR"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.rapidnovor.com/identifying-cdrs-antibody-sequencing/">Yuning Wang, PhD</a></td></tr></tbody></table><p>The tips of the “Y” arms contain a special region known as the CDR. This region is responsible for recognizing and binding to specific parts of foreign invaders, called antigens. Each antibody has six CDRs (three from the light chain and three from the heavy chain), which collectively determine its specificity. It’s like the “lock and key” model; the CDR is the lock, and the antigen is the key.</p><h2 id="The-Magic-of-Phage-Display"><strong>The Magic of Phage Display</strong></h2><p>Phage display is a high-throughput technology used to study protein-protein, protein-peptide, and protein-DNA interactions. It’s like a library, but instead of books, we have bacteriophages - viruses that infect bacteria.</p><h3 id="Basics-of-Phage-Display"><strong>Basics of Phage Display</strong></h3><table><thead><tr><th style="text-align:center"><img src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3656071/bin/hvi-8-1817-g1.jpg" alt="Different types of phage"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3656071/">© Justyna Bazan</a></td></tr></tbody></table><p>In phage display, a gene encoding a protein or peptide of interest is fused to a coat protein gene of a bacteriophage, causing the displayed protein to be expressed on the outside of the phage particle. This allows the protein to be physically linked to the genetic information that encodes it.</p><h3 id="Display-of-antibody-fragments"><strong>Display of antibody fragments</strong></h3><p>Typically, antibodies comprise two heavy chains and a pair of light chains interconnected through noncovalent bonds and disulfide bridges. However, unique antibodies without light chains, found in Camelidae serum, bind antigens using a specific V<sub>H</sub>H fragment. This fragment can recognize distinctive conformational epitopes due to its extended complementary-determining region 3 (CDR3).</p><p>Antibody fragments’ expression in E. coli necessitates in vivo refolding to maintain their activity and function. A method for soluble recombinant protein expression in the cytoplasm of the Origami DE3 E. coli strain has been introduced. This method enhances the folding of heterologous proteins dependent on disulfide bonds. Intriguingly, scFv expressed in the bacterial cytoplasm displayed superior binding characteristics compared to periplasmic expression. While periplasmic expression offers suitable conditions for V<sub>H</sub> and V<sub>L</sub> pairing, co-expression of periplasmic chaperones has shown to significantly impact soluble scFv productivity.</p><p>Various antibody fragments, including Fab, Fv, scFv, and their modifications, are employed in phage display technology. These fragments, particularly scFv, have been expressed on the phage surface without compromising antibody affinity. The CRAbs construct, comprising two scFv fragments targeting adjacent epitopes, is one notable example.</p><table><thead><tr><th style="text-align:center"><img src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3656071/bin/hvi-8-1817-g2.jpg" alt="Schematic presentation of antibody fragments"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3656071/">© Justyna Bazan</a>; Fab (the antigen-binding fragment), scFab (the single chain antigen-binding fragment), scFabΔC (the scFab variant without cysteins), scFv (the single chain fragment variable), Fv (the fragment variable), VHdAb (the antibody with one variable heavy chain domain), CRAb (the construct specific to adjacent epitopes on the antigen)</td></tr></tbody></table><table><thead><tr><th>Antibody Fragment</th><th>Description</th></tr></thead><tbody><tr><td><strong>Fab</strong></td><td>VH-CH and VL-CL segments linked by disulfide bonds. Used in tumor imaging.</td></tr><tr><td><strong>Fv</strong></td><td>Comprises only the VL and VH regions.</td></tr><tr><td><strong>scFv</strong></td><td>A commonly used antibody fragment consisting of VL and VH regions stabilized by (Gly4Ser)3 linker.</td></tr><tr><td><strong>VHH</strong></td><td>Unique fragment found in Camelidae serum antibodies, targeting unique conformational epitopes.</td></tr><tr><td><strong>CRAbs</strong></td><td>Construct with two scFv fragments specific to adjacent epitopes of the same antigen.</td></tr><tr><td><strong>Diabodies</strong></td><td>Formed by dimerization of molecules and connection of antibody fragments.</td></tr></tbody></table><h3 id="Technical-Details-of-Phage-Display"><strong>Technical Details of Phage Display</strong></h3><h4 id="1-Phage-Biology-Basics"><strong>1. Phage Biology Basics:</strong></h4><ul><li><strong>Bacteriophages</strong>, or phages, are viruses that infect bacteria. They are composed of a protein coat that encases their genetic material, which can be either DNA or RNA.</li><li>The life cycle of a phage includes attaching to a bacterial cell, injecting its genetic material, and then using the host’s machinery to replicate and produce new phage particles.</li></ul><h4 id="2-Fusion-Proteins-in-Phage-Display"><strong>2. Fusion Proteins in Phage Display:</strong></h4><ul><li>The principle behind phage display is the creation of <strong>fusion proteins</strong>. A gene of interest (encoding the protein or peptide to be displayed) is inserted into a phage coat protein gene, leading to the expression of a fusion protein on the phage surface.</li><li>Commonly used coat proteins for display include <strong>pIII</strong> and <strong>pVIII</strong> of the M13 filamentous phage.</li></ul><h4 id="3-Constructing-the-Library"><strong>3. Constructing the Library:</strong></h4><ul><li>A diverse collection of DNA sequences is cloned into phage vectors to produce a <strong>library</strong>. This library represents a vast array of different peptides or proteins displayed on the phage surface.</li><li>The library’s diversity can range from millions to billions of unique sequences, making it a powerful tool for screening.</li></ul><h4 id="4-Biopanning-and-Selection"><strong>4. Biopanning and Selection:</strong></h4><ul><li><strong>Biopanning</strong> is the iterative process of enriching phages that bind to a specific target from a diverse library.</li><li>The process involves incubating the phage library with a target (e.g., a protein, cell, or tissue), washing away non-binding phages, and then amplifying the bound phages by infecting bacteria. This cycle is typically repeated several times to enrich for high-affinity binders.</li></ul><h4 id="5-Elution-and-Analysis"><strong>5. Elution and Analysis:</strong></h4><ul><li>After the final round of biopanning, bound phages are eluted, often by changing pH or adding a competitive ligand.</li><li>The DNA from these phages is then sequenced to identify the displayed peptides or proteins. Modern techniques like <strong>next-generation sequencing</strong> can be used to analyze vast numbers of sequences simultaneously.</li></ul><h4 id="6-Applications-in-Drug-Discovery"><strong>6. Applications in Drug Discovery:</strong></h4><ul><li>Phage display is instrumental in <strong>antibody engineering</strong>. Therapeutic antibodies like adalimumab (Humira) were discovered using phage display.</li><li>It’s also used to discover peptide ligands for various targets, which can lead to the development of new drugs or diagnostic tools.</li></ul><h4 id="7-Challenges-and-Considerations"><strong>7. Challenges and Considerations:</strong></h4><ul><li>While phage display is a powerful tool, it’s essential to consider factors like the library’s quality and diversity, the stringency of washing steps during biopanning, and potential biases introduced during phage amplification.</li><li>Some proteins or peptides may not be displayed well on the phage surface due to folding issues or interference with phage assembly.</li></ul><h3 id="Advanced-Insights"><strong>Advanced Insights</strong></h3><ul><li><p><strong>Library Creation</strong>: Scientists can create vast libraries of phages displaying a diverse array of peptides or proteins. When looking for a needle in a haystack (like a specific antibody for a new disease), this library becomes invaluable.</p></li><li><p><strong>Biopanning</strong>: This is the process of selecting phages that bind to a specific target. The library is exposed to a target (like a protein receptor), and non-binding phages are washed away. Those that bind are amplified, creating a pool of potential candidates.</p></li><li><p><strong>Applications</strong>: Phage display has revolutionized medicine, especially in the field of drug discovery. It’s instrumental in identifying therapeutic antibodies, understanding disease mechanisms, and even vaccine development.</p></li></ul><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Understanding Antibodies and Phage Display: A Deep Dive</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Notes/Biology/"/>
    
    <category term="Immunity" scheme="https://karobben.github.io/categories/Notes/Biology/Immunity/"/>
    
    
    <category term="Biology" scheme="https://karobben.github.io/tags/Biology/"/>
    
    <category term="Immunology" scheme="https://karobben.github.io/tags/Immunology/"/>
    
    <category term="Antibody" scheme="https://karobben.github.io/tags/Antibody/"/>
    
  </entry>
  
  <entry>
    <title>Understanding PacBio Sequencing: A Deep Dive for RNA-Seq Enthusiasts</title>
    <link href="https://karobben.github.io/2023/10/30/Bioinfor/PacBio/"/>
    <id>https://karobben.github.io/2023/10/30/Bioinfor/PacBio/</id>
    <published>2023-10-30T21:02:46.000Z</published>
    <updated>2023-10-31T16:44:50.974Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><strong>Introduction</strong>:</h2><p>For the seasoned RNA-Seq explorer, diving into the intricate realms of next-generation sequencing might be routine. But have you paused to marvel at PacBio sequencing, weighing its merits against other sequencing champions? Join us as we unravel PacBio’s mysteries, juxtapose it with its peers, and delve into its data analysis intricacies.</p><h2 id="What-is-PacBio-Sequencing"><strong>What is PacBio Sequencing?</strong></h2><table><thead><tr><th style="text-align:center"><img src="https://www.liebertpub.com/cms/10.1089/gen.36.20.03/asset/images/medium/gen.36.20.03.g001.png" alt="PacBio Sequencing"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.liebertpub.com/doi/10.1089/gen.36.20.03">© </a></td></tr></tbody></table><p>Pacific Biosciences, fondly termed PacBio, is the stalwart behind the long-read sequencing revolution. Standing distinct from short-read sequencers, PacBio devices unfurl considerably elongated reads, paving the path for precise assembly and a simplified data analysis voyage.</p><h2 id="PacBio-vs-Other-Sequencing-Technologies"><strong>PacBio vs. Other Sequencing Technologies</strong>:</h2><ul><li><p><strong>Short-Read Sequencing (e.g., Illumina)</strong>:</p><ul><li><em>Advantages</em>: High-throughput capabilities, economical for grand-scale endeavors, and a rich arsenal of tried-and-tested data tools.</li><li><em>Disadvantages</em>: The brevity of reads can muddle the assembly of repetitive domains and hinder the detection of structural variants.</li></ul></li><li><p><strong>PacBio (Long-Read Sequencing)</strong>:</p><ul><li><em>Advantages</em>: Its prowess in reading extensive DNA fragments simplifies genome assembly and eases the identification of structural variants. A boon, particularly for genomes riddled with repetitive sequences.</li><li><em>Disadvantages</em>: A compromise on throughput in comparison to short-read sequencing and a heftier price tag.</li></ul></li><li><p><strong>Nanopore Sequencing (e.g., Oxford Nanopore Technologies)</strong>:</p><ul><li><em>Advantages</em>: Astoundingly long reads, compact devices, and real-time sequencing insights.</li><li><em>Disadvantages</em>: A trade-off in accuracy vis-à-vis PacBio and an evolving, thus unpredictable, tech landscape.</li></ul></li></ul><h2 id="PacBio-Sequencing-Process">PacBio Sequencing Process</h2><table><thead><tr><th style="text-align:center"><img src="https://www.researchgate.net/profile/Chloe-Baum/publication/357946568/figure/fig2/AS:1114137841143808@1642642569421/Principle-of-Single-molecule-real-time-SMRT-sequencing-from-PacBio-Goodwin-McPherson.png" alt="PacBio"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.researchgate.net/publication/357946568_New_approaches_and_concepts_to_study_complex_microbial_communities?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6Il9kaXJlY3QiLCJwYWdlIjoicHVibGljYXRpb24iLCJwcmV2aW91c1BhZ2UiOiJfZGlyZWN0In19">© Chloé Baum</a></td></tr></tbody></table><p>Video Tutorial:<br>- <a href="https://www.youtube.com/watch?v=_lD8JyAbwEo">PacBio</a><br>- <a href="https://www.youtube.com/watch?v=-nOr5B_bF3A">RobEdwards; SDSU</a></p><p><strong>1. SMRTbell Template Preparation</strong>:</p><ul><li>DNA is fragmented to the desired length, typically ranging from a few kilobases to over 20 kb.</li><li>Fragmented DNA is treated to create blunt ends.</li><li>Hairpin adaptors, called SMRTbell adaptors, are ligated to these blunt ends. This results in the formation of SMRTbell templates which are essentially circular molecules of DNA.</li></ul><p><strong>2. Primer Annealing and DNA Polymerase Binding</strong>:</p><ul><li>A sequencing primer is annealed to the SMRTbell template.</li><li>High-fidelity DNA polymerase is then bound to the primer-annealed SMRTbell template.</li></ul><p><strong>3. Loading onto SMRT Cells</strong>:</p><ul><li>The polymerase-bound SMRTbell templates are loaded onto SMRT Cells. A SMRT Cell contains up to millions of zero-mode waveguides (ZMWs).</li><li>Only a fraction of ZMWs capture a polymerase-bound SMRTbell, ensuring each ZMW contains a single molecule.</li></ul><p><strong>4. Zero-Mode Waveguides (ZMWs)</strong>:</p><ul><li>ZMWs are nanophotonic structures that allow observation of individual fluorophores attached to nucleotides.</li><li>They work by confining the observation volume to a zeptoliter level, thereby enabling the detection of single-molecule fluorescence while excluding background fluorescence.</li></ul><p><strong>5. Sequencing by Synthesis</strong>:</p><ul><li>The sequencing reaction involves the incorporation of fluorescently labeled nucleotides by the DNA polymerase.</li><li>Each of the four DNA bases (A, T, C, G) is attached to a distinct fluorescent dye. As the polymerase adds a nucleotide to the growing DNA strand, the attached dye briefly fluoresces.</li><li>The order in which these dyes fluoresce, as observed in real-time from the bottom of ZMWs, corresponds to the sequence of the template.</li></ul><p><strong>6. Continuous Long Reads</strong>:</p><ul><li>Due to the circular nature of the SMRTbell templates, the DNA polymerase can continue to sequence in a rolling-circle manner, producing long continuous reads from the same template.</li></ul><p><strong>7. Pulse Detection and Base Calling</strong>:</p><ul><li>The raw output from the sequencing process is a series of fluorescence pulses over time.</li><li>Sophisticated algorithms analyze these pulses to detect and differentiate the fluorescent signals from each other and from the background noise.</li><li>These detected pulses are then converted into a sequence of nucleotide bases, resulting in raw sequence reads.</li></ul><p><strong>8. Circular Consensus Sequencing (CCS)</strong>:</p><ul><li>Since the polymerase can sequence the same SMRTbell template multiple times, it generates several subreads from the same molecule.</li><li>These subreads are aligned and a consensus sequence is called, enhancing the accuracy of the read by averaging out the random errors.</li></ul><h2 id="PacBio-Data-Analysis-Pipeline"><strong>PacBio Data Analysis Pipeline</strong>:</h2><p>From raw data collation on PacBio devices to insightful report generation, the pipeline comprises:</p><hr><p><strong>PacBio Data Analysis Pipeline: A Detailed Overview</strong></p><ol><li><p><strong>Raw Data Collection</strong>:</p><ul><li><em>Process</em>: The sequencing run on a PacBio machine produces raw data files.</li><li><em>Output</em>: Files in formats like <code>.h5</code> or <code>.bam</code> which encapsulate raw sequence reads, quality scores, and other metadata.</li></ul></li><li><p><strong>Read Filtering and Quality Control</strong>:</p><ul><li><em>Process</em>: Before analysis, raw reads undergo filtering to remove unwanted sequences.</li><li><em>Tools</em>: <code>pbccs</code> (Circular Consensus Sequencing) refines raw subreads to generate high-quality consensus sequences.</li><li><em>Output</em>: Filtered and high-quality sequence reads ready for further analysis.</li></ul></li><li><p><strong>Genome Assembly (if de novo sequencing)</strong>:</p><ul><li><em>Process</em>: Assembling the filtered reads into contiguous sequences or “contigs”.</li><li><em>Tools</em>:<ul><li><code>Canu</code>: Corrects, trims, and assembles in one go.</li><li><code>Flye</code>: Known for speed and scalability.</li><li><code>HGAP</code>: PacBio’s native assembler, optimized for their data.</li></ul></li><li><em>Output</em>: Genome assembly in the form of contigs or scaffolds.</li></ul></li><li><p><strong>Mapping (if resequencing)</strong>:</p><ul><li><em>Process</em>: Aligning or “mapping” the reads to a reference genome.</li><li><em>Tools</em>:<ul><li><code>pbmm2</code>: Tailored for PacBio data.</li><li><code>minimap2</code>: Versatile and can align both PacBio and Oxford Nanopore data.</li></ul></li><li><em>Output</em>: Alignment file, typically in BAM or SAM format.</li></ul></li><li><p><strong>Variant Calling</strong>:</p><ul><li><em>Process</em>: Post alignment, identify differences or “variants” between the sequenced data and the reference genome.</li><li><em>Tools</em>:<ul><li><code>DeepVariant</code>: Uses deep learning for interpretation.</li><li><code>PBSV</code>: PacBio’s variant caller, adept at detecting larger structural variants.</li></ul></li><li><em>Output</em>: List of variants, typically in VCF format.</li></ul></li><li><p><strong>Annotation and Analysis</strong>:</p><ul><li><em>Process</em>: Predicting genes, proteins, and other genomic elements in the assembled genome or called variants.</li><li><em>Tools</em>:<ul><li><code>Prokka</code> (for prokaryotes)</li><li><code>AUGUSTUS</code> (for eukaryotes)</li></ul></li><li><em>Output</em>: Annotated genome with predicted genes, regulatory elements, and other features.</li></ul></li><li><p><strong>Visualization</strong>:</p><ul><li><em>Process</em>: Visual representation of the data for easier interpretation.</li><li><em>Tools</em>:<ul><li><code>IGV</code> (Integrative Genomics Viewer)</li><li><code>GenomeBrowse</code></li><li><code>Circos</code></li></ul></li><li><em>Output</em>: Graphical representation of the data, such as genome maps, variant plots, etc.</li></ul></li><li><p><strong>Downstream Analysis</strong>:</p><ul><li><em>Process</em>: Additional analyses based on the research question.<ul><li>Comparative genomics: Comparing with other genomes.</li><li>Transcriptomics: Gene expression analysis.</li><li>Metagenomics: Analyzing community composition in mixed samples.</li></ul></li><li><em>Output</em>: Specific insights or findings related to the research question.</li></ul></li><li><p><strong>Report Generation</strong>:</p><ul><li><em>Process</em>: Compiling all findings, methodologies, and conclusions into a comprehensive report.</li><li><em>Output</em>: Detailed report ready for review, publication, or sharing with stakeholders.</li></ul></li></ol><hr><p>This detailed pipeline provides a roadmap for PacBio data analysis, guiding researchers through each stage and ensuring that they obtain meaningful and actionable insights from their data.</p><h2 id="The-different-output-formats">The different output formats</h2><table><thead><tr><th><strong>Dimension</strong></th><th><strong>.h5 Format</strong></th><th><strong>.bam Format</strong></th></tr></thead><tbody><tr><td><strong>Definition</strong></td><td>A hierarchical data format designed to store and organize large amounts of data.</td><td>The binary version of a Sequence Alignment/Map (SAM) format, used to store aligned sequence data.</td></tr><tr><td><strong>Usage in PacBio</strong></td><td>Earlier PacBio sequencing runs produced <code>.h5</code> files as raw output.</td><td>Used as a standard format for storing aligned PacBio reads.</td></tr><tr><td><strong>File Size</strong></td><td>Generally larger due to the comprehensive information it contains about the sequencing run, including raw pulse and signal data.</td><td>Compressed and therefore more compact than its SAM counterpart. Size depends on the depth of sequencing.</td></tr><tr><td><strong>Content</strong></td><td>Contains raw sequence data, quality metrics, and other metadata about the sequencing run.</td><td>Contains aligned sequence reads, quality scores, and alignment information against a reference genome.</td></tr><tr><td><strong>Advantages</strong></td><td>Comprehensive: Contains raw data and additional metadata which can be useful for in-depth analysis.</td><td>Standardized: Widely accepted in bioinformatics pipelines and tools. Efficient storage with indexed access to alignments.</td></tr><tr><td><strong>Disadvantages</strong></td><td>File size can be substantial. Requires specific tools to extract relevant data.</td><td>Does not contain the raw signal or pulse data, only the resultant sequence and its alignment.</td></tr><tr><td><strong>Associated Tools</strong></td><td>PacBio’s SMRT Analysis software can work with <code>.h5</code> files.</td><td>Numerous tools available, e.g., <code>SAMtools</code>, <code>Picard</code>, and many bioinformatics pipelines accept <code>.bam</code> files.</td></tr><tr><td><strong>Interoperability</strong></td><td>More specific to PacBio’s technology and less commonly used in generic bioinformatics pipelines.</td><td>Highly interoperable and recognized as a standard format in genomics.</td></tr></tbody></table><p>Both <code>.h5</code> and <code>.bam</code> formats have their specific utilities in the realm of PacBio sequencing. While <code>.h5</code> offers a deeper dive into the raw data and sequencing intricacies, <code>.bam</code> provides a streamlined, standardized format for aligned sequence data, making it more amenable to various bioinformatics analyses.</p><h2 id="Spotlight-on-Tools-A-Comparative-Table"><strong>Spotlight on Tools: A Comparative Table</strong></h2><table><thead><tr><th><strong>Tool</strong></th><th><strong>Type</strong></th><th><strong>Advantages</strong></th><th><strong>Disadvantages</strong></th></tr></thead><tbody><tr><td><strong>Canu</strong></td><td>Genome Assembler</td><td>Tailored for high-noise single-molecule sequencing. All-in-one: corrects, trims, and assembles.</td><td>Resource-intensive; demands hefty computational power.</td></tr><tr><td><strong>Flye</strong></td><td>Genome Assembler</td><td>Efficient for PacBio &amp; Oxford Nanopore. Speedy and scalable.</td><td>Might struggle with highly repetitive genomes.</td></tr><tr><td><strong>HGAP</strong></td><td>Genome Assembler</td><td>PacBio’s native. Stellar for microbial genomes.</td><td>Challenges with mammoth genomes. Demands high coverage.</td></tr><tr><td><strong>pbmm2</strong></td><td>Mapping Tool</td><td>Custom-made for PacBio data. Handles long-read errors well.</td><td>PacBio-specific; lacks versatility.</td></tr><tr><td><strong>minimap2</strong></td><td>Mapping Tool</td><td>Swift and versatile. Aligns both PacBio and Oxford Nanopore data.</td><td>Optimal results might need parameter fine-tuning.</td></tr><tr><td><strong>DeepVariant</strong></td><td>Variant Caller</td><td>Harnesses deep learning for high accuracy. Adapted for long-reads.</td><td>Computationally taxing. Might be overwhelming for ML novices.</td></tr><tr><td><strong>PBSV</strong></td><td>Variant Caller</td><td>Fine-tuned for PacBio. Excels in detecting large structural variants.</td><td>Exclusively for PacBio data.</td></tr></tbody></table><hr><h2 id="Conclusion"><strong>Conclusion</strong>:</h2><p>While RNA-Seq has its allure, navigating the PacBio seas can offer refreshing insights. With its long-read capabilities, PacBio emerges as a formidable contender in the sequencing arena. As with every tech marvel, it presents both opportunities and challenges. Yet, armed with the right tools and insights, one can sail smoothly through the PacBio waters, discovering genomic treasures along the way.</p><p>To sequencing and beyond!</p><h2 id="More-to-know">More to know</h2><h3 id="What-is-flank-sequence">What is flank sequence</h3><p>In the context of PacBio sequencing, “flanking sequences” or “flanks” often refer to the sequences on <mark>either side of a particular region of interest within the DNA</mark>. These regions can be particularly important in various analyses such as structural variation detection, insertions, deletions, or when identifying the context of a specific mutation or sequence feature.</p><p>However, when referring to “flank sequences” in relation to PacBio’s SMRTbell library preparation, it has a more specific meaning. For PacBio SMRT sequencing, the DNA of interest is ligated to hairpin adapters at both ends, creating a SMRTbell template. These hairpin adapters allow the DNA polymerase to read the same molecule multiple times, moving in a circular fashion. <mark>The sequences directly adjacent to these adapters on the SMRTbell template are often referred to as the “flanking sequences”.</mark></p><p>These flanking sequences are typically removed during data processing to retain only the sequence of interest. In the context of the raw PacBio reads, you might sometimes see remnants of these adapter sequences or the flanking regions, especially if there was any inefficiency in the adapter trimming process.</p><p>If you’re dealing with PacBio data and want to identify or remove such sequences, tools and workflows provided by PacBio, such as the SMRT Link software suite, can help in the adapter trimming and filtering process.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Deep dive into PacBio sequencing, its comparison with other methods, and an in-depth look into its data analysis pipeline.</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="NGS" scheme="https://karobben.github.io/tags/NGS/"/>
    
    <category term="PacBio" scheme="https://karobben.github.io/tags/PacBio/"/>
    
  </entry>
  
  <entry>
    <title>ATAC-seq: A Powerful Tool for Mapping Gene Regulation</title>
    <link href="https://karobben.github.io/2023/10/20/Bioinfor/ATAC-Seq/"/>
    <id>https://karobben.github.io/2023/10/20/Bioinfor/ATAC-Seq/</id>
    <published>2023-10-20T17:18:48.000Z</published>
    <updated>2023-10-30T21:46:45.529Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction">Introduction:</h2><p>The regulation of gene expression is a complex process that involves the interplay of various factors, including transcription factors, enhancers, promoters, and silencers. Understanding the dynamics of gene regulation is essential for unraveling the mysteries of cellular development, differentiation, and disease progression. To address this challenge, researchers have developed a powerful tool called ATAC-seq, which enables the mapping of gene regulation at an unprecedented scale and resolution. In this blog, we will delve into the world of ATAC-seq and explore its applications, advantages, and limitations.<br>What is ATAC-seq?</p><p>ATAC-seq (Assay for Transposase-Accessible Chromatin sequencing) is a genomic technique that allows researchers to profile the open chromatin regions in a given cell type. Open chromatin regions are those that are accessible to a transposase enzyme, which is used to fragment the chromatin into smaller pieces. The resulting fragments are then sequenced, producing a map of open chromatin regions across the genome.</p><p><img src="https://imgur.com/SL59NJU.png" alt="ATAC-Seq"></p><h3 id="Principle">Principle:</h3><p>The principle behind ATAC-seq is straightforward. The assay involves the following steps:</p><ol><li>Crosslinking: Cells are fixed with formaldehyde to create covalent bonds between proteins and DNA.</li><li>Shearing: Chromatin is sheared into smaller fragments using a transposase enzyme.</li><li>End repair and A-tailing: The 3’ ends of the fragmented DNA are repaired and modified to generate blunt ends.</li><li>Sequencing library preparation: The modified DNA fragments are then prepared for sequencing using standard library preparation protocols.</li><li>Sequencing: The sequencing step generates millions of reads that are then mapped back to the reference genome.</li></ol><h3 id="Advantages">Advantages:</h3><ol><li><strong>High resolution</strong>: ATAC-seq offers high resolution mapping of open chromatin regions, allowing researchers to identify regulatory elements at a genomic scale.</li><li><strong>Sensitivity</strong>: The technique is highly sensitive, capable of detecting rare regulatory elements that would be missed by other methods.</li><li><strong>Cost-effective</strong>: ATAC-seq is relatively cost-effective compared to other techniques such as ChIP-seq, which requires expensive antibodies and specialized equipment.</li><li><strong>Genome-wide analysis</strong>: ATAC-seq allows for genome-wide analysis of open chromatin regions, enabling researchers to identify patterns and trends in gene regulation.</li><li><strong>Identification of novel regulatory elements</strong>: ATAC-seq can identify novel regulatory elements that were previously unknown or unannotated, providing new insights into gene regulation.</li><li><strong>Investigation of gene regulation in specific cell types or tissues</strong>: ATAC-seq can be used to study gene regulation in specific cell types or tissues, providing valuable insights into cellular differentiation and development.</li><li><strong>Identification of disease-associated regulatory elements</strong>: ATAC-seq can be used to identify regulatory elements that are associated with diseases, providing new targets for therapeutic intervention.</li><li><strong>Monitoring of gene regulation changes over time</strong>: ATAC-seq can be used to monitor changes in gene regulation over time, providing insights into how gene regulation dynamics contribute to cellular processes.</li></ol><h3 id="Limitations">Limitations:</h3><ol><li>Limited to accessible chromatin regions: ATAC-seq only maps open chromatin regions that are accessible to the transposase enzyme, which means that closed chromatin regions remain unmapped.</li><li>Biases in sequencing libraries: Sequencing libraries can introduce biases in the form of overrepresented or underrepresented regions, which can impact downstream analyses.</li><li><mark>Interpretation challenges</mark>: Interpreting ATAC-seq data requires advanced computational skills and knowledge of bioinformatics tools and methods.</li><li>Limited spatial resolution: ATAC-seq provides a snapshot of open chromatin regions at a particular time point, but does not provide information on the <mark>spatial organization</mark> of regulatory elements.</li></ol><h3 id="Applications">Applications:</h3><ol><li>Stem cell biology: ATAC-seq has been used to study the gene regulation landscape in stem cells, providing insights into <mark>pluripotency</mark> and <mark>lineage commitment</mark>.</li><li>Cancer research: ATAC-seq has been applied to cancer research, identifying regulatory elements that are associated with tumor progression and metastasis.</li><li><strong>Developmental biology</strong>: ATAC-seq has been used to study the gene regulation landscape in the brain, providing insights into neural development, synaptic plasticity, and neurological disorders.</li><li>Immunology: ATAC-seq has been applied to the study of immune cells, revealing regulatory elements that control immune cell function and differentiation.</li><li>Plant biology: ATAC-seq has been used to study gene regulation in plants, providing insights into plant development, stress response, and photosynthesis.</li><li>Microbiology: ATAC-seq has been used to study gene regulation in microbes, including bacteria and yeast, providing insights into the regulation of virulence factors and drug resistance.</li><li>Drug discovery: ATAC-seq can be used to identify potential drug targets by analyzing the regulatory elements that control gene expression in diseased cells.</li><li>Personalized medicine: ATAC-seq can be used to study gene regulation in individual patients, providing insights into personalized therapies and treatment strategies.</li><li>Synthetic biology: ATAC-seq can be used to design and engineer gene circuits for synthetic biology applications, such as biofuels, drugs, and other valuable compounds.</li></ol><h2 id="Summary">Summary</h2><p>In summary, ATAC-seq is a powerful tool for studying gene regulation and has a wide range of applications in various fields, from basic research to drug discovery and personalized medicine.</p><h2 id="Pipelines-for-ATAC-Seq">Pipelines for ATAC-Seq</h2><ul><li><a href="https://www.encodeproject.org/atac-seq/#overview">Encodeproject: ATAC-seq Data Standards and Processing Pipeline</a></li><li><a href="https://github.com/ENCODE-DCC/atac-seq-pipeline">ENCODE-DCC/atac-seq-pipeline</a></li><li><a href="https://yiweiniu.github.io/blog/2019/03/ATAC-seq-data-analysis-from-FASTQ-to-peaks/">Yiwei niu; 2019: ATAC-seq data analysis: from FASTQ to peaks</a></li><li><a href="https://informatics.fas.harvard.edu/atac-seq-guidelines.html">John M. Gaspar; 2019; ATAC-seq Guidelines</a></li><li><a href="https://training.galaxyproject.org/training-material/topics/epigenetics/tutorials/atac-seq/tutorial.html">Lucille Delisle; 2023; ATAC-Seq data analysis</a></li></ul><h3 id="Data-Analysis-Pipeline">Data Analysis Pipeline</h3><p>According to Fen Yan<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup></p><ul><li><strong>pre-analysis</strong>: quality check and alignment</li><li><strong>core analysis</strong>: peak calling</li><li><strong>advanced analysis</strong>:<ul><li>peak differential analysis and annotation<ul><li>no differential peak analysis tools have been specifically developed</li></ul></li><li>motif enrichment</li><li>footprinting</li><li>nucleosome position analysis</li></ul></li></ul><table><thead><tr><th style="text-align:center"><img src="https://media.springernature.com/full/springer-static/image/art%3A10.1186%2Fs13059-020-1929-3/MediaObjects/13059_2020_1929_Fig4_HTML.png" alt="ATAC-Seq"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-1929-3/figures/4">Fen Yan</a></td></tr></tbody></table><style>pre {  background-color:#38393d;  color: #5fd381;}</style><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>Yan, F., Powell, D.R., Curtis, D.J. et al. From reads to insight: a hitchhiker’s guide to ATAC-seq data analysis. Genome Biol 21, 22 (2020). <a href="https://doi.org/10.1186/s13059-020-1929-3">https://doi.org/10.1186/s13059-020-1929-3</a> <a href="#fnref1" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">ATAC-seq: A powerful tool for studying gene regulation and its applications in various fields, including stem cell biology, cancer research, neurobiology, immunology, plant biology, microbiology, drug discovery, personalized medicine, and synthetic biology.</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="NGS" scheme="https://karobben.github.io/tags/NGS/"/>
    
    <category term="ATAC-Seq" scheme="https://karobben.github.io/tags/ATAC-Seq/"/>
    
  </entry>
  
  <entry>
    <title>Pseudotime Analysis with Monocle: A Beginner&#39;s Guide</title>
    <link href="https://karobben.github.io/2023/10/19/Bioinfor/scMonocle/"/>
    <id>https://karobben.github.io/2023/10/19/Bioinfor/scMonocle/</id>
    <published>2023-10-20T03:11:22.000Z</published>
    <updated>2023-10-22T00:27:31.459Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Psudotime-Analysis">Psudotime Analysis</h2><h3 id="Introduction">Introduction</h3><p>In the complex world of cellular dynamics and differentiation, tracking the progression of individual cells can seem like tracking a grain of sand on a beach. Fortunately, pseudotime analysis using tools like Monocle has made it more accessible. But what is pseudotime? And why should we use Monocle for it? Let’s dive in.</p><h3 id="What-is-Pseudotime">What is Pseudotime?</h3><p>Pseudotime is a computational concept used to order cells based on their progression in a particular process, like differentiation. Rather than relying on actual time (which isn’t available in static single-cell datasets), pseudotime arranges cells in a continuum that reflects their progression state. In simple words, it’s like retracing the journey of a cell from its starting point to its destination, based on markers or genes it expresses.</p><h3 id="Why-Do-We-Use-Pseudotime-Analysis">Why Do We Use Pseudotime Analysis?</h3><p>Mode details in <a href="https://cole-trapnell-lab.github.io/monocle-release/docs/#constructing-single-cell-trajectories">Monocle</a></p><ol><li><p><strong>Choosing Genes for Trajectory</strong>: Monocle selects genes that define cellular progress for its machine learning approach. This feature selection is vital as it impacts the trajectory shape. While some low-expressed genes can be noisy, they might hold essential cellular information. Monocle identifies genes with meaningful variations to structure the data. Users can either let Monocle autonomously choose genes (unsupervised) or input known genes to guide the trajectory (semi-supervised).</p></li><li><p><strong>Dimensionality Reduction</strong>: After gene selection, Monocle reduces the data’s dimensionality using the Reversed Graph Embedding algorithm.</p></li><li><p><strong>Pseudotime Cell Ordering</strong>: Monocle projects expression data into a reduced dimension space to determine the cellular trajectory. It presumes a tree-structured trajectory with a root and leaves. Monocle’s objective is to best fit this tree to the data. Cells begin at the root and move along the trajectory, making decisions at branches until reaching a leaf. A cell’s pseudotime is the distance from its position back to the root.</p></li></ol><h3 id="How-Does-Monocle-Work">How Does Monocle Work?</h3><p>Monocle stands out in the world of pseudotime analysis because of its robustness and flexibility. Here’s a simplified overview of how it functions:</p><ol><li><p><strong>Expression Data Input</strong>: Monocle takes in single-cell RNA-sequencing data. Each cell’s gene expression profile serves as a unique identifier of its state.</p></li><li><p><strong>Dimensionality Reduction</strong>: The vastness of gene expression data is reduced into manageable dimensions using techniques like DDRTree or UMAP.</p></li><li><p><strong>Trajectory Construction</strong>: Using the reduced dimensions, Monocle constructs a trajectory that orders cells based on their progression.</p></li><li><p><strong>Pseudotime Assignment</strong>: Cells are then assigned a pseudotime value based on their position in the trajectory.</p></li></ol><h3 id="What-Makes-Monocle-Special">What Makes Monocle Special?</h3><p>Several tools offer pseudotime analysis, but Monocle has some distinct advantages:</p><ol><li><p><strong>Handling Complex Trajectories</strong>: Monocle can discern branched trajectories, which is crucial when cells can differentiate into multiple types.</p></li><li><p><strong>Flexibility</strong>: It is amenable to various types of analyses beyond just pseudotime, such as differential expression analysis across trajectories.</p></li></ol><h3 id="Comparison-with-Other-Techniques">Comparison with Other Techniques</h3><ul><li><p><strong>Monocle vs. Wanderlust</strong>: While both are used for trajectory analysis, Wanderlust was primarily designed for mass cytometry data. Monocle offers a more generalized approach, suitable for scRNA-seq data.</p></li><li><p><strong>Monocle vs. Slingshot</strong>: Slingshot is another tool for pseudotime analysis of scRNA-seq data. While Slingshot excels in simplicity and user-friendly plotting functions, Monocle’s capability to handle more complex trajectories gives it an edge in certain scenarios.</p></li></ul><h3 id="Pros-and-Cons-of-Using-Monocle">Pros and Cons of Using Monocle</h3><p><strong>Advantages</strong>:</p><ul><li>Robust in handling complex cellular trajectories.</li><li>Suitable for various analyses.</li><li>Well-documented and supported by an active community.</li></ul><p><strong>Disadvantages</strong>:</p><ul><li>Might have a steeper learning curve for beginners.</li><li>Certain computations can be time-intensive.</li></ul><h3 id="Conclusion">Conclusion</h3><p>Pseudotime analysis using Monocle offers a deep dive into cellular dynamics, helping researchers unravel mysteries of cell fate decisions, disease progression, and more. While it’s one of many tools available, its capability to deal with complexity makes it a choice worth considering. Like any tool, its efficacy is determined by the skill and knowledge of the user, so if you’re looking to use Monocle, investing time in understanding its nuances will be immensely rewarding.</p><h2 id="Pepeline-from-Seurat-to-Monocle">Pepeline from Seurat to Monocle</h2><p>First, we need to use the <code>SeuratWrappers</code> library to conver the Seurat object into Monocle manageble data<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r"><span class="hljs-comment"># remotes::install_github(&#x27;cole-trapnell-lab/monocle3&#x27;)</span><br>library(Signac)<br>library(Seurat)<br>library(SeuratWrappers)<br>library(monocle3)<br>library(Matrix)<br>library(ggplot2)<br>library(patchwork)<br><br>erythroid.cds &lt;- as.cell_data_set(seurat_object)<br>erythroid.cds &lt;- cluster_cells(cds = erythroid.cds, reduction_method = <span class="hljs-string">&quot;UMAP&quot;</span>)<br><span class="hljs-comment"># try a subset if R is killed due to lack of RAM </span><br>erythroid.cds &lt;- learn_graph(erythroid.cds, use_partition = <span class="hljs-literal">TRUE</span>)<br><br><span class="hljs-comment"># select the root cell (a list of cell tags)</span><br>hsc &lt;- readLines(<span class="hljs-string">&quot;../vignette_data/hsc_cells.txt&quot;</span>)<br>erythroid.cds &lt;- order_cells(erythroid.cds, reduction_method = <span class="hljs-string">&quot;UMAP&quot;</span>, root_cells = hsc)<br><br><br>plot_cells(<br>  cds = erythroid.cds,<br>  color_cells_by = <span class="hljs-string">&quot;pseudotime&quot;</span>,<br>  show_trajectory_graph = <span class="hljs-literal">TRUE</span><br>)<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://stuartlab.org/signac/articles/monocle_files/figure-html/unnamed-chunk-18-1.png" alt="Psudotime Analysis"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://stuartlab.org/signac/articles/monocle">MonoCle</a></td></tr></tbody></table><style>pre {  background-color:#38393d;  color: #5fd381;}</style><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p><a href="https://stuartlab.org/signac/articles/monocle">2023; <code>Signac</code>; Building trajectories with Monocle 3<br></a> <a href="#fnref1" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">Introductory guide to pseudotime analysis using Monocle. Explore the significance of cellular trajectories in single-cell RNA-sequencing data and compare Monocle&#39;s capabilities with other tools.</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Single Cell" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Single-Cell/"/>
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="RNA-Seq" scheme="https://karobben.github.io/tags/RNA-Seq/"/>
    
    <category term="scRNA-Seq" scheme="https://karobben.github.io/tags/scRNA-Seq/"/>
    
  </entry>
  
  <entry>
    <title>Integrating scRNA-Seq and scATAC-Seq Data: A Primer</title>
    <link href="https://karobben.github.io/2023/10/16/Bioinfor/scATAC/"/>
    <id>https://karobben.github.io/2023/10/16/Bioinfor/scATAC/</id>
    <published>2023-10-16T18:43:24.000Z</published>
    <updated>2023-10-22T00:51:02.511Z</updated>
    
    <content type="html"><![CDATA[<p>Single-cell sequencing technologies have revolutionized our understanding of cellular heterogeneity. Among these technologies, scRNA-Seq and scATAC-Seq stand out for their ability to profile gene expression and chromatin accessibility, respectively. But how can we integrate these two types of data to gain a more comprehensive view of cellular states? Let’s dive in!</p><p>Other tutorial: <a href="https://satijalab.org/seurat/articles/atacseq_integration_vignette">Seurat tutorial</a></p><h2 id="Understanding-the-Data"><strong>Understanding the Data</strong></h2><ul><li><p><strong>scRNA-Seq</strong>: Provides gene expression levels in individual cells. The resulting matrix has genes as rows and cells as columns, with values representing gene expression levels.</p></li><li><p><strong>scATAC-Seq</strong>: Profiles chromatin accessibility at specific genomic regions. The resulting matrix has genomic regions (peaks) as rows and cells as columns, with binary values indicating accessibility.</p></li></ul><h3 id="The-Challenge"><strong>The Challenge</strong></h3><p>At first glance, these matrices seem incompatible. One provides gene-centric information, while the other is focused on genomic regions. So, how can we integrate them?</p><h3 id="From-Peaks-to-Genes"><strong>From Peaks to Genes</strong></h3><p>A common approach is to associate scATAC-Seq peaks with nearby genes. This can transform the scATAC-Seq matrix into a gene-by-cell matrix, similar to scRNA-Seq. Strategies include:</p><ul><li>Assigning each peak to the nearest gene’s transcription start site (TSS).</li><li>Using tools that provide more sophisticated peak-to-gene assignment methods.</li></ul><h2 id="Integration-Using-Latent-Spaces"><strong>Integration Using Latent Spaces</strong></h2><p>Tools like Seurat don’t directly merge the matrices. Instead, they:</p><ol><li>Identify shared “latent spaces” or underlying patterns in the data.</li><li>Find features (genes) that are highly variable in both datasets to serve as “anchors.”</li><li>Use these anchors to align the datasets in a shared latent space.</li></ol><p>Once integrated, joint analyses, such as clustering, can identify cell types present in both datasets.</p><h2 id="Example-Integration-Workflow"><strong>Example Integration Workflow</strong></h2><h3 id="From-Peak-to-Seurat-Object">From Peak to Seurat Object</h3><p>A Seurat Object for ATAC data need more things than RNA matrix.</p><ul><li>Except peak matrix as the <code>ChromatinAssay</code> object,</li><li>we still need to ready the Chromosome annatation file for gene activity estimation.</li><li>We also need the <code>Fragment</code> Object.</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r">library(Signac)<br>library(Seurat)<br><br><span class="hljs-comment"># read the peak counts matrix</span><br>peaks &lt;- readRDS(<span class="hljs-string">&#x27;norm_peak_counts.rds&#x27;</span>)<br><span class="hljs-comment"># convert it as ChromatinAssay object. We can define the type of genome here. But I chooce not.</span><br>chromatinassay &lt;- CreateChromatinAssay(counts = peaks)<span class="hljs-comment">#, genome = &quot;dm6&quot;)</span><br>atac_seurat &lt;- CreateSeuratObject(counts = chromatinassay, assay = <span class="hljs-string">&quot;ATAC&quot;</span>)<br><br><span class="hljs-comment"># read meta infors for the cells if you have</span><br>cell_predictions &lt;- readRDS(<span class="hljs-string">&quot;cell_predictions.rds&quot;</span>)<br>atac_seurat@meta.data &lt;- cbind(atac_seurat@meta.data, cell_info_all)<br><br><span class="hljs-comment"># if you have pre-ran demention redundance data like UMAP</span><br>atac_seurat[[<span class="hljs-string">&quot;UMAP&quot;</span>]] &lt;- CreateDimReducObject(embeddings = as.matrix(cell_info_all[<span class="hljs-built_in">c</span>(<span class="hljs-string">&quot;UMAP_1&quot;</span>, <span class="hljs-string">&quot;UMAP_2&quot;</span>)]), key = <span class="hljs-string">&quot;UMAP_&quot;</span>, assay = DefaultAssay(atac_seurat))<br><br>atac_seurat &lt;- NormalizeData(atac_seurat)<br>atac_seurat &lt;- FindVariableFeatures(atac_seurat)<br><br><span class="hljs-comment"># add Fragments object for gene activity counting</span><br>fragments &lt;- CreateFragmentObject(<span class="hljs-string">&#x27;fragments.tsv.gz&#x27;</span>, cells = colnames(x = atac_seurat), verbose = <span class="hljs-literal">FALSE</span>, tolerance = <span class="hljs-number">0.5</span>)<br>Fragments(atac_seurat) &lt;- fragments<br><br><span class="hljs-comment"># Annotation information</span><br><span class="hljs-comment"># cite: https://github.com/stuart-lab/signac/discussions/1088</span><br>library(AnnotationHub)<br>ah &lt;- AnnotationHub()<br>query(ah, <span class="hljs-string">&quot;EnsDb&quot;</span>)<br>ahDb &lt;- query(ah, pattern = <span class="hljs-built_in">c</span>(<span class="hljs-string">&quot;Drosophila&quot;</span>, <span class="hljs-string">&quot;EnsDb&quot;</span>))<br>flygenome &lt;- ahDb[[<span class="hljs-number">19</span>]]<br>annotations &lt;- GetGRangesFromEnsDb(ensdb = flygenome)<br>seqlevelsStyle(annotations) &lt;- <span class="hljs-string">&#x27;NCBI&#x27;</span><br>Annotation(atac_seurat) &lt;- annotations<br><br><span class="hljs-comment"># save the ATAC Seurat object to avoid the creating again</span><br>saveRDS(atac_seurat, <span class="hljs-string">&#x27;scATAC.rds&#x27;</span>)<br></code></pre></td></tr></table></figure></div><h3 id="Integration">Integration</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R"><span class="hljs-comment"># Normalize and find variable features for both datasets</span><br>atac_seurat &lt;- NormalizeData(atac_seurat)<br>atac_seurat &lt;- FindVariableFeatures(atac_seurat)<br><br>rna_seurat &lt;- NormalizeData(rna_seurat)<br>rna_seurat &lt;- FindVariableFeatures(rna_seurat)<br><br><span class="hljs-comment"># run the lsi demaintion dungration</span><br>pbmc.atac &lt;- RunTFIDF(pbmc.atac)<br>pbmc.atac &lt;- FindTopFeatures(pbmc.atac, min.cutoff = <span class="hljs-string">&quot;q0&quot;</span>)<br>pbmc.atac &lt;- RunSVD(pbmc.atac)<br><br><br><span class="hljs-comment"># estimate the gene activities of the feature genes </span><br>gene.activities &lt;- GeneActivity(pbmc.atac, features = VariableFeatures(pbmc.rna))<br><br>pbmc.atac[[<span class="hljs-string">&quot;ACTIVITY&quot;</span>]] &lt;- CreateAssayObject(counts = gene.activities)<br>DefaultAssay(pbmc.atac) &lt;- <span class="hljs-string">&quot;ACTIVITY&quot;</span><br>pbmc.atac &lt;- NormalizeData(pbmc.atac)<br>pbmc.atac &lt;- ScaleData(pbmc.atac, features = rownames(pbmc.atac))<br></code></pre></td></tr></table></figure></div><h3 id="Anchors-identifycation">Anchors identifycation</h3><p>This step would take lots of time.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r"><span class="hljs-comment"># Identify anchors</span><br>transfer.anchors &lt;- FindTransferAnchors(reference = rna_seurat, query = atac_seurat, features = VariableFeatures(object = rna_seurat),<br>    reference.assay = <span class="hljs-string">&quot;RNA&quot;</span>, query.assay = <span class="hljs-string">&quot;ACTIVITY&quot;</span>, reduction = <span class="hljs-string">&quot;cca&quot;</span>)<br></code></pre></td></tr></table></figure></div><h3 id="Label-transfer">Label transfer</h3><p>After identifying anchors, we can transfer annotations from the scRNA-seq dataset onto the scATAC-seq cells. The annotations are stored in the <code>seurat_annotations</code> field, and are provided as input to the <code>refdata</code> parameter. The output will contain a matrix with predictions and confidence scores for each ATAC-seq cell.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r">celltype.predictions &lt;- TransferData(anchorset = transfer.anchors, refdata = rna_seurat$seurat_annotations,<br>    weight.reduction = atac_seurat[[<span class="hljs-string">&quot;lsi&quot;</span>]], dims = <span class="hljs-number">2</span>:<span class="hljs-number">30</span>)<br><br>atac_seurat &lt;- AddMetaData(atac_seurat, metadata = celltype.predictions)<br><br></code></pre></td></tr></table></figure></div><h3 id="Co-embedding-scRNA-seq-and-scATAC-seq-datasets">Co-embedding scRNA-seq and scATAC-seq datasets</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r"><span class="hljs-comment"># note that we restrict the imputation to variable genes from scRNA-seq, but could impute the</span><br><span class="hljs-comment"># full transcriptome if we wanted to</span><br>genes.use &lt;- VariableFeatures(rna_seurat)<br><br><span class="hljs-comment"># if your rna_seurat is integrated result, I believe you&#x27;ld prefer use `assay = &quot;integrated&quot;`</span><br>refdata &lt;- GetAssayData(rna_seurat, assay = <span class="hljs-string">&quot;RNA&quot;</span>, slot = <span class="hljs-string">&quot;data&quot;</span>)[genes.use, ]<br><br><span class="hljs-comment"># refdata (input) contains a scRNA-seq expression matrix for the scRNA-seq cells.  imputation</span><br><span class="hljs-comment"># (output) will contain an imputed scRNA-seq matrix for each of the ATAC cells</span><br>imputation &lt;- TransferData(anchorset = transfer.anchors, refdata = refdata, weight.reduction = atac_seurat[[<span class="hljs-string">&quot;lsi&quot;</span>]],<br>    dims = <span class="hljs-number">2</span>:<span class="hljs-number">30</span>)<br>atac_seurat[[<span class="hljs-string">&quot;RNA&quot;</span>]] &lt;- imputation<br><br>coembed &lt;- merge(x = rna_seurat, y = atac_seurat)<br><br><span class="hljs-comment"># Finally, we run PCA and UMAP on this combined object, to visualize the co-embedding of both</span><br><span class="hljs-comment"># datasets</span><br>coembed &lt;- ScaleData(coembed, features = genes.use, do.scale = <span class="hljs-literal">FALSE</span>)<br>coembed &lt;- RunPCA(coembed, features = genes.use, verbose = <span class="hljs-literal">FALSE</span>)<br>coembed &lt;- RunUMAP(coembed, dims = <span class="hljs-number">1</span>:<span class="hljs-number">30</span>)<br><br>DimPlot(coembed, group.by = <span class="hljs-built_in">c</span>(<span class="hljs-string">&quot;orig.ident&quot;</span>, <span class="hljs-string">&quot;seurat_annotations&quot;</span>))<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://satijalab.org/seurat/articles/atacseq_integration_vignette_files/figure-html/coembed-1.png" alt="Seruat: ATAC-RNA data integration"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://satijalab.org/seurat/articles/atacseq_integration_vignette">© Seurat</a></td></tr></tbody></table><h3 id="Conclusion"><strong>Conclusion</strong></h3><p>Integrating scRNA-Seq and scATAC-Seq data provides a holistic view of cellular states, combining gene expression and chromatin accessibility information. While the integration process might seem daunting, understanding the underlying principles and using the right tools can make it achievable and insightful.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Guide to integrating scRNA-Seq and scATAC-Seq data: Transforming chromatin accessibility and gene expression datasets for a holistic view of cellular states.</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Single Cell" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Single-Cell/"/>
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="RNA-Seq" scheme="https://karobben.github.io/tags/RNA-Seq/"/>
    
    <category term="scRNA-Seq" scheme="https://karobben.github.io/tags/scRNA-Seq/"/>
    
    <category term="scATAC-Seq" scheme="https://karobben.github.io/tags/scATAC-Seq/"/>
    
  </entry>
  
  <entry>
    <title>Evaluating the quality of classification</title>
    <link href="https://karobben.github.io/2023/10/06/Blog/spacial-disEvl/"/>
    <id>https://karobben.github.io/2023/10/06/Blog/spacial-disEvl/</id>
    <published>2023-10-06T17:40:48.000Z</published>
    <updated>2023-12-19T23:48:30.744Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Situation">Situation</h2><p>I have a large, sparse dataset that I’ve analyzed using a neural network model borrowed from previous research. After classifying the data using this model, I applied dimensionality reduction, resulting in well-defined groups. To assess the quality of this classification, I’m considering evaluating the sparsity of classes in the reduced dimension space. One method I’m contemplating is examining the standard deviation in relation to the mean/median value for each group. Are there other effective methods to evaluate the classification based on the distribution in the reduced space?</p><h2 id="How-to-start">How to start</h2><p>Evaluating the quality of classification, especially in the context of redundancy and sparsity, can be a nuanced task. It sounds like you’re interested in understanding how well-separated or distinct the groups are after applying redundancy techniques on the classification results.</p><p>Here’s a structured approach to evaluate your classification results based on redundancy distribution:</p><ol><li><p><strong>Descriptive Statistics</strong>:</p><ul><li><strong>Mean/Median</strong>: Understand the central tendency of each group.</li><li><strong>Standard Deviation (SD)</strong>: Check the spread or variability within each group. A lower SD indicates that the data points are closer to the mean, suggesting tighter clusters or classes.</li><li><strong>Skewness</strong>: Understand the symmetry of your distribution. Positive skewness indicates a long tail on the right, while negative skewness indicates a long tail on the left.<ul><li><code>skewness(X)</code></li></ul></li></ul></li><li><p><strong>Visualization</strong>:</p><ul><li><strong>Heatmaps</strong>: These can help you visualize the density and sparsity of your classes in the redundancy map.</li><li><strong>Histograms/Box-plots</strong>: To visually inspect the distribution of each group.</li></ul></li><li><p><strong>Quantifying Sparsity</strong>:</p><ul><li><strong>Sparsity Ratio</strong>: It’s the ratio of the number of zero (or near-zero, depending on the threshold you set) elements to the total number of elements. A higher sparsity ratio indicates that the classes are more distinct in the redundancy map.</li><li><strong>Gini Coefficient</strong>: Used in economics to measure inequality, it can also measure the inequality of the distribution of classes in a redundancy map. A Gini coefficient of 0 indicates perfect equality, while a Gini coefficient of 1 indicates maximum inequality.</li></ul></li><li><p><strong>Comparative Metrics</strong>:</p><ul><li><strong>Silhouette Score</strong>: Measures how close each sample in one cluster is to the samples in the neighboring clusters. Values range from -1 to 1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters.</li><li><strong>Davies-Bouldin Index</strong>: The lower the value, the better the clustering result. It evaluates intra-cluster similarity and inter-cluster differences.</li></ul></li><li><p><strong>Stability Analysis</strong>:</p><ul><li>If possible, perform the same classification and redundancy process on different subsets of your data. If the results are consistent across different subsets, it adds to the validity of your analysis.</li></ul></li><li><p><strong>Ground Truth Comparison</strong>:</p><ul><li>If there’s a “ground truth” or some external benchmark dataset that you can compare with, it can provide a clear evaluation of how well your classification aligns with known standards.</li></ul></li><li><p><strong>Entropy</strong>:</p><ul><li>For each group or cluster, you can compute its entropy to gauge the randomness or unpredictability of its classification assignments. Lower entropy indicates that a cluster is predominantly made up of one class, whereas higher entropy indicates a mix of classes.</li></ul></li></ol><p>Lastly, remember that no single metric can fully capture the quality and nuances of your classification, especially in the context of redundancy and sparsity. Use a combination of metrics and visualizations to get a comprehensive view of the quality and then base your conclusions on the collective evidence.</p><p>Consider also cross-referencing your results with domain experts or literature in the field to ensure that your evaluations and conclusions align with the underlying phenomena you’re studying.</p><h2 id="Skewness">Skewness</h2><h3 id="run-PCA">run PCA</h3><p>We use the <code>wine</code> data as the example data. The classes information is in <code>wine.class</code></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r"><span class="hljs-comment">## install ggbioplot</span><br><span class="hljs-comment">## remotes::install_github(&quot;vqv/ggbiplot&quot;)</span><br><span class="hljs-comment">## install.packages(&#x27;plyr&#x27;)</span><br>library(plyr)<br>library(ggbiplot)<br>library(ggplot2)<br>data(wine)<br>wine.pca &lt;- prcomp(wine, scale. = <span class="hljs-literal">TRUE</span>)<br><span class="hljs-comment">## bioplot</span><br>ggbiplot(wine.pca, obs.scale = <span class="hljs-number">1</span>, var.scale = <span class="hljs-number">1</span>,<br>         groups = wine.class, ellipse = <span class="hljs-literal">TRUE</span>, circle = <span class="hljs-literal">TRUE</span>) +<br>  scale_color_discrete(name = <span class="hljs-string">&#x27;&#x27;</span>) +<br>  theme_light()+ theme(axis.title = element_text(size=<span class="hljs-number">10</span>))<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://s1.ax1x.com/2020/06/20/NlbAKJ.png" alt="PCA results"></th></tr></thead><tbody></tbody></table><h3 id="Check-the-Skewness">Check the Skewness</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r">library(e1071) <span class="hljs-comment"># for function skewness</span><br><br>score &lt;- wine.pca<br>wine_types &lt;- unique(wine.class)<br><br>skew_TB &lt;- data.frame()<br><span class="hljs-keyword">for</span>(type <span class="hljs-keyword">in</span> wine_types)&#123;<br>  subset_scores &lt;- scores[wine.class == type, ]<br>  <br>  skewness_PC1 &lt;- skewness(subset_scores[, <span class="hljs-number">1</span>])<br>  skewness_PC2 &lt;- skewness(subset_scores[, <span class="hljs-number">2</span>])<br>  <br>  skew_TB &lt;- rbind(skew_TB, data.frame(sk1 = skewness_PC1, sk2 = skewness_PC2, Type = type))<br>&#125;<br><br><span class="hljs-comment"># visualization</span><br><br>ggplot(skew_TB, aes(sk1, sk2, color = Type)) + geom_point() + <br>  theme_bw() + coord_polar(theta = <span class="hljs-string">&#x27;x&#x27;</span>)<br><br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://z1.ax1x.com/2023/10/07/pPjV71s.png" alt="Skewness of the PCA results"></th></tr></thead><tbody><tr><td style="text-align:center">By polarizing the x-axis, the points closer to the center exhibit reduced skewness in both PC components, resulting in decreased sparsity.</td></tr></tbody></table><h2 id="Sparsity-Ratio-and-Gini-Coefficient">Sparsity Ratio and Gini Coefficient</h2><ul><li><p><strong>Sparsity Ratio</strong>: To compute the sparsity ratio for the PCA scores, you’d typically set a threshold (e.g., a value close to 0) below which a score is considered as ‘sparse’ or ‘zero’. The sparsity ratio is then calculated as the number of scores below this threshold divided by the total number of scores.</p></li><li><p><strong>Gini Coefficient</strong>: This measures inequality among values. For the PCA scores, a Gini Coefficient close to 1 indicates high inequality (i.e., few scores dominate), whereas a value close to 0 indicates more equality among scores.</p></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r"><span class="hljs-comment"># following the code above</span><br><br>compute_sparsity_ratio &lt;- <span class="hljs-keyword">function</span>(data, threshold = <span class="hljs-number">0.1</span>)&#123;<br>  <span class="hljs-built_in">return</span>(<span class="hljs-built_in">sum</span>(<span class="hljs-built_in">abs</span>(data) &lt; threshold) / <span class="hljs-built_in">length</span>(data))<br>&#125;<br><br>SG_TB = data.frame()<br><br><span class="hljs-keyword">for</span>(type <span class="hljs-keyword">in</span> wine_types)&#123;<br>  subset_scores_PC1 &lt;- scores[wine.class == type, <span class="hljs-number">1</span>]<br>  subset_scores_PC2 &lt;- scores[wine.class == type, <span class="hljs-number">2</span>]<br>  <br>  <span class="hljs-comment"># Sparsity ratio for PC1 and PC2</span><br>  sparsity_PC1 &lt;- compute_sparsity_ratio(subset_scores_PC1)<br>  sparsity_PC2 &lt;- compute_sparsity_ratio(subset_scores_PC2)<br>  <br>  <span class="hljs-comment"># Gini coefficient for PC1 and PC2</span><br>  gini_PC1 &lt;- ineq::Gini(subset_scores_PC1)<br>  gini_PC2 &lt;- ineq::Gini(subset_scores_PC2)<br><br>  SG_TB &lt;- rbind(SG_TB, data.frame(Type = type, <br>                                   index1 = <span class="hljs-built_in">c</span>(sparsity_PC1, gini_PC1),<br>                                   index2 = <span class="hljs-built_in">c</span>(sparsity_PC2, gini_PC2),<br>                                   index = <span class="hljs-built_in">c</span>(<span class="hljs-string">&#x27;Sparsity&#x27;</span>, <span class="hljs-string">&quot;gigi&quot;</span>)))<br>&#125;<br></code></pre></td></tr></table></figure></div><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Evaluating the quality of classification</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Statistic" scheme="https://karobben.github.io/categories/Notes/Statistic/"/>
    
    <category term="Data Scientists" scheme="https://karobben.github.io/categories/Notes/Statistic/Data-Scientists/"/>
    
    
    <category term="Machine Learning" scheme="https://karobben.github.io/tags/Machine-Learning/"/>
    
    <category term="Data" scheme="https://karobben.github.io/tags/Data/"/>
    
    <category term="Data Science" scheme="https://karobben.github.io/tags/Data-Science/"/>
    
  </entry>
  
  <entry>
    <title>scRNA-Seq: makers explore</title>
    <link href="https://karobben.github.io/2023/10/04/Bioinfor/scRNA-marker/"/>
    <id>https://karobben.github.io/2023/10/04/Bioinfor/scRNA-marker/</id>
    <published>2023-10-04T18:16:57.000Z</published>
    <updated>2023-10-20T17:25:10.204Z</updated>
    
    <content type="html"><![CDATA[<p>Seurat is a popular R package for single-cell RNA sequencing (scRNA-seq) data analysis. If you’ve already processed your data and assigned cell identities (classes), then finding differentially expressed genes (DEGs) between two different classes is a common next step.</p><p>Here’s a brief step-by-step guide on how to identify DEGs between two cell types or classes using Seurat:</p><ol><li><p><strong>Setup</strong>:<br>First, make sure you have the Seurat library loaded.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">library(Seurat)<br></code></pre></td></tr></table></figure></div></li><li><p><strong>Differential Expression</strong>:<br>Use the <code>FindMarkers</code> function in Seurat to identify DEGs. You can specify the two groups you are interested in by setting the <code>ident.1</code> and <code>ident.2</code> parameters.</p><p>For example, if you have two classes named “ClassA” and “ClassB”, you can identify DEGs between these two classes as follows:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">de_genes &lt;- FindMarkers(object = your_seurat_object, <br>             ident.1 = <span class="hljs-string">&quot;ClassA&quot;</span>, <br>             ident.2 = <span class="hljs-string">&quot;ClassB&quot;</span>, <br>             min.pct = <span class="hljs-number">0.25</span>,<br>             logfc.threshold = <span class="hljs-number">0.25</span>,<br>             group.by = <span class="hljs-string">&quot;Final_id&quot;</span>)<br></code></pre></td></tr></table></figure></div><pre> |++++++++++++++++++++++++++++++++++++++++++++++++++| 100% elapsed=29s  </pre><ul><li><code>your_seurat_object</code> is your Seurat object.</li><li><code>min.pct</code> is the minimum percentage of cells where the gene must be detected in either of the two groups.</li><li><code>logfc.threshold</code> is the minimum log-fold change threshold.</li><li><code>group.by</code> is the colname from <code>metadata</code></li></ul></li><li><p><strong>Inspect Results</strong>:<br>The resulting <code>de_genes</code> data frame will contain differentially expressed genes between “ClassA” and “ClassB”. It will include columns for the average expression in each class, the percentage of cells expressing the gene in each class, the log fold-change, and the adjusted p-value (among other metrics).</p></li><li><p><strong>Filter Based on Significance</strong>:<br>You might want to filter out genes based on a significance threshold, for instance, an adjusted p-value less than 0.05:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">significant_genes &lt;- de_genes[de_genes$p_val_adj &lt; <span class="hljs-number">0.05</span>, ]<br></code></pre></td></tr></table></figure></div></li><li><p><strong>Visualize</strong>:<br>You can also visualize the expression of significant genes across different classes using feature plots or violin plots in Seurat.</p></li></ol><p>Remember, the parameters like <code>min.pct</code>, <code>logfc.threshold</code>, and the p-value cutoff should be chosen based on your specific dataset and research questions. Adjust them as necessary to balance sensitivity and specificity.</p><h2 id="Violin-Plot">Violin Plot</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r">VlnPlot(OL3, <br>  idents =  <span class="hljs-built_in">c</span>(<span class="hljs-string">&quot;GMC1&quot;</span>, <span class="hljs-string">&quot;GMC2&quot;</span>, <span class="hljs-string">&quot;GMC3*&quot;</span>), <br>  features = <span class="hljs-string">&quot;N&quot;</span>, <br>  group.by = <span class="hljs-string">&quot;Pred_cl&quot;</span>)<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://z1.ax1x.com/2023/10/05/pPOzURU.png" alt="Show apart of Cells"></th></tr></thead><tbody></tbody></table><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r">VlnPlot(OL3, <br>  idents =  <span class="hljs-built_in">c</span>(<span class="hljs-string">&quot;GMC1&quot;</span>, <span class="hljs-string">&quot;GMC2&quot;</span>, <span class="hljs-string">&quot;GMC3*&quot;</span>), <br>  features = row.names(de_genes), <br>  group.by = <span class="hljs-string">&quot;Pred_cl&quot;</span>)<br></code></pre></td></tr></table></figure></div><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">scRNA-Seq: makers explore</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Single Cell" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Single-Cell/"/>
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="RNA-Seq" scheme="https://karobben.github.io/tags/RNA-Seq/"/>
    
    <category term="NGS" scheme="https://karobben.github.io/tags/NGS/"/>
    
    <category term="scRNA-Seq" scheme="https://karobben.github.io/tags/scRNA-Seq/"/>
    
  </entry>
  
  <entry>
    <title>Understanding the geom_point Function in ggplot2</title>
    <link href="https://karobben.github.io/2023/10/04/R/geom-point/"/>
    <id>https://karobben.github.io/2023/10/04/R/geom-point/</id>
    <published>2023-10-04T15:54:55.000Z</published>
    <updated>2023-10-04T16:54:32.099Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><strong>Introduction</strong></h2><p>Data visualization is an essential aspect of data analysis, allowing us to understand patterns, trends, and relationships in our data. In R, one of the most popular packages for data visualization is <code>ggplot2</code>. Among its many functions, <code>geom_point</code> stands out as a fundamental tool for creating scatter plots. In this blog post, we’ll delve deep into the <code>geom_point</code> function, exploring its basic grammar and how to customize the appearance of points in your plots.</p><h2 id="Basic-Grammar-and-Code-Example"><strong>Basic Grammar and Code Example</strong></h2><p>The basic grammar of <code>geom_point</code> is straightforward. At its core, you need a dataset and aesthetic mappings. The x and y aesthetics are the most common mappings used with <code>geom_point</code>.</p><p>Here’s a simple example:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">library(ggplot2)<br><br><span class="hljs-comment"># Sample data</span><br>data &lt;- data.frame(<br>  x = rnorm(<span class="hljs-number">100</span>),<br>  y = rnorm(<span class="hljs-number">100</span>)<br>)<br><br><span class="hljs-comment"># Basic scatter plot</span><br>ggplot(data, aes(x=x, y=y)) + <br>  geom_point()<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://z1.ax1x.com/2023/10/04/pPOvQfS.png" alt="geom_point"></th></tr></thead><tbody></tbody></table><p>This code will produce a scatter plot with the x and y values from our sample data.</p><h2 id="Customizing-Point-Appearance"><strong>Customizing Point Appearance</strong></h2><ol><li><strong>Changing Point Color</strong></li></ol><p>You can change the color of the points using the <code>color</code> argument inside the <code>aes()</code> function:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">ggplot(data, aes(x=x, y=y, color=<span class="hljs-string">&quot;white&quot;</span>)) + <br>  geom_point()<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://z1.ax1x.com/2023/10/05/pPOv1Sg.png" alt="geom_point assign a group by color"></th></tr></thead><tbody></tbody></table><p>If you want to color points based on a variable, you can do so by mapping that variable to the <code>color</code> aesthetic:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">data$group &lt;- sample(<span class="hljs-built_in">c</span>(<span class="hljs-string">&quot;A&quot;</span>, <span class="hljs-string">&quot;B&quot;</span>), <span class="hljs-number">100</span>, replace = <span class="hljs-literal">TRUE</span>)<br><br>ggplot(data, aes(x=x, y=y, color=group)) + <br>  geom_point() + theme_bw()<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://z1.ax1x.com/2023/10/05/pPOv3lQ.png" alt="geom_point color by group"></th></tr></thead><tbody></tbody></table><h2 id="Show-the-name-of-group-on-the-center-of-scatter-points">Show the name of group on the center of scatter points</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r">data_group &lt;- aggregate(cbind(x, y) ~ group, data=data, FUN=median)<br>ggplot(data, aes(x=x, y=y, color=group)) + <br>  geom_point() + theme_bw() + geom_label(data = data_group, aes( label = group))<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://z1.ax1x.com/2023/10/05/pPOvYmn.png" alt="geom_point label"></th></tr></thead><tbody></tbody></table><h2 id="Changing-Point-Size"><strong>Changing Point Size</strong></h2><p>To change the size of the points, use the <code>size</code> argument:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">ggplot(data, aes(x=x, y=y)) + <br>  geom_point(size=<span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://z1.ax1x.com/2023/10/05/pPOvtwq.png" alt="geom_point point size"></th></tr></thead><tbody></tbody></table><h2 id="Changing-Point-Shape"><strong>Changing Point Shape</strong></h2><p><code>ggplot2</code> provides various shapes for points. You can change the shape using the <code>shape</code> argument:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">ggplot(data, aes(x=x, y=y)) + <br>  geom_point(shape=<span class="hljs-number">17</span>)<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://z1.ax1x.com/2023/10/05/pPOvNT0.png" alt="geom_point point shapes"></th></tr></thead><tbody></tbody></table><p>Shapes are represented by numbers. For example, 16 is a solid circle, 17 is a triangle, and so on. You can explore the <code>?points</code> documentation in R to see a list of available shapes.</p><h2 id="Conclusion"><strong>Conclusion</strong></h2><p>The <code>geom_point</code> function in <code>ggplot2</code> offers a flexible and powerful way to create scatter plots in R. With just a few lines of code, you can produce a basic plot, and with a few more tweaks, you can customize it to your liking. As you continue your data visualization journey, remember that the key is not just to make plots look good, but to make them convey the right information effectively.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">geom_point Function in ggplot2 for scatter plot</summary>
    
    
    
    <category term="R" scheme="https://karobben.github.io/categories/R/"/>
    
    <category term="Plot" scheme="https://karobben.github.io/categories/R/Plot/"/>
    
    <category term="GGPLOT" scheme="https://karobben.github.io/categories/R/Plot/GGPLOT/"/>
    
    
    <category term="Plot" scheme="https://karobben.github.io/tags/Plot/"/>
    
    <category term="R" scheme="https://karobben.github.io/tags/R/"/>
    
    <category term="ggplot" scheme="https://karobben.github.io/tags/ggplot/"/>
    
  </entry>
  
  <entry>
    <title>A Beginner&#39;s Guide to scRNA-Seq Data Integration</title>
    <link href="https://karobben.github.io/2023/10/03/Bioinfor/scRNA-integration/"/>
    <id>https://karobben.github.io/2023/10/03/Bioinfor/scRNA-integration/</id>
    <published>2023-10-03T18:12:39.000Z</published>
    <updated>2023-10-04T21:47:19.941Z</updated>
    
    <content type="html"><![CDATA[<p>Single-cell RNA sequencing (scRNA-seq) has revolutionized our understanding of cellular heterogeneity and function. However, integrating datasets, especially from different labs or experiments, can be challenging. In this guide, we’ll walk through the process of integrating scRNA-seq datasets using Seurat and provide tips for newcomers to the field.</p><h2 id="Why-Integrate-scRNA-Seq-Data"><strong>Why Integrate scRNA-Seq Data?</strong></h2><p>Integrating multiple scRNA-seq datasets allows researchers to compare or combine data from different experiments, conditions, or labs. This is crucial when aiming to:</p><ul><li>Combine datasets to increase sample size.</li><li>Compare conditions across different experiments.</li><li>Mitigate batch effects arising from different experimental conditions.</li></ul><h2 id="The-Seurat-Integration-Workflow"><strong>The Seurat Integration Workflow</strong></h2><p>Seurat, a popular R package for scRNA-seq data analysis, provides a robust framework for data integration. Here’s a step-by-step guide:</p><h3 id="Preprocessing"><strong>Preprocessing</strong></h3><p>Before integration, preprocess each dataset separately. This includes:</p><ul><li>Filtering cells.</li><li>Normalizing data.</li><li>Identifying variable features.</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">library(Seurat)<br><span class="hljs-comment">#DefaultAssay(seurat_obj1) &lt;- &quot;RNA&quot;</span><br><span class="hljs-comment">#DefaultAssay(seurat_obj2) &lt;- &quot;RNA&quot;</span><br>seurat_obj1 &lt;- NormalizeData(seurat_obj1)<br>seurat_obj2 &lt;- NormalizeData(seurat_obj2)<br>seurat_obj1 &lt;- FindVariableFeatures(seurat_obj1, selection.method = <span class="hljs-string">&quot;vst&quot;</span>, nfeatures = <span class="hljs-number">2000</span>)<br>seurat_obj2 &lt;- FindVariableFeatures(seurat_obj2, selection.method = <span class="hljs-string">&quot;vst&quot;</span>, nfeatures = <span class="hljs-number">2000</span>)<br></code></pre></td></tr></table></figure></div><pre>Performing log-normalization0%   10   20   30   40   50   60   70   80   90   100%[----|----|----|----|----|----|----|----|----|----|**************************************************|Calculating gene variances0%   10   20   30   40   50   60   70   80   90   100%[----|----|----|----|----|----|----|----|----|----|**************************************************|Calculating feature variances of standardized and clipped values0%   10   20   30   40   50   60   70   80   90   100%[----|----|----|----|----|----|----|----|----|----|**************************************************|</pre><h4 id="Why-nfeatures-2000">Why nfeatures = 2000</h4><p>The <code>nfeatures</code> parameter, when set to <code>2000</code> in the context of Seurat functions like <code>FindVariableFeatures</code>, specifies that the function should identify the top 2,000 most variable genes in the dataset. These variable genes are often used in downstream analyses, such as PCA, because they capture significant biological and technical variability that can help differentiate cell populations.</p><p>The choice of <code>2000</code> as the number of variable features is somewhat arbitrary but has become a common default in many scRNA-seq workflows. Here’s why:</p><ol><li><p><strong>Historical Precedence</strong>: Early scRNA-seq datasets were smaller, and selecting the top 2,000 variable genes was found to be a good balance between computational efficiency and capturing meaningful biological variability.</p></li><li><p><strong>Computational Efficiency</strong>: Using a subset of genes (like the top 2,000 variable genes) instead of the entire transcriptome makes downstream computations (like PCA, clustering, and UMAP/t-SNE embedding) faster and more memory-efficient.</p></li><li><p><strong>Biological Relevance</strong>: Genes that are variably expressed across cells often represent key markers that can differentiate cell types or states. By focusing on these genes, one can often capture the major axes of variation in the data.</p></li></ol><p>However, it’s essential to understand that <code>2000</code> is not a magic number, and depending on the specific dataset and research question, a different number might be more appropriate. Here are some considerations:</p><ul><li><p><strong>Dataset Size</strong>: For larger datasets with more cells, you might benefit from selecting more than 2,000 variable genes. Conversely, for smaller datasets, a smaller number might suffice.</p></li><li><p><strong>Biological Question</strong>: If you’re interested in subtle subpopulations or rare cell types, you might need to consider more genes to capture this granularity.</p></li><li><p><strong>Exploration</strong>: It’s often beneficial to experiment with different numbers of variable features to see how it impacts downstream analyses. For instance, you can try 1,000, 2,000, 3,000, etc., and observe how it affects clustering or the resolution of cell populations in UMAP/t-SNE plots.</p></li></ul><p>In summary, while <code>nfeatures = 2000</code> is a commonly used default, it’s crucial to understand its implications and adjust it as needed based on the specifics of your dataset and research goals.</p><p>The method <code>'vst'</code> refers to “Variance Stabilizing Transformation.” In the context of Seurat and scRNA-seq data analysis, the VST method is used to identify highly variable genes across single cells.</p><p>Here’s a brief overview of the VST method:</p><h4 id="Variance-Stabilizing-Transformation-VST"><strong>Variance Stabilizing Transformation (VST)</strong>:</h4><ol><li><p><strong>Purpose</strong>: The main goal of VST is to stabilize the variance across the mean of the data. In the context of gene expression data, this means making the variance of gene expression values more consistent across different expression levels.</p></li><li><p><strong>Why It’s Important</strong>: In raw count data, the variance often increases with the mean. This means that highly expressed genes naturally have higher variability just due to the nature of the data. VST aims to correct for this, allowing for the identification of genes that are genuinely variable across cells, not just because of their expression level.</p></li><li><p><strong>How It Works</strong>: Without diving too deep into the math, VST uses a transformation that makes the variance of the data approximately constant across different mean values. This transformation is data-driven and is estimated from the data itself.</p></li><li><p><strong>Application in Seurat</strong>: In Seurat’s <code>FindVariableFeatures</code> function, when the method is set to <code>'vst'</code>, the function will use the VST approach to identify genes that are highly variable after accounting for the relationship between variance and mean expression.</p></li><li><p><strong>Comparison to Other Methods</strong>: Another common method used in Seurat for identifying variable genes is <code>'mean.var.plot'</code>, which fits a loess curve to the relationship between variance and mean expression. The VST method is often more robust, especially for larger datasets, but it’s always a good idea to understand and consider the implications of the method you’re using.</p></li></ol><p>In summary, the VST method in Seurat is a way to identify highly variable genes in a manner that accounts for and corrects the relationship between variance and mean expression. This helps in pinpointing genes that are genuinely variable across cells, which can be crucial for downstream analyses like clustering and dimensionality reduction.</p><h3 id="Identify-Anchors">Identify Anchors</h3><p>Seurat uses the concept of “anchors” to identify correspondences between cells in different datasets. These anchors are then used for data integration.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r"><span class="hljs-comment"># FindIntegrationAnchors is really time consuming. Active per</span><br><br>anchor.features &lt;- SelectIntegrationFeatures(object.list = <span class="hljs-built_in">list</span>(seurat_obj1, seurat_obj2), nfeatures = <span class="hljs-number">2000</span>)<br>anchor.set &lt;- FindIntegrationAnchors(object.list = <span class="hljs-built_in">list</span>(seurat_obj1, seurat_obj2), anchor.features = anchor.features)<br></code></pre></td></tr></table></figure></div><pre>Scaling features for provided objects  |++++++++++++++++++++++++++++++++++++++++++++++++++| 100% elapsed=11s  Finding all pairwise anchors  |                                                  | 0 % ~calculating  Running CCAMerging objectsFinding neighborhoodsFinding anchorsFound 55971 anchorsFiltering anchorsRetained 18262 anchors|++++++++++++++++++++++++++++++++++++++++++++++++++| 100% elapsed=04h 16m 22s</pre><h3 id="Integration"><strong>Integration</strong></h3><p>Seurat uses “anchors” to identify correspondences between cells in different datasets. These anchors are then used for data integration.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">integrated.data &lt;- IntegrateData(anchorset = anchor.set)<br>saveRDS(integrated.data, <span class="hljs-string">&quot;integrated.rds&quot;</span>)<br></code></pre></td></tr></table></figure></div><pre>Merging dataset 2 into 1Extracting anchors for merged samplesFinding integration vectorsFinding integration vector weights0%   10   20   30   40   50   60   70   80   90   100%[----|----|----|----|----|----|----|----|----|----|**************************************************|Integrating data</pre><p>Here, the integration steps are done. The following steps is for checking the integration quality and results.</p><h3 id="Downstream-Analysis"><strong>Downstream Analysis</strong></h3><p>After integration, you can proceed with:</p><ul><li>Scaling the data.</li><li>Running PCA.</li><li>Clustering cells.</li><li>Visualizing data using UMAP or t-SNE.</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">integrated.data &lt;- ScaleData(integrated.data, verbose = <span class="hljs-literal">FALSE</span>)<br>integrated.data &lt;- RunPCA(integrated.data, npcs = <span class="hljs-number">30</span>, verbose = <span class="hljs-literal">FALSE</span>)<br>integrated.data &lt;- FindNeighbors(integrated.data, dims = <span class="hljs-number">1</span>:<span class="hljs-number">30</span>)<br>integrated.data &lt;- FindClusters(integrated.data, resolution = <span class="hljs-number">0.5</span>)<br>integrated.data &lt;- RunUMAP(integrated.data, dims = <span class="hljs-number">1</span>:<span class="hljs-number">30</span>)<br>DimPlot(integrated.data, group.by = <span class="hljs-string">&quot;orig.ident&quot;</span>)<br></code></pre></td></tr></table></figure></div><h2 id="3-Tips-for-Newbies-in-scRNA-Seq-Integration"><strong>3. Tips for Newbies in scRNA-Seq Integration</strong></h2><p>For those new to scRNA-seq integration, here are some essential tips:</p><ul><li><strong>Quality Control</strong>: Ensure thorough QC on each dataset before and after integration.</li><li><strong>Visual Inspection</strong>: Use UMAP/t-SNE plots and heatmaps to visually inspect your data.</li><li><strong>Parameter Tuning</strong>: Adjust parameters based on your specific datasets.</li><li><strong>Biological Validation</strong>: Validate your findings with external data or experimental validation.</li><li><strong>Computational Considerations</strong>: Ensure you have enough memory and computational resources.</li><li><strong>Documentation</strong>: Keep detailed notes and consider using tools like R Markdown.</li><li><strong>Stay Updated</strong>: The field of scRNA-seq is rapidly evolving. Stay updated with the latest methods and best practices.</li><li><strong>Seek Feedback</strong>: Discuss your results with colleagues or experts in the field.</li></ul><h2 id="4-Conclusion"><strong>4. Conclusion</strong></h2><p>Integrating scRNA-seq datasets can be challenging, especially for newcomers. However, with the right tools, a systematic approach, and a focus on the underlying biology, it’s possible to derive meaningful insights from integrated datasets. As with all bioinformatics tasks, continuous learning and practice are key to mastering scRNA-seq data integration.</p><h2 id="Errors">Errors</h2><h3 id="Error-when-running-normalization">Error when running normalization:</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r">NormalizeData(seurat_obj1)                                             <br></code></pre></td></tr></table></figure></div><pre>Performing log-normalization0%   10   20   30   40   50   60   70   80   90   100%[----|----|----|----|----|----|----|----|----|----|**************************************************|Error: Cannot add a different number of cells than already present</pre><p>Solution:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r">seurat_obj1[[<span class="hljs-string">&quot;RNA&quot;</span>]] &lt;- NormalizeData(seurat_obj1[[<span class="hljs-string">&quot;RNA&quot;</span>]])<br></code></pre></td></tr></table></figure></div><h3 id="duplicated-cell-name">duplicated cell-name</h3><pre>In CheckDuplicateCellNames(object.list = object.list) :  Some cell names are duplicated across objects provided. Renaming to enforce unique cell names.</pre><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r">new.names1 &lt;- paste0(colnames(seurat_obj1), <span class="hljs-string">&quot;_P40&quot;</span>)<br>seurat_obj1 &lt;- RenameCells(object = seurat_obj1, new.names = new.names1)<br><br><span class="hljs-comment"># For seurat_obj2, add &quot;_batch2&quot; as a suffix</span><br>new.names2 &lt;- paste0(colnames(seurat_obj2), <span class="hljs-string">&quot;_P50&quot;</span>)<br>seurat_obj2 &lt;- RenameCells(object = seurat_obj2, new.names = new.names2)<br></code></pre></td></tr></table></figure></div><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">A Beginner&#39;s Guide to scRNA-Seq Data Integration</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Single Cell" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Single-Cell/"/>
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="RNA-Seq" scheme="https://karobben.github.io/tags/RNA-Seq/"/>
    
    <category term="scRNA-Seq" scheme="https://karobben.github.io/tags/scRNA-Seq/"/>
    
  </entry>
  
  <entry>
    <title>Understanding and Tackling Batch Effects in Single-Cell RNA-Seq Analysis</title>
    <link href="https://karobben.github.io/2023/10/03/Bioinfor/scRNA-batch/"/>
    <id>https://karobben.github.io/2023/10/03/Bioinfor/scRNA-batch/</id>
    <published>2023-10-03T16:39:22.000Z</published>
    <updated>2023-10-03T18:13:34.068Z</updated>
    
    <content type="html"><![CDATA[<h2 id="The-Challenge-of-Batch-Effects">The Challenge of Batch Effects</h2><p>In the world of single-cell RNA sequencing (scRNA-seq), one of the most prevailing challenges is the presence of batch effects. These are technical non-biological variations that arise when samples are processed in separate runs or under slightly different conditions. If not accounted for, batch effects can overshadow true biological differences, leading to misinterpretations.</p><h2 id="Why-Remove-Batch-Effects">Why Remove Batch Effects?</h2><p>Imagine studying the effects of a drug on cell populations, with samples processed both before and after treatment. If the ‘before’ samples were processed in one batch and the ‘after’ samples in another, any difference you observe might be due to this batch variation rather than the drug effect.</p><p>Removing batch effects ensures that:</p><ul><li>Biological variations are distinguishable from technical variations.</li><li>Combined data from multiple batches can be analyzed together without biases.</li><li>Results are consistent, reproducible, and truly reflective of biological phenomena.</li></ul><h2 id="Approaches-to-Counter-Batch-Effects">Approaches to Counter Batch Effects</h2><p>Several methods have been developed to correct for batch effects. Here, we’ll delve into three popular methods used within the Seurat package: <strong>Harmony</strong>, <strong>fastMNN</strong>, and <strong>SCTransform</strong>.</p><h2 id="A-Comparative-Glimpse">A Comparative Glimpse:</h2><table><thead><tr><th>Feature</th><th><strong>Harmony</strong></th><th><strong>fastMNN (batchelor)</strong></th><th><strong>SCTransform</strong></th></tr></thead><tbody><tr><td>Method</td><td>Operates in PCA space to adjust principal components.</td><td>Uses Mutual Nearest Neighbors to align cells.</td><td>Regresses out unwanted variation and stabilizes variance.</td></tr><tr><td>Use Cases</td><td>Integrating datasets from different conditions, protocols, or platforms.</td><td>Integrating datasets with batch effects. Faster than original MNN.</td><td>Alternative to traditional normalization in Seurat. Prepares data for analysis.</td></tr><tr><td>Advantages</td><td>Preserves biological structures well; robust to complex batch effects.</td><td>Designed for scRNA-seq batch correction; faster than original MNN; corrects severe batch effects.</td><td>Stabilizes variance; can handle large datasets efficiently.</td></tr><tr><td>Disadvantages</td><td>Can be computationally intensive with large datasets.</td><td>Requires a good selection of mutual nearest neighbors.</td><td>Not specifically a batch correction method; often combined with other methods.</td></tr></tbody></table><h2 id="Deep-Dive-into-the-Methods">Deep Dive into the Methods:</h2><ol><li><p><strong>Harmony:</strong> Ideal for integrating multiple scRNA-seq datasets. Harmony adjusts the principal components of the data such that inter-batch differences are minimized while retaining biological variation.</p></li><li><p><strong>fastMNN (from the batchelor package):</strong> This method identifies mutual nearest neighbors between batches, assuming that these pairs of cells represent the same cell type across batches. It’s an optimized and faster variant of the original MNN algorithm.</p></li><li><p><strong>SCTransform:</strong> More than a batch correction technique, SCTransform is a robust normalization method. It prepares the data for downstream analysis, including batch correction, by regressing out unwanted sources of variation.</p></li></ol><h2 id="Final-Thoughts">Final Thoughts:</h2><p>Batch effect correction is a crucial step in scRNA-seq data processing. By choosing the right method tailored to your dataset’s needs, you can unveil genuine biological insights without being misdirected by technical noises. Always visualize and interpret results at each step, ensuring that biological variation remains the highlight of your study.</p><h2 id="In-Action">In Action</h2><p>Seurat offers several methods to correct for batch effects, ensuring that variations across batches don’t obscure the biological signals you’re interested in. Here’s a step-by-step guide to remove batch effects using Seurat:</p><ol><li><p><strong>Install and Load Seurat:</strong></p><p>First, ensure you’ve installed and loaded the Seurat package.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">install.packages(<span class="hljs-string">&#x27;Seurat&#x27;</span>)<br>library(Seurat)<br></code></pre></td></tr></table></figure></div></li><li><p><strong>Data Integration (Using Harmony, SCTransform, and others):</strong></p><p>Seurat offers various integration methods like Harmony, fastMNN, and SCTransform. Here, I’ll showcase using <code>SCTransform</code> followed by <code>RunPCA</code> and <code>Harmony</code>:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R"><span class="hljs-comment"># List of Seurat Objects from different batches</span><br>seurat_list &lt;- <span class="hljs-built_in">list</span>(batch1_seurat, batch2_seurat, ...)<br><br><span class="hljs-comment"># SCTransform normalization</span><br>seurat_list &lt;- lapply(seurat_list, <span class="hljs-keyword">function</span>(x) &#123;<br>  x &lt;- SCTransform(x, verbose = <span class="hljs-literal">FALSE</span>)<br>&#125;)<br><br><span class="hljs-comment"># Identify anchors for integration</span><br>anchors &lt;- FindIntegrationAnchors(object.list = seurat_list, normalization.method = <span class="hljs-string">&quot;SCT&quot;</span>, <br>                                  anchor.features = <span class="hljs-number">2000</span>, verbose = <span class="hljs-literal">FALSE</span>)<br><br><span class="hljs-comment"># Integrate data</span><br>integrated_data &lt;- IntegrateData(anchorset = anchors, normalization.method = <span class="hljs-string">&quot;SCT&quot;</span>, verbose = <span class="hljs-literal">FALSE</span>)<br></code></pre></td></tr></table></figure></div><p>If you prefer using <code>Harmony</code> specifically:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">library(harmony)<br>integrated_data &lt;- RunPCA(integrated_data, features = VariableFeatures(object = integrated_data))<br>integrated_data &lt;- RunHarmony(integrated_data, group.by.vars = <span class="hljs-string">&quot;batch&quot;</span>)<br></code></pre></td></tr></table></figure></div></li><li><p><strong>Scale and Run Linear Dimensional Reduction:</strong></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">integrated_data &lt;- ScaleData(integrated_data, verbose = <span class="hljs-literal">FALSE</span>)<br>integrated_data &lt;- RunPCA(integrated_data, verbose = <span class="hljs-literal">FALSE</span>)<br></code></pre></td></tr></table></figure></div></li><li><p><strong>Cluster and Visualize Integrated Data:</strong></p><p>Using UMAP or t-SNE to visualize the integrated data is a great way to confirm if the batch effects have been mitigated.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">integrated_data &lt;- RunUMAP(integrated_data, reduction = <span class="hljs-string">&quot;harmony&quot;</span>, dims = <span class="hljs-number">1</span>:<span class="hljs-number">30</span>)<br>DimPlot(integrated_data, group.by = <span class="hljs-string">&quot;batch&quot;</span>)<br></code></pre></td></tr></table></figure></div></li><li><p><strong>Optional - Regression of unwanted sources of variation:</strong></p><p>If you are aware of specific unwanted sources of variation, you can regress them out using the <code>vars.to.regress</code> parameter in the <code>ScaleData</code> function.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs R">seurat_object &lt;- ScaleData(seurat_object, vars.to.regress = <span class="hljs-string">&quot;batch&quot;</span>)<br></code></pre></td></tr></table></figure></div></li></ol><p>Remember, the removal of batch effects should be done carefully. Overcorrection might lead to loss of genuine biological variation. It’s always a good practice to visualize and interpret the results at each step, ensuring the intended correction.</p><p>Lastly, Seurat’s integration methods and their parameters might evolve with time, so always consult the latest Seurat documentation or vignettes to ensure you’re using the most effective and up-to-date approaches.</p><p>Harmony, fastMNN, and SCTransform are all methods to handle batch effects and data normalization in single-cell RNA-seq data, but they operate based on different principles and have distinct purposes.</p><p><strong>In summary:</strong></p><ul><li><strong>Harmony</strong> and <strong>fastMNN</strong> are batch-correction methods that work to align datasets from different batches or conditions.</li><li><strong>SCTransform</strong> is a normalization method that prepares the data for further analysis, including batch correction.</li></ul><p>When dealing with batch effects, researchers often first normalize the data using <strong>SCTransform</strong> and then apply batch correction methods like <strong>Harmony</strong> or <strong>fastMNN</strong> to the transformed data. This two-step approach ensures that the data is both normalized and free of batch effects, making downstream analyses like clustering and differential expression more reliable.</p><p>Other tutorial:</p><ul><li><a href="https://www.10xgenomics.com/resources/analysis-guides/introduction-batch-effect-correction">2023; X10 Genomics: Batch Effect Correction</a></li><li><a href="https://satijalab.org/seurat/articles/integration_introduction.html">2023; Seurat: Introduction to scRNA-seq integration<br></a></li></ul><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Remove Batch Effects in Single-Cell RNA-Seq</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Single Cell" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Single-Cell/"/>
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="RNA-Seq" scheme="https://karobben.github.io/tags/RNA-Seq/"/>
    
    <category term="scRNA-Seq" scheme="https://karobben.github.io/tags/scRNA-Seq/"/>
    
  </entry>
  
</feed>
