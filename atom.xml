<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Karobben</title>
  
  <subtitle>Engjoy~</subtitle>
  <link href="https://karobben.github.io/atom.xml" rel="self"/>
  
  <link href="https://karobben.github.io/"/>
  <updated>2023-09-10T03:47:42.535Z</updated>
  <id>https://karobben.github.io/</id>
  
  <author>
    <name>Karobben</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Molecule and Cellular Biology 6</title>
    <link href="https://karobben.github.io/2023/09/07/LearnNotes/UIUC-AdMC-6/"/>
    <id>https://karobben.github.io/2023/09/07/LearnNotes/UIUC-AdMC-6/</id>
    <published>2023-09-07T13:09:04.000Z</published>
    <updated>2023-09-10T03:47:42.535Z</updated>
    
    <content type="html"><![CDATA[<div class="admonition info"><p class="admonition-title">Points for the lecture:</p><ul><li>λ life cycle is regulated through molecular events</li><li>Events are ‘tuned’ for propagation of the phage</li><li>Competition between factors dictates activity state</li></ul></div><h2 id="λ-Phage">λ Phage</h2><h3 id="How-λ-Gets-In">How λ Gets In</h3><ul><li><p><strong>Components and Structure</strong></p><ul><li><strong>Genome:</strong> 48,502 bp of double-stranded DNA (dsDNA).</li><li><strong>Chromosome in the capsid:</strong><ul><li><strong>Structure:</strong> Linear dsDNA.</li><li><strong>Special Feature:</strong> 12 nt single-stranded DNA (ssDNA) cohesive termini.</li></ul></li><li><strong>Capsid:</strong><ul><li><strong>Head:</strong> Comprises products of B, C, Nu3, D, and E genes.</li><li><strong>Tail:</strong> Formed by products of J and H genes.</li></ul></li></ul></li><li><p><strong>Infection Process</strong></p><ol><li><strong>Attachment:</strong> The phage attaches to the host cell’s maltose receptor, a product of the E. coli lamB gene.</li><li><strong>Injection:</strong> Injects its linear dsDNA chromosome into the host cell.</li><li><strong>Circularization:</strong></li></ol><ul><li><strong>Mechanism:</strong> Annealing occurs between complementary 3’ overhanging cos sites.</li><li><strong>Outcome:</strong> Linear dsDNA transforms into a circular form, facilitating the integration into the host’s genome.</li></ul></li><li><p><strong>Notes</strong></p><ul><li>The cohesive termini and the specific structure of the capsid play crucial roles in the bacteriophage’s ability to infect and integrate into the host genome.</li><li>Understanding the precise infection mechanism can offer insights into bacterial immunity and potential applications in bacterial genetics research.</li></ul></li></ul><h3 id="Life-Choice-Depends-on-Genetic-Switch">Life Choice Depends on Genetic Switch</h3><h4 id="1-Lytic-Mode">1. Lytic Mode</h4><ul><li><strong>Initial Phase:</strong><ul><li><strong>DNA Entry:</strong> Phage DNA enters the host cell.</li><li><strong>Transcription:</strong> Host RNA polymerase transcribes phage DNA.</li><li><strong>Translation:</strong> Phage mRNAs are translated to produce phage proteins.</li></ul></li><li><strong>Replication Phase:</strong><ul><li><strong>DNA Replication:</strong> Phage DNA replicates.</li><li><strong>Assembly:</strong> New phages are assembled from DNA and protein components.</li></ul></li><li><strong>Final Phase:</strong><ul><li><strong>Lysis:</strong> The host cell undergoes lysis, releasing progeny phages.</li><li><strong>Result:</strong> The host cell is killed.</li></ul></li></ul><h4 id="2-Lysogenic-Mode">2. Lysogenic Mode</h4><ul><li><strong>Initial Phase:</strong><ul><li><strong>DNA Entry:</strong> Phage DNA enters the cell.</li><li><strong>Early Gene Expression:</strong> Early genes are transcribed and translated.</li></ul></li><li><strong>Repressor Role:</strong><ul><li><strong>λ Repressor (CI) Appearance:</strong> A 27-kD phage protein appears.</li><li><strong>Binding:</strong> CI binds to two phage operator regions.</li><li><strong>Effect:</strong> It shuts down transcription of all phage genes except for cI (gene coding for λ repressor).</li></ul></li><li><strong>Integration Phase:</strong><ul><li><strong>Integration:</strong> Phage DNA integrates into the host genome.</li><li><strong>Lysogen Formation:</strong> The host with integrated phage DNA is termed a lysogen.</li><li><strong>Prophage:</strong> The integrated DNA is referred to as a prophage.</li></ul></li><li><strong>Maintenance Phase:</strong><ul><li><strong>Reproduction:</strong> The phage DNA replicates alongside host DNA.</li><li><strong>Advantage:</strong> Allows the phage to multiply without creating new phage particles, giving it a “free ride.”</li></ul></li><li><strong>Induction Phase (Conditional):</strong><ul><li><strong>Trigger:</strong> Exposure to mutagenic chemicals or radiation.</li><li><strong>Effect:</strong> The lysogenic cycle can be broken, shifting the phage into the lytic phase.</li></ul></li></ul><h4 id="Notes">Notes</h4><ul><li><strong>λ Phage Characteristics:</strong> It is a temperate phage, meaning it can follow both lytic and lysogenic paths.</li><li><strong>Versatility:</strong> λ phage showcases more versatility compared to virulent phages like T2, T4, T7, and SPO1, which always follow the lytic path.</li><li><strong>Lysogenic Stability:</strong> The lysogenic state can be stable indefinitely, beneficial for the phage as it ensures its survival and replication without killing the host.</li></ul><h3 id="λ-Genome-is-Organized-By-Function">λ Genome is Organized By Function</h3><table><thead><tr><th style="text-align:center"><img src="https://www.bx.psu.edu/~ross/workmg/TxnlRegLambdaCh17_files/image011.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.bx.psu.edu/~ross/workmg/TxnlRegLambdaCh17.htm">© bx.psu.edu</a></td></tr></tbody></table><ol><li><p><strong>HEAD &amp; TAIL Region</strong> (left side of the <strong>RECOMBINATION Region</strong>)</p><ul><li><strong>Structure:</strong> Encodes for the structural proteins constituting the phage’s capsid.</li><li><strong>Terminase Enzyme:</strong> Required for processing rolling circle multimers into unit genome-length pieces during DNA packaging.</li></ul></li><li><p><strong>RECOMBINATION Region</strong></p><ul><li><strong>Genes:</strong><ul><li><strong>Int:</strong> Necessary for the integration of the phage into the bacterial host chromosome during lysogenic growth.</li><li><strong>Xis:</strong> Facilitates the excision of the phage from the host chromosome during induction.</li><li><strong>Others:</strong> A variety of other genes facilitating integration and excision processes.</li></ul></li></ul></li><li><p><strong>REGULATION Region</strong></p><ul><li><strong>Immunity Region:</strong> Involved in the phage’s self-immunity processes.</li><li><strong>Switch Control:</strong> Houses genes controlling the switch between lysogenic and lytic growth.</li><li><strong>Q Antiterminator Protein:</strong> Part of the regulatory mechanism.</li><li><strong>Anti-Q RNA:</strong> Works alongside the Q protein in regulation.</li><li><strong>PR’:</strong> Constitutes a secondary regulation region, working in conjunction with Q protein and Anti-Q RNA.</li></ul></li><li><p><strong>REPLICATION Region</strong></p><ul><li><strong>Genes:</strong><ul><li><strong>O:</strong> Replication protein gene.</li><li><strong>P:</strong> Another gene involved in replication.</li></ul></li><li><strong>Origin of Replication:</strong> The starting point for the DNA replication process.</li></ul></li><li><p><strong>LYSIS Region</strong></p><ul><li><strong>Gene Count:</strong> Contains four genes.</li><li><strong>Function:</strong> The genes in this region are generally involved in the lysis of the host cell, facilitating the release of new phage particles.</li></ul></li></ol><h4 id="Note">Note</h4><ul><li><strong>Different Regions:</strong> Each region in the bacteriophage genome is designated for a different function, playing a crucial role in the phage’s life cycle, either helping in its replication, regulation of its life cycle, or in the processes leading to the integration into or excision from the host genome.</li></ul><h3 id="λ-Inserts-into-the-Host-Genome-by-Recombination">λ Inserts into the Host Genome by Recombination</h3><h3 id="λ-has-7-Promoters">λ has 7 Promoters</h3><ul><li>P<sub>R</sub> expresses the replication genes as well as the anti-repressor, Cro, the transcriptional activator cII, and the anti-terminator, Q protein.</li><li>P<sub>L</sub>expresses the recombination genes as well as the anti-terminator, N, and the cIII protein.</li><li>P<sub>R’</sub> expresses the lysis proteins, and the head and tail proteins.</li><li>P<sub>RE</sub> expresses the repressor gene, cI, to establish lysogeny.</li><li>P<sub>RM</sub> expresses the repressor gene, cI, to maintain lysogeny.</li><li>P<sub>I</sub> expresses the int gene to synthesize the Integrase protein.</li><li>P<sub>aQ</sub> drives synthesis of a short anti-sense RNA which blocks translation of Q gene mRNA.</li></ul><h3 id="Protein-Expression-is-Stage-Dependent">Protein Expression is Stage Dependent</h3><table><thead><tr><th>Event</th><th>l Gene Expressed</th><th>Comment</th></tr></thead><tbody><tr><td>Initial infection</td><td>Cro, N</td><td>Only N and Cro are synthesized until the decision point is reached</td></tr><tr><td>Lytic pathway</td><td>Cro, N, Q, late genes</td><td>Cro predominates at operators, N and Q are antiterminators</td></tr><tr><td>Lysogenic pathway</td><td>cI, cII, cIII, int</td><td>cII and cIII collaborate to establish cI synthesis; after genome integration, only cI is expressed during maintenance of lysogeny.</td></tr></tbody></table><h3 id="Consequences-of-Early-Gene-Expression">Consequences of Early Gene Expression</h3><ol><li>Cro repressor mRNA made from PR and translated.</li><li>N antiterminator mRNA made from PL and translated.  Allows transcription and translation of cII and cIII.</li><li>cII/cIII proteins activate PRE, causing transcription of cI</li><li>Concentrations of cI and Cro proteins build up</li></ol><h2 id="Initial-Events">Initial Events</h2><h3 id="Molecular-Decision-Making-Choice-between-Lysis-Lysogeny">Molecular Decision-Making: Choice between Lysis &amp; Lysogeny</h3><ul><li>Determined by relative concentrations of cI and Cro, which act oppositely on P<sub>RM</sub> the promoter for <strong>Repressor Maintenance</strong></li><li>P<sub>RM</sub> <strong>requires cI protein</strong>, therefore not active just after infection. <strong>Inhibited by Cro</strong>.</li><li>Cro lower affinity for PRM but is made earlier.</li><li>Cro binds same operator sites as cI, but not as efficiently or stably. At low levels, will slow down, but not stop expression of N , cIII (P<sub>L</sub>) or cII, P, Q (P<sub>R</sub>).  At high levels, cII and cIII are prevented from being transcribed, so no cI.</li></ul><h3 id="λ-Immunity-Region">λ Immunity Region</h3><table><thead><tr><th style="text-align:center"><img src="http://genes.atspace.org/Figs/G313.gif" alt=""></th></tr></thead><tbody><tr><td style="text-align:center"><a href="http://genes.atspace.org/11.5.html">© genes.atspace.org</a></td></tr></tbody></table><h2 id="Lysogeny">Lysogeny</h2><table><thead><tr><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/10/pPc3ztS.png" alt="Lysogeny"></th></tr></thead><tbody><tr><td style="text-align:center">Unknown</td></tr></tbody></table><h3 id="N-is-an-Anti-Terminator">N is an Anti-Terminator</h3><table><thead><tr><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/10/pPc89pQ.png" alt="N is an Anti-Terminator"></th><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/10/pPc8Clj.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center">Molecular Biology; Weaver, Robert: Fifth edition; P206</td><td style="text-align:center">P207; Figure 8.14</td></tr></tbody></table><ul><li><p><strong>Physical and Functional Layout</strong></p><ul><li><strong>Location</strong>: Situated downstream of the PL promoter and its respective operator, OL.</li><li><strong>Nut Site</strong>: Contains specific sequences, box A and box B, which play crucial roles in the functioning of the N protein.</li></ul></li><li><p><strong>Functionality in the Absence of N Protein</strong></p><ul><li><strong>Transcription Start</strong>: Commences at the PL promoter.</li><li><strong>Transcription Termination</strong>: Occurs at a terminator site situated downstream of the N gene. The RNA polymerase releases the N mRNA here.</li></ul></li><li><p><strong>Functionality in the Presence of N Protein</strong></p><ul><li><strong>N Protein Synthesis</strong>: Once the N gene has been transcribed, the N protein materializes.</li><li><strong>Binding to Nut Site</strong>: The N protein binds to the nut site on the transcript.</li><li><strong>Alteration of RNA Polymerase</strong>: The N protein collaborates with a complex of host proteins, altering the RNA polymerase to overlook the terminator site and proceed with transcription into the delayed early genes.</li></ul></li><li><p><strong>Involvement of Host Proteins</strong></p><ul><li><strong>Nus Proteins</strong>: These include NusA, NusB, and NusG, which have roles in both the phage and host cell processes.</li><li><strong>Ribosomal S10 Protein</strong>: Participates in protein synthesis in the host cell.</li><li><strong>Antitermination</strong>: N and NusA can facilitate antitermination in close proximity to the nut site, forming a short-range antitermination complex with the RNA polymerase.</li></ul></li><li><p><strong>Processive Antitermination</strong></p><ul><li><strong>Long-Range Effect</strong>: In natural circumstances, antitermination occurs hundreds of base pairs downstream of nut sites, requiring the involvement of all Nus proteins and S10 for stability.</li><li><strong>Persistent Complex</strong>: A stable complex is formed, continuing until reaching the terminator.</li></ul></li><li><p><strong>Nut Site Interaction</strong></p><ul><li><strong>RNA Interaction</strong>: Rather than interacting with the nut site itself, the complex interacts with its transcript.</li><li><strong>RNA-binding Domain</strong>: The region in N essential for nut recognition features an arginine-rich domain akin to RNA-binding domains.</li><li><strong>Protection from RNase</strong>: A full assembly of the five proteins in the complex shields both boxes A and B from RNase attacks.</li></ul></li><li><p><strong>RNA Loop Formation</strong></p><ul><li><strong>Sustained Signal</strong>: The RNA between the nut site transcript and the RNA polymerase forms a loop, maintaining the association of N with both, thus providing a continuous signal to the polymerase until it reaches the terminator.</li><li><strong>Evidence</strong>: Experiments have indicated that alterations in the RNA polymerase b-subunit gene can obstruct N-mediated antitermination, suggesting a potential association between the RNA polymerase, N, and the nut site transcript during transcription.</li></ul></li><li><p><strong>Conclusion</strong><br>The gene N encodes for the N protein which plays a pivotal role in the antitermination process during the phage lifecycle. It acts by binding to the nut site of the transcript and altering RNA polymerase activity, facilitating transcription beyond the terminator site. This mechanism leverages both short-range and processive antitermination, guided by a complex interplay of different proteins and the intricate structure of the nut site and its transcript. The stability and sustained activity of this system are central to its function, maintaining a persistent signal through RNA loop formations that guide the RNA polymerase over substantial distances.</p></li></ul><h3 id="N-Prevents-Stem-loop-Formation">N Prevents Stem-loop Formation</h3><table><thead><tr><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/10/pPc8Mc9.png" alt="N Prevents Stem-loop Formation"></th></tr></thead><tbody><tr><td style="text-align:center">P208; Figure 8.15</td></tr></tbody></table><ul><li><p><strong>Background</strong></p><ul><li><strong>Initial Hypothesis</strong>: N restricts the RNA polymerase pausing vital for termination.</li><li><strong>Research by Gusarov and Nudler (2001)</strong>: Contradicted the initial hypothesis, highlighting that N doesn’t significantly affect pausing but instead influences the formation of the terminator hairpin.</li></ul></li><li><p><strong>Mechanism</strong></p><ol><li><strong>N Binding to RNA</strong>: N binds to the portion of RNA supposed to form the upstream part of the terminator hairpin, thereby slowing down its formation.</li><li><strong>Preventing Hairpin Formation</strong>: Without the hairpin structure, the termination process cannot proceed, a mechanism somewhat similar to overriding transcription attenuation seen in the trp operon.</li></ol></li><li><p><strong>Role of NusA</strong></p><ol><li><strong>Interaction with Elongation Complex (EC)</strong>: As EC synthesizes a string of U’s, it pauses after adding the seventh nucleotide, positioning the potential upstream part of the hairpin to bind to the RNA polymerase’s upstream binding site (UBS).</li><li><strong>Time Constraint</strong>: The pause lasts for about 2 seconds, within which the hairpin should form to ensure termination; otherwise, the polymerase progresses without terminating.</li><li><strong>Stimulation of Termination</strong>: NusA weakens the connection between the potential upstream part of the hairpin and the UBS, encouraging quick hairpin formation and subsequently promoting termination.</li></ol></li><li><p><strong>Comprehensive Model (Gusarov and Nudler, 2001)</strong></p><ol><li><strong>Dual Binding</strong>: Both N and NusA bind to the RNA segment meant to form the upstream part of the hairpin.</li><li><strong>Blocking Hairpin Formation</strong>: By binding to the RNA segment, N prevents the quick formation of the hairpin.</li><li><strong>NusA’s Role</strong>: While connected to N, NusA also associates with the RNA segment, further slowing down the hairpin formation.</li><li><strong>Outcome</strong>: Due to the hindered hairpin formation, RNA polymerase moves forward without engaging in the termination process.</li></ol></li><li><p><strong>Conclusion</strong><br>N prevents termination not by limiting RNA polymerase pausing but by binding to the RNA segment that is crucial for forming the terminator hairpin, consequently slowing down its formation. NusA plays a dual role, both facilitating and slowing down hairpin formation depending on its interactions with either the RNA or N. The intricate interaction between N, NusA, and the RNA orchestrates whether the termination proceeds or not.</p></li></ul><h3 id="PL">P<sub>L</sub></h3><table><thead><tr><th style="text-align:center"><img src="https://upload.wikimedia.org/wikipedia/commons/a/a7/Phage_Lambda_int_xis_Retroregulation.jpg" alt=""></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://en.wikipedia.org/wiki/Lambda_phage">source: wiki</a></td></tr></tbody></table><p>In addition to N, the <mark>early transcript</mark> of PL codes for:</p><ul><li>cIII<br>required to protect the activator protein, cII</li><li>Xis<br>normally required for excision of a prophage</li><li>Int<br>normally required for integration of a prophage.</li></ul><h4 id="Background"><strong>Background</strong></h4><ul><li><strong>Context</strong>: Early lytic growth phase of bacteriophages.</li><li><strong>Concerned Molecules</strong>: Xis and Int proteins.</li><li><strong>Primary Regulator</strong>: N protein.</li></ul><h4 id="Mechanism"><strong>Mechanism</strong></h4><ol><li><strong>Role of N Protein</strong>:<ul><li><strong>Transcriptional Impact</strong>: Influences RNA polymerase to bypass the tI transcription terminator and continue transcription through the sib region.</li><li><strong>Attachment</strong>: Remains attached to the ternary transcription complex.</li></ul></li><li><strong>Sib Region</strong>:<ul><li><strong>Characteristic</strong>: Houses the signal for an RNase III processing site.</li><li><strong>Effect on mRNA</strong>: Transcripts passing through this region undergo structural changes to form a hairpin configuration.</li></ul></li><li><strong>Action of RNase III</strong>:<ul><li><strong>Recognition</strong>: Identifies the hairpin structure in the transcripts.</li><li><strong>Cleavage</strong>: Splits the transcript at the identified site, leaving free 3’ ends.</li></ul></li><li><strong>Exonuclease Activity</strong>:<ul><li><strong>Degradation</strong>: Enzymes present in the cell degrade the free 3’ ends further.</li><li><strong>Impact on Xis and Int</strong>: The coding regions for Xis and Int largely get destroyed before translation can occur, reducing their expression significantly.</li></ul></li></ol><h4 id="Retroregulation"><strong>Retroregulation</strong></h4><ul><li><strong>Definition</strong>: A regulatory mechanism where the stability and translatability of mRNA are controlled post-transcriptionally, affecting the subsequent expression of certain genes (in this case, Xis and Int).</li><li><strong>Outcome in the Context</strong>: Ensures limited expression of Xis and Int during the early lytic growth phase, maintaining control over the developmental pathway of the bacteriophage through intricate regulation at the RNA level.</li></ul><h4 id="Conclusion"><strong>Conclusion</strong></h4><ul><li><strong>Efficiency in Regulation</strong>: Retroregulation efficiently controls the expression of Xis and Int proteins during early lytic growth through a series of RNA modifications and processing, preventing their significant expression and translation during this phase.</li><li><strong>Regulatory Network</strong>: The process involves a network of actions including the N protein’s influence on RNA polymerase, hairpin formation guided by the sib region signal, RNase III-mediated cleavage, and exonuclease-induced degradation, demonstrating a tight regulatory mechanism at work during bacteriophage development.</li></ul><h3 id="cIII-Inhibits-Proteolysis-of-cII">cIII Inhibits Proteolysis of cII</h3><p><mark>cII half-life alone is &lt; 1min but with cIII it is ~ 5 min</mark></p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Molecule and Cellular Biology 6</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Class" scheme="https://karobben.github.io/categories/Notes/Class/"/>
    
    <category term="UIUC" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/"/>
    
    <category term="Cell Biology" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/Cell-Biology/"/>
    
    
    <category term="Classes" scheme="https://karobben.github.io/tags/Classes/"/>
    
    <category term="UIUC Classes" scheme="https://karobben.github.io/tags/UIUC-Classes/"/>
    
    <category term="Cell Biology" scheme="https://karobben.github.io/tags/Cell-Biology/"/>
    
  </entry>
  
  <entry>
    <title>Molecule and Cellular Biology 5</title>
    <link href="https://karobben.github.io/2023/09/05/LearnNotes/UIUC-AdMC-5/"/>
    <id>https://karobben.github.io/2023/09/05/LearnNotes/UIUC-AdMC-5/</id>
    <published>2023-09-05T13:09:04.000Z</published>
    <updated>2023-09-09T19:42:12.679Z</updated>
    
    <content type="html"><![CDATA[<div class="admonition info"><p class="admonition-title">Points for the lecture</p><ol><li>Gene regulation by manipulation of DNA structure (bending, looping, twisting)</li><li>Activation does not always involve direct interaction with RNAP</li><li>Genomes are packaged and spatially organized</li></ol><ul><li>Reading: 8.3</li></ul></div><h2 id="DNA-Looping-and-Post-Translation-Modification-PTM">DNA Looping and Post-Translation Modification (PTM)</h2><h3 id="Glutamine-Synthesis">Glutamine Synthesis</h3><table><thead><tr><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/10/pPc39qx.png" alt="Glutamine Synthesis"></th></tr></thead><tbody><tr><td style="text-align:center">Unknown</td></tr></tbody></table><h3 id="NtrC-Controls-glnA-Promoter-from-a-Distance-How-Does-a-Distant-Element-Works">NtrC Controls <em>gln</em>A Promoter from a Distance &amp; How Does a Distant Element Works?</h3><table><thead><tr><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/10/pPc3idK.png" alt="How Does Distant Elements Work"></th></tr></thead><tbody><tr><td style="text-align:center">Unknown</td></tr></tbody></table><table><thead><tr><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/10/pPc3FIO.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center">Enhancers Function Over Long Distances</td></tr><tr><td style="text-align:center"><img src="https://s1.ax1x.com/2023/09/10/pPc3de0.png" alt=""></td></tr><tr><td style="text-align:center">loop <mark>require the ATP</mark> and a littel amout of DNA</td></tr></tbody></table><table><thead><tr><th style="text-align:left"><img src="https://s1.ax1x.com/2023/09/10/pPc3wwV.png" alt=""></th><th style="text-align:left"><img src="https://s1.ax1x.com/2023/09/10/pPc30oT.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:left">NtrC RNAP-Interactions Prefer a 390-bpIntervening Sequence</td><td style="text-align:left">DNA Looping, in general, Requires &gt;250 b.p.</td></tr></tbody></table><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Molecule and Cellular Biology 5</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Class" scheme="https://karobben.github.io/categories/Notes/Class/"/>
    
    <category term="UIUC" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/"/>
    
    <category term="Cell Biology" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/Cell-Biology/"/>
    
    
    <category term="Classes" scheme="https://karobben.github.io/tags/Classes/"/>
    
    <category term="UIUC Classes" scheme="https://karobben.github.io/tags/UIUC-Classes/"/>
    
    <category term="Cell Biology" scheme="https://karobben.github.io/tags/Cell-Biology/"/>
    
  </entry>
  
  <entry>
    <title>Molecule and Cellular Biology 4</title>
    <link href="https://karobben.github.io/2023/08/31/LearnNotes/UIUC-AdMC-4/"/>
    <id>https://karobben.github.io/2023/08/31/LearnNotes/UIUC-AdMC-4/</id>
    <published>2023-08-31T13:09:04.000Z</published>
    <updated>2023-09-09T19:42:11.203Z</updated>
    
    <content type="html"><![CDATA[<h2 id="cAMP-Levels-Control-‘Catabolite-Repression’">cAMP Levels Control ‘Catabolite Repression’</h2><p><strong>Catabolite Activator Protein</strong>: Ira Pastan and his colleagues demonstrated that <mark>cAMP</mark>, added to bacteria, could <mark>overcome catabolite repression</mark> of the lac operon and a number of other operons, including the gal and ara operons.</p><p>A protein involved in gene regulation was discovered and named <mark>CAP</mark> by Zubay and <mark>CRP</mark> by Pastan’s group. We will use the name CAP to refer to this protein and <em>crp</em> as the gene.</p><p><mark>CAP mechanism:</mark></p><ol><li><p><strong>Mutation Discovery</strong>: Zubay’s team found mutations in the lac promoter preventing CAP and cAMP from boosting lac transcription.</p></li><li><p><strong>Binding Site Location</strong>: Research pinpointed the CAP-cAMP binding site upstream of the lac promoter.</p></li><li><p><strong>CAP-cAMP Complex Formation</strong>: cAMP modifies CAP’s shape, increasing its affinity for the binding site.</p></li><li><p><strong>Open Promoter Complex Assistance</strong>: The CAP-cAMP complex helps RNA polymerase to form an <strong>open promoter complex</strong>, aiding transcription initiation.</p></li><li><p><strong>Role in Transcription</strong>: The complex aids in efficient lac operon transcription, helping the cell adapt to nutritional changes.</p></li></ol><p>In this process, the CAP-cAMP complex facilitates the initiation of transcription in response to environmental cues, enhancing the cell’s adaptability.</p><ul><li>Regulation: many layers</li><li>Positive Reg: alpha-subunit of RNAP</li><li>DNA bending</li><li>Weak promoters</li></ul><p>CAP: Catabolic  activator protein</p><p>repressor responsible to low level of Lactose so it wound transcript when Lactose is low<br>CAP responsible to the low level of Glu and help the transcription</p><p>When Glu is low and lactose is high, the repressor is cleared and CAP is on. The transcription is started.</p><p>CAP is a receptor to bind the cAMP. cAMP-CAP complex contribute the activation of the gene expression.</p><h3 id="CAP-Binding-Induces-DNA-Bending">CAP Binding Induces DNA Bending</h3><table><thead><tr><th style="text-align:center"><img src="http://genes.atspace.org/Figs/G281.gif" alt="CAP Binding Induces DNA Bending"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="http://genes.atspace.org/10.9.html">Figure 10.27 CAP bends DNA &gt;90° around the center of symmetry.</a></td></tr></tbody></table><ol><li><p><strong>Study Focus</strong>: Investigation of the DNA bending effect due to CAP–cAMP binding using electrophoresis.</p></li><li><p><strong>Method</strong>:</p><ul><li>Prepared equal length DNA fragments of the lac operon with varied CAP-binding site positions.</li><li>Bound CAP–cAMP to each fragment.</li><li>Performed electrophoresis to observe the migration rates of the DNA-protein complexes.</li></ul></li><li><p><strong>Findings</strong>:</p><ul><li>DNA fragments exhibited different migration rates, indicating DNA bending.</li><li>The degree of bending was estimated to be around 90 degrees, aligning reasonably with the 100 degrees found in later x-ray crystallography studies.</li></ul></li><li><p><strong>Implication</strong>: The observed DNA bending is believed to facilitate optimal interactions between proteins and DNA in the complex.</p></li></ol><h2 id="CAP-cAMP-Binding-Functionally-Similar-to-Up-Element">CAP-cAMP Binding Functionally Similar to Up Element</h2><table><thead><tr><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/09/pPcQIYQ.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center">P182; Figure 7.19</td></tr></tbody></table><ol><li><p><strong>Study Focus</strong>: Importance of interaction between CAP and RNA polymerase’s aCTD in transcription stimulation.</p></li><li><p><strong>Experiment Details</strong>: Used RNA polymerases with both normal and truncated a-subunits to transcribe cloned lac operons in vitro.</p></li><li><p><strong>Findings</strong>:</p><ul><li>Truncated a-subunits could function like wild-type in absence of CAP-cAMP.</li><li>Truncated a-subunits weren’t stimulated by CAP-cAMP, indicating the necessity of aCTD for CAP-cAMP stimulation.</li></ul></li><li><p><strong>Hypothesis</strong>: CAP-cAMP dimer, binding to its activator site, interacts with aCTD, enhancing polymerase’s affinity for the promoter, similar to aCTD’s role with UP elements.</p></li></ol><h2 id="CAP-promoters">CAP promoters</h2><h3 id="3-Classes-of-CAP-Regulated-Promoters">3 Classes of CAP Regulated Promoters</h3><table><thead><tr><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/10/pPclzHf.png" alt="3 Classes of CAP Regulated Promoters"></th></tr></thead><tbody><tr><td style="text-align:center">Unknown</td></tr></tbody></table><table><thead><tr><th><strong>Attribute</strong></th><th><strong>Class I</strong></th><th><strong>Class II</strong></th><th><strong>Class III</strong></th></tr></thead><tbody><tr><td><strong>Activation</strong></td><td>Requires only CAP</td><td>Requires only CAP</td><td>Requires CAP and additional regulators</td></tr><tr><td><strong>CAP/CRP Binding Site</strong></td><td>Upstream of the promoter</td><td>Overlaps the promoter, replacing -35 region</td><td>Variable, typically &gt;90 bp upstream</td></tr><tr><td><strong>Prototype</strong></td><td>LacP1</td><td>GalP1</td><td>None</td></tr><tr><td><strong>Location (from start point)</strong></td><td>Centered 61.5 bp upstream</td><td>Centered 41.5 bp upstream</td><td>More than 90 bp upstream</td></tr><tr><td><strong>Examples</strong></td><td>-</td><td>-</td><td>AraBAD, malK promoter</td></tr></tbody></table><p><strong>CAP Operators Display Periodicity</strong>: The greatest activation was seen at distances of -41.5 and -61.5 which correspond exactly to the spacings observed in CLASS II and CLASS I CRP-activated promoters, respectively.</p><h2 id="DNA-Bending-as-a-Regulatory-Mechanism">DNA Bending as a Regulatory Mechanism</h2><table><thead><tr><th style="text-align:center">Illustrate</th><th style="text-align:left">Description</th></tr></thead><tbody><tr><td style="text-align:center"><img src="https://upload.wikimedia.org/wikipedia/en/8/86/Promoter_bashing.svg" alt=""></td><td style="text-align:left">- Promoter bashing of a hypothetical two-region promoter. The promoter is cloned upstream of the lacZ reporter gene. Point mutations that inactivate each region are made (the red Xs) and the region is cloned onto a plasmid and inserted into E. coli cells, grown up, and has the presence of reporter measured. The binding of Protein B in this example is necessary for RNA polymerase to bind and initiate transcription.<br>- In a laboratory setting, it may not be known that the promoter consists of two regions – single mutations can be made along the promoter, the promoter can be sequenced, and the levels of reporter assayed to find boundaries for each region.</td></tr><tr><td style="text-align:center"><a href="https://en.wikipedia.org/wiki/Promoter_bashing">© wiki</a></td><td style="text-align:left"></td></tr></tbody></table><h3 id="araBAD-Operon">araBAD Operon</h3><ul><li>araBAD encodes enzymes responsible for arabinose breakdown</li><li>Operon is catabolite repressed, and thus requires CAP.cAMP for activation of transcription</li><li>Activation also requires the complex of AraC. arabinose as an activator</li><li>Explains why araBAD is only transcribed in the presence of arabinose</li></ul><p><strong>Components:</strong></p><ul><li><strong>araO<sub>2</sub></strong>: Far upstream binding site for AraC.</li><li><strong>araO<sub>1</sub></strong>: Located between positions -106 and -144, another binding site for AraC.</li><li><strong>araI</strong>: Divided into araI<sub>1</sub> (-56 to -78) and araI<sub>2</sub> (-35 to -51), each can bind one monomer of AraC.</li><li><strong>araA-D</strong>: Four genes in the ara operon where araB, araA, and araD are for arabinose metabolizing enzymes and araC is for encoding the control protein AraC.</li><li><strong>araPBAD</strong>: Promoter for rightward transcription of araB, A, and D.</li><li><strong>araP<sub>C</sub></strong>: Promoter for leftward transcription of araC.</li></ul><p><strong>States:</strong></p><ol><li><p><strong>Without Arabinose (Repressed State):</strong></p><ul><li>AraC binds to araO2 and araI1.</li><li>Causes DNA looping between the binding sites, repressing the operon.</li></ul></li><li><p><strong>With Arabinose (Derepressed State):</strong></p><ul><li>Arabinose alters AraC conformation.</li><li>AraC binds to araI<sub>1</sub> and araI<sub>2</sub>, breaking the repression loop.</li><li>The operon is derepressed.</li></ul></li></ol><p><strong>Positive Control:</strong></p><ul><li>Involves CAP and cAMP.</li><li>They bind to a site upstream of the araBAD promoter.</li><li>DNA looping facilitates CAP’s contact with polymerase, enhancing its binding to the promoter, thereby stimulating transcription.</li></ul><p><strong>Figures:</strong></p><ul><li><strong>Figure 7.21a</strong>: Illustrates the three binding sites of AraC.</li><li><strong>Figure 7.21b</strong>: Shows the repression loop in the absence of arabinose.</li><li><strong>Figure 7.21c</strong>: Depicts the derepressed state with the presence of arabinose and how CAP-cAMP complex influences transcription.</li></ul><p>This structure helps in detailing the different components involved and the states of the ara operon based on the presence or absence of arabinose, along with the role of CAP and cAMP in its regulation. It also mentions the figures that visualize these processes.</p><h3 id="Arabinose-Metabolism-System">Arabinose Metabolism System</h3><h3 id="Promoter-Bashing-Identified-Two-Operator-Sites-for-Repression">Promoter Bashing Identified Two Operator Sites for Repression</h3><h3 id="DNA-Bending-Requires-both-araO2-and-araI-Sites">DNA Bending Requires both araO2 and araI Sites</h3><div class="admonition question"><p class="admonition-title">How can araO2 control transcription from a promoter over 250 bp downstream?</p><p>The most reasonable explanation is that the DNA in between these remote sites (the operator and the promoter) loops out as illustrated in</p></div><p>Sure! Here is a summarized version of the passage in note form:</p><table><thead><tr><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/10/pPc1DxA.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center">P184; Figure 7.22</td></tr></tbody></table><p><strong>Experiment setup:</strong></p><ul><li><strong>Objective:</strong> Verify AraC-induced DNA loop formation in the ara operon in the absence of arabinose.</li><li><strong>Materials:</strong><ul><li>404-bp supercoiled minicircle DNA containing araO2 and araI sites, 160 bp apart.</li><li>AraC protein.</li></ul></li><li><strong>Method:</strong> Electrophoresis to measure DNA loop formation by monitoring changes in electrophoretic mobility.</li></ul><p><strong>Findings:</strong></p><ol><li><p><strong>AraC induces loop formation:</strong></p><ul><li><strong>Evidence:</strong> A new high-mobility band observed upon addition of AraC, indicating looped minicircle (Figure 7.22, compare lanes 1 and 2).</li></ul></li><li><p><strong>Loop stability depends on both araO2 and araI:</strong></p><ul><li><strong>Tested using:</strong><ul><li>Wild-type minicircle.</li><li>Minicircle with mutant araO2.</li><li>Minicircle with mutations in both araI sites.</li></ul></li><li><strong>Results:</strong><ul><li><strong>Wild-type:</strong> Half-time of dissociation ~100 min (50% conversion to unlooped form in 90 min, lanes 3-5).</li><li><strong>araO2 mutant:</strong> Loop broke in &lt;1 min, indicating a crucial role in loop maintenance (lanes 7 and 8).</li><li><strong>araI mutant:</strong> Half-time of loop breakage &lt;10 min, underscoring its role in loop stability.</li></ul></li></ul></li></ol><p><strong>Conclusion:</strong></p><ul><li>AraC can induce DNA looping at the ara operon in the absence of arabinose.</li><li>Both araO2 and araI sites are vital for loop stability; mutations in either site destabilize the loop significantly, showcasing their roles in the AraC-mediated DNA looping mechanism.</li></ul><h3 id="Spacing-is-Important">Spacing is Important</h3><h3 id="AraC-Binding-to-araO2-is-Disrupted-by-Arabinose-Binding-Regulation-of-araPBAD">AraC Binding to araO2 is Disrupted by Arabinose Binding &amp; Regulation of <em>ara</em>P<sub>BAD</sub></h3><table><thead><tr><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/10/pPc1xz9.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center">P184; Figure 7.21</td></tr></tbody></table><p><strong>Experiment Setup:</strong></p><ul><li><strong>Objective:</strong> Understand the effect of arabinose on the AraC-induced DNA loop and elucidate the role of araI2 in AraC binding.</li><li><strong>Materials:</strong><ul><li>Looped minicircles (404-bp supercoiled DNA with araO2 and araI sites).</li><li>Arabinose.</li><li>AraC protein.</li></ul></li><li><strong>Methods:</strong><ul><li>Electrophoresis to observe the influence of arabinose on loop stability.</li><li>Methylation interference to study AraC contacts with araI sites in different states.</li></ul></li></ul><p><strong>Findings:</strong></p><ol><li><p><strong>Arabinose <mark>breaks the repression loop</mark>:</strong></p><ul><li><strong>Evidence:</strong> Disappearance of the looped DNA band upon adding arabinose before electrophoresis (refer to Figure 7.23).</li></ul></li><li><p><strong>Reformation of <mark>broken loop</mark>:</strong></p><ul><li><strong>Conditions:</strong> Removal of arabinose allowed the broken loop to re-form, illustrating reversible control mediated by arabinose.</li></ul></li><li><p><strong>AraC’s <mark>contact shifts from araO2 to araI2</mark>:</strong></p><ul><li><strong>Evidence:</strong><ul><li><strong>Methylation interference:</strong> AraC contacts araI1 but not araI2 in the looped state. Two araI1 bases were lightly methylated in looped DNA and heavily methylated in unlooped DNA, indicating crucial roles in looping.</li><li><strong>Mutation study:</strong> AraI2 mutations didn’t affect AraC binding in looped state but significantly influenced it in the unlooped state, highlighting its role in AraC binding post-loop breakage.</li></ul></li></ul></li></ol><p><strong>Conclusion:</strong></p><ul><li>Arabinose disrupts the AraC-induced DNA loop by altering AraC’s affinity for binding sites: it loses affinity for araO2 and gains affinity for araI2, a dynamic regulatory mechanism controlling the ara operon (depicted in Figure 7.21b and c).</li><li>The role of araI2 is crucial in AraC binding in the unlooped state, facilitating the reformation of the loop upon arabinose removal.</li></ul><h3 id="AraC-autoregulates-its-Own-Expression">AraC autoregulates its Own Expression</h3><table><thead><tr><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/10/pPc1jG4.png" alt="AraC autoregulates its Own Expression"></th></tr></thead><tbody><tr><td style="text-align:center">Molecular Biology; Weaver, Robert: Fifth edition</td></tr></tbody></table><ul><li><p><strong>Background:</strong></p><ul><li><strong>araO1’s function:</strong> Not involved in the repression of araBAD transcription.</li><li><strong>Location:</strong> Positioned to control the transcription of the araC gene (refer to Figure 7.24).</li></ul></li><li><p><strong>Autoregulation Mechanism:</strong></p><ol><li><strong>Transcription Direction:</strong> The araC gene is transcribed leftward from the Pc promoter.</li><li><strong>Binding to araO1:</strong> As AraC levels increase, it binds to araO1.</li><li><strong>Inhibition of Transcription:</strong> The binding of AraC to araO1 inhibits further leftward transcription from Pc.</li><li><strong>Control of AraC Levels:</strong> The process prevents excessive accumulation of AraC, ensuring self-regulation of its synthesis levels.</li></ol></li><li><p><strong>Conclusion:</strong></p><ul><li><strong>Autoregulation:</strong> The mechanism through which AraC controls its own synthesis by inhibiting transcription upon binding to araO1 is termed autoregulation.</li><li><strong>Regulatory Balance:</strong> This autoregulation helps maintain a balance in AraC levels, avoiding its overproduction and ensuring optimal functioning of the operon regulatory system.-</li></ul></li></ul><hr><h2 id="Positive-promoter-elements">Positive promoter elements</h2><p>Lactose operon promoter:<br>-35 and -10 sequences are the two binding site of the CRP-cAMP. One of them are mutated, the binding still performed. But simultaneous mutation would decrease the expression level.</p><ul><li>CAP is a universal transcription promoter</li><li>CAP is a sequence-specific DNA binding protein</li><li>CAP responds to cAMP levels in the cell.</li><li>it binds a dimer</li><li>cAMP-CAP binding is required for high expression of the lac operon-- conserves the cells energy.</li><li>TGTGA sequence</li></ul><p>So far, hundreds of genes have been discovered which are under the control of the CAP-cAMP complex. Among them are genes involved in cell division, carbon metabolism, flagellar synthesis (controlling the motility), cell energy, nitrogen utilization, iron uptake and drug resistance</p><h3 id="CAP-recruitment">CAP recruitment</h3><ol><li>Forma- tion of the closed promoter complex</li><li>conversion of the closed promoter complex to the open promoter complex.</li></ol><p>P19<br>DNA binding doesn’t change so much, but the transcription activation is different.</p><p>Eukaryol: homodimer<br>Prokaryotic /heterodimers</p><p>Class 1: far away from the gene<br>Class 2: closer to the gene</p><p>Kb creating close<br>k2: transition close to the open</p><p>Different promoter classes Utilize different protein regions.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Molecule and Cellular Biology 4</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Class" scheme="https://karobben.github.io/categories/Notes/Class/"/>
    
    <category term="UIUC" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/"/>
    
    <category term="Cell Biology" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/Cell-Biology/"/>
    
    
    <category term="Classes" scheme="https://karobben.github.io/tags/Classes/"/>
    
    <category term="UIUC Classes" scheme="https://karobben.github.io/tags/UIUC-Classes/"/>
    
    <category term="Cell Biology" scheme="https://karobben.github.io/tags/Cell-Biology/"/>
    
  </entry>
  
  <entry>
    <title>Molecule and Cellular Biology 3</title>
    <link href="https://karobben.github.io/2023/08/29/LearnNotes/UIUC-AdMC-3/"/>
    <id>https://karobben.github.io/2023/08/29/LearnNotes/UIUC-AdMC-3/</id>
    <published>2023-08-29T13:09:04.000Z</published>
    <updated>2023-09-09T19:42:01.667Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Reading-for-this-week">Reading for this week:</h2><ul><li>Book<br>Molecular Biology Chapters 7.1, 7.2</li><li>Review:<br><strong>Transcription activation by catabolite activator protein (CAP)</strong>. Busby, S. and Ebright, R.H. J Mol Biol. 1999 Oct 22;293(2):199-213.<br><strong>Bacterial nucleoid-associated proteins, nucleoid structure and gene expression</strong>. Dillon, S.C. and Dorman C.J. Nat Rev Microbiol. 2010 Mar;8(3):185-95.</li><li><strong>Journal Club Paper (to be presented the following week):</strong><br><strong>A phage-encoded nucleoid associated protein compacts both host and phage DNA and derepresses H-NS silencing</strong>. Son B, Patterson-West J, Arroyo-Mendoza M, Ramachandran R, Iben JR, Zhu J, Rao V, Dimitriadis EK, Hinton DM. Nucleic Acids Res. 2021 doi: 10.1093/nar/gkab678.</li></ul><h2 id="Points-for-the-lecture">Points for the lecture:</h2><ul><li>Transcription can be actively <strong>regulated</strong></li><li><strong>Small molecules</strong> can control gene programs</li><li><strong>Operons</strong> help balance protein expression in a pathway<ul><li>co-regulate as unite</li></ul></li><li>Protein <strong>allostery</strong><ul><li>Many level, 1. small molecular, 2. DNA (Bind something to make conformation change.)</li></ul></li><li><strong>Transcription factors</strong> can bend DNA</li></ul><h2 id="Role-of-Regulatory-Proteins-in-Transcription-Initiation">Role of Regulatory Proteins in Transcription Initiation</h2><ul><li>Regulatory proteins bind to specific DNA sequences (<strong>operator/response element</strong>) and control initiation of transcription</li><li><strong>Repressors</strong> - regulatory proteins that prevent transcription of a negatively regulated<br>gene *negatively regulated genes can only be transcribed in the absence of the repressor</li><li><strong>Activators</strong> - regulatory proteins that activate transcription of a positively regulated gene</li><li>Repressors and Activators are often <strong>allosteric proteins</strong> modified by ligand binding</li><li><strong>Agonist</strong> - positively acting ligand</li><li><strong>Antagonist</strong> - negatively acting ligand</li></ul><h2 id="Activator-Strategies-for-Transcriptional-Regulation">Activator Strategies for Transcriptional Regulation</h2><ul><li><p>Ligand binding triggers promoter <mark>association</mark> and RNA <mark>is</mark> produced (Trigger the initiation)</p></li><li><p>Ligand binding triggers promoter <mark>dissociation</mark> and RNA is <mark>not</mark> produced (Stop the transcription)</p></li></ul><p>THe contact is so much and some of the mechanism are still not figured out.</p><h3 id="Repressor-Strategies-for-Transcriptional-Regulation">Repressor Strategies for Transcriptional Regulation</h3><ul><li>Ligand binding triggers promoter <mark>dissociation</mark> and RNA <mark>is</mark> produced</li><li>Ligand binding triggers promoter <mark>association</mark> and RNA <mark>is not</mark> produced</li></ul><h2 id="Transcription-Factors-Bind-Operators-bacteria-Response-Elements-eukaryotes">Transcription Factors Bind Operators (bacteria)/Response Elements (eukaryotes)</h2><p>Eu: Inhancers, depends on different regulation gene, far away from the genes.</p><p>Ba: almost all close to the gene</p><p>!!!  How do you find an Operator/Response Element?<br>- Operators<br>- Many TFs bind inverted repeats as <strong>dimers</strong><br>- More interactions = greater affinity<br>- Enhancer<br>- Promoter ‘Bashing’<br>lacZ could be a report aod transcription reporter and change the color of the cell in this assay.<br>- Linker-scanner Mutagenesis to Refine Position of Promoter Proximal Elements (after the Promoter ‘Bashing’)</p><h2 id="peron">peron</h2><p>Bacteria and viruses often express <mark>functionally operative</mark> genes from a <mark>single promoter</mark> to help insure<br>uniform expression</p><p>DNA order: Activator binding site  promoter, Repressor binding sit (Operator)</p><h3 id="Example-Lactose-Lac-Operon">Example: Lactose (Lac) Operon</h3><ol><li>Lactose permease (Lacy)</li><li>B-Galactosidase (LacZ)</li><li>Thiogalactoside transacetylase (LacA)</li></ol><p>!!! What about the Lactose operon:</p><pre><code>The lac operon in E. coli is one of the most well-studied systems for gene regulation. This operon contains genes for enzymes required for the metabolism of lactose, a disaccharide sugar. The operon consists of three genes:- **lacZ**: Codes for \(\beta\)-galactosidase, which hydrolyzes lactose into glucose and galactose.- **lacY**: Codes for galactoside permease, a transport protein that facilitates the entry of lactose into the cell.- **lacA**: Codes for galactoside transacetylase, whose function is not entirely clear.These genes are transcribed into a single polycistronic mRNA, meaning that they are expressed together. This allows for coordinated control of these functionally related genes.- **Negative Control: The Brake**  In the absence of lactose, a protein called the lac repressor binds to the operator region of the operon, blocking RNA polymerase and thus preventing transcription. This is a form of negative control; it keeps the operon turned off when lactose is not present, which is efficient for the cell.- **Positive Control: The Accelerator**  The lac operon also has a system for positive control, mediated by an activator protein that responds to glucose levels in the cell. This activator is cAMP-CAP (cAMP Receptor Protein). When glucose levels are low, cAMP levels are high, allowing CAP to bind and enhance the transcription of the lac operon.- **Diauxic Growth: Switching from Glucose to Lactose**  When E. coli is grown in a medium containing both glucose and lactose, it exhibits diauxic growth. The bacteria consume glucose first and only switch to lactose metabolism once glucose is depleted. This switch involves a lag phase where the lac operon is activated, allowing the cells to make the enzymes needed for lactose metabolism.- Advantages of Dual Control  1. **Economic Efficiency**: Negative control ensures that the enzymes for lactose metabolism are not produced when lactose is not present. This is energy-efficient.  2. **Resource Prioritization**: Positive control ensures that even if lactose is present, the lac operon will not be fully activated if glucose is also available. This allows E. coli to prioritize the easier-to-metabolize glucose.In summary, the lac operon is a sophisticated system that allows E. coli to adapt to changing nutritional conditions efficiently, ensuring that it utilizes available resources in a manner that is both effective and economical.</code></pre><h4 id="The-Operon-Model-History">The Operon Model (History)</h4><ul><li>A landmark in the history of Molecular Biology was the proposal of the operon model of genetic regulation by François Jacob and Jacques Monod in 1961.</li><li>The core of the model was that the level of proteins in cells was controlled at a genetic level. The theory also predicted the existence of mRNA-an unstable intermediate between the genome and the expressed protein.</li><li>Before this work the prevailing model was called the instruction hypothesis that stated that all proteins were present in a cell, but that in the absence of an inducer they were not properly folded and were inactive.</li><li>Jacob and Monod were awarded the Nobel Prize in 1965 for their work on characterising genes involved in lactose utilization</li></ul><h2 id="Differential-Growth-based-on-Carbon-Source">Differential Growth based on Carbon Source</h2><ul><li><p>Glucose is more rapidly used than lactose, so cells grow faster on glucose.</p></li><li><p>When both present growth is bi- phasic, which is called a diauxic shift.</p></li></ul><p>When you mix up them, the bacteria make the choice. They know when and how to switch the strategies.</p><h2 id="Cell-numberBiological-Purpose-of-Lac-Operon">Cell numberBiological Purpose of Lac Operon</h2><ul><li><p><strong>LacZ</strong> gene: encodes $\beta$ -galactosidase enzyme that breaks down disaccharide lactose into glucose and galactose to be used as source of energy for cell.</p></li><li><p><strong>LacY</strong> gene: encodes $\beta$ -galactoside permease, a membrane-bound protein that helps transport lactose across the membrane of cell.</p></li><li><p><strong>LacA</strong> gene: encodes  -galactoside transacetylase enzyme involved in catabolism of disaccharide (exact role is less clear)</p></li></ul><blockquote><ul><li>Genetic Screen Based on Enzymatic Activity (Blue: lacZ activity)<br>5-bromo-4-chloro-3-indolyl-$\beta$D-galactoside</li><li>Natural &amp; Synthetic Small Molecules<br>IPTG is a non-metabolized analog of allolactose that induces Lac operon but is not broken down by enzymes.<br>Lactose is a disaccharide composed of galactose and glucose linked in a  configuration (1-&gt;4). -galactosidase, the product of the lacZ gene, cleaves this disaccharide into galactose and glucose which can then both be metabolized by the cell. E. coli does not always make this enzyme. It is an inducible enzyme which is synthesized only when lactose is present and when glucose is absent from the growth media. Glucose is one of the few sugars which E. coli will use preferentially over all other sugars because it can be directly routed into glycolysis after phosphorylation without any other modifications.</li></ul></blockquote><h2 id="Merodiploids-Helped-to-Unravel-the-Role-of-Genes-in-the-lac-operon">Merodiploids Helped to Unravel the Role of Genes in the lac operon</h2><h2 id="Studying-the-Lac-Operon">Studying the Lac Operon</h2><p>Isolation and analysis of mutants defective in Lac operon function allowed Jacob and Monod to formulate an accurate Lac operon model PRIOR to the advent of molecular cloning<br>e.g., wild type E. coli form colonies that are blue on IPTG/ XGAL plates and white on XGAL plates</p><p>Mutants that form white colonies on IPTG/XGAL plates can be isolated * this phenotype is often due to a mutation in a Lac structural gene * the number and location of Lac structural genes can be identified by complementation analysis<br>Mutants that form blue colonies on XGAL (no IPTG) can be isolated * this phenotype is often due to a mutation in either the Lac repressor gene or Lac operator * Lac repressor versus operator mutations can be distinguished by cis-trans test F’ plasmids carrying different pieces of E. coli chromosome can be isolated in HFR strains, allowing the creation of partial diploids.<br>F’ plasmid can carry wild type or mutant versions of Lac operon between strains</p><h2 id="Complementation-Analysis-and-Cis-Trans-Tests">Complementation Analysis and Cis-Trans Tests</h2><p>Phenotypes and Genotypes of Mutants Defective in Lac Operon Function</p><ul><li>Lower case letter with superscript asterisk indicates location of mutation</li><li>In practice, you would not know the location; you would only know the phenotypes (blue or white color on  XGAL/IPTG or XGAL) of the haploid (or homozygous diploid) and the heterozygous diploid</li></ul><p>e.g., The diploid resulting from conjugating mutants 2 and 3 give a normal phenotype, consistent with mutations 1 and 2 being recessive and located in different structural genes (i.e., in the diploid there is at least one normal copy of each gene and a correspondingly normal protein)</p><blockquote><p>Mutaion -&gt; got the different phynotype -&gt; trans is protine, cis is DNA. -&gt; Bind the two mutation: Make the crosses and repeat the phenotype. They don’t know what are they yet. The name is made by them and the mechanim are solved years later after the sequencing techs.</p></blockquote><h2 id="‘Trans’-and-‘Cis’">‘Trans’ and ‘Cis’</h2><ul><li><p>In genetic terminology: The lac repressor is a trans-acting element<br>trans = across</p></li><li><p>The operator is a cis-acting element<br>cis=near</p></li></ul><p>The lac repressor is a sequence-specific DNA-binding protein that Negatively regulates expression of the lac operon structural genes.</p><h3 id="Trans-Complementation">Trans Complementation</h3><p>Merodiploid: lacZ - / F’ lacY -<br>lacI<br>lacO lacZ<br>lacY<br>lacA<br>lacI<br>lacO<br>lacZ<br>lacY lacA</p><h3 id="‘Simple’-Mechanism-for-Gene-Regulation-by-Lac-Repressor">‘Simple’ Mechanism for Gene Regulation by Lac Repressor</h3><table><thead><tr><th style="text-align:center"><img src="https://botanystudies.com/wp-content/uploads/2017/09/Negative-Control-of-Lac-Operon.jpg" alt=""></th></tr></thead><tbody><tr><td style="text-align:center">P170; Figure 7.3</td></tr></tbody></table><ul><li>Negative Control<ul><li>Operon naturally “on.”</li><li>Turned “off” by repressor protein from lacI gene.</li></ul></li><li>Allosteric Regulation<ul><li>Repressor is allosteric; its shape changes.</li><li>Inducer is allolactose, changes repressor shape.</li><li>Changed repressor can’t bind to operator, operon “on.”</li></ul></li><li>Basal Level &amp; Initial Activation<ul><li>Repression “leaky,” small amounts of β-galactosidase and permease always present.</li><li>Enough for initial lactose uptake and allolactose creation.</li></ul></li><li>Positive Feedback (Snowball Effect)<ul><li>Derepression leads to more β-galactosidase and permease.</li><li>More lactose uptake and allolactose creation.</li><li>Operon stays “on” if lactose present and glucose absent.</li></ul></li><li>Summary<ul><li>Negative control via repressor.</li><li>Allosteric regulation via allolactose.</li><li>Initial activation via “leaky” repression.</li><li>Positive feedback maintains activation.</li></ul></li></ul><h2 id="Lactose-Levels-“Tune”-the-Response">Lactose Levels “Tune” the Response</h2><p>In the absence of lactose there are only 1-5 molecules of each of the lacZYA proteins in the cell. Following<br>induction, up to 5000 molecules of -<br>galactosidase can accumulate within<br>minutes.</p><p>As lactose is cleaved and used as a carbon source for growth the lactose levels drop. Eventually free repressor molecules will accumulate once more and the lac operon will be switched off.</p><h2 id="Impact-of-Inducer-on-Repressor-DNA-binding">Impact of Inducer on Repressor DNA binding</h2><table><thead><tr><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/07/pPyEuKH.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center">P174; Figure 7.6</td></tr></tbody></table><ul><li>Challenges Faced<ul><li>The lac repressor is in very low concentration in the cell.</li><li>No easy assay to identify the protein was available.</li></ul></li><li><mark>Strategies Used</mark><ul><li>Used a mutant E. coli strain with repressor mutation (lacI t).</li><li>This mutation made the repressor bind to IPTG (isopropylthiogalactoside) more tightly.</li><li>This allowed for detection of the repressor in very impure extracts.</li></ul></li><li>Purification<ul><li>Gilbert and Müller-Hill were able to purify the protein because they could now detect it.</li></ul></li><li>Operator-Binding Studies<ul><li>Conducted by Melvin Cohn and colleagues.</li><li>Used <mark>nitrocellulose filter-binding assay</mark>.</li></ul></li><li><mark>Results</mark><ul><li>Typical saturation curve observed for repressor–operator binding in the absence of inducer.</li><li>No binding observed in the presence of the synthetic inducer, IPTG.</li></ul></li><li>Summary<ul><li>Gilbert and Müller-Hill successfully purified the lac repressor using a mutant strain.</li><li>Cohn’s team demonstrated that inducer (IPTG) blocks repressor–operator binding.</li></ul></li></ul><h2 id="Protein-Allostery-Induced-Conformational-Changes">Protein Allostery (Induced Conformational Changes)</h2><h2 id="Lac-Repressor-Does-Not-Prevent-RNAP-Binding">Lac Repressor Does Not Prevent RNAP Binding</h2><table><thead><tr><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/07/pPyeSxS.png" alt="Repression by Steric Interference?"></th><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/07/pPyZx8f.png" alt="Lac Repressor Does Not Prevent RNAP Binding"></th></tr></thead><tbody><tr><td style="text-align:center">Unknow sours</td><td style="text-align:center">P175; Figure 7.8</td></tr></tbody></table><ul><li><p><strong>Traditional Assumption</strong>: Assumed that lac repressor denies RNA polymerase access to the promoter.</p></li><li><p><strong>Contradictory Evidence</strong></p><ol><li><strong>Pastan’s 1971 Experiment</strong>: Showed that RNA polymerase could bind to the lac promoter even in the presence of repressor.</li><li><strong>Straney and Crothers (1987)</strong>: Showed that polymerase and repressor can bind together to the lac promoter.</li></ol></li><li><p><strong>Alternative Explanations</strong></p><ol><li><strong>Straney and Crothers</strong>: Suggested repressor blocks the formation of an open promoter complex.</li><li><strong>Krummel and Chamberlin</strong>: Proposed that repressor blocks the transition from the initial transcribing complex to the elongation state, trapping the polymerase in a nonproductive state.</li></ol></li><li><p><strong>Supporting Evidence</strong></p><ul><li><strong>Jookyung Lee and Alex Goldfarb’s Experiment</strong><ul><li>Used a run-off transcription assay.</li><li>Found that RNA polymerase is engaged on the DNA template even in the presence of repressor.</li><li>Noted the appearance of shortened abortive transcripts (about 6 nt long) in the presence of repressor, suggesting repressor may lock the polymerase into a nonproductive state.</li></ul></li></ul></li><li><p><strong>Summary</strong></p><ul><li>Repressor doesn’t seem to block RNA polymerase from accessing the lac promoter.</li><li>Evidence suggests that the repressor may lock the polymerase into a nonproductive state, limiting it to making only abortive transcripts.</li></ul></li></ul><h2 id="What-is-the-Mechanism-of-Repression">What is the Mechanism of Repression?</h2><h3 id="Influence-of-Regulators-on-RNAP-Promoter-Complexes">Influence of Regulators on RNAP:Promoter Complexes</h3><p>$$<br>R + P \underset{K_ B}{\rightleftharpoons} RP_ c \underset{k_ 2}{\rightarrow} RP_ o<br>$$</p><ul><li>R is RNA polymerase</li><li>P is the promoter</li><li>RP<sub>c</sub> is the closed promoter complex</li><li>RP<sub>o</sub> is the open promoter complex.</li><li><strong>KB</strong><ul><li><strong>Definition:</strong> Indicates RNA polymerase’s binding affinity to a promoter.</li><li><strong>Influenced by:</strong> Repressors or activators affecting RNA polymerase binding.</li></ul></li><li><strong>k2</strong><ul><li><strong>Definition:</strong> Represents the rate-limiting step in forming an open complex; its physical meaning can vary between promoters.</li><li><strong>Influenced by:</strong> Repressors or activators affecting RNA polymerase-promoter interactions.</li></ul></li><li><strong>Insights</strong><br>Understanding KB and k2 helps in deciphering the effects of auxiliary proteins on RNA polymerase-promoter dynamics. It can hint at how the binding affinity is influenced and the complexities involved in open complex formation.</li></ul><h2 id="Impact-of-Repressor-on-RNAP">Impact of Repressor on RNAP</h2><p>At the lacUV5 promoter, the values of KB and k2 in the presence or absence of repressor are:</p><table><thead><tr><th>Condition</th><th>KB (M⁻¹)</th><th>k2 (s⁻¹)</th></tr></thead><tbody><tr><td>No repressor</td><td>1.9 x 10⁷ M⁻¹</td><td>6.7 x 10⁻² s⁻¹</td></tr><tr><td>With repressor</td><td>2.5 x 10⁹ M⁻¹</td><td>2.5 x 10⁻² s⁻¹</td></tr></tbody></table><ol><li>Data from Straney &amp; Crothers (1987) Cell 51: 699-707.</li><li>The UV5 mutation changes the -10 region of the lacP promoter so that it more closely resembles the consensus -10 sequence. It is a stronger promoter than lacP.</li></ol><p>These data indicate that the lactose repressor INCREASES the binding of RNAP 130-fold; suggest that repressor might be considered a activator. Repressor DECREASES k2 3-fold.</p><h2 id="Repressor-Dimers-Bind-on-Same-Face-of-DNA">Repressor Dimers Bind on Same Face of DNA</h2><table><thead><tr><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/10/pPc3gyR.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center">Unknown</td></tr></tbody></table><blockquote><p>By insert the DNA fragment between the operator and UV5, the transcription efficiency is changed.</p></blockquote><ul><li><strong>Key Findings:</strong><ul><li><strong>Repression maxima:</strong> Occur at distances integral to the DNA double helix pitch (59.5, 70.5, 81.5, 92.5, 115.5, 150.5 nm).</li><li><strong>Wild-type lac operon:</strong> Has a 92.5 nm spacer distance between operators.</li><li><strong>Gal operon:</strong> Features a 115.5 nm spacer distance between operators.</li><li><strong>Longer distances:</strong> Display smaller effects, with distances over 400 bp having little to no impact.</li><li><strong>Non-integral multiples:</strong> No repression observed, aligning with the DNA looping model’s predictions.</li></ul></li><li><strong>Implications:</strong><ul><li><strong>DNA Looping Model:</strong> The observations support a model where interaction is easy when proteins are bound on the same DNA face without needing torsional changes.</li><li><strong>DNA Pitch:</strong> Estimated to be 11.1 bp or 3.4 nm in vivo, based on repression maxima data.</li><li><strong>Limitations:</strong> Distances under 59.5 nm could not be measured due to interference with the promoter.</li></ul></li></ul><h2 id="Repressor-Binds-as-a-Tetramer">Repressor Binds as a Tetramer</h2><h2 id="DNA-Bending-Enables-Proteins-to-Bind-Cooperatively-to-Separated-Sites">DNA Bending Enables Proteins to Bind Cooperatively to Separated Sites</h2><table><thead><tr><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/10/pPcl7ND.png" alt="DNA Bending"></th></tr></thead><tbody><tr><td style="text-align:center"><img src="https://s1.ax1x.com/2023/09/10/pPclXjI.png" alt="Electron microscopy of l repressor bound to dual operators."></td></tr><tr><td style="text-align:center">Molecular Biology; Weaver, Robert: Fifth edition</td></tr></tbody></table><p>bending</p><ul><li>BEND FORMATION REQUIRES THAT BOTH PROTEINS BIND TO THE SAME FACE OF THE DNA</li></ul><p>No bending</p><ul><li>PROTEINS BOUND TO SITES ON OPPOSITE SIDES OF DNA HELIX CANNOT INTERACT</li></ul><h3 id="Lac-Tetramer-Stabilizes-Bent-DNA">Lac Tetramer Stabilizes Bent DNA</h3><h3 id="Detected-by-EMSA">Detected by EMSA</h3><p>Gel electrophosphate</p><h3 id="Promoter-Contains-3-Operator-Sites">Promoter Contains 3 Operator Sites</h3><table><thead><tr><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/08/pPyIRc4.png" alt=""></th><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/08/pPyI4BR.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center">P176; Figure 7.10</td><td style="text-align:center">P176; Figure 7.11</td></tr></tbody></table><h3 id="How-to-Resolve-if-Operator-2-or-3-is-preferred">How to Resolve if Operator 2 or 3 is preferred?</h3><ul><li>Chromatin Immunoprecipitation (ChIP) Assay</li><li>Determines the relative DNA Occupancy of a Target</li><li>Protein at a Particular Site in vivo</li></ul><h3 id="ChIP-Seq-can-Determine-Genome-wide-Binding-Site-Useage-of-a-Target-Protein">ChIP-Seq can Determine Genome-wide Binding Site Useage of a Target Protein</h3><p>Operator 1 + Operator 2: bind different place of the DNA and bind the DNA. Then Promoter is loaded much easier.</p><h2 id="Lac-Repressor-Binding">Lac Repressor Binding</h2><p>to be next: Multiple Regulators</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Molecule and Cellular Biology 3</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Class" scheme="https://karobben.github.io/categories/Notes/Class/"/>
    
    <category term="UIUC" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/"/>
    
    <category term="Cell Biology" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/Cell-Biology/"/>
    
    
    <category term="Classes" scheme="https://karobben.github.io/tags/Classes/"/>
    
    <category term="UIUC Classes" scheme="https://karobben.github.io/tags/UIUC-Classes/"/>
    
    <category term="Cell Biology" scheme="https://karobben.github.io/tags/Cell-Biology/"/>
    
  </entry>
  
  <entry>
    <title>Advanced Molecular &amp; Cell Biology 2</title>
    <link href="https://karobben.github.io/2023/08/23/LearnNotes/UIUC-AdBC-2/"/>
    <id>https://karobben.github.io/2023/08/23/LearnNotes/UIUC-AdBC-2/</id>
    <published>2023-08-24T04:01:49.000Z</published>
    <updated>2023-09-09T19:42:05.575Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Cellular-Biology-2">Cellular Biology 2</h2><p>Bacterial gene are clustered by function (it could regulated by a same prone)</p><p>THe invention of most cellular enzymatic mechanisms and biochemical pathways occured early in microbs and we are inherits it.</p><h2 id="Do-human-continue-to-evolve">Do human continue to evolve?</h2><ol><li>mtDNA mutation making more heat than ATP. Common in Artuc peoples</li><li>Sickle-cell hemogolobin mutations conferring malarial resistance.<br>3 CCR5 delta32 mutation impairing HIV binding to white blood cells. Found esp. In NE, Speculate that it protected against some other pathoge 700 years ago/</li><li>Pre-disposition of hunter-gathere populations t obesity and type-2 diabetes in wester diet.</li><li>Mutation in the Tibetan populations enabling high blood O2 EPAS2 variatn  inherited form Denisovans.</li><li>Multople copies of salivary amylase in populations with high-starh diet</li></ol><p>Q1: whay aren’t there alternative forms of life on Earth?</p><p>Nasa: search for L-isoleucine</p><h2 id="Separated-perticula-questions-from-biology-and-lack-of-the-big-picture">Separated perticula questions from biology and lack of the big picture.</h2><p>Z ion channel; Methane; virus; Phosphorite sugar, ribosome, Chromosome separation, Chaperones.</p><p>So, the question is What is ‘life’?</p><ol><li><p>Metabolism pathway is very complicated.<br>, The hard part about bilogy is its complexity:<br>from isolated cell → clonal collaboration → consotia of multiple species → Tissues → Systems<br>Even a single cell too complex to be understand.</p></li><li><p>Which genes are necessary for something to live?</p><ul><li>it could help ua to understadn how a cell work,</li><li>how life evolved</li><li>build an artificial organism.</li></ul></li></ol><p>Number of Genes:<br>E. Coli: 4200<br>Stretomyctes: 9000<br>saccharomyces cerevisiae: 6200<br>human: 22000</p><h2 id="What-are-the-essential-parts-of-a-cell">What are the essential parts of a cell?</h2><ul><li>Mycoplasma genitalium: 525 genes, an intracellular parasite.<ul><li>Lack a cell wall.</li><li>in a stable environment, so a few adaptive strategies</li><li>Depends on hosts as a source of nutrients.</li></ul></li><li>What genes are universal?<br>Hemophilus influenzae: 1815, 256 shared with M. geneitalium.<br>Challenge:<ul><li>different isozymes could perform the same critial processe: rebonucleoacid redundant: With/without oxygen</li><li>BActeria and eukarya make esterified lipids.</li><li>Humans oxidize NADH via a respiratry chain, yeast do it by making alcohol.</li><li>The specific mechanisms are non-universal- but they are essential to the organism.</li></ul></li></ul><h2 id="Reasoning-from-first-principles">Reasoning from first principles.</h2><p>Transport<br>Energy: carry lots of thermodynamic unfavorite actions for life.</p><h2 id="Which-Genes-cannot-be-knocked-out-without-loss-of-viability">Which Genes cannot be knocked out without loss of viability</h2><ul><li>insert transposon: gene knock out: sequencing the clone and get the non-essential genes</li></ul><p>No mutation list:</p><ul><li>tRNA synthetases</li><li>Ribosome</li><li>Translation factors</li><li>Protein secretion</li><li>Chaperones</li><li>DNA replication</li><li>Transcription</li><li>Cell division</li><li>Nucleotide synthesis</li><li>Cofactor synthesis</li><li>Fatty acid synthesis</li><li>Cell wall synthesis</li><li>Some ventral metabolism</li></ul><p>171 gene in E. Coli were not knocked out.</p><ul><li>biosynthetic genes and catabolic genes (medial is rich in lots of source)</li></ul><p>435 genes are essential for microplasmid and it growth much slower than normal</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Advanced Molecular &amp; Cell Biology 2</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Class" scheme="https://karobben.github.io/categories/Notes/Class/"/>
    
    <category term="UIUC" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/"/>
    
    <category term="Cell Biology" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/Cell-Biology/"/>
    
    
    <category term="Classes" scheme="https://karobben.github.io/tags/Classes/"/>
    
    <category term="UIUC Classes" scheme="https://karobben.github.io/tags/UIUC-Classes/"/>
    
    <category term="Cell Biology" scheme="https://karobben.github.io/tags/Cell-Biology/"/>
    
  </entry>
  
  <entry>
    <title>Advanced Molecular &amp; Cell Biology 2</title>
    <link href="https://karobben.github.io/2023/08/23/LearnNotes/UIUC-AdMC-2/"/>
    <id>https://karobben.github.io/2023/08/23/LearnNotes/UIUC-AdMC-2/</id>
    <published>2023-08-24T04:01:49.000Z</published>
    <updated>2023-09-09T19:42:03.339Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Points-for-the-lecture">Points for the lecture:</h2><ul><li><p>Subunits of any complex typically have distinct activities</p><blockquote><ul><li>The distinct functions of subunits are evident in the RNA polymerase complex, where each subunit specializes in a particular aspect of transcription. For instance, the α subunit is crucial for initiation and interaction with regulatory proteins.</li></ul></blockquote></li><li><p>Sigma factors, in part, determine promoter specificity</p><blockquote><ul><li>Sigma factors are essential for guiding the RNA polymerase to specific sets of genes, ensuring the right genes are expressed under certain conditions.</li></ul></blockquote></li><li><p>Two modes of transcriptional termination in bacteria</p><blockquote><ul><li>These are the Rho-independent and Rho-dependent mechanisms. Each has its unique sequence cues and processes to halt transcription.</li></ul></blockquote></li></ul><h2 id="Transcription-Initiation-In-Four-Steps">Transcription Initiation In Four Steps</h2><ol><li>Forming the <strong>closed promoter complex</strong></li></ol><blockquote><ul><li>This is the initial binding of the RNA polymerase to the promoter region without unwinding the DNA.</li></ul></blockquote><ol start="2"><li>Forming the <strong>open promoter complex</strong></li></ol><blockquote><ul><li>Here, the DNA around the promoter region unwinds, providing a single-stranded template for transcription.</li></ul></blockquote><ol start="3"><li><strong>Incorporating</strong> the first few nucleotides</li></ol><blockquote><ul><li>RNA polymerase begins the synthesis of the RNA strand. It’s a crucial step, ensuring the fidelity of the process.</li></ul></blockquote><ol start="4"><li>Promoter <strong>clearance</strong></li></ol><blockquote><ul><li>After successful initiation, the RNA polymerase moves forward, leaving the promoter region, and enters the elongation phase of transcription.</li></ul></blockquote><p><img src="https://cdn1.byjus.com/wp-content/uploads/2018/12/difference-between-prokaryotic-and-eukaryotic-transcription.png" alt="Transcription Initiation In Four Steps"><br><a href="https://byjus.com/biology/difference-between-prokaryotic-and-eukaryotic-transcription/">→ Source</a></p><h2 id="sigma-Factor-is-Recycled">$\sigma$ Factor is Recycled</h2><blockquote><p>After initiation, the sigma factor can dissociate from the RNA polymerase and be used again for another round of transcription initiation. This recycling process is efficient for the cell.</p></blockquote><p>It is discoverd in a very simply assay. After add the fresh core, it got more transcription products.</p><p>Red curve: Only one round of chain initiation is possible at low ionic strength because (core) polymerase does not dissociate from DNA.<br>Green curve: Fresh core polymerase added. (Products surge)</p><h2 id="Forster-Resonance-Energy-Transfer-FRET">Förster Resonance Energy Transfer (FRET)</h2><p>experiment: retain the core during the cycle.</p><blockquote><p>“FRET studies have been pivotal in understanding sigma factor dynamics during transcription. By employing FRET, the interaction between sigma factors and the core RNA polymerase during various stages of transcription was elucidated.”</p></blockquote><ul><li>$\sigma$ Can Remain with Elongating RNAP<ul><li>If he doesn’t release, it goes slower.</li><li>By attach the accepter at the end of the gene, once doner from the factor attached the accepter and the light signal changed, which means $\sigma$ factor stay with the DNA.</li></ul></li></ul><table><thead><tr><th style="text-align:center"><img src="https://www.researchgate.net/profile/Eva-Stejskalova/publication/233829393/figure/fig1/AS:214231276154880@1428088124427/Foerster-resonance-energy-transfer-FRET-fundamentals-a-Schematic-representation-of.png" alt="Förster Resonance Energy Transfer"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.researchgate.net/publication/233829393_Probing_Nucleic_Acid_Interactions_and_Pre-mRNA_Splicing_by_Forster_Resonance_Energy_Transfer_FRET_Microscopy?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6Il9kaXJlY3QiLCJwYWdlIjoiX2RpcmVjdCJ9fQ">© Eva Stejskalova</a></td></tr></tbody></table><h2 id="Determing-Mechanism-s-of-Action-aka-Biochemistry">Determing Mechanism(s) of Action aka, Biochemistry</h2><h3 id="Run-Off-Transcription-Assay">Run-Off Transcription Assay</h3><blockquote><p>This assay is designed to assess how quickly RNA polymerase can transcribe a given DNA template. By analyzing the rate and extent of transcription, insights into the efficiency of the transcription process under various conditions can be obtained.</p></blockquote><table><thead><tr><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/05/pPrsYFI.png" alt="Run-Off Transcription Assay"></th><th style="text-align:left">Objective: <p>To mutate a gene’s promoter and observe the effects of mutations on the accuracy and efficiency of transcription.</p>Requirements:  <li>To check whether transcription is accurate, i.e., starts at the right place.</li> <li>To quantify how much of this accurate transcription has occurred.</li></th></tr></thead><tbody><tr><td style="text-align:center">P103; Figure 5.31</td><td style="text-align:left"></td></tr></tbody></table><h4 id="Methodology">Methodology:</h4><ol><li><p><strong>Preparation of DNA Fragment</strong>:</p><ul><li>Start with a DNA fragment containing the gene you want to transcribe.</li></ul></li><li><p><strong>Restriction Enzyme Cutting</strong>:</p><ul><li>Cut the fragment with a restriction enzyme in the middle of the transcribed region.</li></ul></li><li><p><strong>In Vitro Transcription</strong>:</p><ul><li>Transcribe the truncated gene fragment in vitro using labeled nucleotides, so the resulting transcript is labeled.</li></ul></li><li><p><strong>Run-Off Mechanism</strong>:</p><ul><li>Since the gene has been cut in the middle, the RNA polymerase will reach the end and “run off”, giving the method its name.</li></ul></li><li><p><strong>Measure Transcript Length</strong>:</p><ul><li>The length of the run-off transcript confirms the starting point of transcription based on the known location of the restriction site.</li></ul></li></ol><h4 id="Advantages">Advantages:</h4><ul><li><strong>Simplicity</strong>: Compared to S1 mapping or primer extension, run-off transcription is simpler.</li><li><strong>Quantitative</strong>: It can serve as a quantitative method to measure the rate of in vitro transcription.</li></ul><h4 id="Limitations">Limitations:</h4><ul><li><strong>In Vitro Only</strong>: The method relies on in vitro transcription and cannot provide information about cellular transcript concentrations.</li><li><strong>Accuracy</strong>: It is effective only for genes that are accurately transcribed in vitro.</li></ul><h4 id="Applications">Applications:</h4><ul><li>After identifying the physiological transcription start site through other methods like S1 mapping or primer extension, run-off transcription can be used to quantify transcription rates in vitro.</li></ul><h4 id="Summary">Summary:</h4><p>Run-off transcription is a simple, yet effective method for studying the efficiency and accuracy of transcription for a gene, especially in in vitro settings. It is particularly useful for quantitative analysis of transcription rates.</p><ul><li>Test the speed of the transcription</li></ul><h3 id="Bound-sigma-Factor-Promotes-RNAP-Pausing">Bound $\sigma$ Factor Promotes RNAP Pausing</h3><ul><li>Abortive Initiation Predominates</li></ul><h4 id="Background">Background:</h4><p>Until 1980, it was widely believed that transcription initiation was completed upon the formation of the first phosphodiester bond, connecting the first two nucleotides in the RNA chain.</p><h4 id="Breakthrough-Study-by-Carpousis-and-Gralla">Breakthrough Study by Carpousis and Gralla:</h4><ul><li><strong>Experimental Setup</strong>:<ul><li>E. coli RNA polymerase</li><li>DNA with a mutant E. coli lac promoter (lac UV5 promoter)</li><li>Heparin (prevents reassociation between DNA and RNA polymerase)</li><li>Labeled ATP (to label RNA products)</li></ul></li><li><strong>Methodology</strong>:<ul><li>Incubated the polymerase, DNA, heparin, and labeled ATP.</li><li>Ran gel electrophoresis on the products to measure their sizes.</li></ul></li></ul><table><thead><tr><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/05/pPryuAs.png" alt=""></th><th style="text-align:left"><p>Key Findings:</p><li><strong>Presence of Small Oligonucleotides</strong>: They found small RNA fragments ranging from 2-6 nucleotides (nt) in length.</li><li><strong>Sequence Matching</strong>: The sequences of these small oligonucleotides matched the beginning of the expected transcript from the lac promoter.</li><li><strong>Many Oligonucleotides per Polymerase</strong>: When the amount of these oligonucleotides was compared to the number of RNA polymerases, there were many oligonucleotides per polymerase.</li></th></tr></thead><tbody><tr><td style="text-align:center">P127; Figure 6.7</td><td style="text-align:left"></td></tr></tbody></table><h4 id="Implications">Implications:</h4><ul><li><strong>Abortive Transcripts</strong>: The polymerase was producing many small, abortive transcripts without leaving the promoter region.</li><li><strong>Complex Initiation Process</strong>: Transcription initiation is more complex than previously thought, involving a stage where multiple abortive transcripts are produced.</li><li><strong>Role of Heparin</strong>: Heparin in the assay prevented free RNA polymerase from reassociating with the DNA, confirming that the abortive transcripts were made by the same polymerase without it detaching from the DNA.</li></ul><h4 id="Follow-up-Research">Follow-up Research:</h4><p>Other researchers have corroborated these findings, even discovering abortive transcripts up to 9 or 10 nt in size.</p><h4 id="Summary-v2">Summary:</h4><p>The study by Carpousis and Gralla showed that transcription initiation is a complex process involving the generation of multiple abortive transcripts. This groundbreaking work has significantly deepened our understanding of the transcription initiation process in E. coli.</p><hr><h3 id="Electro-Mobility-Shift-Assay-EMSA">Electro Mobility Shift Assay (EMSA)</h3><table><thead><tr><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/05/pPryl90.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center">P109; Figure 5.36</td></tr></tbody></table><h4 id="Background-v2">Background:</h4><p>Understanding DNA–protein interactions is crucial for various aspects of molecular biology, including gene regulation. Gel mobility shift assay, also known as electrophoretic mobility shift assay (EMSA), is a technique that allows for the visualization of these interactions.</p><h4 id="Principle">Principle:</h4><p>The basic idea is that a small, labeled DNA fragment will move through an electrophoretic gel much more slowly when it is bound to a protein compared to when it is unbound.</p><h4 id="Methodology-v2">Methodology:</h4><ol><li><strong>Preparation</strong>: A short, double-stranded DNA fragment is labeled.</li><li><strong>Binding</strong>: This labeled DNA is then mixed with the protein of interest.</li><li><strong>Electrophoresis</strong>: The DNA-protein complex is subjected to gel electrophoresis.</li><li><strong>Detection</strong>: The gel is exposed to autoradiography to visualize the labeled species.</li></ol><h4 id="Key-Findings">Key Findings:</h4><ol><li><strong>Naked DNA</strong>: Without any bound protein, the labeled DNA shows high mobility in the gel (Lane 1).</li><li><strong>DNA-Protein Complex</strong>: When the DNA is bound to a protein, its mobility through the gel decreases significantly (Lane 2). This is the basic “shift” that gives the assay its name.</li><li><strong>Supershift</strong>: When the DNA is bound to two proteins, its mobility decreases even further (Lane 3). This is termed a “supershift” and can involve either another DNA-binding protein, a protein that binds to the first protein, or an antibody specific to the first protein.</li></ol><h4 id="Applications-v2">Applications:</h4><ul><li><strong>Study of Protein-DNA Interactions</strong>: Allows researchers to understand which proteins can bind to a specific DNA sequence.</li><li><strong>Supershift Analysis</strong>: Useful in identifying secondary proteins or antibodies that can further bind to the DNA-protein complex.</li><li><strong>Quantitative Analysis</strong>: The degree of shift can also provide quantitative insights into the binding affinities.</li></ul><h4 id="Summary-v3">Summary:</h4><p>EMSA is a powerful and versatile technique for studying DNA–protein interactions. It allows not only the qualitative identification of interacting proteins but also offers clues about the binding dynamics through supershifts.</p><ul><li>Radioisotopically Labeled ATP<br>T4 poly… to tag the DNA end and so, it could create radio-labeled</li><li>Only $\beta$’ Subunit of Core RNAP Binds All Promoters</li></ul><p><strong>rifampicin</strong> actually blocks early elongation<br>b-subunit from a rifampicin-resistant bacterium, the resulting polymerase was antibiotic-resistant.<br>b-subunit came from an antibiotic-sensitive bacterium, the reconstituted enzyme was antibiotic-sensitive,</p><hr><h3 id="beta-and-sigma-Bind-to-‘Open’-DNA-Strands">$\beta$ and $\sigma$ Bind to ‘Open’ DNA Strands</h3><ul><li>Detecting Protein:DNA Complexes by Crosslinking (Chromatin Immunoprecipitation (ChIP), Figure 5.39)</li></ul><table><thead><tr><th style="text-align:center"></th><th style="text-align:left"></th></tr></thead><tbody><tr><td style="text-align:center"><img src="https://s1.ax1x.com/2023/09/05/pPry09x.png" alt="Induction of s binding to the 210 region of a promoter"></td><td style="text-align:left">The small 262-309 fragment of b9 is critical for stimulating s binding to the non-template DNA strand, and mutations within this fragment significantly interfere with the binding.</td></tr><tr><td style="text-align:center">P142; Figure 6.24</td><td style="text-align:left"></td></tr></tbody></table><ol><li><strong>Fragment 1-550</strong>: This fragment of b9 induced binding between s and the non-template strand DNA.</li><li><strong>Smaller Fragments</strong>: All fragments could induce binding; fragment 260-550 worked only at low temperature.</li><li><strong>Critical Fragment 262-309</strong>: A small fragment with 48 amino acids significantly stimulated binding at room temperature.</li><li><strong>Mutations (R275, E295, A302)</strong>: Known to interfere with s binding to promoters and caused significant interference in binding to the non-template strand in the -10 region.</li></ol><h3 id="Strong-Promoters-Have-Another-Conserved-DNA-Element-UP-element">Strong Promoters Have Another Conserved DNA Element (UP element)</h3><table><thead><tr><th style="text-align:center"><img src="http://www.bx.psu.edu/~ross/workmg/TxnlRegPolCh16_files/image083.png" alt="UP element"></th><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/05/pPrgS74.png" alt="DNA Footprinting"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="http://www.bx.psu.edu/~ross/workmg/TxnlRegPolCh16.htm">© Dr. Tracy Nixon</a></td><td style="text-align:center">P143; Figure 6.26</td></tr></tbody></table><h4 id="DNase-Footprinting">DNase Footprinting</h4><ol><li><strong>DNase Footprinting</strong>: Uses DNase I to cut unprotected DNA regions.</li><li><strong>Dimethylsulfate (DMS) Footprinting</strong>: Uses DMS to methylate adenine bases in DNA.</li><li><strong>Hydroxyl Radical Footprinting</strong>: Uses hydroxyl radicals to cleave DNA.</li></ol><ul><li>DNase Footprinting Steps:<ol><li><strong>End-Label DNA</strong>: Only one strand is labeled per experiment.</li><li><strong>Protein Binding</strong>: The target protein is allowed to bind to the DNA.</li><li><strong>DNase I Treatment</strong>: Mild conditions used to ensure only one cut per DNA molecule on average.</li><li><strong>Protein Removal</strong>: The protein is removed to leave only the DNA.</li><li><strong>Gel Electrophoresis</strong>: DNA fragments are separated on a high-resolution gel.</li><li><strong>Control &amp; Multiple Concentrations</strong>: A control with DNA alone is included. Different protein concentrations are tested to observe gradual disappearance of bands.</li></ol></li><li>Outcome:<ul><li>The “footprint” region on the gel corresponds to the DNA region protected by the protein, revealing the protein’s binding site on the DNA.</li></ul></li><li>Significance:<ul><li>Helps in identifying the exact DNA regions or bases involved in binding with a specific protein.</li></ul></li></ul><hr><ul><li><p>Strong Promoters Have Another Conserved DNA Element</p><ul><li>-35 box and -10 box. As long as the promoter binding site close to the gene.</li></ul></li><li><p>Higher Activity Requires ‘Up’stream Sequence and Carboxyl-terminus of $\alpha$-subunit</p><ul><li>example:<ul><li>wilde-type-88 → create lots of DNA; -44: almost makes no DNA</li><li>$\alpha$-235 → never makes lot amount of DNA<br>Result: $\alpha$ initiation the recognition.</li></ul></li></ul></li><li><p>DNA Footprinting</p><ul><li>the position which protein binds the DNA where never be replicated/transcript. As a result, there is a area of the gel lost and know ans the footprint.</li></ul></li><li><p>$\alpha$ Subunit Binds Up Element Independently</p></li><li><p>C-Terminal Domain of $\alpha$ Subunit Can Bind the “Up” Element When Present</p></li></ul><h2 id="Transcription-Termination">Transcription Termination</h2><blockquote><p>Termination is an essential step to ensure only the required genes are transcribed and to prepare RNA polymerase for another round of transcription. Both Rho-independent and Rho-dependent mechanisms have unique triggers and processes to ensure efficient termination.</p></blockquote><p><img src="http://aris.gusc.lv/ChemFiles/MedBiochem2edBaynes07/HTML/common/showimage.cfm@mediaisbn=0723433410&amp;size=thumbnails&amp;figfile=m33410-031-f006.jpg" alt="Transcription Termination"></p><ul><li>Only certain regions of a genome are transcribed</li><li>Transcription complexes assemble at promoters and disassemble at the 3’ end of genes at specific termination sequences</li><li>Two types of termination sequences:<ul><li>Rho-independent termination (Central dogma forward)<ul><li>Formation of an RNA Hairpin: thermodynamic favorite</li><li>Intrinsic Termination Depends on Adenine Run</li></ul></li><li>Rho-dependent termination (got in the control)<ul><li>Rho binds to transcript at rho loading site and pause polymerase</li><li>Hairpin forms; polymerase pauses; roh catches up.</li><li>Rho helices releases transcript and causes termination</li></ul></li></ul></li><li>Initiation or Termination can be Used for Regulation</li></ul><p>Significant: In the microbes, a single operon usually activate a serious of protein for a pathway. But we usually only need apart of the genes as a result, the termination study is very important in microbe engineering</p><h2 id="Housekeeping-vs-Regulated">Housekeeping vs. Regulated</h2><blockquote><p>“Housekeeping genes are essential for the day-to-day functions of the cell and are continuously transcribed. On the other hand, regulated genes are transcribed only under specific conditions. The cell uses various transcription factors and sigma factors to control the expression of these genes.”</p></blockquote><ul><li>Expression of housekeeping genes is constitutive (essentially)</li><li>Housekeeping genes have strong promoters and are efficiently and nearly continuously transcribed *housekeeping genes whose products are required at low levels have weaker promoters</li><li><mark>Regulated genes</mark> are expressed at different levels under different conditions using specific <mark>operators/response</mark> elements within each promoter</li></ul><h2 id="Sigma-Factor-Directed-Transcription-Programs">Sigma Factor Directed Transcription Programs</h2><blockquote><p>“E. coli, a model bacterium, utilizes different sigma factors to control the transcription of various sets of genes. Depending on the environmental conditions, E. coli can switch between these sigma factors to ensure the appropriate genes are being expressed.”</p></blockquote><ul><li>Bacterial Gene Regulators</li></ul><blockquote><p>E. coli can choose between 7 sigma factors and about 350 transcription factors to fine tune its transcriptional output<br>An Rev Micro Vol. 57: 441-466 T. M. Gruber</p></blockquote><table><thead><tr><th style="text-align:left">Sigma subunit</th><th style="text-align:left">Type of gene controlled</th><th style="text-align:left"># of genes controlled</th></tr></thead><tbody><tr><td style="text-align:left">RpoD</td><td style="text-align:left">$\sigma^{70}$ Growth/housekeeping</td><td style="text-align:left">~1000</td></tr><tr><td style="text-align:left">RpoN</td><td style="text-align:left">$\sigma^{54}$ N2; stress response</td><td style="text-align:left">~15</td></tr><tr><td style="text-align:left">RpoS</td><td style="text-align:left">Stationary phase, virulence</td><td style="text-align:left">~100</td></tr><tr><td style="text-align:left">RpoH</td><td style="text-align:left">$\sigma^{32}$ Heat shock</td><td style="text-align:left">~40</td></tr><tr><td style="text-align:left">RpoF</td><td style="text-align:left">Flagella-chemotaxis</td><td style="text-align:left">~40</td></tr><tr><td style="text-align:left">RpoE</td><td style="text-align:left">?</td><td style="text-align:left">~5</td></tr><tr><td style="text-align:left">FecI</td><td style="text-align:left">Ferric citrate transport</td><td style="text-align:left">~5</td></tr></tbody></table><p>[R]poD: means find by gene screening<br>[P]…: Discovered by Chemical way<br>Stress: make very unique proteins for survival</p><p>Different sigma, different RNA (may other sigmas), Different way (final products)</p><ul><li>Sigma Factors Enable Large Changes in Gene Programs</li><li>Directing Simple and Cascade Responses</li></ul><h2 id="Sigma-Factor-Regulation">Sigma Factor Regulation</h2><blockquote><p>“Sigma factors are regulated at multiple levels to ensure appropriate cellular responses. For instance, the sigma factor σ<sup>32</sup> is a heat-shock protein. Under normal conditions, it’s unstable and degraded quickly. However, under heat-shock conditions, it’s stabilized, allowing the cell to respond to the stress.”</p></blockquote><ul><li>$\sigma ^{32}$ is the first $\sigma$ factor bing studied.</li><li>$\sigma ^{32}$ Controls Expression of the Proteins that Control It (a.k.a. Feedback loop)</li><li>$\sigma ^{32}$ Is Continuously Produced but Rapidly Degraded</li><li>$\sigma ^{32}$ Regulation is a Balanced Sensor</li><li>HSPs Reactivate $\sigma ^{70}$ During Recovery</li></ul><p>!!! ? what happened between $\sigma ^{32}$ and $\sigma ^{70}$? How cell make the choice?<br>- $\sigma ^{32}$ is a heat-shock protein. It would degreedated without heat-shock. Heat-shock genes stabilized the $\sigma ^{32}$. In this case, the $\sigma ^{32}$ could win the competition which $\sigma ^{70}$ DnaK, DnaJ, and GrpE are heat-shock proteins work to protect the $\sigma ^{32}$.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Advanced Molecular &amp; Cell Biology 2</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Class" scheme="https://karobben.github.io/categories/Notes/Class/"/>
    
    <category term="UIUC" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/"/>
    
    <category term="Cell Biology" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/Cell-Biology/"/>
    
    
    <category term="Classes" scheme="https://karobben.github.io/tags/Classes/"/>
    
    <category term="UIUC Classes" scheme="https://karobben.github.io/tags/UIUC-Classes/"/>
    
    <category term="Cell Biology" scheme="https://karobben.github.io/tags/Cell-Biology/"/>
    
  </entry>
  
  <entry>
    <title>Acoustics</title>
    <link href="https://karobben.github.io/2023/08/23/LearnNotes/acoustics/"/>
    <id>https://karobben.github.io/2023/08/23/LearnNotes/acoustics/</id>
    <published>2023-08-23T16:27:03.000Z</published>
    <updated>2023-08-29T04:09:07.968Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Acoustics">Acoustics</h2><p><strong>waveform</strong>, <strong>phase</strong>, <strong>amplitude</strong> (usually expressed in log units known as decibels, abbreviated dB), and <strong>frequency</strong>.</p><p>For human listeners, the <strong>amplitude</strong> and <strong>frequency</strong> of a sound pressure change at the ear roughly correspond to <strong>loudness</strong> and <strong>pitch</strong>, respectively.</p><p>Humans can detect sounds in a frequency range from about 20 Hz to 20<br>kHz. Most small mammals are sensitive to very high frequencies, but not to low frequencies.</p><table><thead><tr><th style="text-align:center"><img src="https://cmtext.indiana.edu/acoustics/img/ear_anatomy2.png" alt="ANATOMY OF THE HUMAN EAR"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://commons.wikimedia.org/wiki/File:Anatomy_of_the_Human_Ear.svg">© Lars Chittka; Axel Brockmann</a></td></tr></tbody></table><h2 id="Fragile-X-Syndrome-FXS-Sensory-Processing-Deficits">Fragile X Syndrome (<abbr title="Fragile X Syndrome">FXS</abbr>) - Sensory Processing Deficits</h2><ol><li><p><strong>Introduction</strong></p><ul><li><strong>Definition</strong>: <abbr title="Fragile X Syndrome">FXS</abbr> is a neurodevelopmental disorder leading to intellectual disability.</li><li><strong>Link to Autism</strong>: Leading known genetic cause of autism.</li></ul></li><li><p><strong>Sensory Processing in <abbr title="Fragile X Syndrome">FXS</abbr></strong></p><ul><li><strong>General Characteristics</strong>: Abnormal sensory processing, particularly <mark>sensory hypersensitivity</mark>.</li><li><strong>Manifestations</strong>:<ul><li>Auditory, tactile, or visual defensiveness or avoidance.</li><li>Clinical and behavioral studies show auditory hypersensitivity, <strong>impaired habituation</strong> to repeated sounds, and <strong>reduced auditory attention</strong>.</li></ul></li><li><strong>Visuospatial Impairments</strong>: Significant deficits observed.<ul><li>Noted problems in processing texture-defined motion stimuli, temporal flicker, perceiving ordinal numerical sequences, and maintaining dynamic object identity during occlusion.</li></ul></li></ul></li><li><p><strong>Animal Models: Fmr1 KO Rodents</strong></p><ul><li><strong>General</strong>: Fragile X mental retardation 1 (Fmr1) gene knockout (KO) rodents used as <abbr title="Fragile X Syndrome">FXS</abbr> models.</li><li><strong>Findings</strong>:<ul><li>Seizures.</li><li>Abnormal visual-evoked responses.</li><li>Auditory hypersensitivity.</li><li>Altered acoustic startle responses.</li><li>Abnormal processing in the auditory system.</li></ul></li><li><strong>Tactile Symptoms</strong>:<ul><li>Individuals with <abbr title="Fragile X Syndrome">FXS</abbr> show tactile defensiveness.</li><li>Fmr1 KO mice have impaired tactile stimulation frequency encoding and larger receptive fields in the somatosensory cortex.</li></ul></li></ul></li><li><p><strong>Review Focus</strong>:</p><ul><li>Discusses clinical, functional, and structural studies on sensory processing deficits in <abbr title="Fragile X Syndrome">FXS</abbr> across:<ul><li>Auditory. (We only focus on Auditory in this note)</li><li>Visual.</li><li>Somatosensory domains.</li></ul></li></ul></li><li><p><strong>Significance of Animal Models</strong>:</p><ul><li>Observations in <abbr title="Fragile X Syndrome">FXS</abbr> humans and Fmr1 KO rodents are similar, suggesting conservation of basic sensory processing circuits across species.</li><li>Offers a translational platform to develop biomarkers and understand underlying mechanisms.</li></ul></li><li><p><strong>Conclusion</strong>:</p><ul><li>Emphasizes the value of pre-clinical studies in animal models of <abbr title="Fragile X Syndrome">FXS</abbr>.</li><li>Belief: Understanding mechanisms in basic sensory processing circuits/behaviors can boost the search for new therapeutic approaches in <abbr title="Fragile X Syndrome">FXS</abbr>.</li></ul></li></ol><h3 id="Introduction">Introduction</h3><ol><li><p><strong>Prevalence and Impact</strong>: <strong>intellectual disability</strong>, <strong>Link to Autism</strong>: One of the leading genetic causes.</p><ul><li><strong>Statistics</strong>: Affects 1 in 4,000 boys and 1 in 8,000 girls.</li></ul></li><li><p><strong>Genetic Origin</strong>:</p><ul><li><strong>Gene Impacted</strong>: Fragile X mental retardation 1 (<abbr title="Fragile X mental retardation 1">FMR1</abbr>) gene.</li><li><strong>Causes</strong>:<ul><li>Silencing, Deletion, Loss-of-function mutation.</li></ul></li><li><strong>Consequences</strong>: Results in the non-expression or nonfunctionality of the fragile X mental retardation protein (FMRP).</li></ul></li></ol><ol start="3"><li><strong>About FMRP</strong>:<ul><li><strong>Type</strong>: A messenger RNA (mRNA)-binding protein.</li><li><strong>Functions</strong>:<ul><li>Regulates several aspects of mRNA metabolism, including:<ul><li>Nuclear export.</li><li>Transport to synaptic terminals.</li><li>Activity-dependent ribosome stalling.</li><li>Protein translation.</li></ul></li></ul></li></ul></li></ol><p><strong>FMRP’s Role in Synaptic Function and Translation Regulation</strong></p><ol><li><p><strong>Translation Regulation</strong>:</p><ul><li>FMRP regulates the translation of mRNAs at synapses.</li><li>Some of these mRNAs encode proteins linked to synaptic plasticity.</li></ul></li><li><p><strong>Impact of Absence of FMRP</strong>:</p><ul><li>Results in dysregulation of protein translation and increased protein synthesis.</li><li>This may contribute to altered signaling of metabotropic glutamate receptor 5 (mGluR5).</li><li>This altered signaling may lead to exaggerated long-term depression (LTD) in the hippocampus.</li></ul></li><li><p><strong>Matrix Metalloproteinase-9 (MMP-9)</strong>:</p><ul><li>FMRP negatively regulates MMP-9 translation in neurons because MMP-9 levels are elevated in <abbr title="Fragile X Syndrome">FXS</abbr>.</li><li>mGluR5 and MMP-9 potentially mediate changes in synaptic functions.<ul><li>They might signal through the phosphatidylinositol-3-kinase (PI3K)/mammalian target of rapamycin complex 1 (mTORC1) and extracellular signal-regulated kinase pathways to amplify cap-dependent translation.</li></ul></li></ul></li><li><p><strong>Recent Data on FMRP</strong>:</p><ul><li>Suggests that FMRP might directly regulate PI3K and mTORC1 signaling.<ul><li>This regulation could occur through other signaling proteins like phosphatidylinositol-3-kinase enhancer, phosphatase and tensin homolog, neurofibromin 1, and tuberous sclerosis 2.</li></ul></li></ul></li><li><p><strong>FMRP Targets</strong>:</p><ul><li>All three isoforms of eukaryotic translation initiation factor 4 G.</li><li>Eukaryotic translation elongation factor 1 and 2.</li><li>Argonaute proteins.</li><li>Dicer.</li><li>Dysregulation of these targets might contribute to enhanced neuronal translation in <abbr title="Fragile X Syndrome">FXS</abbr>.</li></ul></li></ol><p><strong>Role of Dysregulated Pathways and FMRP in Dendritic Spine Morphology and Neurophysiology</strong></p><ol><li><p><strong>Dysregulated Pathways in <abbr title="Fragile X Syndrome">FXS</abbr></strong>:</p><ul><li>Dysregulated PI3K/mTOR signaling.</li><li>Enhanced mGluR5-dependent LTD.</li><li>Increased MMP-9 activity.</li><li>Reduced activity of the voltage and $Ca^{2+}$ activated ( K^+ ) (BKCa or BK) channel.</li><li>These might contribute to the immature dendritic spine morphology in rodent models of <abbr title="Fragile X Syndrome">FXS</abbr>.</li></ul></li><li><p><strong>FMRP’s Role in Mice</strong>:</p><ul><li>Might regulate neuronal branching.</li><li>Regulates dendritic spine development.</li></ul></li><li><p><strong>Clinical Studies in Humans</strong>:</p><ul><li>Alterations observed in dendritic spine number and morphology in the cortex of <abbr title="Fragile X Syndrome">FXS</abbr> humans.<ul><li>A notable prevalence of immature dendritic spines.</li></ul></li><li>Dendritic abnormalities are consistent anatomical features linked with intellectual disability.</li></ul></li><li><p><strong>FMRP’s Predominant Activity</strong>:</p><ul><li>Mainly related to the regulation of synaptic functions.</li><li>Yet, there’s limited knowledge about:<ul><li>How synaptic alterations due to the absence of FMRP lead to neurophysiological and behavioral deficits in humans with <abbr title="Fragile X Syndrome">FXS</abbr>.</li><li>The reason why abnormal dendritic spine development alone doesn’t explain the increased cortical excitability seen in <abbr title="Fragile X Syndrome">FXS</abbr>.</li></ul></li></ul></li></ol><h2 id="Using-auditory-reaction-time-to-measure-loudness-growth-in-rats">Using auditory reaction time to measure loudness growth in rats</h2><h3 id="Abstract">Abstract</h3><ol><li><p><strong>Introduction</strong>:</p><ul><li><strong>Auditory Reaction Time (RT)</strong>: Established as a reliable proxy for loudness perception in humans.</li><li><strong>Reaction Time-Intensity (RT-I) Functions</strong>:<ul><li>Effectively mirror equal loudness contours in humans.</li><li>Easier to obtain than equal loudness judgments, particularly in animal subjects.</li></ul></li></ul></li><li><p><strong>Factors Affecting Loudness Estimation</strong>:</p><ul><li><strong>Sound Intensity</strong>: Primary factor.</li><li><strong>Other Acoustic Factors</strong>:<ul><li>Stimulus duration.</li><li>Bandwidth.</li></ul></li><li><strong>Background Noise Effect</strong>:<ul><li>Simulates loudness recruitment.</li><li>Rapid loudness growth near threshold, but stabilizes at suprathreshold levels.</li></ul></li></ul></li><li><p><strong>Study Objectives</strong>:</p><ul><li>Examine if RT-I functions can reliably measure loudness growth in rats.</li><li>Obtain auditory RTs across varying:<ul><li>Stimulus intensities.</li><li>Durations.</li><li>Bandwidths.</li></ul></li><li>Experiments conducted in both quiet conditions and amidst background/masking noise.</li></ul></li><li><p><strong>Findings</strong>:</p><ul><li>Reaction time patterns across different stimulus parameters:<ul><li>Repeated consistently over several months in rats.</li><li>Generally align with human loudness perceptual data.</li></ul></li></ul></li><li><p><strong>Significance</strong>:</p><ul><li>Results lay foundational understanding for upcoming studies on loudness perception in animal models.</li><li>Potential to explore loudness perceptual disorders in animals.</li></ul></li></ol><h3 id="Introduction-v2">Introduction</h3><p><strong>Exploring Loudness Perception Beyond Traditional Methods</strong></p><ol><li><p><strong>Standard Tool</strong>:</p><ul><li>Pure Tone Audiogram: Essential for hearing research but limited in scope.</li></ul></li><li><p><strong>Loudness Perception</strong>:</p><ul><li>Beyond hearing threshold, loudness perception for louder sounds is crucial.</li></ul></li><li><p><strong>Clinical Metrics</strong>:</p><ul><li>Uses scales like ULL and LDL where listeners rate discomfort from various sound intensities.</li></ul></li><li><p><strong>Human Psychophysical Studies</strong>:</p><ul><li>Equal loudness contours: Listeners compare sound loudness to a standard tone, a labor-intensive method.</li></ul></li></ol><p><strong>Measuring Loudness Perception in Animals</strong></p><ol><li><p><strong>Traditional Measures</strong>:</p><ul><li>LDLs and equal loudness contours: Useful for humans but impractical for animals.</li></ul></li><li><p><strong>Auditory Reaction Time (RT)</strong>:</p><ul><li>Used as an indirect metric of loudness in animals.</li><li>In humans, a faster RT correlates with perceived loudness.</li></ul></li><li><p><strong>Advantages of RT</strong>:</p><ul><li>Reliable for both normal-hearing and hearing-impaired listeners.</li><li>Easier to obtain than traditional measures, making it useful for various species.</li></ul></li></ol><p>Certainly! I’ll further condense and clarify the content:</p><p><strong>Loudness Perception Factors in Humans</strong></p><ol><li><p><strong>Intensity</strong>:</p><ul><li>Main determinant, but not the sole factor.</li></ul></li><li><p><strong>Duration</strong>:</p><ul><li>Longer sounds (up to 300 ms) seem louder.</li></ul></li><li><p><strong>Bandwidth</strong>:</p><ul><li>Wider bandwidths make sounds feel louder.</li></ul></li><li><p><strong>Background Noise</strong>:</p><ul><li>Can mimic “loudness recruitment”, where sounds just above threshold feel quiet but get rapidly louder.</li></ul></li></ol><p><strong>Evaluating Reaction Time-Intensity (RT-I) Functions in Rats</strong></p><ol><li><p><strong>Objective</strong>:</p><ul><li>Check if RT-I in rats matches human patterns of perceived loudness.</li></ul></li><li><p><strong>Method</strong>:</p><ul><li>Measured auditory RTs in rats for various:<ul><li>Intensities</li><li>Durations</li><li>Bandwidths</li></ul></li><li>Conducted in quiet and with background noise.</li></ul></li><li><p><strong>Expectations</strong>:</p><ul><li>If rats and humans perceive loudness similarly:<ul><li>RTs should decrease as intensity, duration, and bandwidth increase.</li><li>RTs should rise near the hearing threshold when background noise is present.</li></ul></li></ul></li></ol><p><strong>Aims and Challenges in Developing an Animal Behavioral Model for Loudness Perceptual Disorders</strong></p><ol><li><p><strong>Primary Goal</strong>:</p><ul><li>Develop a behavioral model in animals to study loudness perceptual disorders, specifically loudness recruitment and hyperacusis.</li></ul></li><li><p><strong>Challenges</strong>:</p><ul><li>Accounting for effects of drug or noise on hearing.<ul><li>E.g., High-dose salicylate can cause hearing loss, tinnitus, and possibly hyperacusis.</li><li>Noise often leads to hearing loss, loudness recruitment, and potentially tinnitus and hyperacusis in some listeners.</li></ul></li><li>A successful model should distinguish:<ul><li>Loudness recruitment from hyperacusis.</li><li>Hyperacusis from tinnitus.</li></ul></li></ul></li><li><p><strong>Tinnitus-like Percept Study</strong>:</p><ul><li>Effect of broadband noise vs. tonal masker on RTs was studied.</li><li>Goal: Understand the influence of a “tinnitus-like” percept on loudness growth.</li><li>Hypothesis:<ul><li>Tinnitus-like 16 kHz masker won’t affect RT-I functions for 4 kHz tones but might impact the loudness growth of 16 kHz tones.</li></ul></li></ul></li><li><p><strong>Stability of RTs in Rats</strong>:</p><ul><li>Beyond comparing rat RT-I functions to humans, the study aimed to test RT stability over time.</li><li>This is crucial as animal psychoacoustic studies span weeks or months.</li><li>A consistent loudness perception metric is needed, especially when no experimental manipulations are applied.</li></ul></li></ol><h3 id="Result">Result</h3><p><strong>Impact of Stimulus Duration on Auditory Reaction Time (RT)</strong></p><ol><li><p><strong>Experiment Setup</strong>:</p><ul><li>Reaction time-intensity (RT-I) functions were measured for broadband noise bursts (BBN) across three durations: 20 ms, 100 ms, and 300 ms.</li></ul></li><li><p><strong>Main Findings</strong>:</p><ul><li>RTs for BBN decreased with rising stimulus intensity for all tested durations.</li><li>Rats had quicker RTs (i.e., reacted faster) with longer stimulus durations.</li><li>No significant interaction found between sound level and stimulus duration.</li><li>Results imply rats perceived longer sounds as louder, similar to human perception.</li></ul></li><li><p><strong>Detailed Results</strong>:</p><ul><li>RTs for 300 ms BBN were significantly faster than for 100 ms and 20 ms BBN.</li><li>Significant differences were observed:<ul><li>Between 20 ms and 300 ms BBN across all sound levels.</li><li>Between 100 ms and 300 ms BBN at specific dB levels: 40, 50, 60, and 80 dB SPL.</li></ul></li></ul></li></ol><table><thead><tr><th style="text-align:center"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0378595520302975-gr1.jpg" alt=""></th></tr></thead><tbody></tbody></table><p><strong>Impact of Stimulus Bandwidth on Auditory Reaction Time (RT) in Rats</strong></p><ol><li><p><strong>Hypothesis</strong>:</p><ul><li>Wider band stimuli would sound louder (and thus induce faster RTs in rats) compared to narrower band or pure tone stimuli, based on human data.</li></ul></li><li><p><strong>Key Findings</strong>:</p><ul><li>Rats reacted faster to stimuli with increased bandwidth, aligning with the hypothesis that wideband stimuli sound louder.</li></ul></li><li><p><strong>Detailed Observations</strong>:</p><ul><li>RTs for Broadband Noise Bursts (BBN) were faster than for 16 kHz pure tones at most sound levels, excluding 30 dB SPL.</li><li>RTs for BBN were also faster compared to 16–20 kHz Narrow Band Noise (NBN) for specific dB levels: 30, 40, 50, and 60 dB SPL.</li></ul></li><li><p><strong>Conclusion</strong>:</p><ul><li>Just as with duration, these results indicate that RT is a reliable metric for loudness perception in rats, mirroring known human data on loudness perceptions of different bandwidth sounds.</li></ul></li></ol><table><thead><tr><th style="text-align:center"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0378595520302975-gr2.jpg" alt=""></th></tr></thead><tbody></tbody></table><p><strong>Effects of Background Noise on Loudness Perception in Rats</strong></p><ol><li><p><strong>Experiment Setup</strong>:</p><ul><li>Measured RT-I functions for Broadband Noise Bursts (BBN) in quiet and with low-level background noise (2-20 kHz, 60 dB SPL).</li></ul></li><li><p><strong>Main Findings</strong>:</p><ul><li>In the presence of background noise, rats had:<ul><li>Slower RTs for lower intensity sounds.</li><li>Regular RTs for higher intensity sounds.</li></ul></li><li>These patterns suggest the rats experienced recruitment-like perceptions in noise.</li><li>As intensity increased just above threshold, RT decrease was sharper in noise than in quiet, aligning with loudness recruitment patterns.</li></ul></li><li><p><strong>Background Noise Effects</strong>:</p><ul><li>Significant effects found on RTs for lower intensity stimuli when compared to quiet conditions.</li><li>In particular, differences were noted at 30, 40, and 50 dB SPL BBN levels.</li><li>This indicates that, like humans, rats experience a recruitment-like loudness growth in the presence of background noise.</li></ul></li><li><p><strong>Effects of 16 kHz Masker</strong>:</p><ul><li>No recruitment-like effects on RTs for 4 kHz tones.</li><li>Rats reacted slightly faster at 40 and 50 dB SPL tones with the 16 kHz masker.</li><li>However, the effect might be due to task performance variability.</li><li>For 16 kHz tones, the masker had a significant effect, especially at 60 dB SPL.</li><li>This suggests that animals with tinnitus might show recruitment-like behaviors for sounds close to the tinnitus frequency.</li></ul></li></ol><h3 id="Discussion">Discussion</h3><ul><li>RT-I functions in rats align with established human loudness perception research, suggesting they’re a valid measure of rat loudness growth.</li><li>Their consistency over four months indicates the RT-I approach reliably reflects loudness perception in rats.</li></ul><p><strong>Key Findings on Noise Exposure and Hearing</strong></p><ol><li><p><strong>Loudness Recruitment</strong>:</p><ul><li>Noise and drugs can cause hearing loss.</li><li>This loss can lead to “loudness recruitment,” where soft sounds seem quickly loud, but this doesn’t affect louder sounds.</li></ul></li><li><p><strong>Using Rats to Understand Loudness</strong>:</p><ul><li>In our tests, rats exposed to background noise showed symptoms similar to loudness recruitment.</li></ul></li><li><p><strong>Hyperacusis</strong>:</p><ul><li>This is when everyday sounds seem too loud.</li><li>Certain studies, including ours, used reaction times to detect hyperacusis in animals.</li><li>Our tests found that a high aspirin dose made rats more sensitive to certain sound levels.</li></ul></li><li><p><strong>Noise Exposure’s Role</strong>:</p><ul><li>Extended noise exposure in rats caused both loudness recruitment and hyperacusis-like behaviors.</li></ul></li></ol><p><strong>Reaction Time-Intensity (RT-I) as a Model for Loudness Growth</strong>:</p><ol><li><p><strong>Loudness Growth in Animals</strong>:</p><ul><li>Our RT-I conditioning model effectively maps loudness growth in animals.</li><li>It can predict how noise or drug exposure influences loudness perception.</li></ul></li><li><p><strong>Hyperacusis vs. Loudness Recruitment</strong>:</p><ul><li>Hyperacusis: Faster reaction times at moderate-high sound intensities.</li><li>Loudness Recruitment: Regular reaction times at these intensities.</li><li>Differentiating between tinnitus and hyperacusis is crucial.</li></ul></li><li><p><strong>Studying Tinnitus</strong>:</p><ul><li>Prior studies on tinnitus using RT-I functions lacked comprehensive results.</li><li>In our experiment, using a “tinnitus-like” background showed recruitment-like loudness growth for tones at tinnitus pitch. Other tones remained unaffected.</li><li>Hyperacusis showed a different pattern than tinnitus. Thus, RT-I functions can potentially distinguish between the two.</li><li>However, the overlap of tinnitus with hearing loss complicates this distinction.</li></ul></li><li><p><strong>Conclusion and Future Directions</strong>:</p><ul><li>Auditory reaction time mirrors loudness perception both in rats and humans.</li><li>RT-I functions can screen for hearing disorders in rats post noise/drug exposure.</li><li>Our goal is to expand this model, compare it with human loudness contours, and integrate neural and biochemical measures in future studies.</li></ul></li></ol><h2 id="Testing-the-Central-Gain-Model-Loudness-Growth-Correlates-with-Central-Auditory-Gain-Enhancement-in-a-Rodent-Model-of-Hyperacusis">Testing the Central Gain Model: Loudness Growth Correlates with Central Auditory Gain Enhancement in a Rodent Model of Hyperacusis</h2><h3 id="Abstract-v2">Abstract</h3><p><strong>Central Gain Model of Hyperacusis</strong></p><ul><li><strong>Theory</strong>:<ul><li>Auditory input ↓ → Neuronal gain ↑ → Over-amplification &amp; loudness ↑.</li></ul></li></ul><p><strong>Study Objective</strong></p><ul><li>Link: Sound-evoked activity changes ↔ Loudness perceptual alterations.</li></ul><p><strong>Methodology</strong></p><ul><li><strong>Operant Conditioning Task</strong>:<ul><li>Measure: Loudness via auditory stimuli reaction time.</li></ul></li><li><strong>Chronic Electrophysiological Recordings</strong>:<ul><li>Locations: Auditory cortex &amp; inferior colliculus (awake animals).</li><li>Goal: Daily loudness perception ↔ Neurophysiological sound encoding.</li></ul></li></ul><p><strong>Salicylate-induced Model</strong></p><ul><li>Purpose: Validate the paradigm.</li><li>Effects of high sodium salicylate doses:<ul><li>Temporary hearing loss.</li><li>Neural hyperactivity.</li><li>Auditory disruptions (e.g., tinnitus, hyperacusis).</li></ul></li></ul><p><strong>Findings</strong></p><ul><li>Salicylate effects:<ul><li>Alters: Loudness growth &amp; Evoked response-intensity.</li></ul></li><li>Results:<ul><li>Consistent with: Temporary hearing loss &amp; hyperacusis.</li><li>Correlation: Loudness growth ↔ Sound-evoked activity (individual animals).</li></ul></li></ul><p><strong>Conclusion</strong></p><ul><li>Strong support: Central gain model of hyperacusis.</li><li>Value: Experimental design for within-subject comparison.</li></ul><h3 id="Introduction-v3">Introduction</h3><h4 id="part-1">part 1</h4><p><strong>Hyperacusis</strong></p><ul><li>Definition: Auditory disorder where moderate sounds → intolerably loud/painful.</li><li>Type: Common with sensorineural hearing loss.</li></ul><p><strong>Central Gain Model (CGM)</strong></p><ul><li>Concept: Maladaptive response in auditory system due to hearing loss.</li><li>Mechanism:<ul><li>Central auditory system adjusts for hearing sensitivity.</li></ul><ul><li>Dysregulation &amp; central auditory pathway over-amplification → normal sounds perceived as excessively loud.</li></ul></li><li>Support:<ul><li>Accounts for major hyperacusis features.</li><li>Strong evidence backing.</li></ul></li></ul><p><strong>Validation Need</strong>: Relate central gain changes &amp; loudness perception.</p><p><strong>Human Imaging</strong></p><ul><li>Findings: Hyperacusis patients → increased sound-evoked activity.</li><li>Limitation: Can’t link neurophysiological changes &amp; hyperacusis development.</li></ul><p><strong>Animal Models</strong></p><ul><li>Advantage: Detailed hyperacusis examination.</li><li>Findings: Hearing loss (due to noise/drugs) → central gain increase.</li><li>Limitation:<ul><li>Between-group comparisons.</li></ul><ul><li>Acute measurements from anesthetized subjects.<br>→ Focus on specific auditory areas.</li><li>Few studies link central gain &amp; loudness.</li></ul></li></ul><h4 id="part-2">part 2</h4><p><strong>Challenges in Hyperacusis Study</strong></p><ol><li><strong>Direct Relationship Needs</strong>:<ul><li>Objective loudness perception indicators.</li><li>Indicators should reflect both hearing loss &amp; hyperacusis in single animals.</li></ul></li><li><strong>Inter-subject Variability</strong>:<ul><li>Hearing loss is a hyperacusis trigger but not a guaranteed outcome.</li><li>Not all animals develop hyperacusis even under similar conditions.</li></ul></li></ol><p><strong>Loudness Perception Indicator: RT-I</strong></p><ul><li><strong>RT-I</strong>: Measures loudness growth via subject’s reaction time (RT) to varied sound intensities.<ul><li>Closely linked with human loudness growth &amp; equal loudness contours.</li></ul></li><li><strong>Usage</strong>:<ul><li>Reflects loudness recruitment in hearing impaired humans &amp; animals.</li><li>Captures hyperacusis-like changes (example: rats treated with sodium salicylate).</li></ul></li></ul><p><strong>Animal Models &amp; Hyperacusis Variability</strong></p><ol><li><strong>Need</strong>: Relate neural hyperactivity with hyperacusis-like behavior in each animal.</li><li><strong>Our Approach</strong>:<ul><li>Combine psychophysical &amp; electrophysiological methods.</li><li>Track changes in both loudness perception &amp; sound-evoked activity longitudinally.</li></ul></li></ol><p><strong>Methodology</strong></p><ol><li><strong>Chronic Implants</strong>:<ul><li>Locations: Auditory cortex (AC) &amp; inferior colliculus (IC).</li><li>Purpose: Monitor sound-evoked activity in awake animals &amp; avoid anesthesia issues.</li></ul></li><li><strong>Benefit</strong>: Directly link sound encoding with daily loudness growth assessment per animal.</li></ol><p><strong>Validation of Combined Approach</strong></p><ul><li><strong>Test</strong>: Effect of salicylate on RT-I &amp; neural activity in the same animals.</li><li><strong>Findings</strong>:<ul><li>Salicylate-induced changes in RT-I &amp; sound-evoked activity coexist in individual animals.</li></ul><ul><li>Supports the central gain model.</li><li>Validates the combined behavioral-electrophysiological paradigm.</li></ul></li></ul><h3 id="Result-v2">Result</h3><h4 id="Stable-behavioral-and-electrophysiological-measures-of-loudness-growth">Stable behavioral and electrophysiological measures of loudness growth</h4><p><strong>Experiment Overview</strong></p><ul><li><strong>Tested Animals</strong>: 8 rats.</li><li><strong>Procedure</strong>:<ul><li>Go/No-go operant conditioning paradigm.</li><li>Electrodes chronically implanted in primary AC &amp; central nucleus of the IC.</li></ul></li></ul><p><strong>Observations</strong></p><ol><li><p><strong>LFP Tuning Curves</strong>:</p><ul><li>Well-tuned for frequency.</li><li>AC &amp; IC electrodes matched for characteristic frequency in each hemisphere.</li></ul></li><li><p><strong>Baseline RT-I &amp; LFP I/O Functions</strong> (broadband noise burst 30–90 dB SPL):</p><ul><li><strong>RTs</strong>:<ul><li>Decreased from ~325 ms (30 dB SPL) to ~140 ms (90 dB SPL).</li></ul></li><li><strong>AC I/O Functions</strong>:<ul><li>Amplitude increased from ~30 mV (30 dB SPL) to ~70 mV (90 dB SPL).</li></ul></li><li><strong>IC I/O Functions</strong>:<ul><li>Amplitude grew from ~40 mV (30 dB SPL) to ~125 mV (90 dB SPL).</li></ul></li></ul></li><li><p><strong>Consistency</strong>:</p><ul><li>No significant differences observed across baseline sessions in RT-I, AC, or IC I/O functions.</li></ul></li><li><p><strong>Conclusion</strong>:</p><ul><li>Behavioral &amp; electrophysiological responses are stable without any explicit manipulation.</li></ul></li></ol><h4 id="Salicylate-induced-hyperacusis-and-hyperactivity">Salicylate-induced hyperacusis and hyperactivity</h4><p><strong>Post-Baseline Testing with Sodium Salicylate (SS) Treatment</strong></p><ol><li><p><strong>Procedure</strong>:</p><ul><li>Animals received 200 mg/kg SS injection (i.p.).</li><li>Assessments made 2 hours post-SS and again after 24 hours.</li></ul></li><li><p><strong>Data Analysis</strong>:</p><ul><li>RTs &amp; AC/IC LFP amplitudes normalized to maximum average baseline values.</li></ul></li><li><p><strong>Observations 2 Hours Post-SS</strong>:</p><ul><li><strong>Low-Intensity Noise Bursts (30 dB SPL)</strong>:<ul><li>RTs → Slower than baseline.</li><li>AC/IC Amplitudes → Smaller than baseline.</li><li><strong>Interpretation</strong>: Cochlear hearing loss likely from SS-mediated ototoxicity.</li></ul></li><li><strong>Moderate-to-High Intensities (70-90 dB SPL)</strong>:<ul><li>RTs → Faster than baseline → Suggests sounds perceived louder (possible hyperacusis).</li><li>AC/IC Amplitudes → Larger than baseline → Indicates enhanced central gain.</li></ul></li></ul></li><li><p><strong>Observations 24 Hours Post-SS</strong>:</p><ul><li>Both behavioral and electrophysiological changes observed at 2 hours post-SS were reversed.</li><li>Likely due to drug washout.</li></ul></li></ol><h4 id="Salicylate-induced-gain-modulation">Salicylate-induced gain modulation</h4><p><strong>Results Analysis Based on Fig. 2A-C</strong></p><ol><li><p><strong>Observation</strong>:</p><ul><li>SS alters loudness growth &amp; LFP responses.</li><li>At low intensities: Slower RTs &amp; decreased LFPs.</li><li>At high intensities: Faster RTs &amp; enhanced LFPs.</li><li>Result: Steeper slope of response functions → Central gain theory hallmark.</li></ul></li><li><p><strong>Response Gain Assessment - Approach 1</strong>:</p><ul><li>Fit RT-I &amp; AC/IC LFP response functions with linear regression.</li><li>Check slope changes (normalized response/dB) due to SS.</li><li><strong>2 hours post-SS</strong>:<ul><li>RT, AC, IC functions → Greater slopes than baseline.</li></ul></li><li><strong>24 hours post-SS</strong>:<ul><li>Slopes → No significant deviation from baseline.</li></ul></li></ul></li><li><p><strong>Response Gain Assessment - Approach 2</strong>:</p><ul><li>Transform baseline RT/AC/IC response function to post-SS equivalent.</li><li>Scatter plots depict change in response magnitude at each intensity post-SS.</li><li>Interpretation:<ul><li>Below 45° line → Decreased response post-SS.</li><li>Above 45° line → Increased response post-SS.</li></ul></li></ul></li><li><p><strong>Scatter Plot Analysis</strong>:</p><ul><li>Plots fitted with linear regression (2 &amp; 24 hours post-SS).</li><li>Slope (R Gain) describes magnitude of gain modulation by SS:<ul><li>( R \text{ Gain} &gt; 1 ) → Enhanced response gain.</li><li>( R \text{ Gain} &lt; 1 ) → Decreased response gain.</li><li>( R \text{ Gain} = 1 ) → No change in response gain.</li></ul></li></ul></li><li><p><strong>Key Findings</strong>:</p><ul><li>Baseline sessions: Response gain consistent across RT-I or AC/IC LFP functions.</li><li>2 hours post-SS: Slope &gt; 1 for RT, AC, IC → Increased response gain.</li><li>More robust gain increase observed in AC than IC.</li><li>24 hours post-SS: Response growth rate reverted to baseline.</li></ul></li></ol><h4 id="Within-subject-relationship-between-RT-AC-and-IC-gain-changes">Within-subject relationship between RT, AC and IC gain changes</h4><p><strong>Results Analysis Based on Fig. 2 &amp; 3</strong></p><ol><li><p><strong>Salicylate’s Effects</strong>:</p><ul><li>Alters response gain for RT and LFP I/O functions.</li><li>Central gain enhancement linked with altered loudness perception.</li></ul></li><li><p><strong>Individual Animal Analysis (Fig. 3)</strong>:</p><ul><li>Animal with substantial RT-I alteration post-SS also had pronounced changes in AC/IC I/O functions.</li><li>Animal with modest RT-I alteration post-SS exhibited minor changes in AC/IC I/O functions.</li><li>RT-I &amp; AC/IC I/O functions reverted to baseline levels 24h post-SS in both cases.</li></ul></li><li><p><strong>Subject-by-Subject Analysis</strong>:</p><ul><li>Behavioral &amp; electrophysiological changes due to salicylate are correlated within individual animals.</li><li>Majority of subjects exhibited increased response gain (R G +) post-SS.<ul><li>RT-I function: 7/8 animals had significant change.</li><li>AC I/O function: 6/8 animals had significant increase.</li><li>IC I/O function: 5/8 animals had significant change.</li></ul></li><li>All gain changes reverted to baseline 24h post-SS.</li></ul></li><li><p><strong>Hypothesis Testing</strong>:</p><ul><li>Correlation found between individual AC &amp; RT-I and between individual IC &amp; RT-I response gains.</li><li>AC and RT-I gain changes showed close concordance in magnitude.</li></ul></li><li><p><strong>Distinguishing Hyperacusis from Loudness Recruitment</strong>:</p><ul><li>Increase in response gain doesn’t necessarily indicate hyperacusis.</li><li>Response gain doesn’t determine if responses overshoot baseline.</li><li>Changes in loudness &amp; neural activity post-SS were significantly correlated.</li><li>Decreased sensitivity to low-intensity sounds post-SS linked to response changes in AC and IC.</li><li>Hyperacusis-like behavior at moderate-to-high intensities more correlated with cortical than subcortical response changes.</li></ul></li></ol><h3 id="Discussion-v2">Discussion</h3><p><strong>Discussion</strong>:<br>→ Objective: Link hyperacusis &amp; central gain enhancement.</p><p><strong>Methods</strong>:</p><ul><li>Psychophysical-electrophysiological approach.</li><li>Stable loudness &amp; auditory-evoked functions from animals.</li><li>Assessed salicylate effects on RT-I &amp; AC/IC I/O.</li></ul><p><strong>Findings</strong>:</p><ul><li>Salicylate: Alters RT-I &amp; AC/IC I/O → Suggests hearing loss &amp; hyperacusis.</li><li>Loudness &amp; sound-evoked activity affected by salicylate are correlated.</li></ul><p><strong>Significance</strong>:</p><ul><li>Supports central gain model of hyperacusis.</li><li>Within-subject comparisons valuable; inter-subject variability is a strength.</li></ul><h2 id="Mutations-causing-syndromic-autism-define-an-axis-of-synaptic-pathophysiology">Mutations causing syndromic autism define an axis of synaptic pathophysiology</h2><h3 id="Abstraction">Abstraction</h3><p><strong>Topic</strong>:<br>Tuberous sclerosis complex (TSC) &amp; fragile X syndrome (<abbr title="Fragile X Syndrome">FXS</abbr>): Genetic diseases with intellectual disability &amp; autism.</p><p><strong>Hypothesis</strong>:</p><ul><li>Cause: Mutations in genes regulating neuronal protein synthesis.</li><li>Excessive protein synthesis might be a core mechanism for intellectual disability &amp; autism.</li></ul><p><strong>Method &amp; Findings</strong>:</p><ul><li>Used: Electrophysiological &amp; biochemical assays in the hippocampus of Tsc2<sup>+/-</sup> and Fmr1<sup>-/y</sup> mice.</li></ul><ul><li>Result: Synaptic dysfunction due to mutations falls at opposite ends of a physiological spectrum.</li><li>Synaptic, biochemical, cognitive defects in mutants can be corrected by modulating metabotropic glutamate receptor 5 (mGluR5) in opposite directions.</li><li>Deficits vanish when mice carry both mutations.</li></ul><p><strong>Conclusion</strong>:</p><ul><li>Optimal synaptic plasticity &amp; cognition occur within a specific range of mGluR5-mediated protein synthesis.</li><li>Deviating from this range results in shared behavioural impairments.</li></ul><h3 id="Introduction-v4">Introduction</h3><p><strong>Background</strong>:</p><ul><li>&gt;1% have Autism Spectrum Disorder (ASD).</li><li>50% of them also have intellectual disability (ID).</li><li>Main cause: Unknown.</li><li>Some known: Genetic syndromes.</li></ul><p><strong>Fragile X Syndrome (<abbr title="Fragile X Syndrome">FXS</abbr>)</strong>:</p><ul><li>Caused by <abbr title="Fragile X mental retardation 1">FMR1</abbr> gene silencing.</li><li>Fmr1 knockout mouse: ↑ protein synthesis via mGluR5.</li><li>Inhibiting mGluR5 corrects <abbr title="Fragile X Syndrome">FXS</abbr>.</li></ul><p><strong>Hypothesis</strong>:</p><ul><li>Some ASD &amp; ID from gene mutations affecting synaptic mRNA.</li><li>Altered protein synthesis common in autism &amp; ID?</li></ul><p><strong>Study Aim</strong>:</p><ul><li>Examine: TSC mutation → same protein synthesis abnormalities as <abbr title="Fragile X Syndrome">FXS</abbr>?</li><li>If yes, one treatment could benefit both disorders.</li></ul><h3 id="Result-v3">Result</h3><h4 id="TSC-mutations-affect-synaptic-function">TSC mutations affect synaptic function</h4><p><strong>Reasons</strong>:</p><ol><li>Single-gene disorder → ASD &amp; ID symptoms like <abbr title="Fragile X Syndrome">FXS</abbr>.</li><li>Affected gene in receptor-to-mRNA translation pathway.</li><li>Valid mouse models available.</li><li>Some mouse models respond to protein synthesis treatments.</li></ol><p><strong>TSC Details</strong>:</p><ul><li>Caused by TSC1 or TSC2 gene mutations.</li><li>Form TSC1/2 complex.</li><li>TSC1/2 inhibits Rheb → specific for mTOR in mTORC1 complex.</li><li>Excessive mTORC1 → ↑ mRNA translation &amp; cell growth.</li><li>TSC symptoms: Hamartoma growths due to functional allele inactivation.</li><li>Some TSC neurological symptoms: Tumor growth in cortex.</li><li>Other symptoms (cognitive &amp; autism): Abnormal synaptic signaling.</li></ul><p><strong>Mouse Model</strong>:</p><ul><li>Tsc1 or Tsc2 mutants → hippocampus-dependent learning/memory deficits.</li><li>No brain tumors or seizures.</li><li>Used Tsc2<sup>+/-</sup> model.<ul><li>TSC2 mutations more severe &amp; common in humans.</li><li>Tsc2<sup>+/-</sup> mice treated with mTORC1 inhibitor (rapamycin) → improved hippocampal memory.</li><li>Potential drug treatment for TSC &amp; <abbr title="Fragile X Syndrome">FXS</abbr>.</li></ul></li></ul><p><strong>Hypothesis</strong>:</p><ul><li>TSC synaptic dysfunction → ↑ protein synthesis (due to ↑ mTORC1).</li><li>mTORC1 links mGluR5 to protein synthesis.</li><li>mTOR ↑ protein synthesis also in Fmr1<sup>-/y</sup> mouse (controversial).</li></ul><p><strong>mGluR-LTD</strong>:</p><ul><li>Electrophysiological measure of local mRNA translation.</li><li>Exaggerated LTD in Fmr1<sup>-/y</sup> → led to mGluR <abbr title="Fragile X Syndrome">FXS</abbr> theory.</li><li>Study: Examine mGluR-LTD in Tsc2<sup>+/-</sup> mouse hippocampus.</li></ul><h4 id="Protein-synthesis-and-mGluR-LTD-in-Tsc2-mice">Protein synthesis and mGluR-LTD in Tsc2<sup>+/-</sup> mice</h4><ol><li><p><strong>LTD Induction</strong>:</p><ul><li>Used Gp1 mGluRs (mGluR 1 &amp; 5) activation with DHPG in hippocampal slices.</li><li>Tsc2<sup>+/-</sup> mice showed deficient DHPG-induced LTD compared to WT (Fig. 1a).</li><li>Similar deficit observed with patterned electrical stimulation (Fig. 1b).</li></ul></li><li><p><strong>Tsc2<sup>+/-</sup> Synaptic Function</strong>:</p><ul><li>Basal synaptic transmission in CA1 was normal (Supplementary Fig. 1).</li><li>NMDA-receptor-dependent LTD was also similar between Tsc2<sup>+/-</sup> and WT (Fig. 1c).</li><li>DHPG-induced ERK1/2 phosphorylation (indicator of Gp1 mGluR signalling) unchanged in Tsc2<sup>+/-</sup> (Fig. 1d).</li><li>Concluded: Deficit in mGluR-LTD isn’t from global synaptic or Gp1 mGluR signalling disruption.</li></ul></li><li><p><strong>LTD Mechanisms</strong>:</p><ul><li>Two mechanisms in WT:<ol><li>Reduced presynaptic glutamate release probability.</li><li>Reduced postsynaptic AMPA receptors.</li></ol></li><li>Postsynaptic change needs immediate mRNA translation in hippocampal pyramidal neurons.</li><li>Cycloheximide (protein synthesis inhibitor) reduced LTD in WT (Fig. 2a) but not in Tsc2<sup>+/-</sup> (Fig. 2b).</li><li>Suggests: Tsc2<sup>+/-</sup> has selective loss of protein-synthesis-dependent component of LTD.</li></ul></li><li><p><strong>Comparison with Fmr1<sup>-/y</sup> Mouse</strong>:</p><ul><li>Tsc2<sup>+/-</sup>'s electrophysiological results contrast Fmr1<sup>-/y</sup>, where mGluR-LTD is enhanced.</li><li>Fmr1<sup>-/y</sup> has increased basal mRNA translation downstream of mGluR5.</li><li>Tsc2<sup>+/-</sup> showed decreased [<sup>35</sup>S] methionine/cysteine protein incorporation under basal conditions (Fig. 2d).</li></ul></li><li><p><strong>Arc Protein</strong>:</p><ul><li>Reduced Arc expression in Tsc2<sup>+/-</sup> hippocampal slices (Fig. 2e).</li><li>Arc is synthesized in response to Gp1 mGluR activation and required for mGluR-LTD.</li><li>Significant reduction in Arc translation in Tsc2<sup>+/-</sup> hippocampus (Fig. 2f).</li><li>Indicates: mGluR-LTD deficiency in Tsc2<sup>+/-</sup> due to decreased translation of LTD-stabilizing proteins, including Arc.</li></ul></li></ol><h4 id="LTD-deficit-caused-by-excess-mTOR-activity">LTD deficit caused by excess mTOR activity</h4><ol><li><strong>Goal</strong>: Understand if the Tsc2<sup>+/-</sup> mutation’s impact on mGluR-LTD is due to unchecked mTOR activity.</li><li><strong>Key Findings</strong>:<ul><li>Rapamycin restored mGluR-LTD in Tsc2<sup>+/-</sup> to normal levels.</li><li>This treatment didn’t affect the WT mice.</li><li>The rescue in Tsc2<sup>+/-</sup> was due to restored protein synthesis.</li></ul></li><li><strong>Conclusion</strong>: Uncontrolled mTOR activity in Tsc2<sup>+/-</sup> hinders the protein synthesis needed for mGluR-LTD.</li></ol><h4 id="Effect-of-mGluR5-positive-allosteric-modulation">Effect of mGluR5-positive allosteric modulation</h4><p><strong>mGluR5’s Role in Tsc2<sup>+/-</sup> Model of TSC</strong>:</p><ol><li><p><strong>Background</strong>:</p><ul><li><abbr title="Fragile X Syndrome">FXS</abbr> issues are fixed by lowering mGluR5 signaling.</li><li>Thought of boosting mGluR5 signaling for TSC.</li></ul></li><li><p><strong>mGluR5 PAM’s Impact</strong>:</p><ul><li>A PAM boosts mGluR-LTD in Tsc2<sup>+/-</sup> mice.</li><li>This corrects the protein-dependent part of LTD.</li><li>PAM (CDPPB) also fixes protein and Arc synthesis issues.</li></ul></li><li><p><strong>Behavioral Effects</strong>:</p><ul><li>Tsc2<sup>+/-</sup> mice struggle in a fear task.</li><li>mGluR5 and new protein synthesis are crucial for this.</li><li>CDPPB treatment before training helps Tsc2<sup>+/-</sup> mice.</li></ul></li><li><p><strong>Conclusion</strong>: Boosting mGluR5 might help treat TSC cognitive problems.</p></li></ol><h4 id="Fmr2-y-and-Tsc21-2-mutations-cancel-each-other">Fmr2/y and Tsc21/2 mutations cancel each other</h4><p><strong>Contrasting Effects of <abbr title="Fragile X Syndrome">FXS</abbr> and TSC Mutations on mGluR5 and Memory</strong>:</p><ol><li><p><strong>Initial Findings</strong>:</p><ul><li><abbr title="Fragile X Syndrome">FXS</abbr> and TSC mutations show opposite impacts on protein-synthesis-dependent LTD.</li><li>They respond oppositely to mGluR5 treatments.</li></ul></li><li><p><strong>Experiment with Combined Mutations</strong>:</p><ul><li>Introduced an Fmr1 deletion to Tsc2<sup>+/-</sup> background.</li><li>mGluR-LTD was reduced in Tsc2<sup>+/-</sup> and increased in Fmr1<sup>-/y</sup>.</li><li>Mice with both mutations showed mGluR-LTD similar to WT.</li></ul></li><li><p><strong>Memory Impairment Comparison</strong>:</p><ul><li>Tsc2<sup>+/-</sup> and Fmr1<sup>-/y</sup> have similar cognitive issues, despite opposite synaptic alterations.</li><li>Both have a context discrimination memory deficit.</li><li>However, double mutants don’t show this deficit, suggesting both mutations might counteract each other’s effects on behavior.</li></ul></li></ol><h3 id="Discussion-v3">Discussion</h3><p><strong>LTD, Protein Synthesis, and Genetic Disorders:</strong></p><ol><li><p><strong>Context</strong>:</p><ul><li>LTD and mGluR5-related protein synthesis are significant in <abbr title="Fragile X Syndrome">FXS</abbr>.</li><li><abbr title="Fragile X Syndrome">FXS</abbr> arises from the absence of FMRP, an mRNA-binding protein inhibiting translation.</li><li>In the Fmr1<sup>-/y</sup> mouse, there’s heightened protein synthesis and exaggerated LTD via an mGluR5-ERK1/2 pathway.</li></ul></li><li><p><strong>mTOR Significance</strong>:</p><ul><li>Elevated mTOR activity suppresses protein synthesis vital for LTD in Tsc2<sup>+/-</sup> mice.</li><li>Hyperphosphorylation of FMRP or increased translation of certain mRNAs might explain this suppression.</li><li>Arc, crucial for mGluR5-related long-term plasticity, is under-translated in Tsc2<sup>+/-</sup> mice.</li><li>mGluR-LTD differences in Tsc2<sup>+/-</sup> and Fmr1<sup>-/y</sup> mice suggest distinct regulation by FMRP and TSC1/2.</li></ul></li><li><p><strong>Potential Treatments</strong>:</p><ul><li>Rapamycin, though beneficial, has limitations due to immunosuppressive properties.</li><li>mGluR5 PAMs might target synaptic mechanisms causing cognitive and behavioral issues in TSC.</li></ul></li><li><p><strong>Implications for ASD</strong>:</p><ul><li>TSC and <abbr title="Fragile X Syndrome">FXS</abbr> are significant genetic risk factors for ASD and intellectual disability.</li><li>While Fmr1 mutation leads to exaggerated protein synthesis and LTD, Tsc2 mutation causes the opposite. Both can be balanced out in combined mutations.</li><li>This suggests that ASD’s genetic causes might produce similar effects by deviations from the norm.</li><li>Therapies for one type of ASD might not work for all, emphasizing personalized treatments.</li></ul></li></ol><h2 id="Deletion-of-Fmr1-from-Forebrain-Excitatory-Neurons-Triggers-Abnormal-Cellular-EEG-and-Behavioral-Phenotypes-in-the-Auditory-Cortex-of-a-Mouse-Model-of-Fragile-X-Syndrome">Deletion of Fmr1 from Forebrain Excitatory Neurons Triggers Abnormal Cellular, EEG, and Behavioral Phenotypes in the Auditory Cortex of a Mouse Model of Fragile X Syndrome</h2><h3 id="Abstract-v3">Abstract</h3><p><strong>Fragile X Syndrome and Sensory Processing Deficits:</strong></p><ol><li><p><strong>Context</strong>:</p><ul><li>Fragile X syndrome (<abbr title="Fragile X Syndrome">FXS</abbr>) is a primary genetic cause of autism, marked by sensory processing anomalies.</li><li>In humans with <abbr title="Fragile X Syndrome">FXS</abbr> and Fmr1 knockout (KO) mouse model: EEG shows enhanced resting gamma power and diminished sound-evoked gamma synchrony.</li></ul></li><li><p><strong>Matrix Metalloproteinase-9 (MMP-9)</strong>:</p><ul><li>Past studies indicate elevated MMP-9 levels might influence these EEG anomalies by affecting perineuronal nets (PNNs) around parvalbumin (PV) interneurons in the auditory cortex of Fmr1 KO mice.</li></ul></li><li><p><strong>Effects of Fmr1 Deletion in Excitatory Neurons</strong>:</p><ul><li>Cortical MMP-9 gelatinase activity, mTOR/Akt phosphorylation, and resting EEG gamma power increase.</li><li>Density of PV/PNN cells decrease.</li><li>Cre<sup>Nex1</sup> /Fmr1<sup>Flox/y</sup> cKO mice show heightened locomotor activity but not anxiety-like behaviors.</li></ul></li><li><p><strong>Implications</strong>:</p><ul><li>FMRP changes in cortical excitatory neurons can produce cellular, electrophysiological, and behavioral phenotypes in Fmr1 KO mice.</li><li>Suggests local cortical circuit abnormalities play a role in sensory processing deficits in autism spectrum disorders.</li></ul><p><strong>Fragile X Syndrome and Sensory Processing Deficits: An In-depth Study</strong></p></li></ol><h3 id="Introduction-v5">Introduction</h3><ol><li><p><strong>Introduction &amp; Background</strong>:</p><ul><li>Fragile X syndrome (<abbr title="Fragile X Syndrome">FXS</abbr>) is a monogenic form of autism spectrum disorders (ASD).</li><li>Caused by a CGG repeat expansion in the Fmr1 gene, leading to downregulation of fragile X mental retardation protein (FMRP).</li><li>Symptoms include anxiety, intellectual disability, and abnormal sensory processing, particularly auditory hypersensitivity.</li></ul></li><li><p><strong>Auditory Hypersensitivity in <abbr title="Fragile X Syndrome">FXS</abbr></strong>:</p><ul><li>Both humans with <abbr title="Fragile X Syndrome">FXS</abbr> and Fmr1 knockout (KO) mice exhibit auditory hypersensitivity.</li><li>Electroencephalographic (EEG) studies in these subjects have shown increased resting EEG gamma band power, which could underlie sensory hypersensitivity.</li></ul></li><li><p><strong>The Role of Matrix Metalloproteinase-9 (MMP-9)</strong>:</p><ul><li>MMP-9 levels are elevated in <abbr title="Fragile X Syndrome">FXS</abbr> brains and could affect the development of parvalbumin (PV)-expressing inhibitory interneurons.</li><li>MMP-9 is secreted from various cell types including astrocytes and neurons.</li><li>It can also mediate changes in synaptic functions through the PI3K/Akt/mTOR pathway.</li></ul></li><li><p><strong>Cell-Specific Effects</strong>:</p><ul><li>FMRP is expressed in multiple levels and cell types in the auditory pathway.</li><li>The origin and cell type specificity of abnormal EEG recordings are still unknown.</li></ul></li><li><p><strong>Objective of the Current Study</strong>:</p><ul><li>To understand the impact of deleting Fmr1 specifically from forebrain excitatory neurons.</li></ul></li><li><p><strong>Findings</strong>:</p><ul><li>Deletion of FMRP from forebrain excitatory neurons was sufficient to elicit <abbr title="Fragile X Syndrome">FXS</abbr>-associated symptoms.</li><li>This includes enhanced MMP-9 activity, increased mTOR/Akt signaling, impaired PV/PNN expression, and hyperactive behaviors.</li></ul></li><li><p><strong>Implications</strong>:</p><ul><li>The study suggests that FMRP in excitatory neurons is critical for normal cortical activity.</li><li>Highlights novel mechanisms potentially leading to sensory hypersensitivity in <abbr title="Fragile X Syndrome">FXS</abbr> and possibly other forms of ASD.</li></ul></li></ol><h3 id="Result-v4">Result</h3><ol><li><strong>Goals</strong>:</li></ol><ul><li>Check if issues in auditory cortex of Fmr1 KO mice persist in adulthood.</li><li>Examine effects of FMRP deletion on brain and behavior.</li></ul><ol start="2"><li><strong>Key Results</strong>:</li></ol><ul><li>Reduced density of PV cells in layer 4 of auditory cortex in Fmr1 KO mice.</li><li>Lower density of WFA+ PNN cells in both layer 4 and 2/3 in Fmr1 KO mice.</li><li>Poor formation of PNNs around PV cells in Fmr1 KO mice.</li></ul><ol start="3"><li><strong>Implications</strong>:</li></ol><ul><li>The observed deficits are long-lasting, suggesting they may cause enhanced sound sensitivity in Fmr1 KO mice.</li></ul><h4 id="FMRP-Immunoreactivity-Was-Significantly-Reduced-in-Excitatory-Neurons-of-Auditory-Cortex-of-Adult-CreNex1-Fmr1Flox-y-cKO-Mice">FMRP Immunoreactivity Was Significantly Reduced in Excitatory Neurons of Auditory Cortex of Adult Cre<sup>Nex1</sup> /Fmr1<sup>Flox/y</sup> cKO Mice</h4><ol><li><strong>Method</strong>:</li></ol><ul><li>Used Cre<sup>Nex1</sup> and Fmr1flox/flox KO mice to specifically delete FMRP in forebrain excitatory neurons.</li></ul><ol start="2"><li><strong>Key Results</strong>:</li></ol><ul><li>Significant reduction in FMRP in the auditory cortex of Cre<sup>Nex1</sup>/Fmr1<sup>Flox/y</sup> cKO mice compared to controls.</li><li>No significant change in cell density in the auditory cortex.</li><li>No significant changes in FMRP expression in other parts of the auditory pathway like the inferior colliculus and auditory thalamus.</li></ul><ol start="3"><li><strong>Implications</strong>:</li></ol><ul><li>The deletion of FMRP is specific to forebrain excitatory neurons in the auditory cortex and doesn’t affect other regions, confirming the targeted nature of the genetic manipulation.</li></ul><h4 id="Deletion-of-FMRP-from-Excitatory-Neurons-Reduces-PV-PNN-and-PV-PNN-Colocalization-in-the-Auditory-Cortex-of-Adult-CreNex1-Fmr1-Flox-y-cKO-Mice">Deletion of FMRP from Excitatory Neurons Reduces PV, PNN, and PV/PNN Colocalization in the Auditory Cortex of Adult CreNex1 /Fmr1 Flox/y cKO Mice</h4><ol><li><p><strong>Method</strong>:</p><ul><li>Studied cell density in the auditory cortex of specific knockout mice (CreNex1/Fmr1Flox/y cKO) and control mice (Fmr1Flox/y).</li></ul></li><li><p><strong>Results</strong>:</p><ul><li>Fewer PV cells in knockout mice in two brain layers (L4 and L2/3).</li><li>Fewer WFA+ PNN cells in the same layers in knockout mice.</li><li>Less overlap of PV and WFA+ PNN cells in knockout mice in both layers.</li></ul></li><li><p><strong>Implications</strong>:</p><ul><li>Loss of FMRP in excitatory neurons affects these cells.</li><li>This could disrupt overall brain network function.</li></ul></li></ol><h4 id="Total-Aggrecan-Levels-Are-Reduced-While-Cleaved-Aggrecan-Levels-and-Gelatinase-Activity-Are-Enhanced-in-the-Auditory-Cortex-of-Adult-CreNex1-Fmr1-Flox-y-cKO-Mice">Total Aggrecan Levels Are Reduced, While Cleaved Aggrecan Levels and Gelatinase Activity Are Enhanced in the Auditory Cortex of Adult CreNex1 /Fmr1 Flox/y cKO Mice</h4><ol><li><p><strong>Method</strong>:</p><ul><li>Conducted a gelatinase activity assay and measured aggrecan levels in the auditory cortex of specific mouse models.</li></ul></li><li><p><strong>Results</strong>:</p><ul><li>Higher gelatinase activity in both Fmr1 KO and Cre Nex1/Fmr1 Flox/y cKO mice compared to controls.</li><li>Lower levels of full-length aggrecan and higher levels of cleaved aggrecan in both Fmr1 KO and Cre Nex1/Fmr1 Flox/y cKO mice.</li><li>Increased ratio of cleaved aggrecan to total aggrecan in these mice.</li></ul></li><li><p><strong>Implications</strong>:</p><ul><li>The increased gelatinase activity, likely due to elevated MMP-9 levels, may contribute to the loss of PNNs.</li><li>The cleavage of aggrecan, a key component of PNNs, is also affected.</li><li>The loss of FMRP in excitatory neurons may underlie these molecular changes, affecting overall neural network integrity.</li></ul></li></ol><h4 id="Deletion-of-FMRP-from-Excitatory-Neurons-Triggers-a-Decrease-in-PV-Levels-While-Akt-and-mTOR-Phosphorylation-Is-Increased-in-Auditory-Cortex-of-Adult-CreNex1-Fmr1-Flox-y-cKO-Mice">Deletion of FMRP from Excitatory Neurons Triggers a Decrease in PV Levels, While Akt and mTOR Phosphorylation Is Increased in Auditory Cortex of Adult CreNex1 /Fmr1 Flox/y cKO Mice</h4><p><strong>Key Findings on PV Levels and Akt/mTOR Signaling</strong></p><ol><li><p><strong>Method</strong>:</p><ul><li>Measured levels of Parvalbumin (PV) and phosphorylated forms of Akt and mTOR in the auditory cortex of specific mouse models.</li></ul></li><li><p><strong>Results</strong>:</p><ul><li>Significant decrease in PV levels in the auditory cortex of Fmr1 KO and Cre Nex1/Fmr1 Flox/y cKO mice.</li><li>Higher levels of phosphorylated (i.e., active) forms of Akt and mTOR in these mouse models compared to their controls.</li></ul></li><li><p><strong>Implications</strong>:</p><ul><li>The decrease in PV levels is consistent with earlier findings in autism mouse models and might be linked to network dysfunction.</li><li>Enhanced Akt/mTOR signaling could contribute to synaptic changes and hyperexcitability seen in <abbr title="Fragile X Syndrome">FXS</abbr> and other autism spectrum disorders.</li><li>The deletion of FMRP in excitatory neurons is sufficient to trigger these molecular changes, pointing to its pivotal role in the auditory cortex of adult mice.</li></ul></li></ol><h4 id="Resting-EEG-Gamma-Power-Is-Enhanced-in-the-Auditory-Cortex-of-Adult-CreNex1-Fmr1-Flox-y-cKO-Mice">Resting EEG Gamma Power Is Enhanced in the Auditory Cortex of Adult CreNex1 /Fmr1 Flox/y cKO Mice</h4><p><strong>Key Findings on Impaired Neural Oscillations and Local Circuit Defects</strong></p><ol><li><p><strong>Objective</strong>:</p><ul><li>To determine if deficits in forebrain excitatory neurons cause abnormal neural oscillations similar to global Fmr1 KO mice.</li></ul></li><li><p><strong>Methods</strong>:</p><ul><li>Baseline EEG raw power in auditory cortex examined for Cre Nex1/Fmr1 Flox/y cKO mice (n=9) and control Fmr1Flox/y mice (n=9).</li><li>Analyzed various frequency bands during a 5-minute resting period.</li></ul></li><li><p><strong>Results</strong>:</p><ul><li>Enhanced high-frequency oscillations observed in the auditory cortex of Cre Nex1/Fmr1 Flox/y cKO mice.</li><li>Significant increase in low gamma power (30-55 Hz) in the auditory cortex of these mice.</li></ul></li><li><p><strong>Implications</strong>:</p><ul><li>The abnormal low gamma power likely stems from local circuit defects, similar to global Fmr1 KO mice.</li><li>These local circuit defects may be related to observed increases in gelatinase activity and reduced PV+ cell density and WFA+ PNNs around PV+ neurons.</li><li>The results suggest that specific types of neurons may be critical for the neural oscillation abnormalities observed in <abbr title="Fragile X Syndrome">FXS</abbr> and potentially other autism spectrum disorders.</li></ul></li></ol><p>This study adds to the understanding that local cortical circuit abnormalities, possibly related to impaired PV+ interneuron function, contribute to neural oscillation deficits in <abbr title="Fragile X Syndrome">FXS</abbr>.</p><h4 id="Gamma-Synchronization-Is-Not-Affected-in-Adult-CreNex1-Fmr1-Flox-y-cKO-Mouse-Auditory-Cortex">Gamma Synchronization Is Not Affected in Adult CreNex1 /Fmr1 Flox/y cKO Mouse Auditory Cortex</h4><p><strong>Key Findings on Phase Locking and Gamma Synchronization</strong></p><ol><li><p><strong>Objective</strong>:</p><ul><li>To investigate if increased baseline gamma in Cre Nex1/Fmr1 Flox/y cKO mice impacts the consistency of sound-evoked gamma synchronization.</li></ul></li><li><p><strong>Methods</strong>:</p><ul><li>Used “chirp” stimuli with varying modulation frequencies, both up and down, presented 300 times each.</li><li>Employed Inter-Trial Phase Coherence (ITPC) analysis to measure phase consistency across trials.</li></ul></li><li><p><strong>Results</strong>:</p><ul><li>Despite increased baseline gamma in Cre Nex1/Fmr1 Flox/y cKO mice, there were no significant differences in gamma band ITPC compared to controls.</li><li>Similar patterns observed for both up- and down-chirps.</li></ul></li><li><p><strong>Implications</strong>:</p><ul><li>The lack of difference in gamma ITPC suggests that the gamma synchronization deficits in global Fmr1 KO mice are not solely due to excitatory neurons in the forebrain.</li><li>This opens up the possibility that other cell types in the cortex or subcortical sites could be responsible for these deficits.</li></ul></li></ol><p>The study suggests that while local circuit defects may contribute to baseline gamma power, they may not be the sole factor affecting gamma synchronization in response to auditory stimuli in <abbr title="Fragile X Syndrome">FXS</abbr>.</p><h4 id="Increased-Non–Phase-Locked-STP-Is-Observed-in-the-Auditory-Cortex-of-Adult-CreNex1-Fmr1-Flox-y-cKO-Mice-during-Chirp-Stimulation">Increased Non–Phase-Locked STP Is Observed in the Auditory Cortex of Adult CreNex1 /Fmr1 Flox/y cKO Mice during Chirp Stimulation</h4><ol><li>Studied gamma power in Cre Nex1/Fmr1 Flox/y cKO mice.</li><li>Found increased lower gamma power.</li><li>Suggests local circuit issues.</li></ol><h4 id="Induced-Power-Is-Significantly-Enhanced-in-the-Auditory-Cortex-of-Adult-CreNex1-Fmr1-Flox-y-cKO-Mice">Induced Power Is Significantly Enhanced in the Auditory Cortex of Adult CreNex1 /Fmr1 Flox/y cKO Mice</h4><ol><li>Tested auditory cortex responses to noise bursts at 4 Hz and 0.25 Hz rates.</li><li>Cre Nex1/Fmr1 Flox/y cKO mice showed reduced phase locking in the beta range (20-30 Hz).</li><li>Increased “ongoing” response was observed in the beta to low gamma range (10-50 Hz).</li><li>These effects persisted in repeated sound stimulation.</li><li>Results suggest increased variability and reduced suppression of ongoing activity in cKO mice.</li></ol><h4 id="Excitatory-Neuron-Specific-Adult-CreNex1-Fmr1-Flox-y-cKO-Mice-Display-Increased-Locomotor-Activity-but-No-Anxiety-Like-Behavior">Excitatory Neuron-Specific Adult CreNex1 /Fmr1 Flox/y cKO Mice Display Increased Locomotor Activity, but No Anxiety-Like Behavior</h4><ol><li>Mice were tested for activity and anxiety using elevated plus maze and open field (OF) tests.</li><li>Cre Nex1/Fmr1 Flox/y cKO mice showed more arm entries and higher speed, indicating increased locomotor activity.</li><li>No difference was observed in time spent in open arms, suggesting no change in anxiety levels.</li><li>In the OF test, cKO mice also crossed more lines and moved faster, confirming increased activity.</li><li>No significant difference in time spent in center or thigmotaxis, again suggesting no change in anxiety.</li><li>Conclusion: Deleting FMRP from forebrain excitatory neurons increases activity but doesn’t affect anxiety-like behaviors.</li></ol><h3 id="Discussion-v4">Discussion</h3><ol><li>Study aims to understand sensory processing issues in Fragile X Syndrome (<abbr title="Fragile X Syndrome">FXS</abbr>), a genetic cause of Autism Spectrum Disorder (ASD).</li><li>Deleting Fmr1 from forebrain excitatory neurons causes abnormal EEG patterns in adult auditory cortex.</li><li>This deletion also increases gelatinase activity, affecting Perineuronal Nets (PNNs) around Parvalbumin (PV) neurons.</li><li>PV neurons are crucial for sensory processing; their dysfunction may underlie sensory issues in <abbr title="Fragile X Syndrome">FXS</abbr>.</li><li>The study also finds higher mTOR/Akt phosphorylation in the cortex, suggesting altered signaling pathways.</li><li>Reduced excitation to PV neurons may lead to their decreased activity and function.</li><li>Low-gamma band power in auditory cortex is specifically increased; this could influence sensory and cognitive processes.</li><li>Both cortical and sub-cortical structures likely contribute to auditory processing deficits in <abbr title="Fragile X Syndrome">FXS</abbr>.</li><li>Future research is needed to explore effects of Fmr1 deletion in other brain areas and cell types for a system-level understanding.</li></ol><h4 id="Role-of-Enhanced-Gelatinase-Activity-in-CreNex1-Fmr1Flox-y-cKO-Mice">Role of Enhanced Gelatinase Activity in CreNex1 /Fmr1Flox/y cKO Mice</h4><p>The study elaborates on the intricate relationship between the loss of the FMRP protein and various neural and behavioral phenomena in Fragile X Syndrome (<abbr title="Fragile X Syndrome">FXS</abbr>). Here’s a breakdown:</p><h3 id="Molecular-Mechanisms">Molecular Mechanisms</h3><ol><li><strong>Perineuronal Nets (PNNs) and Parvalbumin (PV) Neurons</strong>: PNNs surround PV neurons and are crucial for their function. Aggrecan, a component of PNNs, is degraded by gelatinases (MMP-2, MMP-9), affecting the structure and function of PNNs.</li><li><strong>Gelatinase Activity</strong>: The study found increased gelatinase activity in the auditory cortex of mice lacking FMRP, indicating that this may contribute to impaired PNN formation.</li><li><strong>Signaling Pathways</strong>: Increased gelatinase activity can also affect the mTOR and Akt signaling pathways, which are implicated in <abbr title="Fragile X Syndrome">FXS</abbr> and regulate neuronal excitability.</li></ol><h3 id="Auditory-Cortex-and-Sensory-Processing">Auditory Cortex and Sensory Processing</h3><ol><li><strong>MMP-9 and Sensory Responses</strong>: Deletion or reduction of MMP-9 activity in mice normalized auditory responses and PNN formation, highlighting its therapeutic potential.</li><li><strong>Subcortical Contributions</strong>: While the study indicates cortical deficits, it also suggests that subcortical areas may contribute to the observed abnormalities.</li></ol><h3 id="Behavioral-Aspects">Behavioral Aspects</h3><ol><li><strong>Locomotor Activity</strong>: Mice with FMRP deletion in forebrain excitatory neurons showed increased locomotor activity but no anxiety-like behaviors.</li><li><strong>Role of FMRP in Other Areas</strong>: FMRP loss in other brain regions like the hippocampus may contribute to other <abbr title="Fragile X Syndrome">FXS</abbr> symptoms like learning and memory deficits.</li></ol><h3 id="Future-Directions">Future Directions</h3><ol><li><strong>Astrocytes and MMP-9</strong>: The study proposes to investigate how astrocytes may be involved in regulating MMP-9 activity and PNN formation.</li><li><strong>Multi-Electrode EEGs</strong>: To get a comprehensive understanding, the study recommends exploring electrocortical activity in different brain areas.</li></ol><p>Overall, the study provides a multi-faceted understanding of how FMRP loss impacts neural circuits and behaviors, offering potential therapeutic targets like MMP-9 for <abbr title="Fragile X Syndrome">FXS</abbr>.</p><p>Certainly! Here’s a more elegant and concise summary of the research findings and their implications.</p><h3 id="Conclusion">Conclusion</h3><p><strong>Key Insights</strong></p><ol><li><p><strong>Parvalbumin Neurons</strong>: Deletion of the Fmr1 gene in forebrain excitatory neurons impinges upon the integrity and function of parvalbumin-positive (PV+) inhibitory neurons.</p></li><li><p><strong>Matrix Enzymology</strong>: Elevated activity of the enzyme MMP-9 remodels the extracellular scaffolding around PV+ neurons, potentially altering cellular signaling cascades.</p></li><li><p><strong>Electrophysiological Nuances</strong>: The study discerns a specific alteration in resting low-gamma EEG power, correlated with hyperactive behaviors but not with anxiety.</p></li><li><p><strong>Symptomatic Specificity</strong>: The research delineates that cortical deficits are responsible for some, but not all, features of Fragile X Syndrome, underscoring a nuanced impact of the Fmr1 deletion.</p></li></ol><p><strong>Clinical Implications</strong></p><ul><li>The findings elegantly illuminate avenues for targeted therapeutic strategies, offering the prospect of interventions honed to specific cellular actors and neural circuits implicated in Fragile X Syndrome.</li></ul><p>By delving into the intricacies of cellular and circuit-level changes, this study enriches our understanding of Fragile X Syndrome and opens new horizons for targeted therapeutic interventions.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Acoustics</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>Advanced Molecular &amp; Cell Biology 1</title>
    <link href="https://karobben.github.io/2023/08/22/LearnNotes/UIUC-AdMC-1/"/>
    <id>https://karobben.github.io/2023/08/22/LearnNotes/UIUC-AdMC-1/</id>
    <published>2023-08-23T04:43:14.000Z</published>
    <updated>2023-09-09T19:42:04.491Z</updated>
    
    <content type="html"><![CDATA[<h2 id="DNA-Structure-RNA-Polymerase-Properties-sigma-Factor-70">DNA Structure; RNA Polymerase Properties; $\sigma$ Factor 70</h2><p>!!! Main purpose for this lecture</p><ul><li>DNA sequences drive specific Protein:DNA interactions, which is fundamental for processes like transcription.</li><li>Transcription steps can be experimentally defined, allowing for detailed understanding and manipulation.</li></ul><h2 id="General-Properties">General Properties</h2><ul><li><strong>Response Element Recognition</strong>: Response elements are DNA sequences that are recognized and bound by transcription factors, enabling regulation of gene expression.</li><li><strong>HAT/PTM Complexes</strong>: Histone acetyltransferases (HAT) and post-translational modifications (PTM) play pivotal roles in regulating gene expression by modifying histones and other proteins.</li><li><strong>Chromatin Remodeling</strong>: This process allows for accessibility of transcriptional machinery to the DNA by changing the structure of chromatin.</li><li><strong>Mediator</strong>: A complex that acts as an interface between transcriptional activators, RNA polymerase, and other transcriptional machinery.</li></ul><p>The environment inside a cell is overcrowded, causing molecules to move rapidly, which influences various cellular processes.</p><table><thead><tr><th style="text-align:center"><img src="http://book.bionumbers.org/wp-content/uploads/2014/07/170-f2-CentralDogmaGoodsell-12.png" alt="Central Dogma Image"></th></tr></thead><tbody><tr><td style="text-align:center">© <a href="http://bionumbers.com">bionumbers.com</a></td></tr></tbody></table><h2 id="Subunits-have-Distinct-Functions-RNAP">Subunits have Distinct Functions (RNAP)</h2><table><thead><tr><th style="text-align:center"><img src="https://golifescience.com/wp-content/uploads/2015/10/Prokaryotic-RNA-Polymerase.png" alt=""></th><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/05/pPrcXcV.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://golifescience.com/rna-polymerase/">© golifescience</a></td><td style="text-align:center">P122; Figure 6.1</td></tr></tbody></table><h2 id="Initial-Steps">Initial Steps</h2><ol><li><strong>Promoter Search</strong>: RNA polymerase locates promoter regions, an ATP-consuming process, to initiate transcription.</li><li><strong>Closed Promoter Complex Formation</strong>: RNA polymerase binds to the promoter region without unwinding the DNA double helix.</li><li><strong>Open Promoter Complex Formation</strong>: The DNA double helix unwinds, allowing RNA polymerase to initiate RNA synthesis.</li></ol><h2 id="sigma-Factors-Driving-Specificity-Stability">$\sigma$ Factors Driving Specificity/Stability</h2><ul><li><p>Background:</p><ul><li>Core enzyme indiscriminate about the T4 genes it transcribes, it also transcribes both DNA strands.</li></ul></li><li><p>Experiment:</p><ul><li>RNA made by the holoenzyme did not hybridize with authentic T4 RNA, confirming it is made asymmetrically like the in vivo RNA.</li><li>About 30% of the RNA made by the core enzyme hybridized with authentic T4 RNA and became RNase-resistant.</li></ul></li><li><p>Conclusion:</p><ul><li>The core enzyme transcribes both DNA strands, unlike the holoenzyme that transcribes asymmetrically. This suggests the core enzyme’s activity is not as specific as the holoenzyme’s.</li></ul></li><li><p>$\sigma$ factors are essential for promoter recognition and transcription initiation.</p></li><li><p>They stabilize DNA-bound RNA Polymerase, ensuring efficient transcription.</p></li></ul><p><strong>Filter Binding Assay</strong>:</p><ul><li><p>DNA molecules can pass through a filter, but the $\sigma$ factor cannot. When mixed together, DNA molecules associate with the $\sigma$ factor, preventing them from passing through.</p></li><li><p>$\sigma$ factor aligns RNA Polymerase at a promoter, ensuring accurate transcription initiation.</p></li></ul><p><strong>Assay for Locating the ‘Melted’ DNA</strong>:</p><ul><li>Radio labeling is used to tag specific DNA sequences.</li><li>Methylation of DNA occurs at specific sites.</li><li>Cleavage of DNA at methylated sites provides insights into DNA regions that are “melted” or unwound during transcription.</li></ul><h2 id="Technics">Technics</h2><h3 id="Filter-binding-assay">Filter binding assay</h3><table><thead><tr><th style="text-align:center"><img src="https://t1.daumcdn.net/cfile/tistory/2347424656EADB1503" alt=""></th></tr></thead><tbody><tr><td style="text-align:center">P108, Figure 5.35</td></tr></tbody></table><p><strong>Nitrocellulose Membrane Filters and DNA-Protein Interaction</strong></p><h4 id="Background">Background:</h4><p>Nitrocellulose membrane filters have long been used for filter-sterilizing solutions. They are also known to bind DNA, but under specific conditions.</p><h4 id="Key-Points">Key Points:</h4><ol><li><p><strong>Binding Conditions</strong>:</p><ul><li><strong>Single-stranded DNA</strong>: Binds readily to nitrocellulose.</li><li><strong>Double-stranded DNA</strong>: Does not bind to nitrocellulose by itself.</li><li><strong>Protein</strong>: Binds to nitrocellulose. When bound to double-stranded DNA, the protein-DNA complex will bind to the filter.</li></ul></li><li><p><strong>Assay Demonstrations</strong>:</p><ul><li><strong>Figure 5.35a</strong>: Labeled double-stranded DNA passed through the filter shows that it does not bind to nitrocellulose. All labeled material found in the filtrate.</li><li><strong>Figure 5.35b</strong>: Labeled protein is filtered and is found to bind to the nitrocellulose filter. Demonstrates that proteins can bind independently.</li><li><strong>Figure 5.35c</strong>: Labeled double-stranded DNA mixed with a binding protein shows that the protein-DNA complex binds to the filter. The radioactivity is found bound to the filter, confirming the interaction.</li></ul></li></ol><h4 id="Conclusion">Conclusion:</h4><p>Filter binding assays using nitrocellulose membrane filters serve as a direct measure of DNA-protein interaction. This makes nitrocellulose filters a useful tool for studying such interactions.</p><h3 id="Methylation-S1-nuclease">Methylation-S1 nuclease</h3><table><thead><tr><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/05/pPrDk1U.png" alt="Locating the region of a T7 phage early promoter melted by RNA polymerase"></th><th style="text-align:center"><img src="https://s1.ax1x.com/2023/09/05/pPrDEX4.png" alt="RNA polymerase melts the DNA in the 29 to 13 region of the T7 A3 promoter"></th></tr></thead><tbody><tr><td style="text-align:center">Figure 6.15; P133</td><td style="text-align:center">Figure 6.16; P134</td></tr></tbody></table><h4 id="Background-v2">Background:</h4><p>In 1979, Ulrich Siebenlist carried out an experiment to identify the base pairs melted by RNA polymerase in a T7 phage early promoter. The aim was to understand the local DNA melting involved in the formation of an open promoter complex.</p><h4 id="Key-Points-v2">Key Points:</h4><ol><li><p><strong>Experiment Strategy</strong>:</p><ul><li><strong>Step 1</strong>: End-label the promoter DNA.</li><li><strong>Step 2</strong>: Add RNA polymerase to form an open promoter complex, which involves local DNA melting.</li><li><strong>Step 3</strong>: Methylate exposed adenines with dimethyl sulfate (DMS).</li><li><strong>Step 4</strong>: Remove RNA polymerase to allow the region to close.</li><li><strong>Step 5</strong>: Treat the DNA with S1 nuclease, which specifically cuts single-stranded DNA.</li><li><strong>Step 6</strong>: Electrophorese the labeled DNA fragments to determine their lengths.</li></ul></li><li><p><strong>Chemical Agent Used</strong>: Dimethyl sulfate (DMS) methylates exposed adenines, preventing them from base-pairing with thymines in the opposite strand when the region closes.</p></li><li><p><strong>S1 Nuclease</strong>: Specifically cuts where an adenine had been in a melted region and had become methylated.</p></li><li><p><strong>Results</strong>:</p><ul><li>A series of fragments extending from position 13 to 29 were observed, rather than a neat set.</li><li>The length of the melted region was estimated to be 12 base pairs.</li><li>G–C pairs were not detected due to the experimental conditions used for methylation.</li></ul></li></ol><h4 id="Conclusion-v2">Conclusion:</h4><p>The melted region in the T7 phage early promoter was identified to extend from positions 13 to 29 and to have a length of approximately 12 bp. This is in agreement with previous estimates. The experiment revealed that the melted region is precisely where RNA polymerase begins transcribing, which is of biological significance. However, the presence of G–C pairs in the region could not be verified due to limitations in the methylation conditions used.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Advanced Molecular &amp; Cell Biology 1</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Class" scheme="https://karobben.github.io/categories/Notes/Class/"/>
    
    <category term="UIUC" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/"/>
    
    <category term="Cell Biology" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/Cell-Biology/"/>
    
    
    <category term="Classes" scheme="https://karobben.github.io/tags/Classes/"/>
    
    <category term="UIUC Classes" scheme="https://karobben.github.io/tags/UIUC-Classes/"/>
    
    <category term="Cell Biology" scheme="https://karobben.github.io/tags/Cell-Biology/"/>
    
  </entry>
  
  <entry>
    <title>Advance BioChemistry: How Organism are Related</title>
    <link href="https://karobben.github.io/2023/08/21/LearnNotes/UIUC-AdBC-1/"/>
    <id>https://karobben.github.io/2023/08/21/LearnNotes/UIUC-AdBC-1/</id>
    <published>2023-08-22T04:05:26.000Z</published>
    <updated>2023-09-09T19:41:33.955Z</updated>
    
    <content type="html"><![CDATA[<h2 id="The-Big-Bang">The Big Bang</h2><p>The big bang → Earth condensation → Microbes → Anabaena with heterocytes → Oxygen appear in the atmosphere → Endosymbiotic (mitochondria) → Endosymbiotic (chloroplast) → Oxygen reach to 22% → Sponges → Trilobites → landing → reptile → mammal like reptile → pangaea separates → flowering plaints/E. coli → primate → Homo</p><table><thead><tr><th style="text-align:center"><img src="https://dailyinfographic.com/wp-content/uploads/2023/02/tKDDEak-scaled.jpg" alt="History of the world"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://dailyinfographic.com/the-history-of-planet-earth-from-the-big-bang-to-humans">© dailyinfographic</a></td></tr></tbody></table><h2 id="How-Similar-We-Are">How Similar We Are</h2><p><strong>In the GMP synthesis, E. coli and eucaryotic organisms are doing the same pathway</strong>. This shared process highlights the similarities in fundamental biochemical pathways across diverse species.</p><p>When compare to E. coli to human cell, E.coli are way more complicated than human cell:</p><ul><li><strong>all amino acid</strong>: It can synthesize all amino acids, whereas humans can’t produce all of them endogenously.</li><li><strong>Food</strong>: Capable of consuming more than 100 types of food.</li><li><strong>Environments</strong>: Can thrive in a wide range of environments, showcasing its adaptability.</li></ul><p>In contrast, <strong>human cells seem more like simplified microbes</strong>. The evolution might have played a role in streamlining certain processes in eukaryotes.</p><h2 id="Ribosomes-in-Chemistry">Ribosomes in Chemistry</h2><ol><li>It precisely matches the protein shelves, making it extremely conservative in its function.</li><li>Secondary structures are paramount, leading to mutations that are commonly paired to preserve structure and function.</li><li>Due to the matched protein structure, the rate of gene drift is limited, ensuring stability.</li></ol><p>Research on this ribosome led to the discovery of Archaea, prompting a revision in our understanding of the tree of life.</p><h2 id="Gene-Transfer-Among-Microbes">Gene Transfer Among Microbes</h2><p>Gene transfer, often referred to as Horizontal Gene Transfer (HGT), is a prevalent phenomenon among microbes. The mechanisms include:</p><ol><li>Uptake of free DNA from the environment.</li><li>Plasmid-mediated transfer.</li><li>Conjugative mating.</li><li>Virus-mediated transfer (transduction).<br>However, HGT is less common in Eukaryotes, with a few exceptions.</li></ol><h2 id="Operon-A-Unique-Feature-of-Microbes">Operon: A Unique Feature of Microbes</h2><p>Microbes often have related functional genes located in proximity. This arrangement is no accident. These genes are regulated by operons, ensuring they function in sync. The clustering of these genes is believed to have arisen due to evolutionary pressures and random events, but once established, they provide a selective advantage.</p><table><thead><tr><th style="text-align:center"><img src="https://www.researchgate.net/profile/Mario-Latendresse/publication/5905615/figure/fig4/AS:280131479326723@1443799957426/Representative-region-of-the-E-coli-genome-generated-by-the-EcoCyc-genome-browser.png" alt="E. coli genome"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.researchgate.net/publication/5905615_Multidimensional_annotation_of_the_Escherichia_coli_K-12_genome?_tp=eyJjb250ZXh0Ijp7InBhZ2UiOiJfZGlyZWN0In19">© Peter Karp, 2007</a></td></tr></tbody></table><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Advance BioChemistry</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Class" scheme="https://karobben.github.io/categories/Notes/Class/"/>
    
    <category term="UIUC" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/"/>
    
    <category term="Biochemistry" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/Biochemistry/"/>
    
    
    <category term="Classes" scheme="https://karobben.github.io/tags/Classes/"/>
    
    <category term="Biochemistry" scheme="https://karobben.github.io/tags/Biochemistry/"/>
    
    <category term="UIUC Classes" scheme="https://karobben.github.io/tags/UIUC-Classes/"/>
    
  </entry>
  
  <entry>
    <title>Behavior Analysis</title>
    <link href="https://karobben.github.io/2023/07/27/LearnNotes/behavior-research/"/>
    <id>https://karobben.github.io/2023/07/27/LearnNotes/behavior-research/</id>
    <published>2023-07-27T07:04:09.000Z</published>
    <updated>2023-07-27T19:50:50.561Z</updated>
    
    <content type="html"><![CDATA[<h2 id="What-is-behavior-research">What is behavior research</h2><p>Behavioral research, often referred to as behavior science, is the scientific study of the behavior of human beings and animals. It involves the systematic collection and analysis of data in order to understand and explain how individuals behave in certain situations.</p><p>Behavioral research spans multiple disciplines including psychology, sociology, anthropology, cognitive science, neurology, and even computer science, and it encompasses a variety of specific fields of study, such as behavioral psychology, behavioral economics, and behavioral neuroscience.</p><p>Here are a few reasons why we study behavior:</p><ol><li><p><em><strong>Understand Mechanisms</strong></em>: Understanding the mechanisms that underlie behavior can give us insights into why individuals act the way they do. This can involve studying the brain and nervous system to understand the physiological basis of behavior.</p></li><li><p><em><strong>Predict Behavior</strong></em>: By understanding the factors that influence behavior, researchers can predict how individuals will behave in different circumstances. This has applications in many fields, from marketing (predicting consumer behavior) to public health (predicting adherence to health guidelines).</p></li><li><p><em><strong>Change Behavior</strong></em>: Once we understand and can predict behavior, we can also try to change it. This can involve designing interventions to promote beneficial behaviors or discourage harmful ones.</p></li><li><p><em><strong>Evaluate Interventions</strong></em>: Behavioral research is also used to evaluate the effectiveness of interventions designed to change behavior.</p></li></ol><h2 id="How-to-study-behaviors">How to study behaviors</h2><p>As for how we study behaviors, it often involves the following steps:</p><ol><li><p><em><strong>Observation</strong></em>: The first step is often to observe the behavior in its natural context, in order to get a sense of what is happening and to generate hypotheses.</p></li><li><p><em><strong>Measurement</strong></em>: Researchers then need to find a way to measure the behavior in a systematic and reliable way. This can involve anything from timing a rat in a maze, to counting the number of times a bird performs a specific action, to administering questionnaires to human participants.</p></li><li><p><em><strong>Experimentation</strong></em>: Once the behavior has been measured, researchers can conduct experiments to test their hypotheses. This typically involves manipulating one or more variables and observing the effect on the behavior.</p></li><li><p><em><strong>Analysis</strong></em>: The data collected in the experiment is then analyzed, often using statistical methods, to determine whether the observed effects are statistically significant.</p></li><li><p><em><strong>Interpretation and Publication</strong></em>: The results are then interpreted in light of the original hypotheses, and the study is usually written up and published in a scientific journal, so that other researchers can evaluate and build on the findings.</p></li></ol><p>Overall, behavioral research is a vast field that offers insights into the complexities of behavior and provides a foundation for making predictions and interventions in various sectors of life and society.</p><h2 id="Common-things-we-can-do-with-in-behavior-analysis">Common things we can do with in behavior analysis</h2><ol><li><p><em><strong>Social network analysis</strong></em>: Consider each animal as a node and an interaction as an edge in a network. You can use graph analysis techniques to identify which animals have the most interactions (central nodes), which ones tend to interact with each other (clusters), and whether the pattern of interactions changes over time.</p></li><li><p><em><strong>Behavioral change over time</strong></em>: Analyze the animals’ behaviors (like wing extensions or movement patterns) over time. Look for patterns or triggers for specific behaviors - do they happen more frequently at certain times or after specific interactions?</p></li><li><p><em><strong>Collective behavior</strong></em>: You can look at the group-level behaviors. For example, if the group tends to move together, you can calculate the polarization of the group, which is a measure of how much the animals’ movement directions align with each other. If the group tends to stay together, you can calculate the nearest neighbor distance or the density of the group, which are measures of the group’s cohesion.</p></li><li><p><em><strong>Individual vs. group behavior</strong></em>: Try comparing individual behaviors to the group behavior. Are there certain individuals that often initiate group movements? Are there individuals that often behave differently than the group?</p></li><li><p><em><strong>Correlation between movement and behavior</strong></em>: Investigate if there’s a correlation between the movement of an animal (speed, acceleration, etc.) and its specific behaviors like wing extensions. Does a specific behavior trigger a change in movement or vice versa?</p></li><li><p><em><strong>Response to stimuli</strong></em>: If your data includes any events or stimuli (like changes in the environment or the appearance of food or predators), you can analyze how these affect the animals’ behavior. Do these events trigger specific behaviors or changes in interaction patterns?</p></li></ol><p>To quantify the interactions, you could count the number of interactions each animal has, the frequency of interactions, the average duration of interactions, etc. You could also quantify the result of each interaction - for example, does one animal tend to move away after interacting with another?</p><p>You would need to use statistical methods and possibly machine learning techniques to perform these analyses, depending on the complexity of your data and the questions you’re trying to answer. You might also find it helpful to visualize your data, both to help you understand it and to communicate your results to others.</p><h2 id="Something-more-we-may-can-do">Something more we may can do</h2><ol><li><p><em><strong>Machine Learning and Predictive Analysis</strong></em>: You can use supervised learning if you have labeled data, or unsophisticated learning if you don’t, to discover patterns in the data and make predictions about future behavior based on past data. For example, you can try to predict when and where certain behaviors will occur, or predict the outcome of interactions based on their initial conditions.</p></li><li><p><em><strong>Multivariate Behavioral Analysis</strong></em>: Investigate the relationships between different behaviors. For example, does a wing extension by one animal often lead to a similar action by another animal? Or does a particular movement pattern often precede or follow certain interactions? These patterns might not be visible in a univariate analysis of individual behaviors, but may emerge when looking at multiple behaviors together.</p></li><li><p><em><strong>Complex Network Analysis</strong></em>: Go beyond basic social network analysis and use techniques from complex network analysis. For example, you might look at motifs (recurring patterns of interactions), centrality measures (which animals are most central or influential in the network), community structure (groups of animals that interact more with each other than with the rest of the group), etc.</p></li><li><p><em><strong>Spatio-temporal Analysis</strong></em>: Study the behavior of the group as a function of both space and time. For example, do the animals exhibit different behaviors or interactions in different parts of the container? Or at different times?</p></li><li><p><em><strong>Comparative Analysis</strong></em>: If you have data for different groups of animals, you might compare their behaviors. Are there consistent differences between groups, or between the same group at different times?</p></li><li><p><em><strong>Ethological Modeling</strong></em>: Based on your data, you could develop models of animal behavior. These models could be mathematical, computational, or conceptual, and they could help you better understand the principles underlying the behaviors you observe.</p></li><li><p><em><strong>Fractional Order Statistics</strong></em>: This is a newer branch of statistics that can be used to model complex systems, it might be helpful if the data shows heavy-tailed distributions or long-range correlations.</p></li></ol><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Behavior Analysis</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="others" scheme="https://karobben.github.io/categories/Biology/others/"/>
    
    
    <category term="Biology" scheme="https://karobben.github.io/tags/Biology/"/>
    
    <category term="Behavior" scheme="https://karobben.github.io/tags/Behavior/"/>
    
  </entry>
  
  <entry>
    <title>Progress Bar in Python</title>
    <link href="https://karobben.github.io/2023/07/10/Python/progressbar/"/>
    <id>https://karobben.github.io/2023/07/10/Python/progressbar/</id>
    <published>2023-07-10T23:38:28.000Z</published>
    <updated>2023-07-10T23:59:57.273Z</updated>
    
    <content type="html"><![CDATA[<h2 id="tqdm">tqdm</h2><p>The tqdm package in Python provides a fast, extensible progress bar for loops and other iterable objects. It was used in pip intall. Here’s a simple example:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">import</span> time<br><br><span class="hljs-comment"># Create a list of numbers</span><br>numbers = <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>)<br><br><span class="hljs-comment"># Wrap your iterable with tqdm()</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> tqdm(numbers):<br>    <span class="hljs-comment"># Simulate some work</span><br>    time.sleep(<span class="hljs-number">0.01</span>)<br></code></pre></td></tr></table></figure></div><p><img src="https://s1.ax1x.com/2023/07/11/pCRXjDH.png" alt="Progress bar, tqdm"></p><h2 id="rich">rich</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> rich.progress <span class="hljs-keyword">import</span> track<br><span class="hljs-keyword">import</span> time<br><br><span class="hljs-comment"># Create a list of numbers</span><br>numbers = <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>)<br><br><span class="hljs-comment"># Wrap your iterable with track()</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> track(numbers, description=<span class="hljs-string">&quot;Processing...&quot;</span>):<br>    <span class="hljs-comment"># Simulate some work</span><br>    time.sleep(<span class="hljs-number">0.01</span>)<br></code></pre></td></tr></table></figure></div><p><code>track()</code> works similarly to tqdm’s wrapper. It takes an iterable and a description for the task, and returns an iterator that produces the same values as the original, but also updates a progress bar in the console as it iterates over the items.</p><p>The <code>description</code> parameter allows you to set a text description for the task that is displayed next to the progress bar.</p><p>Like tqdm, rich offers a variety of options to customize the appearance and behavior of the progress bar. You can find more details in the rich documentation.<br><img src="https://s1.ax1x.com/2023/07/11/pCRXvbd.png" alt="Progress bar, rich"></p><h2 id="progressbar">progressbar</h2><p>cite: <a href="https://www.geeksforgeeks.org/progress-bars-in-python/">sanjaydokula</a></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> progressbar<br> <br>widgets = [<span class="hljs-string">&#x27; [&#x27;</span>,<br>         progressbar.Timer(<span class="hljs-built_in">format</span>= <span class="hljs-string">&#x27;elapsed time: %(elapsed)s&#x27;</span>),<br>         <span class="hljs-string">&#x27;] &#x27;</span>,<br>           progressbar.Bar(<span class="hljs-string">&#x27;*&#x27;</span>),<span class="hljs-string">&#x27; (&#x27;</span>,<br>           progressbar.ETA(), <span class="hljs-string">&#x27;) &#x27;</span>,<br>          ]<br> <br>bar = progressbar.ProgressBar(max_value=<span class="hljs-number">200</span>,<br>                              widgets=widgets).start()<br> <br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">200</span>):<br>    time.sleep(<span class="hljs-number">0.1</span>)<br>    bar.update(i)<br></code></pre></td></tr></table></figure></div><p><img src="https://s1.ax1x.com/2023/07/11/pCRXzVA.png" alt="Progress bar, progressbar"></p><h2 id="light-progress">light-progress</h2><p>cite: <a href="https://qiita.com/itkr/items/fab6a5e492b28bb07fab">@itkr</a></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> time <span class="hljs-keyword">import</span> sleep<br><span class="hljs-keyword">from</span> light_progress.commandline <span class="hljs-keyword">import</span> ProgressBar<br><br>n = <span class="hljs-number">42</span><br>progress_bar = ProgressBar(n)<br>progress_bar.start()<br><br><span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>    sleep(<span class="hljs-number">0.01</span>)<br>    progress_bar.forward()<br><br>progress_bar.finish()<br></code></pre></td></tr></table></figure></div><p><img src="https://s1.ax1x.com/2023/07/11/pCRjp5t.png" alt="Progress bar, light-progress"></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">from</span> time <span class="hljs-keyword">import</span> sleep<br><span class="hljs-keyword">from</span> light_progress.commandline <span class="hljs-keyword">import</span> ProgressBar<br><br>n = <span class="hljs-number">42</span><br>progress_bar = ProgressBar(n)<br>progress_bar.start()<br><br><span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>    sleep(<span class="hljs-number">0.01</span>)<br>    progress_bar.forward()<br><br>progress_bar.finish()<br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> progressbar<br> <br>widgets = [<span class="hljs-string">&#x27; [&#x27;</span>,<br>         progressbar.Timer(<span class="hljs-built_in">format</span>= <span class="hljs-string">&#x27;elapsed time: %(elapsed)s&#x27;</span>),<br>         <span class="hljs-string">&#x27;] &#x27;</span>,<br>           progressbar.Bar(<span class="hljs-string">&#x27;*&#x27;</span>),<span class="hljs-string">&#x27; (&#x27;</span>,<br>           progressbar.ETA(), <span class="hljs-string">&#x27;) &#x27;</span>,<br>          ]<br> <br>bar = progressbar.ProgressBar(max_value=<span class="hljs-number">20</span>,<br>                              widgets=widgets).start()<br> <br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">20</span>):<br>    time.sleep(<span class="hljs-number">0.1</span>)<br>    bar.update(i)<br><span class="hljs-keyword">from</span> rich.progress <span class="hljs-keyword">import</span> track<br><span class="hljs-keyword">import</span> time<br><br><span class="hljs-comment"># Create a list of numbers</span><br>numbers = <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>)<br><br><span class="hljs-comment"># Wrap your iterable with track()</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> track(numbers, description=<span class="hljs-string">&quot;Processing...&quot;</span>):<br>    <span class="hljs-comment"># Simulate some work</span><br>    time.sleep(<span class="hljs-number">0.01</span>)<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">import</span> time<br><br><span class="hljs-comment"># Create a list of numbers</span><br>numbers = <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>)<br><br><span class="hljs-comment"># Wrap your iterable with tqdm()</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> tqdm(numbers):<br>    <span class="hljs-comment"># Simulate some work</span><br>    time.sleep(<span class="hljs-number">0.01</span>)<br></code></pre></td></tr></table></figure></div><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Progress Bar in Python</summary>
    
    
    
    <category term="Python" scheme="https://karobben.github.io/categories/Python/"/>
    
    <category term="Scripting" scheme="https://karobben.github.io/categories/Python/Scripting/"/>
    
    <category term="Module" scheme="https://karobben.github.io/categories/Python/Scripting/Module/"/>
    
    
    <category term="Python" scheme="https://karobben.github.io/tags/Python/"/>
    
    <category term="Script" scheme="https://karobben.github.io/tags/Script/"/>
    
  </entry>
  
  <entry>
    <title>torch: Start with Deep Learning</title>
    <link href="https://karobben.github.io/2023/07/03/Python/torch-dp/"/>
    <id>https://karobben.github.io/2023/07/03/Python/torch-dp/</id>
    <published>2023-07-04T03:44:14.000Z</published>
    <updated>2023-07-04T05:00:50.334Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Torch-Start-with-Deep-Learning">Torch: Start with Deep Learning</h2><blockquote><p>Mostly from ChatGPT4</p></blockquote><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Net</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>(Net, self).__init__()<br>        self.hidden = nn.Linear(<span class="hljs-number">50</span>, <span class="hljs-number">100</span>)  <span class="hljs-comment"># 隐藏层，接收的输入大小为50，输出的大小为100</span><br>        self.relu = nn.ReLU()  <span class="hljs-comment"># 激活函数</span><br>        self.output = nn.Linear(<span class="hljs-number">100</span>, <span class="hljs-number">2</span>)  <span class="hljs-comment"># 输出层，输出的大小为2，对应两个类别</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        x = self.hidden(x)<br>        x = self.relu(x)<br>        x = self.output(x)<br>        <span class="hljs-keyword">return</span> x<br><br><span class="hljs-comment"># 实例化模型</span><br>model = Net()<br><br><span class="hljs-comment"># 首先，我们定义损失函数和优化器。因为我们假设这是一个二分类问题，所以我们使用交叉熵损失（CrossEntropyLoss）。为了优化模型，我们使用随机梯度下降（SGD）</span><br>criterion = nn.CrossEntropyLoss()<br>optimizer = torch.optim.SGD(model.parameters(), lr=<span class="hljs-number">0.01</span>)<br><br><span class="hljs-comment"># 接下来，我们生成一些假的训练数据。假设我们有100个样本，每个样本是一个50维的向量：</span><br>inputs = torch.randn(<span class="hljs-number">100</span>, <span class="hljs-number">50</span>)<br>labels = torch.randint(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, (<span class="hljs-number">100</span>,))  <span class="hljs-comment"># 随机生成0或1作为标签</span><br><br><span class="hljs-comment"># 然后，我们进行一次前向传播、反向传播和权重更新：</span><br><span class="hljs-comment"># 前向传播</span><br><br><span class="hljs-keyword">for</span> epochs <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):<br>  outputs = model(inputs)<br>  loss = criterion(outputs, labels)<br>  <span class="hljs-comment"># 反向传播和权重更新</span><br>  optimizer.zero_grad()<br>  loss.backward()<br>  optimizer.step()<br>  print(<span class="hljs-string">&#x27;Loss:&#x27;</span>, loss.item())<br><br><span class="hljs-comment"># 这样，你的模型就进行了一次训练。</span><br><span class="hljs-comment"># 要进行预测，你可以直接使用模型对输入进行前向传播：</span><br><br><span class="hljs-comment"># 生成一些假的测试数据</span><br>test_inputs = torch.randn(<span class="hljs-number">5</span>, <span class="hljs-number">50</span>)<br><span class="hljs-comment"># 前向传播</span><br>outputs = model(test_inputs)<br><br><span class="hljs-comment"># 使用softmax函数得到每个类别的概率，并使用argmax得到预测的类别</span><br>_, predicted = torch.<span class="hljs-built_in">max</span>(outputs, <span class="hljs-number">1</span>)<br><br>print(<span class="hljs-string">&#x27;Predicted:&#x27;</span>, predicted)<br></code></pre></td></tr></table></figure></div><h2 id="How-to-use-GPU-for-training">How to use GPU for training</h2><ol><li>首先，检查你的系统是否支持CUDA（即GPU计算）：</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">device = torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br>print(device)  <span class="hljs-comment"># 如果你的系统支持CUDA，应该打印出&#x27;cuda:0&#x27;</span><br></code></pre></td></tr></table></figure></div><ol start="2"><li>然后，将模型转移到GPU：</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">model = Net().to(device)<br></code></pre></td></tr></table></figure></div><ol start="3"><li>然后，将模型转移到GPU：</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>):  <span class="hljs-comment"># 进行2个epoch</span><br><br>    running_loss = <span class="hljs-number">0.0</span><br>    <span class="hljs-keyword">for</span> i, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(trainloader, <span class="hljs-number">0</span>):<br>        inputs, labels = data[<span class="hljs-number">0</span>].to(device), data[<span class="hljs-number">1</span>].to(device)  <span class="hljs-comment"># 转移到GPU</span><br><br>        optimizer.zero_grad()<br><br>        outputs = model(inputs)<br>        loss = criterion(outputs, labels)<br>        loss.backward()<br>        optimizer.step()<br><br>        running_loss += loss.item()<br>        <span class="hljs-keyword">if</span> i % <span class="hljs-number">2000</span> == <span class="hljs-number">1999</span>:    <span class="hljs-comment"># 每2000个batch打印一次平均loss值</span><br>            print(<span class="hljs-string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> %<br>                  (epoch + <span class="hljs-number">1</span>, i + <span class="hljs-number">1</span>, running_loss / <span class="hljs-number">2000</span>))<br>            running_loss = <span class="hljs-number">0.0</span><br>print(<span class="hljs-string">&#x27;Finished Training&#x27;</span>)<br></code></pre></td></tr></table></figure></div><ol start="4"><li>同样，当你进行预测时，也需要确保数据被转移到了GPU：</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">correct = <span class="hljs-number">0</span><br>total = <span class="hljs-number">0</span><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> testloader:<br>        images, labels = data[<span class="hljs-number">0</span>].to(device), data[<span class="hljs-number">1</span>].to(device)  <span class="hljs-comment"># 转移到GPU</span><br>        outputs = model(images)<br>        _, predicted = torch.<span class="hljs-built_in">max</span>(outputs.data, <span class="hljs-number">1</span>)<br>        total += labels.size(<span class="hljs-number">0</span>)<br>        correct += (predicted == labels).<span class="hljs-built_in">sum</span>().item()<br><br>print(<span class="hljs-string">&#x27;Accuracy of the network on the 10000 test images: %d %%&#x27;</span> % (<br>    <span class="hljs-number">100</span> * correct / total))<br></code></pre></td></tr></table></figure></div><h2 id="保存和继续训练">保存和继续训练</h2><ol><li>保存整个模型： <code>torch.save(model, 'model.pth')</code></li><li>只保存模型参数： <code>torch.save(model.state_dict(), 'params.pth')</code></li><li>加载整个模型： <code>model = torch.load('model.pth')</code></li><li>只加载模型参数： <code>model.load_state_dict(torch.load('params.pth'))</code></li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="hljs-number">0.01</span>)  <span class="hljs-comment"># 以随机梯度下降为例</span><br>criterion = torch.nn.CrossEntropyLoss()  <span class="hljs-comment"># 假设是分类问题</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    <span class="hljs-comment"># 清零梯度</span><br>    optimizer.zero_grad()<br>    <span class="hljs-comment"># 前向传播</span><br>    outputs = model(new_data)<br>    <span class="hljs-comment"># 计算损失</span><br>    loss = criterion(outputs, new_labels)<br>    <span class="hljs-comment"># 反向传播</span><br>    loss.backward()<br>    <span class="hljs-comment"># 更新参数</span><br>    optimizer.step()<br></code></pre></td></tr></table></figure></div><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">torch: Start with Deep Learning</summary>
    
    
    
    <category term="Python" scheme="https://karobben.github.io/categories/Python/"/>
    
    <category term="Data" scheme="https://karobben.github.io/categories/Python/Data/"/>
    
    <category term="Machine Learning" scheme="https://karobben.github.io/categories/Python/Data/Machine-Learning/"/>
    
    <category term="Deep Learning" scheme="https://karobben.github.io/categories/Python/Data/Machine-Learning/Deep-Learning/"/>
    
    
    <category term="Machine Learning" scheme="https://karobben.github.io/tags/Machine-Learning/"/>
    
    <category term="torch" scheme="https://karobben.github.io/tags/torch/"/>
    
    <category term="Deep Learning" scheme="https://karobben.github.io/tags/Deep-Learning/"/>
    
    <category term="AI" scheme="https://karobben.github.io/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu linux in Android (aarch64)/No root (proot)</title>
    <link href="https://karobben.github.io/2023/06/15/Linux/ubuntuarm/"/>
    <id>https://karobben.github.io/2023/06/15/Linux/ubuntuarm/</id>
    <published>2023-06-15T19:57:59.000Z</published>
    <updated>2023-06-15T22:12:49.395Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Ubuntu-linux-in-Android-aarch64-No-root-proot">Ubuntu linux in Android (aarch64)/No root (proot)</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">apt update<br>apt upgrade<br></code></pre></td></tr></table></figure></div><h2 id="conda">conda</h2><p><a href="https://ivonblog.com/en-us/posts/android-termux-anaconda/">Ivon’s Blog</a></p><h2 id="R">R</h2><ul><li>R: <code>apt install r-base</code></li><li>radian: <code>pip install radian</code></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r">install.packages(<span class="hljs-string">&#x27;ggplot2&#x27;</span>)<br></code></pre></td></tr></table></figure></div><p><img src="https://s1.ax1x.com/2023/06/16/pCMFSHK.png" alt="ggplot example"></p><h2 id="Python">Python</h2><p>apt install python3.10-venv<br>apt install jupyter-notebook<br>python -m venv base<br>source ~/env-name/bin/activate</p><ul><li>ipython: <code>pip install ipython</code></li><li>tk: <code>sudo apt-get install python3-tk</code></li><li>matplotlib: <code>pip install matplotlib</code></li><li>pandas: <code>pip install pandas</code></li></ul><h2 id="Something-I-installed">Something I installed</h2><ul><li>vim: <code>apt install vim</code></li></ul><p>Permission denied (src/ip_resolver.cpp:542)</p><p>sudo chown -R ken:root ~/.local/share/jupyter</p><p>UserWarning: Unexpected error discovering local network interfaces: [Errno 13] Permission denied</p><p>Permission denied (src/ip_resolver.cpp:542)</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Ubuntu linux in Android (aarch64)/No root (proot)</summary>
    
    
    
    <category term="Linux" scheme="https://karobben.github.io/categories/Linux/"/>
    
    <category term="Ubuntu" scheme="https://karobben.github.io/categories/Linux/Ubuntu/"/>
    
    
    <category term="Linux" scheme="https://karobben.github.io/tags/Linux/"/>
    
    <category term="Android" scheme="https://karobben.github.io/tags/Android/"/>
    
  </entry>
  
  <entry>
    <title>Arch linux in Android (aarch64)/No root (proot)</title>
    <link href="https://karobben.github.io/2023/06/15/Linux/archarm/"/>
    <id>https://karobben.github.io/2023/06/15/Linux/archarm/</id>
    <published>2023-06-15T17:17:02.000Z</published>
    <updated>2023-06-15T19:46:58.571Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Arch-linux-in-Android-phon">Arch linux in Android phon</h2><p>Test host: Samsung Galaxy ultra S23</p><h2 id="How-to-install-Tmoe">How to install: Tmoe</h2><p>Tmoe link: <a href="https://gitee.com/mr_ma_technology/linux">majianwei_private</a></p><h2 id="After-start-with-VNC">After start with VNC</h2><ol><li>install a packages:</li></ol>  <div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo pacman -S cmatrix<br></code></pre></td></tr></table></figure></div><ol start="2"><li>remove the package:</li></ol>  <div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo pacman -R cmatrix<br></code></pre></td></tr></table></figure></div><ol start="3"><li>get the information of the package:</li></ol>  <div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">pacman -Qi cmatrix<br></code></pre></td></tr></table></figure></div><pre>Name            : cmatrixVersion         : 2.0-2Description     : A curses-based scrolling 'Matrix'-like screenArchitecture    : aarch64URL             : https://www.asty.org/cmatrix/Licenses        : GPL3Groups          : NoneProvides        : NoneDepends On      : ncursesOptional Deps   : kbd: cmatrix-tty custom font [installed]                  xterm: cmatrix-tty custom fontRequired By     : NoneOptional For    : NoneConflicts With  : NoneReplaces        : NoneInstalled Size  : 94.74 KiBPackager        : Arch Linux ARM Build System <builder+n1@archlinuxarm.org>Build Date      : Mon 29 Jun 2020 02:47:20 PM CDTInstall Date    : Thu 15 Jun 2023 12:26:30 PM CDTInstall Reason  : Explicitly installedInstall Script  : NoValidated By    : Signature</pre><h2 id="setup-yay">setup yay</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo pacman -S --needed base-devel git<br>git <span class="hljs-built_in">clone</span> https://aur.archlinux.org/yay-git.git<br><span class="hljs-built_in">cd</span> yay-git/<br>makepkg -si<br></code></pre></td></tr></table></figure></div><pre>==> Making package: yay-git 12.0.5.r0.g9641d2a-1 (Thu 15 Jun 2023 12:34:49 PM CDT)==> Checking runtime dependencies...==> Checking buildtime dependencies...==> Installing missing dependencies...resolving dependencies...looking for conflicting packages...Packages (1) go-2:1.20.4-1Total Download Size:    35.71 MiBTotal Installed Size:  192.95 MiB:: Proceed with installation? [Y/n]</pre><p>Just type <code>y</code> and <code>enter</code></p><h2 id="some-software-you-may-like">some software you may like</h2><ul><li>firefox: <code>pacman -S firefox</code></li></ul><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Arch linux in Android (aarch64)/No root (proot)</summary>
    
    
    
    <category term="Linux" scheme="https://karobben.github.io/categories/Linux/"/>
    
    <category term="Arch" scheme="https://karobben.github.io/categories/Linux/Arch/"/>
    
    
    <category term="Linux" scheme="https://karobben.github.io/tags/Linux/"/>
    
    <category term="Android" scheme="https://karobben.github.io/tags/Android/"/>
    
  </entry>
  
  <entry>
    <title>Cython</title>
    <link href="https://karobben.github.io/2023/05/17/Python/cython/"/>
    <id>https://karobben.github.io/2023/05/17/Python/cython/</id>
    <published>2023-05-18T03:34:30.000Z</published>
    <updated>2023-06-06T21:42:32.142Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Cython">Cython</h2><p>Tutorial: <a href="https://cython.readthedocs.io/en/latest/src/tutorial/cython_tutorial.html">cython</a></p><h2 id="Hello-world">Hello world</h2><p>First, write the code in the file <code>helloworld.pyx</code></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">print(<span class="hljs-string">&quot;Hello World&quot;</span>)<br></code></pre></td></tr></table></figure></div><p>Then, write a file <code>setup.py</code> with codes below:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> setuptools <span class="hljs-keyword">import</span> setup<br><span class="hljs-keyword">from</span> Cython.Build <span class="hljs-keyword">import</span> cythonize<br><br>setup(<br>    ext_modules = cythonize(<span class="hljs-string">&quot;helloworld.pyx&quot;</span>)<br>)<br></code></pre></td></tr></table></figure></div><p>Now, let’s setup the Cython in the terminal/cmd</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">python setup.py build_ext --inplace<br></code></pre></td></tr></table></figure></div><pre>Compiling helloworld.pyx because it changed.[1/1] Cythonizing helloworld.pyx/home/ken/.local/lib/python3.8/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /home/ken/test/helloworld.pyx  tree = Parsing.p_module(s, pxd, full_module_name)running build_extbuilding 'helloworld' extensiongcc -pthread -B /mnt/8A26661926660713/Conda/miniconda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /mnt/8A26661926660713/Conda/miniconda/include -fPIC -O2 -isystem /mnt/8A26661926660713/Conda/miniconda/include -fPIC -I/mnt/8A26661926660713/Conda/miniconda/include/python3.8 -c helloworld.c -o build/temp.linux-x86_64-cpython-38/helloworld.ogcc -pthread -B /mnt/8A26661926660713/Conda/miniconda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/mnt/8A26661926660713/Conda/miniconda/lib -Wl,-rpath-link,/mnt/8A26661926660713/Conda/miniconda/lib -L/mnt/8A26661926660713/Conda/miniconda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/mnt/8A26661926660713/Conda/miniconda/lib -Wl,-rpath-link,/mnt/8A26661926660713/Conda/miniconda/lib -L/mnt/8A26661926660713/Conda/miniconda/lib build/temp.linux-x86_64-cpython-38/helloworld.o -o build/lib.linux-x86_64-cpython-38/helloworld.cpython-38-x86_64-linux-gnu.socopying build/lib.linux-x86_64-cpython-38/helloworld.cpython-38-x86_64-linux-gnu.so -> </pre><p>Finally, import it in any python interpreter:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> helloworld<br></code></pre></td></tr></table></figure></div><pre>Hello World</pre><h2 id="Speed-up-the-for-loop">Speed up the for loop</h2><p>First, let’s create a file named <code>example.pyx</code> with the following Cython code:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># example.pyx</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sum_elements</span>(<span class="hljs-params">double[:] array</span>):</span><br>    cdef <span class="hljs-built_in">int</span> i<br>    cdef double result = <span class="hljs-number">0</span><br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(array.shape[<span class="hljs-number">0</span>]):<br>        result += array[i]<br><br>    <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></table></figure></div><p>To compile and use the Cython code, you’ll need a <a href="http://setup.py">setup.py</a> file. Create a <code>setup.py</code> file with the following content:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># setup.py</span><br><span class="hljs-keyword">from</span> setuptools <span class="hljs-keyword">import</span> setup<br><span class="hljs-keyword">from</span> Cython.Build <span class="hljs-keyword">import</span> cythonize<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>setup(<br>    ext_modules=cythonize(<span class="hljs-string">&quot;example.pyx&quot;</span>),<br>    include_dirs=[np.get_include()]<br>)<br></code></pre></td></tr></table></figure></div><p>Next, compile the example.pyx file:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">python setup.py build_ext --inplace<br></code></pre></td></tr></table></figure></div><p>Now, you can test it in the python</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> example <span class="hljs-keyword">import</span> sum_elements<br><br><span class="hljs-comment"># define the same function in python to compare the time consuming</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sum_elements_py</span>(<span class="hljs-params">array</span>):</span><br>  result = <span class="hljs-number">0</span><br>  <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(array.shape[<span class="hljs-number">0</span>]):<br>    result += array[i]<br>  <span class="hljs-keyword">return</span>(result)<br><br><br>array = np.array([<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>, <span class="hljs-number">4.0</span>, <span class="hljs-number">5.0</span>]*<span class="hljs-number">200000</span>, dtype=np.float64)<br><br>A = time.time()<br>sum_elements(array)<br>print(time.time() - A)<br><br>A = time.time()<br>sum_elements_py(array)<br>print(time.time() - A)<br><br><span class="hljs-keyword">from</span> numba <span class="hljs-keyword">import</span> njit<br><br><span class="hljs-meta">@njit</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sum_elements_numba</span>(<span class="hljs-params">array</span>):</span><br>    result = <span class="hljs-number">0.0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(array.shape[<span class="hljs-number">0</span>]):<br>        result += array[i]<br>    <span class="hljs-keyword">return</span> result<br><br></code></pre></td></tr></table></figure></div><pre>0.0013694763183593750.11698126792907715</pre><p>When there are 1M loops, Cython is 85 times faster than python.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">array = np.array([<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>, <span class="hljs-number">4.0</span>, <span class="hljs-number">5.0</span>]*<span class="hljs-number">20000000</span>, dtype=np.float64)<br><br>A = time.time()<br>sum_elements_py(array)<br>print(time.time() - A)<br><br><br>A = time.time()<br>sum_elements(array)<br>print(time.time() - A)<br><br>A = time.time()<br>sum_elements_numba(array)<br>print(time.time() - A)<br></code></pre></td></tr></table></figure></div><pre>13.2185833454132080.118685960769653320.19266653060913086</pre><p>When there are 10000M loops, Cython is 85 times faster than python.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Cython, make python faster!</summary>
    
    
    
    <category term="Python" scheme="https://karobben.github.io/categories/Python/"/>
    
    
    <category term="Python" scheme="https://karobben.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Compare the similar of two images</title>
    <link href="https://karobben.github.io/2023/05/12/Python/opencv-similarity/"/>
    <id>https://karobben.github.io/2023/05/12/Python/opencv-similarity/</id>
    <published>2023-05-12T20:27:11.000Z</published>
    <updated>2023-06-15T17:14:45.867Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Picture-similarities-a">Picture similarities a</h2><p>Image from: <a href="https://cancerci.biomedcentral.com/articles/10.1186/s12935-019-0924-9#auth-Chun_Guang-Shan">© Chun-Guang Shan; 2019</a></p><table><thead><tr><th style="text-align:right"><img src="https://s1.ax1x.com/2023/05/13/p96k8pj.png" alt="Fig. 5E"></th><th style="text-align:left"><img src="https://s1.ax1x.com/2023/05/13/p96k1hQ.png" alt="Fig. 3D"></th></tr></thead><tbody></tbody></table><p>Why this example:</p><ul><li>Youtube: <a href="https://www.youtube.com/watch?v=QKOmaQ8bnO8">736778E78A9F9447776A74287756D7</a></li><li>Twitter: <a href="https://twitter.com/MicrobiomDigest">Elisabeth Bik</a></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br><br>img1 = cv2.imread(<span class="hljs-string">&#x27;1.png&#x27;</span>)<br>img2 = cv2.imread(<span class="hljs-string">&#x27;2.png&#x27;</span>)<br>gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)<br>gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)<br><br><span class="hljs-comment"># Initialize SIFT detector</span><br>sift = cv2.SIFT_create()<br><br><span class="hljs-comment"># Find keypoints and descriptors for both images</span><br>kp1, des1 = sift.detectAndCompute(gray1, <span class="hljs-literal">None</span>)<br>kp2, des2 = sift.detectAndCompute(gray2, <span class="hljs-literal">None</span>)<br><br><span class="hljs-comment"># Initialize brute-force matcher</span><br>bf = cv2.BFMatcher()<br><br><span class="hljs-comment"># Match descriptors from both images</span><br>matches = bf.knnMatch(des1, des2, k=<span class="hljs-number">2</span>)<br><br><span class="hljs-comment"># Apply ratio test to remove false matches</span><br>good_matches = []<br><span class="hljs-keyword">for</span> m, n <span class="hljs-keyword">in</span> matches:<br>    <span class="hljs-keyword">if</span> m.distance &lt; <span class="hljs-number">0.75</span> * n.distance:<br>        good_matches.append(m)<br><br><span class="hljs-comment"># Draw the matched keypoints</span><br>result = cv2.drawMatches(img1, kp1, img2, kp2, good_matches, <span class="hljs-literal">None</span>)<br><br>cv2.imshow(<span class="hljs-string">&quot;video&quot;</span>,result)<br><span class="hljs-keyword">if</span> cv2.waitKey(<span class="hljs-number">0</span>)&amp;<span class="hljs-number">0xFF</span>==<span class="hljs-built_in">ord</span>(<span class="hljs-string">&#x27;q&#x27;</span>):<br>    cv2.destroyAllWindows()<br></code></pre></td></tr></table></figure></div><p><img src="https://s1.ax1x.com/2023/05/13/p96k0NF.png" alt="Similarities between two images"></p><p>From this results, we can find that event though the elements of the images are complicated and the color is transferred, this algorithm could still do an awesome job.</p><p>Here we are using the RootSIFT rather then standard SIFT which requires <code>cv2.xfeatures2d</code> module. What’s the difference between them?</p><blockquote><p>SIFT (Scale-Invariant Feature Transform) is an algorithm used to detect and describe local features in images. It was developed by David Lowe in 1999 and is widely used in computer vision applications, such as image matching, object recognition, and stitching. The key advantages of SIFT are its scale and rotation invariance, as well as its robustness to changes in illumination and viewpoint.</p><p>RootSIFT is an extension of SIFT proposed by Arandjelović and Zisserman in 2012. The main idea behind RootSIFT is to improve the performance of the original SIFT descriptor by applying a simple element-wise square root normalization to the descriptor values. This normalization helps to better differentiate between descriptors and improves matching performance, especially in scenarios where the distribution of descriptor distances is heavily skewed.</p><p>The best scenarios for each method:<br><strong>Standard SIFT</strong>:<br>General-purpose feature detection and description<br>Applications where scale and rotation invariance are required<br>Object recognition, image stitching, and 3D reconstruction<br><strong>RootSIFT</strong>:<br>Improved performance in scenarios with skewed descriptor distance distributions<br>Better differentiation between descriptors for more accurate matching<br>Applications where a more discriminative descriptor is needed</p><p>In summary, RootSIFT is an improvement over standard SIFT in terms of descriptor matching performance. It is especially useful in scenarios where the distribution of descriptor distances is heavily skewed, and a more discriminative descriptor is required. However, for general-purpose feature detection and description, the standard SIFT algorithm is still widely applicable.<br>© ChatGPT4</p></blockquote><h2 id="Similarity-by-machine-learning-model">Similarity by machine learning model</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> keras.preprocessing <span class="hljs-keyword">import</span> image<br><span class="hljs-keyword">from</span> keras.applications.vgg16 <span class="hljs-keyword">import</span> VGG16, preprocess_input<br><span class="hljs-keyword">from</span> sklearn.metrics.pairwise <span class="hljs-keyword">import</span> cosine_similarity<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">load_and_preprocess_image</span>(<span class="hljs-params">image_path</span>):</span><br>    img = image.load_img(image_path, target_size=(<span class="hljs-number">224</span>, <span class="hljs-number">224</span>))<br>    img_array = image.img_to_array(img)<br>    img_array = np.expand_dims(img_array, axis=<span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">return</span> preprocess_input(img_array)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">extract_features</span>(<span class="hljs-params">img_array, model</span>):</span><br>    <span class="hljs-keyword">return</span> model.predict(img_array)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">calculate_similarity</span>(<span class="hljs-params">feature_vector1, feature_vector2</span>):</span><br>    <span class="hljs-keyword">return</span> cosine_similarity(feature_vector1, feature_vector2)<br><br><span class="hljs-comment"># Load the pre-trained VGG16 model</span><br>model = VGG16(weights=<span class="hljs-string">&#x27;imagenet&#x27;</span>, include_top=<span class="hljs-literal">False</span>, pooling=<span class="hljs-string">&#x27;avg&#x27;</span>)<br><br><span class="hljs-comment"># Load and preprocess the images</span><br>image1_path = <span class="hljs-string">&#x27;1.png&#x27;</span><br>image2_path = <span class="hljs-string">&#x27;2.png&#x27;</span><br><br>image1 = load_and_preprocess_image(image1_path)<br>image2 = load_and_preprocess_image(image2_path)<br><br><span class="hljs-comment"># Extract high-level features from both images</span><br>feature_vector1 = extract_features(image1, model)<br>feature_vector2 = extract_features(image2, model)<br><br><span class="hljs-comment"># Calculate the cosine similarity between the feature vectors</span><br>similarity_score = calculate_similarity(feature_vector1, feature_vector2)<br><br>print(<span class="hljs-string">&#x27;Similarity score:&#x27;</span>, similarity_score[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>])<br></code></pre></td></tr></table></figure></div><pre>Similarity score: 0.9361447</pre><h3 id="How-it-work">How it work?</h3><p>It compare the similarities of the images is by using a pre-trained deep learning model <code>VGG16</code> to extract high-level features from both images and then calculate the cosine similarity between these features. Here’s an example of how you can do this using Keras with TensorFlow backend:</p><h4 id="What-is-VGG16-From-ChatGPT4">What is VGG16 (From ChatGPT4)</h4><p>VGG16 is a deep convolutional neural network architecture proposed by the Visual Geometry Group (VGG) at the University of Oxford. It was introduced by Karen Simonyan and Andrew Zisserman in their 2014 paper, “<a href="https://arxiv.org/pdf/1409.1556.pdf">Very Deep Convolutional Networks for Large-Scale Image Recognition</a>” VGG16 contains 16 weight layers, including 13 convolutional layers and 3 fully connected layers. It was trained on the ImageNet dataset, which contains over 14 million images belonging to 1,000 different classes.</p><p>The primary purpose of VGG16 is for image classification, where it has achieved top performance in the ImageNet Large Scale Visual Recognition Challenge (ILSVRC). However, its learned features can also be used for various other tasks, such as object detection, segmentation, and image similarity comparison, as demonstrated in the previous code example.</p><p><strong>Merits of using VGG16 for image similarity comparison:</strong></p><ol><li>Pre-trained models: VGG16 is pre-trained on a large dataset (ImageNet), so it has already learned high-level features that can be useful for a wide range of tasks, including image similarity comparison.</li><li>Transfer learning: Since VGG16 has already learned high-level features, you can use it as a feature extractor for your images without having to train the model from scratch.</li><li>Robustness: VGG16 can extract features that are robust to variations in scale, rotation, and translation, making it suitable for comparing images with different sizes and orientations.</li></ol><p><strong>Disadvantages of using VGG16 for image similarity comparison:</strong></p><ol><li>Computational complexity: VGG16 has a large number of parameters, which can make it computationally expensive to use, especially on devices with limited computational resources. This can be a concern if you need to process a large number of images or require real-time processing.</li><li>Model size: The model size of VGG16 is relatively large (around 528 MB), which can be a concern if you have limited storage or need to deploy the model on edge devices.</li><li>Newer models available: Since the introduction of VGG16, several more advanced architectures have been proposed, such as ResNet, Inception, and EfficientNet, which can achieve better performance with less computational complexity and smaller model sizes.</li></ol><p>In summary, while VGG16 can be used effectively for image similarity comparison, its computational complexity and model size might be a concern for certain applications or devices. In such cases, you may consider using more recent and efficient architectures like ResNet or EfficientNet for feature extraction.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">align_images</span>(<span class="hljs-params">image1, image2</span>):</span><br>    h1, w1, _ = image1.shape<br>    h2, w2, _ = image2.shape<br>    aligned_image = np.zeros((<span class="hljs-built_in">max</span>(h1, h2), w1 + w2, <span class="hljs-number">3</span>), dtype=np.uint8)<br>    aligned_image[:h1, :w1] = image1<br>    aligned_image[:h2, w1:] = image2<br>    <span class="hljs-keyword">return</span> aligned_image<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">draw_matching_lines</span>(<span class="hljs-params">image1, image2, num_matches=<span class="hljs-number">50</span></span>):</span><br>    akaze = cv2.AKAZE_create()<br>    keypoints1, descriptors1 = akaze.detectAndCompute(image1, <span class="hljs-literal">None</span>)<br>    keypoints2, descriptors2 = akaze.detectAndCompute(image2, <span class="hljs-literal">None</span>)<br><br>    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=<span class="hljs-literal">True</span>)<br>    matches = bf.match(descriptors1, descriptors2)<br>    matches = <span class="hljs-built_in">sorted</span>(matches, key=<span class="hljs-keyword">lambda</span> x: x.distance)[:num_matches]<br><br>    aligned_image = align_images(image1, image2)<br><br>    <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> matches:<br>        pt1 = <span class="hljs-built_in">tuple</span>(np.<span class="hljs-built_in">round</span>(keypoints1[m.queryIdx].pt).astype(<span class="hljs-built_in">int</span>))<br>        pt2 = <span class="hljs-built_in">tuple</span>(np.<span class="hljs-built_in">round</span>(keypoints2[m.trainIdx].pt).astype(<span class="hljs-built_in">int</span>))<br>        pt2 = (pt2[<span class="hljs-number">0</span>] + image1.shape[<span class="hljs-number">1</span>], pt2[<span class="hljs-number">1</span>])<br>        cv2.line(aligned_image, pt1, pt2, (<span class="hljs-number">0</span>, <span class="hljs-number">255</span>, <span class="hljs-number">0</span>), <span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">return</span> aligned_image<br><br><span class="hljs-comment"># Load the images</span><br>image1_path = <span class="hljs-string">&#x27;1.png&#x27;</span><br>image2_path = <span class="hljs-string">&#x27;2.png&#x27;</span><br><br>image1 = cv2.imread(image1_path)<br>image2 = cv2.imread(image2_path)<br><br><span class="hljs-comment"># Draw lines between matching keypoints</span><br>aligned_image = draw_matching_lines(image1, image2, num_matches=<span class="hljs-number">50</span>)<br><br><span class="hljs-comment"># Show the aligned images with matching lines</span><br>cv2.imshow(<span class="hljs-string">&#x27;Aligned Images with Similar Regions&#x27;</span>, aligned_image)<br>cv2.waitKey(<span class="hljs-number">0</span>)<br>cv2.destroyAllWindows()<br></code></pre></td></tr></table></figure></div><p>= = I am not quirt accept this results</p><p><img src="https://s1.ax1x.com/2023/05/14/p9cYeyt.png" alt="Image Similarities check "></p><style>pre {  background-color:#38393d;  color: #5fd381;}</style><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> os <br><span class="hljs-keyword">import</span> itertools<br><br>Img_lst = os.listdir(<span class="hljs-string">&#x27;Test&#x27;</span>)<br>pairs = <span class="hljs-built_in">list</span>(itertools.combinations(Img_lst, <span class="hljs-number">2</span>))<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> pairs:<br>  img1 = cv2.imread(<span class="hljs-string">&#x27;Test/&#x27;</span> + i[<span class="hljs-number">0</span>])<br>  img2 = cv2.imread(<span class="hljs-string">&#x27;Test/&#x27;</span> + i[<span class="hljs-number">1</span>])<br>  gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)<br>  gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)<br><br>  <span class="hljs-comment"># Initialize SIFT detector</span><br>  sift = cv2.SIFT_create()<br><br>  <span class="hljs-comment"># Find keypoints and descriptors for both images</span><br>  kp1, des1 = sift.detectAndCompute(gray1, <span class="hljs-literal">None</span>)<br>  kp2, des2 = sift.detectAndCompute(gray2, <span class="hljs-literal">None</span>)<br><br>  <span class="hljs-comment"># Initialize brute-force matcher</span><br>  bf = cv2.BFMatcher()<br><br>  <span class="hljs-comment"># Match descriptors from both images</span><br>  matches = bf.knnMatch(des1, des2, k=<span class="hljs-number">2</span>)<br><br>  <span class="hljs-comment"># Apply ratio test to remove false matches</span><br>  good_matches = []<br>  <span class="hljs-keyword">for</span> m, n <span class="hljs-keyword">in</span> matches:<br>      <span class="hljs-keyword">if</span> m.distance &lt; <span class="hljs-number">0.75</span> * n.distance:<br>          good_matches.append(m)<br><br>  <span class="hljs-comment"># Draw the matched keypoints</span><br>  result = cv2.drawMatches(img1, kp1, img2, kp2, good_matches, <span class="hljs-literal">None</span>)<br><br>  cv2.imwrite(<span class="hljs-string">&quot;Result/&quot;</span> + i[<span class="hljs-number">0</span>] + <span class="hljs-string">&#x27;_&#x27;</span> + i[<span class="hljs-number">1</span>], result)<br></code></pre></td></tr></table></figure></div>]]></content>
    
    
    <summary type="html">Compare the similar of two images</summary>
    
    
    
    <category term="Python" scheme="https://karobben.github.io/categories/Python/"/>
    
    <category term="Data" scheme="https://karobben.github.io/categories/Python/Data/"/>
    
    
    <category term="Python" scheme="https://karobben.github.io/tags/Python/"/>
    
    <category term="Image" scheme="https://karobben.github.io/tags/Image/"/>
    
  </entry>
  
  <entry>
    <title>RNN, Recurrent Neural Network</title>
    <link href="https://karobben.github.io/2023/05/02/Python/rnn/"/>
    <id>https://karobben.github.io/2023/05/02/Python/rnn/</id>
    <published>2023-05-02T15:17:32.000Z</published>
    <updated>2023-06-06T21:42:32.146Z</updated>
    
    <content type="html"><![CDATA[<h2 id="RNN-Recurrent-Neural-Network">RNN, Recurrent Neural Network</h2><blockquote><p>A Recurrent Neural Network (RNN) is a class of artificial neural network that has <strong>memory or feedback loops</strong> that allow it to better recognize <strong>patterns in data</strong>. RNNs are an extension of regular artificial neural networks that add connections <strong>feeding the hidden layers</strong> of the neural network <strong>back into themselves</strong> - these are called recurrent connections. The recurrent connections provide a recurrent network with visibility of not just the current data sample it has been provided, but also it’s previous hidden state. A recurrent network with a feedback loop can be visualized as multiple copies of a neural network, with the output of one serving as an input to the next. Unlike traditional neural networks, recurrent nets use their <strong>understanding of past events</strong> to process the input vector rather than starting from scratch every time.</p><p>A RNN is particularly useful when a <strong>sequence of data</strong> is being processed to make a <strong>classification</strong> decision or <strong>regression</strong> estimate but it can also be used on <strong>non-sequential data</strong>. Recurrent neural networks are typically used to solve tasks related to time series data. Applications of recurrent neural networks include natural language processing, speech recognition, machine translation, character-level language modeling, image classification, image captioning, stock prediction, and financial engineering. We can teach RNNs to learn and understand sequences of words. RNNs can also be used to generate sequences mimicking everything from Shakespeare to Linux source code, to baby names.<br><a href="https://developer.nvidia.com/discover/recurrent-neural-network">© NVDIA</a></p></blockquote><p>Recurrent neural networks have memory to remember important past events, which is essential for successful sequence learning. Regular neural networks have fixed input size, while recurrent networks can handle sequences of any length. They process each element of a sequence one at a time, making them suitable for processing sequential data.</p><h2 id="A-Sample-Example">A Sample Example</h2><p>There is an example from Abid Ali Awan, 2022.<br>The training data is from kaggle <a href="https://www.kaggle.com/datasets/kalilurrahman/mastercard-stock-data-latest-and-updated?resource=download">MasterCard Stock Data</a></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Importing the libraries</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> MinMaxScaler<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error<br><br><span class="hljs-keyword">from</span> tensorflow.keras.models <span class="hljs-keyword">import</span> Sequential<br><span class="hljs-keyword">from</span> tensorflow.keras.layers <span class="hljs-keyword">import</span> Dense, LSTM, Dropout, GRU, Bidirectional<br><span class="hljs-keyword">from</span> tensorflow.keras.optimizers <span class="hljs-keyword">import</span> SGD<br><span class="hljs-keyword">from</span> tensorflow.random <span class="hljs-keyword">import</span> set_seed<br><br>set_seed(<span class="hljs-number">455</span>)<br>np.random.seed(<span class="hljs-number">455</span>)<br><br><span class="hljs-comment"># Read the data</span><br>dataset = pd.read_csv(<br>    <span class="hljs-string">&quot;/home/ken/Downloads//Mastercard_stock_history.csv&quot;</span>, index_col=<span class="hljs-string">&quot;Date&quot;</span>, parse_dates=[<span class="hljs-string">&quot;Date&quot;</span>]<br>).drop([<span class="hljs-string">&quot;Dividends&quot;</span>, <span class="hljs-string">&quot;Stock Splits&quot;</span>], axis=<span class="hljs-number">1</span>)<br>print(dataset.head())<br></code></pre></td></tr></table></figure></div><pre>                Open      High       Low     Close     VolumeDate                                                         2006-05-25  3.748967  4.283869  3.739664  4.279217  3953430002006-05-26  4.307126  4.348058  4.103398  4.179680  1030440002006-05-30  4.183400  4.184330  3.986184  4.093164   498980002006-05-31  4.125723  4.219679  4.125723  4.180608   300020002006-06-01  4.179678  4.474572  4.176887  4.419686   62344000</pre><p>This code is for visualizing the training and testing data. We use the data from the previous year as the training data to predict the data for the last four years.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">tstart = <span class="hljs-number">2016</span><br>tend = <span class="hljs-number">2020</span><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train_test_plot</span>(<span class="hljs-params">dataset, tstart, tend</span>):</span><br>    dataset.loc[<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;tstart&#125;</span>&quot;</span>:<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;tend&#125;</span>&quot;</span>, <span class="hljs-string">&quot;High&quot;</span>].plot(figsize=(<span class="hljs-number">16</span>, <span class="hljs-number">4</span>), legend=<span class="hljs-literal">True</span>)<br>    dataset.loc[<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;tend+<span class="hljs-number">1</span>&#125;</span>&quot;</span>:, <span class="hljs-string">&quot;High&quot;</span>].plot(figsize=(<span class="hljs-number">16</span>, <span class="hljs-number">4</span>), legend=<span class="hljs-literal">True</span>)<br>    plt.legend([<span class="hljs-string">f&quot;Train (Before <span class="hljs-subst">&#123;tend+<span class="hljs-number">1</span>&#125;</span>)&quot;</span>, <span class="hljs-string">f&quot;Test (<span class="hljs-subst">&#123;tend+<span class="hljs-number">1</span>&#125;</span> and beyond)&quot;</span>])<br>    plt.title(<span class="hljs-string">&quot;MasterCard stock price&quot;</span>)<br>    plt.show()<br><br>train_test_plot(dataset,tstart,tend)<br></code></pre></td></tr></table></figure></div><details>    <summary>Detailed explain    </summary><pre><code>The code defines a function `train_test_plot` that takes in a dataset, a start year `tstart`, and an end year `tend`. It plots the `High` column of the dataset for the years between `tstart` and `tend`, and the `High` column of the dataset for the years after `tend+1`.This function is then called with the `dataset`, `tstart`, and `tend` variables that were previously defined from reading in the Mastercard stock history data.The resulting plot shows the trend of the Mastercard stock price for the years before `tend+1` (train data) and the years after `tend+1` (test data). The plot helps to visualize how the dataset is split into training and testing sets for model development and evaluation.</code></pre></details><p><img src="https://res.cloudinary.com/dyd911kmh/image/upload/v1647442110/image5_ryzmps.png" alt=""></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train_test_split</span>(<span class="hljs-params">dataset, tstart, tend</span>):</span><br>    train = dataset.loc[<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;tstart&#125;</span>&quot;</span>:<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;tend&#125;</span>&quot;</span>, <span class="hljs-string">&quot;High&quot;</span>].values<br>    test = dataset.loc[<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;tend+<span class="hljs-number">1</span>&#125;</span>&quot;</span>:, <span class="hljs-string">&quot;High&quot;</span>].values<br>    <span class="hljs-keyword">return</span> train, test<br>training_set, test_set = train_test_split(dataset, tstart, tend)<br>sc = MinMaxScaler(feature_range=(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>))<br>training_set = training_set.reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>training_set_scaled = sc.fit_transform(training_set)<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">split_sequence</span>(<span class="hljs-params">sequence, n_steps</span>):</span><br>    X, y = <span class="hljs-built_in">list</span>(), <span class="hljs-built_in">list</span>()<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(sequence)):<br>        end_ix = i + n_steps<br>        <span class="hljs-keyword">if</span> end_ix &gt; <span class="hljs-built_in">len</span>(sequence) - <span class="hljs-number">1</span>:<br>            <span class="hljs-keyword">break</span><br>        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]<br>        X.append(seq_x)<br>        y.append(seq_y)<br>    <span class="hljs-keyword">return</span> np.array(X), np.array(y)<br><br>n_steps = <span class="hljs-number">60</span><br>features = <span class="hljs-number">1</span><br><span class="hljs-comment"># split into samples</span><br>X_train, y_train = split_sequence(training_set_scaled, n_steps)<br><br><span class="hljs-comment"># Reshaping X_train for model</span><br>X_train = X_train.reshape(X_train.shape[<span class="hljs-number">0</span>],X_train.shape[<span class="hljs-number">1</span>],features)<br></code></pre></td></tr></table></figure></div><details><summary>Detailed explain</summary><p>The code defines several functions to prepare the dataset for training the RNN model.</p><p>The <code>train_test_split</code> function takes in the <code>dataset</code>, <code>tstart</code>, and <code>tend</code> variables and returns the <code>High</code> column values of the dataset for the years between tstart and <code>tend</code> as the training set and the <code>High</code> column values of the dataset for the years after <code>tend+1</code> as the test set.</p><p>The <code>MinMaxScaler</code> function from <code>sklearn.preprocessing</code> is used to scale the <code>training_set</code> values between 0 and 1. Then, the split_sequence function is defined to split the training set into input-output sequences of length <code>n_steps</code>. This function takes in a sequence and the number of time steps to split the sequence into.</p><p>Next, <code>n_steps</code> and <code>features</code> are defined as 60 and 1, respectively. The <code>split_sequence</code> function is then called to split the <code>training_set_scaled</code> into <code>X_train</code> (input sequences) and <code>y_train</code> (output sequences) for the RNN model.</p><p>Finally, <code>X_train</code> is reshaped to a 3D tensor to match the input shape required by the RNN model, with dimensions <code>(number of samples, number of time steps, number of features)</code>. The <code>number of samples</code> is inferred from the input data, <code>number of time steps</code> is set to <code>n_steps</code>, and <code>number of features</code> is set to <code>1</code>.</p></details><p>In this code, we only focus on the “High” column. After splitting the data into <code>training_set</code> and <code>test_set</code> using a predefined function, they are still one-dimensional with lengths of 1259 and 195, respectively. Next, we need to reshape the training set and scale it using MinMaxScaler.</p><p>We then define a number of steps (<code>n_steps</code>) for the input sequence. This is similar to defining a sliding window, with the window size determined by the number of steps. Based on the features of this window, we can predict the information beyond the window.</p><h3 id="LSTM-Model">LSTM Model</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># The LSTM architecture</span><br>model_lstm = Sequential()<br>model_lstm.add(LSTM(units=<span class="hljs-number">125</span>, activation=<span class="hljs-string">&quot;tanh&quot;</span>, input_shape=(n_steps, features)))<br>model_lstm.add(Dense(units=<span class="hljs-number">1</span>))<br><span class="hljs-comment"># Compiling the model</span><br>model_lstm.<span class="hljs-built_in">compile</span>(optimizer=<span class="hljs-string">&quot;RMSprop&quot;</span>, loss=<span class="hljs-string">&quot;mse&quot;</span>)<br><br>model_lstm.summary()<br>model_lstm.fit(X_train, y_train, epochs=<span class="hljs-number">50</span>, batch_size=<span class="hljs-number">32</span>)<br><br>dataset_total = dataset.loc[:,<span class="hljs-string">&quot;High&quot;</span>]<br>inputs = dataset_total[<span class="hljs-built_in">len</span>(dataset_total) - <span class="hljs-built_in">len</span>(test_set) - n_steps :].values<br>inputs = inputs.reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br><span class="hljs-comment">#scaling</span><br>inputs = sc.transform(inputs)<br><br><span class="hljs-comment"># Split into samples</span><br>X_test, y_test = split_sequence(inputs, n_steps)<br><span class="hljs-comment"># reshape</span><br>X_test = X_test.reshape(X_test.shape[<span class="hljs-number">0</span>], X_test.shape[<span class="hljs-number">1</span>], features)<br><span class="hljs-comment">#prediction</span><br>predicted_stock_price = model_lstm.predict(X_test)<br><span class="hljs-comment">#inverse transform the values</span><br>predicted_stock_price = sc.inverse_transform(predicted_stock_price)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_predictions</span>(<span class="hljs-params">test, predicted</span>):</span><br>    plt.plot(test, color=<span class="hljs-string">&quot;gray&quot;</span>, label=<span class="hljs-string">&quot;Real&quot;</span>)<br>    plt.plot(predicted, color=<span class="hljs-string">&quot;red&quot;</span>, label=<span class="hljs-string">&quot;Predicted&quot;</span>)<br>    plt.title(<span class="hljs-string">&quot;MasterCard Stock Price Prediction&quot;</span>)<br>    plt.xlabel(<span class="hljs-string">&quot;Time&quot;</span>)<br>    plt.ylabel(<span class="hljs-string">&quot;MasterCard Stock Price&quot;</span>)<br>    plt.legend()<br>    plt.show()<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">return_rmse</span>(<span class="hljs-params">test, predicted</span>):</span><br>    rmse = np.sqrt(mean_squared_error(test, predicted))<br>    print(<span class="hljs-string">&quot;The root mean squared error is &#123;:.2f&#125;.&quot;</span>.<span class="hljs-built_in">format</span>(rmse))<br><br>plot_predictions(test_set,predicted_stock_price)<br><br>return_rmse(test_set,predicted_stock_price)<br></code></pre></td></tr></table></figure></div><p><img src="https://res.cloudinary.com/dyd911kmh/image/upload/v1647442110/image1_xiar7i.png" alt=""></p><details><summary>Detailed explain</summary><p>The code is building a LSTM (Long Short-Term Memory) neural network model for time-series forecasting.</p><p>First, the code splits the dataset into training and testing sets using a specified time period. It then applies feature scaling to the training set using MinMaxScaler, which scales the data to a range between 0 and 1.</p><p>The function <code>split_sequence</code> is defined to prepare the training data into input-output pairs. Given a sequence of data points, this function divides the data into input sequences (X) of length n_steps and the corresponding output values (y).</p><p>The LSTM model is defined using the <code>Sequential</code> class from Keras. It has one LSTM layer with 125 units and a tanh activation function. The output from the LSTM layer is then passed to a Dense layer with one unit. The model is compiled with the RMSprop optimizer and mean squared error (mse) loss function.</p><p>After defining the model, the training set is used to fit the model for 50 epochs with a batch size of 32.</p><p>Next, the testing set is prepared by selecting the required number of time steps from the end of the dataset, scaling it, and then splitting it into input-output pairs using the same <code>split_sequence</code> function. The input sequence is then reshaped into a 3D format that can be input into the LSTM model. Finally, the model is used to make predictions on the testing set, and the predictions are inverse transformed to get the actual stock prices.</p></details><h3 id="GRU-Model">GRU Model</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">model_gru = Sequential()<br>model_gru.add(GRU(units=<span class="hljs-number">125</span>, activation=<span class="hljs-string">&quot;tanh&quot;</span>, input_shape=(n_steps, features)))<br>model_gru.add(Dense(units=<span class="hljs-number">1</span>))<br><span class="hljs-comment"># Compiling the RNN</span><br>model_gru.<span class="hljs-built_in">compile</span>(optimizer=<span class="hljs-string">&quot;RMSprop&quot;</span>, loss=<span class="hljs-string">&quot;mse&quot;</span>)<br><br>model_gru.summary()<br>model_gru.fit(X_train, y_train, epochs=<span class="hljs-number">50</span>, batch_size=<span class="hljs-number">32</span>)<br>GRU_predicted_stock_price = model_gru.predict(X_test)<br>GRU_predicted_stock_price = sc.inverse_transform(GRU_predicted_stock_price)<br>plot_predictions(test_set, GRU_predicted_stock_price)<br>return_rmse(test_set,GRU_predicted_stock_price)<br></code></pre></td></tr></table></figure></div><p><img src="https://res.cloudinary.com/dyd911kmh/image/upload/v1647442110/image4_quiccx.png" alt=""></p><details><summary>Detailed explain</summary><p>The code is defining and training a GRU (Gated Recurrent Unit) model for predicting stock prices.</p><p>First, the model is defined using the <code>Keras Sequential API</code>. The model has one GRU layer with 125 units and “tanh” activation function, and a Dense output layer with one unit. The model is then compiled using “RMSprop” optimizer and “mse” loss function.</p><p>The model is trained using the training data, <code>X_train</code> and <code>y_train</code>, with 50 epochs and a batch size of 32.</p><p>Then, the model is used to predict the stock prices for the test set using the predict method. The predicted prices are then inverse-transformed using the MinMaxScaler to obtain the actual stock prices.</p><p>Finally, the predicted prices are plotted against the actual prices using the plot_predictions function and the root-mean-square error (RMSE) is computed using the return_rmse function.</details></p><h2 id="RNN-in-Action">RNN in Action</h2><p>Prepair the functions</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">split_sequence</span>(<span class="hljs-params">sequence, n_steps</span>):</span><br>    X, y = <span class="hljs-built_in">list</span>(), <span class="hljs-built_in">list</span>()<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(sequence)):<br>        end_ix = i + n_steps<br>        <span class="hljs-keyword">if</span> end_ix &gt; <span class="hljs-built_in">len</span>(sequence) - <span class="hljs-number">1</span>:<br>            <span class="hljs-keyword">break</span><br>        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]<br>        X.append(seq_x)<br>        y.append(seq_y)<br>    <span class="hljs-keyword">return</span> np.array(X), np.array(y)<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">Data_prepare</span>(<span class="hljs-params">training_set, n_steps = <span class="hljs-number">60</span>, features =<span class="hljs-number">1</span></span>):</span><br>    <span class="hljs-comment">#sc = MinMaxScaler(feature_range=(0, 1))</span><br>    training_set = training_set.reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>    <span class="hljs-comment">#training_set_scaled = sc.fit_transform(training_set)</span><br>    <span class="hljs-comment"># split into samples</span><br>    X_train, y_train = split_sequence(training_set_scaled, n_steps)<br><br>    <span class="hljs-comment"># Reshaping X_train for model</span><br>    X_train = X_train.reshape(X_train.shape[<span class="hljs-number">0</span>],X_train.shape[<span class="hljs-number">1</span>],features)<br>    <span class="hljs-keyword">return</span> X_train, y_train<br></code></pre></td></tr></table></figure></div><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>Data = <span class="hljs-string">&quot;/media/ken/DATA/tracking_test/WT_court10min_ID.csv&quot;</span><br>TB = pd.read_csv(Data, index_col=<span class="hljs-number">0</span>)<br><br><span class="hljs-comment"># select the Fly_8 as an example</span><br><span class="hljs-comment">#for ID in TB.ID.unique()[:12]:</span><br>ID = <span class="hljs-string">&quot;Fly_8&quot;</span><br>training_set_X = TB.X[TB.ID==ID][:<span class="hljs-number">2000</span>].to_numpy()<br>test_set_X = TB.X[TB.ID==ID][<span class="hljs-number">2000</span>:<span class="hljs-number">3000</span>].to_numpy()<br>training_set_Y = TB.Y[TB.ID==ID][:<span class="hljs-number">2000</span>].to_numpy()<br>test_set_Y = TB.Y[TB.ID==ID][<span class="hljs-number">2000</span>:<span class="hljs-number">3000</span>].to_numpy()<br><br>plt.plot(training_set_X, training_set_Y)<br>plt.plot(test_set_X, test_set_Y)<br>plt.show()<br></code></pre></td></tr></table></figure></div><p><img src="https://s1.ax1x.com/2023/05/04/p9Y5vD0.png" alt=""></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">n_steps = <span class="hljs-number">60</span><br>features = <span class="hljs-number">2</span><br><br>training_set = TB[[<span class="hljs-string">&quot;X&quot;</span>, <span class="hljs-string">&quot;Y&quot;</span>]][TB.ID==ID][:<span class="hljs-number">2000</span>].to_numpy()<br>X_train, y_train = split_sequence(training_set, n_steps)<br>X_train = X_train.reshape(X_train.shape[<span class="hljs-number">0</span>],X_train.shape[<span class="hljs-number">1</span>],features)<br><br>test_set = TB[[<span class="hljs-string">&quot;X&quot;</span>, <span class="hljs-string">&quot;Y&quot;</span>]][TB.ID==ID][<span class="hljs-number">2000</span>:<span class="hljs-number">3000</span>].to_numpy()<br>X_test, y_test = split_sequence(test_set, n_steps)<br>X_test = X_test.reshape(X_test.shape[<span class="hljs-number">0</span>],X_test.shape[<span class="hljs-number">1</span>],features)<br><br><br>model_gru = Sequential()<br>model_gru.add(GRU(units=<span class="hljs-number">125</span>, activation=<span class="hljs-string">&quot;tanh&quot;</span>, input_shape=(n_steps, features)))<br>model_gru.add(Dense(units=<span class="hljs-number">2</span>))<br><span class="hljs-comment"># Compiling the RNN</span><br>model_gru.<span class="hljs-built_in">compile</span>(optimizer=<span class="hljs-string">&quot;RMSprop&quot;</span>, loss=<span class="hljs-string">&quot;mse&quot;</span>)<br><br>model_gru.summary()<br>model_gru.fit(X_train, y_train, epochs=<span class="hljs-number">50</span>, batch_size=<span class="hljs-number">32</span>)<br><br>GRU_predicted_stock_price = model_gru.predict(X_test)<br><span class="hljs-comment">#GRU_predicted_stock_price = sc.inverse_transform(GRU_predicted_stock_price)</span><br><br>plt.plot(GRU_predicted_stock_price[:,<span class="hljs-number">0</span>], GRU_predicted_stock_price[:,<span class="hljs-number">1</span>])<br>plt.plot(test_set[:,<span class="hljs-number">0</span>], test_set[:,<span class="hljs-number">1</span>])<br>plt.show()<br><br><br>Predict = []<br>Track = X_train[-<span class="hljs-number">1</span>] <br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>):<br>    Predict += model_gru.predict(np.array([Track])).tolist()<br>    Track = np.concatenate([Track[<span class="hljs-number">1</span>:], [Predict[-<span class="hljs-number">1</span>]]])<br><br>plt.plot(np.array(Predict)[:,<span class="hljs-number">0</span>], np.array(Predict)[:,<span class="hljs-number">1</span>])<br>plt.plot(GRU_predicted_stock_price[:,<span class="hljs-number">0</span>], GRU_predicted_stock_price[:,<span class="hljs-number">1</span>])<br>plt.plot(test_set[:,<span class="hljs-number">0</span>], test_set[:,<span class="hljs-number">1</span>])<br>plt.show()<br><br><br><span class="hljs-comment"># plot for other fly</span><br><br><br><br>test_set = TB[[<span class="hljs-string">&quot;X&quot;</span>, <span class="hljs-string">&quot;Y&quot;</span>]][TB.ID==ID].to_numpy()<br>X_test, y_test = split_sequence(test_set, n_steps)<br>X_test = X_test.reshape(X_test.shape[<span class="hljs-number">0</span>],X_test.shape[<span class="hljs-number">1</span>],features)<br>plt.plot(GRU_predicted_stock_price[:,<span class="hljs-number">0</span>], GRU_predicted_stock_price[:,<span class="hljs-number">1</span>])<br>plt.plot(test_set[:,<span class="hljs-number">0</span>], test_set[:,<span class="hljs-number">1</span>])<br>plt.show()<br><br><br></code></pre></td></tr></table></figure></div><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">RNN, Recurrent Neural Network</summary>
    
    
    
    <category term="Python" scheme="https://karobben.github.io/categories/Python/"/>
    
    <category term="Data" scheme="https://karobben.github.io/categories/Python/Data/"/>
    
    <category term="Machine Learning" scheme="https://karobben.github.io/categories/Python/Data/Machine-Learning/"/>
    
    <category term="RNN" scheme="https://karobben.github.io/categories/Python/Data/Machine-Learning/RNN/"/>
    
    
    <category term="Python" scheme="https://karobben.github.io/tags/Python/"/>
    
    <category term="Machine Learning" scheme="https://karobben.github.io/tags/Machine-Learning/"/>
    
    <category term="Data" scheme="https://karobben.github.io/tags/Data/"/>
    
    <category term="RNN" scheme="https://karobben.github.io/tags/RNN/"/>
    
  </entry>
  
  <entry>
    <title>Wnt signal pathways</title>
    <link href="https://karobben.github.io/2023/03/12/LearnNotes/wnt/"/>
    <id>https://karobben.github.io/2023/03/12/LearnNotes/wnt/</id>
    <published>2023-03-12T17:07:47.000Z</published>
    <updated>2023-06-06T21:42:32.138Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Canonical-Wnt-Signal-Pathway">Canonical Wnt Signal Pathway</h2><table><thead><tr><th style="text-align:center"><img src="https://www.kegg.jp/kegg/pathway/map/map04310.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.kegg.jp/pathway/map04310">© KEGG</a></td></tr></tbody></table><p>Resources:</p><ol><li><a href="https://www.youtube.com/watch?v=EsypBtCI0kU">© Hussain Biology; youtube, 2018</a></li><li><a href="https://www.youtube.com/watch?v=eMgVfwCdRIs">© Catalyst University: youtube, 2019</a></li></ol><h3 id="Without-the-Wnt">Without the Wnt</h3><p>From the KEGG pathway map, we can know that a receptor complex is composed by <em><strong>LRP</strong></em> and <em><strong>frizzled</strong></em>. On the downside of the receptor, there is a degradation complex (grey arear on the map which name is scaffold) which mad by <em><strong>Axin</strong></em>, <em><strong>CKI</strong></em>, <em><strong>GSK3B</strong></em>, and the most important two proteins: <em><strong>$\beta$-catenin</strong></em> and <em><strong>APC</strong></em>. <em><strong>CKI</strong></em> and <em><strong>GSK3B</strong></em> both phosphorylate the <em><strong>$\beta$-catenin</strong></em> and then it was degradation by proteosome. On the other side, which is in the nuclear, protein <em><strong>TCF</strong></em> and <em><strong>LEF</strong></em> formed a complex and bind on the DNA which responsible for transcription of the genes. But  <em><strong>groucho</strong></em> bind with <em><strong>TCF/LEF</strong></em> to prohibit the release of DNA.</p><h3 id="With-the-present-of-Wnt">With the present of Wnt</h3><p>When the receptor complex activated by <em><strong>Wnt</strong></em>, Dishevelled protein (<em><strong>Dvl</strong></em>) and degradation complex are recruited by receptor complex. In this way, the <em><strong>$\beta$-catenin</strong></em> is not ubiquinated and released into the nuclear. Then, <em><strong>$\beta$-catenin</strong></em> releases the <em><strong>groucho</strong></em> and bind with <em><strong>TCF</strong></em> and started to bind the DNA. In this way, wnt signal pathway regulated genes are activated and expressed.</p><h2 id="Abnormal-in-Wnt">Abnormal in Wnt</h2><p>Intestine stem cells is a group of fast poliferation cell because the intestine epithelial cells only last for 4 days. Lost of tha <em><strong>APC</strong></em> could cause the fail of <em><strong>$\beta$-catenin</strong></em> phosphorylation and leading the constant of gene transcription (90% of human colon cancer).</p><p>??</p><p>over-expression of wild-type Wts has relatively little effect on wing growth in wild-type flies, but can suppress the over-growth phenotypes associated with mutation of upstream tumor suppressors that activate Yki<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>Sun, Gongping, and Kenneth D. Irvine. “Regulation of Hippo signaling by Jun kinase signaling during compensatory cell proliferation and regeneration, and in neoplastic tumors.” Developmental biology 350.1 (2011): 139-151. <a href="#fnref1" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">Wnt signal pathways</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Notes/Biology/"/>
    
    <category term="Dme" scheme="https://karobben.github.io/categories/Notes/Biology/Dme/"/>
    
    
    <category term="Biology" scheme="https://karobben.github.io/tags/Biology/"/>
    
  </entry>
  
  <entry>
    <title>DNA Damage</title>
    <link href="https://karobben.github.io/2023/03/12/LearnNotes/Paper-dna-damage/"/>
    <id>https://karobben.github.io/2023/03/12/LearnNotes/Paper-dna-damage/</id>
    <published>2023-03-12T16:32:35.000Z</published>
    <updated>2023-06-06T21:42:32.130Z</updated>
    
    <content type="html"><![CDATA[<h2 id="DNA-Damage">DNA Damage</h2><blockquote><p>DNA is vulnerable to damage resulting from endogenous metabolites, environmental and dietary carcinogens, some anti-inflammatory drugs, and genotoxic cancer therapeutics. Cells respond to DNA damage by activating complex signalling networks that decide cell fate, promoting not only DNA repair and survival but also cell death. The decision between cell survival and death following DNA damage rests on factors that are involved in DNA damage recognition, and DNA repair and damage tolerance, as well as on factors involved in the activation of apoptosis, necrosis, autophagy and senescence. The pathways that dictate cell fate are entwined and have key roles in cancer initiation and progression. Furthermore, they determine the outcome of cancer therapy with genotoxic drugs. Understanding the molecular basis of these pathways is important not only for gaining insight into carcinogenesis, but also in promoting successful cancer therapy. In this Review, we describe key decision-making nodes in the complex interplay between cell survival and death following DNA damage.<br><a href="https://www.nature.com/articles/nrc.2015.2">© Wynand P. Roos; 2016</a></p></blockquote><p>In the event of DNA damage, cells activate DNA repair pathways to facilitate the removal of replication barriers. Conversely, in instances of irreparable DNA damage, cells are prompted to undergo programmed cell death<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>.<br>Reactive oxygen species (<abbr title="Reactive oxygen species">ROS</abbr>), a by-product of regular cellular metabolism, along with various environmental and endogenous genotoxic factors, pose a threat to the stability of DNA and other macromolecules<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>.<br>In response to oxidative DNA damage, cells activate cell cycle checkpoints, leading to the arrest of the cell cycle and cessation of DNA replication. This creates a time window during which DNA repair pathways, such as excision repair, can effectively identify and repair DNA damage induced by oxidative stress. Excision repair is a critical system for repairing oxidative stress-induced DNA damage<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>.</p><table><thead><tr><th style="text-align:center"><img src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fnrc.2015.2/MediaObjects/41568_2016_Article_BFnrc20152_Fig1_HTML.jpg" alt="Cellular consequences of DNA damage"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.nature.com/articles/nrc.2015.2">© Wynand P. Roos; 2016</a></td></tr></tbody></table><p><img src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnrc.2015.2/MediaObjects/41568_2016_Article_BFnrc20152_Fig2_HTML.jpg?as=webp" alt="DNA damage-dependent apoptosis"></p><p>Key damage tolerance mechanisms for cell survival<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup><sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup><sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup>:</p><ul><li>non-homologous end joining (NHEJ)</li><li>homologous recombination (HR), MMR, BER, nucleotide excision repair (NER)</li><li>protein-linked DNA break (PDB) repair in combination with <abbr title="DNA damage response">DDR</abbr> signallin.</li></ul><p>Three immediate-early sensors in the <abbr title="DNA damage response">DDR</abbr> -  PI3K-related kinases (PIKKs)<sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup>:</p><ul><li>ataxia telangiectasia mutated (ATM)<ul><li><em><strong>ATM</strong></em> is frequently mutated in tumours<sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup>, which is accompanied by a gain of therapeutic resistance<sup class="footnote-ref"><a href="#fn9" id="fnref9">[9]</a></sup>.</li><li><em><strong>ATM</strong></em> mutation increased risk of breast cancer<sup class="footnote-ref"><a href="#fn10" id="fnref10">[10]</a></sup> nad colon cancer<sup class="footnote-ref"><a href="#fn11" id="fnref11">[11]</a></sup></li><li>more frequently altered than ATR<sup class="footnote-ref"><a href="#fn12" id="fnref12">[12]</a></sup></li></ul></li><li>ataxia telangiectasia and Rad3-related (ATR)<ul><li>functionally compromised ATR also show malignancy</li></ul></li><li>DNA-dependent protein kinase (DNA-PK)</li></ul><p>ATM and ATR promote cell death in instances of high <abbr title="DNA double-strand break">DSB</abbr> levels<sup class="footnote-ref"><a href="#fn13" id="fnref13">[13]</a></sup></p><table><thead><tr><th style="text-align:center"><img src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fnrc.2015.2/MediaObjects/41568_2016_Article_BFnrc20152_Fig5_HTML.jpg?as=webp" alt="DNA damage-dependent autophagy"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.nature.com/articles/nrc.2015.2">© Wynand P. Roos; 2016</a></td></tr></tbody></table><style>pre {  background-color:#38393d;  color: #5fd381;}</style><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>L.H. Pearl, A.C. Schierz, S.E. Ward, B. Al-Lazikani, F.M. Pearl<br>Therapeutic opportunities within the DNA damage response<br>Nat. Rev. Cancer, 15 (3) (2015), pp. 166-180 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>M. Majidinia, B. Yousefi DNA damage response regulation by MicroRNAs as a therapeutic target in cancer<br>DNA Repair, 47 (2016), pp. 1-11 <a href="#fnref2" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>Davies, Kelvin JA, ed. Oxidative damage &amp; repair: Chemical, biological and medical aspects. Elsevier, 2013. <a href="#fnref3" class="footnote-backref">↩︎</a></p></li><li id="fn4" class="footnote-item"><p>Roos, W. P. et al. The translesion polymerase Rev3L in the tolerance of alkylating anticancer drugs. Mol. Pharmacol. 76, 927–934 (2009). <a href="#fnref4" class="footnote-backref">↩︎</a></p></li><li id="fn5" class="footnote-item"><p>Ashour, M. E., Atteya, R. &amp; El-Khamisy, S. F. Topoisomerase-mediated chromosomal break repair: an emerging player in many games. Nat. Rev. Cancer 15, 137–151 (2015). <a href="#fnref5" class="footnote-backref">↩︎</a></p></li><li id="fn6" class="footnote-item"><p>Stingele, J., Habermann, B. &amp; Jentsch, S. DNA–protein crosslink repair: proteases as DNA repair enzymes. Trends Biochem. Sci. 40, 67–71 (2015). <a href="#fnref6" class="footnote-backref">↩︎</a></p></li><li id="fn7" class="footnote-item"><p>Rogakou, E. P., Pilch, D. R., Orr, A. H., Ivanova, V. S. &amp; Bonner, W. M. DNA double-stranded breaks induce histone H2AX phosphorylation on serine 139. J. Biol. Chem. 273, 5858–5868 (1998) <a href="#fnref7" class="footnote-backref">↩︎</a></p></li><li id="fn8" class="footnote-item"><p>Stankovic, T. et al. ATM mutations in sporadic lymphoid tumours. Leuk. Lymphoma 43, 1563–1571 (2002). <a href="#fnref8" class="footnote-backref">↩︎</a></p></li><li id="fn9" class="footnote-item"><p>Kim, H. et al. Having pancreatic cancer with tumoral loss of ATM and normal TP53 protein expression is associated with a poorer prognosis. Clin. Cancer Res. 20, 1865–1872 (2014). <a href="#fnref9" class="footnote-backref">↩︎</a></p></li><li id="fn10" class="footnote-item"><p>Swift, M., Morrell, D., Massey, R. B. &amp; Chase, C. L. Incidence of cancer in 161 families affected by ataxia-telangiectasia. N. Engl. J. Med. 325, 1831–1836 (1991). <a href="#fnref10" class="footnote-backref">↩︎</a></p></li><li id="fn11" class="footnote-item"><p>Thompson, D. et al. Cancer risks and mortality in heterozygous ATM mutation carriers. J. Natl Cancer Inst. 97, 813–822 (2005). <a href="#fnref11" class="footnote-backref">↩︎</a></p></li><li id="fn12" class="footnote-item"><p>Khanna, K. K. Cancer risk and the ATM gene: a continuing debate. J. Natl Cancer Inst. 92, 795–802 (2000). <a href="#fnref12" class="footnote-backref">↩︎</a></p></li><li id="fn13" class="footnote-item"><p>Pusapati, R. V. et al. ATM promotes apoptosis and suppresses tumorigenesis in response to Myc. Proc. Natl Acad. Sci. USA 103, 1446–1451 (2006). <a href="#fnref13" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">DNA Damage</summary>
    
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/tags/Biology/"/>
    
    <category term="Paper" scheme="https://karobben.github.io/tags/Paper/"/>
    
  </entry>
  
  <entry>
    <title>Image skills for python</title>
    <link href="https://karobben.github.io/2023/03/07/Python/image/"/>
    <id>https://karobben.github.io/2023/03/07/Python/image/</id>
    <published>2023-03-08T02:25:35.000Z</published>
    <updated>2023-06-06T21:42:32.142Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Read-tiff-files">Read tiff files</h2><p><a href="https://biomedicalhub.github.io/python-data/skimage.html">skimage</a></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> skimage.io <span class="hljs-keyword">as</span> skio<br>imstack1    = skio.imread(<span class="hljs-string">&quot;FILENAME.TIF&quot;</span>, plugin=<span class="hljs-string">&quot;tifffile&quot;</span>)<br></code></pre></td></tr></table></figure></div><h2 id="Gaussian-Smoothing">Gaussian Smoothing</h2><p><a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.gaussian_filter.html">scipy</a></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> scipy.ndimage <span class="hljs-keyword">import</span> gaussian_filter<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>a = np.arange(<span class="hljs-number">50</span>, step=<span class="hljs-number">2</span>).reshape((<span class="hljs-number">5</span>,<span class="hljs-number">5</span>))<br>b = gaussian_filter(a, sigma=<span class="hljs-number">3</span>)<br><br>fig, axs = plt.subplots(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>)<br>axs[<span class="hljs-number">0</span>].imshow(a)<br>axs[<span class="hljs-number">1</span>].imshow(b)<br><br>plt.show()<br></code></pre></td></tr></table></figure></div><p><img src="https://s1.ax1x.com/2023/03/08/ppe5dzD.png" alt="Gaussian Smoothing"></p><table><thead><tr><th style="text-align:center"><img src="https://docs.scipy.org/doc/scipy/_images/scipy-ndimage-gaussian_filter-1.png" alt="Gaussian example from scipy"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.gaussian_filter.html">© scipy</a></td></tr></tbody></table><h2 id="Turn-image-to-DataFrame">Turn image to DataFrame</h2><h3 id="Grey-image">Grey image</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-comment"># create a 2D image array</span><br>image_array = np.array([[<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">30</span>], [<span class="hljs-number">40</span>, <span class="hljs-number">50</span>, <span class="hljs-number">60</span>], [<span class="hljs-number">70</span>, <span class="hljs-number">80</span>, <span class="hljs-number">90</span>]])<br><span class="hljs-comment"># convert to pandas dataframe</span><br>df = pd.DataFrame(image_array)<br><span class="hljs-comment"># print dataframe</span><br>print(df)<br></code></pre></td></tr></table></figure></div><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Image skills for python</summary>
    
    
    
    <category term="Python" scheme="https://karobben.github.io/categories/Python/"/>
    
    
    <category term="Python" scheme="https://karobben.github.io/tags/Python/"/>
    
    <category term="Image" scheme="https://karobben.github.io/tags/Image/"/>
    
  </entry>
  
</feed>
