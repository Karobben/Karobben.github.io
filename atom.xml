<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Karobben</title>
  
  <subtitle>Engjoy~</subtitle>
  <link href="https://karobben.github.io/atom.xml" rel="self"/>
  
  <link href="https://karobben.github.io/"/>
  <updated>2023-07-27T07:39:14.617Z</updated>
  <id>https://karobben.github.io/</id>
  
  <author>
    <name>Karobben</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Behavior Analysis</title>
    <link href="https://karobben.github.io/2023/07/27/LearnNotes/behavior-research/"/>
    <id>https://karobben.github.io/2023/07/27/LearnNotes/behavior-research/</id>
    <published>2023-07-27T07:04:09.000Z</published>
    <updated>2023-07-27T07:39:14.617Z</updated>
    
    <content type="html"><![CDATA[<h2 id="What-is-behavior-research">What is behavior research</h2><p>Behavioral research, often referred to as behavior science, is the scientific study of the behavior of human beings and animals. It involves the systematic collection and analysis of data in order to understand and explain how individuals behave in certain situations.</p><p>Behavioral research spans multiple disciplines including psychology, sociology, anthropology, cognitive science, neurology, and even computer science, and it encompasses a variety of specific fields of study, such as behavioral psychology, behavioral economics, and behavioral neuroscience.</p><p>Here are a few reasons why we study behavior:</p><ol><li><p><em><strong>Understand Mechanisms</strong></em>: Understanding the mechanisms that underlie behavior can give us insights into why individuals act the way they do. This can involve studying the brain and nervous system to understand the physiological basis of behavior.</p></li><li><p><em><strong>Predict Behavior</strong></em>: By understanding the factors that influence behavior, researchers can predict how individuals will behave in different circumstances. This has applications in many fields, from marketing (predicting consumer behavior) to public health (predicting adherence to health guidelines).</p></li><li><p><em><strong>Change Behavior</strong></em>: Once we understand and can predict behavior, we can also try to change it. This can involve designing interventions to promote beneficial behaviors or discourage harmful ones.</p></li><li><p><em><strong>Evaluate Interventions</strong></em>: Behavioral research is also used to evaluate the effectiveness of interventions designed to change behavior.</p></li></ol><h2 id="How-to-study-behaviors">How to study behaviors</h2><p>As for how we study behaviors, it often involves the following steps:</p><ol><li><p><em><strong>Observation</strong></em>: The first step is often to observe the behavior in its natural context, in order to get a sense of what is happening and to generate hypotheses.</p></li><li><p><em><strong>Measurement</strong></em>: Researchers then need to find a way to measure the behavior in a systematic and reliable way. This can involve anything from timing a rat in a maze, to counting the number of times a bird performs a specific action, to administering questionnaires to human participants.</p></li><li><p><em><strong>Experimentation</strong></em>: Once the behavior has been measured, researchers can conduct experiments to test their hypotheses. This typically involves manipulating one or more variables and observing the effect on the behavior.</p></li><li><p><em><strong>Analysis</strong></em>: The data collected in the experiment is then analyzed, often using statistical methods, to determine whether the observed effects are statistically significant.</p></li><li><p><em><strong>Interpretation and Publication</strong></em>: The results are then interpreted in light of the original hypotheses, and the study is usually written up and published in a scientific journal, so that other researchers can evaluate and build on the findings.</p></li></ol><p>Overall, behavioral research is a vast field that offers insights into the complexities of behavior and provides a foundation for making predictions and interventions in various sectors of life and society.</p><h2 id="Common-things-we-can-do-with-in-behavior-analysis">Common things we can do with in behavior analysis</h2><ol><li><p><em><strong>Social network analysis</strong></em>: Consider each animal as a node and an interaction as an edge in a network. You can use graph analysis techniques to identify which animals have the most interactions (central nodes), which ones tend to interact with each other (clusters), and whether the pattern of interactions changes over time.</p></li><li><p><em><strong>Behavioral change over time</strong></em>: Analyze the animals’ behaviors (like wing extensions or movement patterns) over time. Look for patterns or triggers for specific behaviors - do they happen more frequently at certain times or after specific interactions?</p></li><li><p><em><strong>Collective behavior</strong></em>: You can look at the group-level behaviors. For example, if the group tends to move together, you can calculate the polarization of the group, which is a measure of how much the animals’ movement directions align with each other. If the group tends to stay together, you can calculate the nearest neighbor distance or the density of the group, which are measures of the group’s cohesion.</p></li><li><p><em><strong>Individual vs. group behavior</strong></em>: Try comparing individual behaviors to the group behavior. Are there certain individuals that often initiate group movements? Are there individuals that often behave differently than the group?</p></li><li><p><em><strong>Correlation between movement and behavior</strong></em>: Investigate if there’s a correlation between the movement of an animal (speed, acceleration, etc.) and its specific behaviors like wing extensions. Does a specific behavior trigger a change in movement or vice versa?</p></li><li><p><em><strong>Response to stimuli</strong></em>: If your data includes any events or stimuli (like changes in the environment or the appearance of food or predators), you can analyze how these affect the animals’ behavior. Do these events trigger specific behaviors or changes in interaction patterns?</p></li></ol><p>To quantify the interactions, you could count the number of interactions each animal has, the frequency of interactions, the average duration of interactions, etc. You could also quantify the result of each interaction - for example, does one animal tend to move away after interacting with another?</p><p>You would need to use statistical methods and possibly machine learning techniques to perform these analyses, depending on the complexity of your data and the questions you’re trying to answer. You might also find it helpful to visualize your data, both to help you understand it and to communicate your results to others.</p><h2 id="Something-more-we-may-can-do">Something more we may can do</h2><ol><li><p><em><strong>Machine Learning and Predictive Analysis</strong></em>: You can use supervised learning if you have labeled data, or unsophisticated learning if you don’t, to discover patterns in the data and make predictions about future behavior based on past data. For example, you can try to predict when and where certain behaviors will occur, or predict the outcome of interactions based on their initial conditions.</p></li><li><p><em><strong>Multivariate Behavioral Analysis</strong></em>: Investigate the relationships between different behaviors. For example, does a wing extension by one animal often lead to a similar action by another animal? Or does a particular movement pattern often precede or follow certain interactions? These patterns might not be visible in a univariate analysis of individual behaviors, but may emerge when looking at multiple behaviors together.</p></li><li><p><em><strong>Complex Network Analysis</strong></em>: Go beyond basic social network analysis and use techniques from complex network analysis. For example, you might look at motifs (recurring patterns of interactions), centrality measures (which animals are most central or influential in the network), community structure (groups of animals that interact more with each other than with the rest of the group), etc.</p></li><li><p><em><strong>Spatio-temporal Analysis</strong></em>: Study the behavior of the group as a function of both space and time. For example, do the animals exhibit different behaviors or interactions in different parts of the container? Or at different times?</p></li><li><p><em><strong>Comparative Analysis</strong></em>: If you have data for different groups of animals, you might compare their behaviors. Are there consistent differences between groups, or between the same group at different times?</p></li><li><p><em><strong>Ethological Modeling</strong></em>: Based on your data, you could develop models of animal behavior. These models could be mathematical, computational, or conceptual, and they could help you better understand the principles underlying the behaviors you observe.</p></li><li><p><em><strong>Fractional Order Statistics</strong></em>: This is a newer branch of statistics that can be used to model complex systems, it might be helpful if the data shows heavy-tailed distributions or long-range correlations.</p></li></ol><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Behavior Analysis</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="others" scheme="https://karobben.github.io/categories/Biology/others/"/>
    
    
    <category term="Biology" scheme="https://karobben.github.io/tags/Biology/"/>
    
    <category term="Behavior" scheme="https://karobben.github.io/tags/Behavior/"/>
    
  </entry>
  
  <entry>
    <title>Progress Bar in Python</title>
    <link href="https://karobben.github.io/2023/07/10/Python/progressbar/"/>
    <id>https://karobben.github.io/2023/07/10/Python/progressbar/</id>
    <published>2023-07-10T23:38:28.000Z</published>
    <updated>2023-07-10T23:59:57.273Z</updated>
    
    <content type="html"><![CDATA[<h2 id="tqdm">tqdm</h2><p>The tqdm package in Python provides a fast, extensible progress bar for loops and other iterable objects. It was used in pip intall. Here’s a simple example:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">import</span> time<br><br><span class="hljs-comment"># Create a list of numbers</span><br>numbers = <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>)<br><br><span class="hljs-comment"># Wrap your iterable with tqdm()</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> tqdm(numbers):<br>    <span class="hljs-comment"># Simulate some work</span><br>    time.sleep(<span class="hljs-number">0.01</span>)<br></code></pre></td></tr></table></figure></div><p><img src="https://s1.ax1x.com/2023/07/11/pCRXjDH.png" alt="Progress bar, tqdm"></p><h2 id="rich">rich</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> rich.progress <span class="hljs-keyword">import</span> track<br><span class="hljs-keyword">import</span> time<br><br><span class="hljs-comment"># Create a list of numbers</span><br>numbers = <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>)<br><br><span class="hljs-comment"># Wrap your iterable with track()</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> track(numbers, description=<span class="hljs-string">&quot;Processing...&quot;</span>):<br>    <span class="hljs-comment"># Simulate some work</span><br>    time.sleep(<span class="hljs-number">0.01</span>)<br></code></pre></td></tr></table></figure></div><p><code>track()</code> works similarly to tqdm’s wrapper. It takes an iterable and a description for the task, and returns an iterator that produces the same values as the original, but also updates a progress bar in the console as it iterates over the items.</p><p>The <code>description</code> parameter allows you to set a text description for the task that is displayed next to the progress bar.</p><p>Like tqdm, rich offers a variety of options to customize the appearance and behavior of the progress bar. You can find more details in the rich documentation.<br><img src="https://s1.ax1x.com/2023/07/11/pCRXvbd.png" alt="Progress bar, rich"></p><h2 id="progressbar">progressbar</h2><p>cite: <a href="https://www.geeksforgeeks.org/progress-bars-in-python/">sanjaydokula</a></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> progressbar<br> <br>widgets = [<span class="hljs-string">&#x27; [&#x27;</span>,<br>         progressbar.Timer(<span class="hljs-built_in">format</span>= <span class="hljs-string">&#x27;elapsed time: %(elapsed)s&#x27;</span>),<br>         <span class="hljs-string">&#x27;] &#x27;</span>,<br>           progressbar.Bar(<span class="hljs-string">&#x27;*&#x27;</span>),<span class="hljs-string">&#x27; (&#x27;</span>,<br>           progressbar.ETA(), <span class="hljs-string">&#x27;) &#x27;</span>,<br>          ]<br> <br>bar = progressbar.ProgressBar(max_value=<span class="hljs-number">200</span>,<br>                              widgets=widgets).start()<br> <br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">200</span>):<br>    time.sleep(<span class="hljs-number">0.1</span>)<br>    bar.update(i)<br></code></pre></td></tr></table></figure></div><p><img src="https://s1.ax1x.com/2023/07/11/pCRXzVA.png" alt="Progress bar, progressbar"></p><h2 id="light-progress">light-progress</h2><p>cite: <a href="https://qiita.com/itkr/items/fab6a5e492b28bb07fab">@itkr</a></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> time <span class="hljs-keyword">import</span> sleep<br><span class="hljs-keyword">from</span> light_progress.commandline <span class="hljs-keyword">import</span> ProgressBar<br><br>n = <span class="hljs-number">42</span><br>progress_bar = ProgressBar(n)<br>progress_bar.start()<br><br><span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>    sleep(<span class="hljs-number">0.01</span>)<br>    progress_bar.forward()<br><br>progress_bar.finish()<br></code></pre></td></tr></table></figure></div><p><img src="https://s1.ax1x.com/2023/07/11/pCRjp5t.png" alt="Progress bar, light-progress"></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">from</span> time <span class="hljs-keyword">import</span> sleep<br><span class="hljs-keyword">from</span> light_progress.commandline <span class="hljs-keyword">import</span> ProgressBar<br><br>n = <span class="hljs-number">42</span><br>progress_bar = ProgressBar(n)<br>progress_bar.start()<br><br><span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>    sleep(<span class="hljs-number">0.01</span>)<br>    progress_bar.forward()<br><br>progress_bar.finish()<br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> progressbar<br> <br>widgets = [<span class="hljs-string">&#x27; [&#x27;</span>,<br>         progressbar.Timer(<span class="hljs-built_in">format</span>= <span class="hljs-string">&#x27;elapsed time: %(elapsed)s&#x27;</span>),<br>         <span class="hljs-string">&#x27;] &#x27;</span>,<br>           progressbar.Bar(<span class="hljs-string">&#x27;*&#x27;</span>),<span class="hljs-string">&#x27; (&#x27;</span>,<br>           progressbar.ETA(), <span class="hljs-string">&#x27;) &#x27;</span>,<br>          ]<br> <br>bar = progressbar.ProgressBar(max_value=<span class="hljs-number">20</span>,<br>                              widgets=widgets).start()<br> <br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">20</span>):<br>    time.sleep(<span class="hljs-number">0.1</span>)<br>    bar.update(i)<br><span class="hljs-keyword">from</span> rich.progress <span class="hljs-keyword">import</span> track<br><span class="hljs-keyword">import</span> time<br><br><span class="hljs-comment"># Create a list of numbers</span><br>numbers = <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>)<br><br><span class="hljs-comment"># Wrap your iterable with track()</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> track(numbers, description=<span class="hljs-string">&quot;Processing...&quot;</span>):<br>    <span class="hljs-comment"># Simulate some work</span><br>    time.sleep(<span class="hljs-number">0.01</span>)<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">import</span> time<br><br><span class="hljs-comment"># Create a list of numbers</span><br>numbers = <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>)<br><br><span class="hljs-comment"># Wrap your iterable with tqdm()</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> tqdm(numbers):<br>    <span class="hljs-comment"># Simulate some work</span><br>    time.sleep(<span class="hljs-number">0.01</span>)<br></code></pre></td></tr></table></figure></div><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Progress Bar in Python</summary>
    
    
    
    <category term="Python" scheme="https://karobben.github.io/categories/Python/"/>
    
    <category term="Scripting" scheme="https://karobben.github.io/categories/Python/Scripting/"/>
    
    <category term="Module" scheme="https://karobben.github.io/categories/Python/Scripting/Module/"/>
    
    
    <category term="Python" scheme="https://karobben.github.io/tags/Python/"/>
    
    <category term="Script" scheme="https://karobben.github.io/tags/Script/"/>
    
  </entry>
  
  <entry>
    <title>torch: Start with Deep Learning</title>
    <link href="https://karobben.github.io/2023/07/03/Python/torch-dp/"/>
    <id>https://karobben.github.io/2023/07/03/Python/torch-dp/</id>
    <published>2023-07-04T03:44:14.000Z</published>
    <updated>2023-07-04T05:00:50.334Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Torch-Start-with-Deep-Learning">Torch: Start with Deep Learning</h2><blockquote><p>Mostly from ChatGPT4</p></blockquote><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Net</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>(Net, self).__init__()<br>        self.hidden = nn.Linear(<span class="hljs-number">50</span>, <span class="hljs-number">100</span>)  <span class="hljs-comment"># 隐藏层，接收的输入大小为50，输出的大小为100</span><br>        self.relu = nn.ReLU()  <span class="hljs-comment"># 激活函数</span><br>        self.output = nn.Linear(<span class="hljs-number">100</span>, <span class="hljs-number">2</span>)  <span class="hljs-comment"># 输出层，输出的大小为2，对应两个类别</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        x = self.hidden(x)<br>        x = self.relu(x)<br>        x = self.output(x)<br>        <span class="hljs-keyword">return</span> x<br><br><span class="hljs-comment"># 实例化模型</span><br>model = Net()<br><br><span class="hljs-comment"># 首先，我们定义损失函数和优化器。因为我们假设这是一个二分类问题，所以我们使用交叉熵损失（CrossEntropyLoss）。为了优化模型，我们使用随机梯度下降（SGD）</span><br>criterion = nn.CrossEntropyLoss()<br>optimizer = torch.optim.SGD(model.parameters(), lr=<span class="hljs-number">0.01</span>)<br><br><span class="hljs-comment"># 接下来，我们生成一些假的训练数据。假设我们有100个样本，每个样本是一个50维的向量：</span><br>inputs = torch.randn(<span class="hljs-number">100</span>, <span class="hljs-number">50</span>)<br>labels = torch.randint(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, (<span class="hljs-number">100</span>,))  <span class="hljs-comment"># 随机生成0或1作为标签</span><br><br><span class="hljs-comment"># 然后，我们进行一次前向传播、反向传播和权重更新：</span><br><span class="hljs-comment"># 前向传播</span><br><br><span class="hljs-keyword">for</span> epochs <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):<br>  outputs = model(inputs)<br>  loss = criterion(outputs, labels)<br>  <span class="hljs-comment"># 反向传播和权重更新</span><br>  optimizer.zero_grad()<br>  loss.backward()<br>  optimizer.step()<br>  print(<span class="hljs-string">&#x27;Loss:&#x27;</span>, loss.item())<br><br><span class="hljs-comment"># 这样，你的模型就进行了一次训练。</span><br><span class="hljs-comment"># 要进行预测，你可以直接使用模型对输入进行前向传播：</span><br><br><span class="hljs-comment"># 生成一些假的测试数据</span><br>test_inputs = torch.randn(<span class="hljs-number">5</span>, <span class="hljs-number">50</span>)<br><span class="hljs-comment"># 前向传播</span><br>outputs = model(test_inputs)<br><br><span class="hljs-comment"># 使用softmax函数得到每个类别的概率，并使用argmax得到预测的类别</span><br>_, predicted = torch.<span class="hljs-built_in">max</span>(outputs, <span class="hljs-number">1</span>)<br><br>print(<span class="hljs-string">&#x27;Predicted:&#x27;</span>, predicted)<br></code></pre></td></tr></table></figure></div><h2 id="How-to-use-GPU-for-training">How to use GPU for training</h2><ol><li>首先，检查你的系统是否支持CUDA（即GPU计算）：</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">device = torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br>print(device)  <span class="hljs-comment"># 如果你的系统支持CUDA，应该打印出&#x27;cuda:0&#x27;</span><br></code></pre></td></tr></table></figure></div><ol start="2"><li>然后，将模型转移到GPU：</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">model = Net().to(device)<br></code></pre></td></tr></table></figure></div><ol start="3"><li>然后，将模型转移到GPU：</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>):  <span class="hljs-comment"># 进行2个epoch</span><br><br>    running_loss = <span class="hljs-number">0.0</span><br>    <span class="hljs-keyword">for</span> i, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(trainloader, <span class="hljs-number">0</span>):<br>        inputs, labels = data[<span class="hljs-number">0</span>].to(device), data[<span class="hljs-number">1</span>].to(device)  <span class="hljs-comment"># 转移到GPU</span><br><br>        optimizer.zero_grad()<br><br>        outputs = model(inputs)<br>        loss = criterion(outputs, labels)<br>        loss.backward()<br>        optimizer.step()<br><br>        running_loss += loss.item()<br>        <span class="hljs-keyword">if</span> i % <span class="hljs-number">2000</span> == <span class="hljs-number">1999</span>:    <span class="hljs-comment"># 每2000个batch打印一次平均loss值</span><br>            print(<span class="hljs-string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> %<br>                  (epoch + <span class="hljs-number">1</span>, i + <span class="hljs-number">1</span>, running_loss / <span class="hljs-number">2000</span>))<br>            running_loss = <span class="hljs-number">0.0</span><br>print(<span class="hljs-string">&#x27;Finished Training&#x27;</span>)<br></code></pre></td></tr></table></figure></div><ol start="4"><li>同样，当你进行预测时，也需要确保数据被转移到了GPU：</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">correct = <span class="hljs-number">0</span><br>total = <span class="hljs-number">0</span><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> testloader:<br>        images, labels = data[<span class="hljs-number">0</span>].to(device), data[<span class="hljs-number">1</span>].to(device)  <span class="hljs-comment"># 转移到GPU</span><br>        outputs = model(images)<br>        _, predicted = torch.<span class="hljs-built_in">max</span>(outputs.data, <span class="hljs-number">1</span>)<br>        total += labels.size(<span class="hljs-number">0</span>)<br>        correct += (predicted == labels).<span class="hljs-built_in">sum</span>().item()<br><br>print(<span class="hljs-string">&#x27;Accuracy of the network on the 10000 test images: %d %%&#x27;</span> % (<br>    <span class="hljs-number">100</span> * correct / total))<br></code></pre></td></tr></table></figure></div><h2 id="保存和继续训练">保存和继续训练</h2><ol><li>保存整个模型： <code>torch.save(model, 'model.pth')</code></li><li>只保存模型参数： <code>torch.save(model.state_dict(), 'params.pth')</code></li><li>加载整个模型： <code>model = torch.load('model.pth')</code></li><li>只加载模型参数： <code>model.load_state_dict(torch.load('params.pth'))</code></li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="hljs-number">0.01</span>)  <span class="hljs-comment"># 以随机梯度下降为例</span><br>criterion = torch.nn.CrossEntropyLoss()  <span class="hljs-comment"># 假设是分类问题</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    <span class="hljs-comment"># 清零梯度</span><br>    optimizer.zero_grad()<br>    <span class="hljs-comment"># 前向传播</span><br>    outputs = model(new_data)<br>    <span class="hljs-comment"># 计算损失</span><br>    loss = criterion(outputs, new_labels)<br>    <span class="hljs-comment"># 反向传播</span><br>    loss.backward()<br>    <span class="hljs-comment"># 更新参数</span><br>    optimizer.step()<br></code></pre></td></tr></table></figure></div><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">torch: Start with Deep Learning</summary>
    
    
    
    <category term="Python" scheme="https://karobben.github.io/categories/Python/"/>
    
    <category term="Data" scheme="https://karobben.github.io/categories/Python/Data/"/>
    
    <category term="Machine Learning" scheme="https://karobben.github.io/categories/Python/Data/Machine-Learning/"/>
    
    <category term="Deep Learning" scheme="https://karobben.github.io/categories/Python/Data/Machine-Learning/Deep-Learning/"/>
    
    
    <category term="Machine Learning" scheme="https://karobben.github.io/tags/Machine-Learning/"/>
    
    <category term="torch" scheme="https://karobben.github.io/tags/torch/"/>
    
    <category term="Deep Learning" scheme="https://karobben.github.io/tags/Deep-Learning/"/>
    
    <category term="AI" scheme="https://karobben.github.io/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu linux in Android (aarch64)/No root (proot)</title>
    <link href="https://karobben.github.io/2023/06/15/Linux/ubuntuarm/"/>
    <id>https://karobben.github.io/2023/06/15/Linux/ubuntuarm/</id>
    <published>2023-06-15T19:57:59.000Z</published>
    <updated>2023-06-15T22:12:49.395Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Ubuntu-linux-in-Android-aarch64-No-root-proot">Ubuntu linux in Android (aarch64)/No root (proot)</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">apt update<br>apt upgrade<br></code></pre></td></tr></table></figure></div><h2 id="conda">conda</h2><p><a href="https://ivonblog.com/en-us/posts/android-termux-anaconda/">Ivon’s Blog</a></p><h2 id="R">R</h2><ul><li>R: <code>apt install r-base</code></li><li>radian: <code>pip install radian</code></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r">install.packages(<span class="hljs-string">&#x27;ggplot2&#x27;</span>)<br></code></pre></td></tr></table></figure></div><p><img src="https://s1.ax1x.com/2023/06/16/pCMFSHK.png" alt="ggplot example"></p><h2 id="Python">Python</h2><p>apt install python3.10-venv<br>apt install jupyter-notebook<br>python -m venv base<br>source ~/env-name/bin/activate</p><ul><li>ipython: <code>pip install ipython</code></li><li>tk: <code>sudo apt-get install python3-tk</code></li><li>matplotlib: <code>pip install matplotlib</code></li><li>pandas: <code>pip install pandas</code></li></ul><h2 id="Something-I-installed">Something I installed</h2><ul><li>vim: <code>apt install vim</code></li></ul><p>Permission denied (src/ip_resolver.cpp:542)</p><p>sudo chown -R ken:root ~/.local/share/jupyter</p><p>UserWarning: Unexpected error discovering local network interfaces: [Errno 13] Permission denied</p><p>Permission denied (src/ip_resolver.cpp:542)</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Ubuntu linux in Android (aarch64)/No root (proot)</summary>
    
    
    
    <category term="Linux" scheme="https://karobben.github.io/categories/Linux/"/>
    
    <category term="Ubuntu" scheme="https://karobben.github.io/categories/Linux/Ubuntu/"/>
    
    
    <category term="Linux" scheme="https://karobben.github.io/tags/Linux/"/>
    
    <category term="Android" scheme="https://karobben.github.io/tags/Android/"/>
    
  </entry>
  
  <entry>
    <title>Arch linux in Android (aarch64)/No root (proot)</title>
    <link href="https://karobben.github.io/2023/06/15/Linux/archarm/"/>
    <id>https://karobben.github.io/2023/06/15/Linux/archarm/</id>
    <published>2023-06-15T17:17:02.000Z</published>
    <updated>2023-06-15T19:46:58.571Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Arch-linux-in-Android-phon">Arch linux in Android phon</h2><p>Test host: Samsung Galaxy ultra S23</p><h2 id="How-to-install-Tmoe">How to install: Tmoe</h2><p>Tmoe link: <a href="https://gitee.com/mr_ma_technology/linux">majianwei_private</a></p><h2 id="After-start-with-VNC">After start with VNC</h2><ol><li>install a packages:</li></ol>  <div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo pacman -S cmatrix<br></code></pre></td></tr></table></figure></div><ol start="2"><li>remove the package:</li></ol>  <div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo pacman -R cmatrix<br></code></pre></td></tr></table></figure></div><ol start="3"><li>get the information of the package:</li></ol>  <div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">pacman -Qi cmatrix<br></code></pre></td></tr></table></figure></div><pre>Name            : cmatrixVersion         : 2.0-2Description     : A curses-based scrolling 'Matrix'-like screenArchitecture    : aarch64URL             : https://www.asty.org/cmatrix/Licenses        : GPL3Groups          : NoneProvides        : NoneDepends On      : ncursesOptional Deps   : kbd: cmatrix-tty custom font [installed]                  xterm: cmatrix-tty custom fontRequired By     : NoneOptional For    : NoneConflicts With  : NoneReplaces        : NoneInstalled Size  : 94.74 KiBPackager        : Arch Linux ARM Build System <builder+n1@archlinuxarm.org>Build Date      : Mon 29 Jun 2020 02:47:20 PM CDTInstall Date    : Thu 15 Jun 2023 12:26:30 PM CDTInstall Reason  : Explicitly installedInstall Script  : NoValidated By    : Signature</pre><h2 id="setup-yay">setup yay</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo pacman -S --needed base-devel git<br>git <span class="hljs-built_in">clone</span> https://aur.archlinux.org/yay-git.git<br><span class="hljs-built_in">cd</span> yay-git/<br>makepkg -si<br></code></pre></td></tr></table></figure></div><pre>==> Making package: yay-git 12.0.5.r0.g9641d2a-1 (Thu 15 Jun 2023 12:34:49 PM CDT)==> Checking runtime dependencies...==> Checking buildtime dependencies...==> Installing missing dependencies...resolving dependencies...looking for conflicting packages...Packages (1) go-2:1.20.4-1Total Download Size:    35.71 MiBTotal Installed Size:  192.95 MiB:: Proceed with installation? [Y/n]</pre><p>Just type <code>y</code> and <code>enter</code></p><h2 id="some-software-you-may-like">some software you may like</h2><ul><li>firefox: <code>pacman -S firefox</code></li></ul><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Arch linux in Android (aarch64)/No root (proot)</summary>
    
    
    
    <category term="Linux" scheme="https://karobben.github.io/categories/Linux/"/>
    
    <category term="Arch" scheme="https://karobben.github.io/categories/Linux/Arch/"/>
    
    
    <category term="Linux" scheme="https://karobben.github.io/tags/Linux/"/>
    
    <category term="Android" scheme="https://karobben.github.io/tags/Android/"/>
    
  </entry>
  
  <entry>
    <title>Cython</title>
    <link href="https://karobben.github.io/2023/05/17/Python/cython/"/>
    <id>https://karobben.github.io/2023/05/17/Python/cython/</id>
    <published>2023-05-18T03:34:30.000Z</published>
    <updated>2023-06-06T21:42:32.142Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Cython">Cython</h2><p>Tutorial: <a href="https://cython.readthedocs.io/en/latest/src/tutorial/cython_tutorial.html">cython</a></p><h2 id="Hello-world">Hello world</h2><p>First, write the code in the file <code>helloworld.pyx</code></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">print(<span class="hljs-string">&quot;Hello World&quot;</span>)<br></code></pre></td></tr></table></figure></div><p>Then, write a file <code>setup.py</code> with codes below:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> setuptools <span class="hljs-keyword">import</span> setup<br><span class="hljs-keyword">from</span> Cython.Build <span class="hljs-keyword">import</span> cythonize<br><br>setup(<br>    ext_modules = cythonize(<span class="hljs-string">&quot;helloworld.pyx&quot;</span>)<br>)<br></code></pre></td></tr></table></figure></div><p>Now, let’s setup the Cython in the terminal/cmd</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">python setup.py build_ext --inplace<br></code></pre></td></tr></table></figure></div><pre>Compiling helloworld.pyx because it changed.[1/1] Cythonizing helloworld.pyx/home/ken/.local/lib/python3.8/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /home/ken/test/helloworld.pyx  tree = Parsing.p_module(s, pxd, full_module_name)running build_extbuilding 'helloworld' extensiongcc -pthread -B /mnt/8A26661926660713/Conda/miniconda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /mnt/8A26661926660713/Conda/miniconda/include -fPIC -O2 -isystem /mnt/8A26661926660713/Conda/miniconda/include -fPIC -I/mnt/8A26661926660713/Conda/miniconda/include/python3.8 -c helloworld.c -o build/temp.linux-x86_64-cpython-38/helloworld.ogcc -pthread -B /mnt/8A26661926660713/Conda/miniconda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/mnt/8A26661926660713/Conda/miniconda/lib -Wl,-rpath-link,/mnt/8A26661926660713/Conda/miniconda/lib -L/mnt/8A26661926660713/Conda/miniconda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/mnt/8A26661926660713/Conda/miniconda/lib -Wl,-rpath-link,/mnt/8A26661926660713/Conda/miniconda/lib -L/mnt/8A26661926660713/Conda/miniconda/lib build/temp.linux-x86_64-cpython-38/helloworld.o -o build/lib.linux-x86_64-cpython-38/helloworld.cpython-38-x86_64-linux-gnu.socopying build/lib.linux-x86_64-cpython-38/helloworld.cpython-38-x86_64-linux-gnu.so -> </pre><p>Finally, import it in any python interpreter:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> helloworld<br></code></pre></td></tr></table></figure></div><pre>Hello World</pre><h2 id="Speed-up-the-for-loop">Speed up the for loop</h2><p>First, let’s create a file named <code>example.pyx</code> with the following Cython code:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># example.pyx</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sum_elements</span>(<span class="hljs-params">double[:] array</span>):</span><br>    cdef <span class="hljs-built_in">int</span> i<br>    cdef double result = <span class="hljs-number">0</span><br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(array.shape[<span class="hljs-number">0</span>]):<br>        result += array[i]<br><br>    <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></table></figure></div><p>To compile and use the Cython code, you’ll need a <a href="http://setup.py">setup.py</a> file. Create a <code>setup.py</code> file with the following content:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># setup.py</span><br><span class="hljs-keyword">from</span> setuptools <span class="hljs-keyword">import</span> setup<br><span class="hljs-keyword">from</span> Cython.Build <span class="hljs-keyword">import</span> cythonize<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>setup(<br>    ext_modules=cythonize(<span class="hljs-string">&quot;example.pyx&quot;</span>),<br>    include_dirs=[np.get_include()]<br>)<br></code></pre></td></tr></table></figure></div><p>Next, compile the example.pyx file:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">python setup.py build_ext --inplace<br></code></pre></td></tr></table></figure></div><p>Now, you can test it in the python</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> example <span class="hljs-keyword">import</span> sum_elements<br><br><span class="hljs-comment"># define the same function in python to compare the time consuming</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sum_elements_py</span>(<span class="hljs-params">array</span>):</span><br>  result = <span class="hljs-number">0</span><br>  <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(array.shape[<span class="hljs-number">0</span>]):<br>    result += array[i]<br>  <span class="hljs-keyword">return</span>(result)<br><br><br>array = np.array([<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>, <span class="hljs-number">4.0</span>, <span class="hljs-number">5.0</span>]*<span class="hljs-number">200000</span>, dtype=np.float64)<br><br>A = time.time()<br>sum_elements(array)<br>print(time.time() - A)<br><br>A = time.time()<br>sum_elements_py(array)<br>print(time.time() - A)<br><br><span class="hljs-keyword">from</span> numba <span class="hljs-keyword">import</span> njit<br><br><span class="hljs-meta">@njit</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sum_elements_numba</span>(<span class="hljs-params">array</span>):</span><br>    result = <span class="hljs-number">0.0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(array.shape[<span class="hljs-number">0</span>]):<br>        result += array[i]<br>    <span class="hljs-keyword">return</span> result<br><br></code></pre></td></tr></table></figure></div><pre>0.0013694763183593750.11698126792907715</pre><p>When there are 1M loops, Cython is 85 times faster than python.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">array = np.array([<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>, <span class="hljs-number">4.0</span>, <span class="hljs-number">5.0</span>]*<span class="hljs-number">20000000</span>, dtype=np.float64)<br><br>A = time.time()<br>sum_elements_py(array)<br>print(time.time() - A)<br><br><br>A = time.time()<br>sum_elements(array)<br>print(time.time() - A)<br><br>A = time.time()<br>sum_elements_numba(array)<br>print(time.time() - A)<br></code></pre></td></tr></table></figure></div><pre>13.2185833454132080.118685960769653320.19266653060913086</pre><p>When there are 10000M loops, Cython is 85 times faster than python.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Cython, make python faster!</summary>
    
    
    
    <category term="Python" scheme="https://karobben.github.io/categories/Python/"/>
    
    
    <category term="Python" scheme="https://karobben.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Compare the similar of two images</title>
    <link href="https://karobben.github.io/2023/05/12/Python/opencv-similarity/"/>
    <id>https://karobben.github.io/2023/05/12/Python/opencv-similarity/</id>
    <published>2023-05-12T20:27:11.000Z</published>
    <updated>2023-06-15T17:14:45.867Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Picture-similarities-a">Picture similarities a</h2><p>Image from: <a href="https://cancerci.biomedcentral.com/articles/10.1186/s12935-019-0924-9#auth-Chun_Guang-Shan">© Chun-Guang Shan; 2019</a></p><table><thead><tr><th style="text-align:right"><img src="https://s1.ax1x.com/2023/05/13/p96k8pj.png" alt="Fig. 5E"></th><th style="text-align:left"><img src="https://s1.ax1x.com/2023/05/13/p96k1hQ.png" alt="Fig. 3D"></th></tr></thead><tbody></tbody></table><p>Why this example:</p><ul><li>Youtube: <a href="https://www.youtube.com/watch?v=QKOmaQ8bnO8">736778E78A9F9447776A74287756D7</a></li><li>Twitter: <a href="https://twitter.com/MicrobiomDigest">Elisabeth Bik</a></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br><br>img1 = cv2.imread(<span class="hljs-string">&#x27;1.png&#x27;</span>)<br>img2 = cv2.imread(<span class="hljs-string">&#x27;2.png&#x27;</span>)<br>gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)<br>gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)<br><br><span class="hljs-comment"># Initialize SIFT detector</span><br>sift = cv2.SIFT_create()<br><br><span class="hljs-comment"># Find keypoints and descriptors for both images</span><br>kp1, des1 = sift.detectAndCompute(gray1, <span class="hljs-literal">None</span>)<br>kp2, des2 = sift.detectAndCompute(gray2, <span class="hljs-literal">None</span>)<br><br><span class="hljs-comment"># Initialize brute-force matcher</span><br>bf = cv2.BFMatcher()<br><br><span class="hljs-comment"># Match descriptors from both images</span><br>matches = bf.knnMatch(des1, des2, k=<span class="hljs-number">2</span>)<br><br><span class="hljs-comment"># Apply ratio test to remove false matches</span><br>good_matches = []<br><span class="hljs-keyword">for</span> m, n <span class="hljs-keyword">in</span> matches:<br>    <span class="hljs-keyword">if</span> m.distance &lt; <span class="hljs-number">0.75</span> * n.distance:<br>        good_matches.append(m)<br><br><span class="hljs-comment"># Draw the matched keypoints</span><br>result = cv2.drawMatches(img1, kp1, img2, kp2, good_matches, <span class="hljs-literal">None</span>)<br><br>cv2.imshow(<span class="hljs-string">&quot;video&quot;</span>,result)<br><span class="hljs-keyword">if</span> cv2.waitKey(<span class="hljs-number">0</span>)&amp;<span class="hljs-number">0xFF</span>==<span class="hljs-built_in">ord</span>(<span class="hljs-string">&#x27;q&#x27;</span>):<br>    cv2.destroyAllWindows()<br></code></pre></td></tr></table></figure></div><p><img src="https://s1.ax1x.com/2023/05/13/p96k0NF.png" alt="Similarities between two images"></p><p>From this results, we can find that event though the elements of the images are complicated and the color is transferred, this algorithm could still do an awesome job.</p><p>Here we are using the RootSIFT rather then standard SIFT which requires <code>cv2.xfeatures2d</code> module. What’s the difference between them?</p><blockquote><p>SIFT (Scale-Invariant Feature Transform) is an algorithm used to detect and describe local features in images. It was developed by David Lowe in 1999 and is widely used in computer vision applications, such as image matching, object recognition, and stitching. The key advantages of SIFT are its scale and rotation invariance, as well as its robustness to changes in illumination and viewpoint.</p><p>RootSIFT is an extension of SIFT proposed by Arandjelović and Zisserman in 2012. The main idea behind RootSIFT is to improve the performance of the original SIFT descriptor by applying a simple element-wise square root normalization to the descriptor values. This normalization helps to better differentiate between descriptors and improves matching performance, especially in scenarios where the distribution of descriptor distances is heavily skewed.</p><p>The best scenarios for each method:<br><strong>Standard SIFT</strong>:<br>General-purpose feature detection and description<br>Applications where scale and rotation invariance are required<br>Object recognition, image stitching, and 3D reconstruction<br><strong>RootSIFT</strong>:<br>Improved performance in scenarios with skewed descriptor distance distributions<br>Better differentiation between descriptors for more accurate matching<br>Applications where a more discriminative descriptor is needed</p><p>In summary, RootSIFT is an improvement over standard SIFT in terms of descriptor matching performance. It is especially useful in scenarios where the distribution of descriptor distances is heavily skewed, and a more discriminative descriptor is required. However, for general-purpose feature detection and description, the standard SIFT algorithm is still widely applicable.<br>© ChatGPT4</p></blockquote><h2 id="Similarity-by-machine-learning-model">Similarity by machine learning model</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> keras.preprocessing <span class="hljs-keyword">import</span> image<br><span class="hljs-keyword">from</span> keras.applications.vgg16 <span class="hljs-keyword">import</span> VGG16, preprocess_input<br><span class="hljs-keyword">from</span> sklearn.metrics.pairwise <span class="hljs-keyword">import</span> cosine_similarity<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">load_and_preprocess_image</span>(<span class="hljs-params">image_path</span>):</span><br>    img = image.load_img(image_path, target_size=(<span class="hljs-number">224</span>, <span class="hljs-number">224</span>))<br>    img_array = image.img_to_array(img)<br>    img_array = np.expand_dims(img_array, axis=<span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">return</span> preprocess_input(img_array)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">extract_features</span>(<span class="hljs-params">img_array, model</span>):</span><br>    <span class="hljs-keyword">return</span> model.predict(img_array)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">calculate_similarity</span>(<span class="hljs-params">feature_vector1, feature_vector2</span>):</span><br>    <span class="hljs-keyword">return</span> cosine_similarity(feature_vector1, feature_vector2)<br><br><span class="hljs-comment"># Load the pre-trained VGG16 model</span><br>model = VGG16(weights=<span class="hljs-string">&#x27;imagenet&#x27;</span>, include_top=<span class="hljs-literal">False</span>, pooling=<span class="hljs-string">&#x27;avg&#x27;</span>)<br><br><span class="hljs-comment"># Load and preprocess the images</span><br>image1_path = <span class="hljs-string">&#x27;1.png&#x27;</span><br>image2_path = <span class="hljs-string">&#x27;2.png&#x27;</span><br><br>image1 = load_and_preprocess_image(image1_path)<br>image2 = load_and_preprocess_image(image2_path)<br><br><span class="hljs-comment"># Extract high-level features from both images</span><br>feature_vector1 = extract_features(image1, model)<br>feature_vector2 = extract_features(image2, model)<br><br><span class="hljs-comment"># Calculate the cosine similarity between the feature vectors</span><br>similarity_score = calculate_similarity(feature_vector1, feature_vector2)<br><br>print(<span class="hljs-string">&#x27;Similarity score:&#x27;</span>, similarity_score[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>])<br></code></pre></td></tr></table></figure></div><pre>Similarity score: 0.9361447</pre><h3 id="How-it-work">How it work?</h3><p>It compare the similarities of the images is by using a pre-trained deep learning model <code>VGG16</code> to extract high-level features from both images and then calculate the cosine similarity between these features. Here’s an example of how you can do this using Keras with TensorFlow backend:</p><h4 id="What-is-VGG16-From-ChatGPT4">What is VGG16 (From ChatGPT4)</h4><p>VGG16 is a deep convolutional neural network architecture proposed by the Visual Geometry Group (VGG) at the University of Oxford. It was introduced by Karen Simonyan and Andrew Zisserman in their 2014 paper, “<a href="https://arxiv.org/pdf/1409.1556.pdf">Very Deep Convolutional Networks for Large-Scale Image Recognition</a>” VGG16 contains 16 weight layers, including 13 convolutional layers and 3 fully connected layers. It was trained on the ImageNet dataset, which contains over 14 million images belonging to 1,000 different classes.</p><p>The primary purpose of VGG16 is for image classification, where it has achieved top performance in the ImageNet Large Scale Visual Recognition Challenge (ILSVRC). However, its learned features can also be used for various other tasks, such as object detection, segmentation, and image similarity comparison, as demonstrated in the previous code example.</p><p><strong>Merits of using VGG16 for image similarity comparison:</strong></p><ol><li>Pre-trained models: VGG16 is pre-trained on a large dataset (ImageNet), so it has already learned high-level features that can be useful for a wide range of tasks, including image similarity comparison.</li><li>Transfer learning: Since VGG16 has already learned high-level features, you can use it as a feature extractor for your images without having to train the model from scratch.</li><li>Robustness: VGG16 can extract features that are robust to variations in scale, rotation, and translation, making it suitable for comparing images with different sizes and orientations.</li></ol><p><strong>Disadvantages of using VGG16 for image similarity comparison:</strong></p><ol><li>Computational complexity: VGG16 has a large number of parameters, which can make it computationally expensive to use, especially on devices with limited computational resources. This can be a concern if you need to process a large number of images or require real-time processing.</li><li>Model size: The model size of VGG16 is relatively large (around 528 MB), which can be a concern if you have limited storage or need to deploy the model on edge devices.</li><li>Newer models available: Since the introduction of VGG16, several more advanced architectures have been proposed, such as ResNet, Inception, and EfficientNet, which can achieve better performance with less computational complexity and smaller model sizes.</li></ol><p>In summary, while VGG16 can be used effectively for image similarity comparison, its computational complexity and model size might be a concern for certain applications or devices. In such cases, you may consider using more recent and efficient architectures like ResNet or EfficientNet for feature extraction.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">align_images</span>(<span class="hljs-params">image1, image2</span>):</span><br>    h1, w1, _ = image1.shape<br>    h2, w2, _ = image2.shape<br>    aligned_image = np.zeros((<span class="hljs-built_in">max</span>(h1, h2), w1 + w2, <span class="hljs-number">3</span>), dtype=np.uint8)<br>    aligned_image[:h1, :w1] = image1<br>    aligned_image[:h2, w1:] = image2<br>    <span class="hljs-keyword">return</span> aligned_image<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">draw_matching_lines</span>(<span class="hljs-params">image1, image2, num_matches=<span class="hljs-number">50</span></span>):</span><br>    akaze = cv2.AKAZE_create()<br>    keypoints1, descriptors1 = akaze.detectAndCompute(image1, <span class="hljs-literal">None</span>)<br>    keypoints2, descriptors2 = akaze.detectAndCompute(image2, <span class="hljs-literal">None</span>)<br><br>    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=<span class="hljs-literal">True</span>)<br>    matches = bf.match(descriptors1, descriptors2)<br>    matches = <span class="hljs-built_in">sorted</span>(matches, key=<span class="hljs-keyword">lambda</span> x: x.distance)[:num_matches]<br><br>    aligned_image = align_images(image1, image2)<br><br>    <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> matches:<br>        pt1 = <span class="hljs-built_in">tuple</span>(np.<span class="hljs-built_in">round</span>(keypoints1[m.queryIdx].pt).astype(<span class="hljs-built_in">int</span>))<br>        pt2 = <span class="hljs-built_in">tuple</span>(np.<span class="hljs-built_in">round</span>(keypoints2[m.trainIdx].pt).astype(<span class="hljs-built_in">int</span>))<br>        pt2 = (pt2[<span class="hljs-number">0</span>] + image1.shape[<span class="hljs-number">1</span>], pt2[<span class="hljs-number">1</span>])<br>        cv2.line(aligned_image, pt1, pt2, (<span class="hljs-number">0</span>, <span class="hljs-number">255</span>, <span class="hljs-number">0</span>), <span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">return</span> aligned_image<br><br><span class="hljs-comment"># Load the images</span><br>image1_path = <span class="hljs-string">&#x27;1.png&#x27;</span><br>image2_path = <span class="hljs-string">&#x27;2.png&#x27;</span><br><br>image1 = cv2.imread(image1_path)<br>image2 = cv2.imread(image2_path)<br><br><span class="hljs-comment"># Draw lines between matching keypoints</span><br>aligned_image = draw_matching_lines(image1, image2, num_matches=<span class="hljs-number">50</span>)<br><br><span class="hljs-comment"># Show the aligned images with matching lines</span><br>cv2.imshow(<span class="hljs-string">&#x27;Aligned Images with Similar Regions&#x27;</span>, aligned_image)<br>cv2.waitKey(<span class="hljs-number">0</span>)<br>cv2.destroyAllWindows()<br></code></pre></td></tr></table></figure></div><p>= = I am not quirt accept this results</p><p><img src="https://s1.ax1x.com/2023/05/14/p9cYeyt.png" alt="Image Similarities check "></p><style>pre {  background-color:#38393d;  color: #5fd381;}</style><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> os <br><span class="hljs-keyword">import</span> itertools<br><br>Img_lst = os.listdir(<span class="hljs-string">&#x27;Test&#x27;</span>)<br>pairs = <span class="hljs-built_in">list</span>(itertools.combinations(Img_lst, <span class="hljs-number">2</span>))<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> pairs:<br>  img1 = cv2.imread(<span class="hljs-string">&#x27;Test/&#x27;</span> + i[<span class="hljs-number">0</span>])<br>  img2 = cv2.imread(<span class="hljs-string">&#x27;Test/&#x27;</span> + i[<span class="hljs-number">1</span>])<br>  gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)<br>  gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)<br><br>  <span class="hljs-comment"># Initialize SIFT detector</span><br>  sift = cv2.SIFT_create()<br><br>  <span class="hljs-comment"># Find keypoints and descriptors for both images</span><br>  kp1, des1 = sift.detectAndCompute(gray1, <span class="hljs-literal">None</span>)<br>  kp2, des2 = sift.detectAndCompute(gray2, <span class="hljs-literal">None</span>)<br><br>  <span class="hljs-comment"># Initialize brute-force matcher</span><br>  bf = cv2.BFMatcher()<br><br>  <span class="hljs-comment"># Match descriptors from both images</span><br>  matches = bf.knnMatch(des1, des2, k=<span class="hljs-number">2</span>)<br><br>  <span class="hljs-comment"># Apply ratio test to remove false matches</span><br>  good_matches = []<br>  <span class="hljs-keyword">for</span> m, n <span class="hljs-keyword">in</span> matches:<br>      <span class="hljs-keyword">if</span> m.distance &lt; <span class="hljs-number">0.75</span> * n.distance:<br>          good_matches.append(m)<br><br>  <span class="hljs-comment"># Draw the matched keypoints</span><br>  result = cv2.drawMatches(img1, kp1, img2, kp2, good_matches, <span class="hljs-literal">None</span>)<br><br>  cv2.imwrite(<span class="hljs-string">&quot;Result/&quot;</span> + i[<span class="hljs-number">0</span>] + <span class="hljs-string">&#x27;_&#x27;</span> + i[<span class="hljs-number">1</span>], result)<br></code></pre></td></tr></table></figure></div>]]></content>
    
    
    <summary type="html">Compare the similar of two images</summary>
    
    
    
    <category term="Python" scheme="https://karobben.github.io/categories/Python/"/>
    
    <category term="Data" scheme="https://karobben.github.io/categories/Python/Data/"/>
    
    
    <category term="Python" scheme="https://karobben.github.io/tags/Python/"/>
    
    <category term="Image" scheme="https://karobben.github.io/tags/Image/"/>
    
  </entry>
  
  <entry>
    <title>RNN, Recurrent Neural Network</title>
    <link href="https://karobben.github.io/2023/05/02/Python/rnn/"/>
    <id>https://karobben.github.io/2023/05/02/Python/rnn/</id>
    <published>2023-05-02T15:17:32.000Z</published>
    <updated>2023-06-06T21:42:32.146Z</updated>
    
    <content type="html"><![CDATA[<h2 id="RNN-Recurrent-Neural-Network">RNN, Recurrent Neural Network</h2><blockquote><p>A Recurrent Neural Network (RNN) is a class of artificial neural network that has <strong>memory or feedback loops</strong> that allow it to better recognize <strong>patterns in data</strong>. RNNs are an extension of regular artificial neural networks that add connections <strong>feeding the hidden layers</strong> of the neural network <strong>back into themselves</strong> - these are called recurrent connections. The recurrent connections provide a recurrent network with visibility of not just the current data sample it has been provided, but also it’s previous hidden state. A recurrent network with a feedback loop can be visualized as multiple copies of a neural network, with the output of one serving as an input to the next. Unlike traditional neural networks, recurrent nets use their <strong>understanding of past events</strong> to process the input vector rather than starting from scratch every time.</p><p>A RNN is particularly useful when a <strong>sequence of data</strong> is being processed to make a <strong>classification</strong> decision or <strong>regression</strong> estimate but it can also be used on <strong>non-sequential data</strong>. Recurrent neural networks are typically used to solve tasks related to time series data. Applications of recurrent neural networks include natural language processing, speech recognition, machine translation, character-level language modeling, image classification, image captioning, stock prediction, and financial engineering. We can teach RNNs to learn and understand sequences of words. RNNs can also be used to generate sequences mimicking everything from Shakespeare to Linux source code, to baby names.<br><a href="https://developer.nvidia.com/discover/recurrent-neural-network">© NVDIA</a></p></blockquote><p>Recurrent neural networks have memory to remember important past events, which is essential for successful sequence learning. Regular neural networks have fixed input size, while recurrent networks can handle sequences of any length. They process each element of a sequence one at a time, making them suitable for processing sequential data.</p><h2 id="A-Sample-Example">A Sample Example</h2><p>There is an example from Abid Ali Awan, 2022.<br>The training data is from kaggle <a href="https://www.kaggle.com/datasets/kalilurrahman/mastercard-stock-data-latest-and-updated?resource=download">MasterCard Stock Data</a></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Importing the libraries</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> MinMaxScaler<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error<br><br><span class="hljs-keyword">from</span> tensorflow.keras.models <span class="hljs-keyword">import</span> Sequential<br><span class="hljs-keyword">from</span> tensorflow.keras.layers <span class="hljs-keyword">import</span> Dense, LSTM, Dropout, GRU, Bidirectional<br><span class="hljs-keyword">from</span> tensorflow.keras.optimizers <span class="hljs-keyword">import</span> SGD<br><span class="hljs-keyword">from</span> tensorflow.random <span class="hljs-keyword">import</span> set_seed<br><br>set_seed(<span class="hljs-number">455</span>)<br>np.random.seed(<span class="hljs-number">455</span>)<br><br><span class="hljs-comment"># Read the data</span><br>dataset = pd.read_csv(<br>    <span class="hljs-string">&quot;/home/ken/Downloads//Mastercard_stock_history.csv&quot;</span>, index_col=<span class="hljs-string">&quot;Date&quot;</span>, parse_dates=[<span class="hljs-string">&quot;Date&quot;</span>]<br>).drop([<span class="hljs-string">&quot;Dividends&quot;</span>, <span class="hljs-string">&quot;Stock Splits&quot;</span>], axis=<span class="hljs-number">1</span>)<br>print(dataset.head())<br></code></pre></td></tr></table></figure></div><pre>                Open      High       Low     Close     VolumeDate                                                         2006-05-25  3.748967  4.283869  3.739664  4.279217  3953430002006-05-26  4.307126  4.348058  4.103398  4.179680  1030440002006-05-30  4.183400  4.184330  3.986184  4.093164   498980002006-05-31  4.125723  4.219679  4.125723  4.180608   300020002006-06-01  4.179678  4.474572  4.176887  4.419686   62344000</pre><p>This code is for visualizing the training and testing data. We use the data from the previous year as the training data to predict the data for the last four years.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">tstart = <span class="hljs-number">2016</span><br>tend = <span class="hljs-number">2020</span><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train_test_plot</span>(<span class="hljs-params">dataset, tstart, tend</span>):</span><br>    dataset.loc[<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;tstart&#125;</span>&quot;</span>:<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;tend&#125;</span>&quot;</span>, <span class="hljs-string">&quot;High&quot;</span>].plot(figsize=(<span class="hljs-number">16</span>, <span class="hljs-number">4</span>), legend=<span class="hljs-literal">True</span>)<br>    dataset.loc[<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;tend+<span class="hljs-number">1</span>&#125;</span>&quot;</span>:, <span class="hljs-string">&quot;High&quot;</span>].plot(figsize=(<span class="hljs-number">16</span>, <span class="hljs-number">4</span>), legend=<span class="hljs-literal">True</span>)<br>    plt.legend([<span class="hljs-string">f&quot;Train (Before <span class="hljs-subst">&#123;tend+<span class="hljs-number">1</span>&#125;</span>)&quot;</span>, <span class="hljs-string">f&quot;Test (<span class="hljs-subst">&#123;tend+<span class="hljs-number">1</span>&#125;</span> and beyond)&quot;</span>])<br>    plt.title(<span class="hljs-string">&quot;MasterCard stock price&quot;</span>)<br>    plt.show()<br><br>train_test_plot(dataset,tstart,tend)<br></code></pre></td></tr></table></figure></div><details>    <summary>Detailed explain    </summary><pre><code>The code defines a function `train_test_plot` that takes in a dataset, a start year `tstart`, and an end year `tend`. It plots the `High` column of the dataset for the years between `tstart` and `tend`, and the `High` column of the dataset for the years after `tend+1`.This function is then called with the `dataset`, `tstart`, and `tend` variables that were previously defined from reading in the Mastercard stock history data.The resulting plot shows the trend of the Mastercard stock price for the years before `tend+1` (train data) and the years after `tend+1` (test data). The plot helps to visualize how the dataset is split into training and testing sets for model development and evaluation.</code></pre></details><p><img src="https://res.cloudinary.com/dyd911kmh/image/upload/v1647442110/image5_ryzmps.png" alt=""></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train_test_split</span>(<span class="hljs-params">dataset, tstart, tend</span>):</span><br>    train = dataset.loc[<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;tstart&#125;</span>&quot;</span>:<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;tend&#125;</span>&quot;</span>, <span class="hljs-string">&quot;High&quot;</span>].values<br>    test = dataset.loc[<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;tend+<span class="hljs-number">1</span>&#125;</span>&quot;</span>:, <span class="hljs-string">&quot;High&quot;</span>].values<br>    <span class="hljs-keyword">return</span> train, test<br>training_set, test_set = train_test_split(dataset, tstart, tend)<br>sc = MinMaxScaler(feature_range=(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>))<br>training_set = training_set.reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>training_set_scaled = sc.fit_transform(training_set)<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">split_sequence</span>(<span class="hljs-params">sequence, n_steps</span>):</span><br>    X, y = <span class="hljs-built_in">list</span>(), <span class="hljs-built_in">list</span>()<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(sequence)):<br>        end_ix = i + n_steps<br>        <span class="hljs-keyword">if</span> end_ix &gt; <span class="hljs-built_in">len</span>(sequence) - <span class="hljs-number">1</span>:<br>            <span class="hljs-keyword">break</span><br>        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]<br>        X.append(seq_x)<br>        y.append(seq_y)<br>    <span class="hljs-keyword">return</span> np.array(X), np.array(y)<br><br>n_steps = <span class="hljs-number">60</span><br>features = <span class="hljs-number">1</span><br><span class="hljs-comment"># split into samples</span><br>X_train, y_train = split_sequence(training_set_scaled, n_steps)<br><br><span class="hljs-comment"># Reshaping X_train for model</span><br>X_train = X_train.reshape(X_train.shape[<span class="hljs-number">0</span>],X_train.shape[<span class="hljs-number">1</span>],features)<br></code></pre></td></tr></table></figure></div><details><summary>Detailed explain</summary><p>The code defines several functions to prepare the dataset for training the RNN model.</p><p>The <code>train_test_split</code> function takes in the <code>dataset</code>, <code>tstart</code>, and <code>tend</code> variables and returns the <code>High</code> column values of the dataset for the years between tstart and <code>tend</code> as the training set and the <code>High</code> column values of the dataset for the years after <code>tend+1</code> as the test set.</p><p>The <code>MinMaxScaler</code> function from <code>sklearn.preprocessing</code> is used to scale the <code>training_set</code> values between 0 and 1. Then, the split_sequence function is defined to split the training set into input-output sequences of length <code>n_steps</code>. This function takes in a sequence and the number of time steps to split the sequence into.</p><p>Next, <code>n_steps</code> and <code>features</code> are defined as 60 and 1, respectively. The <code>split_sequence</code> function is then called to split the <code>training_set_scaled</code> into <code>X_train</code> (input sequences) and <code>y_train</code> (output sequences) for the RNN model.</p><p>Finally, <code>X_train</code> is reshaped to a 3D tensor to match the input shape required by the RNN model, with dimensions <code>(number of samples, number of time steps, number of features)</code>. The <code>number of samples</code> is inferred from the input data, <code>number of time steps</code> is set to <code>n_steps</code>, and <code>number of features</code> is set to <code>1</code>.</p></details><p>In this code, we only focus on the “High” column. After splitting the data into <code>training_set</code> and <code>test_set</code> using a predefined function, they are still one-dimensional with lengths of 1259 and 195, respectively. Next, we need to reshape the training set and scale it using MinMaxScaler.</p><p>We then define a number of steps (<code>n_steps</code>) for the input sequence. This is similar to defining a sliding window, with the window size determined by the number of steps. Based on the features of this window, we can predict the information beyond the window.</p><h3 id="LSTM-Model">LSTM Model</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># The LSTM architecture</span><br>model_lstm = Sequential()<br>model_lstm.add(LSTM(units=<span class="hljs-number">125</span>, activation=<span class="hljs-string">&quot;tanh&quot;</span>, input_shape=(n_steps, features)))<br>model_lstm.add(Dense(units=<span class="hljs-number">1</span>))<br><span class="hljs-comment"># Compiling the model</span><br>model_lstm.<span class="hljs-built_in">compile</span>(optimizer=<span class="hljs-string">&quot;RMSprop&quot;</span>, loss=<span class="hljs-string">&quot;mse&quot;</span>)<br><br>model_lstm.summary()<br>model_lstm.fit(X_train, y_train, epochs=<span class="hljs-number">50</span>, batch_size=<span class="hljs-number">32</span>)<br><br>dataset_total = dataset.loc[:,<span class="hljs-string">&quot;High&quot;</span>]<br>inputs = dataset_total[<span class="hljs-built_in">len</span>(dataset_total) - <span class="hljs-built_in">len</span>(test_set) - n_steps :].values<br>inputs = inputs.reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br><span class="hljs-comment">#scaling</span><br>inputs = sc.transform(inputs)<br><br><span class="hljs-comment"># Split into samples</span><br>X_test, y_test = split_sequence(inputs, n_steps)<br><span class="hljs-comment"># reshape</span><br>X_test = X_test.reshape(X_test.shape[<span class="hljs-number">0</span>], X_test.shape[<span class="hljs-number">1</span>], features)<br><span class="hljs-comment">#prediction</span><br>predicted_stock_price = model_lstm.predict(X_test)<br><span class="hljs-comment">#inverse transform the values</span><br>predicted_stock_price = sc.inverse_transform(predicted_stock_price)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_predictions</span>(<span class="hljs-params">test, predicted</span>):</span><br>    plt.plot(test, color=<span class="hljs-string">&quot;gray&quot;</span>, label=<span class="hljs-string">&quot;Real&quot;</span>)<br>    plt.plot(predicted, color=<span class="hljs-string">&quot;red&quot;</span>, label=<span class="hljs-string">&quot;Predicted&quot;</span>)<br>    plt.title(<span class="hljs-string">&quot;MasterCard Stock Price Prediction&quot;</span>)<br>    plt.xlabel(<span class="hljs-string">&quot;Time&quot;</span>)<br>    plt.ylabel(<span class="hljs-string">&quot;MasterCard Stock Price&quot;</span>)<br>    plt.legend()<br>    plt.show()<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">return_rmse</span>(<span class="hljs-params">test, predicted</span>):</span><br>    rmse = np.sqrt(mean_squared_error(test, predicted))<br>    print(<span class="hljs-string">&quot;The root mean squared error is &#123;:.2f&#125;.&quot;</span>.<span class="hljs-built_in">format</span>(rmse))<br><br>plot_predictions(test_set,predicted_stock_price)<br><br>return_rmse(test_set,predicted_stock_price)<br></code></pre></td></tr></table></figure></div><p><img src="https://res.cloudinary.com/dyd911kmh/image/upload/v1647442110/image1_xiar7i.png" alt=""></p><details><summary>Detailed explain</summary><p>The code is building a LSTM (Long Short-Term Memory) neural network model for time-series forecasting.</p><p>First, the code splits the dataset into training and testing sets using a specified time period. It then applies feature scaling to the training set using MinMaxScaler, which scales the data to a range between 0 and 1.</p><p>The function <code>split_sequence</code> is defined to prepare the training data into input-output pairs. Given a sequence of data points, this function divides the data into input sequences (X) of length n_steps and the corresponding output values (y).</p><p>The LSTM model is defined using the <code>Sequential</code> class from Keras. It has one LSTM layer with 125 units and a tanh activation function. The output from the LSTM layer is then passed to a Dense layer with one unit. The model is compiled with the RMSprop optimizer and mean squared error (mse) loss function.</p><p>After defining the model, the training set is used to fit the model for 50 epochs with a batch size of 32.</p><p>Next, the testing set is prepared by selecting the required number of time steps from the end of the dataset, scaling it, and then splitting it into input-output pairs using the same <code>split_sequence</code> function. The input sequence is then reshaped into a 3D format that can be input into the LSTM model. Finally, the model is used to make predictions on the testing set, and the predictions are inverse transformed to get the actual stock prices.</p></details><h3 id="GRU-Model">GRU Model</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">model_gru = Sequential()<br>model_gru.add(GRU(units=<span class="hljs-number">125</span>, activation=<span class="hljs-string">&quot;tanh&quot;</span>, input_shape=(n_steps, features)))<br>model_gru.add(Dense(units=<span class="hljs-number">1</span>))<br><span class="hljs-comment"># Compiling the RNN</span><br>model_gru.<span class="hljs-built_in">compile</span>(optimizer=<span class="hljs-string">&quot;RMSprop&quot;</span>, loss=<span class="hljs-string">&quot;mse&quot;</span>)<br><br>model_gru.summary()<br>model_gru.fit(X_train, y_train, epochs=<span class="hljs-number">50</span>, batch_size=<span class="hljs-number">32</span>)<br>GRU_predicted_stock_price = model_gru.predict(X_test)<br>GRU_predicted_stock_price = sc.inverse_transform(GRU_predicted_stock_price)<br>plot_predictions(test_set, GRU_predicted_stock_price)<br>return_rmse(test_set,GRU_predicted_stock_price)<br></code></pre></td></tr></table></figure></div><p><img src="https://res.cloudinary.com/dyd911kmh/image/upload/v1647442110/image4_quiccx.png" alt=""></p><details><summary>Detailed explain</summary><p>The code is defining and training a GRU (Gated Recurrent Unit) model for predicting stock prices.</p><p>First, the model is defined using the <code>Keras Sequential API</code>. The model has one GRU layer with 125 units and “tanh” activation function, and a Dense output layer with one unit. The model is then compiled using “RMSprop” optimizer and “mse” loss function.</p><p>The model is trained using the training data, <code>X_train</code> and <code>y_train</code>, with 50 epochs and a batch size of 32.</p><p>Then, the model is used to predict the stock prices for the test set using the predict method. The predicted prices are then inverse-transformed using the MinMaxScaler to obtain the actual stock prices.</p><p>Finally, the predicted prices are plotted against the actual prices using the plot_predictions function and the root-mean-square error (RMSE) is computed using the return_rmse function.</details></p><h2 id="RNN-in-Action">RNN in Action</h2><p>Prepair the functions</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">split_sequence</span>(<span class="hljs-params">sequence, n_steps</span>):</span><br>    X, y = <span class="hljs-built_in">list</span>(), <span class="hljs-built_in">list</span>()<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(sequence)):<br>        end_ix = i + n_steps<br>        <span class="hljs-keyword">if</span> end_ix &gt; <span class="hljs-built_in">len</span>(sequence) - <span class="hljs-number">1</span>:<br>            <span class="hljs-keyword">break</span><br>        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]<br>        X.append(seq_x)<br>        y.append(seq_y)<br>    <span class="hljs-keyword">return</span> np.array(X), np.array(y)<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">Data_prepare</span>(<span class="hljs-params">training_set, n_steps = <span class="hljs-number">60</span>, features =<span class="hljs-number">1</span></span>):</span><br>    <span class="hljs-comment">#sc = MinMaxScaler(feature_range=(0, 1))</span><br>    training_set = training_set.reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>    <span class="hljs-comment">#training_set_scaled = sc.fit_transform(training_set)</span><br>    <span class="hljs-comment"># split into samples</span><br>    X_train, y_train = split_sequence(training_set_scaled, n_steps)<br><br>    <span class="hljs-comment"># Reshaping X_train for model</span><br>    X_train = X_train.reshape(X_train.shape[<span class="hljs-number">0</span>],X_train.shape[<span class="hljs-number">1</span>],features)<br>    <span class="hljs-keyword">return</span> X_train, y_train<br></code></pre></td></tr></table></figure></div><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>Data = <span class="hljs-string">&quot;/media/ken/DATA/tracking_test/WT_court10min_ID.csv&quot;</span><br>TB = pd.read_csv(Data, index_col=<span class="hljs-number">0</span>)<br><br><span class="hljs-comment"># select the Fly_8 as an example</span><br><span class="hljs-comment">#for ID in TB.ID.unique()[:12]:</span><br>ID = <span class="hljs-string">&quot;Fly_8&quot;</span><br>training_set_X = TB.X[TB.ID==ID][:<span class="hljs-number">2000</span>].to_numpy()<br>test_set_X = TB.X[TB.ID==ID][<span class="hljs-number">2000</span>:<span class="hljs-number">3000</span>].to_numpy()<br>training_set_Y = TB.Y[TB.ID==ID][:<span class="hljs-number">2000</span>].to_numpy()<br>test_set_Y = TB.Y[TB.ID==ID][<span class="hljs-number">2000</span>:<span class="hljs-number">3000</span>].to_numpy()<br><br>plt.plot(training_set_X, training_set_Y)<br>plt.plot(test_set_X, test_set_Y)<br>plt.show()<br></code></pre></td></tr></table></figure></div><p><img src="https://s1.ax1x.com/2023/05/04/p9Y5vD0.png" alt=""></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">n_steps = <span class="hljs-number">60</span><br>features = <span class="hljs-number">2</span><br><br>training_set = TB[[<span class="hljs-string">&quot;X&quot;</span>, <span class="hljs-string">&quot;Y&quot;</span>]][TB.ID==ID][:<span class="hljs-number">2000</span>].to_numpy()<br>X_train, y_train = split_sequence(training_set, n_steps)<br>X_train = X_train.reshape(X_train.shape[<span class="hljs-number">0</span>],X_train.shape[<span class="hljs-number">1</span>],features)<br><br>test_set = TB[[<span class="hljs-string">&quot;X&quot;</span>, <span class="hljs-string">&quot;Y&quot;</span>]][TB.ID==ID][<span class="hljs-number">2000</span>:<span class="hljs-number">3000</span>].to_numpy()<br>X_test, y_test = split_sequence(test_set, n_steps)<br>X_test = X_test.reshape(X_test.shape[<span class="hljs-number">0</span>],X_test.shape[<span class="hljs-number">1</span>],features)<br><br><br>model_gru = Sequential()<br>model_gru.add(GRU(units=<span class="hljs-number">125</span>, activation=<span class="hljs-string">&quot;tanh&quot;</span>, input_shape=(n_steps, features)))<br>model_gru.add(Dense(units=<span class="hljs-number">2</span>))<br><span class="hljs-comment"># Compiling the RNN</span><br>model_gru.<span class="hljs-built_in">compile</span>(optimizer=<span class="hljs-string">&quot;RMSprop&quot;</span>, loss=<span class="hljs-string">&quot;mse&quot;</span>)<br><br>model_gru.summary()<br>model_gru.fit(X_train, y_train, epochs=<span class="hljs-number">50</span>, batch_size=<span class="hljs-number">32</span>)<br><br>GRU_predicted_stock_price = model_gru.predict(X_test)<br><span class="hljs-comment">#GRU_predicted_stock_price = sc.inverse_transform(GRU_predicted_stock_price)</span><br><br>plt.plot(GRU_predicted_stock_price[:,<span class="hljs-number">0</span>], GRU_predicted_stock_price[:,<span class="hljs-number">1</span>])<br>plt.plot(test_set[:,<span class="hljs-number">0</span>], test_set[:,<span class="hljs-number">1</span>])<br>plt.show()<br><br><br>Predict = []<br>Track = X_train[-<span class="hljs-number">1</span>] <br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>):<br>    Predict += model_gru.predict(np.array([Track])).tolist()<br>    Track = np.concatenate([Track[<span class="hljs-number">1</span>:], [Predict[-<span class="hljs-number">1</span>]]])<br><br>plt.plot(np.array(Predict)[:,<span class="hljs-number">0</span>], np.array(Predict)[:,<span class="hljs-number">1</span>])<br>plt.plot(GRU_predicted_stock_price[:,<span class="hljs-number">0</span>], GRU_predicted_stock_price[:,<span class="hljs-number">1</span>])<br>plt.plot(test_set[:,<span class="hljs-number">0</span>], test_set[:,<span class="hljs-number">1</span>])<br>plt.show()<br><br><br><span class="hljs-comment"># plot for other fly</span><br><br><br><br>test_set = TB[[<span class="hljs-string">&quot;X&quot;</span>, <span class="hljs-string">&quot;Y&quot;</span>]][TB.ID==ID].to_numpy()<br>X_test, y_test = split_sequence(test_set, n_steps)<br>X_test = X_test.reshape(X_test.shape[<span class="hljs-number">0</span>],X_test.shape[<span class="hljs-number">1</span>],features)<br>plt.plot(GRU_predicted_stock_price[:,<span class="hljs-number">0</span>], GRU_predicted_stock_price[:,<span class="hljs-number">1</span>])<br>plt.plot(test_set[:,<span class="hljs-number">0</span>], test_set[:,<span class="hljs-number">1</span>])<br>plt.show()<br><br><br></code></pre></td></tr></table></figure></div><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">RNN, Recurrent Neural Network</summary>
    
    
    
    <category term="Python" scheme="https://karobben.github.io/categories/Python/"/>
    
    <category term="Data" scheme="https://karobben.github.io/categories/Python/Data/"/>
    
    <category term="Machine Learning" scheme="https://karobben.github.io/categories/Python/Data/Machine-Learning/"/>
    
    <category term="RNN" scheme="https://karobben.github.io/categories/Python/Data/Machine-Learning/RNN/"/>
    
    
    <category term="Python" scheme="https://karobben.github.io/tags/Python/"/>
    
    <category term="Machine Learning" scheme="https://karobben.github.io/tags/Machine-Learning/"/>
    
    <category term="Data" scheme="https://karobben.github.io/tags/Data/"/>
    
    <category term="RNN" scheme="https://karobben.github.io/tags/RNN/"/>
    
  </entry>
  
  <entry>
    <title>Wnt signal pathways</title>
    <link href="https://karobben.github.io/2023/03/12/LearnNotes/wnt/"/>
    <id>https://karobben.github.io/2023/03/12/LearnNotes/wnt/</id>
    <published>2023-03-12T17:07:47.000Z</published>
    <updated>2023-06-06T21:42:32.138Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Canonical-Wnt-Signal-Pathway">Canonical Wnt Signal Pathway</h2><table><thead><tr><th style="text-align:center"><img src="https://www.kegg.jp/kegg/pathway/map/map04310.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.kegg.jp/pathway/map04310">© KEGG</a></td></tr></tbody></table><p>Resources:</p><ol><li><a href="https://www.youtube.com/watch?v=EsypBtCI0kU">© Hussain Biology; youtube, 2018</a></li><li><a href="https://www.youtube.com/watch?v=eMgVfwCdRIs">© Catalyst University: youtube, 2019</a></li></ol><h3 id="Without-the-Wnt">Without the Wnt</h3><p>From the KEGG pathway map, we can know that a receptor complex is composed by <em><strong>LRP</strong></em> and <em><strong>frizzled</strong></em>. On the downside of the receptor, there is a degradation complex (grey arear on the map which name is scaffold) which mad by <em><strong>Axin</strong></em>, <em><strong>CKI</strong></em>, <em><strong>GSK3B</strong></em>, and the most important two proteins: <em><strong>$\beta$-catenin</strong></em> and <em><strong>APC</strong></em>. <em><strong>CKI</strong></em> and <em><strong>GSK3B</strong></em> both phosphorylate the <em><strong>$\beta$-catenin</strong></em> and then it was degradation by proteosome. On the other side, which is in the nuclear, protein <em><strong>TCF</strong></em> and <em><strong>LEF</strong></em> formed a complex and bind on the DNA which responsible for transcription of the genes. But  <em><strong>groucho</strong></em> bind with <em><strong>TCF/LEF</strong></em> to prohibit the release of DNA.</p><h3 id="With-the-present-of-Wnt">With the present of Wnt</h3><p>When the receptor complex activated by <em><strong>Wnt</strong></em>, Dishevelled protein (<em><strong>Dvl</strong></em>) and degradation complex are recruited by receptor complex. In this way, the <em><strong>$\beta$-catenin</strong></em> is not ubiquinated and released into the nuclear. Then, <em><strong>$\beta$-catenin</strong></em> releases the <em><strong>groucho</strong></em> and bind with <em><strong>TCF</strong></em> and started to bind the DNA. In this way, wnt signal pathway regulated genes are activated and expressed.</p><h2 id="Abnormal-in-Wnt">Abnormal in Wnt</h2><p>Intestine stem cells is a group of fast poliferation cell because the intestine epithelial cells only last for 4 days. Lost of tha <em><strong>APC</strong></em> could cause the fail of <em><strong>$\beta$-catenin</strong></em> phosphorylation and leading the constant of gene transcription (90% of human colon cancer).</p><p>??</p><p>over-expression of wild-type Wts has relatively little effect on wing growth in wild-type flies, but can suppress the over-growth phenotypes associated with mutation of upstream tumor suppressors that activate Yki<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>Sun, Gongping, and Kenneth D. Irvine. “Regulation of Hippo signaling by Jun kinase signaling during compensatory cell proliferation and regeneration, and in neoplastic tumors.” Developmental biology 350.1 (2011): 139-151. <a href="#fnref1" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">Wnt signal pathways</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Notes/Biology/"/>
    
    <category term="Dme" scheme="https://karobben.github.io/categories/Notes/Biology/Dme/"/>
    
    
    <category term="Biology" scheme="https://karobben.github.io/tags/Biology/"/>
    
  </entry>
  
  <entry>
    <title>DNA Damage</title>
    <link href="https://karobben.github.io/2023/03/12/LearnNotes/Paper-dna-damage/"/>
    <id>https://karobben.github.io/2023/03/12/LearnNotes/Paper-dna-damage/</id>
    <published>2023-03-12T16:32:35.000Z</published>
    <updated>2023-06-06T21:42:32.130Z</updated>
    
    <content type="html"><![CDATA[<h2 id="DNA-Damage">DNA Damage</h2><blockquote><p>DNA is vulnerable to damage resulting from endogenous metabolites, environmental and dietary carcinogens, some anti-inflammatory drugs, and genotoxic cancer therapeutics. Cells respond to DNA damage by activating complex signalling networks that decide cell fate, promoting not only DNA repair and survival but also cell death. The decision between cell survival and death following DNA damage rests on factors that are involved in DNA damage recognition, and DNA repair and damage tolerance, as well as on factors involved in the activation of apoptosis, necrosis, autophagy and senescence. The pathways that dictate cell fate are entwined and have key roles in cancer initiation and progression. Furthermore, they determine the outcome of cancer therapy with genotoxic drugs. Understanding the molecular basis of these pathways is important not only for gaining insight into carcinogenesis, but also in promoting successful cancer therapy. In this Review, we describe key decision-making nodes in the complex interplay between cell survival and death following DNA damage.<br><a href="https://www.nature.com/articles/nrc.2015.2">© Wynand P. Roos; 2016</a></p></blockquote><p>In the event of DNA damage, cells activate DNA repair pathways to facilitate the removal of replication barriers. Conversely, in instances of irreparable DNA damage, cells are prompted to undergo programmed cell death<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>.<br>Reactive oxygen species (<abbr title="Reactive oxygen species">ROS</abbr>), a by-product of regular cellular metabolism, along with various environmental and endogenous genotoxic factors, pose a threat to the stability of DNA and other macromolecules<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>.<br>In response to oxidative DNA damage, cells activate cell cycle checkpoints, leading to the arrest of the cell cycle and cessation of DNA replication. This creates a time window during which DNA repair pathways, such as excision repair, can effectively identify and repair DNA damage induced by oxidative stress. Excision repair is a critical system for repairing oxidative stress-induced DNA damage<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>.</p><table><thead><tr><th style="text-align:center"><img src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fnrc.2015.2/MediaObjects/41568_2016_Article_BFnrc20152_Fig1_HTML.jpg" alt="Cellular consequences of DNA damage"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.nature.com/articles/nrc.2015.2">© Wynand P. Roos; 2016</a></td></tr></tbody></table><p><img src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnrc.2015.2/MediaObjects/41568_2016_Article_BFnrc20152_Fig2_HTML.jpg?as=webp" alt="DNA damage-dependent apoptosis"></p><p>Key damage tolerance mechanisms for cell survival<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup><sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup><sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup>:</p><ul><li>non-homologous end joining (NHEJ)</li><li>homologous recombination (HR), MMR, BER, nucleotide excision repair (NER)</li><li>protein-linked DNA break (PDB) repair in combination with <abbr title="DNA damage response">DDR</abbr> signallin.</li></ul><p>Three immediate-early sensors in the <abbr title="DNA damage response">DDR</abbr> -  PI3K-related kinases (PIKKs)<sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup>:</p><ul><li>ataxia telangiectasia mutated (ATM)<ul><li><em><strong>ATM</strong></em> is frequently mutated in tumours<sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup>, which is accompanied by a gain of therapeutic resistance<sup class="footnote-ref"><a href="#fn9" id="fnref9">[9]</a></sup>.</li><li><em><strong>ATM</strong></em> mutation increased risk of breast cancer<sup class="footnote-ref"><a href="#fn10" id="fnref10">[10]</a></sup> nad colon cancer<sup class="footnote-ref"><a href="#fn11" id="fnref11">[11]</a></sup></li><li>more frequently altered than ATR<sup class="footnote-ref"><a href="#fn12" id="fnref12">[12]</a></sup></li></ul></li><li>ataxia telangiectasia and Rad3-related (ATR)<ul><li>functionally compromised ATR also show malignancy</li></ul></li><li>DNA-dependent protein kinase (DNA-PK)</li></ul><p>ATM and ATR promote cell death in instances of high <abbr title="DNA double-strand break">DSB</abbr> levels<sup class="footnote-ref"><a href="#fn13" id="fnref13">[13]</a></sup></p><table><thead><tr><th style="text-align:center"><img src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fnrc.2015.2/MediaObjects/41568_2016_Article_BFnrc20152_Fig5_HTML.jpg?as=webp" alt="DNA damage-dependent autophagy"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.nature.com/articles/nrc.2015.2">© Wynand P. Roos; 2016</a></td></tr></tbody></table><style>pre {  background-color:#38393d;  color: #5fd381;}</style><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>L.H. Pearl, A.C. Schierz, S.E. Ward, B. Al-Lazikani, F.M. Pearl<br>Therapeutic opportunities within the DNA damage response<br>Nat. Rev. Cancer, 15 (3) (2015), pp. 166-180 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>M. Majidinia, B. Yousefi DNA damage response regulation by MicroRNAs as a therapeutic target in cancer<br>DNA Repair, 47 (2016), pp. 1-11 <a href="#fnref2" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>Davies, Kelvin JA, ed. Oxidative damage &amp; repair: Chemical, biological and medical aspects. Elsevier, 2013. <a href="#fnref3" class="footnote-backref">↩︎</a></p></li><li id="fn4" class="footnote-item"><p>Roos, W. P. et al. The translesion polymerase Rev3L in the tolerance of alkylating anticancer drugs. Mol. Pharmacol. 76, 927–934 (2009). <a href="#fnref4" class="footnote-backref">↩︎</a></p></li><li id="fn5" class="footnote-item"><p>Ashour, M. E., Atteya, R. &amp; El-Khamisy, S. F. Topoisomerase-mediated chromosomal break repair: an emerging player in many games. Nat. Rev. Cancer 15, 137–151 (2015). <a href="#fnref5" class="footnote-backref">↩︎</a></p></li><li id="fn6" class="footnote-item"><p>Stingele, J., Habermann, B. &amp; Jentsch, S. DNA–protein crosslink repair: proteases as DNA repair enzymes. Trends Biochem. Sci. 40, 67–71 (2015). <a href="#fnref6" class="footnote-backref">↩︎</a></p></li><li id="fn7" class="footnote-item"><p>Rogakou, E. P., Pilch, D. R., Orr, A. H., Ivanova, V. S. &amp; Bonner, W. M. DNA double-stranded breaks induce histone H2AX phosphorylation on serine 139. J. Biol. Chem. 273, 5858–5868 (1998) <a href="#fnref7" class="footnote-backref">↩︎</a></p></li><li id="fn8" class="footnote-item"><p>Stankovic, T. et al. ATM mutations in sporadic lymphoid tumours. Leuk. Lymphoma 43, 1563–1571 (2002). <a href="#fnref8" class="footnote-backref">↩︎</a></p></li><li id="fn9" class="footnote-item"><p>Kim, H. et al. Having pancreatic cancer with tumoral loss of ATM and normal TP53 protein expression is associated with a poorer prognosis. Clin. Cancer Res. 20, 1865–1872 (2014). <a href="#fnref9" class="footnote-backref">↩︎</a></p></li><li id="fn10" class="footnote-item"><p>Swift, M., Morrell, D., Massey, R. B. &amp; Chase, C. L. Incidence of cancer in 161 families affected by ataxia-telangiectasia. N. Engl. J. Med. 325, 1831–1836 (1991). <a href="#fnref10" class="footnote-backref">↩︎</a></p></li><li id="fn11" class="footnote-item"><p>Thompson, D. et al. Cancer risks and mortality in heterozygous ATM mutation carriers. J. Natl Cancer Inst. 97, 813–822 (2005). <a href="#fnref11" class="footnote-backref">↩︎</a></p></li><li id="fn12" class="footnote-item"><p>Khanna, K. K. Cancer risk and the ATM gene: a continuing debate. J. Natl Cancer Inst. 92, 795–802 (2000). <a href="#fnref12" class="footnote-backref">↩︎</a></p></li><li id="fn13" class="footnote-item"><p>Pusapati, R. V. et al. ATM promotes apoptosis and suppresses tumorigenesis in response to Myc. Proc. Natl Acad. Sci. USA 103, 1446–1451 (2006). <a href="#fnref13" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">DNA Damage</summary>
    
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/tags/Biology/"/>
    
    <category term="Paper" scheme="https://karobben.github.io/tags/Paper/"/>
    
  </entry>
  
  <entry>
    <title>Image skills for python</title>
    <link href="https://karobben.github.io/2023/03/07/Python/image/"/>
    <id>https://karobben.github.io/2023/03/07/Python/image/</id>
    <published>2023-03-08T02:25:35.000Z</published>
    <updated>2023-06-06T21:42:32.142Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Read-tiff-files">Read tiff files</h2><p><a href="https://biomedicalhub.github.io/python-data/skimage.html">skimage</a></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> skimage.io <span class="hljs-keyword">as</span> skio<br>imstack1    = skio.imread(<span class="hljs-string">&quot;FILENAME.TIF&quot;</span>, plugin=<span class="hljs-string">&quot;tifffile&quot;</span>)<br></code></pre></td></tr></table></figure></div><h2 id="Gaussian-Smoothing">Gaussian Smoothing</h2><p><a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.gaussian_filter.html">scipy</a></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> scipy.ndimage <span class="hljs-keyword">import</span> gaussian_filter<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>a = np.arange(<span class="hljs-number">50</span>, step=<span class="hljs-number">2</span>).reshape((<span class="hljs-number">5</span>,<span class="hljs-number">5</span>))<br>b = gaussian_filter(a, sigma=<span class="hljs-number">3</span>)<br><br>fig, axs = plt.subplots(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>)<br>axs[<span class="hljs-number">0</span>].imshow(a)<br>axs[<span class="hljs-number">1</span>].imshow(b)<br><br>plt.show()<br></code></pre></td></tr></table></figure></div><p><img src="https://s1.ax1x.com/2023/03/08/ppe5dzD.png" alt="Gaussian Smoothing"></p><table><thead><tr><th style="text-align:center"><img src="https://docs.scipy.org/doc/scipy/_images/scipy-ndimage-gaussian_filter-1.png" alt="Gaussian example from scipy"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.gaussian_filter.html">© scipy</a></td></tr></tbody></table><h2 id="Turn-image-to-DataFrame">Turn image to DataFrame</h2><h3 id="Grey-image">Grey image</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-comment"># create a 2D image array</span><br>image_array = np.array([[<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">30</span>], [<span class="hljs-number">40</span>, <span class="hljs-number">50</span>, <span class="hljs-number">60</span>], [<span class="hljs-number">70</span>, <span class="hljs-number">80</span>, <span class="hljs-number">90</span>]])<br><span class="hljs-comment"># convert to pandas dataframe</span><br>df = pd.DataFrame(image_array)<br><span class="hljs-comment"># print dataframe</span><br>print(df)<br></code></pre></td></tr></table></figure></div><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Image skills for python</summary>
    
    
    
    <category term="Python" scheme="https://karobben.github.io/categories/Python/"/>
    
    
    <category term="Python" scheme="https://karobben.github.io/tags/Python/"/>
    
    <category term="Image" scheme="https://karobben.github.io/tags/Image/"/>
    
  </entry>
  
  <entry>
    <title>Python 3D Plot</title>
    <link href="https://karobben.github.io/2023/03/07/Python/3dball/"/>
    <id>https://karobben.github.io/2023/03/07/Python/3dball/</id>
    <published>2023-03-08T01:58:47.000Z</published>
    <updated>2023-06-06T21:42:32.142Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Plot-a-ball">Plot a ball</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> mpl_toolkits.mplot3d <span class="hljs-keyword">import</span> Axes3D<br><br><span class="hljs-comment"># Generate random points on the surface of a unit sphere</span><br>np.random.seed(<span class="hljs-number">123</span>)<br>n_points = <span class="hljs-number">500</span><br>theta = np.random.uniform(<span class="hljs-number">0</span>, <span class="hljs-number">2</span> * np.pi, size=n_points)<br>phi = np.random.uniform(<span class="hljs-number">0</span>, np.pi, size=n_points)<br>x = np.sin(phi) * np.cos(theta)<br>y = np.sin(phi) * np.sin(theta)<br>z = np.cos(phi)<br><br><span class="hljs-comment"># Plot the points on a 3D scatter plot</span><br>fig = plt.figure()<br>ax = fig.add_subplot(<span class="hljs-number">111</span>, projection=<span class="hljs-string">&#x27;3d&#x27;</span>)<br>ax.scatter(x, y, z, s=<span class="hljs-number">50</span>)<br><br><span class="hljs-comment"># Connect the dots to the center of the ball</span><br>center = np.array([<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>])<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_points):<br>    point = np.array([x[i], y[i], z[i]])<br>    ax.plot([center[<span class="hljs-number">0</span>], point[<span class="hljs-number">0</span>]], [center[<span class="hljs-number">1</span>], point[<span class="hljs-number">1</span>]], [center[<span class="hljs-number">2</span>], point[<span class="hljs-number">2</span>]], <span class="hljs-string">&#x27;k--&#x27;</span>, alpha=<span class="hljs-number">0.3</span>)<br><br><span class="hljs-comment"># Set axis limits and labels</span><br>ax.set_xlim([-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>])<br>ax.set_ylim([-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>])<br>ax.set_zlim([-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>])<br>ax.set_xlabel(<span class="hljs-string">&#x27;X&#x27;</span>)<br>ax.set_ylabel(<span class="hljs-string">&#x27;Y&#x27;</span>)<br>ax.set_zlabel(<span class="hljs-string">&#x27;Z&#x27;</span>)<br>plt.show()<br><br></code></pre></td></tr></table></figure></div><p>In this code, we first generate random points on the surface of a unit sphere using the <code>numpy.random.uniform</code> function. Then we plot these points on a 3D scatter plot using matplotlib. Finally, we connect each point to the center of the sphere using a black dotted line with <code>ax.plot</code>. The center of the sphere is defined as <code>[0, 0, 0]</code>.</p><p><img src="https://s1.ax1x.com/2023/03/08/ppe2Ozj.png" alt="3D ball shape dots plot"></p><h2 id="Add-a-plate-to-slice-the-dots">Add a plate to slice the dots</h2><h3 id="how-to-plot-a-surface">how to plot a surface</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> mpl_toolkits.mplot3d <span class="hljs-keyword">import</span> Axes3D<br><br>fig = plt.figure()<br>ax = fig.add_subplot(<span class="hljs-number">111</span>, projection=<span class="hljs-string">&#x27;3d&#x27;</span>)<br><br><span class="hljs-comment"># Generate some data for the plot</span><br>x, y = np.meshgrid(np.arange(-<span class="hljs-number">5</span>, <span class="hljs-number">5</span>, <span class="hljs-number">0.5</span>), np.arange(-<span class="hljs-number">5</span>, <span class="hljs-number">5</span>, <span class="hljs-number">0.5</span>))<br>z = np.zeros(x.shape)<br><br><span class="hljs-comment"># Create the plane surface</span><br>ax.plot_surface(x, y, z, alpha=<span class="hljs-number">0.5</span>, color=<span class="hljs-string">&#x27;blue&#x27;</span>)<br><br><span class="hljs-comment"># Plot some 3D points</span><br>xs = np.random.normal(size=<span class="hljs-number">50</span>)<br>ys = np.random.normal(size=<span class="hljs-number">50</span>)<br>zs = np.random.normal(size=<span class="hljs-number">50</span>)<br><br>ax.scatter(xs, ys, zs)<br><br>plt.show()<br></code></pre></td></tr></table></figure></div><p>In this code, we first create a <code>figure</code> and a <code>subplot</code> with a 3D projection. Then, we generate some data for the surface plane using <code>numpy.meshgrid()</code>. We set the <code>z</code> values to zero so that the plane is on the <code>xy</code> plane.</p><p>We then create the plane surface using <code>Axes3D.plot_surface()</code> function. The <code>alpha</code> parameter sets the transparency of the surface and the <code>color</code> parameter sets its color.</p><p>Finally, we plot some 3D points using the <code>Axes3D.scatter()</code> function.</p><p>When you run this code, you should see a 3D plot with a transparent blue plane surface and some randomly scattered 3D points.</p><p><img src="https://s1.ax1x.com/2023/03/08/ppeRiYF.png" alt="Python: A surface in 3D plot"></p><h3 id="Slice-the-ball-with-the-surface">Slice the ball with the surface</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> mpl_toolkits.mplot3d <span class="hljs-keyword">import</span> Axes3D<br><br><span class="hljs-comment"># Generate random points on the surface of a unit sphere</span><br>np.random.seed(<span class="hljs-number">123</span>)<br>n_points = <span class="hljs-number">500</span><br>theta = np.random.uniform(<span class="hljs-number">0</span>, <span class="hljs-number">2</span> * np.pi, size=n_points)<br>phi = np.random.uniform(<span class="hljs-number">0</span>, np.pi, size=n_points)<br>x = np.sin(phi) * np.cos(theta)<br>y = np.sin(phi) * np.sin(theta)<br>z = np.cos(phi)<br><br><span class="hljs-comment"># Plot the points on a 3D scatter plot</span><br>fig = plt.figure()<br>ax = fig.add_subplot(<span class="hljs-number">111</span>, projection=<span class="hljs-string">&#x27;3d&#x27;</span>)<br>ax.scatter(x, y, z, s=<span class="hljs-number">50</span>)<br><br><span class="hljs-comment"># Connect the dots to the center of the ball</span><br>center = np.array([<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>])<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_points):<br>    point = np.array([x[i], y[i], z[i]])<br>    ax.plot([center[<span class="hljs-number">0</span>], point[<span class="hljs-number">0</span>]], [center[<span class="hljs-number">1</span>], point[<span class="hljs-number">1</span>]], [center[<span class="hljs-number">2</span>], point[<span class="hljs-number">2</span>]], <span class="hljs-string">&#x27;k--&#x27;</span>, alpha=<span class="hljs-number">0.3</span>)<br><br><span class="hljs-comment"># Set axis limits and labels</span><br>ax.set_xlim([-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>])<br>ax.set_ylim([-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>])<br>ax.set_zlim([-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>])<br>ax.set_xlabel(<span class="hljs-string">&#x27;X&#x27;</span>)<br>ax.set_ylabel(<span class="hljs-string">&#x27;Y&#x27;</span>)<br>ax.set_zlabel(<span class="hljs-string">&#x27;Z&#x27;</span>)<br><br><span class="hljs-comment"># Add plate</span><br><br>x, y =  np.meshgrid(np.arange(-<span class="hljs-number">1</span>, <span class="hljs-number">1.5</span>, <span class="hljs-number">0.5</span>), <br>        np.arange(-<span class="hljs-number">1</span>, <span class="hljs-number">1.5</span>, <span class="hljs-number">0.5</span>))<br>z = np.zeros(x.shape)<br><br><span class="hljs-comment"># Create the plane surface</span><br>ax.plot_surface(x, y, z + <span class="hljs-number">.7</span>, alpha=<span class="hljs-number">0.5</span>, color=<span class="hljs-string">&#x27;steelblue&#x27;</span>)<br>ax.plot_surface(x, y, z +<span class="hljs-number">.75</span>, alpha=<span class="hljs-number">0.5</span>, color=<span class="hljs-string">&#x27;red&#x27;</span>)<br>ax.plot_surface(x, y, z + <span class="hljs-number">.8</span>, alpha=<span class="hljs-number">0.5</span>, color=<span class="hljs-string">&#x27;steelblue&#x27;</span>)<br><br><br>plt.show()<br></code></pre></td></tr></table></figure></div><p><img src="https://s1.ax1x.com/2023/03/08/ppeRwtS.png" alt="Python 3D plot: slice a ball with plate"></p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">3D plot in python</summary>
    
    
    
    <category term="Python" scheme="https://karobben.github.io/categories/Python/"/>
    
    
    <category term="Python" scheme="https://karobben.github.io/tags/Python/"/>
    
    <category term="Plot" scheme="https://karobben.github.io/tags/Plot/"/>
    
    <category term="3D" scheme="https://karobben.github.io/tags/3D/"/>
    
  </entry>
  
  <entry>
    <title>Python Dictionary is awesome</title>
    <link href="https://karobben.github.io/2023/03/01/Python/dictionary/"/>
    <id>https://karobben.github.io/2023/03/01/Python/dictionary/</id>
    <published>2023-03-01T18:41:49.000Z</published>
    <updated>2023-06-06T21:42:32.142Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Dictionary">Dictionary</h2><p>A dictionary in Python is an unordered collection of key-value pairs. It is a mutable, indexed, and iterable data structure that is commonly used to store and retrieve data. The keys in a dictionary must be unique and immutable (strings, integers, tuples) while the values can be of any data type (strings, integers, lists, sets, other dictionaries, etc.). It could be create by <code>my_dict = &#123;&quot;name&quot;: &quot;John&quot;, &quot;age&quot;: 25, &quot;city&quot;: &quot;New York&quot;&#125;</code></p><p>Here is some basic operations for Python dictionary</p><ol><li>Creating a dictionary</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">my_dict = &#123;<span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;John&quot;</span>, <span class="hljs-string">&quot;age&quot;</span>: <span class="hljs-number">25</span>, <span class="hljs-string">&quot;city&quot;</span>: <span class="hljs-string">&quot;New York&quot;</span>&#125;<br></code></pre></td></tr></table></figure></div><ol start="2"><li>Accessing values using keys</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">print(my_dict[<span class="hljs-string">&quot;name&quot;</span>]) <br>print(my_dict[<span class="hljs-string">&quot;age&quot;</span>]) <br></code></pre></td></tr></table></figure></div><pre>John25</pre><ol start="3"><li>Adding a new key-value pair</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">my_dict[<span class="hljs-string">&quot;country&quot;</span>] = <span class="hljs-string">&quot;USA&quot;</span><br>print(my_dict)  <br></code></pre></td></tr></table></figure></div><pre>{"name": "John", "age": 25, "city": "New York", "country": "USA"}</pre><ol start="4"><li>Removing and Updating</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">del</span> my_dict[<span class="hljs-string">&quot;city&quot;</span>]<br>my_dict[<span class="hljs-string">&quot;age&quot;</span>] = <span class="hljs-number">26</span><br></code></pre></td></tr></table></figure></div><ol start="5"><li>Checking if a key exists in a dictionary</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> <span class="hljs-string">&quot;name&quot;</span> <span class="hljs-keyword">in</span> my_dict:<br>    print(<span class="hljs-string">&quot;Name is present&quot;</span>)<br><span class="hljs-keyword">else</span>:<br>    print(<span class="hljs-string">&quot;Name is not present&quot;</span>)<br><br><span class="hljs-comment"># Iterating through a dictionary</span><br><span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> my_dict.items():<br>    print(key, value)<br></code></pre></td></tr></table></figure></div><h2 id="Find-the-max-value-from-a-dictionary">Find the max value from a dictionary</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">d = &#123;<span class="hljs-string">&#x27;a&#x27;</span>: <span class="hljs-number">10</span>, <span class="hljs-string">&#x27;b&#x27;</span>: <span class="hljs-number">5</span>, <span class="hljs-string">&#x27;c&#x27;</span>: <span class="hljs-number">20</span>&#125;<br>max_value = <span class="hljs-built_in">max</span>(d, key=d.get)<br>print(max_value)<br></code></pre></td></tr></table></figure></div><pre>c</pre><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Python Dictionary is awesome</summary>
    
    
    
    <category term="Python" scheme="https://karobben.github.io/categories/Python/"/>
    
    <category term="Beginner" scheme="https://karobben.github.io/categories/Python/Beginner/"/>
    
    
    <category term="Python" scheme="https://karobben.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>path find in a network plot</title>
    <link href="https://karobben.github.io/2023/02/26/Python/net-path/"/>
    <id>https://karobben.github.io/2023/02/26/Python/net-path/</id>
    <published>2023-02-26T17:22:57.000Z</published>
    <updated>2023-06-06T21:42:32.146Z</updated>
    
    <content type="html"><![CDATA[<h2 id="path-find-in-a-network-plot">path find in a network plot</h2><p>Here’s an example code for a more complicated network graph using NetworkX and finding a path from one node to another node:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> networkx <span class="hljs-keyword">as</span> nx<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-comment"># Create a graph</span><br>G = nx.DiGraph()<br><br><span class="hljs-comment"># Add nodes</span><br>G.add_nodes_from([<span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-string">&#x27;C&#x27;</span>, <span class="hljs-string">&#x27;D&#x27;</span>, <span class="hljs-string">&#x27;E&#x27;</span>, <span class="hljs-string">&#x27;F&#x27;</span>, <span class="hljs-string">&#x27;G&#x27;</span>, <span class="hljs-string">&#x27;H&#x27;</span>])<br><br><span class="hljs-comment"># Add edges</span><br>G.add_edges_from([(<span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>), (<span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-string">&#x27;C&#x27;</span>), (<span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-string">&#x27;D&#x27;</span>), (<span class="hljs-string">&#x27;C&#x27;</span>, <span class="hljs-string">&#x27;E&#x27;</span>), (<span class="hljs-string">&#x27;D&#x27;</span>, <span class="hljs-string">&#x27;E&#x27;</span>),<br>                  (<span class="hljs-string">&#x27;D&#x27;</span>, <span class="hljs-string">&#x27;F&#x27;</span>), (<span class="hljs-string">&#x27;E&#x27;</span>, <span class="hljs-string">&#x27;G&#x27;</span>), (<span class="hljs-string">&#x27;F&#x27;</span>, <span class="hljs-string">&#x27;G&#x27;</span>), (<span class="hljs-string">&#x27;G&#x27;</span>, <span class="hljs-string">&#x27;H&#x27;</span>)])<br><br><span class="hljs-comment"># Plot the graph</span><br>pos = nx.spring_layout(G, seed=<span class="hljs-number">123</span>)<br>nx.draw_networkx(G, pos, with_labels=<span class="hljs-literal">True</span>)<br>edge_labels = nx.get_edge_attributes(G, <span class="hljs-string">&#x27;weight&#x27;</span>)<br>nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)<br>plt.show()<br><br><span class="hljs-comment"># Find a path from node &#x27;A&#x27; to node &#x27;H&#x27;</span><br>path = nx.shortest_path(G, <span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;H&#x27;</span>)<br>print(path)<br><br><br><span class="hljs-comment"># highlight the path</span><br>edge_colors = [<span class="hljs-string">&#x27;red&#x27;</span> <span class="hljs-keyword">if</span> (u, v) <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(path, path[<span class="hljs-number">1</span>:]) <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;black&#x27;</span> <span class="hljs-keyword">for</span> u, v <span class="hljs-keyword">in</span> G.edges()]<br>nx.draw(G,  pos, with_labels=<span class="hljs-literal">True</span>, edge_color=edge_colors)<br>plt.show()<br></code></pre></td></tr></table></figure></div><pre>['A', 'B', 'C', 'E', 'G', 'H']</pre><p><img src="https://s1.ax1x.com/2023/03/02/ppFiGOf.png" alt="Net work path find"></p><p>In this code, we create a directed graph <code>G</code> using <code>nx.DiGraph()</code>. We add nodes to the graph using <code>G.add_nodes_from()</code>, and add edges to the graph using <code>G.add_edges_from()</code>. We can assign a weight to each edge using a dictionary, but in this example we don’t do that.</p><p>We then use the <code>nx.spring_layout()</code> function to generate node positions for the graph. This function positions nodes using the Fruchterman-Reingold force-directed algorithm. In this example, we set the random seed to 123 using the <code>seed</code> parameter of <code>nx.spring_layout()</code>. This ensures that the initial conditions of the spring layout algorithm are the same each time you run the code, and the layout of the graph remains the same.</p><p>We then use <code>nx.draw_networkx()</code> to draw nodes and edges of the graph with labels. We also use <code>nx.get_edge_attributes()</code> and <code>nx.draw_networkx_edge_labels()</code> to add labels to the edges of the graph. Finally, we use <code>plt.show()</code> to display the plot.</p><p>After displaying the graph, we use <code>nx.shortest_path()</code> to find the shortest path from node ‘A’ to node ‘H’. The function returns a list of nodes that form the path. We print the path to the console.</p><p>Note that you can modify the graph and the path-finding algorithms according to your specific needs using the functions available in the NetworkX library.</p><h2 id="How-does-nx-shortest-path-works">How does <strong>nx.shortest_path</strong> works</h2><p>The <code>nx.shortest_path()</code> function in NetworkX is used to find the shortest path between two nodes in a graph. It uses the <em><strong>Dijkstra’s algorithm</strong></em>, which is an algorithm for finding the shortest paths between nodes in a graph.</p><p>The <code>nx.shortest_path()</code> function takes three parameters:</p><ul><li><code>G</code>: the graph to search for shortest path in.</li><li><code>source</code>: the starting node for the path.</li><li><code>target</code>: the ending node for the path.<br>The function returns a list of nodes in the shortest path from the <code>source</code> node to the <code>target</code> node.</li></ul><h2 id="what-is-Dijkstra’s-algorithm">what is <em><strong>Dijkstra’s algorithm</strong></em></h2><p><em><strong>Dijkstra’s algorithm</strong></em> is a graph search algorithm that works by finding the shortest path from a starting node to all other nodes in the graph. The algorithm maintains a set of visited nodes and a set of unvisited nodes, with the distance from the starting node to each unvisited node initialized to infinity. At each step, the algorithm selects the unvisited node with the smallest distance from the starting node and adds it to the visited set. It then updates the distances of all adjacent nodes that are still in the unvisited set, setting their distance to the sum of the distance to the current node and the weight of the edge between them. The algorithm continues until the target node is reached, or until all nodes have been visited.</p><p>Once the shortest path has been found, <code>nx.shortest_path()</code> returns a list of nodes in the path, in the order that they appear in the path.</p><h2 id="What-is-“bellman-ford”">What is “bellman-ford”?</h2><p>Bellman-Ford is an algorithm for finding the shortest paths between nodes in a weighted graph. The algorithm can handle negative edge weights, whereas Dijkstra’s algorithm, which we discussed in a previous question, cannot. However, Bellman-Ford is slower than Dijkstra’s algorithm and has a higher time complexity of O(V*E), where V is the number of vertices and E is the number of edges in the graph.</p><p>The Bellman-Ford algorithm works by relaxing all edges in the graph V-1 times, where V is the number of vertices in the graph. During each iteration, the algorithm checks if the distance to a node can be improved by going through another node. If so, it updates the distance to the node. The algorithm repeats this process V-1 times to ensure that all possible paths have been explored.</p><p>After the V-1 iterations, the algorithm performs one more check to see if there are any negative weight cycles in the graph. If there are, then the algorithm cannot find a shortest path because the distance to the node can be decreased indefinitely by traversing the negative cycle. In this case, the algorithm returns a message indicating that a negative cycle has been detected.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> networkx <span class="hljs-keyword">as</span> nx<br><br><span class="hljs-comment"># Create a graph</span><br>G = nx.DiGraph()<br><br><span class="hljs-comment"># Add nodes</span><br>G.add_nodes_from([<span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-string">&#x27;C&#x27;</span>, <span class="hljs-string">&#x27;D&#x27;</span>, <span class="hljs-string">&#x27;E&#x27;</span>])<br><br><span class="hljs-comment"># Add edges with weights</span><br>G.add_weighted_edges_from([(<span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-number">3</span>), (<span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;C&#x27;</span>, <span class="hljs-number">8</span>), (<span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-string">&#x27;C&#x27;</span>, -<span class="hljs-number">4</span>),<br>                           (<span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-string">&#x27;D&#x27;</span>, <span class="hljs-number">1</span>), (<span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-string">&#x27;E&#x27;</span>, <span class="hljs-number">7</span>), (<span class="hljs-string">&#x27;C&#x27;</span>, <span class="hljs-string">&#x27;D&#x27;</span>, <span class="hljs-number">2</span>),<br>                           (<span class="hljs-string">&#x27;D&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-number">2</span>), (<span class="hljs-string">&#x27;E&#x27;</span>, <span class="hljs-string">&#x27;D&#x27;</span>, -<span class="hljs-number">5</span>)])<br><br><span class="hljs-comment"># Find the shortest paths using Bellman-Ford algorithm</span><br>distances, predecessors = nx.bellman_ford(G, <span class="hljs-string">&#x27;A&#x27;</span>)<br><br><span class="hljs-comment"># Print the distances</span><br>print(distances)<br><br><span class="hljs-comment"># Print the predecessors</span><br>print(predecessors)<br></code></pre></td></tr></table></figure></div><p>In this example, we create a directed graph with five nodes and eight edges, with some edges having negative weights. We then use <code>nx.bellman_ford()</code> to find the shortest paths from the node ‘A’ to all other nodes in the graph. The function returns two dictionaries: one with the shortest distance from the starting node to each node, and another with the predecessor node in the shortest path for each node. We print these dictionaries to the console.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">path find in a network plot</summary>
    
    
    
    <category term="Python" scheme="https://karobben.github.io/categories/Python/"/>
    
    
    <category term="Network" scheme="https://karobben.github.io/tags/Network/"/>
    
  </entry>
  
  <entry>
    <title>Fruchterman Reingold layout</title>
    <link href="https://karobben.github.io/2023/02/20/LearnNotes/fruchterman-reingold/"/>
    <id>https://karobben.github.io/2023/02/20/LearnNotes/fruchterman-reingold/</id>
    <published>2023-02-21T03:44:24.000Z</published>
    <updated>2023-06-06T21:42:32.134Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Fruchterman–Reingold">Fruchterman–Reingold</h2><blockquote><p>Fruchterman-Reingold is an algorithm used for force-directed graph drawing, which is a way of visualizing graph structures in a 2D or 3D space. The algorithm was first introduced by Thomas M. Fruchterman and Edward M. Reingold in 1991.</p><p>The Fruchterman-Reingold algorithm works by simulating a physical system in which the nodes of a graph are treated as objects with electrical charges and the edges of the graph are treated as springs. The nodes are initially placed at random positions in the 2D or 3D space, and then the algorithm iteratively adjusts the position of the nodes based on the repulsion between the nodes and the attraction between the connected nodes. The nodes that are connected by an edge are pulled closer together, while the nodes that are not connected are pushed apart.</p><p>The Fruchterman-Reingold algorithm aims to minimize the total energy of the system by finding an equilibrium state where the forces between the nodes and edges are balanced. The algorithm iteratively adjusts the positions of the nodes until it reaches the equilibrium state. The result is a visually pleasing graph layout that allows the viewer to easily see the connections and relationships between the nodes.</p><p>The Fruchterman-Reingold algorithm is widely used in many fields such as social network analysis, information visualization, and bioinformatics. It has been implemented in many software packages, including Gephi, Cytoscape, and NetworkX.<br>Fruchterman–Reingold is a type of layout which widely be used in the network, social network and protein-protein interaction network for instance, analysis.<br><a title='ChatGPT'> Who sad this?</a></p></blockquote><p>So, imagine that all the nodes are electrons that carry the same charge. As a result, they prefer to stay away from each other and distribute evenly in a limited space. However, the connections (edges) work like springs that pull two nodes together. If two groups have connections that frequently occur within the group, those nodes would prefer to be close to each other and form two large clusters because of the “springs”. The two groups would be away from each other because no/or a few of spring pulls them together, and the two huge groups of nodes would push the nodes outside the cluster. If a new node is added that has connections to both clusters and the number is significant enough, it could form an hourglass-like structure. And if there are a few other connections between two clusters at the same time, it would merge the two groups into a single one.</p><p>Harel–Koren Fast Multiscaling layout</p><h2 id="Want-to-know-more">Want to know more?</h2><p>This algorithm was published in 1991 by Fruchterman &amp; Reingold<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>. It is a undirected layout and modified from the spring-embedder model and VLSI technique called force-directed placement.</p><p>By this methoud, it is mainly concerned about:</p><ol><li>Distribute the vertices evenly in the frame.</li><li>Minimize edge crossings.</li><li>Make  edge lengths uniform.</li><li>Reflect inherent symmetry.</li><li>Conform to the  frame.</li></ol><ul><li><p>Repulsive forces<br>$<br>f _{rep}(u,v) = \frac{c _{rep}}{||p _v - p _u||^ 2} × \overrightarrow{p _vp _u}<br>$</p></li><li><p>Attractive forces<br>$<br>f _{spring}(u,v) = c _{spring} × log\frac{||p _v - p _u||}{\ell} × \overrightarrow{p _vp _u}<br>$</p></li></ul><p>$<br>f_{attr}(u,v) = f _spring(u,v)-f _{rep}(u,v)<br>$</p><ul><li>Resulting displacement vector<br>$<br>F _u =  \sum _{v \in V} f _{rep}(u, v) + \sum _{uv \in E} f _{attr} (u,v)<br>$</li></ul><p>More Details and example you can find at <a href="https://www.youtube.com/watch?v=JAe7Oscsp98">Philipp Kindermann’s Youtobe Video (2021) </a></p><style>pre {  background-color:#38393d;  color: #5fd381;}</style><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>Fruchterman, Thomas MJ, and Edward M. Reingold. “Graph drawing by force‐directed placement.” Software: Practice and experience 21.11 (1991): 1129-1164. <a href="#fnref1" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">Fruchterman Reingold</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Statistic" scheme="https://karobben.github.io/categories/Notes/Statistic/"/>
    
    <category term="others" scheme="https://karobben.github.io/categories/Notes/Statistic/others/"/>
    
    
    <category term="Statistic" scheme="https://karobben.github.io/tags/Statistic/"/>
    
    <category term="Network" scheme="https://karobben.github.io/tags/Network/"/>
    
  </entry>
  
  <entry>
    <title>Overlap calculation in R</title>
    <link href="https://karobben.github.io/2023/02/14/R/r-overlap/"/>
    <id>https://karobben.github.io/2023/02/14/R/r-overlap/</id>
    <published>2023-02-14T07:25:30.000Z</published>
    <updated>2023-06-06T21:42:32.150Z</updated>
    
    <content type="html"><![CDATA[<h2 id="overlap">overlap</h2><p><code>overlap</code>: The overlap package provides functions to calculate and visualize the overlap of two or more density distributions. The <code>overlapEst</code> function can be used to calculate the overlap of two density distributions, while the <code>overlapPlot</code> function can be used to visualize the overlap.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r">library(overlap)<br>library(ggplot2)<br><br><span class="hljs-comment"># Generate two random lists of numbers</span><br>set.seed(<span class="hljs-number">123</span>)<br>list1 &lt;- rnorm(<span class="hljs-number">100</span>, mean = <span class="hljs-number">5</span>, sd = <span class="hljs-number">1</span>)<br>list2 &lt;- rnorm(<span class="hljs-number">100</span>, mean = <span class="hljs-number">8</span>, sd = <span class="hljs-number">1</span>)<br><br><span class="hljs-comment"># Calculate overlap density</span><br>overlapEst(list1, list2)<br><br>ggplot() + geom_density(aes(list1, fill = <span class="hljs-string">&quot;list1&quot;</span>), alpha = <span class="hljs-number">.5</span>) + <br>  geom_density(aes(list2, fill = <span class="hljs-string">&quot;list2&quot;</span>), alpha = <span class="hljs-number">.5</span>) + theme_bw()<br><br></code></pre></td></tr></table></figure></div><pre>    Dhat1     Dhat4     Dhat5 0.2460298        NA        NA </pre><p><img src="https://s1.ax1x.com/2023/02/14/pSTf79K.png" alt="Density overlapping estimate 1"></p><h2 id="overlapping">overlapping</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r">library(overlapping)<br><br><span class="hljs-comment"># Generate two random lists of numbers</span><br>set.seed(<span class="hljs-number">123</span>)<br>list1 &lt;- rnorm(<span class="hljs-number">100</span>, mean = <span class="hljs-number">5</span>, sd = <span class="hljs-number">1</span>)<br>list2 &lt;- rnorm(<span class="hljs-number">100</span>, mean = <span class="hljs-number">8</span>, sd = <span class="hljs-number">1</span>)<br><br><span class="hljs-comment"># Calculate overlap density</span><br>overlap(<span class="hljs-built_in">list</span>(list1, list2))<br></code></pre></td></tr></table></figure></div><pre>$OV[1] 0.1431085</pre><p>I personally believe that this result is more reliable.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Overlap calculation in R with library overlap and kerndwd</summary>
    
    
    
    <category term="Data" scheme="https://karobben.github.io/categories/Data/"/>
    
    <category term="Statistic" scheme="https://karobben.github.io/categories/Data/Statistic/"/>
    
    
    <category term="R" scheme="https://karobben.github.io/tags/R/"/>
    
    <category term="Data" scheme="https://karobben.github.io/tags/Data/"/>
    
  </entry>
  
  <entry>
    <title>From igraph to ggplot2</title>
    <link href="https://karobben.github.io/2023/02/07/R/igraph-ggplot2/"/>
    <id>https://karobben.github.io/2023/02/07/R/igraph-ggplot2/</id>
    <published>2023-02-07T18:44:28.000Z</published>
    <updated>2023-06-06T21:42:32.150Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Turn-igraph-result-to-ggplot2-plot">Turn igraph result to ggplot2 plot</h2><div class="admonition note"><p class="admonition-title">Why you want to turn igraph network polot to ggplot?</p><ul><li>Flexibility: ggplot is a very flexible and customizable plotting package that allows you to create high-quality, publication-ready plots with a high degree of control over the visual aesthetics of your plots. You can easily modify various aspects of the plot, such as the color, shape, and size of the nodes and edges, and the placement of the labels.</li><li>Integration with igraph: ggplot works seamlessly with igraph, making it easy to create complex and informative visualizations of your network data. You can use ggplot to visualize network data in a variety of ways, including heatmaps, scatterplots, and bar charts.</li><li>Consistency: ggplot provides a consistent grammar for building plots, which makes it easy to create plots with a consistent style and look across different datasets. This can be particularly useful if you are working with multiple datasets and want to create a consistent visual language for your plots.</li><li>Reproducibility: ggplot produces code that can be easily reproduced, making it easier to share and collaborate on your work. You can also easily modify and update your plots as your data or analysis changes.Overall, using ggplot to plot igraph results can help you create informative, visually appealing, and reproducible visualizations of your network data.</li></ul></div><p>Basic idea of this post is from <a href="https://chrischizinski.github.io/rstats/igraph-ggplotll/">© Christopher Chizinski, 2014</a>. It is an old post but all codes work just fine!</p><h2 id="install-igraph">install igraph</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r">install.packages(<span class="hljs-string">&#x27;igraph&#x27;</span>)<br></code></pre></td></tr></table></figure></div><ul><li><p>Errors</p><pre>libopenblas.so.0: cannot open shared object file: No such file or directory</pre><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo apt-get install libopenblas-dev<br></code></pre></td></tr></table></figure></div></li></ul><h2 id="Example-data-for-igraph">Example data for igraph</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r">library(stringr)<br>library(reshape2)<br>library(ggplot2)<br>library(igraph)<br>library(RColorBrewer)<br>library(qgraph)<br>library(ggthemes)<br><br><br><span class="hljs-comment"># data clean</span><br>dataUU &lt;- read.table(<span class="hljs-string">&quot;https://raw.githubusercontent.com/holtzy/data_to_viz/master/Example_dataset/13_AdjacencyUndirectedUnweighted.csv&quot;</span>, header=<span class="hljs-literal">TRUE</span>)<br>TB &lt;- na.omit(melt(dataUU))<br>TB$from &lt;- str_replace_all(TB$from, <span class="hljs-string">&#x27; &#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>)<br><span class="hljs-comment"># width of the edges</span><br>set.seed(<span class="hljs-number">3</span>)<br>TB$value = runif(nrow(TB), <span class="hljs-built_in">min</span>=<span class="hljs-number">0</span>, <span class="hljs-built_in">max</span>=<span class="hljs-number">10</span>)<br><span class="hljs-comment"># size of pointsd</span><br>TB_size &lt;- as.data.frame(table(<span class="hljs-built_in">c</span>(as.matrix(TB[<span class="hljs-number">1</span>:<span class="hljs-number">2</span>]))))<br><br>network=graph_from_data_frame(TB[<span class="hljs-number">1</span>:<span class="hljs-number">2</span>] )<br><br>set.seed(<span class="hljs-number">1</span>)<br>e &lt;- get.edgelist(network,<span class="hljs-built_in">names</span>=<span class="hljs-literal">FALSE</span>)<br>l &lt;- qgraph.layout.fruchtermanreingold(e,vcount=vcount(network),  <br>    area=<span class="hljs-number">30</span>*(vcount(network)^<span class="hljs-number">2</span>), repulse.rad=(vcount(network)^<span class="hljs-number">4</span>))  <br>plot(network,  <br>    layout=l, <br>    vertex.size=<span class="hljs-number">4</span>, vertex.label=<span class="hljs-literal">NA</span>,  <br>    edge.arrow.size= <span class="hljs-number">0</span>, <br>)<br></code></pre></td></tr></table></figure></div><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r"><span class="hljs-comment">## convert the layout to a data.frame</span><br>fr.all.df &lt;- as.data.frame(l)<br><span class="hljs-comment">## add in the species codes</span><br>fr.all.df$species &lt;- V(network)$name<br><span class="hljs-comment">## add size for each nodes</span><br>fr.all.df$size &lt;- TB_size$Freq[match(fr.all.df$species, TB_size$Var1)]<br><br>g &lt;- TB[<span class="hljs-number">1</span>:<span class="hljs-number">2</span>]<br>colnames(g) &lt;-<span class="hljs-built_in">c</span>(<span class="hljs-string">&#x27;from&#x27;</span>, <span class="hljs-string">&#x27;to&#x27;</span>)<br>g$weight = TB[[<span class="hljs-number">3</span>]]<br>g$from.x &lt;- fr.all.df$V1[match(g$from, fr.all.df$species)]  <span class="hljs-comment">#  match the from locations from the node data.frame we previously connected</span><br>g$from.y &lt;- fr.all.df$V2[match(g$from, fr.all.df$species)]<br>g$to.x &lt;- fr.all.df$V1[match(g$to, fr.all.df$species)]  <span class="hljs-comment">#  match the to locations from the node data.frame we previously connected</span><br>g$to.y &lt;- fr.all.df$V2[match(g$to, fr.all.df$species)]<br><br>P &lt;-ggplot() +<br>        geom_segment(data=g,aes(x=from.x,xend = to.x, y=from.y,yend = to.y, size = weight),colour=<span class="hljs-string">&quot;black&quot;</span>, alpha =<span class="hljs-number">.1</span> ) +<br>        geom_point(data=fr.all.df,aes(x=V1,y=V2)) +<br>        geom_text(data=fr.all.df,aes(x=V1,y=V2,label=<span class="hljs-string">&quot;&quot;</span>)) +<br>        theme_map()   + coord_fixed(ratio = <span class="hljs-number">1</span>) + coord_fixed(ratio = <span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://s1.ax1x.com/2023/02/08/pS2NQED.png" alt=""></th><th style="text-align:center"><img src="https://s1.ax1x.com/2023/02/08/pS2N14H.png" alt=""></th></tr></thead><tbody></tbody></table><h2 id="include-size-of-the-dots-and-the-weight-of-edges">include size of the dots and the weight of edges</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="R"><figure class="iseeu highlight /r"><table><tr><td class="code"><pre><code class="hljs r">ggplot() +<br>  geom_segment(data=g,aes(x=from.x,xend = to.x, y=from.y,yend = to.y, size = weight), size = <span class="hljs-built_in">log</span>(g$weight + <span class="hljs-number">1</span>)/<span class="hljs-number">2</span>, colour=<span class="hljs-string">&quot;black&quot;</span>, alpha =<span class="hljs-number">.1</span> ) +<br>  geom_point(data=fr.all.df,aes(x=V1,y=V2, size = size, color = size), alpha = <span class="hljs-number">.8</span>) +<br>  geom_text(data=fr.all.df,aes(x=V1,y=V2,label=<span class="hljs-string">&quot;&quot;</span>)) +<br>  theme_map()   + coord_fixed(ratio = <span class="hljs-number">1</span>) + coord_fixed(ratio = <span class="hljs-number">1</span>) + scale_color_gradient(high = <span class="hljs-string">&#x27;red&#x27;</span>, low = <span class="hljs-string">&#x27;steelblue&#x27;</span>)<br></code></pre></td></tr></table></figure></div><p><img src="https://s1.ax1x.com/2023/02/08/pS2UVIg.png" alt=""></p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Turn igraph result to ggplot2 and more</summary>
    
    
    
    <category term="R" scheme="https://karobben.github.io/categories/R/"/>
    
    <category term="Plot" scheme="https://karobben.github.io/categories/R/Plot/"/>
    
    <category term="GGPLOT" scheme="https://karobben.github.io/categories/R/Plot/GGPLOT/"/>
    
    
    <category term="Network" scheme="https://karobben.github.io/tags/Network/"/>
    
    <category term="ggplot2" scheme="https://karobben.github.io/tags/ggplot2/"/>
    
  </entry>
  
  <entry>
    <title>How to set a static IP address for Linux</title>
    <link href="https://karobben.github.io/2023/01/31/Linux/linux-static-ip/"/>
    <id>https://karobben.github.io/2023/01/31/Linux/linux-static-ip/</id>
    <published>2023-01-31T16:40:12.000Z</published>
    <updated>2023-06-06T21:42:32.142Z</updated>
    
    <content type="html"><![CDATA[<h2 id="How-to-set-a-static-ip-for-Pop-os">How to set a static ip for Pop os</h2><ol><li>Find <code>Gateway</code> and the <code>DNS</code> for your network</li></ol><p><img src="https://s1.ax1x.com/2023/02/01/pS0LD5n.png" alt=""><br>Setting → Network → Check the details of your network.<br>Here, <code>Default Route</code> is the <code>Gateway</code>,<br><code>DNS</code> is the <code>DNS</code></p><ol start="2"><li>Find the Netmask for your network by <code>ifconfig</code></li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">ifconfig<br></code></pre></td></tr></table></figure></div><pre>eno1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500        inet 192.168.3.1  netmask 255.255.255.0  broadcast 192.168.3.255...</pre><ol start="3"><li>fill them in IPv4 setting</li></ol><p>Fill the address you want and rest of other infor you jut get from above.<br>||<img src="https://s1.ax1x.com/2023/02/01/pS0L62V.png" alt=""></p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">How to set a static IP address for Linux</summary>
    
    
    
    <category term="Linux" scheme="https://karobben.github.io/categories/Linux/"/>
    
    <category term="System" scheme="https://karobben.github.io/categories/Linux/System/"/>
    
    
    <category term="Linux" scheme="https://karobben.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>IdTrackerAI</title>
    <link href="https://karobben.github.io/2023/01/24/Bioinfor/idtracker/"/>
    <id>https://karobben.github.io/2023/01/24/Bioinfor/idtracker/</id>
    <published>2023-01-24T22:41:05.000Z</published>
    <updated>2023-06-29T18:26:59.578Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Set-up-Install">Set up/Install</h2><p><a href="https://idtracker.ai/en/latest/user_guide/installation.html">Documentation</a></p><p>how to install correct pytorch and cuda: <a href="https://pytorch.org/get-started/previous-versions/">https://pytorch.org/get-started/previous-versions/</a></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">conda create -y --name idtrackerai python=3.7 Tensorflow=2.0.0 cudatoolkit=11.3.1 pytorch=1.10.0<br>conda activate idtrackerai<br>pip install <span class="hljs-string">&quot;idtrackerai[gui]&quot;</span><br></code></pre></td></tr></table></figure></div><h2 id="General-information-for-utility">General information for utility</h2><p><img src="https://s1.ax1x.com/2023/06/28/pCwm69f.png" alt="IDtracker.AI"></p><p>As shown above, the interface is very user-friendly. It can be divided into six regions:</p><ol><li>Video Load</li><li>Arguments for Tracking</li><li>Arguments for Object Segmentation:<ul><li>Blob Intensity: This represents the threshold of the targets based on the grey value, which ranges from 0 (dark) to 255 (light).</li><li>Blob Area: This is the area of the object, measured in pixels.</li></ul></li><li>Tracking Related Arguments</li><li>Number of Objects and their corresponding sizes: Objects that are significantly larger than others usually indicate occlusion from multiple targets.</li><li>Area to illustrate the segmentation results for the current frame.</li></ol><p>First, we use this interface to select the most appropriate parameters and <code>Save parameters</code> as a **.toml file. Then, we simply need to run the following command:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">idtrackerai --load mix.toml --track<br></code></pre></td></tr></table></figure></div><p>This command will load the parameters from the .toml file and initiate the tracking process.</p><h2 id="Idtracker-Data-analysis">Idtracker Data analysis</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> trajectorytools <span class="hljs-keyword">as</span> tt<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br>trajectories_file_path = <span class="hljs-string">&#x27;trajectories/trajectories_wo_gaps.npy&#x27;</span><br>trajectories_dict = np.load(trajectories_file_path, allow_pickle=<span class="hljs-literal">True</span>).item()<br>trajectories = trajectories_dict[<span class="hljs-string">&#x27;trajectories&#x27;</span>]<br>tr = tt.Trajectories.from_positions(trajectories)<br><br><br>fig, ax_trajectories = plt.subplots(figsize=(<span class="hljs-number">5</span>,<span class="hljs-number">5</span>))<br>frame_range = <span class="hljs-built_in">range</span>(<span class="hljs-number">13883</span>) <br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(tr.number_of_individuals):<br>    ax_trajectories.plot(tr.s[frame_range,i,<span class="hljs-number">0</span>], tr.s[frame_range,i,<span class="hljs-number">1</span>])<br>    ax_trajectories.set_aspect(<span class="hljs-string">&#x27;equal&#x27;</span>,<span class="hljs-string">&#x27;box&#x27;</span>)<br>    ax_trajectories.set_title(<span class="hljs-string">&#x27;Trajectories&#x27;</span>,fontsize=<span class="hljs-number">24</span>)<br>    ax_trajectories.set_xlabel(<span class="hljs-string">&#x27;X (BL)&#x27;</span>,fontsize=<span class="hljs-number">24</span>)<br>    ax_trajectories.set_ylabel(<span class="hljs-string">&#x27;Y (BL)&#x27;</span>,fontsize=<span class="hljs-number">24</span>)<br>fig.savefig(<span class="hljs-string">&quot;trajectory2.png&quot;</span>)<br></code></pre></td></tr></table></figure></div><p><img src="https://s1.ax1x.com/2023/01/25/pSt1TnH.png" alt="Trajectory"></p><p>With video</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> colors<br><br>Palette = [<span class="hljs-string">&quot;#B03D3B&quot;</span>, <span class="hljs-string">&quot;#B86C3D&quot;</span>, <span class="hljs-string">&quot;#BF8040&quot;</span>, <span class="hljs-string">&quot;#ACC144&quot;</span>, <span class="hljs-string">&quot;#78C144&quot;</span>, <span class="hljs-string">&quot;#47C291&quot;</span>, <span class="hljs-string">&quot;#478BC2&quot;</span>, <span class="hljs-string">&quot;#4760C2&quot;</span>, <span class="hljs-string">&quot;#574BC3&quot;</span>, <span class="hljs-string">&quot;#834BC3&quot;</span>, <span class="hljs-string">&quot;#C34BAB&quot;</span>, <span class="hljs-string">&quot;#C14465&quot;</span>, <span class="hljs-string">&quot;#DEB59C&quot;</span>, <span class="hljs-string">&quot;#D7DF9F&quot;</span>, <span class="hljs-string">&quot;#A7DF9F&quot;</span>, <span class="hljs-string">&quot;#9FDFD9&quot;</span>, <span class="hljs-string">&quot;#A3B3E0&quot;</span>, <span class="hljs-string">&quot;#D0A3E0&quot;</span>, <span class="hljs-string">&quot;#E2A7CD&quot;</span>, <span class="hljs-string">&quot;#361712&quot;</span>, <span class="hljs-string">&quot;#1A3913&quot;</span>, <span class="hljs-string">&quot;#132B39&quot;</span>, <span class="hljs-string">&quot;#2D1339&quot;</span>, <span class="hljs-string">&quot;#391330&quot;</span>]<br>Num = <span class="hljs-number">0</span><br><span class="hljs-comment">#V_loc = &#x27;/mnt/Ken_lap/Vlog/upload/promE-GFP/20210622_promE-GFP_C0074_Trim.mp4&#x27;</span><br>V_loc = <span class="hljs-string">&#x27;/mnt/Ken_lap/Vlog/upload/promE-fru-IR-v330035/20220116-promE-v330035-298d-C0379_Trim-2.mp4&#x27;</span><br><span class="hljs-comment">#V_loc = &#x27;/mnt/Ken_lap/Vlog/upload/elav-GS-fru-IR-V330035/20220123C0394_Trim.mp4&#x27;</span><br><br>cap=cv2.VideoCapture(V_loc)<br>fourcc = cv2.VideoWriter_fourcc(*<span class="hljs-string">&#x27;XVID&#x27;</span>)<br>out = cv2.VideoWriter(<span class="hljs-string">&#x27;output.avi&#x27;</span>,fourcc, <span class="hljs-number">30.0</span>, (<span class="hljs-number">1920</span>,<span class="hljs-number">1080</span>))<br><br><span class="hljs-keyword">while</span> (<span class="hljs-literal">True</span>):<br>  ret,frame=cap.read()<br>  <span class="hljs-keyword">for</span> <span class="hljs-built_in">id</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(trajectories[<span class="hljs-number">0</span>])):<br>    XY = np.array(trajectories[Num][<span class="hljs-built_in">id</span>], dtype = <span class="hljs-built_in">int</span>)<br>    C = np.array(colors.to_rgba(Palette[<span class="hljs-built_in">id</span>]))[:-<span class="hljs-number">1</span>] * <span class="hljs-number">225</span><br>    cv2.putText(frame, <span class="hljs-built_in">str</span>(<span class="hljs-built_in">id</span>) ,(XY[<span class="hljs-number">0</span>], XY[<span class="hljs-number">1</span>]), cv2.FONT_HERSHEY_COMPLEX, <span class="hljs-number">1</span>, C, <span class="hljs-number">2</span>)<br><br>  <span class="hljs-comment">#cv2.imshow(&quot;video&quot;,frame)</span><br>  Num +=<span class="hljs-number">1</span> <br>  out.write(frame)<br>  <span class="hljs-comment">#if cv2.waitKey(30)&amp;0xFF==ord(&#x27;q&#x27;):</span><br>  <span class="hljs-comment">#    cv2.destroyAllWindows()</span><br>  <span class="hljs-comment">#    break</span><br><br>out.release()<br></code></pre></td></tr></table></figure></div><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> trajectorytools <span class="hljs-keyword">as</span> tt<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> json<br><br><br>F = <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;data/csv/20220116-promE-v330035-298d-C0379_Trim-2.mp4_.json&quot;</span>, <span class="hljs-string">&#x27;r&#x27;</span>).read()<br>Dict = json.loads(F)<br>trajectories = np.array([[Dict[i][ii][<span class="hljs-string">&#x27;body&#x27;</span>][:<span class="hljs-number">2</span>] <span class="hljs-keyword">for</span> ii <span class="hljs-keyword">in</span> np.sort([ii <span class="hljs-keyword">for</span> ii <span class="hljs-keyword">in</span> Dict[<span class="hljs-string">&#x27;12&#x27;</span>].keys()])] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> Dict.keys()])<br>tr = tt.Trajectories.from_positions(trajectories)<br><br>fig, ax_trajectories = plt.subplots(figsize=(<span class="hljs-number">5</span>,<span class="hljs-number">5</span>))<br>frame_range = <span class="hljs-built_in">range</span>(<span class="hljs-number">30</span>*<span class="hljs-number">30</span>) <br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(tr.number_of_individuals):<br>    ax_trajectories.plot(tr.s[frame_range,i,<span class="hljs-number">0</span>], tr.s[frame_range,i,<span class="hljs-number">1</span>])<br>    ax_trajectories.set_aspect(<span class="hljs-string">&#x27;equal&#x27;</span>,<span class="hljs-string">&#x27;box&#x27;</span>)<br>    ax_trajectories.set_title(<span class="hljs-string">&#x27;Trajectories&#x27;</span>,fontsize=<span class="hljs-number">24</span>)<br>    ax_trajectories.set_xlabel(<span class="hljs-string">&#x27;X (BL)&#x27;</span>,fontsize=<span class="hljs-number">24</span>)<br>    ax_trajectories.set_ylabel(<span class="hljs-string">&#x27;Y (BL)&#x27;</span>,fontsize=<span class="hljs-number">24</span>)<br>    ax_trajectories.set_aspect(<span class="hljs-number">.5</span>)<br><br><br>fig.savefig(<span class="hljs-string">&quot;20220123C0394_Trim_30.png&quot;</span>)<br><br><br><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> colors<br><br>Palette = [<span class="hljs-string">&quot;#B03D3B&quot;</span>, <span class="hljs-string">&quot;#B86C3D&quot;</span>, <span class="hljs-string">&quot;#BF8040&quot;</span>, <span class="hljs-string">&quot;#ACC144&quot;</span>, <span class="hljs-string">&quot;#78C144&quot;</span>, <span class="hljs-string">&quot;#47C291&quot;</span>, <span class="hljs-string">&quot;#478BC2&quot;</span>, <span class="hljs-string">&quot;#4760C2&quot;</span>, <span class="hljs-string">&quot;#574BC3&quot;</span>, <span class="hljs-string">&quot;#834BC3&quot;</span>, <span class="hljs-string">&quot;#C34BAB&quot;</span>, <span class="hljs-string">&quot;#C14465&quot;</span>, <span class="hljs-string">&quot;#DEB59C&quot;</span>, <span class="hljs-string">&quot;#D7DF9F&quot;</span>, <span class="hljs-string">&quot;#A7DF9F&quot;</span>, <span class="hljs-string">&quot;#9FDFD9&quot;</span>, <span class="hljs-string">&quot;#A3B3E0&quot;</span>, <span class="hljs-string">&quot;#D0A3E0&quot;</span>, <span class="hljs-string">&quot;#E2A7CD&quot;</span>, <span class="hljs-string">&quot;#361712&quot;</span>, <span class="hljs-string">&quot;#1A3913&quot;</span>, <span class="hljs-string">&quot;#132B39&quot;</span>, <span class="hljs-string">&quot;#2D1339&quot;</span>, <span class="hljs-string">&quot;#391330&quot;</span>]<br>V_list = &#123;<span class="hljs-string">&quot;20210622_promE-GFP_C0074_Trim.mp4&quot;</span>: <span class="hljs-string">&#x27;/mnt/8A26661926660713/Vlog/upload/promE-GFP/20210622_promE-GFP_C0074_Trim.mp4&#x27;</span>,<br>    <span class="hljs-string">&quot;20220116-promE-v330035-298d-C0379_Trim-2.mp4&quot;</span>: <span class="hljs-string">&#x27;/mnt/8A26661926660713/Vlog/upload/promE-fru-IR-v330035/20220116-promE-v330035-298d-C0379_Trim-2.mp4&#x27;</span>,<br>    <span class="hljs-string">&quot;20220123C0394_Trim.mp4&quot;</span>: <span class="hljs-string">&#x27;/mnt/8A26661926660713/Vlog/upload/elav-GS-fru-IR-V330035/20220123C0394_Trim.mp4&#x27;</span>&#125;<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">Video_output</span>(<span class="hljs-params">Video, V_loc</span>):</span><br>  loc = [i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> os.listdir(<span class="hljs-string">&quot;data/csv&quot;</span>) <span class="hljs-keyword">if</span> Video <span class="hljs-keyword">in</span> i <span class="hljs-keyword">and</span> <span class="hljs-string">&quot;json&quot;</span> <span class="hljs-keyword">in</span> i][<span class="hljs-number">0</span>]<br>  F = <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;data/csv/&quot;</span> + loc , <span class="hljs-string">&#x27;r&#x27;</span>).read()<br>  Dict = json.loads(F)<br>  trajectories = np.array([[Dict[i][ii][<span class="hljs-string">&#x27;body&#x27;</span>][:<span class="hljs-number">2</span>] <span class="hljs-keyword">for</span> ii <span class="hljs-keyword">in</span> np.sort([ii <span class="hljs-keyword">for</span> ii <span class="hljs-keyword">in</span> Dict[<span class="hljs-string">&#x27;12&#x27;</span>].keys()])] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> Dict.keys()])<br>  tr = tt.Trajectories.from_positions(trajectories)<br><br>  Num = <span class="hljs-number">0</span><br>  cap=cv2.VideoCapture(V_loc)<br>  fourcc = cv2.VideoWriter_fourcc(*<span class="hljs-string">&#x27;XVID&#x27;</span>)<br>  out = cv2.VideoWriter(Video + <span class="hljs-string">&quot;_30.avi&quot;</span>, fourcc, <span class="hljs-number">20.0</span>, (<span class="hljs-number">1920</span>,<span class="hljs-number">1080</span>))<br>  <br>  List = []<br>  <span class="hljs-keyword">while</span> Num &lt;= <span class="hljs-number">900</span>:<br>    ret,frame=cap.read()<br>    List += [trajectories[Num]]<br>    List = List[-<span class="hljs-number">100</span>:]<br>    <span class="hljs-keyword">for</span> Trace <span class="hljs-keyword">in</span> List:<br>      <span class="hljs-keyword">for</span> <span class="hljs-built_in">id</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(Trace)):<br>        XY = np.array(Trace[<span class="hljs-built_in">id</span>]  * (<span class="hljs-number">1920</span>, <span class="hljs-number">1080</span>), dtype = <span class="hljs-built_in">int</span>)<br>        C = np.array(colors.to_rgba(Palette[<span class="hljs-built_in">id</span>]))[:-<span class="hljs-number">1</span>] * <span class="hljs-number">225</span><br>        cv2.putText(frame, <span class="hljs-string">&quot;.&quot;</span> ,(XY[<span class="hljs-number">0</span>], XY[<span class="hljs-number">1</span>]), cv2.FONT_HERSHEY_COMPLEX, <span class="hljs-number">1</span>, C, <span class="hljs-number">2</span>)<br><br>    Trace = List[-<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">for</span> <span class="hljs-built_in">id</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(Trace)):<br>      XY = np.array(Trace[<span class="hljs-built_in">id</span>]  * (<span class="hljs-number">1920</span>, <span class="hljs-number">1080</span>), dtype = <span class="hljs-built_in">int</span>)<br>      C = np.array(colors.to_rgba(Palette[<span class="hljs-built_in">id</span>]))[:-<span class="hljs-number">1</span>] * <span class="hljs-number">225</span><br>      cv2.putText(frame, <span class="hljs-built_in">str</span>(<span class="hljs-built_in">id</span>) ,(XY[<span class="hljs-number">0</span>], XY[<span class="hljs-number">1</span>]), cv2.FONT_HERSHEY_COMPLEX, <span class="hljs-number">1</span>, C, <span class="hljs-number">2</span>)<br><br>    cv2.imshow(<span class="hljs-string">&quot;video&quot;</span>,frame)<br>    Num +=<span class="hljs-number">1</span> <br>    out.write(frame)<br>    <span class="hljs-keyword">if</span> cv2.waitKey(<span class="hljs-number">30</span>)&amp;<span class="hljs-number">0xFF</span>==<span class="hljs-built_in">ord</span>(<span class="hljs-string">&#x27;q&#x27;</span>):<br>        cv2.destroyAllWindows()<br>        out.write(frame)<br>        <span class="hljs-keyword">break</span><br>  cv2.destroyAllWindows()<br>  out.write(frame)<br><br><br><br><span class="hljs-keyword">for</span> Video <span class="hljs-keyword">in</span> V_list.keys():<br>    Video_output(Video, V_list[Video])<br></code></pre></td></tr></table></figure></div><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">IdTrackerAI</summary>
    
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Bioinformatics/"/>
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="Machine Learning" scheme="https://karobben.github.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>VS code</title>
    <link href="https://karobben.github.io/2023/01/13/Linux/vscode/"/>
    <id>https://karobben.github.io/2023/01/13/Linux/vscode/</id>
    <published>2023-01-13T20:31:21.000Z</published>
    <updated>2023-06-06T21:42:32.142Z</updated>
    
    <content type="html"><![CDATA[<h2 id="VS-code">VS code</h2><p>I am a loyal Atom user. But Atom has died and I have to move on.</p><h2 id="Hotkeys">Hotkeys</h2><p><a href="https://code.visualstudio.com/shortcuts/keyboard-shortcuts-linux.pdf">Keyboard shortcuts for Linux</a></p><ul><li>Fold all: <code>ctrl+k</code> <code>ctrl+0</code></li><li>Release all: <code>ctrl+k</code> <code>ctrl+j</code></li><li>wrap text: <code>Alt+z</code></li></ul><h2 id="Plugins-List">Plugins List</h2><p><code>ctrl+shift+x</code>  to open and search plugins.</p><ul><li>Markdown Preview Enhance</li><li>R</li><li>Code Spell Checker</li></ul><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">VS code, ide for all</summary>
    
    
    
    <category term="Linux" scheme="https://karobben.github.io/categories/Linux/"/>
    
    <category term="Software" scheme="https://karobben.github.io/categories/Linux/Software/"/>
    
    
    <category term="Linux" scheme="https://karobben.github.io/tags/Linux/"/>
    
    <category term="Software" scheme="https://karobben.github.io/tags/Software/"/>
    
    <category term="IDE" scheme="https://karobben.github.io/tags/IDE/"/>
    
  </entry>
  
</feed>
