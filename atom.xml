<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Karobben</title>
  
  <subtitle>Engjoy~</subtitle>
  <link href="https://karobben.github.io/atom.xml" rel="self"/>
  
  <link href="https://karobben.github.io/"/>
  <updated>2024-02-06T08:40:49.156Z</updated>
  <id>https://karobben.github.io/</id>
  
  <author>
    <name>Karobben</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>FLUORESCENCE SPECTROSCOPY</title>
    <link href="https://karobben.github.io/2024/02/06/LearnNotes/fluorescence/"/>
    <id>https://karobben.github.io/2024/02/06/LearnNotes/fluorescence/</id>
    <published>2024-02-06T07:22:42.000Z</published>
    <updated>2024-02-06T08:40:49.156Z</updated>
    
    <content type="html"><![CDATA[<h2 id="FLUORESCENCE-SPECTROSCOPY">FLUORESCENCE SPECTROSCOPY</h2><div class="admonition note"><p class="admonition-title">What happens after the molecule is excited?</p><p><img src="https://imgur.com/nD2T2sw.png" alt="" />Fluorescence properties depend on what happens to the molecule during the ~10-8 sec during which it is excited</p></div><h3 id="What-are-the-processes-of-non-radiative-decay">What are the processes of non-radiative decay?</h3><table><thead><tr><th style="text-align:center"></th><th style="text-align:left">Unit: sec<sup>-1</sup></th></tr></thead><tbody><tr><td style="text-align:center"><img src="https://imgur.com/uYOhyLM.png" alt=""></td><td style="text-align:left">Black = Non-radiative<br> Red = Radiative (photon)<br> ABS = absorption (10<sup>15</sup>)<br><strong>IC</strong> = internal conversion <br> (k<sub>IC</sub> ≈ 10<sup>11~12</sup>)<br> <strong>Q</strong> = quenching<br><strong>IX</strong>=intersystem crossing<br>S<sub>1</sub>→T<sub>0</sub>: 10<sup>8</sup>; T<sub>1</sub>→S<sub>0</sub>: 10<sup>2</sup><br> <strong>Chem</strong>=photochemistry<br>k<sub>f</sub> ≈ 10<sup>8</sup>; k<sub>p</sub> ≈ 10<sup>2</sup><br> <strong>F</strong> = fluorescence<br> <strong>P</strong> = phosphorescence<br> Trans = energy transfer<br>k<sub>collision</sub> ≈ 10<sup>10</sup> M<sup>-1</sup>sec<sup>-1</sup></td></tr></tbody></table><ul><li>Internal Conversion: energy loss due to collisions with solvent molecules<ul><li>collision rate = k<sub>coll</sub> [solvent]<ul><li>k<sub>coll</sub> ~10<sup>10</sup>M<sup>-1</sup>sec<sup>-1</sup></li><li>[slovent]: 55M for water</li><li>The rate of collision of a single molecule is ≈ 10<sup>11</sup>-10<sup>12</sup>sec<sup>-1</sup></li></ul></li><li><mark>S1-S2</mark>: Heat. Fast IC (10<sup>-11</sup>sec): heat loss to solvent, <strong>all excited molecules are in the lowest vibrational state</strong> of S<sub>1</sub></li><li><mark>S0-S1</mark>: Heat. Slow IC (10<sup>-8</sup>sec): due to larger energy gap, therefore fluorescence is possible.</li></ul></li></ul><div class="admonition note"><p class="admonition-title">What is the concentration of pure water?</p><li> 1 L water = 1000 g<li> water molecule = 18 g/mol<li> So 1 L water = 1000/18 =55 mol<li> [M] = 55 mol/1 L = 55 M</div><h4 id="Solvent-reorganization-and-the-Stokes-Shift">Solvent reorganization and the Stokes Shift</h4><p>Measure fluorescence at fixed λ<sub>ex</sub> as a function of <em><strong>λ<sub>em</sub></strong></em><br><strong>Stokes shift</strong>: Emission spectrum is always red-shifted (lower energy) compared to the absorption spectrum</p><table><thead><tr><th style="text-align:center">Vibrational relaxation</th><th style="text-align:center">Solvent reorganization</th></tr></thead><tbody><tr><td style="text-align:center"><img src="https://chem.libretexts.org/@api/deki/files/79075/%253DScreen_shot_2011-03-14_at_11.08.58_AM.png?revision=1&amp;size=bestfit&amp;width=224&amp;height=274" alt=""></td><td style="text-align:center"><img src="https://upload.wikimedia.org/wikipedia/commons/f/fc/Stokes_shift_diagram.svg" alt=""></td></tr><tr><td style="text-align:center"><a href="https://chem.libretexts.org/Bookshelves/Physical_and_Theoretical_Chemistry_Textbook_Maps/Supplemental_Modules_(Physical_and_Theoretical_Chemistry)/Spectroscopy/Electronic_Spectroscopy/Jablonski_diagram">© libretexts.org</a></td><td style="text-align:center"><a href="https://en.wikipedia.org/wiki/Stokes_shift">© wikipedia</a></td></tr><tr><td style="text-align:center"></td><td style="text-align:center">Franck-Condon Overlap Factors<br>Prob (0’→2’) ≅ Prob (2’←0’) etc</td></tr></tbody></table><p><img src="https://imgur.com/3c7E6y8.png" alt=""></p><p>Absorption: ~ 10<sup>-15</sup> sec<br>Solvent reorganization (relaxation): ~ 10<sup>-10</sup> sec<br>Fluorescence: ~ 10<sup>-8</sup> sec<br>Step 1: Permanent Dipoles of solvent re-orient to adjust to the altered dipole of the excited fluorophore.<br>Step 2: The dipole-dipole interaction in turn stabilizes S1 and destabilizes S0.<br><strong>Requires</strong>:<br>1. solvent polarity (dielectric constant, ε)<br>2. mobility of solvent (reorientation of solvent dipoles)</p><h3 id="How-long-can-a-molecule-stay-in-its-excited-state">How long can a molecule stay in its excited state?</h3><p>Excite some molecules to $ S_1 $ with a brief pulse of light at $ t = 0 $, $ N_0^* $ excited state molecules<br>Decay of the excited state population is exponential: $ \frac{dN^<em>(t)}{dt} = -(k_f + k_{NR})N^</em>(t) $<br>So: $ N^ <em>(t) = N_0^ * e ^ {-(k_f+k_{NR})t} = N_0^ * e^ {-t/\tau} \quad$ where $N^</em> (t)$ is the number of excited molecules at time <em><strong>t</strong></em>.</p><p>Define: lifetime $ \tau $<br>$ \tau = \frac{1}{k_f + k_{NR}} $<br>Hence, the equation for the decay of the excited state population:<br>$ N^<em>(t) = N_0^</em> e^ {-t/\tau} $</p><div class="admonition note"><p class="admonition-title">The meaning of the fluorescence lifetime</p><p><em><strong>τ</strong></em> has units of time (seconds) <br>$[N_ {t=\tau}^ *] = \frac{N_ 0^ *}{e} \approx 0/37N_ 0^ *$<br>After one lifetime following excitation, the probability of a molecule still being in the excited state is about 37%</p></div><h4 id="How-bright-can-a-molecule-be">How bright can a molecule be?</h4><p>Rate up: $S_0 \rightarrow S_1 = I_0$, unit: [# of photons absorbed/sec]<br>Rate down: $S_1 \rightarrow S_0 = -(k_f + k_{NR}) \cdot N^*(t)$<br>Unit: [1/sec][# of photons]</p><p>$N^<em>(t)$ = concentration of excited state molecules at any time, $t$<br>$k_{NR}$ = sum of all non-radiative rate constants<br>$N^</em>(t) = [S_1(t)]$, [# of molecules]</p><p>Steady state: rate up = rate down<br>$0 = \frac{dN^<em>(t)}{dt} = I_0 - (k_f + k_{NR}) N^</em>(t)$</p><p>In the steady state $N^<em>(t)$ is constant $= N^</em><em>{SS}$<br>$I_0 = (k_f + k</em>{NR}) N^*_{SS}$</p><h4 id="Fluorescence-quantum-yield-QY">Fluorescence quantum yield (QY)</h4><p>$Q_f$ (QY): fraction of excited-state molecules that relax to the ground state by emitting a photon.</p><p>photons/sec emitted in steady state</p><p>$Q_f = \frac{k_f N^<em>_{SS}}{I_0} = \frac{k_f N^</em><em>{SS}}{(k_f + k</em>{NR})N^*_{SS}}$</p><p>Since $I_0 = (k_f + k_{NR})N^*_{SS}$</p><p>photons/sec absorbed in steady state</p><p>$Q_f = \frac{k_f}{(k_f + k_{NR})} = k_f \times \tau$</p><p>Recall $\tau = \frac{1}{(k_f + k_{NR})}$</p><h3 id="What-are-the-fluorophores-in-biological-systems">What are the fluorophores in biological systems?</h3><ul><li>Intrinsic Fluorescence of Proteins</li></ul><p>Absorption spectra Fluorescence spectra of amino acids in water “About 300 papers per year abstracted in Biological Abstracts report work that exploits or studies tryptophan (Trp) fluorescence in proteins…”<br>Vivian et al. Biophysical Journal 2001</p><table><thead><tr><th></th><th>Lifetime (nsec)</th><th>Absorption</th><th></th><th>Fluorescence</th><th></th></tr></thead><tbody><tr><td></td><td></td><td>Wavelength (nm)</td><td>Absorptivity (ε, M<sup>-1cm</sup>-1)</td><td>Wavelength (λmax, nm)</td><td>Quantum Yield (25°C)</td></tr><tr><td>Tryptophan</td><td>2.6</td><td>280</td><td>5,600</td><td>348</td><td>0.20</td></tr><tr><td>Tyrosine</td><td>3.6</td><td>274</td><td>1,400</td><td>303</td><td>0.14</td></tr><tr><td>Phenylalanine</td><td>6.4</td><td>257</td><td>200</td><td>282</td><td>0.04</td></tr></tbody></table><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">FLUORESCENCE SPECTROSCOPY</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>SeqKit: A Cross-Platform and Ultrafast Toolkit for FASTA/Q File Manipulation</title>
    <link href="https://karobben.github.io/2024/02/05/Bioinfor/seqkit/"/>
    <id>https://karobben.github.io/2024/02/05/Bioinfor/seqkit/</id>
    <published>2024-02-05T21:00:06.000Z</published>
    <updated>2024-02-06T08:40:49.156Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Install">Install</h2><p>GitHub: <a href="https://github.com/shenwei356/seqkit">shenwei356/seqkit</a></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">wget https://github.com/shenwei356/seqkit/releases/download/v2.7.0/seqkit_linux_amd64.tar.gz<br>tar -zxvf seqkit_linux_amd64.tar.gz<br></code></pre></td></tr></table></figure></div><h3 id="Convert-the-Fastq-to-Fasta">Convert the Fastq to Fasta</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">seqkit fq2fa output_directory/output_prefix.extendedFrags.fastq -o output_directory/output_prefix.merged.fasta<br></code></pre></td></tr></table></figure></div><h3 id="Remove-Duplicated-Sequence">Remove Duplicated Sequence</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash"><br></code></pre></td></tr></table></figure></div><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">SeqKit provides a comprehensive suite of utilities for the efficient and high-throughput processing of FASTA/Q files. This toolkit allows for format conversion, subsequence extraction, quality control, and much more.</summary>
    
    
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="Sequencing" scheme="https://karobben.github.io/tags/Sequencing/"/>
    
    <category term="FASTA/Q" scheme="https://karobben.github.io/tags/FASTA-Q/"/>
    
    <category term="SeqKit" scheme="https://karobben.github.io/tags/SeqKit/"/>
    
  </entry>
  
  <entry>
    <title>Linear Regression</title>
    <link href="https://karobben.github.io/2024/02/05/LearnNotes/ai-linear/"/>
    <id>https://karobben.github.io/2024/02/05/LearnNotes/ai-linear/</id>
    <published>2024-02-05T18:26:13.000Z</published>
    <updated>2024-02-06T08:40:49.156Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Linear-Regression">Linear Regression</h2><h3 id="Vectors-and-Matrix">Vectors and Matrix</h3><p>In numpy, the dot product can be written np.dot(w,x) or w@x.<br>Vectors will always be column vectors. Thus:</p><table><thead><tr><th style="text-align:center"><img src="https://imgur.com/Zq0RMO8.png" alt=""></th><th style="text-align:center"><img src="https://imgur.com/TF5NMbz.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center">Vectors are lowercase bold letters</td><td style="text-align:center">Matrices are uppercase bold letters</td></tr></tbody></table><p>Vector and Matrix Gradients<br>The gradient of a scalar function with respect to a vector or matrix is:<br>The symbol $\frac{\sigma f}{\sigma x_ 1}$ means “partial derivative of f with respect to <em>x<sub>1</sub></em>”</p><table><thead><tr><th style="text-align:center"><img src="https://imgur.com/2b5hSHK.png" alt=""></th></tr></thead><tbody></tbody></table><table><thead><tr><th style="text-align:center"><img src="https://www.researchgate.net/profile/Vladimir-Nasteski/publication/328146111/figure/fig4/AS:702757891751937@1544561946700/Visual-representation-of-the-linear-regression-22.ppm" alt=""></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.researchgate.net/publication/328146111_An_overview_of_the_supervised_machine_learning_methods?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6Il9kaXJlY3QiLCJwYWdlIjoiX2RpcmVjdCJ9fQ">© Vladimir Nasteski</a></td></tr></tbody></table><p>$$ f(x) = w^ T x + b = \sum_{j=0} ^{D-1} w_ j x_ j + b $$</p><ul><li>$f(x) = y$</li><li>Generally, we want to choose the weights and bias, <em>w</em> and <em>b</em>, in order to minimize the errors.</li><li>The errors are the vertical green bars in the figure at right, <em>ε = f(x) − y</em>.</li><li>Some of them are positive, some are negative. What does it mean to “minimize” them?<ul><li>$ f(x) = w^ T x + b = \sum_{j=0} ^{D-1} w_ j x_ j + b $</li></ul></li><li>Training token errors Using that notation, we can define a signed error term for every training token: <em>ε = f(x<sub>i</sub>) - y<sub>i</sub></em></li><li>The error term is positive for some tokens, negative for other tokens. What does it mean to minimize it?</li></ul><h3 id="Mean-squared-error">Mean-squared error</h3><p>Squared: tends to notice the big values and trying ignor small values.</p><p>One useful criterion (not the only useful criterion, but perhaps the most common) of “minimizing the error” is to minimize the mean squared error:<br>$$  \mathcal{L} = \frac{1}{2n} \sum_{i=1}^ {n} \varepsilon_i^ 2 = \frac{1}{2n} \sum_{i=1}^ {n} (f(x_ i) - y_ i)^ 2  $$<br>The factor $\frac{1}{2}$ is included so that, so that when you differentiate ℒ , the 2 and the $\frac{1}{2}$ can cancel each other.</p><div class="admonition note"><p class="admonition-title">MSE = Parabola </p><p>Notice that MSE is a non -negative quadratic function of <em>f(<strong>x</strong>~i~) = <strong>w</strong>^T^ x~i~ + b</em>, therefore it’s a non negative quadratic function of <em><strong>w</strong></em> . Since it’s a non -negative quadratic function of <em><strong>w</strong></em>, it has a unique minimum that you can compute in closed form! We won’t do that today.</p></div><p>$\mathcal{L} = \frac{1}{2n} \sum_{i=1}^ {n} (f(x_ i) - y_ i)^ 2$</p><p><strong>The iterative solution to linear regression</strong> (gradient descent):</p><ul><li>Instead of minimizing MSE in closed form, we’re going to use an iterative algorithm called gradient descent. It works like this:<ul><li>Start: random initial <em><strong>w</strong></em> and <em>b</em> (at <em>t=0</em>)</li><li>Adjust <em><strong>w</strong></em> and <em>b</em> to reduce MSE (<em>t=1</em>)</li><li>Repeat until you reach the optimum (<em>t = ∞</em>).</li></ul></li></ul><p>$ w \leftarrow w - \eta \frac{\partial \mathcal{L}}{\partial w} $<br>$ b \leftarrow b - \eta \frac{\partial \mathcal{L}}{\partial b} $</p><h3 id="Finding-the-gradient">Finding the gradient</h3><p>The loss function ( \mathcal{L} ) is defined as:</p><p>[ \mathcal{L} = \frac{1}{2n} \sum_{i=1}^{n} L_i, \quad L_i = \varepsilon_i^2, \quad \varepsilon_i = w^T x_i + b - y_i ]</p><p>To find the gradient, we use the chain rule of calculus:</p><p>[ \frac{\partial \mathcal{L}}{\partial w} = \frac{1}{2n} \sum_{i=1}^{n} \frac{\partial L_i}{\partial w}, \quad \frac{\partial L_i}{\partial w} = 2\varepsilon_i \frac{\partial \varepsilon_i}{\partial w}, \quad \frac{\partial \varepsilon_i}{\partial w} = x_i ]</p><p>Putting it all together,</p><p>[ \frac{\partial \mathcal{L}}{\partial w} = \frac{1}{n} \sum_{i=1}^{n} \varepsilon_i x_i ]</p><h3 id="The-iterative-solution-to-linear-regression">The iterative solution to linear regression</h3><p>• Start from random initial values of<br>� and � (at � = 0).<br>• Adjust � and � according to:</p><p>[ w \leftarrow w - \frac{\eta}{n} \sum_{i=1}^{n} \varepsilon_i x_i ]<br>[ b \leftarrow b - \frac{\eta}{n} \sum_{i=1}^{n} \varepsilon_i ]</p><ul><li>Intuition:</li><li>Notice the sign:<br>[ w \leftarrow w - \frac{\eta}{n} \sum_{i=1}^{n} \varepsilon_i x_i ]</li><li>If ( \varepsilon_i ) is positive (( f(x_i) &gt; y_i )), then we want to <em>reduce</em> ( f(x_i) ), so we make ( w ) less like ( x_i )</li><li>If ( \varepsilon_i ) is negative (( f(x_i) &lt; y_i )), then we want to <em>increase</em> ( f(x_i) ), so we make ( w ) more like ( x_i )</li></ul><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Linear Regression</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>Learning Progress</title>
    <link href="https://karobben.github.io/2024/02/02/LearnNotes/ai-learning/"/>
    <id>https://karobben.github.io/2024/02/02/LearnNotes/ai-learning/</id>
    <published>2024-02-02T18:58:50.000Z</published>
    <updated>2024-02-03T00:22:19.388Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Learning">Learning</h2><div class="admonition note"><p class="admonition-title">Biological inspiration: Long-term potentiation</p><ol><li>A synapse is repeatedly stimulated<br></li><li>More dendritic receptors<br></li><li>More neurotransmitters<br></li><li>A stronger link between neurons</li></ol></div><ul><li>Mathematical Model this Biological Learning Model:<ul><li><em><strong>X</strong></em> = input signal; <em><strong>f(X)</strong></em> = output signal</li><li><strong>Learning</strong> = adjust the parameters of the learning machine so that <em><strong>f(x)</strong></em> becomes the function we want</li></ul></li><li>Mathematical Model of Supervised Learning<ul><li><em><strong>D = {(x<sub>1</sub>, y<sub>1</sub>), …, (x<sub>n</sub>, y<sub>n</sub>)}</strong></em> = training dataset containing pairs of (example signal <em><strong>x<sub>i</sub></strong></em>, desired system output <em><strong>y<sub>i</sub></strong></em>)</li><li><strong>Supervised Learning</strong> = adjust parameters of the learner to minimize <em><strong>E[ℓ(Y, f(X))]</strong></em></li><li><em><strong>ℓ</strong></em>: loss function</li></ul></li></ul><table><thead><tr><th style="text-align:center"><img src="https://imgur.com/228ikan.png" alt="loss-function"></th></tr></thead><tbody></tbody></table><h3 id="Decision-tree-learning-An-example">Decision tree learning: An example</h3><p>The Titanic sank. You were rescued. You want to know if your friend was also rescued. You can’t find them. Can you use machine learning methods to estimate the probability that your friend survived? (Calculate the possibility of your friend also be rescued)</p><ol><li>Gather data about as many of the passengers as you can.<ul><li>X = variables that describe the passenger, e.g., age, gender, number of siblings on board.</li><li>Y = 1 if the person is known to have survived</li></ul></li><li>Learn a function, f(X), that matches the known data as well as possible</li><li>Apply f(x) to your friend’s facts, to estimate their probability of survival</li></ol><p><strong>Decision-tree learning</strong>*:</p><ul><li>1st branch = variable that best distinguishes between groups with higher vs. lower survival rates (e.g., gender)</li><li>2nd branch = variable that best subdivides the remaining group</li><li>Quit when all people in a group have the same outcome, or when the group is too small to be reliably subdivided.</li></ul><table><thead><tr><th style="text-align:center"><img src="https://upload.wikimedia.org/wikipedia/commons/e/eb/Decision_Tree.jpg" alt="Decision-tree for Titanic"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://en.m.wikipedia.org/wiki/File:Decision_Tree.jpg">© wikipedia</a></td></tr></tbody></table><p>In each leaf node of this tree:</p><ul><li><p>Number on the left = probability of survival</p></li><li><p>Number on the right = percentage of all known cases that are explained by this node</p></li><li><p>A decision tree is an example of a parametric learner</p></li><li><p>The function <em><strong>f(x)</strong></em> is determined by some learned parameters</p></li><li><p>In this case, the parameters are:</p></li><li><p>Should this node split, or not?</p></li><li><p>If so, which tokens go to the right-hand child?</p></li><li><p>If not, what is <em><strong>f(x)</strong></em> at the current node?</p></li><li><p>Titanic shipwreck example:</p><ul><li>Θ = [Y, female, Y, age ≤ 9.5, N, f(x) = 0.73, …]</li></ul></li></ul><div class="admonition note"><p class="admonition-title">A mathematical definition of learning</p><ul><li>Environment: there are two random variables, X and Y, that are jointly distributed according to</li><li><em><strong>P(X,Y)</strong></em></li><li>Data: <em><strong>P(X, Y)</strong></em> is unknown, but we have a sample of training data</li><li><em><strong>D = {(x~1~, y~1~), ..., (x~n~, y~n~)}</strong></em></li><li>Objective: We would like a function � that minimizes the expected value of some loss function, <em><strong>ℓ(Y , f(x))</strong></em> :</li><li><em><strong>ℛ = E[ℓ(Y, f(x))]</strong></em></li><li>Definition of learning: Learning is the task of estimating the function <em><strong>f</strong></em>, given knowledge of <em><strong>D</strong></em>.</li></ul></div><h3 id="Training-vs-Test-Corpora">Training vs. Test Corpora</h3><ul><li><strong>Training Corpus</strong> = a set of data that you use in order to optimize the parameters of your classifier (for example, optimize which features you measure, how you use those features to make decisions, and so on).<ul><li>Measuring the training corpus accuracy is important for debugging: if your training algorithm is working, then training corpus error rate should always go down.</li></ul></li><li><strong>Test Corpus</strong> = a set of data that is non-overlapping with the training set (none of the test tokens are also in the training dataset) that you can use to measure the error rate.<ul><li>Measuring the test corpus error rate is the only way to estimate how your classifier will work on new data (data that you’ve never yet seen)</li></ul></li><li><strong>Training error</strong> is sometimes called “optimization error”. It happens because you haven’t finished optimizing your parameters.</li><li><strong>Test error</strong> = <mark>optimization error + generalization error</mark></li><li><strong>Evaluation Test Corpus</strong> = a dataset that is used only to test the ONE classifier that does best on DevTest. From this corpus, you learn how well your classifier will perform in the real world.</li></ul><h3 id="Early-stopping">Early stopping</h3><ul><li><p><strong>Learning</strong>: Given $\mathcal{D} = {(x_1, y_1), \ldots, (x_n, y_n)}$, find the function $f(X)$ that minimizes some measure of risk.</p></li><li><p><strong>Empirical risk</strong>: a.k.a. training corpus error:</p><ul><li>$R_{\text{emp}} = \frac{1}{n} \sum_{i=1}^{n} \ell(y_i, f(x_i))$</li></ul></li><li><p><strong>True risk</strong>, a.k.a. expected test corpus error:</p><ul><li>$R = \mathbb{E}[\ell(Y, f(X))] = R_{\text{emp}} + R_{\text{generalization}}$</li></ul></li><li><p>Usually, minimum test error and minimum dev error don’t occur at the same time</p></li><li><p>… but early stopping based on the test set is cheating,</p></li><li><p>… so early stopping based on the dev set is the best we can do w/o cheating.</p></li></ul><h2 id="Summary">Summary</h2><ul><li><strong>Biological inspiration</strong>: Neurons that fire together wire together. Given enough training examples <em><strong>(x<sub>i</sub>, y<sub>i</sub>)</strong></em>, can we learn a desired function so that <em><strong>f(x) ≈ y</strong></em>?</li><li><strong>Classification tree</strong>: Learn a sequence of if-then statements that computes <em><strong>f(x) ≈ y</strong></em></li><li><strong>Mathematical definition of supervised learning</strong>: Given a training dataset, <em><strong>D = {(x<sub>1</sub>, y<sub>1</sub>), …, (x<sub>n</sub>, y<sub>n</sub>)}</strong></em> , find a function <em><strong>f</strong></em> that minimizes the risk, <em><strong>ℛ = E[ℓ(Y, f(x))]</strong></em>.</li><li><strong>Overtraining</strong>: $ℛ_ {emp} = \frac{1}{n} \sum^n_{i=1} ℓ*y_i, f(x_i))$ reaches zero if you train long enough.</li><li><strong>Early Stopping</strong>: Stop when error rate on the dev set reaches a minimum</li></ul><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Learning Progress</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>Naive Bayes and Bayes NetWork</title>
    <link href="https://karobben.github.io/2024/02/01/LearnNotes/bayes/"/>
    <id>https://karobben.github.io/2024/02/01/LearnNotes/bayes/</id>
    <published>2024-02-02T05:20:50.000Z</published>
    <updated>2024-02-03T00:22:19.388Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Naive-Bayes">Naïve Bayes</h2><div class="admonition note"><p class="admonition-title">The problem with likelihood: Too many words</p><p>What does it mean to say that the words, x, have a particular probability?<br>Suppose our training corpus contains two sample emails:<br></p><ul><li>Email1: Y = spam, X =&quot;Hi there man – feel the vitality! Nice meeting you…&quot;<br></li><li>Email2: Y = ham, X =&quot;This needs to be in production by early afternoon…&quot;<br></li></ul><p>Our test corpus is just one email:<br></p><ul><li>Email1: X=&quot;Hi! You can receive within days an approved prescription for increased vitality and stamina&quot;<br>How can we estimate P(X=&quot;Hi! You can receive within days an approved prescription for increased vitality and stamina&quot;|Y = spam)?<br></li></ul></div><p>One thing we could do is:</p><ol><li>$P(W = \text{“hi”} | Y = \text{spam}), P(W = \text{“hi”} | Y = \text{ham})$</li><li>$P(W = \text{“vitality”} | Y = \text{spam}), P(W = \text{“vitality”} | Y = \text{ham})$</li><li>$P(W = \text{“production”} | Y = \text{spam}), P(W = \text{“production”} | Y = \text{ham})$</li></ol><p>Then the approximation formula for $P(X | Y)$ is given by:</p><p>$$ P(X = x | Y = y) \approx \prod_{i=1}^{n} P(W = w_i | Y = y) $$</p><p>In this context, $W$ represents a word in a document, $X$ represents the document itself, $Y$ represents the class (spam or ham), $w_i$ represents the $i$-th word in the document, and $n$ is the total number of words in the document. The product is taken over all words in the document, assuming that the words are conditionally independent of each other given the class label $Y$.</p><div class="admonition question"><p class="admonition-title">Why naïve Bayes is naïve?</p><p>We call this model &quot;naïve Bayes&quot; because the words aren't really conditionally independent given the label. For example, the sequence &quot;for you&quot; is more common in spam emails than it would be if the words &quot;for&quot; and &quot;you&quot; were conditionally independent.<br><strong>True Statement</strong>:<br></p><ul><li><em><strong>P(X = for you|Y= Spam &gt; P( W = for |Y = Spam)(P = you |= Spam)</strong></em><br>The naïve Bayes approximation simply says: estimating the likelihood of every word sequence is too hard, so for computational reasons, we'll pretend that sequence probability doesn't matter.<br></li></ul><p><strong>Naïve Bayes Approximation</strong>:<br></p><ul><li><em><strong>P(X = for you |Y = Spam) ≈ P(W = for |Y = Spam)P( W= you |Y= Spam)</strong></em><br>We use naïve Bayes a lot because, even though we know it's wrong, it gives us computationally efficient algorithms that work remarkably well in practice.</li></ul></div><ul><li>Floating-point underflow<br>That equation has a computational issue. Suppose that the probability of any given word is roughly <em><strong>P(W = W<sub>i</sub>|Y = y) ≈ 10<sup>-3</sup></strong></em>, and suppose that there are 103 words in an email. Then <em><strong>∏<sup>n</sup><sub>i=1</sub> P(W = W<sub>i</sub>|Y = y) = 10<sup>-309</sup></strong></em>,which gets rounded off to zero. This phenomenon is called “floating-point underflow”.</li><li>Solution<br>$f(x) = \underset{y}{\mathrm{argmax}} \left( \ln P(Y = y) + \sum^n_{i=1} \ln P(W = w_i | Y = y) \right)$</li></ul><h3 id="Reducing-the-naivety-of-naive-Bayes">Reducing the naivety of naïve Bayes</h3><p>Remember that the bag-of-words model is unable to represent this fact:</p><ul><li><p><strong>True Statement</strong>:</p><ul><li><em><strong>P(X = for you|Y= Spam &gt; P( W = for |Y = Spam)(P = you |= Spam)</strong></em><br>Though the bag-of-words model can’t represent that fact, we can represent it using a slightly more sophisticated naïve Bayes model, called a “bigram” model.</li></ul></li><li><p>N-Grams:</p><ul><li>Unigram: a unigram (1-gram) is an isolated word, e.g., “you”</li><li>Bigram: a bigram (2-gram) is a pair of words, e.g., “for you”</li><li>Trigram: a trigram (3-gram) is a triplet of words, e.g., “prescription for you”</li><li>4-gram: a 4-gram is a 4-tuple of words, e.g., “approved prescription for you”</li></ul></li></ul><div class="admonition note"><p class="admonition-title">Bigram naïve Bayes</p><p>A bigram naïve Bayes model approximates the bigrams as conditionally independent, instead of the unigrams. For example,<br><em><strong>P(X = “approved prescription for you” | Y= Spam) ≈</strong></em><br><em><strong>P(B = “approved prescription” |Y = Spam) ×</strong></em><br><em><strong>P(B = “prescription for” | Y= Spam) ×</strong></em><br><em><strong>P(B = “for you” |Y = Spam)</strong></em></p></div><ul><li>The naïve Bayes model has two types of parameters:<ul><li>The a priori parameters: <em><strong>P(Y = y)</strong></em></li><li>The likelihood parameters: <em><strong>P(W = w<sub>i</sub>| Y = y)</strong></em></li></ul></li><li>In order to create a naïve Bayes classifiers, we must somehow estimate the numerical values of those parameters.</li><li>Model parameters: feature likelihoods <em><strong>P(Word | Class)</strong></em> and priors <em><strong>P(Class)</strong></em></li></ul><h3 id="Parameter-estimation-Prior">Parameter estimation: Prior</h3><p>The prior, <em><strong>P(x)</strong></em>, is usually estimated in one of two ways.</p><ul><li>If we believe that the test corpus is like the training corpus, then we just use frequencies in the training corpus:<br>$$<br>P(Y = Spam) = \frac{Docs(Y=Spam)}{Docs(Y=Spam) + Docs(Y \neq Spam)}<br>$$<br>where <em><strong>Docs(Y=Spam)</strong></em> means the number of documents in the training corpus that have the label Y=Spam.</li><li>If we believe that the test corpus is different from the training corpus, then we set <em><strong>P(Y = Spam)</strong></em> = the frequency with which we believe spam will occur in the test corpus.</li></ul><h3 id="Parameter-estimation-Likelihood">Parameter estimation: Likelihood</h3><p>The likelihood, ***P(W = w<sub>i</sub>|Y = y), is also estimated by counting. The “maximum likelihood estimate of the likelihood parameter” is the most intuitively obvious estimate:<br>$$<br>P(W=w_i| Y = Spam) = \frac{Count(W=w_i, Y = Spam)}{Count(Y = Spam)}<br>$$<br>where <em><strong>Count(W=w<sub>i</sub>, Y = Spam)</strong></em> means the number of times that the word <em><strong>w<sub>i</sub></strong></em> occurs in the Spam portion of the training corpus, and <em><strong>Count(Y = Spam)</strong></em> is the total number of words in the Spam portion.</p><h3 id="Laplace-Smoothing-for-Naive-Bayes">Laplace Smoothing for Naïve Bayes</h3><p>One of the biggest challenge for Bayes is it can’t handle unobserved situation.</p><ul><li><p>The basic idea: add $k$ “unobserved observations” to the count of every unigram</p><ul><li>If a word occurs 2000 times in the training data, Count = 2000+k</li><li>If a word occur once in training data, Count = 1+k</li><li>If a word never occurs in the training data, then it gets a pseudo-Count of $k$</li></ul></li><li><p>Estimated probability of a word that occurred Count(w) times in the training data:<br>$$ P(W = w) = \frac{k + \text{Count}(W = w)}{k + \sum_v (k + \text{Count}(W = v))} $$</p></li><li><p>Estimated probability of a word that never occurred in the training data (an “out of vocabulary” or OOV word):<br>$$ P(W = \text{OOV}) = \frac{k}{k + \sum_v (k + \text{Count}(W = v))} $$</p></li><li><p>Notice that<br>$$ P(W = \text{OOV}) + \sum_w P(W = w) = 1 $$</p></li></ul><h2 id="Bayesian-Networks">Bayesian Networks</h2><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Naive Bayes and Bayes NetWork</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>OPTICAL SPECTROSCOPY – THE ABSORPTION PROCESS</title>
    <link href="https://karobben.github.io/2024/01/30/LearnNotes/absorption/"/>
    <id>https://karobben.github.io/2024/01/30/LearnNotes/absorption/</id>
    <published>2024-01-31T05:37:02.000Z</published>
    <updated>2024-02-06T08:40:49.156Z</updated>
    
    <content type="html"><![CDATA[<h2 id="OPTICAL-SPECTROSCOPY-–-THE-ABSORPTION-PROCESS">OPTICAL SPECTROSCOPY – THE ABSORPTION PROCESS</h2><table><thead><tr><th style="text-align:center"><img src="https://upload.wikimedia.org/wikipedia/commons/1/14/EM_Spectrum_Properties_%28Amplitude_Corrected%2C_Bitmap%29.png" alt="Eelctromagenetic spectrum"></th></tr></thead><tbody><tr><td style="text-align:center">© wiki</td></tr></tbody></table><ul><li>Small wavelength; High frequency; Blue end of the visible spectrum</li><li>Long wavelength; Low frequency; Red end of the visible spectrum</li><li>Energy of visible light is about 100-500 kJ/mol</li></ul><h2 id="Beer’s-Law-and-Absorbance">Beer’s Law and Absorbance</h2><p>$$<br>\frac{I}{I_ 0} = 10^ {-\frac{kc(\Delta y)}{2.303}} = 10^ {- \epsilon c (\Delta y)} = 10^ {-A}<br>$$</p><table><thead><tr><th style="text-align:center"><img src="https://imgur.com/66fOitE.png" alt="Beer’s Law"></th><th style="text-align:left"><mark>Define of absorbance</mark>: <li> $ A = \epsilon c (\Delta y)$ or $A=\epsilon c l $<li> <em><strong>ε</strong></em>: Molar extinction coefficient<li> <em><strong>c</strong></em>: concentration in <em><strong>M</strong></em><li> <em><strong>Δy</strong></em>: path length in <em><strong>cm</strong></em> (some place use <em><strong>l</strong></em> as <em><strong>Δy</strong></em>)</th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://imamagnets.com/en/blog/the-beer-lambert-law/">© imamagnets</a></td><td style="text-align:left"></td></tr></tbody></table><div class="admonition note"><p class="admonition-title">Application of Absorbance</p><p>Use UV-Vis absorbance to calculate the concentration of the molecules like DNA, protein, etc.</p><p>$A=\epsilon (\lambda) c l$</p></div><table><thead><tr><th>Molecule</th><th>λ (nm)</th><th>ε (×10<sup>-3</sup>) (M<sup>-1</sup>cm<sup>-1</sup>)</th></tr></thead><tbody><tr><td>Adenine</td><td>260.5</td><td>13.4</td></tr><tr><td>Adenosine</td><td>259.5</td><td>14.9</td></tr><tr><td>NADH</td><td>340, 259</td><td>6.23, 14.4</td></tr><tr><td>NAD+</td><td>260</td><td>18</td></tr><tr><td>FAD</td><td>450</td><td>11.2</td></tr><tr><td>Tryptophan</td><td>280, 219</td><td>5.6, 47</td></tr><tr><td>Tyrosine</td><td>274,222,193</td><td>1.4, 8, 48</td></tr><tr><td>Phenylalanine</td><td>257, 206, 188</td><td>0.2, 9.3, 60</td></tr><tr><td>Histidine</td><td>211</td><td>5.9</td></tr><tr><td>Cysteine</td><td>250</td><td>0.3</td></tr></tbody></table><h2 id="Quantum-Mechanical-Transition-Probability">Quantum Mechanical Transition Probability</h2><p><img src="https://imgur.com/63nZqbL.png" alt="Transition Probability"></p><p>The probability per unit time that a molecule in state 1 will end up in state 2 in the presence of an oscillating electromagnetic field at the resonance frequency<br><mark>Energy of the light = Difference between energy levels</mark></p><p>$$<br>Rate_ {1 → 2} = B_ {12} \rho (\nu)[S_ 1]<br>$$</p><ul><li><em><strong>B<sub>12</sub></strong></em>: rate constant</li><li><em><strong>ρ(ν)</strong></em>: radiation field density</li><li><em><strong>S<sub>1</sub></strong></em>: Concentration of molecules in the ground state</li></ul><div class="admonition note"><p class="admonition-title">Rate constant dependents on the transition dipole moment </p><p>$B_{12} \propto \langle \mu \rangle^2$<br>$\langle \mu \rangle = \int \Psi_2 (q_e\vec{r})\Psi dV$<br>Transition dipole moment:<br>$\langle \mu \rangle \propto$ overlap between $\Psi_1$ and $\Psi_2$<br></p></div><h3 id="Dipole-approximation">Dipole approximation</h3><p>When a light wave hit hydrogen atom, the <em><strong>r</strong></em> from the atom into electron is far smaller than the <em><strong>λ</strong></em>.</p><ul><li>$\because r &lt;&lt; \lambda$</li><li>$\vec{\mu} = - q\vec{r}$</li><li>$Energy = -\vec{\mu}\cdot\vec{E}$<ul><li>$\vec{\mu}$: matter</li><li>$\vec{E}$: Electric Field (amplitude of light)</li></ul></li></ul><table><thead><tr><th style="text-align:center"><img src="https://i.stack.imgur.com/Dmk1Z.png" alt="Transition of the Dipole"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://chemistry.stackexchange.com/questions/90956/are-there-any-simple-molecules-with-very-different-absorption-and-emission-dip">© Sentry</a></td></tr><tr><td style="text-align:center">The transition dipole reflects the change of electron distribution by excitation</td></tr></tbody></table><table><thead><tr><th style="text-align:center"><img src="https://upload.wikimedia.org/wikipedia/commons/e/e0/StationaryStatesAnimation.gif" alt="Transition of the Dipole"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://en.wikipedia.org/wiki/Transition_dipole_moment">© wikipedia</a></td></tr><tr><td style="text-align:center">Transition dipole moment</td></tr></tbody></table><h3 id="Overlap-of-wavefunctions-and-transition-probability">Overlap of wavefunctions and transition probability</h3><p>$$\mu_{mn} = \int_{-\infty}^{\infty} \Psi_n^* \left( \sum_{i=1}^{N} q_e \vec{r}_i \right) \Psi_m , dr $$</p><p>Where:</p><ul><li>$N$: Number of electrons in a molecule</li><li>$\vec{r}_i$: Position of each electron</li><li>$q_e$: electron charge</li><li>$\Psi_n$: Excited state (or final state) molecular wave function</li><li>$\Psi_m$: Ground state (or initial state) molecular wave function</li></ul><p>Note: each molecular wavefunction depends on the position of BOTH Nucleus AND electron but for now, let’s focus on electron wavefunction (i.e. no structural change of molecular structure or atom position).<br>Larger overlap of initial and final state wavefunctions means higher transition probability, which generates higher extinction coefficient (Fermi’s golden rule).</p><p><strong>Wavefunction overlap:</strong> Larger wavefunction overlap of initial and final state means higher transition probability, which generates higher extinction coefficient (Fermi’s golden rule).</p><p><strong>Orbital Symmetry:</strong></p><p>$\int_{-\infty}^{\infty} f(r ) , dr = 0 \quad \text{if} \quad f(r )$ is an odd function; i.e., $f(-x) = -f(x)$<br>$\int_{-\infty}^{\infty} f(r ) , dr \neq 0 \quad \text{if} \quad f(r )$ is an even function; i.e., $f(-x) = f(x)$</p><p>So: $\Psi_n^* \tilde{\Psi}_m$ must be an even function;<br>or: $\Psi_n^* \Psi_m$ must be an odd function (e.g., } $\pi$ and $\pi^ *$ state</p><h3 id="Dipole-strength-and-Oscillator-strength">Dipole strength and Oscillator strength</h3><p>Traditional ways to quantify the “strength of a transition”</p><p><strong>Dipole strength</strong>: $D_{mn} = |\mu_{mn}|^2 = 9.18 \times 10^{-3} \int \left( \frac{\varepsilon}{\nu} \right) d\nu $<br><strong>Oscillator strength</strong>: $f_{mn} = 4.315 \times 10^{-9} \int \varepsilon(\nu) d\nu $<br>Area under the spectrum associated with the <em><strong>m→n</strong></em> transition</p><p>$ f_{mn} \approx 0.1-1 $ Strong absorption (heme, chlorophyll, organic dyes)<br>$ f_{mn} \approx 10^{-5} $ Weak absorption</p><h3 id="Kuhn-Thomas-sum-rule-for-oscillator-strengths">Kuhn-Thomas sum rule for oscillator strengths</h3><p>In any molecule with N electrons the sum of the oscillator strengths from any one state to all of the other states is equal to the sum of the electrons<br>$$<br>\sum_j f_{ij} = N<br>$$</p><p>This means that <strong>the area underneath the absorption spectrum is a constant</strong> (ground state is the initial state).<br>If a molecule is perturbed (change environments) then if one transition goes down, another must go up.</p><div class="admonition note"><p class="admonition-title">Every transition is associated with a transition dipole</p><p>The transition dipole is a vector:</p><ul><li>Direction: point in the direction of the electron displacement</li><li>Amplitude: Strength of the absorption.</li></ul></div><h3 id="Possible-transitions-in-UV-Vis-light-range">Possible transitions in UV-Vis light range</h3><table><thead><tr><th style="text-align:center"><img src="http://www.chem.ucla.edu/~bacher/UV-vis/electronic_energy_diagram.jpg" alt=""></th><th style="text-align:center"><img src="http://www.chem.ucla.edu/~bacher/UV-vis/UV_vis_tetracyclone.jpg" alt=""></th></tr></thead><tbody></tbody></table><p><a href="http://www.chem.ucla.edu/~bacher/UV-vis/uv_vis_tetracyclone.html.html">© ucla.edu</a></p><p><em><strong>σ→σ<sup>*</sup></strong></em> often requires absorption of photons higher than the UV- vis range (200-700 nm).</p><h3 id="What-determines-the-probability-of-a-transition-strength-of-the-absorption-band">What determines the probability of a transition? (strength of the absorption band)</h3><ol><li>Orbital overlap (wavefunction)<br>π →π * Large overlap, more likely to happen, strong absorption<br>n →π * Small overlap, weak absorption</li><li>Spin multiplicity<br>Electrons prefer not to change its intrinsic spin direction after absorption.</li></ol><p><img src="https://imgur.com/zDYufIq.png" alt=""></p><h3 id="Effective-light-matter-interaction">Effective light-matter interaction</h3><p><img src="https://imgur.com/xIpNElQ.png" alt=""></p><ul><li><p><strong>Transition Rate:</strong><br>$$ Rate_{1 \rightarrow 2} = B_{12} \rho(\nu) [S_1]$$<br>Radiation field density</p></li><li><p><strong>Component of the Electric Field:</strong><br>$$ E_{\parallel} = |\vec{E}| \cos \theta$$</p></li><li><p><strong>Density of States:</strong><br>$$ \rho(\nu) \propto |E_{\parallel}|^2 = |\vec{E}|^2 \cos^2 \theta$$</p></li></ul><h3 id="Effective-light-matter-interaction-v2">Effective light-matter interaction</h3><p>The density of states $\rho(\nu)$ is proportional to the square of the parallel component of the electric field:</p><p>$$ \rho(\nu) \propto |E_{\parallel}|^2 = |\vec{E}|^2 \cos^2 \theta$$</p><p>This relationship is depicted through diagrams that illustrate the electric field vector $\vec{E}$ relative to the molecular transition dipole moment $\vec{\mu}$. The alignment of $\vec{E}$ with $\vec{\mu}$ affects the absorption, with maximum absorption when they are parallel and zero absorption when they are perpendicular. This is exemplified by the molecular orientations of adenine shown in the image.</p><h3 id="Absorption-emission-and-stimulated-emission">Absorption, emission, and stimulated emission</h3><p>The rates of absorption, emission, and stimulated emission can be described by the following equations:</p><table><thead><tr><th style="text-align:left">Rates</th><th style="text-align:left">Equetion</th></tr></thead><tbody><tr><td style="text-align:left"><strong>Absorption Rate</strong></td><td style="text-align:left">$ Rate_{abs} = B_{12} \rho(\nu) [S_1] $</td></tr><tr><td style="text-align:left"><strong>Emission Rate</strong></td><td style="text-align:left">$ Rate_{emi} = -A_{21} [S_2] $</td></tr><tr><td style="text-align:left"><strong>Stimulated Emission Rate</strong></td><td style="text-align:left">$ Rate_{se} = -B_{21} \rho(\nu) [S_2] $</td></tr></tbody></table><p>At steady state, the rate of upward transitions (absorption) equals the rate of downward transitions (emission and stimulated emission):<br>$$ B_{12} \rho(\nu) [S_1] = A_{21} [S_2] + B_{21} \rho(\nu) [S_2] $$</p><p><mark>A<sub>21</sub>, B<sub>12</sub>, and B<sub>21</sub> are called Einstein coefficients.</mark></p><p><img src="https://imgur.com/xLU05Eh.png" alt=""></p><p>It can be shown that:</p><ol><li>B<sub>12</sub>=B<sub>21</sub></li><li>$\frac{A_ {21}}{B_ {21}} = \frac{16\pi^ 2 \hbar \nu^ 3}{c^ 3}$</li></ol><p>Faster spontaneous emission at higher Frequency</p><p>In a typical UV-Vis spectroscopy (electronic transitions)</p><p><strong>Conditions:</strong> $ A \gg B \rho(\nu) $<br><strong>Einstein coefficients relationships:</strong> $ B_{12} \rho(\nu) [S_1] = A_{21} [S_2] + B_{21} \rho(\nu) [S_2] \approx A_{21} [S_2] $<br><strong>Approximations:</strong> $ \frac{B_{12} \rho(\nu)}{A_{21}} \frac{[S_2]}{[S_1]} \ll 1 $<br><strong>Population of states:</strong> $ [S_2] \ll [S_1] $<br>The population of the excited state never builds up to a significant amount.</p><p>laser requires stimulated emission rate constant, i.e. B21, to be much larger than the spontaneous emission rate constant, i.e. A21.<br>So, UV laser is harder to make than visible light laser</p><h2 id="Boltzmann-Distribution">Boltzmann Distribution</h2><p>The probability $P_i$ of a system being in a state i with energy $E_i$ at temperature T is given by:</p><p>$$ P_i = \frac{e^{-\frac{E_i}{k_B T}}}{\sum_{i=0}^{M} e^{-\frac{E_i}{k_B T}}} = \frac{e^{-\frac{E_i}{k_B T}}}{Q} $$</p><p>Where:</p><ul><li>$Q$: Partition function</li><li>$E_i$: Energy of the ith state</li><li>$k_B$: Boltzmann constant $= 1.38 \times 10^{-23} J/K$</li><li>$T$: Temperature (K)</li></ul><p>The ratio of probabilities between two states i and j is given by:</p><p>$$ \frac{P_i}{P_j} = e^{-\frac{(E_i - E_j)}{k_B T}} = e^{-\frac{\Delta E}{k_B T}} $$</p><h3 id="Quantum-Mechanical-Harmonic-Oscillator">Quantum Mechanical Harmonic Oscillator</h3><table><thead><tr><th style="text-align:center"><img src="https://www.researchgate.net/profile/Mauricio-Palafox/publication/277716088/figure/fig6/AS:651496681140224@1532340321204/Light-behaves-in-exactly-the-same-way-as-a-quantum-harmonic-oscillator-and-has-the-same.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.researchgate.net/publication/277716088_Spectra_and_structure_of_benzonitriles_and_some_of_its_simple_derivatives_Spectra_and_structure_of_benzonitriles_and_some_of_its_simple_derivatives?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6Il9kaXJlY3QiLCJwYWdlIjoiX2RpcmVjdCJ9fQ">© Mauricio Alcolea Palafox</a></td></tr></tbody></table><table><thead><tr><th style="text-align:center"><img src="https://www.researchgate.net/profile/Anas-Al-Rabadi/publication/228529042/figure/fig3/AS:393722123571205@1470882077644/Harmonic-oscillator-HO-potential-and-wavefunctions-a-wavefunctions-for-various.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.researchgate.net/figure/Harmonic-oscillator-HO-potential-and-wavefunctions-a-wavefunctions-for-various_fig3_228529042">© Anas Al-Rabadi</a> The panel left: wave funciton, the panel right: porbability of finding a nuclei</td></tr></tbody></table><ul><li>Solve the time-independent Schrödinger Equation (for the nucleus) with<ul><li>$ V(x) = \frac{1}{2}kx^2 $</li></ul></li><li>The time-independent Schrödinger Equation is:<ul><li>$ -\frac{\hbar^2}{2m} \frac{d^ 2\Psi(x)}{dx^2} + V(x)\Psi(x) = E\Psi(x) $</li></ul></li><li>We get a set of wave functions and a set of energies:<ul><li>$ \Psi_n(x) \quad$ (set of wave functions)</li><li>$ E_n \quad $ (set of energies)</li></ul></li><li>For a <mark>harmonic oscillator potential</mark>, the energy levels are given by:<ul><li>$ E_n = \left(n + \frac{1}{2}\right)\hbar\omega $</li><li>$ \omega_0 = \sqrt{\frac{k}{m_r}} = 2\pi\nu_0 $<br>where $ n = 0,1,2,3,\ldots $</li></ul></li></ul><table><thead><tr><th style="text-align:center"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/0e/Franck-Condon-diagram.png/800px-Franck-Condon-diagram.png" alt=""></th><th style="text-align:center"><img src="https://api.oe1.com/upload/2023/06/1_638205815647121689-20230606104546661.jpg" alt=""></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://en.wikipedia.org/wiki/Deslandres_table">© wikipedia</a> Vibrational energy of the nuclei on top of electronic energy</td><td style="text-align:center"><a href="https://www.oe1.com/article/7071678131478081536.html">© oe1.com</a> Jablonski energy diagram</td></tr></tbody></table><p><mark>VERTICAL TRANSITION</mark>: consider the nuclei to remain in the same place during an electronic transition.<br>At thermal equilibrium, most molecules will be in the lowest vibrational state</p><h3 id="Franck-Condon-factor-nuclear">Franck-Condon factor (nuclear)</h3><p>The total wavefunction $\Psi(r, R)$ is a product of the electronic $\Psi_{el}(r, R)$ and nuclear $\Psi_{nuc}®$ wavefunctions:</p><p>$$ \Psi(r, R) = \Psi_{el}(r, R)\Psi_{nuc}( R) $$</p><ul><li><code>electrons</code> refers to $\Psi_{el}(r, R)$</li><li><code>nuclei</code> refers to $\Psi_{nuc}(R )$</li></ul><p>Transition from vibrational level i of the ground electronic state to the vibrational level j of the exited electronic state is given by:</p><p>$$ \vec{\mu}_ {g \rightarrow ex,j} = \left( \vec{\mu}_ {g \rightarrow ex} \right) \int \Psi_ {nuc(j)}^* \Psi_ {nuc(i)} dR $$</p><ul><li>The electron transition dipole moment $\vec{\mu}_{g \rightarrow ex}$ represents the <code>Electron transition dipole moment</code>.</li><li>Rest of the integral represents the <code>Nuclear overlap Factor</code>, also known as the Franck-Condon factor.</li></ul><table><thead><tr><th style="text-align:center">Vibrational structure and the Franck- Condon principle: vertical transitions</th></tr></thead><tbody><tr><td style="text-align:center"><img src="https://imgur.com/tykLmAg.png" alt=""></td></tr></tbody></table><h3 id="Spectroscopic-broadening">Spectroscopic broadening</h3><h4 id="Intrinsic">Intrinsic</h4><table><thead><tr><th>Column1</th><th>Column2</th><th>Column3</th></tr></thead><tbody><tr><td>Vibrational Structure</td><td><img src="https://imgur.com/pmgO3tQ.png" alt=""></td><td><img src="https://imgur.com/eEq28Js.png" alt=""></td></tr><tr><td>Overlapping Electronic Bands</td><td><img src="https://imgur.com/g55mveQ.png" alt=""></td><td><img src="https://imgur.com/WxAS0gX.png" alt=""></td></tr></tbody></table><h4 id="Environment-solvent-effect">Environment: solvent effect</h4><p><img src="https://imgur.com/UzP9Z1j.png" alt=""></p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center"><li>25% λ1 (state 1)<li> 50% λ2 (state 2)<li> 25% λ3 (state 3)</td><td style="text-align:center"><img src="https://imgur.com/FIuq6xu.png" alt=""></td></tr></tbody></table><h3 id="Solvent-effects-on-the-absorption-spectrum-of-anisole">Solvent effects on the absorption spectrum of anisole</h3><table><thead><tr><th style="text-align:center"><img src="https://psiberg.com/wp-content/uploads/2021/09/chromophoric-shift-path.svg" alt="Hypochromic shift"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://psiberg.com/uv-vis-spectroscopy">© PSIBERG Team</a></td></tr></tbody></table><p><img src="https://imgur.com/eU4ljWs.png" alt=""></p><p>to left: Bathochromic or <mark>Red shift</mark><br>to right: Hypsochromic or <mark>Blue shift</mark><br>The nature of the changes are not always simple to predict.</p><div class="admonition note"><p class="admonition-title">How does the solvent influence the ground and excited states?</p><ol><li>SOLVENT POLARITY: permanent dipole of the solvent molecules measured by the static dielectric constant. <em><strong>ε~r~</strong></em></li><li>SOLVENT POLARIZABILITY: electron polarizability measured by index of refraction. <em><strong>n</strong></em></li><li>Hydrogen bonding (protic vs. aprotic solvent)</li></ol></div><p><img src="https://imgur.com/q6g0Azf.png" alt=""></p><div class="admonition note"><p class="admonition-title">More on the dielectric constant</p></div><p><strong>Material 1</strong>: High <em><strong>ε<sub>r</sub></strong></em>, therefore higher ability to cancel out (stabilize) the original source charge<br><strong>Material 2</strong>: Low <em><strong>ε<sub>r</sub></strong></em>, The ability to insulate charge or The ability to stabilize charges</p><p>The relative permittivity $\varepsilon_r$ as a function of frequency $\omega$ is given by:</p><p>$$ \varepsilon_r(\omega) = \frac{\varepsilon(\omega)}{\varepsilon_0} $$</p><p>Where:</p><ul><li>$\varepsilon_0$: vacuum permittivity (= 1.0)</li><li>$\varepsilon$: material’s absolute permittivity</li><li>$\varepsilon_r$: relative permittivity or dielectric constant</li></ul><p>Examples of relative permittivity for different materials:</p><ul><li>$\varepsilon_r$ (styrofoam) = 1.03</li><li>$\varepsilon_r$ (dry wood) = 1.4 - 2.9</li><li>$\varepsilon_r$ = 20</li></ul><p>Relative permittivity values for various solvents:</p><table><thead><tr><th>Solvent</th><th>Hexane</th><th>Ether</th><th>Ethanol</th><th>Methanol</th><th>Water</th></tr></thead><tbody><tr><td>$\varepsilon_r$</td><td>2</td><td>4.3</td><td>25.8</td><td>31</td><td>81</td></tr></tbody></table><p>Small value means it is non-polar solvent. Large value means it is a polar solvent.</p><h3 id="Polar-effects-on-transitions-between-molecular-orbitals">Polar effects on transitions between molecular orbitals</h3><table><thead><tr><th style="text-align:center"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0030402617306472-gr9_lrg.jpg" alt=""></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.sciencedirect.com/science/article/pii/S0030402617306472#fig0045">© Vaishali Gupta</a></td></tr></tbody></table><table><thead><tr><th>Compound</th><th>λ(nm)</th><th>Intensity/ε</th><th>Transition with lowest energy</th></tr></thead><tbody><tr><td>CH₄</td><td>122</td><td>intense</td><td>σ→σ* (C-H)</td></tr><tr><td>CH₃CH₃</td><td>130</td><td>intense</td><td>σ→σ* (C-C)</td></tr><tr><td>CH₃OH</td><td>183</td><td>200</td><td>n→σ* (C-O)</td></tr><tr><td>CH₃SH</td><td>235</td><td>180</td><td>n→σ* (C-S)</td></tr><tr><td>CH₃NH₂</td><td>210</td><td>800</td><td>n→σ* (C-N)</td></tr><tr><td>CH₃Cl</td><td>173</td><td>200</td><td>n→σ* (C-Cl)</td></tr><tr><td>CH₃I</td><td>258</td><td>380</td><td>n→σ* (C-I)</td></tr><tr><td>CH₂=CH₂</td><td>165</td><td>16000</td><td>π→π* (C=C)</td></tr><tr><td>CH₃COCH₃</td><td>187</td><td>950</td><td>π→π* (C=O)</td></tr><tr><td>CH₃COCH₃</td><td>273</td><td>14</td><td>n→π* (C=O)</td></tr><tr><td>CH₃CSCl₃</td><td>460</td><td>weak</td><td>n→π* (C=S)</td></tr><tr><td>CH₃N=NCCH₃</td><td>347</td><td>15</td><td>n→π* (N=N)</td></tr></tbody></table><h3 id="Polarity-effect-on-π-π-transitions">Polarity effect on π-π* transitions</h3><p><strong>Typical π-π<sup>*</sup> transitions</strong>: the dipole gets larger in the same direction<br>More stabilization, energy increases; <em><strong>high solvent polarity results in a RED SHIFT (of the absorption peak)</strong></em>.<br><img src="https://imgur.com/gvx01OG.png" alt=""><br>In a more polar state: More stabilization, energy increases; high solvent polarity results in a RED SHIFT (of the absorption peak).</p><p><strong>Typical n-π<sup>*</sup> transitions</strong>: the dipole of the chromophore <strong>gets smaller</strong> or shifts direction after excitation.<br><img src="https://imgur.com/OIis4vS.png" alt=""><br>Less stabilization, energy increases; <strong>high solvent polarity</strong> results in a <strong>BLUE SHIFT (of the absorption peak)</strong></p><h3 id="Example-spectral-shifts-of-mesityl-oxide">Example: spectral shifts of mesityl oxide</h3><table><thead><tr><th style="text-align:center"><img src="https://upload.wikimedia.org/wikipedia/commons/d/d8/Mesityl_oxide.png" alt="Mesityl oxide"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://en.wikipedia.org/wiki/Mesityl_oxide">© wikipedia</a></td></tr></tbody></table><p>The solvent effects on the absorption maxima (λmax) for the π→π* and n→π* transitions in acetone:</p><table><thead><tr><th>solvent</th><th>Static dielectric constant</th><th>λmax (nm) π→π* (Red shift)</th><th>λmax (nm) n→π* (Blue shift)</th></tr></thead><tbody><tr><td>Hexane</td><td>2</td><td>229.5</td><td>327</td></tr><tr><td>Ether</td><td>4.3</td><td>230</td><td>326</td></tr><tr><td>Ethanol</td><td>25.8</td><td>237</td><td>315</td></tr><tr><td>Methanol</td><td>31</td><td>238</td><td>312</td></tr><tr><td>Water</td><td>81</td><td>244.5</td><td>305</td></tr></tbody></table><ul><li><mark>Red shift</mark> indicates a lower energy transition as the dielectric constant increases.</li><li><mark>Blue shift</mark> indicates a higher energy transition as the dielectric constant decreases.</li></ul><p>The transitions are characterized by their molar absorptivities (ε):</p><ul><li>n→π*: ε = 40M⁻¹cm⁻¹</li><li>π→π*: ε = 12,600M⁻¹cm⁻¹</li></ul><h3 id="Indol-Tryptophan-π-π-transitions">Indol (Tryptophan) π-π* transitions</h3><table><thead><tr><th style="text-align:center"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S1386142506001314-gr1.jpg" alt=""></th><th style="text-align:center"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S1386142506001314-gr3.gif" alt=""></th></tr></thead><tbody></tbody></table><p><a href="https://www.sciencedirect.com/science/article/pii/S1386142506001314?via%3Dihub">© Neera Sharma</a><br><em><strong>L<sub>a</sub></strong></em>: large excited state dipole (lower energy state)<br><em><strong>L<sub>b</sub></strong></em>: Smaller excited state dipole</p><h3 id="Solvent-polarizability-measured-by-the-index-of-refraction">Solvent polarizability measured by the index of refraction</h3><p>dipole is induced in the solvent by the dipole of the chromophore (ground state and excited state)<br>No nuclear movement involved. Purely due to electrons</p><p><img src="https://imgur.com/qK3vQLw.png" alt=""><br>ground state dipole ( ← )<br>excited state (↑)<br>induced dipoles in solvent ( ← )</p><h3 id="Some-values-of-solvent-index-of-refraction">Some values of solvent index of refraction</h3><table><thead><tr><th style="text-align:left">solvent</th><th style="text-align:center">Index of refraction</th></tr></thead><tbody><tr><td style="text-align:left">Perfluoropentane</td><td style="text-align:center">1.239</td></tr><tr><td style="text-align:left">Water</td><td style="text-align:center">1.333</td></tr><tr><td style="text-align:left">Ethanol</td><td style="text-align:center">1.362</td></tr><tr><td style="text-align:left">Iso-octane</td><td style="text-align:center">1.392</td></tr><tr><td style="text-align:left">Chloroform</td><td style="text-align:center">1.446</td></tr><tr><td style="text-align:left">Carbontetrachloride</td><td style="text-align:center">1.463</td></tr></tbody></table><p>Note that water is less polarizable than iso-octane although clearly water is a much more polar solvent (larger dielectric constant)</p><h3 id="Influence-on-the-energy-levels-of-π-n-π-orbitals-by-solvent-polarizability">Influence on the energy levels of π, n, π* orbitals by solvent polarizability</h3><p><img src="https://imgur.com/g0UTFzH.png" alt=""></p><ul><li>π - π* transitions: red shift in more polarizable solvent<br>π* interacts with solvent dipoles more strongly than π</li><li>n - π* transitions: blue shift in more polarizable solvent<br>n interacts with solvent dipoles more strongly than π*</li></ul><h3 id="Solvent-can-influence-the-energy-of-both-the-ground-and-the-excited-states">Solvent can influence the energy of both the ground and the excited states</h3><p><img src="https://imgur.com/WPrGRUi.png" alt=""></p><h3 id="Rhodopsin-a-protein-“solvent”-effect-on-the-absorption-spectrum-of-retinal">Rhodopsin: a protein “solvent” effect on the absorption spectrum of retinal</h3><table><thead><tr><th style="text-align:center"></th><th style="text-align:left"></th></tr></thead><tbody><tr><td style="text-align:center"><img src="https://imgur.com/fwb7LLC.png" alt=""></td><td style="text-align:left">vision is due to same pigment proteins in <strong><mark>rod</mark></strong> and <strong><mark>cone</mark></strong> cells:<li> λmax = 500 nm (rod cell)<li> λmax = 414 nm (blue cone)<li> λmax = 533 nm (green cone)<li> λmax = 560 nm (red cone) <br><br> Same chromophore: 11-cis retinal <br> “spectral tuning” by interaction with amino acid residues nearby</td></tr></tbody></table><table><thead><tr><th style="text-align:center"></th><th style="text-align:left"></th></tr></thead><tbody><tr><td style="text-align:center"><img src="https://imgur.com/zpUcJAg.png" alt=""></td><td style="text-align:left"><li>WT: 500 nm<li> G90S: 487 nm<li> T118A: 484 nm<li> E122D: 477 nm<li> A292S: 489 nm<li> A295S: 498 nm<li> T/E/A triple mutant: 453 nm</td></tr></tbody></table><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">OPTICAL SPECTROSCOPY – THE ABSORPTION PROCESS</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>Artificial Intelligent 1</title>
    <link href="https://karobben.github.io/2024/01/26/LearnNotes/AI1/"/>
    <id>https://karobben.github.io/2024/01/26/LearnNotes/AI1/</id>
    <published>2024-01-26T07:22:21.000Z</published>
    <updated>2024-02-02T17:06:57.293Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Random-Variable">Random Variable</h2><p>Probability:</p><ul><li>Exp1: $Pr(A) &gt; 0$ which means that A has non-negative probability.</li><li>Exp2: $Pr(A) = 1$ means when event A occurs, the probability is 1.</li><li>Exp3: $Pr(A \cap B) = Pr(A) × Pr(B)$ when events A and B are independent.</li></ul><div class="admonition question"><p class="admonition-title">What is <b>Random Variable</b>?</p><ul><li>We use <b>capital letters</b> to denote the random variable</li><li>We use a small letter to denote a particular outcome of the experiment</li></ul></div><p>$P(X=x)$ means the probability of the occurs for value x. Here $P(X=x)$ is a <mark>number</mark>, the $P(X)$ is a distribution.</p><div class="admonition note"><p class="admonition-title">Example </p><p>Event = [Cloud, Cloud, Rain]In this Weather event P(X), it the probability of:</p><ul><li>Cloud: $P(X=Cloud) = \frac{2}{3}$.</li><li>Rain: $P(X=Rain) = \frac{1}{3}$</li><li>Sun:  $P(X=sun) = 0$</li></ul></div><p>The random variable we used in the example above is <mark>Discrete</mark> random variable, but sometimes we have to use continues random variable. For example: $X \in R$ (the set of all positive real numbers)</p><p>Because we have two types of random variable, the function for calculating the sun of all possible variables are different:</p><ul><li><strong>Probability Mass Function</strong> (pmf): For discrete random variable<ul><li>If <em>X</em> is a <strong>discrete random variable</strong>, then <em>P(X)</em> is its <strong>probability mass function (pmf)</strong>.</li><li>A probability mass is just a probability. <em>P(X=x) = Pr(X=x)</em> is the just the probability of the outcome <em>X = x</em> Thus:</li><li>$0 \leqslant P(X=x)$</li><li>$ 1 = \sum _x{P(X=x)}$</li></ul></li><li><strong>Probability Density Function</strong> (pdf):<ul><li>If <em>X</em> is a <strong>density random variable</strong>, then <em>P(x)</em> is its <strong>probability density function (pdf)</strong>.</li><li>A probability density is NOT a probability. Instead, we define it as a density $P(X=x) = \frac{d}{dx} Pr(X \leqslant x)$</li><li>$0 \leqslant P(X=x)$</li><li>$ 1 = \int_{-\infty}^\infty {P (X=x)dx}$</li></ul></li></ul><h3 id="Jointly-Random-Variables">Jointly Random Variables</h3><ul><li>Two or three random variables are “jointly random” if they are both outcomes of the same experiment.</li><li>For example, here are the temperature (Y, in °C), and precipitation (X, symbolic) for six days in Urbana:</li></ul><table><thead><tr><th>Date</th><th>X=Temperature (°C)</th><th>Y=Precipitation</th></tr></thead><tbody><tr><td>January 11</td><td>4</td><td>cloud</td></tr><tr><td>January 12</td><td>1</td><td>cloud</td></tr><tr><td>January 13</td><td>-2</td><td>snow</td></tr><tr><td>January 14</td><td>-3</td><td>cloud</td></tr><tr><td>January 15</td><td>-3</td><td>clear</td></tr><tr><td>January 16</td><td>4</td><td>rain</td></tr></tbody></table><p>For this table, we could have joint random variables <em>P(X=x, Y=y)</em>:</p><table><thead><tr><th>P(X=x,Y=y)</th><th>snow</th><th>rain</th><th>cloud</th><th>clear</th></tr></thead><tbody><tr><td>-3</td><td>0</td><td>0</td><td>1/6</td><td>1/6</td></tr><tr><td>-2</td><td>1/6</td><td>0</td><td>0</td><td>0</td></tr><tr><td>1</td><td>0</td><td>0</td><td>1/6</td><td>0</td></tr><tr><td>4</td><td>0</td><td>1/6</td><td>1/6</td><td>0</td></tr></tbody></table><h4 id="Notation-Vectors-and-Matrices">Notation: Vectors and Matrices</h4><ul><li>A normal-font capital letter (<em>X</em>) is a random variable, which is a function mapping from the outcome of an experiment to a measurement</li><li>A normal-font small letter (<em>x</em>) is a scalar instance</li><li>A boldface small letter (<em><strong>x</strong></em>) is a vector instance</li><li>A boldface capital letter (<em><strong>X</strong></em>) is a matrix instance</li></ul><p><em>P(X=<strong>x</strong>)</em> is the probability that random variable <em>X</em> takes the value of the vector <em><strong>x</strong></em>. This is just a shorthand for the joint distribution of <em>x<sub>1</sub>, x<sub>2</sub>, …, x<sub>n</sub></em></p><table><thead><tr><th style="text-align:center"><img src="https://imgur.com/FRHL0fI.png" alt="vector x"></th></tr></thead><tbody></tbody></table><table><thead><tr><th style="text-align:center"><img src="https://imgur.com/ihgeuXc.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center">When <em><strong>X</strong></em> is a random matrix</td></tr></tbody></table><h3 id="Marginal-Distributions">Marginal Distributions</h3><p>Suppose we know the joint distribution <em>P(X,Y)</em>. We want to find the two <strong>marginal distributions</strong> <em>P(X)</em>:</p><ul><li>If the unwanted variable is discrete, we marginalize by adding:<ul><li>$P(X) = \sum_ y P(X,Y=y)$</li></ul></li><li>If the unwanted variable is continuous, we marginalize by integrating:<ul><li>$P(X) = \int P(X,Y=y)$</li></ul></li></ul><p>Backing the table above, we could know that the marginal distributions of:</p><ul><li><em>P(X)</em> = 1/6 + 1/6 = 1/3; 1/6; 1/6; 1/6 + 1/6 = 1/3</li><li><em>P(Y)</em> = 1/6; 1/6; 1/6 + 1/6 + 1/6 = 1/2; 1/6</li></ul><p>PS: Some place also write <em>P(X)</em> as <em>P<sub>X</sub>(X)</em> or <em>P<sub>X</sub>(i)</em> and <em>P(Y)</em> as <em>P<sub>Y</sub>(Y)</em> or <em>P<sub>Y</sub>(j)</em>.</p><h3 id="Joint-and-Conditional-distributions">Joint and Conditional distributions</h3><p>With the joint possibility and marginal possibility, we could now calculating the Joint and Conditional distributions, which is <em>P(Y|X)</em></p><ul><li><em>P(Y|X)</em> is the probability (or pdf) that <em>Y = y</em> happens, given that <em>X = x</em> happens, over all <em>x</em> and <em>y</em>. This is called the <strong>conditional distribution</strong> of <em>Y</em> given <em>X</em>.</li><li><em>P(X|Y)</em> is the conditional probability distribution of outcomes <em>P(X=x|Y=y)</em></li><li>The conditional is the joint divided by the marginal:<ul><li>$P(X=x|Y=y) = \frac{P(X = x, Y = y)}{P(Y= y)}$</li></ul></li></ul><div class="admonition note"><p class="admonition-title">Exp of Joint and Conditional Distribution *P(X|Y = cloud)*</p><p>$P(X|Y=could) = \frac{P(X, Y = y)}{P(Y = cloud)}$</p><p>$=\frac{\frac{1}{6}\ \ 0\ \ \frac{1}{6}\ \ \frac{1}{6}}{\frac{1}{2}}$</p><p>So, the result is a vector = {1/3, 0, 1/3, 1/3}</p></div><p>According to the example, we could know that: <mark>Joint = Conditional×Marginal</mark>; which is:<br>$$<br>P(X,Y) = P(X|Y)P(Y)<br>$$</p><h3 id="Independent-Random-Variables">Independent Random Variables</h3><ul><li>Two random variables are said to be independent, which means <em>P(X|Y) = P(X)</em><br>In other words, knowing the value of <em>Y</em> tells you nothing about the value of <em>X</em>.</li><li>According to this, we can also know:<ul><li>$\because$ <em>P(X,Y) = P(X|Y)P(Y)</em></li><li>$\therefore$ <em>P(X,Y) = P(X)P(Y)</em></li></ul></li><li><em>Pr(A⋀B) = Pr(A)Pr(B)</em></li></ul><h3 id="Expectation">Expectation</h3><p>The expected value of a function is its weighted average, weighted by its pmf or pdf.</p><ul><li>For discrete X and Y:<br>$ E[f(X, Y)] = \sum_{x,y} f(x, y)P(X = x, Y = y) $</li><li>If X is continuous:<br>$ E[f(X, Y)] = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} f(x, y)P(X = x, Y = y) ,dx,dy $</li></ul><h3 id="Covariance">Covariance</h3><p>The covariance of two random variables is the expected product of their deviations:</p><p><strong>Covar(X,Y) = E[(X- E[X])(Y-E[Y])]</strong></p><p>Covariance Matrix:<br>Suppose <em>X = [X<sub>1</sub>, … , X<sub>n</sub>]</em> is a random vector. Its matrix of variances and covariances (a.k.a. covariance matrix) is</p><table><thead><tr><th style="text-align:center"><img src="https://imgur.com/AHw4vkP.png" alt="Covariance Matrix"></th></tr></thead><tbody></tbody></table><h2 id="Decision-Theory">Decision Theory</h2><ul><li>Suppose we have an experiment with two random variables, X and Y.<ul><li>X is something we can observe, like the words in an email.</li><li>Y is something we can’t observe, but we want to know. For example, Y=1 means the email is spam (junk mail), Y=0 means it’s ham (desirable mail).</li></ul></li><li>Can we train an AI to read the email, and determine whether it’s spam or not?</li></ul><p>In this case, we have:</p><ul><li><em>Y</em> = the correct label<ul><li><em>Y</em> = the correct label as a random variable (“in general”)</li><li><em>y</em> = the label observed in a particular experiment (“in particular”)</li></ul></li><li><em>f(X)</em> = the decision that we make, after observing the datum, <em>X</em>.<ul><li><em>f(X)</em> = the function applied to random variable <em>X</em> (“in general”)</li><li><em>f(x)</em> = the function applied to a particular value of <em>x</em> (“in particular”)</li></ul></li></ul><h3 id="Deciding-how-to-Decide-Loss-and-Risk">Deciding how to Decide: Loss and Risk</h3><ul><li><p>Suppose that deciding $f(x)$, when the correct label is $Y = y$, costs us a certain amount of money (or prestige, or safety, or points, or whatever) – call that the loss, $L(f(x), y)$</p></li><li><p>In general, we would like to lose as few points as possible (negative losses are good…)</p></li><li><p>Define the risk, $R(f)$, to be the expected loss incurred by using the decision rule $f(X)$:</p></li></ul><p>$$ R(f) = E[L(f(X), Y)] = \sum_y \sum_x L(f(x), y)P(X = x, Y = y) $$</p><h3 id="Minimum-Risk-Decisions">Minimum-Risk Decisions</h3><ul><li>If we want to the smallest average loss (the smallest risk), then our<br>decision rule should be<br><em><strong>f = argmin R(f)</strong></em></li><li>In other words, for each possible <em>x</em>, we find the value of <em>f(x)</em> that minimizes our expected loss given that <em>x</em>, and that is the <em>f(x)</em> that our algorithm should produce.</li></ul><h4 id="Zero-One-Loss">Zero-One Loss</h4><p>Suppose that $f(x)$ is an estimate of the correct label, and</p><ul><li>We lose one point if $f(x) \neq y$</li><li>We lose zero points if $f(x) = y$</li></ul><p>Then the loss function $L(f(x), y)$ is defined as:</p><table><thead><tr><th style="text-align:center"><img src="https://imgur.com/y5yAXn9.png" alt="Zero-One Loss"></th></tr></thead><tbody></tbody></table><p>Then the risk is</p><p>$$ R(f) = E[L(f(X), Y)] = Pr(f(X) \neq Y) $$</p><h4 id="Minimum-Probability-of-Error">Minimum Probability of Error</h4><p>We can minimize the probability of error by designing <em><strong>f(x)</strong></em> so that <em><strong>f(x) = 1</strong></em> when <em><strong>Y= 1</strong></em> is more probable, and <em><strong>f(x) = 0</strong></em> when <em><strong>Y= 0</strong></em> is more probable.</p><table><thead><tr><th style="text-align:center"><img src="https://imgur.com/qFXNGic.png" alt="Minimum Probability of Error"></th></tr></thead><tbody></tbody></table><h3 id="The-Bayesian-Scenario">The Bayesian Scenario</h3><table><thead><tr><th style="text-align:center"><img src="https://upload.wikimedia.org/wikipedia/commons/d/d4/Thomas_Bayes.gif" alt="Bayes"></th></tr></thead><tbody><tr><td style="text-align:center">[© wikipedia]</td></tr></tbody></table><ul><li>Let’s use <em><strong>x~X</strong></em> to mean that <em><strong>x</strong></em> is an instance of random variable <em><strong>X</strong></em>, and similarly <em><strong>y~Y</strong></em>.</li><li>In order to minimize the probability of error, we just need to know <em><strong>P(Y = y|X = x)</strong></em> for every pair of values <em><strong>x~X</strong></em> and<br><em><strong>y~Y</strong></em>. Then we choose $f(x) = \underset{y}{argmaxP}(Y = y|X = x)$.</li></ul><h4 id="Example-spam-detection">Example: spam detection</h4><div class="admonition question"><p class="admonition-title"> how can we estimate the P(Y=y|X=x)?</p><ul><li>The prior probability of spam might be obvious. If 80% of all email on the internet is spam, that means that<em><strong>P(Y=1)=0.8, P(Y=0)=0.2</strong></em><br></li><li>The probability of X given Y is also easy. Suppose we have a database full of sample emails, some known to be spam, some known to be ham. We count how often any word occurs in spam vs. ham emails, and estimate:<br></li></ul><ol><li><em><strong>P(X=x|Y=1)=</strong></em> frequency of the words <em><strong>x</strong></em> in emails known to be spam<br></li><li><em><strong>P(X=x|Y=0)=</strong></em> frequency of the words <em><strong>x</strong></em> in emails known to be ham<br></li></ol><ul><li>Now we have <em><strong>P( X=x|Y=y)</strong></em> and <em><strong>P(Y=y)</strong></em> . How do we get <em><strong>P(Y=y|X=x)</strong></em><br>For solve this problem, Bayes come with an idea: <strong>Bayes' Rule</strong><br>$P(Y=y|X=x) = \frac{P(X=x, Y=y)}{P(X=x)}$<br>$\frac{P(X=x|Y=y)P(Y=y)}{P(X=x)}$</li></ul></div><h3 id="The-four-Bayesian-probabilities">The four Bayesian probabilities</h3><p>$$<br>P(Y=y|X=x) =\frac{P(X=x|Y=y)P(Y=y)}{P(X=x)}<br>$$</p><p>This equation shows the relationship among four probabilities. This equation has become so world-famous, since 1763, that these four probabilities have standard universally recognized names that you need to know:</p><ul><li><em><strong>P(Y=y|X=x)</strong></em> is the a <strong>posteriori</strong> (after-the-fact) probability, or <strong>posterior</strong></li><li><em><strong>P(Y=y)</strong></em> is the <strong>a priori</strong> (before-the-fact) probability, or <strong>prior</strong></li><li><em><strong>P(X=x|Y=y)</strong></em> is the <strong>likelihood</strong></li><li><em><strong>P(X=x)</strong></em> is the <strong>evidence</strong><br>Bayes’ rule: the posterior equals the prior times the likelihood over the evidence.</li></ul><h4 id="MPE-MAP">MPE = MAP</h4><ul><li>The “minimum probability of error” (MPE) decision rule is the rule that chooses <em><strong>f(X)</strong></em> in order to minimize the probability of error:<ul><li><em><strong>f(x) = argmin P(Error|X = x)</strong></em></li></ul></li><li>The “maximum a posteriori” (MAP) decision rule is the rule that chooses <em><strong>f(x)</strong></em> in order to maximize the posteriori probability:<ul><li><em><strong>f(x) = argmin P(Y = f(x)|X = x)</strong></em></li></ul></li><li>Those two decision rules are the same: <strong>MPE = MAP</strong></li></ul><p>Using Bayes’ Rule:</p><ul><li><p>MPE = MAP: to minimize the probability of error, design f(X) so that:<br>$f(x) = \underset{y}{argmaxP}(Y = y|X = x)$</p></li><li><p>Bayes’ Rule<br>$P(Y=y|X=x) =\frac{P(X=x|Y=y)P(Y=y)}{P(X=x)}$</p></li><li><p>Putting the two together:<br>$f(x) = \underset{y}{argmaxP}\frac{P(X=x|Y=y)P(Y=y)}{P(X=x)}$<br>$\ \ \ =\underset{y}{argmaxP}(X=x|Y=y)P(Y=y)$</p></li><li><p>Accuracy<br>When we train a classifier, the metric that we usually report is “accuracy”<br>$Accuracy = \frac{n tokens\ correctly\ classified}{n\ tokens\ total}$</p></li><li><p>Error Rate<br>Equivalently, we could report error rate, which is just 1-accuracy:<br>$Error Rate = \frac{n\ tokens\ incorrectly\ classified}{n\ tokens\ total}$</p></li><li><p>Bayes Error Rate<br>The “Bayes Error Rate” is the smallest possible error rate of any classifier with labels “y” and features “x”:<br>$Error Rate = \sum_x P(X=x)\underset{y}{min} P(Y \neq y |x=x)$<br>It’s called the “Bayes error rate” because it’s the error rate of the Bayesian classifier</p></li></ul><h2 id="The-problem-with-accuracy">The problem with accuracy</h2><ul><li>In most real-world problems, there is one class label that is much more frequent than all others.<ul><li>Words: most words are nouns</li><li>Animals: most animals are insects</li></ul></li><li>Disease: most people are healthy</li><li>It is therefore easy to get a very high accuracy. All you need to do is write a program that completely ignores its input, and always guesses the majority class. The accuracy of this classifier is called the “chance accuracy.”</li><li>It is sometimes very hard to beat the chance accuracy. If chance=90%, and your classifier gets 89% accuracy, is that good, or bad?</li></ul><p>The solution: <mark>Confusion Matrix</mark>:<br>Confusion Matrix =<br>• <em><strong>(m, n)<sup>th</sup></strong></em> element is the number of tokens of the <em><strong>m<sup>th</sup></strong></em> class that were labeled, by the classifier, as belonging to the <em><strong>n<sup>th</sup></strong></em> class.</p><table><thead><tr><th style="text-align:center"><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/04/Basic-Confusion-matrix.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.analyticsvidhya.com/blog/2020/04/confusion-matrix-machine-learning/">© Aniruddha Bhandari</a></td></tr></tbody></table><div class="admonition note"><p class="admonition-title">Confusion matrix for a binary classifier</p><ul><li>Suppose that the correct label is either 0 or 1. Then the confusion matrix is just 2x2.<br></li><li>For example, in this box, you would write the # tokens of class 1 that were misclassified as class 0<br></li><li>Than, you got TP (True Positives), FN (False Negatives), FP (False Positives), and TN (True Negative)<br></li><li>The binary confusion matrix is standard in many fields, but different fields summarize its content in different ways.<br></li><li>In medicine, it is summarized using Sensitivity and Specificity.</li><li>In information retrieval (IR) and AI, we usually summarize it using Recall and Precision.</li></ul></div><h4 id="Specificity-and-Sensitivity">Specificity and Sensitivity</h4><ul><li>Specificity = True Negative Rate (TNR):<ul><li>$TNR = P(f(X) =0|Y=0) = \frac{TN}{TN+FP}$</li></ul></li><li>Sensitivity = True Positive Rate (TPR):<ul><li>$TRP = P(f(X) =1|Y=1) = \frac{TP}{TP+FN}$</li></ul></li><li>Precision:<ul><li>$P=P(Y =1|f(x)=1)=\frac{TP}{TP+FP}$</li></ul></li><li>Recall:<ul><li>Recall = Sensitivity = TPR:</li><li>$R = TRP = P(f(X) =1|Y=1) = \frac{TP}{TP+FN}$</li></ul></li></ul><h4 id="Training-Corpora">Training Corpora</h4><ul><li>Training vs. Test Corpora<br><strong>Training Corpus</strong>: a set of data that you use in order to optimize the parameters of your classifier (for example, optimize which features you measure, how you use those features to make decisions, and so on).<br><strong>Test Corpus</strong>: a set of data that is non-overlapping with the training set (none of the test tokens are also in the training dataset) that you can use to measure the accuracy.<ul><li>Measuring the training corpus accuracy is useful for debugging: if your training algorithm is working, then training corpus accuracy should always go up.</li><li>Measuring the test corpus accuracy is the only way to estimate how your classifier will work on new data (data that you’ve never yet seen).</li></ul></li></ul><div class="admonition note"><p class="admonition-title">Accuracy on which corpus?</p><ul><li>Large Scale Visual Recognition Challenge 2015: Each competing institution was allowed to test up to 2 different fully-trained classifiers per week.<br></li><li>One institution used 30 different e-mail addresses so that they could test a lot more classifiers (200, total). One of their systems achieved &lt;46% error rate – the competition’s best, at that time.<br></li><li>Is it correct to say that that institution’s algorithm was the best?</li></ul></div><ul><li>Training vs. development test vs. evaluation test corpora<ul><li><strong>Training Corpus</strong>: a set of data that you use in order to optimize the parameters of your classifier (for example, optimize which features you measure, what are the weights of those features, what are the thresholds, and so on).</li><li><strong>Development Test (DevTest or Validation) Corpus</strong>: a dataset, separate from the training dataset, on which you test 200 different fully-trained classifiers (trained, e.g., using different training algorithms, or different features) to find the best.</li><li><strong>Evaluation Test Corpus</strong>: a dataset that is used only to test the ONE classifier that does best on DevTest. From this corpus, you learn how well your classifier will perform in the real world.</li></ul></li></ul><h3 id="Summary">Summary</h3><ol><li><p>Bayes Error Rate:<br>$$<br>Error Rate = \sum_x P(X=x)\underset{y}{min} P(Y \neq y |x=x)<br>$$</p></li><li><p>Confusion Matrix, Precision &amp; Recall (Sensitivity)<br>$$P=P(Y =1|f(x)=1)=\frac{TP}{TP+FP}$$<br>$$R = TRP = P(f(X) =1|Y=1) = \frac{TP}{TP+FN}$$</p></li></ol><h4 id="Training-Corpora-v2">Training Corpora</h4><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Artificial Intelligent</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>Schrodinger Function</title>
    <link href="https://karobben.github.io/2024/01/25/LearnNotes/schrodinger/"/>
    <id>https://karobben.github.io/2024/01/25/LearnNotes/schrodinger/</id>
    <published>2024-01-25T21:15:01.000Z</published>
    <updated>2024-01-31T05:30:45.767Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Energy-Momentum-Relation">Energy Momentum Relation</h2><p>$E^2 = (m_ 0 C ^2) ^2 + (pc)^ 2$</p><p>For Energy with rest mess: $E = m_0c^2$<br>For Energy with no rest mess: $E = pc$</p><p>Introducing Bacground:</p><ul><li>Light is a ruler; molecules are objects to be measured.</li><li>Visible light is a coarse ruler (300 nm resolution)</li><li>Molecules, on the other hand, are fine objects (0.1 nm)</li><li>How can we measure such a fine object with a coarse ruler?<ul><li>Use a finer ruler (electron microscopy)</li><li>Use indirect evidence to infer the information (today’s focus)</li></ul></li></ul><p>How to infer? What indirect evidence?</p><ul><li>Use a language to describe the matter (molecule).</li><li>Find information that is related to the size of a molecule.</li><li>Hopefully that information can be obtained by measurement (using light).</li><li>Infer the information about the molecule to be studied.</li><li>Here is one way to do this:<ul><li>Use the Schrödinger equation to describe the system (molecule, atoms, electrons).</li><li>Find out that energy of electrons is related to the size of the molecule.</li><li>Measure the energy of the system using light.</li><li>Infer the size of the molecule by interpreting the energy information.</li></ul></li></ul><h2 id="Use-the-Schrodinger-Equation-to-Describe-the-System">Use the Schrödinger Equation to Describe the System</h2><p>$$<br>-\frac{\hbar}{2m} \frac{d^2 \Psi (x)}{dx^ 2} + V(x)\Psi(x) = E\Psi(x)<br>$$</p><ul><li>V(x): Potential energy provides the constraints</li><li>E: Solve for Energy(also called eigenvalues)</li><li>$\Psi(x)$: Solve for wavefunctions (also called eigenvectors or eigenfunctions)</li></ul><p>We will end up with a series of wavefunctions with associated energies:<br>$$\Psi(x) \leftrightarrow E_ n $$</p><p>The Schrödinger Equation is a fundamental equation in quantum mechanics that describes how the quantum state of a physical system changes over time. It was formulated by Erwin Schrödinger in 1925. There are two forms of the Schrödinger Equation: the time-dependent and the time-independent forms.</p><h3 id="The-Meaning-of-Φ-x">The Meaning of Φ(x)</h3><p>$$<br>P(x_0, t_0)dx = \Psi^ * (x_0, t_0)\Psi(x_0, t_0)dx = |\Psi (x_0, t_0)|^2 dx<br>$$</p><p><em><strong>P(x<sub>0</sub>, t<sub>0</sub>)</strong></em>: <em>Probability</em>* of finding the particle (e.g. electron) within an interval<br>of <em>dx</em> of position <em>x<sub>0</sub></em> at time <em>t<sub>0</sub></em></p><h3 id="Properties-of-Φ-x">Properties of Φ(x);</h3><p>$$<br>\int_{-\infty}^{\infty} \Psi^* (x, t) \Psi (x, t)dx = 1<br>$$</p><p>Average value of f(x) over all space</p><p>$$<br>\left \langle  f(x) \right \rangle = \frac{ \int_{-\infty}^{\infty} \Psi^* (x) \Psi (x)f(x)dx }{\int_{-\infty}^{\infty} \Psi^* (x) \Psi (x)dx}<br>$$</p><h2 id="Find-Out-That-Energy-of-Electrons-Is-Related-to-the-Size-of-the-Molecule">Find Out That Energy of Electrons Is Related to the Size of the Molecule.</h2><h3 id="1-d-particle-in-a-box">1-d particle in a box</h3><p>Here <strong>Particle = electrons in a molecule</strong><br><strong>Layman language</strong>: Potential energy outside the box is infinite.<br><strong>Mathematical language</strong>: Boundary condition</p><p><img src="https://bouman.chem.georgetown.edu/S02/lect13/piab.gif" alt=""></p><p><em><strong>V(x) = 0 for L &gt; x &gt; 0</strong></em><br><em><strong>V(x) = ∞ for x ≥ L, x ≤ 0</strong></em></p><p>$$<br>\frac{d^ 2 \Psi(x)}{dx^ 2} = \frac{2m} {\hbar^ 2} [V(x)-E]\Psi(x)<br>$$</p><ol><li><p>Since <em><strong>V(x)</strong></em> is infinite outside the box, <em><strong>Ψ(x)</strong></em> must be zero outside the box<br>(otherwise $\frac{d^2 Ψ(x)}{dx^2}$ would be infinite: not allowed)</p></li><li><p>Since <em><strong>Ψ(x)</strong></em> must be continous, <em><strong>Ψ(x)</strong></em> inside the box must connect smoothly to <em><strong>Ψ(x)</strong></em> outside the box<br>Hence, $Ψ(0)= Ψ(L) = 0$</p></li></ol><p>$$ \Psi_ n (x) = \sqrt{\frac{2}{L}}  sin(\frac{n\pi x}{L}) $$</p><ul><li>$ E_ n= \frac{h^2 n ^2}{8ma ^ 2} $</li><li>$ where n = 1, 2, 3, 4… $</li><li>Energy of the electron (<em><strong>E</strong></em>) is related to the size of the molecule (<em><strong>L</strong></em>).</li></ul><p>With this theory, we could measure the energy of the system using light</p><ul><li>Pi-electrons behave as a “particle in a box: Molecules has different absorb peak when they as different number of conjugation bounds.</li></ul><div class="admonition note"><p class="admonition-title">The electrons and its orbitals</p><p>4 pi electrons =&gt; 2 orbitals8 pi electrons =&gt; 4 orbitals</p></div><h2 id="Estimate-bond-length-from-the-transition-energy">Estimate bond length from the transition energy</h2><p>$$<br>\Delta E = \frac{(n_ 3 ^ 2 - n_ 2^ 2) h^ 2 }{8mL^ 2}<br>$$</p><p>For this compound, There are <strong>4 pi electrons</strong>. Two each in the n=1 and n=2 orbitals. (This is due to electron spin, which we will see later).<br>The absorption is due to promoting an electron from the n=2 to the n=3 orbital.</p><ul><li>Infinite potential: infinite number of solutions</li><li>Finite potential:<ol><li>A finite number of solutions (5 in this example)</li><li>Wavefunctions are not zero at the boundary of the box</li><li>The wavefunctions have finite amplitude outside the box.<br>Finite chance the particle can be outside the box even though <em><strong>E&lt;V<sub>0</sub></strong></em></li></ol></li></ul><div class="admonition note"><p class="admonition-title">TUNNELING effect in Quantum Mechanics</p><p><img src="https://www.ntmdt-si.com/data/media/images/spm_basics/scanning_tunnel_microscopy_stm/stm_physical_backgrounds/tunneling_effect/img04.gif" alt="Quantum Tunneling" /> <a href="https://www.ntmdt-si.com/resources/spm-theory/theoretical-background-of-spm/1-scanning-tunnel-microscopy-%28stm%29/11-stm-physical-backgrounds/111-tunneling-effect">© ntmdt-si</a></p><p>a particle can go &quot;through&quot; an energy barrier instead of needing to have sufficient energy to go over the barrierWhen the wave go through the energy barrier, the exponential decay occurred inside of the energy barrier.</p></div><h2 id="Predict-the-Energy-and-Optical-Property">Predict the Energy and Optical Property</h2><p>If we know the structure of the molecule, can we predict the energy and optical property of the molecule?<br>Take the <strong>hydrogen atom</strong> as example.</p><ul><li>$V( r ) = \frac{e^ 2}{4\pi \epsilon_ 0 r}$</li><li><em><strong>e</strong></em> = electron charge</li><li><em><strong>ε<sub>0</sub></strong></em> = permittivity of free space</li></ul><h3 id="Predicted-the-Energy">Predicted the Energy</h3><p>Here we only need 3 quantum number: <em><strong>n</strong></em>, <em><strong>l</strong></em>, and <em><strong>m<sub>l</sub></strong></em></p><ul><li>the principal quantum number: <em><strong>n</strong></em>  = 1, 2, 3, 4…</li><li>the angular momentum quantum number: <em><strong>l</strong></em> = 0, 1, 2, … (n -1)</li><li>the magnetic quantum number: <em><strong>m<sub>l</sub></strong></em> = 0, ±1, ±2, … ± <em><strong>l</strong></em></li></ul><p>As you can see, the energy only depends on <em><strong>n</strong></em>:<br>$E_ n = - \frac{m_ e e^ 4}{8 \epsilon_ 0^ 2 h^2 n^ 2} = - \frac{2.179 × 10 ^ {-18}}{n^ 2}Joule = -\frac{13.6}{n^ 2}eV\ \ \ n = 1, 2, 3… $</p><table><thead><tr><th style="text-align:center"><img src="https://imgur.com/Kwx6VEm.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center">© Atkins, The Elements of Physical Chemistry</td></tr></tbody></table><h2 id="Cheat-Sheet">Cheat Sheet</h2><ul><li>Energy: kcal/mol, kJ/mol</li><li>Wavelength: nm</li><li>Frequency: Hz</li><li>$E = h\nu = \frac{hc}{\lambda}$</li><li>Planck constant (<em><strong>h</strong></em>) = 6.62607015 × 10<sup>-34</sup> J∙s</li><li>Speed of light (<em><strong>c</strong></em>) = 299 792 458 m/s ~ 3 × 10<sup>8</sup> m/s</li></ul><div class="admonition note"><p class="admonition-title">Calculate the energy of one photon of green light (532 nm)</p><p>$ E = h\nu = \frac{hc}{\lambda} = \frac{hc}{532 × 10^ {-9}m} = 3.823×10^ {-19}J$</p></div><div class="admonition note"><p class="admonition-title">Convert J to Hz</p><p>$ \nu = \frac{E}{h} = \frac{3.823×10^ {-19}J}{h} = 5.8 × 10^ {14} Hz$</p></div><div class="admonition note"><p class="admonition-title">Convert kJ/mol and kcal/mol</p><p>$E_ {total} = N_ A × E = 6.02 × 10^ {23} \frac{1}{mol} × 3.823 × 10^ {-19} J$</p><p>$= 230226 J/mol ~ 230 kJ/mol $</p><p>$= 55 kcal/mol$</p></div><br><br><br><br><br><br><br><h2 id="Extra-Reading">Extra Reading</h2><ol><li><p><strong>Time-Dependent Schrödinger Equation:</strong><br>$$<br>i\hbar\frac{\partial}{\partial t}\Psi(\mathbf{r}, t) = \hat{H}\Psi(\mathbf{r}, t)<br>$$<br>Here, $\Psi(\mathbf{r}, t)$ is the wave function of the system, $i$ is the imaginary unit, $\hbar$ is the reduced Planck constant, $t$ represents time, $\mathbf{r}$ is the position vector, and $\hat{H}$ is the Hamiltonian operator which represents the total energy of the system.</p></li><li><p><strong>Time-Independent Schrödinger Equation:</strong><br>$$<br>\hat{H}\psi(\mathbf{r}) = E\psi(\mathbf{r})<br>$$<br>In this form, $\psi(\mathbf{r})$ is the time-independent wave function, $E$ represents the energy of the system, and other symbols have the same meaning as in the time-dependent equation.</p></li></ol><p>The Schrödinger Equation is a cornerstone of quantum mechanics, providing a mathematical framework for understanding and predicting the behavior of quantum systems. It’s important to note that these equations are usually accompanied by specific boundary conditions or potentials, depending on the physical situation being modeled.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">To develop a quantitative understanding of macromolecules in biological systems.</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>PARTICLE-WAVE DUALITY</title>
    <link href="https://karobben.github.io/2024/01/23/LearnNotes/par-wave-dual/"/>
    <id>https://karobben.github.io/2024/01/23/LearnNotes/par-wave-dual/</id>
    <published>2024-01-23T15:57:26.000Z</published>
    <updated>2024-01-31T05:31:36.820Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Failure-of-Classical-Mechanics">Failure of Classical Mechanics</h2><h3 id="Black-Body-Radiation">Black Body Radiation</h3><ul><li><strong>Experiment</strong>: measure the radiation intensity as a function of frequency of the radiation emitted from a black body (a physical body that absorbs all incident electromagnetic radiation) at thermal equilibrium</li><li><strong>Model</strong>: Emitted radiation is classically due to oscillating electric dipoles within the material, acting like broadcast antennas.</li><li><strong>Classical expectation</strong>: higher temperature should result in a large increase in the radiation emitted at high frequencies (fast oscillation at high T)</li></ul><div class="admonition note"><p class="admonition-title">Gustav Kirchhoff</p><p>The blackbody is an idealized physical body that absorbs all incident electromagnetic radiation (such as light), regardless of frequency or angle of incidence.</p><p>A black body can also emit black-body radiation, which is solely determined by its temperature.</p><p><a href="https://en.wikipedia.org/wiki/Gustav_Kirchhoff"><img src="https://upload.wikimedia.org/wikipedia/commons/f/fe/Gustav_Robert_Kirchhoff.jpg" alt="Gustav Robert Kirchhoff" /></a></p></div><h3 id="Black-body-Radiation-Spectrum-Intensity-vs-Wavelength">Black-body Radiation Spectrum: Intensity vs. Wavelength</h3><table><thead><tr><th style="text-align:center"><img src="https://i.stack.imgur.com/f4xki.gif" alt="Relationship between radiational intensity vs. wavelength"></th></tr></thead><tbody></tbody></table><p>Notic: the “Cold” object also emit “light” as long as its above the absolute zero (-273.15 °C). And it would appear “blakc” because the peak wavelength is in infrared range, which human eye cannot recognize.</p><p>According to this theory, we could astimate the temperature of stars based on its color.</p><table><thead><tr><th style="text-align:center"><img src="https://stsci-opo.org/STScI-01G7RQ0CRCSNKZNX18HNNAQRV0.jpg" alt=""></th><th style="text-align:center"><img src="https://www.astronomy.com/wp-content/uploads/sites/2/2023/02/ScreenShot20210420at3.19.16PM.jpg" alt=""></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://webbtelescope.org/contents/media/images/01F8GF8WYBCQVKTGPX3MA58182?Type=Infographics&amp;Tag=Spectroscopy">webbtelescope</a></td><td style="text-align:center"><a href="https://www.astronomy.com/astronomy-for-beginners/color-coding-stars/">astronomy.com</a></td></tr></tbody></table><h3 id="Wien’s-Displacement-Law">Wien’s Displacement Law</h3><p>$ \lambda _{max} = \frac{W}{T} $</p><ul><li>$  \lambda _{max} $: Peak wavelength</li><li>W: Wien’s constant = 2.9 e<sup>-3</sup> m Kelvin</li><li>T: Surfave temperature</li></ul><p>Exp:</p><p>When λ<sub>max</sub> = 500nm:<br>$T = \frac{W}{\lambda_ {max}} = \frac{2.9 e^ {-3} mK}{500e^ {-9}m } = 5800K$</p><h3 id="Rayleigh-Jeans-law-Classical-description-of-light">Rayleigh-Jeans law (Classical description of light)</h3><ul><li>Predict the spectral irradiance (or spectral density) of a black body radiation as a function of wavelength or frequency for a fixed temperature.</li><li>Spectrum Density (ν, T) = $\frac{8\pi\nu^2}{ c^3 }k_BT$<ul><li>c: speed of light</li><li>k<sub>B</sub> = Boltzmann constant = 1.380649 × 10<sup>-23</sup> J/K</li><li>T: temperature</li><li>ν: frequency</li></ul></li></ul><h3 id="Spectral-density">Spectral density</h3><ul><li>Density = radiance<br>The power of radiation (W) passing a unit area (m<sup>2</sup>) within a unit solid angle (sr), within a unit time<br>(s). It has the unit of W/(m<sup>2</sup> × sr × s)</li><li>Spectral density = Spectral radiance<br>The radiance per unit wavelength (um) or per unit frequency (Hz), depending on if the power is measured over wavelength or frequency. Therefore, spectral density has the unit of W/(m<sup>2</sup> × sr × s × um) or W/(m<sup>2</sup> × sr × s × Hz).</li></ul><h3 id="Unexpected-Black-Body-Radiation-UV-Catastrophe">Unexpected Black Body Radiation: UV Catastrophe</h3><div class="admonition note"><p class="admonition-title">Conflict between observation and expectation</p><ul><li><strong>Observation</strong> :Spectral density does not monotonically increase as the frequency increases.</li><li><strong>Classical expectation</strong>:According to the Rayleigh-Jean law, spectral density should increase as the frequency increases</li></ul></div><p>Reason: <mark>The classic oscillating field from electromagnetic radiation drives the motion of a spring</mark><br>- faster oscillation → higher frequency → higher energy</p><p>For fix this conflict, a propportional model was given: E = nhν (<mark>Max Planck</mark>)</p><ul><li>n = 1, 2, 3…</li><li>Planck’s constant (h) = 6.626×10<sup>−34</sup> Js</li></ul><p>$$<br>\rho (\nu, T) = \frac{8\pi\nu^2 h \nu}{ c^3 } \frac{1}{e^{\frac{hv}{k_ BT}} - 1 }<br>$$</p><p>Explained:<br>- energy of photon (with frequent ν): hν<br>- weight if photon population (ν): g(ν) = $\frac{8\pi \nu ^2 }{c^ 3}$<br>- averagy number of photon (ν): n(#, T) = $\frac{1}{exp(\frac{h\nu}{k_BT})-1}$<br>- ρ (νT)dν = hν × g(ν) × n(#, T)<br>= $h\nu × \frac{8\pi \nu ^2 }{c^ 3} × \frac{1}{exp(\frac{h\nu}{k_BT})-1}$<br>= $\frac{8\pi h \nu^3}{ c^3 } \frac{1}{e^{\frac{hv}{k_ BT}} - 1 }$</p><p>In Planck Low, it show either high temperature or low frequency would case the “Ultralviolet catastrophe”:</p><p><img src="https://imgur.com/rWBTB6C.png" alt="planck Law"></p><ul><li>From the left to the right:<ul><li>$\frac{8\pi \nu ^2 }{c^ 3}$</li><li>$\frac{1}{exp(\frac{h\nu}{k_BT})-1}$</li><li>$\frac{8\pi h \nu^3}{ c^3 } \frac{1}{e^{\frac{hv}{k_ BT}} - 1 }$</li></ul></li></ul><details><summary>Plot Codes</summary><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">Rayleigh_Jeans</span>(<span class="hljs-params">v, T</span>):</span><br>    kB = <span class="hljs-number">1.380649</span> * <span class="hljs-number">10</span>**(<span class="hljs-number">0</span>-<span class="hljs-number">23</span>)<br>    c = <span class="hljs-number">3</span> * <span class="hljs-number">10</span>**<span class="hljs-number">8</span><br>    <span class="hljs-keyword">return</span> (v**<span class="hljs-number">2</span>) * <span class="hljs-number">8</span> * np.pi * kB * T / (c**<span class="hljs-number">3</span>)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">Planck</span>(<span class="hljs-params">v, T</span>):</span><br>    h = <span class="hljs-number">6.626</span>*<span class="hljs-number">10</span>**(<span class="hljs-number">0</span>-<span class="hljs-number">34</span>)<br>    kB = <span class="hljs-number">1.380649</span> * <span class="hljs-number">10</span>**(<span class="hljs-number">0</span>-<span class="hljs-number">23</span>)<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> /( np.e ** (h*v / (kB * T) ) - <span class="hljs-number">1</span> )<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">Merged</span>(<span class="hljs-params">v, T</span>):</span><br>    h = <span class="hljs-number">6.626e-34</span><br>    kB = <span class="hljs-number">1.380649e-23</span><br>    c = <span class="hljs-number">3</span> * <span class="hljs-number">10</span> **<span class="hljs-number">8</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">8</span> * np.pi * h * v**<span class="hljs-number">3</span> / c**<span class="hljs-number">3</span> / np.e**(h *v /(kB * T))<br><br><span class="hljs-comment"># Constants</span><br>h = <span class="hljs-number">6.62607015e-34</span>  <span class="hljs-comment"># Planck&#x27;s constant (m^2 kg / s)</span><br>c = <span class="hljs-number">299792458</span>       <span class="hljs-comment"># Speed of light in vacuum (m / s)</span><br>k_B = <span class="hljs-number">1.380649e-23</span>  <span class="hljs-comment"># Boltzmann constant (J / K)</span><br><br><span class="hljs-comment"># Planck&#x27;s law function</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">planck_law</span>(<span class="hljs-params">frequency, temperature</span>):</span><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Calculate the spectral radiance of a black body at thermal equilibrium.  </span><br><span class="hljs-string">    Parameters:</span><br><span class="hljs-string">    frequency (float): frequency of the electromagnetic radiation (Hz)</span><br><span class="hljs-string">    temperature (float): absolute temperature of the body (K)</span><br><span class="hljs-string">    Returns:</span><br><span class="hljs-string">    float: spectral radiance (W / (m^2 * sr * Hz))</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    exponent = (h * frequency) / (k_B * temperature)<br>    spectral_radiance = (<span class="hljs-number">8</span> * np.pi * h * frequency**<span class="hljs-number">3</span>) / (c**<span class="hljs-number">3</span>) * (<span class="hljs-number">1</span> / (np.exp(exponent) - <span class="hljs-number">1</span>))<br>    <span class="hljs-keyword">return</span> spectral_radiance<br><br><span class="hljs-comment"># Example usage: Calculate the spectral radiance for a frequency of 1e14 Hz at 5000 K</span><br>frequency_example = <span class="hljs-number">1e14</span>  <span class="hljs-comment"># Hz</span><br>temperature_example = <span class="hljs-number">5000</span>  <span class="hljs-comment"># K</span><br>radiance_example = planck_law(frequency_example, temperature_example)<br><br><span class="hljs-comment"># Plot the graphs above</span><br>X = [i /<span class="hljs-number">10</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span>  <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">100</span>)]<br>fig, axs = plt.subplots(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)<br>axs[<span class="hljs-number">0</span>].plot(X, [Planck(i * <span class="hljs-number">1e14</span>, <span class="hljs-number">3000</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> X])<br>axs[<span class="hljs-number">1</span>].plot(X, [Rayleigh_Jeans(i * <span class="hljs-number">1e14</span>, <span class="hljs-number">3000</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> X])<br>axs[<span class="hljs-number">2</span>].plot(X, [h *(i *<span class="hljs-number">1e14</span>)* Rayleigh_Jeans(i*<span class="hljs-number">1e14</span>, <span class="hljs-number">3000</span>) * Planck(i*<span class="hljs-number">1e14</span>, <span class="hljs-number">3000</span>)  <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> X])<br>plt.tight_layout()<br>plt.show()<br><br><span class="hljs-comment"># plot the mergerd function</span><br>plt.plot(X, [Merged(i*<span class="hljs-number">1e14</span>/<span class="hljs-number">10</span>, <span class="hljs-number">3000</span>)  <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> X])<br>plt.show()<br></code></pre></td></tr></table></figure></div></details><p>So, both Rayleigh-Jean law and Planck law agree with the observation very well in very low frequency.<br>But only Plank law could fit the decreasing of the intensity in high frequency situation.</p><h2 id="Light-is-Particle">Light is Particle</h2><h3 id="Einstein’s-Contribution-Photoelectric-Effect">Einstein’s Contribution: Photoelectric Effect</h3><p>$$<br>E = nhν<br>$$</p><p>By using the light to eject electrons from a copper, they found the <mark>kinetic energy of ejected electrons depends on light frequency</mark></p><p>$$<br>E_{light} = \beta\nu_{light}<br>$$</p><h3 id="The-Photoelectric-Effect">The Photoelectric Effect</h3><p>Conservation of energy</p><table><thead><tr><th style="text-align:center"><img src="https://imgur.com/DSOpstj.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center">…?unknow</td></tr></tbody></table><p>$$<br>E_{elec} + \Phi= \beta \nu<br>$$</p><ul><li>E<sub>elec</sub>: (Measured) Electron kinetic energy</li><li>&amp;\Phi; Work to remove electron from target (independently determined)</li><li>ν: Determine the value of &amp;\beta;</li></ul><div class="admonition note"><p class="admonition-title">Einstein concluded that light must be behaving like a particle in this experiment: PHOTON</p><p>E = <em>hν</em></p></div><h3 id="Duality-in-partical-with-mass">Duality in partical with mass</h3><ul><li><strong>Electron diffraction</strong>: This is a typical diffraction pattern of a beam of electrons diffracted by a crystalline solid</li></ul><p>from Planck’s equation to Einstein’s equestion:</p><ul><li><em>E = h&amp;nu</em> → <em>E = mc<sup>2</sup></em></li></ul><p>$v = h\nu$<br>$mv = P = m\lambda\nu$<br>$v = \frac{P}{m\lambda}$<br>$E = h\nu = \frac(hP){m\lambda} → E = \frac{p^2 }{m}$</p><p>De Broglie Equation:<br>$\lambda = \frac{h}{p} = \frac{h}{m\nu}$</p><h3 id="About-Weight-Terms-in-Spectral-Density">About Weight Terms in Spectral Density</h3><p>$g(\nu) = \frac{N(E)}{V} = \frac{Number of States (E)}{Volumne}$</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">PARTICLE-WAVE DUALITY</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>Light in Physics</title>
    <link href="https://karobben.github.io/2024/01/18/LearnNotes/light/"/>
    <id>https://karobben.github.io/2024/01/18/LearnNotes/light/</id>
    <published>2024-01-19T03:30:37.000Z</published>
    <updated>2024-02-02T01:28:32.399Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Mathmatic-Description-of-the-Light">Mathmatic Description of the Light</h2><p>In the equation you’ve provided:</p><p>$$<br>E(x,t) = E^0 \sin\left[2\pi \left(\frac{x}{\lambda} - \frac{t}{T}\right)\right]<br>$$</p><p>This represents a sinusoidal wave function, where $E(x,t)$ is the electric field of the light wave at a position $x$ and at time $t$. Here’s what the terms mean:</p><ul><li>$E^0$ is the amplitude of the wave, which indicates the maximum strength of the electric field.</li><li>$\lambda$ (lambda) is the wavelength of the light, which is the distance over which the wave’s shape repeats.</li><li>$T$ is the period of the wave, which is the time it takes for one complete cycle of the wave to pass a point. ($\frac{1}{T} = \nu$)</li></ul><p>The reason both $\lambda$ and $T$ are present in the equation is because they describe different aspects of the wave:</p><ul><li>$\lambda$ describes the spatial repetition of the wave along the $x$-axis.</li><li>$T$ describes the temporal repetition of the wave along the $t$-axis (time).</li></ul><p>The term $\frac{x}{\lambda} - \frac{t}{T}$ is the phase of the wave, which determines the position of the peaks and troughs of the wave at any given time $t$ and position $x$. It’s not meant to equal zero; instead, it changes with time and position to represent the propagation of the wave through space and time.</p><p>The phase changes as time goes by, indicating that the peaks and troughs of the wave are moving. If $\frac{x}{\lambda} - \frac{t}{T}$ were always zero, it would imply a stationary wave, not a propagating one.</p><p>The product $2\pi$ times the phase gives you the argument of the sine function in radians, which is necessary because the sine function is periodic with a period of $2\pi$. This means that the wave repeats itself every $2\pi$ radians, which corresponds to one wavelength in space and one period in time.</p><p><img src="https://imgur.com/D0t8uGs.png" alt="Wave Function"></p><details><summary>Plot codes</summary><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">waveFun</span>(<span class="hljs-params">x, t = <span class="hljs-number">0</span>, lamb = <span class="hljs-number">1</span>, pi = np.pi, T = <span class="hljs-number">1</span>, E0 = <span class="hljs-number">1</span></span>):</span><br>    E = E0 * np.sin(<span class="hljs-number">2</span> * pi * (x/lamb - t/T))<br>    <span class="hljs-keyword">return</span> E     <br><br>Y = <span class="hljs-built_in">range</span>(-<span class="hljs-number">50</span>,<span class="hljs-number">50</span>)<br>X = <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,<span class="hljs-number">100</span>)<br>Points = []<br><span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> X:<br>    <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> Y:<br>        Dis = np.sqrt((x/<span class="hljs-number">10</span>)**<span class="hljs-number">2</span> + (y/<span class="hljs-number">10</span>)**<span class="hljs-number">2</span>)<br>        Points += [[x, y, waveFun(Dis)]]<br><br>Points = np.array(Points)<br><br>plt.figure(figsize=(<span class="hljs-number">7</span>, <span class="hljs-number">5</span>))<br>plt.scatter(Points[:, <span class="hljs-number">0</span>], Points[:, <span class="hljs-number">1</span>] + <span class="hljs-number">0.5</span>, c= Points[:, <span class="hljs-number">2</span>], marker=<span class="hljs-string">&#x27;o&#x27;</span>, cmap=plt.cm.coolwarm,)<br>plt.show()<br></code></pre></td></tr></table></figure></div></details><h3 id="Example-1-Single-Location-Position">Example 1: Single Location Position</h3><p>Let’s set the $\lambda$ as 1, T as 10, and x = 0. Then, the equation could be simplified as $E(0, t) = sin[2\pi(0 - \frac{t}{10})]$.<br>And the change of the E<sup>0</sup> with T could be show as the animation below.</p><table><thead><tr><th style="text-align:center">The E<sup>0</sup> corresponded with the t</th><th style="text-align:center">Static View by using x axis as t</th></tr></thead><tbody><tr><td style="text-align:center"><img src="https://imgur.com/WvAIY5p.gif" alt="Observing the wave in single position"></td><td style="text-align:center"><img src="https://imgur.com/Ct71NCk.png" alt="Spread the observed points"></td></tr></tbody></table><h3 id="Example-2-Multiple-Observation-Locations">Example 2: Multiple Observation Locations</h3><p>If we observe more positions, let’s say, 0 to 10, and using the full function, we could get an animation like below. This is the propagating wave we could observe in 10 different locations.</p><p><img src="https://imgur.com/KdWk5PU.gif" alt="The propagating wave"></p><table><thead><tr><th style="text-align:center"><img src="https://www.acs.psu.edu/drussell/Demos/wave-x-t/wave-x-t.gif" alt="Wave Motion in Time and Space"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.acs.psu.edu/drussell/Demos/wave-x-t/wave-x-t.html">© psu</a></td></tr></tbody></table><h2 id="Direction-of-the-Wave">Direction of the Wave</h2><p>When t increases, x increases =&gt; “+” direction on x;<br>When t increases, x decreases =&gt; “-” direction on x.</p><h2 id="Speed-of-the-Wave">Speed of the Wave</h2><p>$velocity = \frac{\lambda}{T} = \lambda \nu$</p><ul><li>$\nu$ id frequency ($\frac{1}{T}$) of the wave.</li></ul><p>So, the light of the wave is:</p><ul><li>$c = \lambda \nu$</li></ul><h2 id="Energy-of-the-Wave">Energy of the Wave</h2><p>Energy of a wave is proportional to the square of the amplitude (in classical mechanics)</p><p>$\rho(\nu)$: energy per unit volume</p><p>$$<br>\rho(\nu) = constant\ x (E^ o)^ 2<br>$$</p><ul><li><mark>Classic</mark>: Energy is dependent on amplitude</li><li><mark>QM</mark>: Energy is dependent on frequency</li></ul><h2 id="Commonly-used-notation">Commonly used notation</h2><ol><li><p><strong>Wave Vector ($k$)</strong>: The wave vector is defined as $\frac{2\pi}{\lambda}$, where $\lambda$ is the wavelength of the wave. The wave vector points in the direction of the wave’s propagation and has a magnitude equal to the number of wave cycles per unit distance. The notation $\hat{k}$ represents a unit vector in the direction of $k$, so the wave vector $k$ is sometimes written as $\frac{2\pi}{\lambda} \hat{k}$, emphasizing its direction.</p></li><li><p><strong>Angular Frequency ($\omega$)</strong>: This is defined as $2\pi\nu$, where $\nu$ is the frequency of the wave. It represents how many radians the wave cycles through per unit time.</p></li><li><p><strong>Phase ($\phi$)</strong>: The phase is a term that allows us to specify where in its cycle the wave is at $t = 0$ and $x = 0$. It lets us define <strong>the “zero point” or starting point</strong> of the wave at a place other than the origin of our coordinate system.</p></li></ol><p>$$E(x,t) = E^0 \sin(kx - \omega t + \phi)$$<br>$$H(x,t) = H^0 \sin(kx - \omega t + \phi)$$</p><div class="admonition question"><p class="admonition-title">Why Standard Form?</p><p>The first function form expresses the wave in terms of its wavelength λ and period T, which are perhaps more intuitive when you're first learning about waves.  It makes it very clear that the wave repeats itself every wavelength λ in space and every period T in time.</p><p>The second function is the standard form. It's particularly useful in more advanced topics like wave interference, diffraction, and quantum mechanics, where the concept of phase space and the relationship between position and momentum (or wavelength and frequency) are crucial.</p><p>For example, when you want to mimic the interference of the wave, the previous function could became extreamly complcated because the only difference between two wave is phase.</p></div><details> <summary>More descriptions</summary>These equations describe how the electric and magnetic fields oscillate as a function of space and time, which is characteristic of electromagnetic waves such as light. The quantities $E^0$ and $H^0$ are the maximum strengths of the electric and magnetic fields, respectively.<p>In an electromagnetic wave, the electric and magnetic fields are perpendicular to each other and to the direction of wave propagation. The equations show that both fields oscillate in sync (they have the same phase $\phi$) but are described by separate equations since they are perpendicular components.</p><p>The term $kx - \omega t$ indicates that the wave is moving in the positive $x$-direction. If the wave were moving in the negative $x$-direction, the sign in front of $\omega t$ would be positive.</p><p>The factor $\sin(kx - \omega t + \phi)$ varies between (-1) and (1), causing the electric and magnetic field strengths to oscillate between $-E^0$ to $E^0$ and $-H^0$ to $H^0$, respectively. The wave thus carries energy and, if it is light, can be observed as it interacts with matter.</p></details><h2 id="Huygen’s-Principle-1678">Huygen’s Principle (1678)</h2><p>Waves spread as if each region of space is behaving as a source of new waves of the <mark>same frequency and phase</mark>.<br>So, Huygen’s principle applied to light showing a wave front.</p><h2 id="Diffraction">Diffraction</h2><p><img src="https://imgur.com/vtuefhO.png" alt="Wave Diffraction"></p><p>When we konw d, D, X, and θ we could calcualate the λ (wave length):</p><ul><li>When the light patten shows the dark point, we know that the phase between two waves is $n\frac{\lambda}{2}$</li><li>So the $\Delta \phi$ of the first dark spot would be $\frac{\lambda}{2}$</li><li>According to the plot, the λ would be (path4 - path3) * 2 $ = \frac{d}{2}sin\theta$</li><li>When the angle is very small, we have $sin\theta \approx tan\theta = \frac{X}{2}\frac{1}{D}$</li><li>So finally, we could get: $\frac{d}{2}\frac{X}{2D} = \frac{\lambda}{2}$<ul><li>$\lambda = \frac{dX}{2D}$</li></ul></li></ul><table><thead><tr><th style="text-align:center"><img src="https://imgur.com/qiLpQ7c.png" alt="Two wave interference"></th><th style="text-align:center"><img src="https://imgur.com/1Cqo89a.png" alt="Three wave interference"></th></tr></thead><tbody><tr><td style="text-align:center">Two wave interference (center: y<sub>1</sub> = -15, y<sub>2</sub> = 15)</td><td style="text-align:center">Three wave interference (y<sub>1</sub> = 10, y<sub>2</sub> = 0, y<sub>3</sub> = -10)</td></tr></tbody></table><table><thead><tr><th style="text-align:center"><img src="http://hyperphysics.phy-astr.gsu.edu/hbase/phyopt/imgpho/muls2.png" alt="Double Slit"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="http://hyperphysics.phy-astr.gsu.edu/hbase/phyopt/mulslid.html">© gsu</a></td></tr><tr><td style="text-align:center"><img src="https://myslu.stlawu.edu/~jmil/physics/labs/152_lab/setup_manual/blackboard/img/double_slit.gif" alt="Double Slit"></td></tr><tr><td style="text-align:center"><a href="http://stlawu.edu">stlawu.edu</a></td></tr></tbody></table><p>$$<br>n\lambda = d sin\theta_n \approx d tan\theta_n = d \frac{x_ n }{D}<br>$$</p><ul><li>Each photon is represented as a plane wave at the slits.</li><li>The square of the amplitude of the recombined wave is proportional to the probability of finding the photon at this point</li></ul><details><summary>Plot code</summary><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br>Y = <span class="hljs-built_in">range</span>(-<span class="hljs-number">50</span>,<span class="hljs-number">50</span>)<br>X = <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,<span class="hljs-number">100</span>)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">waveFun</span>(<span class="hljs-params">x, t = <span class="hljs-number">0</span>, lamb = <span class="hljs-number">1</span>, pi = np.pi, T = <span class="hljs-number">1</span>, E0 = <span class="hljs-number">1</span></span>):</span><br>    E = E0 * np.sin(<span class="hljs-number">2</span> * pi * (x/lamb - t/T))<br>    <span class="hljs-keyword">return</span> E     <br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">WaveE</span>(<span class="hljs-params">X, Y, dy = <span class="hljs-number">0</span></span>):</span><br>    Points = []<br>    <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> X:<br>        <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> Y:<br>            Dis = np.sqrt((x/<span class="hljs-number">10</span>)**<span class="hljs-number">2</span> + (y/<span class="hljs-number">10</span>)**<span class="hljs-number">2</span>)<br>            Points += [[x, y + dy, waveFun(Dis)]]<br>    Points = np.array(Points)<br>    <span class="hljs-keyword">return</span> Points<br><br>P1 = WaveE(X, Y, <span class="hljs-number">0</span>)<br>P2 = WaveE(X, Y, <span class="hljs-number">10</span>)<br>P3 = WaveE(X, Y, -<span class="hljs-number">10</span>)<br><br>P1 = pd.DataFrame(P1, columns = [<span class="hljs-string">&#x27;x&#x27;</span>, <span class="hljs-string">&#x27;y&#x27;</span>, <span class="hljs-string">&quot;E1&quot;</span>])<br>P2 = pd.DataFrame(P2, columns = [<span class="hljs-string">&#x27;x&#x27;</span>, <span class="hljs-string">&#x27;y&#x27;</span>, <span class="hljs-string">&quot;E2&quot;</span>])<br>P3 = pd.DataFrame(P3, columns = [<span class="hljs-string">&#x27;x&#x27;</span>, <span class="hljs-string">&#x27;y&#x27;</span>, <span class="hljs-string">&quot;E3&quot;</span>])<br><br>TB = pd.merge(P1, P2)<br>TB = pd.merge(TB, P3)<br>TB[<span class="hljs-string">&#x27;E&#x27;</span>] = TB.E1 + TB.E2  + TB.E3<br><br>fig, ax = plt.subplots(subplot_kw=&#123;<span class="hljs-string">&quot;projection&quot;</span>: <span class="hljs-string">&quot;3d&quot;</span>&#125;, figsize=(<span class="hljs-number">6</span>,<span class="hljs-number">6</span>))<br>ax.plot_trisurf(TB.x, TB.y, TB.E, vmin=TB.E.<span class="hljs-built_in">min</span>() * <span class="hljs-number">2</span>, cmap=cm.coolwarm)<br>plt.show()<br><br><span class="hljs-comment">#plt.figure(figsize=(5, 5))</span><br><span class="hljs-comment">#plt.scatter(TB.x, TB.y, c= TB.E, marker=&#x27;o&#x27;, cmap=plt.cm.coolwarm,)</span><br><span class="hljs-comment">#plt.show()</span><br></code></pre></td></tr></table></figure></div></details><h2 id="Principle-of-Superposition">Principle of Superposition</h2><p>At the beginning of the story, let’s say there are two same waves with different $\phi$ which: $\phi_2 - \phi_1 = \pi$</p><p>In this case, the Intensity of this two wave is:</p><ul><li>$E^2_{sum} = (E_1 + E_2 )^2 = 0$</li><li>ps: <mark>Not</mark> $E^2_{sum} = E_1^2 + E_2^2 \neq 0$</li></ul><p>(Destructive interference)</p><h3 id="For-Two-Traveling-Waves">For Two Traveling Waves</h3><ul><li>Two sine waves with the same amplitude but slightly different frequencies traveling at the same velocity in the same direction</li></ul><p>$ E(x,t) = E^o sin(k_1 x - \omega _1 t) +E^o sin(k_2 x - \omega _2 t) $<br>$ = 2 E^o cos [\frac{[k_1 - k_2]}{2}x - \frac{\omega _1 - \omega _2}{2}t] sin[\frac{[k_1 - k_2]}{2}x - \frac{\omega _1 - \omega _2}{2}t] $</p><h2 id="Direction">Direction</h2><p>$$ 𝑛_1 \cdot sin 𝜃_1 = 𝑛_2 \cdot sin 𝜃_2 $$</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style><h2 id="Extra-Explore">Extra Explore</h2><p>Becuase we konw:</p><ul><li>$E(x,t) = E^0 \sin\left[2\pi \left(\frac{x}{\lambda} - \frac{t}{T}\right)\right]$</li></ul><p>So, when we move to the 2D wave, we could have function:</p><ul><li>$E(x, y, t) = E^0 \sin\left[2\pi \left(\frac{\sqrt{x^2 - y^2}}{\lambda} - \frac{t}{T}\right)\right]$</li></ul><p>In order to calcualte the 2D wave from the different emission location, we need to introduce the initial point b=(b<sub>x</sub>, b<sub>y</sub>)</p><ul><li>$E(x, y, b_x, b_y, t) = E^0 \sin\left[2\pi \left(\frac{\sqrt{(x-b_x)^2 - (y-b_y)^2}}{\lambda} - \frac{t}{T}\right)\right]$</li></ul><details><summary>Plot codes</details><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> NearestNeighbors<br><span class="hljs-keyword">import</span> pyvista <span class="hljs-keyword">as</span> pv<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">waveFun</span>(<span class="hljs-params">x, y, bx =<span class="hljs-number">0</span>, by = <span class="hljs-number">0</span>, t = <span class="hljs-number">0</span>, lamb = <span class="hljs-number">1</span>, pi = np.pi, T = <span class="hljs-number">1</span>, E0 = <span class="hljs-number">1</span></span>):</span><br>    E = E0 * np.sin(<span class="hljs-number">2</span> * pi * ((np.sqrt((x-bx)**<span class="hljs-number">2</span>+(y-by)**<span class="hljs-number">2</span>))/lamb - t/T))<br>    <span class="hljs-keyword">return</span> E     <br><br><br>X = np.arange(<span class="hljs-number">100</span>, step = <span class="hljs-number">.1</span>)<br>Y = np.arange(-<span class="hljs-number">50</span>,<span class="hljs-number">50</span>, step = <span class="hljs-number">.1</span>)<br>X, Y = np.meshgrid(X, Y)<br>Points = waveFun(X,X)<br><br>X = np.arange(-<span class="hljs-number">50</span>, <span class="hljs-number">50</span>, step = <span class="hljs-number">.1</span>)<br>Y = np.arange(-<span class="hljs-number">50</span>, <span class="hljs-number">50</span>, step = <span class="hljs-number">.1</span>)<br>X, Y = np.meshgrid(X, Y)<br>Points += waveFun(X,Y, lamb = <span class="hljs-number">.7</span>, T = <span class="hljs-number">.7</span>)<br><br>plt.imshow(Points)<br>plt.show()<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">200</span>):<br>    i = (i-<span class="hljs-number">100</span>)/<span class="hljs-number">20</span>  <br>    X = np.arange(<span class="hljs-number">100</span>, step = <span class="hljs-number">.1</span>)<br>    Y = np.arange(-<span class="hljs-number">50</span> + i,<span class="hljs-number">50</span> + i, step = <span class="hljs-number">.1</span>)<br>    X, Y = np.meshgrid(X, Y)<br>    Points += waveFun(X,Y)<br><br><br><span class="hljs-comment">#plt.scatter(points_array[:, 0], points_array[:, 1] + 0.5, c= points_array[:, 2], marker=&#x27;o&#x27;, cmap=plt.cm.coolwarm,)</span><br><span class="hljs-comment">#plt.show()</span><br><span class="hljs-comment"># Create a PyVista point cloud</span><br>point_cloud = pv.PolyData(points_array)<br>point_cloud[<span class="hljs-string">&#x27;point_color&#x27;</span>] = point_cloud.points[:, <span class="hljs-number">2</span>]<br>point_cloud.plot(point_size=<span class="hljs-number">5</span>,scalars=<span class="hljs-string">&#x27;point_color&#x27;</span>, cmap=<span class="hljs-string">&quot;jet&quot;</span>, show_bounds=<span class="hljs-literal">True</span>)<br><br><br><br><br><br><br>Y = <span class="hljs-built_in">range</span>(-<span class="hljs-number">100</span>,<span class="hljs-number">100</span>)<br>X = <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,<span class="hljs-number">200</span>)<br>Points = []<br><span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> X:<br>    x /=<span class="hljs-number">10</span><br>    <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> Y:<br>        y /=<span class="hljs-number">10</span><br>        E = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> by <span class="hljs-keyword">in</span> np.arange(-<span class="hljs-number">10</span>,<span class="hljs-number">11</span>, <span class="hljs-number">.1</span>):<br>            E += waveFun(x, y, <span class="hljs-number">0</span>, by)<br>        Points += [[x, y, E] ]<br><br>points_array = np.array(Points)<br><span class="hljs-comment">#plt.scatter(points_array[:, 0], points_array[:, 1] + 0.5, c= points_array[:, 2], marker=&#x27;o&#x27;, cmap=plt.cm.coolwarm,)</span><br><span class="hljs-comment">#plt.show()</span><br><span class="hljs-comment"># Create a PyVista point cloud</span><br>point_cloud = pv.PolyData(points_array)<br>point_cloud[<span class="hljs-string">&#x27;point_color&#x27;</span>] = point_cloud.points[:, <span class="hljs-number">2</span>]<br>point_cloud.plot(point_size=<span class="hljs-number">5</span>,scalars=<span class="hljs-string">&#x27;point_color&#x27;</span>, cmap=<span class="hljs-string">&quot;jet&quot;</span>, show_bounds=<span class="hljs-literal">True</span>)<br><br><br><br>point_cloud = pv.PolyData(Points)<br>volume = point_cloud.delaunay_3d(alpha = <span class="hljs-number">5</span>)<br>shell = volume.extract_geometry()<br>shell.plot(show_edges=<span class="hljs-literal">True</span>)<br><br>TB = pd.DataFrame(Points, columns = [<span class="hljs-string">&#x27;x&#x27;</span>, <span class="hljs-string">&#x27;y&#x27;</span>, <span class="hljs-string">&#x27;E&#x27;</span>])<br><br>fig, ax = plt.subplots(subplot_kw=&#123;<span class="hljs-string">&quot;projection&quot;</span>: <span class="hljs-string">&quot;3d&quot;</span>&#125;, figsize=(<span class="hljs-number">6</span>,<span class="hljs-number">6</span>))<br>P = ax.plot_trisurf(TB.x, TB.y, TB.E, vmin=TB.E.<span class="hljs-built_in">min</span>() * <span class="hljs-number">2</span>, cmap=plt.cm.coolwarm)<br>plt.show()<br><br><br><span class="hljs-keyword">from</span> scipy.interpolate <span class="hljs-keyword">import</span> griddata<br><br>df =TB<br>x1 = np.linspace(df[<span class="hljs-string">&#x27;x&#x27;</span>].<span class="hljs-built_in">min</span>(), df[<span class="hljs-string">&#x27;x&#x27;</span>].<span class="hljs-built_in">max</span>(), <span class="hljs-built_in">len</span>(df[<span class="hljs-string">&#x27;x&#x27;</span>].unique()))<br>y1 = np.linspace(df[<span class="hljs-string">&#x27;y&#x27;</span>].<span class="hljs-built_in">min</span>(), df[<span class="hljs-string">&#x27;y&#x27;</span>].<span class="hljs-built_in">max</span>(), <span class="hljs-built_in">len</span>(df[<span class="hljs-string">&#x27;y&#x27;</span>].unique()))<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">x, y via meshgrid for vectorized evaluation of</span><br><span class="hljs-string">2 scalar/vector fields over 2-D grids, given</span><br><span class="hljs-string">one-dimensional coordinate arrays x1, x2,..., xn.</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br>x2, y2 = np.meshgrid(x1, y1)<br><span class="hljs-comment"># Interpolate unstructured D-dimensional data.</span><br>z2 = griddata((df[<span class="hljs-string">&#x27;x&#x27;</span>], df[<span class="hljs-string">&#x27;y&#x27;</span>]), df[<span class="hljs-string">&#x27;E&#x27;</span>], (x2, y2), method=<span class="hljs-string">&#x27;cubic&#x27;</span>)<br><br><br><br><span class="hljs-comment"># Ready to plot</span><br>fig = plt.figure()<br>ax = fig.subplots(subplot_kw = &#123;<span class="hljs-string">&quot;projection&quot;</span>:<span class="hljs-string">&#x27;3d&#x27;</span>&#125;)<br><br>surf = ax.plot_surface(x2, y2, z2, rstride=<span class="hljs-number">1</span>, cstride=<span class="hljs-number">1</span>, cmap=plt.cm.coolwarm,<br>                       linewidth=<span class="hljs-number">0</span>, antialiased=<span class="hljs-literal">False</span>)<br>ax.set_zlim(-<span class="hljs-number">1.01</span>, <span class="hljs-number">1.01</span>)<br><br>ax.zaxis.set_major_locator(LinearLocator(<span class="hljs-number">10</span>))<br>ax.zaxis.set_major_formatter(FormatStrFormatter(<span class="hljs-string">&#x27;%.02f&#x27;</span>))<br>fig.colorbar(surf, shrink=<span class="hljs-number">0.5</span>, aspect=<span class="hljs-number">5</span>)<br>plt.title(<span class="hljs-string">&#x27;Meshgrid Created from 3 1D Arrays&#x27;</span>)<br><br>plt.show()<br><br></code></pre></td></tr></table></figure></div></details>]]></content>
    
    
    <summary type="html">Light in Physics</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>Using Vim as Python and R IDE</title>
    <link href="https://karobben.github.io/2024/01/03/Linux/nvimr/"/>
    <id>https://karobben.github.io/2024/01/03/Linux/nvimr/</id>
    <published>2024-01-03T20:42:34.000Z</published>
    <updated>2024-01-20T23:06:45.609Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Using-Vim-as-IDE">Using Vim as IDE</h2><p>Vim is a classic text editor known for efficiency, while NeoVim is its modernized fork with improvements like better plugin support. LunarVim, built on NeoVim, offers a pre-configured setup, making it easier for users to get a powerful, feature-rich environment without the hassle of individual configurations. Ideal for those new to Vim/NeoVim or seeking a ready-to-use development setup, LunarVim combines ease of setup with customizability. It’s particularly appealing for its integrated toolset, active community support, and a balance between functionality and performance, making it a great choice for a streamlined coding experience.</p><p>Plug: <a href="https://github.com/jamespeapen/Nvim-R/wiki">Nvim-R</a><br>Video Tutorial: <a href="https://www.youtube.com/watch?v=nm45WagtV3w">Rohit Farmer</a><br>Instruction following the video: <a href="https://gist.github.com/rohitfarmer/68cdadeaeeb196e8a6ecdebdee6e76a5">rohitfarmer</a></p><p>Final work:</p><table><thead><tr><th style="text-align:center"><img src="https://imgur.com/Pdzomq1.png" alt="Using vim as R IDE"></th></tr></thead><tbody><tr><td style="text-align:center">© Karobben</td></tr></tbody></table><h2 id="Installation">Installation</h2><p>Please install the latest NeoVim by following the <a href="https://github.com/neovim/neovim/blob/master/INSTALL.md">Neovim document</a> and <a href="https://www.lunarvim.org/docs/installation">LunarVim Document</a></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># install neovim</span><br><span class="hljs-comment"># sudo apt install neovim</span><br><span class="hljs-comment"># install vim-plug</span><br>curl -fLo ~/.<span class="hljs-built_in">local</span>/share/nvim/site/<span class="hljs-built_in">autoload</span>/plug.vim --create-dirs \<br>    https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim<br><br><span class="hljs-comment"># for storing the config file</span><br>mkdir ~/.config/nvim<br>touch ~/.config/nvim/init.vim<br><span class="hljs-comment"># for storing plug</span><br><span class="hljs-comment"># because all plug would be installed by here, you could just delete the directories here to delete plugs.</span><br>mkdir ~/.vim/plugged<br><span class="hljs-comment"># open and edit the config file</span><br>vim ~/.config/nvim/init.vim<br></code></pre></td></tr></table></figure></div><p>Save the lines below in the <code>~/.config/nvim/init.vim</code> file to install the pluges.</p><pre>" Specify a directory for plugins" - Avoid using standard Vim directory names like 'plugin'call plug#begin('~/.vim/plugged')" List of plugins." Make sure you use single quotes" Shorthand notationPlug 'jalvesaq/Nvim-R', { 'branch' : 'stable' }Plug 'ncm2/ncm2'Plug 'roxma/nvim-yarp'Plug 'gaalcaras/ncm-R'Plug 'preservim/nerdtree'Plug 'Raimondi/delimitMate'Plug 'patstockwell/vim-monokai-tasty'Plug 'itchyny/lightline.vim'" Initialize plugin systemcall plug#end()</pre><div class="admonition note"><p class="admonition-title">How to instsall the plunges</p><p>After stored the change, you need to open it again by using <code>nvim ~/.config/nvim/init.vim</code>. And then, under the command model (which is triggered by <code>:</code>), input <code>PlugInstall</code> (<code>PlugUpdate</code> if you want to update them). After you see the picture below which means you installed it successfully:<img src="https://imgur.com/SMB1YM3.png" alt="" /></p></div><p>By following the instruction from <a href="https://gist.github.com/rohitfarmer/68cdadeaeeb196e8a6ecdebdee6e76a5">rohitfarmer</a>’s post, we could add more things at the end of the <code>init.vim</code> file:</p><div class="admonition note"><p class="admonition-title">folding behavior</p><pre>" Set foldbehavior<p>set tabstop=2        &quot; Number of spaces that a <Tab> in the file counts for<br>set shiftwidth=2     &quot; Number of spaces to use for each step of (auto)indent<br>set softtabstop=2    &quot; Number of spaces that a <Tab> counts for while performing editing operations<br>set expandtab        &quot; Use spaces instead of tabs</p><p>set foldmethod=indent<br>set foldlevelstart=2    &quot; Start folding at an indent level greater than 2<br></pre></p><p>For quick unfold all codes:</p><pre>:set nofoldenable</pre></div><pre>" Set a Local Leader" With a map leader it's possible to do extra key combinations" like <leader>w saves the current filelet mapleader = ","let g:mapleader = ","" Plugin Related Settings" NCM2autocmd BufEnter * call ncm2#enable_for_buffer()    " To enable ncm2 for all buffers.set completeopt=noinsert,menuone,noselect           " :help Ncm2PopupOpen for more                                                    " information." NERD Treemap <leader>nn :NERDTreeToggle<CR>                  " Toggle NERD tree." Monokai-tastylet g:vim_monokai_tasty_italic = 1                  " Allow italics.colorscheme vim-monokai-tasty                       " Enable monokai theme." LightLine.vim set laststatus=2              " To tell Vim we want to see the statusline.let g:lightline = {   \ 'colorscheme':'monokai_tasty',   \ }" General NVIM/VIM Settings" Mouse Integrationset mouse=i                   " Enable mouse support in insert mode." Tabs & Navigationmap <leader>nt :tabnew<cr>    " To create a new tab.map <leader>to :tabonly<cr>     " To close all other tabs (show only the current tab).map <leader>tc :tabclose<cr>    " To close the current tab.map <leader>tm :tabmove<cr>     " To move the current tab to next position.map <leader>tn :tabn<cr>        " To swtich to next tab.map <leader>tp :tabp<cr>        " To switch to previous tab." Line Numbers & Indentationset backspace=indent,eol,start  " To make backscape work in all conditions.set ma                          " To set mark a at current cursor location.set number                      " To switch the line numbers on.set expandtab                   " To enter spaces when tab is pressed.set smarttab                    " To use smart tabs.set autoindent                  " To copy indentation from current line                                 " when starting a new line.set si                          " To switch on smart indentation." Searchset ignorecase                  " To ignore case when searching.set smartcase                   " When searching try to be smart about cases.set hlsearch                    " To highlight search results.set incsearch                   " To make search act like search in modern browsers.set magic                       " For regular expressions turn magic on." Bracketsset showmatch                   " To show matching brackets when text indicator                                 " is over them.set mat=2                       " How many tenths of a second to blink                                 " when matching brackets." Errorsset noerrorbells                " No annoying sound on errors." Color & Fontssyntax enable                   " Enable syntax highlighting.set encoding=utf8                " Set utf8 as standard encoding and                                  " en_US as the standard language." Enable 256 colors palette in Gnome Terminal.if $COLORTERM == 'gnome-terminal'    set t_Co=256endiftry    colorscheme desertcatchendtry" Files & Backupset nobackup                     " Turn off backup.set nowb                         " Don't backup before overwriting a file.set noswapfile                   " Don't create a swap file.set ffs=unix,dos,mac             " Use Unix as the standard file type." Return to last edit position when opening filesau BufReadPost * if line("'\"") > 1 && line("'\"") <= line("$") | exe "normal! g'\"" | endif</pre><h2 id="Basic-Usage-of-Nvim-R">Basic Usage of Nvim-R</h2><pre>Ctrl + W + HJKL   " Remove the cursor from window to window,nt               " Open a new tab,tn               " Move to the next tab,tp               " Back to the previous tab# code fold behaviorzc - Close (fold) the current fold under the cursor.zo - Open (unfold) the current fold under the cursor.za - Toggle between closing and opening the fold under the cursor.zR - Open all folds in the current buffer.zM - Close all folds in the current buffer.# Nvim-RCtrl + x + o      " Access the help information (auto fill)\rf               " Connect to R console.\rq               " Quit R console.\ro               " Open object bowser.\d                " Execute current line of code and move to the next line.\ss               " Execute a block of selected code.\aa               " Execute the entire script. This is equivalent to source().\xx               " Toggle comment in an R script.# NERDTree,nn               " Toggle NERDTree.</pre><h2 id="Basic-codes-for-nvim">Basic codes for nvim</h2><p>You could also included them into the <code>vim.init</code> file</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># wrap the words in it is too long</span><br>:<span class="hljs-built_in">set</span> wrap <br>:<span class="hljs-built_in">set</span> nowrap<br><span class="hljs-comment"># set the wrap behavior</span><br>:<span class="hljs-built_in">set</span> showbreak=↪\ <br></code></pre></td></tr></table></figure></div><h2 id="Bugs">Bugs</h2><p>After installed the Nvim-R (them master branch), you’ll have the error code below whenever you open nvim. Just ignore it and it would be fine.</p><pre>Error detected while processing function ROnJobStdout[40]..UpdateSynRhlist[11]..FunHiOtherBf:line   10:E117: Unknown function: nvim_set_option_valuePress ENTER or type command to continue</pre><h2 id="Configure-for-LuanrVim">Configure for LuanrVim</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">curl --proto <span class="hljs-string">&#x27;=https&#x27;</span> --tlsv1.2 -sSf https://sh.rustup.rs | sh<br>cat <span class="hljs-string">&quot;<span class="hljs-variable">$HOME</span>/.cargo/env&quot;</span> &gt;&gt; ~/.zshrc<br><span class="hljs-built_in">source</span> ~/.zshrc<br><br><span class="hljs-comment"># install LunarVim</span><br>LV_BRANCH=<span class="hljs-string">&#x27;release-1.3/neovim-0.9&#x27;</span> bash &lt;(curl -s https://raw.githubusercontent.com/LunarVim/LunarVim/release-1.3/neovim-0.9/utils/installer/install.sh)<br><br>rm -rf ~/.config/lvim/<br>git <span class="hljs-built_in">clone</span> https://github.com/Karobben/kickstart.nvim.git ~/.config/lvim<br></code></pre></td></tr></table></figure></div><h3 id="Nerd-font">Nerd font</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># curl -fsSL https://raw.githubusercontent.com/ronniedroid/getnf/master/install.sh | bash</span><br>mkdir -p ~/.<span class="hljs-built_in">local</span>/share/fonts<br><span class="hljs-built_in">cd</span> ~/.<span class="hljs-built_in">local</span>/share/fonts &amp;&amp; curl -fLO https://github.com/ryanoasis/nerd-fonts/raw/HEAD/patched-fonts/DroidSansMono/DroidSansMNerdFont-Regular.otf<br>fc-cache -f -v<br></code></pre></td></tr></table></figure></div><h3 id="Words-Editing">Words Editing</h3><p>For editing the word, we need to switch the model of read, visual, and editing. Press <code>i</code> enable the editing mode. Type <code>Esc</code> or <code>Ctrl + c</code> exist the editing mode and back to the reading mode. <code>v</code> enable selection model so you could select words.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="LIVECODESERVER"><figure class="iseeu highlight /livecodeserver"><table><tr><td class="code"><pre><code class="hljs livecodeserver">i                   enter editing mode<br>dd                  cut <span class="hljs-keyword">the</span> selected <span class="hljs-built_in">line</span> <span class="hljs-keyword">into</span> paste board<br>p                   paste <span class="hljs-keyword">the</span> coppied contents<br>v                   selecte mode <span class="hljs-built_in">to</span> selecte multiple <span class="hljs-keyword">words</span> <span class="hljs-keyword">and</span> <span class="hljs-keyword">lines</span><br>    wd              <span class="hljs-built_in">delete</span> <span class="hljs-keyword">the</span> selected <span class="hljs-keyword">words</span>/<span class="hljs-keyword">lines</span><br>    y               copy <span class="hljs-keyword">the</span> selected <span class="hljs-keyword">words</span>/<span class="hljs-keyword">lines</span><br>    p               repalce <span class="hljs-keyword">the</span> selected workds/<span class="hljs-keyword">lines</span> <span class="hljs-keyword">with</span> coppied contents<br>o                   Start <span class="hljs-keyword">a</span> <span class="hljs-built_in">new</span> <span class="hljs-built_in">line</span><br>:&gt;                  Intend <span class="hljs-keyword">the</span> selected <span class="hljs-built_in">line</span> <br>:&gt;&gt;                 Intend tiwce<br>:&lt;                  Undo <span class="hljs-keyword">the</span> intend<br>: m <span class="hljs-number">10</span>              Move <span class="hljs-keyword">the</span> selected <span class="hljs-keyword">words</span>/<span class="hljs-built_in">line</span> <span class="hljs-keyword">into</span> <span class="hljs-built_in">line</span> <span class="hljs-number">10</span><br>Alt+ j/k        Move selected <span class="hljs-keyword">words</span>/<span class="hljs-keyword">lines</span> up/donw<br></code></pre></td></tr></table></figure></div><h3 id="Cursor-Related">Cursor Related</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="LIVECODESERVER"><figure class="iseeu highlight /livecodeserver"><table><tr><td class="code"><pre><code class="hljs livecodeserver">h                   moving left<br>j                   moving down<br>k                   moving up<br>l                   moving <span class="hljs-literal">right</span><br>:<span class="hljs-number">10</span>                 moving <span class="hljs-built_in">to</span> <span class="hljs-built_in">line</span> <span class="hljs-number">10</span><br>w                   moving <span class="hljs-built_in">to</span> <span class="hljs-keyword">the</span> head <span class="hljs-keyword">of</span> <span class="hljs-keyword">the</span> next <span class="hljs-built_in">word</span><br>e                   moving <span class="hljs-built_in">to</span> <span class="hljs-keyword">the</span> <span class="hljs-function"><span class="hljs-keyword">end</span> <span class="hljs-title">of</span> <span class="hljs-title">the</span> <span class="hljs-title">word</span></span><br>b                   moving <span class="hljs-built_in">to</span> <span class="hljs-keyword">the</span> head <span class="hljs-keyword">of</span> <span class="hljs-keyword">the</span> previous <span class="hljs-built_in">word</span><br>ge                  moving back <span class="hljs-built_in">to</span> <span class="hljs-keyword">the</span> <span class="hljs-function"><span class="hljs-keyword">end</span> <span class="hljs-title">of</span> <span class="hljs-title">the</span> <span class="hljs-title">word</span></span><br><br>gg                  moving <span class="hljs-built_in">to</span> <span class="hljs-keyword">the</span> top <span class="hljs-keyword">of</span> <span class="hljs-keyword">the</span> <span class="hljs-built_in">file</span><br>G                   moving <span class="hljs-built_in">to</span> <span class="hljs-keyword">the</span> <span class="hljs-function"><span class="hljs-keyword">end</span> <span class="hljs-title">of</span> <span class="hljs-title">the</span> <span class="hljs-title">file</span></span><br>Ctrl + f            page foward (donw)<br>Ctrl + b            page back (up)<br></code></pre></td></tr></table></figure></div><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="VIM"><figure class="iseeu highlight /vim"><table><tr><td class="code"><pre><code class="hljs vim"><span class="hljs-symbol">&lt;leader&gt;</span> <span class="hljs-keyword">e</span>          <span class="hljs-keyword">open</span> directory exploer<br><span class="hljs-symbol">&lt;leader&gt;</span> <span class="hljs-keyword">w</span>          save the <span class="hljs-keyword">edit</span> <span class="hljs-keyword">file</span> (:<span class="hljs-keyword">w</span>)<br><br># about <span class="hljs-keyword">tab</span><br><span class="hljs-symbol">&lt;leader&gt;</span> bb         back <span class="hljs-keyword">to</span> the <span class="hljs-keyword">tab</span> <span class="hljs-keyword">left</span><br><span class="hljs-symbol">&lt;leader&gt;</span> <span class="hljs-keyword">bn</span>         <span class="hljs-keyword">go</span> <span class="hljs-keyword">to</span> the <span class="hljs-keyword">next</span> <span class="hljs-keyword">tab</span> (<span class="hljs-keyword">right</span>)<br>:<span class="hljs-keyword">bd</span>                 <span class="hljs-keyword">close</span> the current <span class="hljs-keyword">tab</span><br><br><span class="hljs-symbol">&lt;Alt&gt;</span> <span class="hljs-number">1</span>/<span class="hljs-number">2</span>/<span class="hljs-number">3</span>         <span class="hljs-keyword">open</span> <span class="hljs-keyword">a</span> terminal (<span class="hljs-keyword">only</span> when you installed the pluges)<br><span class="hljs-symbol">&lt;Ctrl&gt;</span> <span class="hljs-keyword">w</span>            swtich between windows<br><br>:<span class="hljs-keyword">set</span> mouse-=<span class="hljs-keyword">a</span>       Disable the mouse selection<br>:<span class="hljs-keyword">set</span> mouse=<span class="hljs-keyword">a</span>        Inable the mouse <br></code></pre></td></tr></table></figure></div><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Using Vim as Python and R IDE, easy configure</summary>
    
    
    
    <category term="Linux" scheme="https://karobben.github.io/categories/Linux/"/>
    
    
    <category term="IDE" scheme="https://karobben.github.io/tags/IDE/"/>
    
    <category term="vim" scheme="https://karobben.github.io/tags/vim/"/>
    
  </entry>
  
  <entry>
    <title>Structure of the Immunoglobulin</title>
    <link href="https://karobben.github.io/2024/01/02/LearnNotes/igstructure/"/>
    <id>https://karobben.github.io/2024/01/02/LearnNotes/igstructure/</id>
    <published>2024-01-02T16:53:01.000Z</published>
    <updated>2024-01-12T00:29:13.787Z</updated>
    
    <content type="html"><![CDATA[<h2 id="The-Structure-of-the-Immunoglobulin">The Structure of the Immunoglobulin</h2><table><thead><tr><th style="text-align:center"><img src="https://www.researchgate.net/publication/337733518/figure/fig2/AS:832370903097347@1575464096611/Basic-structure-of-an-IgG-antibody-The-IgG-antibody-is-made-out-of-variable-V-and.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.researchgate.net/publication/337733518_Quantitative_Mass_Spectrometric_Analysis_of_Autoantibodies_as_a_Paradigm_Shift_in_Autoimmune_Serology">© Adrian Y. S. Lee</a></td></tr></tbody></table><p>Immunoglobulins, commonly known as antibodies, are crucial proteins in the immune system that recognize and bind to specific antigens, such as bacteria and viruses, to help protect the body. Their structure is both unique and complex, consisting of several key components:</p><ol><li><p><strong>Basic Structure</strong>: Immunoglobulins are Y-shaped molecules made up of four polypeptide chains - two identical heavy (H) chains and two identical light (L) chains. These chains are held together by disulfide bonds.</p></li><li><p><strong>Variable (V) and Constant © Regions</strong>:</p><ul><li><strong>Variable Regions</strong>: The tips of the ‘Y’ shape consist of the variable regions of the light and heavy chains. These regions are highly diverse and are responsible for the antigen-binding specificity of the antibody.</li><li><strong>Constant Regions</strong>: The rest of the molecule forms the constant region, which is relatively conserved across different antibodies. The constant region of the heavy chains determines the class or isotype (e.g., IgG, IgM, IgA, IgE, IgD) of the antibody and mediates effector functions.</li></ul></li><li><p><strong>Isotypes</strong>: Mammals have several classes of immunoglobulins (IgG, IgA, IgM, IgE, IgD), each with different roles in the immune response. These isotypes differ mainly in their heavy chain constant regions.</p></li><li><p><strong>Glycosylation</strong>: Many antibodies are glycosylated, meaning they have carbohydrate groups attached. This glycosylation can affect the antibody’s stability, distribution, and activity.</p></li><li><p><strong>Light Chain Types</strong>: There are two types of light chains in antibodies - kappa (<mark>κ</mark>) and lambda (<mark>λ</mark>). An individual antibody will have two identical light chains of one type.</p></li></ol><h2 id="V-D-J">V(D)J</h2><table><thead><tr><th style="text-align:center"><img src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5089068/bin/nihms-673138-f0001.jpg" alt=""></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5089068/">© David B. Roth</a></td></tr></tbody></table><p>V(D)J recombination is a mechanism in the immune system that generates the immense diversity of antibodies (immunoglobulins) and T cell receptors necessary for the adaptive immune response. This process is named for the three gene segments involved in the recombination: Variable (V), Diversity (D), and Joining (J). So, V(D)J is the recombination unit.</p><h3 id="V-D-J-in-3D-Structure">V(D)J in 3D Structure</h3><p>We take <code>5wl2</code> as example:</p><table><thead><tr><th style="text-align:center"><img src="https://cdn.rcsb.org/images/structures/5wl2_assembly-1.jpeg" alt=""></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.rcsb.org/structure/5wl2">©PDB 5wl2</a></td></tr></tbody></table><h2 id="Kabat-Number">Kabat Number</h2><table><thead><tr><th style="text-align:center"><img src="https://assets-global.website-files.com/628cfd01406f3f5bb9c8477d/63821c6283c0cdf36d5289da_Antibody-numbering-IMGT-Kabat-Chothia.png" alt="Kabat number"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://pipebio.com/blog/antibody-numbering">© pipebio</a></td></tr></tbody></table><p>How to make it in python:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> abnumber <span class="hljs-keyword">import</span> Chain<br><br>Fasta = <span class="hljs-string">&quot;xxx.fa&quot;</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(Fasta, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> F:<br>    Seq = F.read()<br><br>KABAT = pd.DataFrame([<span class="hljs-built_in">dict</span>(Chain(i, scheme=<span class="hljs-string">&#x27;kabat&#x27;</span>)) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span>  Seq.split(<span class="hljs-string">&#x27;\n&#x27;</span>)[:-<span class="hljs-number">2</span>] <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;&gt;&quot;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> i])<br></code></pre></td></tr></table></figure></div><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Structure of the Immunoglobulin</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>ImageMagick: convert</title>
    <link href="https://karobben.github.io/2023/12/25/Linux/convert/"/>
    <id>https://karobben.github.io/2023/12/25/Linux/convert/</id>
    <published>2023-12-25T23:16:09.000Z</published>
    <updated>2023-12-26T01:02:50.382Z</updated>
    
    <content type="html"><![CDATA[<p>Documentation: <a href="https://imagemagick.org/script/command-line-tools.php">imagemagick.org</a></p><p>The <code>convert</code> command in Linux is a part of the ImageMagick suite, a powerful toolset for image manipulation. This command allows you to convert between different image formats, resize images, change image quality, and perform a wide variety of other image transformations.</p><p>Here are a few basic examples of what you can do with the <code>convert</code> command:</p><ol><li><strong>Converting an Image Format:</strong><br>To convert a JPEG image to a PNG, you would use:</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">convert image.jpg image.png<br></code></pre></td></tr></table></figure></div><ol start="2"><li><strong>Resizing an Image:</strong><br>To resize an image to a specific width and height (e.g., 100x100 pixels), you can use:</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># based on the pixel of x*y </span><br>convert original.jpg -resize 100x100 resized.jpg<br><span class="hljs-comment"># based on the ratio </span><br>convert original.jpg -resize 30% reduced.jpg<br><span class="hljs-comment"># based on the ratio of x*y</span><br>convert original.jpg -resize 50%x30% reduced.jpg<br></code></pre></td></tr></table></figure></div><ol start="3"><li><strong>Changing Image Quality:</strong><br>To change the quality of a JPEG image, useful for reducing file size, use:</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">convert original.jpg -quality 85 compressed.jpg<br></code></pre></td></tr></table></figure></div><ol start="4"><li><strong>Combining Multiple Images:</strong><br>To combine multiple images into one, for instance, side by side:</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">convert image1.jpg image2.jpg +append combined.jpg<br></code></pre></td></tr></table></figure></div><ol start="5"><li><strong>Converting a PDF to an Image:</strong><br>To convert a PDF file to a series of images, you can use:</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">convert document.pdf document.png<br></code></pre></td></tr></table></figure></div><ol start="6"><li><strong>Creating an Animated GIF:</strong><br>To create an animated GIF from a series of images:</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">convert -delay 20 -loop 0 frame1.png frame2.png frame3.png animated.gif<br></code></pre></td></tr></table></figure></div><p>These examples are just the tip of the iceberg in terms of what ImageMagick’s <code>convert</code> command can do. It’s a very powerful tool with a wide array of options and capabilities. For more detailed information, you can check the manual page (<code>man convert</code>) or the official ImageMagick documentation.</p><h2 id="Other-Functions-You-May-Want-to-Know">Other Functions You May Want to Know</h2><p>Certainly! Here are examples demonstrating various capabilities of ImageMagick:</p><ol><li><strong>Image Composition:</strong><br>Overlay one image on top of another (watermark):</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">convert background.jpg watermark.png -gravity center -composite output.jpg<br></code></pre></td></tr></table></figure></div><ol start="2"><li><strong>Color Manipulation:</strong><br>Convert an image to grayscale:</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">convert original.jpg -colorspace Gray grayscale.jpg<br></code></pre></td></tr></table></figure></div><ol start="3"><li><strong>Cropping:</strong><br>Crop an image to a 100x100 pixel square starting at (50,50):</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">convert original.jpg -crop 100x100+50+50 cropped.jpg<br></code></pre></td></tr></table></figure></div><ol start="4"><li><strong>Rotating and Flipping:</strong><br>Rotate an image by 90 degrees:</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">convert original.jpg -rotate 90 rotated.jpg<br></code></pre></td></tr></table></figure></div><ol start="5"><li><strong>Blurring and Sharpening:</strong><br>Apply a Gaussian blur:</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">convert original.jpg -blur 0x8 blurred.jpg<br></code></pre></td></tr></table></figure></div><ol start="6"><li><strong>Drawing:</strong><br>Draw a red rectangle:</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">convert original.jpg -fill none -stroke red -draw <span class="hljs-string">&quot;rectangle 10,10 50,50&quot;</span> output.jpg<br></code></pre></td></tr></table></figure></div><ol start="7"><li><strong>Format Conversion:</strong><br>Convert an image to a different format (e.g., PNG to GIF):</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">convert image.png image.gif<br></code></pre></td></tr></table></figure></div><ol start="8"><li><strong>Handling Transparency:</strong><br>Make the white background of an image transparent:</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">convert original.jpg -transparent white output.png<br></code></pre></td></tr></table></figure></div><ol start="9"><li><strong>Image Annotation:</strong><br>Add text to an image:</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">convert original.jpg -pointsize 24 -fill black -annotate +50+50 <span class="hljs-string">&#x27;Sample Text&#x27;</span> output.jpg<br></code></pre></td></tr></table></figure></div><ol start="10"><li><strong>Special Effects:</strong><br>Add a shadow to an image:</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">convert original.jpg \( +<span class="hljs-built_in">clone</span> -background black -shadow 60x5+10+10 \) +swap -background none -layers merge +repage shadow.jpg<br></code></pre></td></tr></table></figure></div><ol start="11"><li><strong>Image Optimization:</strong><br>Optimize an image for the web (reduce file size):</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">convert original.jpg -strip -interlace Plane -gaussian-blur 0.05 -quality 85% optimized.jpg<br></code></pre></td></tr></table></figure></div><ol start="12"><li><strong>Batch Processing:</strong><br>Resize all PNG images in a directory (example in a bash loop):</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-keyword">for</span> img <span class="hljs-keyword">in</span> *.png; <span class="hljs-keyword">do</span> convert <span class="hljs-string">&quot;<span class="hljs-variable">$img</span>&quot;</span> -resize 50% <span class="hljs-string">&quot;resized_<span class="hljs-variable">$img</span>&quot;</span>; <span class="hljs-keyword">done</span><br></code></pre></td></tr></table></figure></div><ol start="13"><li><strong>Image Analysis:</strong><br>Get image information (format, dimensions, etc.):</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">identify -verbose image.jpg<br></code></pre></td></tr></table></figure></div><ol start="14"><li><strong>Creating Thumbnails:</strong><br>Generate a thumbnail:</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">convert original.jpg -thumbnail 100x100 thumbnail.jpg<br></code></pre></td></tr></table></figure></div><ol start="15"><li><strong>Morphing and Transforming:</strong><br>Morph between two images:</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">convert image1.jpg image2.jpg -morph 10 morph_output.jpg<br></code></pre></td></tr></table></figure></div><p>These commands showcase the versatility of ImageMagick. Remember to adjust the file names and parameters according to your specific needs. The ImageMagick documentation provides more detailed information and examples for these and other features.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">ImageMagick: convert</summary>
    
    
    
    <category term="Linux" scheme="https://karobben.github.io/categories/Linux/"/>
    
    <category term="Software" scheme="https://karobben.github.io/categories/Linux/Software/"/>
    
    
    <category term="Image" scheme="https://karobben.github.io/tags/Image/"/>
    
    <category term="Linux" scheme="https://karobben.github.io/tags/Linux/"/>
    
    <category term="bash" scheme="https://karobben.github.io/tags/bash/"/>
    
    <category term="Scripting" scheme="https://karobben.github.io/tags/Scripting/"/>
    
    <category term="CLI Tools" scheme="https://karobben.github.io/tags/CLI-Tools/"/>
    
  </entry>
  
  <entry>
    <title>IMGT®: the international ImMunoGeneTics information system®</title>
    <link href="https://karobben.github.io/2023/12/25/Bioinfor/imgt/"/>
    <id>https://karobben.github.io/2023/12/25/Bioinfor/imgt/</id>
    <published>2023-12-25T17:06:14.000Z</published>
    <updated>2023-12-25T19:08:52.156Z</updated>
    
    <content type="html"><![CDATA[<h2 id="What-is-IMGT">What is IMGT</h2><p>IMGT® provides a range of databases, tools, and web resources focused on the immune system, particularly on the genetic and structural aspects of immunoglobulins (IG), T cell receptors (TCR), major histocompatibility complex (MHC) of all vertebrate species, and related proteins of the immune system (RPI) of any species. These resources are crucial for research in various fields, including immunology, genetics, bioinformatics, drug design, and personalized medicine.</p><p>Key features and offerings of IMGT® include:</p><ol><li><p><strong>Databases:</strong> IMGT® offers several databases containing detailed information on IG, TCR, and MHC sequences and structures, along with RPI. These databases are meticulously curated and regularly updated.</p></li><li><p><strong>Analysis Tools:</strong> IMGT® provides tools for sequence analysis, gene identification, and 3D structure determination. IMGT/V-QUEST, for instance, is a widely used tool for the analysis of IG and TCR sequences.</p></li><li><p><strong>Standardized Nomenclature:</strong> IMGT® has established a standardized nomenclature for the description of IG and TCR genetic components, which is essential for consistent communication and research in the field.</p></li><li><p><strong>Educational Resources:</strong> The system also offers educational resources for those new to the field of immunogenetics, including tutorials, glossaries, and comprehensive descriptions of the molecular components of the immune system.</p></li><li><p><strong>Research and Clinical Applications:</strong> The information and tools provided by IMGT® are invaluable for various applications, including research in immunology, genetics, and autoimmunity, as well as in clinical settings for antibody engineering, diagnosis, and understanding of immune disorders.</p></li></ol><h2 id="Main-Service-of-the-IMGT">Main Service of the IMGT</h2><table><thead><tr><th><strong>Category</strong></th><th><strong>Name</strong></th><th><strong>Description/Focus Area</strong></th></tr></thead><tbody><tr><td><strong>Databases</strong></td><td>IMGT/GENE-DB</td><td>Database for immunoglobulin (IG) and T cell receptor (TCR) genes of all vertebrate species.</td></tr><tr><td></td><td>IMGT/3Dstructure-DB</td><td>Database for 3D structures of IG, TCR, MHC, and RPI (related proteins of the immune system).</td></tr><tr><td></td><td>IMGT/LIGM-DB</td><td>A comprehensive database of IG and TCR nucleotide sequences from various species.</td></tr><tr><td></td><td>IMGT/PRIMER-DB</td><td>Database of primers and probes for IG and TCR gene sequences.</td></tr><tr><td></td><td>IMGT/PROTEIN-DB</td><td>Database for IG, TCR, MHC, and RPI protein sequences and structures.</td></tr><tr><td><strong>Analysis Tools</strong></td><td><mark>IMGT/V-QUEST</mark></td><td>Tool for the analysis of IG and TCR nucleotide sequences. Identifies V, D, and J gene segments and alleles.</td></tr><tr><td></td><td><mark>IMGT/JunctionAnalysis</mark></td><td>Tool focused on detailed analysis of the V-J and V-D-J junctions of IG and TCR sequences.</td></tr><tr><td></td><td>IMGT/HighV-QUEST</td><td>High-throughput version of IMGT/V-QUEST for next-generation sequencing (NGS) data.</td></tr><tr><td></td><td>IMGT/DomainGapAlign</td><td>Tool for the analysis of IG, TCR, and RPI domain sequences and comparison with IMGT reference directory.</td></tr><tr><td></td><td>IMGT/Collier-de-Perles</td><td>Tool for two-dimensional (2D) graphical representation of IG and TCR variable domains.</td></tr><tr><td><strong>Resources</strong></td><td>IMGT Education</td><td>Educational resources, including tutorials, glossaries, and comprehensive descriptions of immunogenetics.</td></tr><tr><td></td><td>IMGT Scientific chart</td><td>Standardized nomenclature and classification for IG, TCR, and MHC of humans and other vertebrates.</td></tr><tr><td></td><td>IMGT Repertoire</td><td>Compilation of allelic polymorphisms and protein displays for variable (V), diversity (D), and joining (J) genes.</td></tr><tr><td><strong>Other Services</strong></td><td>IMGT/Therapeutic</td><td>Information on therapeutic antibodies and fusion proteins for immune applications.</td></tr><tr><td></td><td>IMGT/mAb-DB</td><td>Specific database for monoclonal antibodies (mAbs).</td></tr></tbody></table><h2 id="What-is-IMGT-V-QUEST-database">What is IMGT/V-QUEST database?</h2><p>IMGT/V-QUEST is a specialized database and analysis tool that is part of the broader IMGT®, the international ImMunoGeneTics information system®. This system is a high-quality integrated knowledge resource specializing in immunoglobulins (IG), T cell receptors (TCR), major histocompatibility complex (MHC) of all vertebrate species, and related proteins of the immune system (RPI) of any species.</p><p>IMGT/V-QUEST specifically provides detailed analysis of nucleotide sequences for immunoglobulins (IG) and T cell receptors (TCR). It is widely used in immunology and related research fields for tasks such as:</p><ol><li><p><strong>Sequence Analysis:</strong> It allows for the identification and delimitation of V, D, and J genes and alleles in the input sequences. This is crucial for understanding the genetic basis of the immune response.</p></li><li><p><strong>Clonotype Characterization:</strong> Researchers use it to characterize the clonotypes (unique T cell or B cell receptor sequences) in an individual’s immune repertoire, which is important in studies of immune system diversity and response.</p></li><li><p><strong>Somatic Hypermutation Studies:</strong> It helps in the analysis of somatic hypermutations, which are critical for understanding adaptive immunity and processes like affinity maturation.</p></li><li><p><strong>Comparative Immunology:</strong> By providing a comprehensive and curated database of IG and TCR sequences across different species, it aids in comparative immunology studies.</p></li></ol><p>As of my last update in April 2023, IMGT/V-QUEST continues to be a valuable resource for immunologists, molecular biologists, and other researchers studying the adaptive immune system. The database is regularly updated to include new findings and sequences, ensuring its relevance and usefulness in the field.</p><div class="admonition note"><p class="admonition-title">Something You May Want to Know</p><p>c16 &gt; g, Q6 &gt; E (++−) means that the nt mutation (c &gt; g) leads to an AA change at codon 6 with the same hydropathy (+) and volume (+) but with different physicochemical properties (−) classes ( 12 )[^Pommié_04].</p></div><h2 id="What-is-IMGT-Ontology">What is IMGT-Ontology?</h2><p>IMGT/Ontology is a key component of IMGT®, the international ImMunoGeneTics information system®. It represents the first ontology for immunogenetics and immunoinformatics and is a foundational aspect of the IMGT® information system. Developed by Marie-Paule Lefranc and her team, IMGT/Ontology provides a standardized vocabulary and a set of concepts that are essential for the consistent annotation, description, and comparison of the immune system’s components across different species. So, <strong>IMGT/Ontology is more of a set of criteria or a framework rather than a specific tool or software.</strong></p><p>Key features and aspects of IMGT/Ontology include:</p><details><summary>1. Standardized Vocabulary</summary>IMGT/Ontology provides a controlled vocabulary for the description of immunogenetic sequences. This includes terms for genes, alleles, and other genetic elements relevant to immunogenetics.</details><details><summary>2. Classification Criteria</summary>It establishes clear and standardized criteria for the classification of immunoglobulins (IG), T cell receptors (TCR), and major histocompatibility complex (MHC) molecules. This classification is crucial for the accurate comparison and analysis of these molecules.</details><details><summary>3. Identification of Key Concepts</summary>The ontology identifies and defines key concepts in immunogenetics, such as gene segment functionality, recombination features, and junctional diversity. These concepts are critical for understanding the adaptive immune response.</details><details><summary>4. IMGT-ONTOLOGY Axioms</summary>These are the rules that define the relations between the concepts and are used for the annotation and description of the IG, TCR, and MHC sequences in the IMGT® databases and tools.</details><details><summary>5. Facilitating Data Integration and Analysis</summary>By providing a common framework and language, IMGT/Ontology enables the integration, analysis, and sharing of immunogenetic data across different research projects and databases.</details><details><summary>6. Support for Research and Clinical Applications</summary>The standardized approach of IMGT/Ontology supports various research and clinical applications, including antibody engineering, vaccine development, and the study of immune responses.</details><br><div class="admonition note"><p class="admonition-title">IMGT-ONTOLOGY axioms and concepts</p></div><blockquote><p>Seven IMGT-ONTOLOGY axioms have been defined: ‘IDENTIFICATION’ <sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>, ‘DESCRIPTION’ <sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>, ‘CLASSIFICATION’ <sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>, ‘NUMEROTATION’ <sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup><sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup>, ‘LOCALIZATION’, ‘ORIENTATION’, and ‘OBTENTION’. They constitute the Formal IMGT-ONTOLOGY or IMGT-Kaleidoscope <sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup>.</p></blockquote><table><thead><tr><th style="text-align:center"><img src="https://www.imgt.org/IMGTeducation/Tutorials/Ontology/UK/Figure3.png" alt="IMGT-ONTOLOGY"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.imgt.org/IMGTeducation/Tutorials/index.php?article=Ontology&amp;lang=UK&amp;nbr=all">© IMGT Education</a></td></tr></tbody></table><p>IMGT/Ontology is a critical resource for researchers and professionals in immunology, genetics, bioinformatics, and related fields. It ensures that data and analyses are consistent, reproducible, and interoperable, which is vital in advancing our understanding of the immune system and in developing immunotherapy and other medical applications.</p><p>The oldest paper about ontology:</p><ul><li>1999: <a href="https://academic.oup.com/bioinformatics/article/15/12/1047/248534">Ontology for immunogenetics: the IMGT-ONTOLOGY</a> <sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup><ul><li>The first ontology to be developed for immunogenetics. ‘An ontology is a specification of conceptualization’ (Gruber, 1993).</li><li>Covers four main concepts: ‘IDENTIFICATION’, ‘DESCRIPTION’, ‘CLASSIFICATION’ and ‘OBTENTION’.</li></ul></li><li>2008: <a href="https://www.sciencedirect.com/science/article/abs/pii/S0300908407002453">IMGT-Kaleidoscope, the formal IMGT-ONTOLOGY paradigm</a><sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup><ul><li>seven axioms, ‘IDENTIFICATION’, ‘DESCRIPTION’, ‘CLASSIFICATION’, ‘NUMEROTATION’, ‘LOCALIZATION’, ‘ORIENTATION’ and ‘OBTENTION’</li></ul></li></ul><h3 id="References">References</h3><ol><li><a href="https://www.imgt.org/IMGTindex/ontology.php">IMGT®: Ontology (IMGT-ONTOLOGY)</a></li><li><a href="https://www.sciencedirect.com/science/article/abs/pii/S0300908407002453">Duroux P, Kaas Q, Brochet X, et al. IMGT-Kaleidoscope, the formal IMGT-ONTOLOGY paradigm[J]. Biochimie, 2008, 90(4): 570-583.</a></li><li><a href="https://www.frontiersin.org/articles/10.3389/fgene.2012.00079/full">Giudicelli V, Lefranc M P. Imgt-ontology 2012[J]. Frontiers in genetics, 2012, 3: 79.</a></li><li><a href="https://www.frontiersin.org/articles/10.3389/fimmu.2014.00022/full">Lefranc M P. Immunoglobulin and T cell receptor genes: IMGT® and the birth and rise of immunoinformatics[J]. Frontiers in immunology, 2014, 5: 22.</a></li></ol><h2 id="Other-References">Other References</h2><ol><li><a href="https://academic.oup.com/nar/article/36/suppl_2/W503/2506795?login=false">Brochet X, Lefranc M P, Giudicelli V. IMGT/V-QUEST: the highly customized and integrated system for IG and TR standardized VJ and VDJ sequence analysis[J]. Nucleic acids research, 2008, 36(suppl_2): W503-W508.</a></li></ol><style>pre {  background-color:#38393d;  color: #5fd381;}</style><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>Lefranc, M.-P. From IMGT-ONTOLOGY IDENTIFICATION Axiom to IMGT Standardized Keywords: For Immunoglobulins (IG), T Cell Receptors (TR), and Conventional Genes. Cold Spring Harb Protoc., 1;2011(6): 604-613. pii: pdb.ip82. doi: 10.1101/pdb.ip82(2011) PMID:21632792. <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>Lefranc, M.-P. From IMGT-ONTOLOGY DESCRIPTION Axiom to IMGT Standardized Labels: For Immunoglobulin (IG) and T Cell Receptor (TR) Sequences and Structures. Cold Spring Harb Protoc., 1;2011(6): 614-626. pii: pdb.ip83. doi: 10.1101/pdb.ip83 (2011) PMID:21632791. <a href="#fnref2" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>Lefranc, M.-P. From IMGT-ONTOLOGY CLASSIFICATION Axiom to IMGT Standardized Gene and Allele Nomenclature: For Immunoglobulins (IG) and T Cell Receptors (TR). Cold Spring Harb Protoc., 1;2011(6): 627-632. pii: pdb.ip84. doi: 10.1101/pdb.ip84 (2011) PMID:21632790. <a href="#fnref3" class="footnote-backref">↩︎</a></p></li><li id="fn4" class="footnote-item"><p>Lefranc, M.-P. “IMGT Collier de Perles for the Variable (V), Constant ©, and Groove (G) Domains of IG, TR, MH, IgSF, and MhSF” Cold Spring Harb Protoc. 2011 Jun 1;2011(6). pii: pdb.ip86. doi: 10.1101/pdb.ip86. PMID: 21632788 <a href="#fnref4" class="footnote-backref">↩︎</a></p></li><li id="fn5" class="footnote-item"><p>Lefranc, M.-P. IMGT Unique Numbering for the Variable (V), Constant ©, and Groove (G) Domains of IG, TR, MH, IgSF, and MhSF. Cold Spring Harb Protoc., 1;2011(6). pii: pdb.ip85. doi: 10.1101/pdb.ip85 (2011) PMID: 21632789 <a href="#fnref5" class="footnote-backref">↩︎</a></p></li><li id="fn6" class="footnote-item"><p>Duroux P et al., IMGT-Kaleidoscope, the Formal IMGT-ONTOLOGY paradigm. Biochimie, 90:570-83. Epub 2007 Sep 11 (2008) PMID:17949886 <a href="#fnref6" class="footnote-backref">↩︎</a></p></li><li id="fn7" class="footnote-item"><p>Giudicelli V, Lefranc M P. Ontology for immunogenetics: the IMGT-ONTOLOGY[J]. Bioinformatics, 1999, 15(12): 1047-1054. <a href="#fnref7" class="footnote-backref">↩︎</a></p></li><li id="fn8" class="footnote-item"><p>Duroux P, Kaas Q, Brochet X, et al. IMGT-Kaleidoscope, the formal IMGT-ONTOLOGY paradigm[J]. Biochimie, 2008, 90(4): 570-583. <a href="#fnref8" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">IMGT®: the international ImMunoGeneTics information system®</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Database" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Database/"/>
    
    
    <category term="Database" scheme="https://karobben.github.io/tags/Database/"/>
    
    <category term="Bioinformatic" scheme="https://karobben.github.io/tags/Bioinformatic/"/>
    
    <category term="Immunology" scheme="https://karobben.github.io/tags/Immunology/"/>
    
    <category term="Protein" scheme="https://karobben.github.io/tags/Protein/"/>
    
  </entry>
  
  <entry>
    <title>Immunoglobulin BLAST (Igblast), a Blast Tool Specific for Antibodies</title>
    <link href="https://karobben.github.io/2023/12/21/Bioinfor/igblast/"/>
    <id>https://karobben.github.io/2023/12/21/Bioinfor/igblast/</id>
    <published>2023-12-22T02:21:23.000Z</published>
    <updated>2023-12-26T01:34:43.074Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Key-Features-of-IgBLAST">Key Features of IgBLAST</h2><ol><li><p><strong>Identification of V(D)J segments</strong>: IgBLAST can identify variable (V), diversity (D), and joining (J) gene segments in IG or TCR sequences.</p></li><li><p><strong>Clonotype Analysis</strong>: It helps in determining clonotypes based on V(D)J segment usage, providing insights into the diversity and clonality of IG or TCR repertoires.</p></li><li><p><strong>Somatic Hypermutation Analysis</strong>: It identifies somatic hypermutations in IG sequences and can compare these to germline sequences, which is critical in understanding adaptive immune responses.</p></li><li><p><strong>Flexible Input Options</strong>: IgBLAST can process both nucleotide and protein sequences, and it supports various input formats.</p></li><li><p><strong>Detailed Alignment Information</strong>: It provides detailed alignment results that include information about gene segments, framework regions, complementarity-determining regions (CDRs), and mutations.</p></li><li><p><strong>Integration with Other Databases</strong>: The results can be linked to other NCBI databases for additional information and analysis.</p></li></ol><p>IgBLAST is widely used in immunology and related fields for studying B cell and T cell receptor repertoire, which is crucial for understanding immune responses, vaccine development, and in the study of autoimmune diseases and cancer.</p><h2 id="Local-Set-Up">Local Set Up</h2><ul><li>Basically, you can use the online service: <a href="https://www.ncbi.nlm.nih.gov/igblast/">NCBI igblast</a></li><li>Set up by following the official documentation: <a href="https://ncbi.github.io/igblast/cook/How-to-set-up.html">NCBI igblast set up</a></li></ul><p>Here is an example of set up by using conda from <a href="https://github.com/nicwulab/SARS-CoV-2_Abs#local-igblast-setup">nicwulab/SARS-CoV-2_Abs</a></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">conda create -n Abs -c bioconda \<br>  python=3.9 \<br>  igblast<br><br>conda activate Abs<br><span class="hljs-comment"># install pyir and use it to set up the blast database</span><br>pip3 install crowelab_pyir<br>pyir setup<br></code></pre></td></tr></table></figure></div><p>In the <code>pyir</code>, it is using ‘http’ and download the data failed. By following the error code, we could find the script and alter the ‘http’ to ‘https’. It should solving the problem.</p><p>An example of running the program:</p><ol><li><p>prepare the DataBase</p></li><li><p>run the blast</p></li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">igblastn -query result/test.fasta \<br>  -germline_db_V imgt_database/human_nuc/IGV.fasta \<br>  -germline_db_J imgt_database/human_nuc/IGJ.fasta \<br>  -germline_db_D imgt_database/human_nuc/IGD.fasta \<br>  -organism human -domain_system kabat \<br>  -auxiliary_data imgt_database/optional_file/human_gl.aux \<br>  -out result/igblast_output<br></code></pre></td></tr></table></figure></div><pre>-germline_db_V <String> Germline database name-organism <String> The organism for your query sequence. Supported organisms include human, mouse, rat, rabbit and rhesus_monkey for Ig and human and mouse for TCR. Custom organism is also supported but you need to supply your own germline annotations (see IgBLAST web site for details) Default = `human'</pre><h2 id="pyir">pyir</h2><p>If you installed pyir, we could use the <a href="https://github.com/crowelab/PyIR">pyir</a> to do the igblast with less parameters.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">pyir -m 60  result/clean_split.fa --outfmt tsv -o result/clean<br></code></pre></td></tr></table></figure></div><p>Key parameters:</p><pre>--sequence_type {nucl,prot}     default: nucl-m MULTI, --multi MULTI         Number of threads-o,  --out                      default: inputfile.json.gz--outfmt {tsv,lsjson,dict,json} suggest: tsv--igdata IGDATA                 Path to your IGDATA directory.-r, --receptor {Ig,TCR}         The receptor you are analyzing, immunoglobulin or t cell receptor-s, --species {human,mouse...}  The Species you are analyzing {human,mouse,rabbit,rat,rhesus_monkey}</pre><h2 id="Q-A">Q&amp;A</h2><div class="admonition question"><p class="admonition-title">Can I annotate the light chain and heavy chain simultaneously?</p><p>IgBLAST is designed to analyze immunoglobulin (IG) sequences, including both heavy and light chains. However, it typically processes and analyzes these chains separately. When you input a sequence that contains both heavy and light chains, IgBLAST might only process the first recognizable sequence, which in your case appears to be the heavy chain.</p><p>To analyze both heavy and light chains using IgBLAST, you generally need to input them as separate sequences. This means splitting your combined sequence into two parts - one for the heavy chain and the other for the light chain - and then running IgBLAST for each part individually.</p><p>There isn't a parameter in IgBLAST that allows for the simultaneous analysis of both heavy and light chains when they are combined into a single sequence. The tool's algorithm is designed to identify and annotate the V(D)J segments of a single chain at a time, as the structure and sequence features of heavy and light chains are distinct.</p><p>If you are consistently working with sequences that contain both chains, you may need to develop a preprocessing step in your workflow to separate these chains before analysis. Alternatively, if such a tool is essential for your work, you might need to look into other bioinformatics tools or custom scripting to first identify and separate the heavy and light chain sequences before feeding them into IgBLAST.</p></div><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Igblast, a Blast Tool Specific for Antibodies</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Software" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Software/"/>
    
    <category term="Align" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Software/Align/"/>
    
    
    <category term="Software" scheme="https://karobben.github.io/tags/Software/"/>
    
    <category term="Database" scheme="https://karobben.github.io/tags/Database/"/>
    
    <category term="Align" scheme="https://karobben.github.io/tags/Align/"/>
    
  </entry>
  
  <entry>
    <title>scVDJ-Seq Pipeline (CellRanger)</title>
    <link href="https://karobben.github.io/2023/12/21/Bioinfor/scvdj-seq/"/>
    <id>https://karobben.github.io/2023/12/21/Bioinfor/scvdj-seq/</id>
    <published>2023-12-21T20:52:46.000Z</published>
    <updated>2023-12-21T21:14:25.261Z</updated>
    
    <content type="html"><![CDATA[<h2 id="scVDJ-Seq">scVDJ-Seq</h2><table><thead><tr><th style="text-align:center"><img src="https://imgur.com/PxRTphj.png" alt="scVDJ-Seq"></th></tr></thead><tbody><tr><td style="text-align:center">V(D)J Library Construction</td></tr></tbody></table><ol><li><p><font style="background-color: red">V</font> (Variable): These are gene segments that code for the variable region of an antibody or T-cell receptor. The variable region is responsible for binding to antigens.</p></li><li><p><font style="background-color: gold">D</font> (Diversity): These segments are found in some classes of antibodies and in T-cell receptors. They provide an additional level of diversity to the antigen-binding region.</p></li><li><p><font style="background-color: green">J</font> (Joining): These gene segments join with the V (and D, where present) segments to complete the variable region of the receptor.</p></li><li><p><font style="background-color: royalblue">C</font> (Constant): The constant region of the antibody or T-cell receptor is encoded by these segments. This region does not vary much between different antibodies and is responsible for the effector functions of the antibody, such as recruiting other parts of the immune system.</p></li></ol><h2 id="Pipeline">Pipeline</h2><table><thead><tr><th style="text-align:center"><img src="https://cdn.10xgenomics.com/image/upload/v1654273213/software-support/vdj/algorithms/algorithm-workflow.png" alt="Cell Ranger's V(D)J Algorithm"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.10xgenomics.com/cn/support/software/cell-ranger/algorithms-overview/cr-5p-vdj-algorithm">© 10X Genomics</a></td></tr></tbody></table><h2 id="Install-CellRanger">Install CellRanger</h2><p>Click the <a href="https://www.10xgenomics.com/support/software/cell-ranger/downloads">Link</a> and fill out the information and you could get the download page</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># download the software (expired)</span><br>curl -o cellranger-7.2.0.tar.gz <span class="hljs-string">&quot;https://cf.10xgenomics.com/releases/cell-exp/cellranger-7.2.0.tar.gz?Expires=1703232056&amp;Key-Pair-Id=APKAI7S6A5RYOXBWRPDA&amp;Signature=hm5oQoPrhuNznBtqCREVSaH34WF-Fute6XHYRDUIvIsajK~sFKYuonBEUQsxRJ1oKmxuuAhmtJg3N-mEQU2dr223oXTTr9e70gFlx9-3qgR7cvAhbZXMMGPMhOVVixoEF2GaE1~x0LA4KLXG3xu4mDGsBn4u870Ql~~OfhYBF5bHcqV6hf8X-YPXNG8TbRZMe-dqcogRTPYpeOpfKBtvPs63CDJ3YgC2Bahci4jYuo2v7MZDTR018C~X-3qwgRMIPKCMZFInEjpkfds34TJ0yP3uwAprvpR~S3WCngKKzSmAQszkDMqSB2eXZw6~FF~6oFIIYV~-DmPV~a7DO416nQ__&quot;</span><br><br><span class="hljs-comment"># decompress and install</span><br>tar -zxvf cellranger-7.2.0.tar.gz<br><br><span class="hljs-comment"># add this directory in your path</span><br><span class="hljs-built_in">export</span> PATH=$(<span class="hljs-built_in">pwd</span>):<span class="hljs-variable">$PATH</span><br><span class="hljs-comment"># You may wish to add this command to your ~/.bashrc or ~/.zshrc for convenience.</span><br><span class="hljs-comment"># for get the full command, you can run `echo export PATH=$(pwd):\$PATH` and add the print out result at the end of the ~/.bashrc or ~/.zshrc</span><br></code></pre></td></tr></table></figure></div><div class="admonition note"><p class="admonition-title">Reference</p><p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Download the reference</span><br><span class="hljs-comment">## Human reference (GRCh38) - 2020-A</span><br>curl -O <span class="hljs-string">&quot;https://cf.10xgenomics.com/supp/cell-exp/refdata-gex-GRCh38-2020-A.tar.gz&quot;</span><br><span class="hljs-comment">## Mouse reference (mm10) - 2020-A</span><br>curl -O <span class="hljs-string">&quot;https://cf.10xgenomics.com/supp/cell-exp/refdata-gex-mm10-2020-A.tar.gz&quot;</span><br><span class="hljs-comment">## Human (GRCh38) and mouse (mm10) reference - 2020-A</span><br>curl -O <span class="hljs-string">&quot;https://cf.10xgenomics.com/supp/cell-exp/refdata-gex-GRCh38-and-mm10-2020-A.tar.gz&quot;</span><br><br><span class="hljs-comment">## Human V(D)J reference (GRCh38)</span><br>curl -O <span class="hljs-string">&quot;https://cf.10xgenomics.com/supp/cell-vdj/refdata-cellranger-vdj-GRCh38-alts-ensembl-7.1.0.tar.gz&quot;</span><br><span class="hljs-comment">## Mouse V(D)J reference (GRCm38)</span><br>curl -O <span class="hljs-string">&quot;https://cf.10xgenomics.com/supp/cell-vdj/refdata-cellranger-vdj-GRCm38-alts-ensembl-7.0.0.tar.gz&quot;</span><br></code></pre></td></tr></table></figure></div></p></div><h3 id="Run">Run</h3><p>Documentation: <a href="https://www.10xgenomics.com/cn/support/software/cell-ranger/algorithms-overview/cr-5p-vdj-algorithm">10X Genomics</a></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">cellranger vdj --id=sample345 \<br>         --reference=/opt/refdata-cellranger-vdj-GRCh38-alts-ensembl-7.1.0 \<br>         --fastqs=/home/jdoe/runs/HAWT7ADXX/outs/fastq_path \<br>         --sample=mysample \<br>         --localcores=8 \<br>         --localmem=64<br></code></pre></td></tr></table></figure></div><ul><li><strong>Command and Arguments</strong>:</li></ul><pre>cellranger vdj:     This is the main command being run. `cellranger` is the software package, and `vdj` specifies that you are running the V(D)J analysis pipeline, which is used for assembling and annotating V(D)J sequences from single-cell RNA-Seq data.--id=sample345:     This sets the unique identifier for the run. Here, the identifier is `sample345`. This ID is used to name the output directory.--reference=...:    This specifies the reference dataset to be used for the analysis. The provided path (`/opt/refdata-cellranger-vdj-GRCh38-alts-ensembl-7.1.0`) points to a reference dataset for human V(D)J sequences.--fastqs=...:       This indicates the directory where the FASTQ files are located. FASTQ files are the input files for the Cell Ranger software, containing the sequenced reads.--sample=mysample:  This specifies the name of the sample to be analyzed. It should match the sample name in the FASTQ files.--localcores=8:     This parameter tells Cell Ranger to use 8 CPU cores for the computation. This setting helps to optimize the use of available computational resources.--localmem=64:      This allocates 64 GB of memory (RAM) for the run. This parameter is crucial for ensuring the software has enough memory to process the data without crashing.</pre><h2 id="When-the-Job-is-Done">When the Job is Done</h2><p>A successful <code>cellranger vdj</code> run should conclude with a message similar to this:</p><pre>Outputs:- Run summary HTML:                                 /home/jdoe/runs/sample345/outs/web_summary.html- Run summary CSV:                                  /home/jdoe/runs/sample345/outs/metrics_summary.csv- Clonotype info:                                   /home/jdoe/runs/sample345/outs/clonotypes.csv- Filtered contig sequences FASTA:                  /home/jdoe/runs/sample345/outs/filtered_contig.fasta- Filtered contig sequences FASTQ:                  /home/jdoe/runs/sample345/outs/filtered_contig.fastq- Filtered contigs (CSV):                           /home/jdoe/runs/sample345/outs/filtered_contig_annotations.csv- All-contig FASTA:                                 /home/jdoe/runs/sample345/outs/all_contig.fasta- All-contig FASTA index:                           /home/jdoe/runs/sample345/outs/all_contig.fasta.fai- All-contig FASTQ:                                 /home/jdoe/runs/sample345/outs/all_contig.fastq- Read-contig alignments:                           /home/jdoe/runs/sample345/outs/all_contig.bam- Read-contig alignment index:                      /home/jdoe/runs/sample345/outs/all_contig.bam.bai- All contig annotations (JSON):                    /home/jdoe/runs/sample345/outs/all_contig_annotations.json- All contig annotations (BED):                     /home/jdoe/runs/sample345/outs/all_contig_annotations.bed- All contig annotations (CSV):                     /home/jdoe/runs/sample345/outs/all_contig_annotations.csv- Barcodes that are declared to be targetted cells: /home/jdoe/runs/sample345/outs/cell_barcodes.json- Clonotype consensus FASTA:                        /home/jdoe/runs/sample345/outs/consensus.fasta- Clonotype consensus FASTA index:                  /home/jdoe/runs/sample345/outs/consensus.fasta.fai- Contig-consensus alignments:                      /home/jdoe/runs/sample345/outs/consensus.bam- Contig-consensus alignment index:                 /home/jdoe/runs/sample345/outs/consensus.bam.bai- Clonotype consensus annotations (CSV):            /home/jdoe/runs/sample345/outs/consensus_annotations.csv- Concatenated reference sequences:                 /home/jdoe/runs/sample345/outs/concat_ref.fasta- Concatenated reference index:                     /home/jdoe/runs/sample345/outs/concat_ref.fasta.fai- Contig-reference alignments:                      /home/jdoe/runs/sample345/outs/concat_ref.bam- Contig-reference alignment index:                 /home/jdoe/runs/sample345/outs/concat_ref.bam.bai- Loupe V(D)J Browser file:                         /home/jdoe/runs/sample345/outs/vloupe.vloupe- V(D)J reference:fasta:regions:       /home/jdoe/runs/sample345/outs/vdj_reference/fasta/regions.fadonor_regions: /home/jdoe/runs/sample345/outs/vdj_reference/fasta/donor_regions.fareference: /home/jdoe/runs/sample345/outs/vdj_reference/reference.json- AIRR Rearrangement TSV:                           /home/jdoe/runs/sample345/outs/airr_rearrangement.tsv- All contig info (ProtoBuf format):                /home/jdoe/runs/sample345/outs/vdj_contig_info.pbWaiting 6 seconds for UI to do final refresh.Pipestance completed successfully!</pre><p>Once <code>cellranger vdj</code> has successfully completed, you can browse the resulting summary HTML file in any supported web browser, open the <code>.vloupe</code> file in Loupe V(D)J Browser, or refer to the Understanding Output section to explore the data by hand.</p><h2 id="Trouble-Shoot">Trouble Shoot</h2><h3 id="Too-Low-to-Meet-the-Required-Threshold">Too Low to Meet the Required Threshold</h3><pre>[error] Pipestance failed. Error log at:MockC_cs/SC_VDJ_ASSEMBLER_CS/SC_MULTI_CORE/MULTI_CHEMISTRY_DETECTOR/VDJ_CHEMISTRY_DETECTOR/DETECT_VDJ_RECEPTOR/fork0/chnk0-u22ea849f77/_errorsLog message:V(D)J Chain detection failed for Sample VDJ-B-293-redo-1 in "/raid/home/wenkanl2/MokC_sc/1_primary_seq".Total Reads          = 1000000Reads mapped to TR   = 30Reads mapped to IG   = 28665In order to distinguish between the TR and the IG chain the following conditions need to be satisfied:- A minimum of 10000 total reads- A minimum of 5.0% of the total reads needs to map to TR or IG- The number of reads mapped to TR should be at least 3.0x compared to the number of reads mapped to IG or vice versaPlease check the input data and/or specify the chain via the --chain argument.</pre><p>The problem here is with the proportion of reads mapping to TR and IG. Even though you have a significant number of reads mapped to IG, the number of reads mapped to TR is <mark>too low to meet the required thresholds</mark>.</p><div class="admonition note"><p class="admonition-title">Resolution:</p><p>The message suggests checking the input data or specifying the chain via the --chain argument. Explicitly specify whether you are analyzing T-cell receptors (TR) or Immunoglobulins (IG) by using the --chain flag in your Cell Ranger command.For example, assume that it is B cell data, we could add <code>--chain IG</code> to solve this problem</p></div><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">scVDJ-Seq Pipeline</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Single Cell" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Single-Cell/"/>
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="RNA-Seq" scheme="https://karobben.github.io/tags/RNA-Seq/"/>
    
    <category term="NGS" scheme="https://karobben.github.io/tags/NGS/"/>
    
    <category term="scRNA-Seq" scheme="https://karobben.github.io/tags/scRNA-Seq/"/>
    
  </entry>
  
  <entry>
    <title>Secure Shell (SSH)</title>
    <link href="https://karobben.github.io/2023/12/20/Linux/ssh/"/>
    <id>https://karobben.github.io/2023/12/20/Linux/ssh/</id>
    <published>2023-12-20T17:59:14.000Z</published>
    <updated>2024-01-14T08:37:53.151Z</updated>
    
    <content type="html"><![CDATA[<h2 id="SSH">SSH</h2><p>SSH, short for Secure Shell, is a network protocol used to securely access and manage a computer over an unsecured network. It provides a secure channel over an unencrypted network, like the internet, allowing users to log into another computer, execute commands remotely, and move files. SSH uses strong encryption to protect the data being transmitted, ensuring confidentiality and integrity of the data against eavesdropping and interception. It’s commonly used by system administrators and IT professionals for managing systems and applications remotely.</p><h2 id="How-to-Use-It">How to Use It</h2><p>Using SSH typically involves two primary components: an SSH client and an SSH server. The server runs on the machine you want to connect to, while the client runs on the machine you’re connecting from. Here’s a basic guide on how to use SSH:</p><h3 id="Setting-Up-an-SSH-Server">Setting Up an SSH Server</h3><ol><li><p><strong>Install SSH Server</strong>: On the remote machine (the one you want to access), you need to install an SSH server. For Linux systems, this is often done using the <code>openssh-server</code> package.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo apt update<br>sudo apt install openssh-server<br></code></pre></td></tr></table></figure></div><p>This example is for Debian-based systems (like Ubuntu). The commands might vary for other systems.</p></li><li><p><strong>Start and Enable SSH Service</strong>: Ensure that the SSH service is started and enabled to start on boot.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo systemctl start ssh<br>sudo systemctl <span class="hljs-built_in">enable</span> ssh<br></code></pre></td></tr></table></figure></div></li><li><p><strong>Configure SSH Server (Optional)</strong>: You can configure your SSH server by editing the <code>/etc/ssh/sshd_config</code> file. This step is optional and typically only necessary for advanced configurations.</p></li></ol><h3 id="Connecting-Using-an-SSH-Client">Connecting Using an SSH Client</h3><ol><li><p><strong>Install SSH Client</strong>: Most Unix-like systems (Linux, macOS) come with an SSH client pre-installed. For Windows, you can use clients like PuTTY or use the built-in SSH client in Windows 10/11.</p></li><li><p><strong>Establish an SSH Connection</strong>: To connect to the SSH server, you need the IP address or hostname of the server and the username on that system. The basic command is:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">ssh [username]@[host]<br></code></pre></td></tr></table></figure></div><p>For example, if your username is <code>user</code> and the server’s IP address is <code>192.168.1.100</code>, you would use:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">ssh user@192.168.1.100<br></code></pre></td></tr></table></figure></div></li><li><p><strong>Authenticate</strong>: When you connect for the first time, you’ll be asked to verify the identity of the server. After accepting, you’ll be prompted for the password of the user account you are logging into on the remote machine.</p></li><li><p><strong>Using SSH</strong>: Once connected, you can execute commands on the remote machine as if you were physically present.</p></li><li><p><strong>Transferring Files (Optional)</strong>: SSH also allows for secure file transfer using SCP or SFTP.</p><ul><li>To copy a file from your local machine to the remote machine:<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">scp /path/to/<span class="hljs-built_in">local</span>/file user@192.168.1.100:/path/to/remote/directory<br></code></pre></td></tr></table></figure></div></li><li>To copy a file from the remote machine to your local machine:<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">scp user@192.168.1.100:/path/to/remote/file /path/to/<span class="hljs-built_in">local</span>/directory<br></code></pre></td></tr></table></figure></div></li></ul></li><li><p><strong>Exiting SSH</strong>: To end your SSH session, simply type <code>exit</code> or press <code>Ctrl+D</code>.</p></li></ol><h2 id="Configure-file">Configure file</h2><p><code>vim ~/.ssh/config</code></p><pre>Host home_pc    HostName 192.168.3.1    User john    Port 2322</pre><p>How to login this host:<br><code>ssh home_pc</code></p><h3 id="Security-Considerations">Security Considerations</h3><ul><li><p><strong>SSH Keys</strong>: For better security, it’s recommended to use SSH keys instead of passwords. SSH keys are a pair of cryptographic keys that can be used to authenticate to an SSH server as an alternative to password-based logins.</p></li><li><p><strong>Firewall Settings</strong>: Make sure your firewall settings allow SSH connections (usually on port 22).</p></li><li><p><strong>Regular Updates</strong>: Keep the SSH server software up to date for security.</p></li></ul><p>SSH is a powerful tool for remote administration, but it’s important to use it securely to protect your systems and data.</p><h2 id="SSH-Key">SSH Key</h2><p>Generating an SSH key is a security practice for authenticating to an SSH server more securely than using just a password. Here’s why you should do it and how to generate an SSH key:</p><h3 id="Why-Use-SSH-Keys">Why Use SSH Keys?</h3><ol><li><p><strong>Enhanced Security</strong>: SSH keys are cryptographic keys that are much more secure than passwords. They are almost impossible to decipher using brute force methods.</p></li><li><p><strong>No Need for Passwords</strong>: When you use SSH keys, you don’t need to enter your password every time you connect, which reduces the risk of password theft.</p></li><li><p><strong>Automation Friendly</strong>: SSH keys are ideal for automated processes. Scripts and applications can authenticate without manual password entry.</p></li><li><p><strong>Access Control</strong>: SSH keys can be used to control who can access a server. Only users with the matching private key can access the server configured with the public key.</p></li></ol><h3 id="How-to-Generate-an-SSH-Key">How to Generate an SSH Key</h3><h4 id="On-Linux-or-macOS">On Linux or macOS:</h4><ol><li><p><strong>Open Terminal</strong>: Launch the terminal application.</p></li><li><p><strong>Generate Key Pair</strong>: Use the <code>ssh-keygen</code> command to generate a new SSH key pair.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">ssh-keygen -t rsa -b 4096<br></code></pre></td></tr></table></figure></div><p>This command creates a new SSH key using the RSA algorithm with a key size of 4096 bits, providing a good balance between security and compatibility. You can choose other algorithms like <code>ed25519</code> which is considered more secure but may not be compatible with older systems.</p></li><li><p><strong>Specify File to Save the Key</strong>: By default, <code>ssh-keygen</code> will save the key in the <code>~/.ssh/id_rsa</code> file. You can specify a different file if you want.</p></li><li><p><strong>Enter a Passphrase (Optional)</strong>: For additional security, you can enter a passphrase when prompted. This passphrase will be required whenever the private key is used.</p></li></ol><h3 id="Adding-the-SSH-Key-to-Your-SSH-Server">Adding the SSH Key to Your SSH Server</h3><ol><li><p><strong>Copy Public Key</strong>: After generating your SSH key, you need to add the public key to the <code>~/.ssh/authorized_keys</code> file on your SSH server.</p></li><li><p><strong>Use <code>ssh-copy-id</code> on Linux/macOS</strong>: If you’re using Linux or macOS, you can use <code>ssh-copy-id</code> to copy your public key to the server easily.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">ssh-copy-id user@server-address<br></code></pre></td></tr></table></figure></div></li><li><p><strong>Manual Copying</strong>: If <code>ssh-copy-id</code> isn’t available or you’re using Windows, you can manually copy the public key text and append it to <code>~/.ssh/authorized_keys</code> on the server.</p></li></ol><p>Remember, never share your private key. The public key is what you distribute or add to servers, while the private key should be securely stored and kept private.</p><h2 id="Trouble-Shooting-Public-Key-Doesn’t-Work">Trouble Shooting: Public Key Doesn’t Work</h2><p>If your SSH public key authentication isn’t working, there could be several reasons. Here’s a troubleshooting guide to help you resolve common issues:</p><h3 id="1-Check-File-Permissions">1. Check File Permissions</h3><ul><li><strong>On the Server</strong>: SSH is particular about file permissions for the <code>~/.ssh</code> directory and the <code>authorized_keys</code> file. Incorrect permissions can prevent SSH from authenticating using keys.<ul><li>The <code>~/.ssh</code> directory should have permissions set to <code>700</code> (drwx------).</li><li>The <code>authorized_keys</code> file should have permissions set to <code>600</code> (-rw-------).</li><li>Use the <code>chmod</code> command to set these permissions:</li></ul></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">chmod 700 ~/.ssh<br>chmod 600 ~/.ssh/authorized_keys<br></code></pre></td></tr></table></figure></div><h3 id="2-Ensure-Correct-Ownership">2. Ensure Correct Ownership</h3><p>The <code>.ssh</code> directory and the <code>authorized_keys</code> file should be owned by the user, not root or any other user. Use the <code>chown</code> command to set the ownership:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">chown -R your_username:your_username ~/.ssh<br></code></pre></td></tr></table></figure></div><p>You can also make sure that the home directory permissions are restricted to the user. I think it could do the same thing.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">chmod -R u+rwX,go-rwx /home/your_username<br></code></pre></td></tr></table></figure></div><h3 id="3-Verify-the-Public-Key-Format">3. Verify the Public Key Format</h3><p>Ensure that the public key in <code>authorized_keys</code> is in the correct format. It should be a single line starting with <code>ssh-rsa</code> or <code>ssh-ed25519</code>, followed by the key, and optionally a comment.</p><h3 id="4-Check-the-SSH-Server-Configuration">4. Check the SSH Server Configuration</h3><p>The SSH server configuration file (<code>/etc/ssh/sshd_config</code>) on the server might restrict public key authentication. Check the following settings:</p><ul><li><code>PubkeyAuthentication yes</code> should be set to allow public key authentication.</li><li><code>AuthorizedKeysFile</code> should point to the correct path, typically <code>.ssh/authorized_keys</code>.</li><li>If <code>PasswordAuthentication</code> is set to <code>no</code>, the server will not fall back to password authentication if key authentication fails.</li><li>After making changes, restart the SSH service:</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo systemctl restart ssh<br></code></pre></td></tr></table></figure></div><h3 id="5-Check-SSH-Client-Configuration">5. Check SSH Client Configuration</h3><p>On your client machine, ensure you’re specifying the correct private key. If you’re using a key with a non-default name or location, specify it with the <code>-i</code> option:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">ssh -i /path/to/private_key user@server<br></code></pre></td></tr></table></figure></div><h3 id="6-Look-at-Server-Logs">6. Look at Server Logs</h3><p>SSH server logs can provide details on why the key authentication is failing. Check the logs for relevant error messages:</p><ul><li>On most Linux systems, SSH logs are located in <code>/var/log/auth.log</code> or <code>/var/log/secure</code>.</li></ul><h3 id="7-Validate-Key-Pair">7. Validate Key Pair</h3><p>Ensure that the public and private keys are a matching pair. If you have regenerated or changed keys, make sure the server has the corresponding public key.</p><h3 id="8-Check-Passphrase">8. Check Passphrase</h3><p>If your private key is protected with a passphrase, ensure you’re entering the correct passphrase when prompted.</p><h3 id="9-Network-Issues">9. Network Issues</h3><p>Confirm there are no network issues preventing SSH access. Firewall settings on either the client or server side can block SSH connections.</p><h3 id="10-Client-Side-Debugging">10. Client-Side Debugging</h3><p>Use SSH with the <code>-vvv</code> option for verbose output, which can give more insights:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">ssh -vvv -i /path/to/private_key user@server<br></code></pre></td></tr></table></figure></div><p>This will provide detailed debug information about each step of the SSH connection process, potentially highlighting where the issue lies.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Secure Shell (SSH) installation, usage, and trouble shooting</summary>
    
    
    
    <category term="Linux" scheme="https://karobben.github.io/categories/Linux/"/>
    
    <category term="System" scheme="https://karobben.github.io/categories/Linux/System/"/>
    
    
    <category term="Linux" scheme="https://karobben.github.io/tags/Linux/"/>
    
    <category term="bash" scheme="https://karobben.github.io/tags/bash/"/>
    
    <category term="CLI Tools" scheme="https://karobben.github.io/tags/CLI-Tools/"/>
    
  </entry>
  
  <entry>
    <title>Phylogenetic Tree</title>
    <link href="https://karobben.github.io/2023/12/18/Bioinfor/phylogenetic/"/>
    <id>https://karobben.github.io/2023/12/18/Bioinfor/phylogenetic/</id>
    <published>2023-12-18T17:26:46.000Z</published>
    <updated>2023-12-20T20:28:41.089Z</updated>
    
    <content type="html"><![CDATA[<h2 id="What-is-Phylogenetic-Tree">What is Phylogenetic Tree</h2><blockquote><p>A phylogenetic tree is a diagram representing the evolutionary relationships among species or other entities based on their genetic or physical characteristics. The branches of the tree indicate how these species have evolved from common ancestors. The tree can be rooted, showing the most recent common ancestor, or unrooted, illustrating relationships without a common origin point. Constructed using data like DNA sequences or morphological traits, these trees are essential in studying evolutionary biology, tracking disease evolution, and in conservation efforts. They provide a visual representation of the evolutionary history and connections between different forms of life.<br>(GPT4)</p></blockquote><h2 id="General-Ideas-of-Phylogenetic-Tree">General Ideas of Phylogenetic Tree</h2><p>Source: <a href="https://evolution.berkeley.edu/evolution-101/the-history-of-life-looking-at-the-patterns/understanding-phylogenies/">Evo 101, Berkeley</a></p><table><thead><tr><th style="text-align:center"><img src="https://evolution.berkeley.edu/wp-content/uploads/2021/11/understanding_phylos_Understanding-phylo1-500x185.png" alt=""></th><th style="text-align:center"><img src="https://evolution.berkeley.edu/wp-content/uploads/2021/11/understanding_phylos_speciation-event-500x184.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center"><img src="https://evolution.berkeley.edu/wp-content/uploads/2021/11/understanding_phylos_unique-history-500x185.png" alt=""></td><td style="text-align:center"><img src="https://evolution.berkeley.edu/wp-content/uploads/2021/11/understanding_phylos_unique-ancestor-500x184.png" alt=""></td></tr></tbody></table><h2 id="Distance-Matrix-GPT4">Distance Matrix (GPT4)</h2><p>More related source could be found at <a href="https://academic-accelerator.com/encyclopedia/distance-matrix">academic accelerator</a></p><p>A distance matrix, in general, is a table used to show the distance between elements in a set. In the context of phylogenetics, it represents the genetic distance between various species or sequences.<br>A distance matrix in phylogenetics is a tool to quantify and visualize the genetic distances between different species or sequences. This matrix forms the basis for constructing phylogenetic trees, which depict the evolutionary relationships and history among the species studied.</p><details><summary>1. <b>General Distance Matrix</b></summary><ul><li>This is a square matrix where the elements represent the distances between pairs of objects.</li><li>In the matrix, each row and column represents an object, and each cell in the matrix shows the distance between the two objects.</li><li>The distances can be based on various metrics, depending on the context (e.g., physical distance, similarity in characteristics, etc.).</li></ul></details><details><summary>2. <b>Distance Matrix in Phylogenetics</b></summary><ul><li>In phylogenetics, the distance matrix represents genetic distances between different species or DNA sequences.</li><li>The genetic distance can be based on differences in DNA, RNA, or protein sequences, indicating how much genetic change has occurred between the sequences.</li><li>The distances are often calculated using methods that count the number of differences between sequences (like nucleotide substitutions) or more complex models that account for the rate of evolution and types of mutations.</li></ul></details><details><summary>3. <b>How it Works in Phylogenetics</b></summary><ul><li><strong>Data Collection</strong>: First, genetic data (like DNA sequences) from different species or organisms are collected.</li><li><strong>Distance Calculation</strong>: Algorithms calculate the genetic distance between each pair of sequences. These calculations can be straightforward (like counting differences) or complex (accounting for evolutionary models).</li><li><strong>Matrix Formation</strong>: These distances are then arranged in a matrix format, where each row and column represents a species or sequence, and each cell shows the genetic distance between them.</li><li><strong>Tree Construction</strong>: Phylogenetic trees can be constructed using this matrix. Methods like UPGMA (Unweighted Pair Group Method with Arithmetic mean) or neighbor-joining are used to create trees that best reflect the distances in the matrix.</li><li><strong>Analysis</strong>: The resulting tree is analyzed to understand evolutionary relationships, like which species are more closely related based on the genetic distances.</li></ul></details><br><table><thead><tr><th style="text-align:center"><img src="https://upload.wikimedia.org/wikipedia/commons/8/80/Additive_distance_matrix.png" alt=""></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://academic-accelerator.com/encyclopedia/distance-matrix">© academic accelerator</a></td></tr></tbody></table><div class="admonition note"><p class="admonition-title">How to make the sense of the  dendrogram?</p><p>This graph illustrates the distance matrix and how it gives sense to the phylogenetic tree. According to the tree, the distance between <strong>b</strong> and <strong>c</strong> is 1+2=3. Similarly, we can deduce from the tree that the distance between <strong>a</strong> and <strong>d</strong> is 4+4+1=9.</p></div><h3 id="Methods-for-Calculating-the-Distance-Matrix-GPT4">Methods for Calculating the Distance Matrix (GPT4)</h3><p>In phylogenetics, there are several methods to calculate the distance matrix, each with its own approach to measuring genetic distances between sequences. These methods vary in complexity and the types of evolutionary changes they consider. Here are some commonly used methods:</p><details><summary>1. <b>Simple Counting Methods</b></summary><ul><li>These involve counting the number of differences (e.g., nucleotide or amino acid substitutions) between each pair of sequences.</li><li>One example is the Hamming distance, which is simply the number of positions at which the corresponding elements (nucleotides or amino acids) are different.</li></ul></details><details><summary>2. <b>Corrected Distance Methods</b></summary><ul><li>These methods account for multiple changes at the same site and unseen changes due to evolutionary processes.</li><li>An example is the Jukes-Cantor model, which corrects for multiple substitutions at the same site by assuming that all changes occur at the same rate.</li></ul></details><details><summary>3. <b>Model-Based Methods</b></summary><ul><li>These use complex models of sequence evolution, accounting for factors like different rates of substitution between different nucleotides or amino acids, transition/transversion bias, and others.</li><li>Examples include the Kimura 2-parameter model and the Tamura-Nei model, which provide more sophisticated ways to estimate genetic distances by incorporating specific evolutionary assumptions.</li></ul></details><details><summary>4. <b>Maximum Likelihood and Bayesian Methods</b></summary><ul><li>These are more computationally intensive methods that use probabilistic models of sequence evolution.</li><li>They estimate the likelihood of observing the data given various possible evolutionary histories and can provide more accurate estimates of genetic distances.</li></ul></details><br><p>Each of these methods has its own strengths and limitations, and the choice of method often depends on the specifics of the data and the research question. Simple counting methods are straightforward but may underestimate distances, especially when sequences have diverged significantly. Corrected distance and model-based methods provide more accurate estimates by considering the complexities of molecular evolution, but they require more computational resources and deeper understanding of evolutionary models. Maximum likelihood and Bayesian methods are highly accurate but computationally demanding.</p><p>In practice, the choice of method is often a balance between the need for accuracy and the availability of computational resources, as well as the evolutionary characteristics of the organisms being studied.</p><h2 id="Different-Ways-to-Illustrate-the-Tree-By-GGTREE">Different Ways to Illustrate the Tree (By GGTREE)</h2><table><thead><tr><th style="text-align:center"><img src="https://yulab-smu.top/treedata-book/treedata_files/figure-html/layout-1.svg" alt="ggtree"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://yulab-smu.top/treedata-book/chapter4.html">© YuLab@SMU</a></td></tr></tbody></table><h2 id="Something-You’d-Like-to-Know-About-Phylogenetic-Trees-Chat4">Something You’d Like to Know About Phylogenetic Trees (Chat4)</h2><p>When working with phylogenetic trees, there are several key points and common misconceptions to be aware of:</p><details><summary>1. <b>Tree Topology Matters More Than Branch Length</b></summary>The branching pattern (topology) of the tree indicates the evolutionary relationships among the species or genes in the tree. However, unless explicitly stated, the length of the branches might not represent evolutionary time or genetic distance.</details><details><summary>2. <b>Branch Points (Nodes) Represent Common Ancestors</b></summary>Each node where branches diverge represents the most recent common ancestor of the groups branching off from that node.</details><details><summary>3. <b>Reading the Tree Correctly</b></summary>A common misunderstanding is the way to interpret the tree's layout. The tree should be read as a series of branching events, not as a left-to-right progression. The order of groups along the tips of the branches doesn't necessarily indicate any specific type of progression or superiority.</details><details><summary>4. <b>Phylogenetic Trees Are Hypothetical</b></summary>These trees are based on the best available data and the most accurate methods at the time. As new data emerge, the tree might be modified.</details><details><summary>5. <b>Rooted vs. Unrooted Trees</b></summary>Rooted trees have a single ancestral lineage (usually at the base) that serves as a common ancestor for all the entities in the tree. Unrooted trees do not show an ancestral root and are used to illustrate the relationships between different lineages without assuming their descent from a common ancestor.</details><details><summary>6. <b>Monophyletic, Paraphyletic, and Polyphyletic Groups</b></summary>Misunderstanding these terms can lead to confusion. Monophyletic groups include an ancestor and all its descendants, paraphyletic groups include an ancestor and some but not all descendants, and polyphyletic groups are characterized by members that do not share a recent common ancestor in the context of the tree.</details><details><summary>7. <b>Convergent Evolution Can Be Misleading</b></summary>Sometimes, unrelated species may appear closely related due to similar selective pressures rather than shared ancestry, a phenomenon known as convergent evolution.</details><details><summary>8. <b>Horizontal Gene Transfer</b></summary>Especially in bacterial phylogenetics, horizontal gene transfer can complicate the interpretation of evolutionary relationships.</details><br><p>Understanding these points can help in correctly interpreting phylogenetic trees and avoiding common misconceptions. It’s also important to remember that phylogenetics is a constantly evolving field, with new methods and data continually refining our understanding of evolutionary relationships.</p><h2 id="Beyond-the-Distance-Matrix-Chat4">Beyond the Distance Matrix (Chat4)</h2><p>Phylogenetic trees can also be constructed without using a distance matrix. The construction of phylogenetic trees can be broadly categorized into two main approaches: distance-based methods and character-based methods. While distance-based methods do rely on distance matrices, character-based methods do not. Here’s a brief overview of these approaches:</p><ol><li><p><strong>Distance-Based Methods</strong>: These methods, such as UPGMA (Unweighted Pair Group Method with Arithmetic Mean) and Neighbor-Joining (exp, <code>-QUICKTREE</code> from <code>clustalW</code>), <mark>rely on a distance matrix</mark> that represents the genetic distance (differences) between pairs of taxa. The matrix is used to construct a tree that represents these distances as accurately as possible.</p></li><li><p><strong>Character-Based Methods</strong>: These methods do not use a distance matrix. Instead, they directly analyze the character states (such as DNA, RNA, or protein sequences) of the taxa being studied. There are two primary types of character-based methods:</p><ul><li><p><strong>Maximum Parsimony</strong>: This method identifies the tree that requires the smallest number of evolutionary changes. It looks for the tree that explains the data with the least amount of complexity, without involving a distance matrix.</p></li><li><p><strong>Maximum Likelihood and Bayesian Methods</strong>: These are statistical methods that evaluate different possible phylogenetic trees and choose the tree that is most likely to have produced the observed set of data. These methods are based on explicit models of evolutionary change and do not rely on a pre-calculated distance matrix.</p></li></ul></li></ol><p>Each method has its advantages and limitations, and the choice of method can depend on the type of data available, the computational resources, and the specific objectives of the study. Character-based methods, especially those involving statistical approaches like Maximum Likelihood and Bayesian Inference, have become increasingly popular due to their ability to incorporate complex models of evolutionary change and handle large datasets effectively.</p><h2 id="The-Difference-Between-NJ-Tree-and-ML-Tree-Chat4">The Difference Between NJ-Tree and ML-Tree (Chat4)</h2><p>The popularity and suitability of the Neighbor-Joining (NJ) and Maximum Likelihood (ML) methods for constructing phylogenetic trees depend on the specific requirements and constraints of the research being conducted. Both methods have their advantages and limitations, and their appropriateness can vary based on factors like data complexity, computational resources, and the level of accuracy needed.</p><h3 id="Popularity">Popularity</h3><ol><li><p><strong>Neighbor-Joining (NJ)</strong>: <mark>Historically</mark>, NJ has been very popular, particularly in earlier studies, due to its computational efficiency. It’s well-suited for large datasets where quick, preliminary analyses are needed. NJ’s simplicity and speed made it a go-to method for many researchers, especially before the widespread availability of powerful computational resources.</p></li><li><p><strong>Maximum Likelihood (ML)</strong>: With the increase in computational power and the development of more sophisticated software, ML has gained substantial popularity, especially in more recent studies. It is often preferred for its ability to provide <mark>more accurate and statistically robust trees</mark>, especially for complex datasets.</p></li></ol><table><thead><tr><th>Feature</th><th>Neighbor-Joining (NJ)</th><th>Maximum Likelihood (ML)</th></tr></thead><tbody><tr><td><strong>Speed and Efficiency</strong></td><td>Fast and efficient, ideal for large datasets and quick analyses.</td><td>Slower and computationally intensive, especially with larger datasets.</td></tr><tr><td><strong>Accuracy</strong></td><td>Less accurate for complex evolutionary models; sensitive to rate variation and sampling errors.</td><td>More accurate and statistically robust across a wide range of datasets.</td></tr><tr><td><strong>Evolutionary Models</strong></td><td>Does not explicitly model evolutionary processes.</td><td>Incorporates explicit models of sequence evolution, handling varying rates of evolution better.</td></tr><tr><td><strong>Computational Resources</strong></td><td>Less demanding, suitable for limited computational resources.</td><td>Requires significant computational power for large and complex datasets.</td></tr><tr><td><strong>Statistical Support</strong></td><td>Limited statistical measures for tree support.</td><td>Provides robust statistical measures (like bootstrap values) for tree support.</td></tr><tr><td><strong>Use Case</strong></td><td>Suitable for preliminary or rapid analyses when computational resources are limited.</td><td>Preferred for detailed, accurate phylogenetic analyses where computational resources are available.</td></tr><tr><td><strong>Complexity and Understanding</strong></td><td>Simpler to understand and use.</td><td>Requires a good understanding of evolutionary models and statistical methods.</td></tr></tbody></table><h3 id="Conclusion">Conclusion</h3><p>The choice between NJ and ML largely depends on the specific requirements of your phylogenetic analysis. For preliminary or rapid analyses with large datasets, NJ remains popular due to its speed. However, for in-depth studies where accuracy and model-based statistical rigor are crucial, ML is often considered superior, albeit at the cost of greater computational demand. With ongoing advancements in computational methods and resources, ML is becoming increasingly accessible and popular in phylogenetic studies.</p><h2 id="Maximum-Likelihood">Maximum Likelihood</h2><p>Maximum Likelihood (ML) is a statistical method used in the construction of phylogenetic trees, which represent the evolutionary relationships among various species or genetic sequences. This method is based on the principle of finding the tree topology (i.e., the arrangement of branches and nodes) that has the highest probability of producing the observed set of genetic data. Here’s a simplified explanation of how it works:</p><ol><li><p><strong>Model of Sequence Evolution</strong>: ML requires a model of sequence evolution. This model includes parameters such as the rates of different types of mutations (e.g., transitions and transversions in nucleotide sequences), the frequency of each nucleotide or amino acid, and potentially other factors like the rate at which different parts of the sequence evolve. These models attempt to approximate the real biological processes that lead to changes in genetic sequences over time.</p></li><li><p><strong>Tree Topologies</strong>: The algorithm considers different possible tree topologies. A topology is a specific arrangement of species or sequences on a tree, indicating how they are related to each other.</p></li><li><p><strong>Calculating Likelihoods</strong>: For each tree topology, the likelihood that the observed data (genetic sequences of the species or taxa being studied) would evolve according to the specified model is calculated. This involves complex computations where the algorithm assesses the probability of changes occurring along the branches of the tree to result in the observed sequences at the tree’s tips (leaves).</p></li><li><p><strong>Comparing Trees</strong>: The likelihoods of different tree topologies are compared. The tree with the highest likelihood is considered the best estimate of the true evolutionary relationships among the sequences. This is because, under the chosen model, this tree would be the most likely to produce the observed data.</p></li><li><p><strong>Optimization and Searching</strong>: Because there are usually an extraordinarily large number of possible tree topologies (increasing exponentially with the number of sequences), it’s impractical to evaluate every possible tree. Therefore, heuristic algorithms are used to search tree space efficiently, focusing on those areas where higher likelihood trees are more likely to be found.</p></li><li><p><strong>Statistical Testing</strong>: Often, statistical methods such as bootstrap analysis are used to test the reliability of the tree. This involves resampling the data and recalculating trees to see how often certain groupings appear, providing a measure of confidence in the tree’s branches.</p></li></ol><p>Maximum Likelihood is favored for its statistical rigor and its ability to provide a clear criterion (likelihood) for choosing among trees. However, it is computationally intensive, especially for large datasets, and the results can be sensitive to the choice of the evolutionary model. Despite these challenges, ML remains a popular and powerful method in phylogenetic analysis.</p><h3 id="A-Simple-Practice">A Simple Practice</h3><p>In this practice, we generated genetic data for two species and their common ancestor. We then used the Jukes-Cantor model to calculate the likelihood of the observed sequences given a tree topology and a mutation rate. Here’s a summary of the process and results:</p><ul><li>Generated Data: We created random genetic sequences for a common ancestor and two descendant species.</li><li>Jukes-Cantor Model: This model was used to estimate the likelihood of one sequence evolving into another under a uniform mutation rate.</li><li>Initial Likelihood Calculation: For the given tree topology (where the common ancestor is the parent of both species), we calculated the likelihood of this tree using a mutation rate of 0.1. The likelihood was found to be approximately 20.46.</li><li>Optimization: We used an optimization algorithm to find the mutation rate that maximizes the likelihood of the observed data given the tree structure. The optimal mutation rate was found to be 1.0.</li><li>Optimized Likelihood: Recalculating the likelihood with the optimized mutation rate, we obtained an improved likelihood of approximately 7.05.</li></ul><p>This demonstration shows how Maximum Likelihood is used in phylogenetics to find the most likely tree structure and parameters (like mutation rate) that explain the observed genetic data. In real-world scenarios, the data and models are much more complex, and the computations are more intensive, but the underlying principles remain the same. ​</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Corrected implementation for demonstrating Maximum Likelihood in phylogenetics</span><br><br><span class="hljs-comment"># Generate a simple example dataset with direct ancestor-descendant relationships</span><br>np.random.seed(<span class="hljs-number">0</span>)<br><span class="hljs-comment"># Assume we have two species and their common ancestor</span><br>data = &#123;<br>    <span class="hljs-string">&quot;Common_Ancestor&quot;</span>: np.random.choice([<span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;T&#x27;</span>, <span class="hljs-string">&#x27;G&#x27;</span>, <span class="hljs-string">&#x27;C&#x27;</span>], <span class="hljs-number">10</span>),<br>    <span class="hljs-string">&quot;Species_A&quot;</span>: np.random.choice([<span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;T&#x27;</span>, <span class="hljs-string">&#x27;G&#x27;</span>, <span class="hljs-string">&#x27;C&#x27;</span>], <span class="hljs-number">10</span>),<br>    <span class="hljs-string">&quot;Species_B&quot;</span>: np.random.choice([<span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;T&#x27;</span>, <span class="hljs-string">&#x27;G&#x27;</span>, <span class="hljs-string">&#x27;C&#x27;</span>], <span class="hljs-number">10</span>)<br>&#125;<br>df = pd.DataFrame(data)<br>print(<span class="hljs-string">&quot;Generated Genetic Data:\n&quot;</span>, df)<br><br><span class="hljs-comment"># Define a simple model of sequence evolution</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">jukes_cantor_model</span>(<span class="hljs-params">seq1, seq2, mu</span>):</span><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Jukes-Cantor model to calculate the likelihood of seq2 evolving from seq1</span><br><span class="hljs-string">    under a uniform mutation rate mu.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    diff = <span class="hljs-built_in">sum</span>(c1 != c2 <span class="hljs-keyword">for</span> c1, c2 <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(seq1, seq2))<br>    same = <span class="hljs-built_in">len</span>(seq1) - diff<br>    p_diff = <span class="hljs-number">3</span>/<span class="hljs-number">4</span> * (<span class="hljs-number">1</span> - np.exp(-<span class="hljs-number">4</span>/<span class="hljs-number">3</span> * mu))<br>    p_same = <span class="hljs-number">1</span>/<span class="hljs-number">4</span> + <span class="hljs-number">1</span>/<span class="hljs-number">4</span> * np.exp(-<span class="hljs-number">4</span>/<span class="hljs-number">3</span> * mu)<br><br>    likelihood = (p_diff ** diff) * (p_same ** same)<br>    <span class="hljs-keyword">return</span> likelihood<br><br><span class="hljs-comment"># Function to calculate the likelihood of a tree given the data</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">tree_likelihood</span>(<span class="hljs-params">tree, data, mu</span>):</span><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Calculate the likelihood of a given tree topology.</span><br><span class="hljs-string">    The tree is represented as a dictionary where keys are nodes and values are the sequences.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    likelihood = <span class="hljs-number">1.0</span><br>    <span class="hljs-keyword">for</span> parent, child <span class="hljs-keyword">in</span> tree.items():<br>        parent_seq = data[parent]<br>        child_seq = data[child]<br>        likelihood *= jukes_cantor_model(parent_seq, child_seq, mu)<br>    <span class="hljs-keyword">return</span> -log(likelihood)  <span class="hljs-comment"># negative log-likelihood for optimization</span><br><br><span class="hljs-comment"># Example tree topology (parent: child)</span><br>tree_example = &#123;<br>    <span class="hljs-string">&quot;Common_Ancestor&quot;</span>: <span class="hljs-string">&quot;Species_A&quot;</span>,<br>    <span class="hljs-string">&quot;Common_Ancestor&quot;</span>: <span class="hljs-string">&quot;Species_B&quot;</span>,<br>&#125;<br><br><span class="hljs-comment"># Assume a mutation rate (mu)</span><br>mu = <span class="hljs-number">0.1</span><br><br><span class="hljs-comment"># Calculate the likelihood of this tree</span><br>likelihood = tree_likelihood(tree_example, df, mu)<br>print(<span class="hljs-string">&quot;\nLikelihood of the tree:&quot;</span>, likelihood)<br><br><span class="hljs-comment"># Now we will use optimization to find the mutation rate that maximizes the likelihood</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">optimize_mu</span>(<span class="hljs-params">mu, tree, data</span>):</span><br>    <span class="hljs-keyword">return</span> tree_likelihood(tree, data, mu)<br><br>result = minimize(optimize_mu, x0=mu, args=(tree_example, df), bounds=[(<span class="hljs-number">0.001</span>, <span class="hljs-number">1</span>)])<br>optimal_mu = result.x[<span class="hljs-number">0</span>]<br>print(<span class="hljs-string">&quot;\nOptimal mutation rate:&quot;</span>, optimal_mu)<br><br><span class="hljs-comment"># Recalculate the likelihood with the optimized mutation rate</span><br>optimized_likelihood = tree_likelihood(tree_example, df, optimal_mu)<br>print(<span class="hljs-string">&quot;\nOptimized likelihood of the tree:&quot;</span>, optimized_likelihood)<br></code></pre></td></tr></table></figure></div><pre>Generated Genetic Data:   Common_Ancestor Species_A Species_B0               A         T         G1               C         G         C2               T         A         C3               A         C         G4               C         G         A5               C         A         T6               C         A         T7               C         A         T8               T         G         T9               C         T         ALikelihood of the tree: 20.463275567320334Optimal mutation rate: 1.0Optimized likelihood of the tree: 7.05394379820434</pre><h3 id="Things-You’d-Like-to-Know">Things You’d Like to Know</h3><ol><li><p><strong>Pairwise Comparisons</strong>: In the ML approach, the focus is <mark>not typically on pairwise comparisons between sequences</mark> (as it is in methods like distance matrix or neighbor-joining). Instead, ML <mark>evaluates the likelihood of entire tree topologies</mark>. It looks at how likely it is for a given tree structure, with its branching pattern and lengths, to have produced the observed set of genetic sequences under a specific evolutionary model.</p></li><li><p><strong>Likelihood Calculations</strong>: For each possible tree topology, ML calculates the likelihood that the proposed tree would result in the observed data (e.g., DNA, RNA, or protein sequences). This calculation involves estimating the probability of changes in the sequences along each branch of the tree. The likelihood depends on both the tree topology (how the branches are arranged) and the model parameters (like mutation rates).</p></li><li><p><strong>Optimization</strong>: The <mark>goal</mark> is to find the tree topology (and associated model parameters) that <mark>maximizes the likelihood</mark>. Due to the vast number of possible trees, especially with larger datasets, <mark>heuristic search</mark> algorithms are used to navigate the space of possible trees efficiently.</p></li><li><p><strong>Likelihood Matrix</strong>: Unlike methods that rely on a distance matrix, <mark>ML doesn’t typically produce a matrix of pairwise likelihoods</mark>. Instead, it directly evaluates the likelihood of entire tree topologies.</p></li><li><p><strong>Resulting Tree</strong>: The end result of an ML analysis is <mark>a single tree</mark> (or sometimes a set of trees) that has the highest likelihood given the data and the chosen model. This tree represents the estimated evolutionary relationships among the sequences.</p></li><li><p><strong>Dendrogram/Phylogenetic Tree</strong>: The final output is a phylogenetic tree (often visualized as a dendrogram) that represents the <mark>hypothesized evolutionary relationships</mark> among the species or sequences analyzed. This tree is based on the topology that provided the highest likelihood.</p></li></ol><p>In summary, while ML involves complex calculations involving the entire tree, it doesn’t use a pairwise likelihood matrix in the same way that distance-based methods use a distance matrix. The primary focus of ML is on evaluating and comparing the likelihoods of different tree topologies to find the one that best explains the observed data under a given evolutionary model.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Phylogenetic Tree</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="others" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/others/"/>
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="Biology" scheme="https://karobben.github.io/tags/Biology/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://karobben.github.io/2023/12/13/Bioinfor/cdhit/"/>
    <id>https://karobben.github.io/2023/12/13/Bioinfor/cdhit/</id>
    <published>2023-12-13T21:21:40.000Z</published>
    <updated>2023-12-14T17:04:35.763Z</updated>
    
    <content type="html"><![CDATA[<h2 id="CD-HIT">CD-HIT</h2><p>Documentation: <a href="https://www.bioinformatics.org/cd-hit/cd-hit-user-guide">CD-HIT</a></p><p>CD-HIT (Cluster Database at High Identity with Tolerance) is a widely used bioinformatics tool designed to cluster biological sequences (such as DNA, RNA, or proteins) to reduce sequence redundancy and improve the efficiency of other sequence analyses. It’s particularly useful when dealing with large datasets, such as those frequently encountered in genomics and proteomics studies.</p><p>Here are some key features and uses of CD-HIT:</p><ol><li><p><strong>Sequence Clustering</strong>: CD-HIT efficiently clusters similar sequences together based on a user-defined similarity threshold. For example, if you set a threshold of 90%, the tool will group sequences that are 90% identical into the same cluster.</p></li><li><p><strong>Reduction of Redundancy</strong>: By clustering similar sequences, CD-HIT helps in reducing redundancy in the dataset. This is particularly important when creating sequence databases or when analyzing large datasets where many sequences may be very similar or nearly identical.</p></li><li><p><strong>Speed and Efficiency</strong>: CD-HIT is known for its speed and low memory usage, making it suitable for handling very large datasets that are common in modern high-throughput sequencing projects.</p></li><li><p><strong>Multiple Applications</strong>: It’s used in a variety of applications, such as creating non-redundant sequence databases, preparing datasets for further analyses (like phylogenetic studies), or in metagenomics for analyzing diversity and similarity of species.</p></li><li><p><strong>Customizable Parameters</strong>: Users can customize several parameters, such as the identity threshold for clustering, the word size for initial comparisons, and memory usage, allowing for flexibility depending on the specific requirements of the data or the analysis.</p></li><li><p><strong>Output Files</strong>: CD-HIT generates two main types of output files - one containing the clustered sequences and another (<code>.clstr</code> file) detailing the composition of each cluster.</p></li></ol><p>CD-HIT is a command-line tool, which means it is run from a terminal or command prompt and offers great flexibility in scripting and automation within bioinformatics pipelines. The tool is an essential part of the toolkit for biologists and bioinformaticians dealing with large-scale sequence data.</p><h2 id="Example">Example</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">cd-hit -i Trunked.fa -o cdhit/Trunked_<span class="hljs-variable">$x</span>.fa -c <span class="hljs-variable">$x</span> -M 32000 -d 0 -T 8 -n 5 -aL 0.8 -s 0.95  -uS 0.2  -sc 1 -sf 1<br></code></pre></td></tr></table></figure></div><p>The command you’ve provided is for CD-HIT, a widely used bioinformatics tool for clustering and comparing protein or nucleotide sequences. CD-HIT helps to significantly reduce the redundancy of large datasets by clustering similar sequences together based on a specified sequence identity threshold. This is particularly useful in tasks like constructing databases or preparing datasets for other analyses where redundancy might be an issue.</p><p>Let’s break down the components of your command:</p><ul><li><p><code>cd-hit</code>: This invokes the CD-HIT program.</p></li><li><p><code>-i Trunked.fa</code>: The <code>-i</code> option specifies the input file. Here, the input file is <code>Trunked.fa</code>, which likely contains a collection of nucleotide or protein sequences in FASTA format.</p></li><li><p><code>-o cdhit/Trunked_$x.fa</code>: The <code>-o</code> option specifies the output file. This command will create an output file in the <code>cdhit</code> directory with a name based on the value of the variable <code>$x</code>. The <code>$x</code> seems to be a shell variable that would be replaced with its value when the command runs.</p></li><li><p><code>-c $x</code>: The <code>-c</code> option sets the sequence identity threshold. Sequences are clustered together if they are similar to each other above this threshold. The exact value is determined by the variable <code>$x</code>.</p></li><li><p><code>-M 32000</code>: This sets the maximum available memory (in MB). <code>32000</code> here means 32,000 MB, or 32 GB of RAM.</p></li><li><p><code>-d 0</code>: The <code>-d</code> option is for the description length to show in the <code>.clstr</code> output file. <code>0</code> means it will show the full sequence defline.</p></li><li><p><code>-T 8</code>: This specifies the number of threads to use. <code>8</code> means the program will run on 8 threads, enabling parallel computation for faster processing.</p></li><li><p><code>-n 5</code>: For protein sequences, this sets the word length for the initial match. <code>5</code> is typically used for thresholds between 0.7 and 0.8.</p></li><li><p><code>-aL 0.8</code>: This sets the alignment coverage for the longer sequence. <code>0.8</code> means 80% of the longer sequence must be covered in the alignment.</p></li><li><p><code>-s 0.95</code>: This sets the alignment coverage for the shorter sequence. <code>0.95</code> means 95% of the shorter sequence must be included in the alignment.</p></li><li><p><code>-uS 0.2</code>: This specifies the maximum unmatched percentage of the shorter sequence. <code>0.2</code> means up to 20% of the shorter sequence can be unmatched.</p></li><li><p><code>-sc 1</code>: This option, when set to <code>1</code>, sorts clusters by decreasing size.</p></li><li><p><code>-sf 1</code>: This option, when set to <code>1</code>, sorts fasta sequence by cluster size.</p></li></ul><p>Each of these options tailors the behavior of CD-HIT to your specific requirements, influencing how sequences are clustered and how the output is formatted and organized. The use of shell variables (like <code>$x</code>) suggests that this command is part of a script where the value of <code>$x</code> is dynamically set, allowing for flexible application of the command with different parameters.</p><h2 id="Read-the-cd-hit-Result-as-pandas-dataframe">Read the cd-hit Result as pandas dataframe</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br><span class="hljs-comment"># Initialize lists to store data</span><br>sequence_names = []<br>cluster_ids = []<br><br><span class="hljs-comment"># Open the .clstr file and parse it</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;your_file.clstr&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> file:<br>    current_cluster_id = <span class="hljs-literal">None</span><br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> file:<br>        <span class="hljs-keyword">if</span> line.startswith(<span class="hljs-string">&#x27;&gt;Cluster &#x27;</span>):<br>            current_cluster_id = line.split()[<span class="hljs-number">1</span>]<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># Extracting sequence name</span><br>            parts = line.split()<br>            seq_name = parts[<span class="hljs-number">2</span>].strip(<span class="hljs-string">&#x27;&gt;&#x27;</span>).split(<span class="hljs-string">&#x27;...&#x27;</span>)[<span class="hljs-number">0</span>]<br>            sequence_names.append(seq_name)<br>            cluster_ids.append(current_cluster_id)<br><br><span class="hljs-comment"># Create a DataFrame</span><br>df = pd.DataFrame(&#123;<span class="hljs-string">&#x27;Sequence Name&#x27;</span>: sequence_names, <span class="hljs-string">&#x27;Cluster ID&#x27;</span>: cluster_ids&#125;)<br><br><span class="hljs-comment"># Display the DataFrame</span><br>print(df)<br></code></pre></td></tr></table></figure></div><h2 id="Trouble-Shooting">Trouble Shooting</h2><pre>Fatal Error:Too low cluster threshold for the word length.Increase the threshold or the tolerance, or decrease the word length.Program halted !!</pre><p>The error message you’re encountering, “Fatal Error: Too low cluster threshold for the word length. Increase the threshold or the tolerance, or decrease the word length. Program halted !!”, indicates a conflict between the parameters you’ve set in CD-HIT, particularly relating to the sequence identity threshold and the word length.</p><p>In CD-HIT, the “word length” refers to the length of the initial exact match that the algorithm looks for when comparing sequences. The “cluster threshold” is the percentage similarity required for two sequences to be clustered together. When the cluster threshold is set too low relative to the word length, the program cannot effectively perform the initial sequence matching, leading to this error.</p><p>To resolve this issue, you can:</p><ol><li><p><strong>Increase the Threshold</strong>: Increase the sequence identity threshold (<code>-c</code> parameter). If it’s currently very low, increasing it will make the clustering less stringent. For instance, if you have set <code>-c 0.6</code> (60% identity), try increasing it to 0.7 or higher.</p></li><li><p><strong>Decrease the Word Length</strong>: Decrease the word length (<code>-n</code> parameter). A lower word length means the program will look for shorter exact matches in the initial step, which can be more tolerant of low similarity thresholds. However, be cautious, as too low a word length might make the process slower and less efficient.</p></li><li><p><strong>Adjust Tolerance</strong>: If your dataset includes very diverse sequences and you need to maintain a low threshold, you might have to adjust other parameters to balance the sensitivity and specificity of the clustering.</p></li></ol><p>Remember that the appropriate values for these parameters can vary depending on your specific dataset and the objectives of your analysis. It might require some experimentation to find the right balance for your needs.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">CD-HIT, a protein/nuclear</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Software" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Software/"/>
    
    <category term="more" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Software/more/"/>
    
    
    <category term="Cluster" scheme="https://karobben.github.io/tags/Cluster/"/>
    
    <category term="Software" scheme="https://karobben.github.io/tags/Software/"/>
    
    <category term="NGS" scheme="https://karobben.github.io/tags/NGS/"/>
    
  </entry>
  
  <entry>
    <title>Extract Information from PDB and Visualize with Pyvista</title>
    <link href="https://karobben.github.io/2023/12/08/Bioinfor/pdbpyvista/"/>
    <id>https://karobben.github.io/2023/12/08/Bioinfor/pdbpyvista/</id>
    <published>2023-12-08T15:26:56.000Z</published>
    <updated>2023-12-19T22:56:00.935Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Quick-Codes">Quick Codes</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> Bio.PDB <span class="hljs-keyword">import</span> PDBParser<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pyvista <span class="hljs-keyword">as</span> pv<br><br><span class="hljs-comment"># Parse the PDB file</span><br>parser = PDBParser()<br>structure = parser.get_structure(<span class="hljs-string">&quot;1nnc&quot;</span>, <span class="hljs-string">&quot;PDB/1nnc.pdb&quot;</span>)<br><br><span class="hljs-comment"># Extract 3D coordinates and print atom names</span><br>points = []<br><span class="hljs-keyword">for</span> model <span class="hljs-keyword">in</span> structure:<br>    <span class="hljs-keyword">for</span> chain <span class="hljs-keyword">in</span> model:<br>        <span class="hljs-keyword">for</span> residue <span class="hljs-keyword">in</span> chain:<br>            <span class="hljs-keyword">for</span> atom <span class="hljs-keyword">in</span> residue:<br>                points.append(atom.get_coord())<br>                print(<span class="hljs-string">f&quot;Atom Name: <span class="hljs-subst">&#123;atom.get_name()&#125;</span>, Coordinates: <span class="hljs-subst">&#123;atom.get_coord()&#125;</span>&quot;</span>)<br><br><span class="hljs-comment"># Convert to a numpy array</span><br>points_array = np.array(points)<br><br><span class="hljs-comment"># Create a PyVista point cloud</span><br>point_cloud = pv.PolyData(points_array)<br>point_cloud.plot(point_size=<span class="hljs-number">5</span>, color=<span class="hljs-string">&#x27;red&#x27;</span>)<br></code></pre></td></tr></table></figure></div><p>In this updated script:</p><ul><li>The <code>print</code> statement within the innermost loop (<code>for atom in residue:</code>) prints the name of each atom and its coordinates.</li><li><code>atom.get_name()</code> retrieves the name of the atom.</li><li><code>atom.get_coord()</code> retrieves the 3D coordinates of the atom.</li></ul><p>Remember to replace <code>&quot;protein_id&quot;</code> and <code>&quot;path_to_your_pdb_file.pdb&quot;</code> with the appropriate identifiers and file path for your PDB file.</p><p>This script will print the name and coordinates of each atom in the console and plot the points in 3D using PyVista. You can further modify this script to include more details or to format the output as per your requirement.</p><h2 id="The-Name-of-Atoms">The Name of Atoms</h2><p>Certainly! In the context of a Protein Data Bank (PDB) file, atoms within proteins are named according to standard conventions that reflect their chemical properties and their position within the protein structure. Here’s a breakdown of what different atom names typically signify:</p><ol><li><p><strong>Element Symbol</strong>: The first part of an atom’s name usually represents its element symbol from the periodic table. For example, “C” stands for Carbon, “N” for Nitrogen, “O” for Oxygen, “S” for Sulfur, and so on.</p></li><li><p><strong>Amino Acid Context</strong>: Atoms are part of amino acids in proteins. Each amino acid has a specific set of atoms. For instance, in the amino acid glycine, you might find atoms named “CA” (alpha carbon), “N” (amino nitrogen), “O” (carbonyl oxygen), etc.</p></li><li><p><strong>Position in Amino Acid</strong>:</p><ul><li><strong>Alpha Carbon (CA)</strong>: This is the central carbon atom to which the amino group (NH2), carboxyl group (COOH), hydrogen (H), and the R group (side chain) are attached in amino acids.</li><li><strong>Backbone Atoms</strong>: These include “N” (the amide nitrogen), “CA” (alpha carbon), and “C” (the carbonyl carbon). These atoms form the backbone of the protein chain.</li><li><strong>Side Chain Atoms</strong>: Atoms in the side chain (or R group) of an amino acid are denoted by different names depending on their position and chemical nature. For example, in the amino acid lysine, you might see names like “CG”, “CD”, “CE” - these are carbon atoms in the side chain, labeled in order from the alpha carbon.</li></ul></li><li><p><strong>Hydrogen Atoms</strong>: These are often denoted by “H” followed by additional characters to specify their position. For example, “HA” might be a hydrogen attached to the alpha carbon.</p></li><li><p><strong>Prosthetic Groups or Non-standard Residues</strong>: In addition to standard amino acids, proteins may have non-standard residues or prosthetic groups like heme in hemoglobin. These will have their own unique naming conventions based on their molecular structure.</p></li><li><p><strong>Alternate Locations</strong>: Sometimes an atom can occupy multiple positions due to structural flexibility. These are often indicated by an additional character like “A” or “B” following the atom name.</p></li></ol><p>Understanding these naming conventions can help in interpreting the structure and function of the protein, as the 3D arrangement of these atoms determines the protein’s shape and reactive sites. In practical use, this information is crucial for tasks like modeling protein-ligand interactions, understanding enzyme active sites, or studying protein folding and dynamics.</p><h2 id="Show-the-Alpha-Carbon-Only">Show the Alpha Carbon Only</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> Bio.PDB <span class="hljs-keyword">import</span> PDBParser<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pyvista <span class="hljs-keyword">as</span> pv<br><br><span class="hljs-comment"># Parse the PDB file</span><br>parser = PDBParser()<br>structure = parser.get_structure(<span class="hljs-string">&quot;Mos99&quot;</span>, <span class="hljs-string">&quot;PDB/Mos99_WT_NA_monomer.pdb&quot;</span>)<br><br><span class="hljs-comment"># Extract 3D coordinates and print atom names</span><br>points = []<br><span class="hljs-keyword">for</span> model <span class="hljs-keyword">in</span> structure:<br>    <span class="hljs-keyword">for</span> chain <span class="hljs-keyword">in</span> model:<br>        <span class="hljs-keyword">for</span> residue <span class="hljs-keyword">in</span> chain:<br>            <span class="hljs-keyword">for</span> atom <span class="hljs-keyword">in</span> residue:<br>              <span class="hljs-keyword">if</span> atom.get_name() == <span class="hljs-string">&quot;CA&quot;</span>:<br>                points.append(atom.get_coord())<br>                <span class="hljs-comment">#print(f&quot;Atom Name: &#123;atom.get_name()&#125;, Coordinates: &#123;atom.get_coord()&#125;&quot;)</span><br><br><span class="hljs-comment"># Convert to a numpy array</span><br>points_array = np.array(points)<br><br><span class="hljs-comment"># Create a PyVista point cloud</span><br>point_cloud = pv.PolyData(points_array)<br>point_cloud.plot(point_size=<span class="hljs-number">5</span>, color=<span class="hljs-string">&#x27;red&#x27;</span>)<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://imgur.com/bdjsps4.png" alt=""></th></tr></thead><tbody></tbody></table><h2 id="Convert-it-into-Mesh">Convert it into Mesh</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># select the dots on the surface</span><br><span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> NearestNeighbors<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><br><span class="hljs-comment"># Assuming &#x27;points_array&#x27; is your numpy array of 3D points</span><br>points = points_array.copy()<br><br><span class="hljs-comment"># Use KNN to find the nearest neighbors</span><br>nbrs = NearestNeighbors(n_neighbors=<span class="hljs-number">10</span>).fit(points)<br>distances, indices = nbrs.kneighbors(points)<br><br><span class="hljs-comment"># Determine a threshold distance for surface points</span><br>threshold_distance = np.percentile(distances, <span class="hljs-number">90</span>)  <span class="hljs-comment"># adjust as needed</span><br><br><span class="hljs-comment"># Identify surface points</span><br>surface_points = points[np.<span class="hljs-built_in">max</span>(distances, axis=<span class="hljs-number">1</span>) &gt; threshold_distance]<br><br>point_cloud = pv.PolyData(surface_points)<br><span class="hljs-comment">#point_cloud = pv.PolyData(points_array)</span><br>volume = point_cloud.delaunay_3d(alpha = <span class="hljs-number">4</span>)<br>shell = volume.extract_geometry()<br>shell.plot(show_edges=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://imgur.com/QbP7pRg.png" alt="Mesh Surface of Alpha Carbon"></th></tr></thead><tbody></tbody></table><h2 id="Visualize-a-Single-Amino-Acid">Visualize a Single Amino Acid</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">chain_id = <span class="hljs-string">&#x27;A&#x27;</span>  <span class="hljs-comment"># Replace with the relevant chain ID</span><br>residue_number = <span class="hljs-number">100</span>  <span class="hljs-comment"># Replace with the residue number of the amino acid</span><br><br><span class="hljs-comment"># Extract coordinates</span><br>amino_acid_data = []<br><span class="hljs-keyword">for</span> model <span class="hljs-keyword">in</span> structure:<br>    <span class="hljs-keyword">for</span> chain <span class="hljs-keyword">in</span> model:<br>        <span class="hljs-keyword">if</span> chain.get_id() == chain_id:<br>            <span class="hljs-keyword">for</span> residue <span class="hljs-keyword">in</span> chain:<br>                <span class="hljs-keyword">if</span> residue.get_id()[<span class="hljs-number">1</span>] == residue_number:<br>                    <span class="hljs-keyword">for</span> atom <span class="hljs-keyword">in</span> residue:<br>                        amino_acid_data.append((atom.get_coord(), atom.element, atom.get_id()))<br>                    tmp = residue<br>                    print(residue.get_full_id(), residue.get_resname())<br><br><span class="hljs-comment"># Separate coordinates, elements, and atom names</span><br>coordinates, elements, atom_names = <span class="hljs-built_in">zip</span>(*amino_acid_data)<br>coordinates = np.array(coordinates)<br><br><br><span class="hljs-comment"># find bounds:</span><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">infer_bonds</span>(<span class="hljs-params">coords, max_bond_length=<span class="hljs-number">2</span></span>):</span><br>    bonds = []<br>    num_atoms = <span class="hljs-built_in">len</span>(coords)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_atoms):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(i+<span class="hljs-number">1</span>, num_atoms):<br>            <span class="hljs-keyword">if</span> np.linalg.norm(coords[i] - coords[j]) &lt; max_bond_length:<br>                bonds.append((i, j))<br>    <span class="hljs-keyword">return</span> bonds<br><br><span class="hljs-comment"># Infer bonds</span><br>bonds = infer_bonds(coordinates)<br><br><br><span class="hljs-comment"># Plot all</span><br><span class="hljs-comment"># Map elements to RGB colors (customize this as needed)</span><br>element_colors = &#123;<br>    <span class="hljs-string">&quot;C&quot;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],  <span class="hljs-comment"># Carbon (black)</span><br>    <span class="hljs-string">&quot;N&quot;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">255</span>],  <span class="hljs-comment"># Nitrogen (blue)</span><br>    <span class="hljs-string">&quot;O&quot;</span>: [<span class="hljs-number">255</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],  <span class="hljs-comment"># Oxygen (red)</span><br>    <span class="hljs-string">&quot;S&quot;</span>: [<span class="hljs-number">255</span>, <span class="hljs-number">255</span>, <span class="hljs-number">0</span>],  <span class="hljs-comment"># Sulfur (yellow)</span><br>    <span class="hljs-comment"># Add more elements and colors as required</span><br>&#125;<br><br><span class="hljs-comment"># Create an array to store RGB colors</span><br>rgb_colors = np.array([element_colors.get(element, [<span class="hljs-number">125</span>, <span class="hljs-number">125</span>, <span class="hljs-number">125</span>]) <span class="hljs-keyword">for</span> element <span class="hljs-keyword">in</span> elements])  <span class="hljs-comment"># Default grey</span><br><br><span class="hljs-comment"># Create a PyVista plotter</span><br>plotter = pv.Plotter()<br><br><span class="hljs-comment"># Plot atoms</span><br><span class="hljs-keyword">for</span> coord, color <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(coordinates, rgb_colors):<br>    sphere = pv.Sphere(radius=<span class="hljs-number">0.5</span>, center=coord)<br>    plotter.add_mesh(sphere, color=color)<br><br><span class="hljs-comment"># Plot bonds</span><br><span class="hljs-keyword">for</span> bond <span class="hljs-keyword">in</span> bonds:<br>    start, end = coordinates[bond[<span class="hljs-number">0</span>]], coordinates[bond[<span class="hljs-number">1</span>]]<br>    line = pv.Line(start, end)<br>    plotter.add_mesh(line, color=<span class="hljs-string">&#x27;grey&#x27;</span>, line_width=<span class="hljs-number">3</span>)<br><br><span class="hljs-comment"># Show plot</span><br>plotter.show()<br></code></pre></td></tr></table></figure></div><p><img src="https://imgur.com/E3f8WPj.png" alt=""></p><p>In this case, in the atom_names:</p><ul><li>CA: alpha carbon</li><li>C: the carbon from C<sub>α</sub>-COOH</li><li>N: The N from C<sub>α</sub>-NH<sub>3</sub></li></ul><p>rest of atoms are coming from side chain.</p><h2 id="Turn-IT-into-Dictionary">Turn IT into Dictionary</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">Protein_dic = &#123;&#125;<br><span class="hljs-keyword">for</span> model <span class="hljs-keyword">in</span> structure:<br>  <span class="hljs-keyword">for</span> chain <span class="hljs-keyword">in</span> model:<br>    chain_dic = &#123;&#125; <br>    <span class="hljs-keyword">for</span> residue <span class="hljs-keyword">in</span> chain:<br>      chain_dic.update(&#123;residue.get_id()[<span class="hljs-number">1</span>]: residue&#125;)<br>    Protein_dic.update(&#123;chain.get_id(): chain_dic&#125;)<br></code></pre></td></tr></table></figure></div><h2 id="Check-the-Adjacent-Side-Chain-by-Side-Chain">Check the Adjacent Side Chain by Side Chain</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">Get_atom</span>(<span class="hljs-params">Res</span>):</span><br>  R = []<br>  <span class="hljs-keyword">for</span> atom <span class="hljs-keyword">in</span> Res:<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(Res) == <span class="hljs-number">4</span>:<br>      R += [atom.get_coord()]<br>    <span class="hljs-keyword">else</span>:      <br>      <span class="hljs-keyword">if</span> atom.get_id() <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;N&#x27;</span>, <span class="hljs-string">&#x27;CA&#x27;</span>, <span class="hljs-string">&quot;C&quot;</span>, <span class="hljs-string">&quot;O&quot;</span>]:<br>        R += [atom.get_coord()]<br>  R = np.array(R)<br>  <span class="hljs-keyword">return</span> R<br><br>AA_list = [<span class="hljs-string">&#x27;ALA&#x27;</span>, <span class="hljs-string">&#x27;ARG&#x27;</span>, <span class="hljs-string">&#x27;ASN&#x27;</span>, <span class="hljs-string">&#x27;ASP&#x27;</span>, <span class="hljs-string">&#x27;CYS&#x27;</span>, <span class="hljs-string">&#x27;GLN&#x27;</span>, <span class="hljs-string">&#x27;GLU&#x27;</span>, <span class="hljs-string">&#x27;GLY&#x27;</span>, <span class="hljs-string">&#x27;HIS&#x27;</span>, <span class="hljs-string">&#x27;ILE&#x27;</span>, <span class="hljs-string">&#x27;LEU&#x27;</span>, <span class="hljs-string">&#x27;LYS&#x27;</span>, <span class="hljs-string">&#x27;MET&#x27;</span>, <span class="hljs-string">&#x27;PHE&#x27;</span>, <span class="hljs-string">&#x27;PRO&#x27;</span>, <span class="hljs-string">&#x27;SER&#x27;</span>, <span class="hljs-string">&#x27;THR&#x27;</span>, <span class="hljs-string">&#x27;TRP&#x27;</span>, <span class="hljs-string">&#x27;TYR&#x27;</span>, <span class="hljs-string">&#x27;VAL&#x27;</span>]<br><br>Residues = []<br><span class="hljs-keyword">for</span> chain <span class="hljs-keyword">in</span> Protein_dic.keys():<br>  <span class="hljs-keyword">for</span> pos <span class="hljs-keyword">in</span> Protein_dic[chain]:<br>    <span class="hljs-keyword">if</span> Protein_dic[chain][pos].get_resname() <span class="hljs-keyword">in</span> AA_list:<br>      Residues += [[chain, pos, Protein_dic[chain][pos].get_resname(), <br>                  np.mean(Get_atom(Protein_dic[chain][pos]), axis=<span class="hljs-number">0</span>)]]<br><br><br><br><span class="hljs-comment"># plot hte residues position</span><br><span class="hljs-comment"># Convert to a numpy array</span><br>points_array = np.array([i[-<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> Residues])<br><br><span class="hljs-comment"># Create a PyVista point cloud</span><br>point_cloud = pv.PolyData(points_array)<br><br>point_cloud.plot(point_size=<span class="hljs-number">5</span>, color=<span class="hljs-string">&#x27;red&#x27;</span>)<br><br><br><span class="hljs-comment"># mesh</span><br><br><span class="hljs-comment"># Assuming &#x27;points_array&#x27; is your numpy array of 3D points</span><br>points = points_array.copy()<br><br><span class="hljs-comment"># Use KNN to find the nearest neighbors</span><br>nbrs = NearestNeighbors(n_neighbors=<span class="hljs-number">5</span>).fit(points)<br>distances, indices = nbrs.kneighbors(points)<br><br><span class="hljs-comment"># Determine a threshold distance for surface points</span><br>threshold_distance = np.percentile(distances, <span class="hljs-number">90</span>)  <span class="hljs-comment"># adjust as needed</span><br><br><span class="hljs-comment"># Identify surface points</span><br>surface_points = points[np.<span class="hljs-built_in">max</span>(distances, axis=<span class="hljs-number">1</span>) &gt; threshold_distance]<br>surface_res = np.array(Residues)[np.<span class="hljs-built_in">max</span>(distances, axis=<span class="hljs-number">1</span>) &gt; threshold_distance]<br><br>point_cloud = pv.PolyData(surface_points)<br><span class="hljs-comment">#point_cloud = pv.PolyData(points_array)</span><br>volume = point_cloud.delaunay_3d(alpha = <span class="hljs-number">10</span>)<br>shell = volume.extract_geometry()<br>shell.plot(show_edges=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure></div><p><img src="https://imgur.com/c0OUROW.png" alt=""></p><h2 id="Check-the-Residua-Local-environment">Check the Residua Local environment</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">nbrs = NearestNeighbors(n_neighbors=<span class="hljs-number">6</span>).fit(surface_points)<br>distances, indices = nbrs.kneighbors(surface_points)<br><br>Loc_res = &#123;&#125;; [Loc_res.update(&#123;i[<span class="hljs-number">1</span>]:i[<span class="hljs-number">2</span>]&#125;) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> Residues <span class="hljs-keyword">if</span> i [<span class="hljs-number">0</span>]==<span class="hljs-string">&#x27;A&#x27;</span>]<br><span class="hljs-comment"># rm duplicated</span><br><br>Net_charge = &#123;<span class="hljs-string">&quot;ALA&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;ARG&quot;</span>:+<span class="hljs-number">1</span>, <span class="hljs-string">&quot;ASN&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;ASP&quot;</span>:-<span class="hljs-number">1</span>, <span class="hljs-string">&quot;CYS&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;GLN&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;GLU&quot;</span>:-<span class="hljs-number">1</span>, <span class="hljs-string">&quot;GLY&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;HIS&quot;</span>:+<span class="hljs-number">1</span>, <span class="hljs-string">&quot;ILE&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;LEU&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;LYS&quot;</span>:+<span class="hljs-number">1</span>, <span class="hljs-string">&quot;MET&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;PHE&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;PRO&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;SER&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;THR&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;TRP&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;TYR&quot;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&quot;VAL&quot;</span>:<span class="hljs-number">0</span>&#125;<br><br><br>res_pos  = np.array([[surface_res[ii][<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> ii <span class="hljs-keyword">in</span> i[:<span class="hljs-number">5</span>]] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> indices])<br>res_pos = np.unique(res_pos, axis= <span class="hljs-number">0</span>)<br><br>res_name = [[Loc_res[ii] <span class="hljs-keyword">for</span> ii <span class="hljs-keyword">in</span> i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> res_pos]<br>Charge_av = [<span class="hljs-built_in">sum</span>([Net_charge[ii] <span class="hljs-keyword">for</span> ii <span class="hljs-keyword">in</span> i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> res_name]<br><br><br>Loc_net = &#123;&#125;<br>[Loc_net.update(&#123;i[<span class="hljs-number">0</span>]:ii&#125;) <span class="hljs-keyword">for</span> i,ii <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(res_pos, Charge_av)]<br>values = [Loc_net[i[<span class="hljs-number">1</span>]] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> surface_res]<br><br>point_cloud = pv.PolyData(surface_points)<br>point_cloud[<span class="hljs-string">&quot;values&quot;</span>] = values<br><br><span class="hljs-comment">#point_cloud = pv.PolyData(points_array)</span><br>volume = point_cloud.delaunay_3d(alpha = <span class="hljs-number">10</span>)<br>shell = volume.extract_geometry()<br><br>plotter = pv.Plotter()<br>plotter.add_mesh(volume, scalars=<span class="hljs-string">&quot;values&quot;</span>, cmap=<span class="hljs-string">&quot;coolwarm&quot;</span>)<br>plotter.add_scalar_bar(color=<span class="hljs-string">&#x27;black&#x27;</span>)  <span class="hljs-comment"># Set scalar bar font color to black</span><br>plotter.set_background(color=<span class="hljs-string">&#x27;white&#x27;</span>)<br>plotter.show()<br><br><br>shell.plot(show_edges=<span class="hljs-literal">True</span>, scalars=<span class="hljs-string">&quot;values&quot;</span>, cmap=<span class="hljs-string">&quot;coolwarm&quot;</span>)<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://imgur.com/ZKPfTRr.png" alt=""></th></tr></thead><tbody></tbody></table><h2 id="Camera-Position">Camera Position</h2><p>In PyVista, you can easily get and set the camera position to ensure a consistent view across different plots. The camera position in PyVista is defined by a tuple of three elements:</p><ol><li><strong>Camera Position</strong>: The location of the camera in the 3D space.</li><li><strong>Focal Point</strong>: The point in the 3D space that the camera is looking at.</li><li><strong>View Up</strong>: A vector that defines the ‘up’ direction in the view of the camera.</li></ol><p>Here’s how you can get and then set the camera position:</p><h3 id="Getting-the-Camera-Position">Getting the Camera Position</h3><p>After you have displayed your plot once, you can retrieve the camera position:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pyvista <span class="hljs-keyword">as</span> pv<br><br><span class="hljs-comment"># [Your code to create and display the mesh]</span><br><br><span class="hljs-comment"># Create a plotter and add the mesh</span><br>plotter = pv.Plotter()<br>plotter.add_mesh(mesh)<br>plotter.show()<br><br><span class="hljs-comment"># Q to quite the polt</span><br><span class="hljs-comment"># Get the camera position</span><br>camera_position = plotter.camera_position<br></code></pre></td></tr></table></figure></div><h3 id="Setting-the-Camera-Position">Setting the Camera Position</h3><p>When you create a new plot and want to use the same camera position, you can set it like this:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Create a new plotter</span><br>plotter = pv.Plotter()<br><span class="hljs-comment"># Add the mesh to the new plotter</span><br>plotter.add_mesh(mesh)<br><span class="hljs-comment"># Set the camera position to the saved one</span><br>plotter.camera_position = camera_position<br><span class="hljs-comment"># Show the plot with the set camera position</span><br>plotter.show()<br></code></pre></td></tr></table></figure></div><p>Remember, you should retrieve and set the camera position after and before calling <code>show()</code>, respectively. This method ensures that every time you plot your mesh, the view will be identical, assuming the mesh and other plot settings remain the same.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Extract Information from PDB by using Biopython, rebuild the model and Visualize it with Pyvista</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Protein Structure" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Protein-Structure/"/>
    
    
    <category term="Software" scheme="https://karobben.github.io/tags/Software/"/>
    
    <category term="3D" scheme="https://karobben.github.io/tags/3D/"/>
    
    <category term="Pyvista" scheme="https://karobben.github.io/tags/Pyvista/"/>
    
    <category term="Protein" scheme="https://karobben.github.io/tags/Protein/"/>
    
  </entry>
  
</feed>
