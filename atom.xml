<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Karobben</title>
  
  <subtitle>Engjoy~</subtitle>
  <link href="https://karobben.github.io/atom.xml" rel="self"/>
  
  <link href="https://karobben.github.io/"/>
  <updated>2024-07-06T23:06:18.942Z</updated>
  <id>https://karobben.github.io/</id>
  
  <author>
    <name>Karobben</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>FoldX</title>
    <link href="https://karobben.github.io/2024/07/06/Bioinfor/foldx/"/>
    <id>https://karobben.github.io/2024/07/06/Bioinfor/foldx/</id>
    <published>2024-07-06T22:11:38.000Z</published>
    <updated>2024-07-06T23:06:18.942Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Run-the-FoldX">Run the FoldX</h2><p>In this example, I am using the <strong>7ekb</strong> as example</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># download the pdb</span><br>wget https://files.rcsb.org/view/7ekb.pdb<br><span class="hljs-comment"># Repair the PDB. After repaired it, you&#x27;ll get the 7ekb_Repair.pdb for the next step</span><br>FoldX --<span class="hljs-built_in">command</span>=RepairPDB --pdb=7ekb.pdb<br><span class="hljs-comment"># calculate the free energy of the PDB  </span><br>FoldX --<span class="hljs-built_in">command</span>=Stability  --pdb=7ekb_Repair.pdb<br></code></pre></td></tr></table></figure></div><h2 id="RepairPDB">RepairPDB</h2><h3 id="Why-Repair-PDB">Why Repair PDB?</h3><p>According to ChatGPT4o, <code>RepairPDB</code> command in FoldX is a crucial step to ensure the quality and integrity of your PDB file before performing stability calculations or other analyses. Also, you could found more information from <a href="https://foldxsuite.crg.eu/command/RepairPDB">document</a></p><ol><li><p><strong>Fix Structural Issues</strong>:</p><ul><li><strong>Correcting Errors</strong>: PDB files obtained from experiments like X-ray crystallography or cryo-EM often have missing atoms, residues, or other structural issues that can affect downstream analyses. <code>RepairPDB</code> fixes these issues to ensure a complete and accurate structure.</li><li><strong>Adding Missing Atoms</strong>: The command can add missing atoms, such as hydrogen atoms, which are essential for energy calculations.</li></ul></li><li><p><strong>Standardizing the Structure</strong>:</p><ul><li><strong>Normalization</strong>: <code>RepairPDB</code> standardizes the structure to ensure that all residues and atoms are in the correct format and positions. This includes correcting bond lengths and angles to standard values.</li><li><strong>Removing Non-standard Residues</strong>: It can remove or correct non-standard residues and ligands that might interfere with calculations.</li></ul></li><li><p><strong>Improving Energy Calculations</strong>:</p><ul><li><strong>Optimizing Geometry</strong>: The command optimizes the geometry of the protein, ensuring that the atomic positions are energetically favorable. This leads to more accurate stability and free energy calculations.</li><li><strong>Minimizing Steric Clashes</strong>: It identifies and resolves steric clashes (where atoms are too close to each other), which can distort energy calculations.</li></ul></li><li><p><strong>Ensuring Compatibility</strong>:</p><ul><li><strong>Consistency</strong>: Running <code>RepairPDB</code> ensures that your PDB file is compatible with FoldX’s algorithms, reducing the risk of errors during subsequent steps.</li></ul></li></ol><div class="admonition question"><p class="admonition-title">How does the Output looks like?</p></div><pre>Residue LYSH222 has high Energy, we mutate it to itselfRepair Residue ID= LYSH222BackHbond       =               -317.22SideHbond       =               -137.87Energy_VdW      =               -476.42Electro         =               -15.23Energy_SolvP    =               628.80Energy_SolvH    =               -624.90Energy_vdwclash =               15.60energy_torsion  =               9.33backbone_vdwclash=              143.43Entropy_sidec   =               245.04Entropy_mainc   =               632.72water bonds     =               0.00helix dipole    =               -0.35loop_entropy    =               0.00cis_bond        =               4.50disulfide       =               -13.95kn electrostatic=               -0.25partial covalent interactions = 0.00Energy_Ionisation =             1.07Entropy Complex =               0.00-----------------------------------------------------------Total          =   -49.10</pre><p>It took me <mark>2m 48s</mark>. It only work in single thread and cannot move on multiple threads. I guess because it works by following the order of the AA and the <code>Total</code> is depending on the previous values. So, it can’t work on multiple threads.</p><p>Here is the result of before and after repairing. The RMS=0.01 which means it almost the same. But the slightly different are mainly focus on the loos area. In the picture present below, the left panel with green structure is the raw pdb file from PDB database. The light blue structure on the right is the corrected by FoldX. Red structure is antigen. As I marked on the left panel, 2 beta-sheets and 1 alpha helix are deleted and become random loop. Those area from the antibody are very closing to the antigen. So, technically, random loop would make more sense to me.</p><p><img src="https://imgur.com/i8aPrTy.png" alt=""></p><h2 id="Stability-Calculations">Stability Calculations</h2><p>After repaired the PDB file, you can get the result immediately.</p><pre>   ********************************************   ***                                      ***   ***             FoldX 5.1 (c)            ***   ***                                      ***   ***     code by the FoldX Consortium     ***   ***                                      ***   ***     Jesper Borg, Frederic Rousseau   ***   ***    Joost Schymkowitz, Luis Serrano   ***   ***    Peter Vanhee, Erik Verschueren    ***   ***     Lies Baeten, Javier Delgado      ***   ***       and Francois Stricher          ***   *** and any other of the 9! permutations ***   ***   based on an original concept by    ***   ***   Raphael Guerois and Luis Serrano   ***   ********************************************Stability >>>1 models read: 7ekb_Repair.pdbBackHbond       =               -332.04SideHbond       =               -163.29Energy_VdW      =               -481.14Electro         =               -17.42Energy_SolvP    =               626.91Energy_SolvH    =               -633.28Energy_vdwclash =               13.20energy_torsion  =               9.65backbone_vdwclash=              144.57Entropy_sidec   =               259.27Entropy_mainc   =               634.24water bonds     =               0.00helix dipole    =               -0.40loop_entropy    =               0.00cis_bond        =               4.50disulfide       =               -13.95kn electrostatic=               -0.41partial covalent interactions = 0.00Energy_Ionisation =             1.14Entropy Complex =               0.00-----------------------------------------------------------Total          =   -93.01FINISHING STABILITY ANALYSIS OPTIONYour file run OKEnd time of FoldX: Sat Jul  6 17:23:18 2024Total time spend: 0.85 seconds.</pre><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">FoldX</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>Nanopre and PacBio based Genome Assembly</title>
    <link href="https://karobben.github.io/2024/06/30/Bioinfor/LongReads/"/>
    <id>https://karobben.github.io/2024/06/30/Bioinfor/LongReads/</id>
    <published>2024-06-30T20:50:52.000Z</published>
    <updated>2024-07-05T16:33:10.980Z</updated>
    
    <content type="html"><![CDATA[<p>Related Papers:</p><ul><li>Rayamajhi N, Cheng C H C, Catchen J M. Evaluating Illumina-, Nanopore-, and PacBio-based genome assembly strategies with the bald notothen, Trematomus borchgrevinki[J]. G3, 2022, 12(11): jkac192. <a href="https://academic.oup.com/g3journal/article/12/11/jkac192/6651842">Paper</a></li><li>van Rengs W M J, Schmidt M H W, Effgen S, et al. A chromosome scale tomato genome built from complementary PacBio and Nanopore sequences alone reveals extensive linkage drag during breeding[J]. The Plant Journal, 2022, 110(2): 572-588. <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/tpj.15690">Paper</a></li><li>Murigneux V, Rai S K, Furtado A, et al. Comparison of long-read methods for sequencing and assembly of a plant genome[J]. GigaScience, 2020, 9(12): giaa146. <a href="https://academic.oup.com/gigascience/article/9/12/giaa146/6042729">Paper</a></li></ul><h2 id="Evaluating-Illumina-Nanopore-and-PacBio-based-genome-assembly-strategies-with-the-bald-notothen-Trematomus-borchgrevinki">Evaluating Illumina-, Nanopore-, and PacBio-based genome assembly strategies with the bald notothen, Trematomus borchgrevinki</h2><table><thead><tr><th style="text-align:left"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:left">In this paper, they did long reads assembly and Long-reads, short-reads hybrid assembly comparing. The experiment organism is “Trematomus borchgrevinki” (<strong>fish</strong>), a cold specialized Antarctic notothenioid fish with an estimated genome size of 1.28 Gb</td><td style="text-align:center"><img src="https://www.researchgate.net/profile/Gregory-Sloop/publication/364608485/figure/fig6/AS:11431281091299426@1666380222030/Trematomus-bernacchii-Courtesy-of-Zureks-and-Wikimedia-Commons.png" alt=""><br><a href="https://www.researchgate.net/publication/364608485_The_Cardiovascular_System_of_Antarctic_Icefish_Appears_to_Have_Been_Designed_to_Utilize_Hemoglobinless_Blood?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6Il9kaXJlY3QiLCJwYWdlIjoiX2RpcmVjdCJ9fQ">© Gregory Sloop</a></td></tr></tbody></table><p>Sequencing Size:</p><ul><li>Nanopore: 24.29 Gb</li><li>PacBio: 118.42 Gb</li></ul><p><strong>Hybrid</strong> assemblies can generate <mark>higher contiguity</mark> they tend to suffer from lower quality. <strong>long-read-only assemblies</strong> can be optimized for <mark>contiguity</mark> by subsampling length-restricted raw reads. Long-read contig assembly is the current <strong>best choice</strong> and that assemblies from phase I and phase II were of lower quality.</p><p>Strategies:</p><ul><li>Long-reads and short-reads hybrid: quickmerge<ol><li>Long-reads assembly independently: <code>Canu</code> and <code>WTDBG2</code> assembly, assessed with <code>QUAST</code></li><li>2 rounds of polishing with <code>Pilon</code>. (First round: SNPs adn indels, Second round: local reassembly)</li><li>Gap filling with <code>PBJELLY</code></li></ol></li><li>Long-reads only was assembly by variaties of tools. The yacrd (Marijon et al. 2020) it the tool to identify potential <strong>chimeric reads</strong><ol><li><code>WTDBG2</code> was used to do the assembly</li></ol></li></ul><p>For long-reads, comparing to short-reads assembled genome, it has high continuity but also more number of duplicated BUSCO genes. Chimeric reads are exist. In this paper, they also applied the subsampling to deleted chimeric reads. By cooperate with the limiting reads lengths, the PacBio reads assembly results could be improved. The number of contigs dropped from 10,848 to 4,409 with only 70 Gb of data (generated by sampling minimum and maximum read lengths of 10 and 40 kb)</p><p>In this paper, the data shows that the assembly results from ONT reads are not as good as those from PacBio reads. However, because they used very different methods for pre-processing reads and assembly, the results are somewhat incomparable. Therefore, we can only conclude that the PacBio pipeline is more advanced.</p><h2 id="Comparison-of-long-read-methods-for-sequencing-and-assembly-of-a-plant-genome">Comparison of long-read methods for sequencing and assembly of a plant genome</h2><table><thead><tr><th style="text-align:left"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:left">This paper targets <em><strong>Macadamia jansenii</strong></em>, a type of tree. The PacBio data surprised others because it has higher coverage and longer reads than the typical ONT data. Therefore, <strong>cross-comparison is meaningless</strong>. However, they assembled the genome using <strong>multiple tools</strong>, so the <strong>internal data-type comparison</strong> is still valuable.</td><td style="text-align:center"><img src="https://www.researchgate.net/profile/Ian-Cock/publication/264458556/figure/fig1/AS:392523655729155@1470596340564/Macadamia-integriflora-leaves-and-flowers-photographed-accessed-from-Wikipedia-Commons.png" alt="Macadamia integriflora"><a href="https://www.researchgate.net/publication/264458556_Evaluation_of_the_potential_of_Macadamia_integriflora_extracts_as_antibacterial_food_agents?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6Il9kaXJlY3QiLCJwYWdlIjoiX2RpcmVjdCJ9fQ">© Ian Edwin Cock</a></td></tr></tbody></table><table><thead><tr><th>Category</th><th>ONT</th><th>PacBio</th><th>BGI</th></tr></thead><tbody><tr><td><strong>Mean Reads Length</strong></td><td>7,962</td><td>20,575</td><td>2 × 100</td></tr><tr><td><strong>Assembly</strong></td><td>Redbean v2.5, Flye v2.5, and Canu</td><td>Redbean v2.5, Flye v2.5, and Canu</td><td>SuperPlus v1.0, Supernova v2.1.1, TGS-GapCloser</td></tr><tr><td><strong>Data Size</strong></td><td>24.9 Gb</td><td>65.2 Gb</td><td>74.5 Gb</td></tr><tr><td><strong>Largest Contigs</strong></td><td>9,683,794</td><td>23,824,472</td><td>517,998</td></tr><tr><td><strong>Scaffold</strong></td><td>5,332</td><td>5,446</td><td>5,065</td></tr><tr><td><strong>Scaffold N50</strong></td><td>3.52</td><td>3.50</td><td>3.54</td></tr><tr><td><strong>Contigs</strong></td><td>6,022</td><td>5,717</td><td>19,954</td></tr><tr><td><strong>Contigs N50(M)</strong></td><td>1.04</td><td>1.60</td><td>0.036</td></tr><tr><td><strong>BUSCO</strong></td><td>1,963 (92.5)</td><td>1,983 (93.5)</td><td>1,873 (88.3)</td></tr></tbody></table><p>Hybrid assembly:</p><ol><li>MaSuRCA v3.3.3: Illumina + ONT/PacBio</li><li>Flye v2.5 to perform the final assembly</li></ol><p>Diploid de novo genome assembly: PacBio reads was performed with FALCON v1.3.0</p><p>Assembly Evaluation: QUAST v5.0.2;  publicly available reference genome of M. integrifolia v2 (Genbank accession: GCA_900631585.1); subjected to BUSCO v3.0.2 with the eudicotyledons_odb10 database (2,121 genes).</p><p>In this result, the PacBio sequences dominate everything. This is because ultra-long ONT reads were not used here. Consequently, not only the length of the reads but also the accuracy and coverage of the ONT reads are lower than those of the PacBio. This comparison is extremely uneven. By <strong>comparing different long-reads assembly tools</strong> (Redbean, Flye, Falcon, Canu, Raven), the <mark>Rave</mark> is the best for both PacBio and ONT data. An interesting thing is, according to the paper, Rave supports the GPU-accelerate. But in this research, they only given 12 threads for Rave though, technically, we could give more than 1,000 of threads if we have a professional GPU.</p><h2 id="A-chromosome-scale-tomato-genome-built-from-complementary-PacBio-and-Nanopore-sequences-alone-reveals-extensive-linkage-drag-during-breeding">A chromosome scale tomato genome built from complementary PacBio and Nanopore sequences alone reveals extensive linkage drag during breeding</h2><pre class="mermaid">graph LR;　　Nanopore-->|NECAT|Assembly1;　　PacBio-->|Hifiasm|Assembly2;    Assembly1-->|quickmerge| Sinlge;    Assembly2-->|quickmerge| Sinlge</pre><table><thead><tr><th style="text-align:left"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:left">In this research, they target into the cultivated <strong>tomato</strong> (Solanum lycopersicum). They applied PacBio HiFi and ONT Nanopore sequencing to develop <strong>independent</strong>. After then, they <strong>merged the HiFi and ONT assemblies</strong> to generate a long-read-only assembly where all 12 chromosomes were represented as 12 contiguous sequences (N50 = 68.5 Mbp).</td><td style="text-align:center"><img src="https://www.researchgate.net/profile/Gbenga-Orunmolase/publication/371350058/figure/fig1/AS:11431281165942236@1686127227760/Tomato-Solanum-lycopersicum.jpg" alt=""><br><a href="https://www.researchgate.net/publication/371350058_MICROORGANISMS_ASSOCIATED_WITH_SOFT_ROT_OF_TOMATOES?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6Il9kaXJlY3QiLCJwYWdlIjoiX2RpcmVjdCJ9fQ">© Gbenga Emmanuel Orunmolase</a></td></tr></tbody></table><table><thead><tr><th></th><th>ONT</th><th>PacBio HiFi</th></tr></thead><tbody><tr><td><strong>Data Size</strong></td><td>100~ Gb (x2)</td><td>20~ Gb (x2)</td></tr><tr><td><strong>Assembled Contigs</strong></td><td>100~300</td><td>700~2000</td></tr><tr><td><strong>Computational Costs</strong></td><td>3 days with 256 threads (NECAT)</td><td>2 hours with 128 threads (Hifiasm)</td></tr></tbody></table><p>Although the <strong>ONT has fewer contigs</strong>, it has a lower BUSCO (complete) percentage due to uncorrectable base errors. For the <mark>saturating test</mark>, they found that for PacBio HiFi reads, <strong>20 Gb</strong> would be enough to finish a good assembly with <strong>Hifiasm</strong>. For longer ONT reads, <strong>50 Gb</strong> could do a similar job with <strong>NECAT</strong>. After that, they conducted the <mark>merge test</mark> because they found partial complementarity of the assemblies as the breakpoints were different. After merging the two results, they obtained 12 super contigs, which correspond to the 12 chromosomes. Along with these 12 super contigs, they also obtained 54 contigs that could not be assembled into the 12 chromosomes; these could be chloroplast, mitochondrial, rDNA, and satellite repeat-derived sequences.</p><h3 id="MbTMV-assembly-pipeline-Merge-ONT-and-PacBio-results">MbTMV assembly pipeline (Merge ONT and PacBio results)</h3><ol><li>Assembly result polishing</li><li>nucmer (part of mummer v.4.0.0rc1) with the -l parameter to prevent invalid contig links</li><li>quickmerge<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup> was used to merge 2 assemblies with the parameter -c 7.0.</li></ol><p>A very interesting thing is they use a customized script to convert the Salsa2 output to Hi-C file and plot the contact plot with jucibox</p><hr><p>A recent comparison pointed out that PacBio HiFi reads tend to lead to better assembly of the barley (Hordeum vulgare) genome than ONT (Mascher et al., 2021)</p><style>pre {//  background-color:#38393d;  color: #5fd381;}</style><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>Chakraborty M, Baldwin-Brown J G, Long A D, et al. Contiguous and accurate de novo assembly of metazoan genomes with modest long read coverage[J]. Nucleic acids research, 2016, 44(19): e147-e147. <a href="https://github.com/mahulchak/quickmerge">GitHub</a> <a href="#fnref1" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">Nanopre and PacBio based Genome Assembly</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="WGS" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/WGS/"/>
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="NGS" scheme="https://karobben.github.io/tags/NGS/"/>
    
    <category term="Genome" scheme="https://karobben.github.io/tags/Genome/"/>
    
    <category term="WGS" scheme="https://karobben.github.io/tags/WGS/"/>
    
  </entry>
  
  <entry>
    <title>Juicer: a One-Click System for Analyzing Loop-Resolution Hi-C Experiments</title>
    <link href="https://karobben.github.io/2024/06/27/Bioinfor/juicer/"/>
    <id>https://karobben.github.io/2024/06/27/Bioinfor/juicer/</id>
    <published>2024-06-27T20:55:58.000Z</published>
    <updated>2024-07-05T19:41:51.202Z</updated>
    
    <content type="html"><![CDATA[<p>Prerequisite :</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">conda install bwa               <span class="hljs-comment"># for short reads alignment</span><br>conda install samtools          <span class="hljs-comment"># for reading the align results </span><br></code></pre></td></tr></table></figure></div><p>Resources:</p><ul><li>Paper: Durand NC, Shamim MS, Machol I, Rao SSP, Huntley MH, Lander ES, et al. Juicer Provides a One-Click System for Analyzing Loop-Resolution Hi-C Experiments. Cell Syst. 2016;3:95–8.</li><li>GitHub Source code: <a href="https://github.com/aidenlab/juicer">aidenlab/juicer</a></li><li>Example Pipeline: <a href="https://github.com/ENCODE-DCC/hic-pipeline">ENCODE-DCC/hic-pipeline</a></li><li>Forums: <a href="https://groups.google.com/g/3d-genomics">3d-genomics; google</a>. They suggest to talk and ask on the google group rather than the github issue because you could got faster responds there.</li></ul><p>For working on <strong>hic-pipeline</strong>, if you want to run it in local machine, make sure that <code>docker</code> is installed. I don’t have docker installed, so, I’ll giving this try up.</p><p>When you got the mistake and want run again, make sure remove those directories first.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">rm -rf /home/wenkanl2/Tomas/20240614_DuckGenome/myJuicerDir/aligned<br></code></pre></td></tr></table></figure></div><h2 id="Juicer-in-Action">Juicer in Action</h2><p>According to the <a href="https://github.com/aidenlab/juicer/wiki/Usage">documentation</a>, there are 5 steps for running this juicer:</p><ol><li>Download genome fasta file, put in references folder</li><li>Run <code>bwa index</code> on the fasta file</li><li>At the same time, run <a href="https://github.com/theaidenlab/juicer/blob/master/misc/generate_site_positions.py">generate_site_positions.py</a> on the fasta file + your restriction enzyme (see <a href="https://github.com/theaidenlab/juicer/wiki/Pre#restriction-site-file-format">this site about the restriction site file format</a>)</li><li>Once generate_site_positions is done, run <code>awk 'BEGIN&#123;OFS="\t"&#125;&#123;print $1, $NF&#125;' mygenome_myenzyme.txt &gt; mygenome.chrom.sizes</code> (where mygenome is your genome, like hg19, and myenzyme is your enzyme, like MboI)</li><li>Run juicer.sh with the flags <code>-z &lt;path to genome fasta file&gt;</code>, <code>-p &lt;path to mygenome.chrom.sizes&gt;</code>, and  <code>-y &lt;path to  mygenome_myenzyme.txt&gt;</code></li></ol><h3 id="1-Prepare-Your-Data">1. Prepare Your Data</h3><p>The data download from NCBI is not applicable for this pipeline. We need to adapt the name of each reads. According to the error codes <test>(-: Aligning files matching <em>/myJuicerDir/fastq/</em>_R*.fastq*</test>, we could know that the name of the reads should be <code>*_R*.fastq*</code>. Specified, according to the test data, the name of the paired ends reads should be: <code>*_R1*.fastq*</code> and <code>*_R2*.fastq</code>. So, make sure you have the correct name for each of reads.</p><h3 id="3-Generate-Restriction-Site">3. Generate Restriction Site</h3><p>It seams like you’d like to naming your ref genome first. For example, it automatically supplies the <strong>hg19</strong> and <strong>hg38</strong>. If you list the <code>restriction_site</code> directory, it has <code>hg19_MboI.txt</code></p><p>Before running the pipeline, we need to ready the <code>restriction_site</code> file, too. Here is a script from juicer to help us to generate it: <code>misc/generate_site_positions.py</code>. It works as below. To be notice, the helpers said that <test>Usage: ./generate_site_positions.py <restriction enzyme> <genome> [location]</test>. But the genome here means the name of the genome. In the example, I give it <em><strong>ZJU1.0</strong></em>. The third parameter <code>[location]</code> is the location of the genome fasta file. With the code below, they would output the file <code>ZJU1.0_HindIII.txt</code></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">python generate_site_positions.py HindIII ZJU1.0 GCF_015476345.1_ZJU1.0_genomic.fna<br>mv ZJU1.0_HindIII.txt ../restriction_sites/<br></code></pre></td></tr></table></figure></div><p>Here is the few supported name of restriction enzymes:</p><pre>    'HindIII'     : 'AAGCTT',    'DpnII'       : 'GATC',    'MboI'        : 'GATC',    'Sau3AI'      : 'GATC',    'Arima'       : [ 'GATC', 'GANTC' ],</pre><h3 id="4-Create-Chromosome-Size-File">4. Create Chromosome Size File</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">awk <span class="hljs-string">&#x27;BEGIN&#123;OFS=&quot;\t&quot;&#125;&#123;print $1, $NF&#125;&#x27;</span> restriction_sites/ZJU1.0_HindIII.txt &gt; ZJU1.0.chrom.sizes<br></code></pre></td></tr></table></figure></div><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># HiCCUPS</span><br>scripts/common/juicer_tools hiccups --ignore_sparsity aligned/inter_30.hic aligned/inter_30_loops<br><span class="hljs-comment"># APA: </span><br>scripts/common/juicer_tools apa aligned/inter_30.hic aligned/inter_30_loops apa_results<br></code></pre></td></tr></table></figure></div><p>In the test data, it generally takes 90GB RAM and 7 GB of GPU RAM</p><h3 id="5-Run-with-the-New-Parameters">5. Run with the New Parameters</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">&lt;myJuicerDir&gt;/scripts/juicer.sh -D &lt;myJuicerDir&gt; <br></code></pre></td></tr></table></figure></div><h3 id="Result">Result</h3><p>I didn’t processing the Juicer successfully yet. It was always exit at post data processing. I get the aligned result successfully. But it seems like failed to find the loop and get the <code>apa_resutls</code>.</p><p>So, according to the ChatGPT4o, we expected to get the results below after juicer:</p><ol><li>Contact Maps: These are heatmap-like visualizations showing the frequency of interactions between different regions of the genome.</li><li>.hic Files: The primary output format of Juicer, .hic files contain the processed Hi-C data, which can be visualized using tools like Juicebox.</li><li>Statistics and Quality Metrics; Genome-Wide Interaction Profiles; Contact Frequency Plots; and Visualizations in Juicebox</li></ol><p>In the <code>aligned</code> directory, we got 2 <code>.hic</code> file, one is <code>inter_30.hic</code>, another is <code>inter.hic</code>. According to ChatGPT4o, <code>inter.hic</code> typically contains the raw or minimally processed interaction data. <code>inter_30.hic</code> contains interaction data that has been <strong>normalized</strong> and possibly <strong>filtered</strong> to remove noise and low-quality interactions. The “30” in the name usually refers to a specific bin size (e.g., 30 kb). And typically, the <code>inter_30.hic</code> file or another similarly named file with a specific bin size (e.g., <code>inter_5.hic</code>, <code>inter_10.hic</code>) is considered the final, high-quality result suitable for detailed analysis.</p><h2 id="Troubleshooting">Troubleshooting</h2><pre>HiCCUPS:GPUs are not installed so HiCCUPs cannot be run(-: Postprocessing successfully completed, maps too sparse to annotate or GPUs unavailable (-:***! Error! Either inter.hic or inter_30.hic were not createdEither inter.hic or inter_30.hic were not created.  Check  for results</pre><p>Check if cuda is installed appropriate. If so, Check if it is in your working environment.</p><p>How to add it in your working environment: (edit your <code>~/.bashrc</code> or <code>~/.zshrc</code> file)</p><pre>export PATH="/usr/local/cuda-8.0/bin:$PATH"export LD_LIBRARY_PATH="/usr/local/cuda-8.0/lib64:$LD_LIBRARY_PATH"</pre><p>Or you could add the <code>--cpu</code> flag on file <code>scripts/common/juicer_postprocessing.sh</code></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="DIFF"><figure class="iseeu highlight /diff"><table><tr><td class="code"><pre><code class="hljs diff"><span class="hljs-deletion">- if hash nvcc 2&gt;/dev/null</span><br><span class="hljs-deletion">- then</span><br><span class="hljs-deletion">-    $&#123;juicer_tools_path&#125; hiccups $&#123;hic_file_path&#125; $&#123;hic_file_path%.*&#125;&quot;_loops&quot;</span><br><span class="hljs-addition">+    $&#123;juicer_tools_path&#125; hiccups --cpu $&#123;hic_file_path&#125; $&#123;hic_file_path%.*&#125;&quot;_loops&quot;</span><br><span class="hljs-deletion">-    if [ $? -ne 0 ]; then</span><br><span class="hljs-deletion">-echo &quot;***! Problem while running HiCCUPS&quot;;</span><br><span class="hljs-deletion">-exit 1</span><br><span class="hljs-deletion">-    fi</span><br><span class="hljs-deletion">-else</span><br><span class="hljs-deletion">-    echo &quot;GPUs are not installed so HiCCUPs cannot be run&quot;;</span><br><span class="hljs-deletion">-fi</span><br></code></pre></td></tr></table></figure></div><p>When the <code>if hash nvcc 2&gt;/dev/null</code> detected that the <code>nvcc</code> doesn’t in the environment, it would exit. So, you may like to delete the entail if statement.</p><pre>HiCCUPS:Picked up _JAVA_OPTIONS: -Xmx150000m -Xms150000mReading file: /home/wenkanl2/Tomas/20240614_DuckGenome/myJuicerDir/aligned/inter_30.hicNo valid configurations specified, using default settingsWarning Hi-C map is too sparse to find many loops via HiCCUPS.Exiting. To disable sparsity check, use the --ignore_sparsity flag.</pre><p>As it suggests, you need to add the <code>--ignore_sparsity</code> flag. But, again, you can only make this change by alter <code>scripts/common/juicer_postprocessing.sh</code></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="DIFF"><figure class="iseeu highlight /diff"><table><tr><td class="code"><pre><code class="hljs diff">if hash nvcc 2&gt;/dev/null<br>then<br><span class="hljs-deletion">-    $&#123;juicer_tools_path&#125; hiccups $&#123;hic_file_path&#125; $&#123;hic_file_path%.*&#125;&quot;_loops&quot;</span><br><span class="hljs-addition">+    $&#123;juicer_tools_path&#125; hiccups  --ignore_sparsity $&#123;hic_file_path&#125; $&#123;hic_file_path%.*&#125;&quot;_loops&quot;</span><br>    if [ $? -ne 0 ]; then<br>echo &quot;***! Problem while running HiCCUPS&quot;;<br>exit 1<br>    fi<br>else<br>    echo &quot;GPUs are not installed so HiCCUPs cannot be run&quot;;<br>fi<br></code></pre></td></tr></table></figure></div><p>0 loops</p><pre>100% 0 loops written to file: ...HiCCUPS complete</pre><p>According to this <a href="https://groups.google.com/g/3d-genomics/c/9f5UUhuS8O4/m/RTE1YVTKAgAJ">post answer by Neva Durand</a>, it could be the data is too sparse.</p><blockquote><p>Yes, it’s an order of magnitude too few reads to find loops. You need to do deeper sequencing  / more replicates and then combine them. You need at least 1 billion reads. Otherwise your experiments simply don’t have the depth to determine loops (with any algorithm).</p></blockquote><pre>Not including fragment mapError while reading graphs file: java.io.FileNotFoundException: /home/wenkanl2/Tomas/20240614_DuckGenome/myJuicerDir/aligned/inter_30_hists.m (No such file or directory)Start preprocessWriting headerWriting bodyjava.lang.RuntimeException: No reads in Hi-C contact matrices. This could be because the MAPQ filter is set too high (-q) or because all reads map to the same fragment.at juicebox.tools.utils.original.Preprocessor$MatrixZoomDataPP.mergeAndWriteBlocks(Preprocessor.java:1650)at juicebox.tools.utils.original.Preprocessor$MatrixZoomDataPP.access$000(Preprocessor.java:1419)at juicebox.tools.utils.original.Preprocessor.writeMatrix(Preprocessor.java:832)at juicebox.tools.utils.original.Preprocessor.writeBody(Preprocessor.java:582)at juicebox.tools.utils.original.Preprocessor.preprocess(Preprocessor.java:346)at juicebox.tools.clt.old.PreProcessing.run(PreProcessing.java:116)at juicebox.tools.HiCTools.main(HiCTools.java:96)real2m7.365suser0m33.647ssys0m49.450sPicked up _JAVA_OPTIONS: -Xmx150000m -Xms150000mError reading datasetnulljava.io.EOFExceptionat htsjdk.tribble.util.LittleEndianInputStream.readFully(LittleEndianInputStream.java:138)at htsjdk.tribble.util.LittleEndianInputStream.readLong(LittleEndianInputStream.java:80)at htsjdk.tribble.util.LittleEndianInputStream.readDouble(LittleEndianInputStream.java:100)at juicebox.data.DatasetReaderV2.readFooter(DatasetReaderV2.java:470)at juicebox.data.DatasetReaderV2.read(DatasetReaderV2.java:235)at juicebox.tools.utils.original.NormalizationVectorUpdater.updateHicFile(NormalizationVectorUpdater.java:78)at juicebox.tools.clt.old.AddNorm.run(AddNorm.java:84)at juicebox.tools.HiCTools.main(HiCTools.java:96)real0m0.706suser0m1.229ssys0m0.399s/home/wenkanl2/Tomas/20240614_DuckGenome/myJuicerDir/scripts/common/juicer_postprocessing.sh: option requires an argument -- gUsage: /home/wenkanl2/Tomas/20240614_DuckGenome/myJuicerDir/scripts/common/juicer_postprocessing.sh [-h] -j <juicer_tools_file_path> -i <hic_file_path> -m <bed_file_dir> -g <genome ID>***! Error! Either inter.hic or inter_30.hic were not createdEither inter.hic or inter_30.hic were not created.  Check  for results</pre><h2 id="Other-Pipelines-for-Hi-C-Data">Other Pipelines for Hi-C Data</h2><p><img src="https://s3.amazonaws.com/4dn-dcic-public/static-pages/hicpipeline.png" alt="© 4dn"></p><ul><li><a href="https://data.4dnucleome.org/resources/data-analysis/hi_c-processing-pipeline">Hi-C Processing Pipeline</a></li><li><a href="https://genomebiology.biomedcentral.com/articles/10.1186/s13059-015-0831-x">HiC-Pro: an optimized and flexible pipeline for Hi-C data processing</a></li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4706059/">HiCUP: pipeline for mapping and processing Hi-C data</a></li><li><a href="https://www.bioinformatics.babraham.ac.uk/projects/hicup/">Babraham Bioinformatics: HiCUP (Hi-C User Pipeline)</a></li><li><a href="https://www.encodeproject.org/hic/">HiC Data Standards and Processing Pipeline</a></li><li><a href="https://nf-co.re/hic/2.1.0">nf-core/hic</a></li></ul><style>pre {  background-color:#38393d;  color: #5fd381;}test {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Juicer: a One-Click System for Analyzing Loop-Resolution Hi-C Experiments</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="WGS" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/WGS/"/>
    
    
    <category term="Software" scheme="https://karobben.github.io/tags/Software/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="NGS" scheme="https://karobben.github.io/tags/NGS/"/>
    
    <category term="Genome" scheme="https://karobben.github.io/tags/Genome/"/>
    
    <category term="WGS" scheme="https://karobben.github.io/tags/WGS/"/>
    
  </entry>
  
  <entry>
    <title>NextDenovo: an efficient error correction and accurate assembly tool for noisy long reads</title>
    <link href="https://karobben.github.io/2024/06/26/Bioinfor/NextDenovo/"/>
    <id>https://karobben.github.io/2024/06/26/Bioinfor/NextDenovo/</id>
    <published>2024-06-26T16:11:48.000Z</published>
    <updated>2024-06-30T21:16:55.880Z</updated>
    
    <content type="html"><![CDATA[<ul><li><a href="https://nextdenovo.readthedocs.io/en/latest/QSTART.html#quick-start">Quick Start</a></li><li><a href="https://nextdenovo.readthedocs.io/en/latest/TEST1.html">Tutorial</a></li><li>Other related Long reads Assembly Tools, check the end of the post, for example: Falcon (Chin et al. 2016), Canu (Koren et al. 2017), WTDBG2 (Ruan and Li 2020), or Flye (Kolmogorov et al. 2019)</li></ul><h2 id="NextDenovo">NextDenovo</h2><p>Paper: <a href="https://genomebiology.biomedcentral.com/articles/10.1186/s13059-024-03252-4">Hu J, Wang Z, Sun Z, et al. NextDenovo: an efficient error correction and accurate assembly tool for noisy long reads[J]. Genome Biology, 2024, 25(1): 107.</a></p><h3 id="Background">Background</h3><ul><li>Third-generation long-read:<br>PacBio has high-fidelity (HiFi) reads but they are relatively short (~ 15 kb). So, it is unable to span long tandem or highly homologous multi-copy repeats like centromeres. ONT sequencing can generate &gt; 100-kb “ultra-long” reads.</li><li>CTA and ATC:<br>“correction then assembly” (CTA, an assembler first corrects errors in the reads and then uses the corrected reads for assembly) and “assembly then correction” (ATC, an assembler uses error-prone reads to assemble the genome and then corrects errors in the assembled genome) are commonly used in assembly. CTA is much slower. But in terms of the assembly of segmental duplications/repeats, and especially for large plant genome assemblies, the CTA-based strategy usually has an enhanced ability to distinguish different gene copies and produce more accurate and continuous assemblies. <mark>NextDenovo is the tool of CTA-based assembly tool</mark></li></ul><h3 id="Steps">Steps</h3><ol><li><p>Detecting Overlapping Reads</p><ul><li><strong>Initial Detection</strong>: Detects overlapping reads (Fig. 1A).</li><li><strong>Filtering</strong>: Filters out alignments caused by repeats.</li><li><strong>Splitting</strong>: Splits chimeric seeds based on overlapping depth (Fig. 1B).</li></ul></li><li><p>Rough Correction with KSC Algorithm</p><ul><li><strong>Algorithm Used</strong>: Kmer score chain (KSC) algorithm, used in NextPolish [19], for initial rough correction (Fig. 1C).</li></ul></li><li><p>Handling Repeated Regions</p><ul><li><strong>Detection of Low-Score Regions (LSRs)</strong>: Uses a heuristic algorithm during traceback within the KSC algorithm.</li><li><strong>Accurate Correction</strong>:<ul><li>Combines partial order alignment (POA) [20] and KSC.</li><li>Collects subsections spanning LSRs and generates kmer sets at flanking sequences.</li><li>Filters subsections with lower kmer scores.</li><li>Creates pseudo-LSR seeds from top-ranked subsections using a greedy POA consensus algorithm.</li><li>Maps and corrects pseudo-LSR seeds multiple times for accuracy.</li><li>Integrates corrected LSRs back into the primary corrected seed (Fig. 1D).</li></ul></li></ul></li><li><p>Pairwise Overlapping and Dovetail Alignments</p><ul><li><strong>Two Rounds of Overlapping</strong>:<ul><li><strong>First Round</strong>: Uses rapid detection parameters.</li><li><strong>Second Round</strong>: Applies rigorous parameters for accurate alignments.</li></ul></li><li><strong>Graph Construction</strong>:<ul><li>Constructs a directed string graph.</li><li>Removes transitive edges using the “best overlap graph” (BOG) algorithm.</li><li>For repeat nodes, edges are only removed if below specific thresholds to maintain connectivity.</li><li>Removes tips and resolves bubbles.</li></ul></li></ul></li><li><p>Progressive Graph Cleaning</p><ul><li><strong>Simplifying Subgraphs</strong>:<ul><li>Uses a progressive cleaning strategy with increasingly stringent thresholds.</li><li>Breaks paths at nodes with multiple connections.</li><li>Outputs contigs from broken linear paths.</li></ul></li><li><strong>Reducing Misassemblies</strong>:<ul><li>Maps all seeds to contigs.</li><li>Breaks contigs at lower mapping depth regions (LDRs) (Fig. 1E).</li></ul></li></ul></li></ol><h3 id="Key-Algorithms-and-Techniques">Key Algorithms and Techniques</h3><ul><li><strong>KSC Algorithm</strong>: Used for initial rough correction and handling LSRs.</li><li><strong>Heuristic and Accurate Algorithms</strong>: For detecting and correcting LSRs.</li><li><strong>BOG Algorithm</strong>: For removing transitive edges in the graph.</li></ul><h2 id="Error-Correction">Error Correction</h2><p>NextDenovo is 1.63 times faster on real data compared to Consent, Canu, and Necat. As the read length increases, the time required for correction also increases. However, NextDenovo and Necat demonstrated only slight increases, while Canu exhibited a significant increase in processing time</p><h2 id="Installation">Installation</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Prerequirement</span><br>pip install paralleltask<br><br><span class="hljs-comment"># Install from github </span><br>git <span class="hljs-built_in">clone</span> git@github.com:Nextomics/NextDenovo.git<br><span class="hljs-built_in">cd</span> NextDenovo &amp;&amp; make<br><br><span class="hljs-comment"># Test</span><br>nextDenovo test_data/run.cfg<br></code></pre></td></tr></table></figure></div><h2 id="Run">Run</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">nextDenovo run.cfg<br></code></pre></td></tr></table></figure></div><p>Example of <code>run.cfg</code></p><pre>[General]job_type = local job_prefix = nextDenovotask = allrewrite = yesdeltmp = yesparallel_jobs = 22input_type = rawread_type = ont # clr, ont, hifiinput_fofn = input.fofninput_fofn2 = input2.fofnworkdir = HG002_NA24385_son_assemble[correct_option]read_cutoff = 1kgenome_size = 3g # estimated genome sizesort_options = -m 50g -t 30minimap2_options_raw = -t 8pa_correction = 5correction_options = -p 30[assemble_option]minimap2_options_cns = -t 8nextgraph_options = -a 1</pre><h2 id="Result">Result</h2><ul><li>Sequence: <code>01_rundir/03.ctg_graph/nd.asm.fasta</code></li><li>Statistics: <code>01_rundir/03.ctg_graph/nd.asm.fasta.stat</code></li></ul><p>Assembly data: 109G+98G<br>RAM utility: about 400GB. (You can also make it run with 64 RAM but it would takes much loger time to finish)<br>Time: about 2 days.</p><h2 id="After-Assembly">After Assembly</h2><h3 id="Compare-the-result-from-the-SKLA1-0-by-MUMmer">Compare the result from the SKLA1.0 by MUMmer</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">~/software/mummer-4.0.0rc1/mummer  -l 200 -threads 30 -qthreads 30  -mum -b -c data/NextDenovo_result.fa  data/SKLA1.0.chrall.fa &gt; result/NextDenovo_SKLA1.0.mums<br></code></pre></td></tr></table></figure></div><p><img src="https://imgur.com/nsV3ADI.png" alt="mummer"></p><p>According to this result, the first three chromosomes from bottom to top are chr1, chr2, and chr3. The x-axis, from left to right, is sorted by the length of the contigs. As we can see, the first contig represents the full length of chr3. Contigs 2, 3, and 7 represent chr1, while contigs 6, 8, and 9 are three pieces of chr2. Another very interesting result is that, except for chr2, both chr1 and chr3 are complemented and reversed.</p><h2 id="NextPolish">NextPolish</h2><p>NextPolish was also recomand. You can download and install by following the instruction form <a href="https://github.com/Nextomics/NextPolish">github</a>. But I am not that luck to install it in my Ubuntu server. It come with the error:</p><pre>gcc -g -Wall -Wno-unused-function -O2 -DHAVE_PTHREAD -DUSE_MALLOC_WRAPPERS bwashm.o bwase.o bwaseqio.o bwtgap.o bwtaln.o bamlite.o bwape.o kopen.o pemerge.o maxk.o bwtsw2_core.o bwtsw2_main.o bwtsw2_aux.o bwt_lite.o bwtsw2_chain.o fastmap.o bwtsw2_pair.o main.o -o bwa -L. -lbwa -lm -lz -lpthread -lrt/usr/bin/ld: ./libbwa.a(rope.o):/raid/home/wenkanl2/BioTools/NextPolish/util/bwa/rle.h:33: multiple definition of `rle_auxtab'; ./libbwa.a(bwtindex.o):/raid/home/wenkanl2/BioTools/NextPolish/util/bwa/rle.h:33: first defined here/usr/bin/ld: ./libbwa.a(rle.o):/raid/home/wenkanl2/BioTools/NextPolish/util/bwa/rle.h:33: multiple definition of `rle_auxtab'; ./libbwa.a(bwtindex.o):/raid/home/wenkanl2/BioTools/NextPolish/util/bwa/rle.h:33: first defined herecollect2: error: ld returned 1 exit statusmake[2]: *** [Makefile:30: bwa] Error 1make[2]: Leaving directory '/raid/home/wenkanl2/BioTools/NextPolish/util/bwa'make[1]: *** [Makefile:19: bwa_] Error 2make[1]: Leaving directory '/raid/home/wenkanl2/BioTools/NextPolish/util'make: *** [Makefile:18: all] Error 2</pre><p>So, I tied install it with bioconda:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">conda install NextPolish<br></code></pre></td></tr></table></figure></div><pre>nextpolish-1.4.1           |  py311h99925d8_3         1.7 MB  bioconda</pre><p>And them, it installed the version 1.4.1. Next, I tried the test: <code>nextPolish test_data/run.cfg</code> and it finished the test correctly:</p><pre>Type           Length (bp)            Count (#)N10                60501                   1N20                60501                   1N30                60501                   1N40                60501                   1N50                60501                   1N60                51048                   2N70                51048                   2N80                51048                   2N90                51048                   2Min.               51048                   -Max.               60501                   -Ave.               55774                   -Total             111549                   2</pre><h3 id="Options-for-NextPolish">Options for NextPolish</h3><p>[sgs_option]: Polishing using short reads only<br>[lgs_option]: Polishing using long reads only</p><h3 id="In-Action">In Action:</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># prepare the short reads information</span><br>ls data/WGS/*.fastq &gt; sgs.fofn<br><span class="hljs-comment"># Start running</span><br>nohup nextPolish Polish.cfg &gt; Polish.log &amp;<br></code></pre></td></tr></table></figure></div><p>cfg file for this experiment:</p><pre>[General]job_type = localjob_prefix = nextPolishtask = defaultrewrite = yesrerun = 3parallel_jobs = 20multithread_jobs = 20genome = result/NextDenovo_result.fagenome_size = autoworkdir = ./01_rundirpolish_options = -p {multithread_jobs}[sgs_option]sgs_fofn = ./sgs.fofnsgs_options = -max_depth 100</pre><p>In this config file, it given the number of parallel jobs as 20 and multithread jobs as 20, which means the max threads allocated would be 20*20 = 400. So,be sure about that you have that much of threads for calculation or it would make the whole processes slower than normal.</p><h2 id="Other-Long-Reads-Assembly-Tools">Other Long-Reads Assembly Tools</h2><h3 id="LongStitch-Enhancing-Genome-Assembly-with-Long-Reads">LongStitch: Enhancing Genome Assembly with Long Reads</h3><p>LongStitch<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup> is a powerful computational tool designed to improve the quality of genome assemblies by utilizing long-read sequencing data. It addresses common issues in genome assembly, such as errors and gaps, that are often introduced during the assembly of short-read sequences.</p><p>It was published at 2021. Until the July 2024, it got 34 citations. It is an open source software and deposit in <a href="https://github.com/bcgsc/longstitch">GitHub</a> with 42 starts.</p><p>Key features of LongStitch include:</p><ul><li><strong>Error Correction</strong>: By aligning long reads to the existing genome assembly, LongStitch identifies and corrects misassemblies, leading to a more accurate genomic representation.</li><li><strong>Scaffolding</strong>: LongStitch leverages long reads to link contigs into scaffolds, significantly enhancing the continuity and completeness of the genome assembly.</li><li><strong>High-Quality Output</strong>: The resulting assemblies are more comprehensive and accurate, making them invaluable for further genomic analysis and research.</li></ul><p>LongStitch’s ability to handle repetitive regions and complex genomic structures makes it an essential tool for researchers aiming to achieve high-quality genome assemblies.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>Coombe L, Li J X, Lo T, et al. LongStitch: high-quality genome assembly correction and scaffolding using long reads[J]. BMC bioinformatics, 2021, 22: 1-13. <a href="#fnref1" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">NextDenovo is a string graph-based de novo assembler for long reads (CLR, HiFi and ONT)</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Software" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Software/"/>
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="NGS" scheme="https://karobben.github.io/tags/NGS/"/>
    
    <category term="Genome" scheme="https://karobben.github.io/tags/Genome/"/>
    
    <category term="WGS" scheme="https://karobben.github.io/tags/WGS/"/>
    
  </entry>
  
  <entry>
    <title>IgCaller</title>
    <link href="https://karobben.github.io/2024/06/24/Bioinfor/IgCaller/"/>
    <id>https://karobben.github.io/2024/06/24/Bioinfor/IgCaller/</id>
    <published>2024-06-24T21:45:27.000Z</published>
    <updated>2024-06-25T17:34:50.131Z</updated>
    
    <content type="html"><![CDATA[<p>IgCaller is used extensively in immunology research to study B-cell receptor diversity and antibody generation mechanisms. Clinically, it helps identify clonal B-cell expansions, monitor minimal residual disease in leukemias and lymphomas, and analyze antibody responses to vaccines. Additionally, it supports therapeutic antibody development by identifying candidate antibodies from strong immune responses.</p><p>It is an <a href="https://github.com/ferrannadeu/IgCaller">open-source</a> tool designed to study human B cell Ig gene rearrangements. According to the documentation, it only supports the human hg19 or hg38 genome as the input reference, so the application of this tool is limited to humans. It requires selecting specific areas of the genome.</p><p>I am currently working on nonhuman Ig. I may update with more details later when I work with human Ig.</p><p>The basic use only requires the short reads aligned BAM file:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">IgCaller -I /path/to/IgCaller/IgCaller_reference_files/ -V hg19 -C ensembl -T /path/to/bams/tumor.bam -N /path/to/bams/normal.bam -R /path/to/reference/genome_hg19.fa -o /path/to/IgCaller/outputs/<br></code></pre></td></tr></table></figure></div><ul><li>Output: IgCaller returns a set of tab-separated files:<ul><li>tumor_sample_output_filtered.tsv: High confidence rearrangements passing the defined filters.</li><li>tumor_sample_output_IGH.tsv: File containing all IGH rearrangements.</li><li>tumor_sample_output_IGK.tsv: File containing all IGK rearrangements.</li><li>tumor_sample_output_IGL.tsv: File containing all IGL rearrangements.</li><li>tumor_sample_output_class_switch.tsv: File containing all CSR rearrangements.</li><li>tumor_sample_output_oncogenic_IG_rearrangements.tsv: File containing all oncogenic IG rearrangements (translocations, deletions, inversions, and gains) identified genome-wide.</li></ul></li></ul><p>More details:<br>Nadeu, F., Mas-de-les-Valls, R., Navarro, A. et al. IgCaller for reconstructing immunoglobulin gene rearrangements and oncogenic translocations from whole-genome sequencing in lymphoid neoplasms. Nature Communications 11, 3390 (2020). <a href="https://doi.org/10.1038/s41467-020-17095-7">https://doi.org/10.1038/s41467-020-17095-7</a>.</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Reconstructing immunoglobulin gene rearrangements and oncogenic translocations from WGS, WES, and capture NGS data</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Software" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Software/"/>
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="NGS" scheme="https://karobben.github.io/tags/NGS/"/>
    
    <category term="Genome" scheme="https://karobben.github.io/tags/Genome/"/>
    
    <category term="Antibody" scheme="https://karobben.github.io/tags/Antibody/"/>
    
    <category term="Immunology" scheme="https://karobben.github.io/tags/Immunology/"/>
    
  </entry>
  
  <entry>
    <title>MUMmer: Rapidly Genomes Alignment</title>
    <link href="https://karobben.github.io/2024/06/21/Bioinfor/MUMmer/"/>
    <id>https://karobben.github.io/2024/06/21/Bioinfor/MUMmer/</id>
    <published>2024-06-21T23:29:31.000Z</published>
    <updated>2024-06-24T21:55:49.415Z</updated>
    
    <content type="html"><![CDATA[<p>Installation:</p><p>In linux, you could simply install it by apt install mummer. The version of the mummer is around 3.1. The version from Bioconda is little bit new than the apt source but still kind of old. If you install teh MUMmer from those 2 source, you’ll meet error when the reads is too long.</p><h2 id="NUCmer">NUCmer:</h2><p>Test target: Chicken Genome (GRCg6a) and Duck Genome (SKLA1.0)<br>It could be RAM monster when you compare 2 Genome directly. Especially when you want to use the multiple threads, the RAM would be occupied very quick and the program would be killed.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">nucmer -maxmatch -c 100 -p output_prefix reference.fasta query.fasta<br>show-coords -rcl output_prefix.delta &gt; output_prefix.coords<br>cat output_prefix.coords<br>grep -Ev <span class="hljs-string">&quot;^$|=|\[&quot;</span> result/test.coords| grep <span class="hljs-string">&quot;^ &quot;</span>| awk <span class="hljs-string">&#x27;BEGIN &#123; OFS=&quot;\t&quot;; print &quot;Ref_Start&quot;, &quot;Ref_End&quot;, &quot;Query_Start&quot;, &quot;Query_End&quot;, &quot;Length1&quot;, &quot;Length2&quot;, &quot;Identity&quot;, &quot;Ref&quot;, &quot;Query&quot; &#125; &#123;OFS=&quot;\t&quot;;  print $1, $2, $4, $5, $7, $8, $10, $12, $13&#125;&#x27;</span> &gt; test.coords<br><br></code></pre></td></tr></table></figure></div><p>But the problem is there are no such parameter for NUCmer to limited the use of RAM. The only way to solving this problem is split the genome into single sequences and processing one by one.</p><pre>[1]    70706 killed     nucmer --maxmatch -c 100 -p result/Chicken-SKLA1.0</pre><p><img src="https://imgur.com/iXM6Kr2.png" alt="btop"></p><p>I was tried to extract the first chromosome (196,202,544 bp, 192M) from the Chicken align against the Duck genome (1.2 Gb) and it takes 41 GB RAM if you given only 1 thread. If you run it without given threads, it would run with 3 threads and the RAM would increased into 70 GB. So, it seams it is save to run with about 7 threads with this size of data. But after 1h 12min, it was killed because of the increased demand of RAM. If you use single thread, the RAM would increased in to 77 after about 1h and 12min. Finally, it takes 13h 3m.</p><h3 id="MUMmer">MUMmer</h3><p>MUMmer is focusing on the difference between the reference and the Subject. It output is very sample. It only contains the start, end, and the length of the reference. Based on this, we could know that they are forward or reverse-complemented. It doesn’t has the responded position for Subject chromosome. So, because of the low dimension information, it requires very low RAM and works very efficient. It could finishing calculation in a very short time.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">mummer -mum -b -c ref.fa sub.fa  &gt; ref.mums<br>mummerplot --postscript --prefix=ref_qry ref.mums<br>gnuplot ref_qry.gp<br></code></pre></td></tr></table></figure></div><p>For visualization, you could use the package provide tools. You could also convert it into tables and visualize it with your favorite tools. So, after convert the mummer result into <code>tsv</code> by a python script, we could visualize the result with ggplot.</p><p><img src="https://imgur.com/KcnMXqg.png" alt="mummer plots"></p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">MUMmer is a system for rapidly aligning entire genomes</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Software" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Software/"/>
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="NGS" scheme="https://karobben.github.io/tags/NGS/"/>
    
    <category term="Genome" scheme="https://karobben.github.io/tags/Genome/"/>
    
    <category term="WGS" scheme="https://karobben.github.io/tags/WGS/"/>
    
  </entry>
  
  <entry>
    <title>Whole Genome Sequencing (WGS)</title>
    <link href="https://karobben.github.io/2024/06/17/Bioinfor/wholegenomesequencing/"/>
    <id>https://karobben.github.io/2024/06/17/Bioinfor/wholegenomesequencing/</id>
    <published>2024-06-17T20:34:03.000Z</published>
    <updated>2024-07-04T05:36:59.789Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Whole-Genome-Sequencing-WGS">Whole Genome Sequencing (WGS)</h2><blockquote><p>Whole-genome sequencing (WGS) is a comprehensive method for analyzing entire genomes. Genomic information has been instrumental in identifying inherited disorders, characterizing the mutations that drive cancer progression, and tracking disease outbreaks. Rapidly dropping sequencing costs and the ability to produce large volumes of data with today’s sequencers make whole-genome sequencing a powerful tool for genomics research. (<a href="https://www.illumina.com/techniques/sequencing/dna-sequencing/whole-genome-sequencing.html">Illumina</a>)</p></blockquote><h2 id="Illumina-WGS">Illumina WGS</h2><p>KEY WHOLE-GENOME SEQUENCING METHODS</p><ul><li>Large whole-genome sequencing</li><li>Small whole-genome sequencing</li><li>De novo sequencing<ul><li>Targeting to species without reference genome</li></ul></li><li>Phased sequencing</li><li>Human whole-genome sequencing<ul><li>optimized for human</li></ul></li><li>Long-reads sequencing</li></ul><h2 id="Examples-from-Publications">Examples from Publications</h2><h3 id="SKLA1-0-Duck">SKLA1.0 (Duck)</h3><table><thead><tr><th style="text-align:left"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:left">A chromosome-scale Beijing duck assembly (SKLA1.0<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>) by integrating Nanopore, Bionano, and Hi-C data covers 40 chromosomes, improves the contig N50 of the previous duck assembly with highest contiguity (ZJU1.0) of more than a 5.79-fold and contains a complete genomic map of the MHC.</td><td style="text-align:center"><img src="https://www.researchgate.net/profile/Inma-Aznar/publication/51580858/figure/fig19/AS:669632922923023@1536664338755/Mallard-Anas-platyrhynchos-Photo-John-Carey.png" alt="Duck"><a href="https://www.researchgate.net/publication/51580858_A_review_of_Ireland's_waterbirds_with_emphasis_on_wintering_migrants_and_reference_to_H5N1_avian_influenza?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6Il9kaXJlY3QiLCJwYWdlIjoiX2RpcmVjdCJ9fQ">© Olivia Crowe</a></td></tr></tbody></table><p>Species: Anas platyrhynchos (a native breed in China, using a hierarchical and hybrid approach)</p><p>Reads types: Nanopore, Bionano, and Hi-C data.</p><ul><li>71-fold normal and 24-fold ultra-long Nanopore reads</li><li>117-fold 150bp paired-end Illumina reads for polishing</li><li>216-fold optical map reads and 234-fold PE150 Hi-C</li></ul><p>Result:</p><ul><li>40 chromosomes, improves the contig N50 of the previous duck assembly with highest contiguity (ZJU1.0) of more than a 5.79-fold</li><li>a complete genomic map of the MHC</li></ul><p>Solved challenges:</p><ul><li>traditional assembly tools have not enabled proper genomic draft of highly repetitive and GC-rich sequences, such as the MHC</li></ul><p>Something I don’t understand:</p><ul><li>C18 Duck?</li><li>heterozygosity estimation: why they do it? How could it help on the genome assembly?</li><li>What is BUSCO score?</li></ul><h4 id="Steps-for-Genome-assembly">Steps for Genome assembly:</h4><ol><li><strong>Estimate Genome Heterozygosity</strong><ul><li>Before starting the assembly, the genome heterozygosity of the C18 duck was estimated. The heterozygosity was found to be as low as 0.58% (Additional file 1: Table S1 and Additional file 2: Fig. S1-S3).</li></ul></li><li><strong>Assemble Genome with <mark>Nanopore Reads</mark></strong><ul><li>Using 71-fold normal and 24-fold ultra-long Nanopore reads, the duck genome was assembled into 151 contigs covering a total length of 1.22 Gb with a contig N50 of 32.81 Mb (Additional file 1: Table S2-S3).</li><li><a href="https://github.com/Nextomics/NextDenovo"><strong>NextDenovo</strong></a>: Clean and assembly</li></ul></li><li><strong>Polish Contigs with <mark>Illumina Reads</mark></strong><ul><li>The 151 contigs were then polished with 912 million 150-bp Illumina pair-end reads, corrected, and integrated with high-quality optical maps (Additional file 1: Table S4-S5). This effort generated 69 scaffolds with a scaffold N50 of 72.53 Mb (Additional file 1: Table S6).</li><li><strong>Nextpolish-1.2.3</strong><sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>: polished three rounds</li></ul></li><li><strong>Use <mark>Hi-C Data</mark> for Scaffold Ordering</strong><ul><li>A total of 274 Gb PE150 Hi-C data was used to order and orient the duck scaffolds, correct mis-joined sections, and merge overlaps, resulting in 40 super-scaffolds (Additional file 1: Table S7).</li><li><strong>Trimmomatic-0.36</strong><sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>; <strong>Juicer software-1.5</strong><sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>; <strong>3d-DNA package-180922</strong><sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup>; <strong>Juicebox-1.13.01</strong><sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup></li></ul></li><li><strong>Perform Gap Filling</strong><ul><li>Gap filling was performed using 95-fold corrected Nanopore reads to remove gaps, generating the final duck assembly (SKLA1.0), representing 1.16 Gb of the genomic sequence, approximately 99.11% of the estimated genome size (Table 1).</li><li><strong>Gapcloser-0.56</strong><sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup></li></ul></li><li><strong>Chromosome Coverage and Comparison</strong><ul><li>Since the duck contains 80 chromosomes (diploid, 2n=80), it was inferred that this duck assembly had covered all chromosomes except W (Additional file 1: Table S8). The SKLA1.0 assembly was compared with the previous duck BGI_duck_1.0 assembly, the ZJU1.0 assembly, and two high-quality avian reference genomes (chicken GRCg6a and zebra finch bTaeGut1.4.pri). These analyses indicated that the SKLA1.0 assembly represents a major improvement over the previous assemblies in terms of contiguity, completeness, and chromosome size. The contiguity and completeness of SKLA1.0 is also higher than that of the zebra finch bTaeGut1.4.pri and the chicken GRCg6a (Fig. 1a–d and Table 1).</li></ul></li></ol><h4 id="After-Assembly">After Assembly</h4><ul><li>Funannotate pipeline and the <strong>GETA pipeline</strong> together with a manual curation of key gene families: 17,896 duck coding genes. Quality was validated by number of coding genes, # of transcripts, # of gaps, and <strong>BUSCO</strong> score.</li><li>Visualization: Bionano map-<a href="https://bionanogenomics.com/support/software-downloads">SOLVE</a></li></ul><h3 id="ASM2904224v1-Greater-scaup-Aythya-marila">ASM2904224v1: Greater scaup (Aythya marila)</h3><table><thead><tr><th style="text-align:left"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:left">First high-quality chromosome-level genome assembly of A. marila<sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup>, with a final genome size of 1.14 Gb, scaffold N50 of 85.44 Mb, and contig N50 of 32.46 Mb. A total of 154.94 Mb of repetitive sequences were identified. 15,953 protein-coding genes were predicted in the genome, and 98.96% of genes were functionally annotated.</td><td style="text-align:center"><img src="https://www.researchgate.net/profile/Inma-Aznar/publication/51580858/figure/fig19/AS:669632922923023@1536664338755/Mallard-Anas-platyrhynchos-Photo-John-Carey.png" alt="Duck"><a href="https://www.researchgate.net/publication/51580858_A_review_of_Ireland's_waterbirds_with_emphasis_on_wintering_migrants_and_reference_to_H5N1_avian_influenza?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6Il9kaXJlY3QiLCJwYWdlIjoiX2RpcmVjdCJ9fQ">© Olivia Crowe</a></td></tr></tbody></table><ol><li><strong>Nanopore long reads</strong>, errors corrected using <strong>Illumina short reads</strong></li><li>Quality: Final size: 1.14 Gb, scaffold N50 of 85.44 Mb, and contig N50 of 32.46 Mb.</li><li>106 contigs were clustered and ordered onto 35 chromosomes based on <strong>Hi-C data</strong>, covering approximately 98.28% of the genome</li><li>BUSCO assessment showed that 97.0% of the highly conserved genes</li></ol><p>Source: muscle tissue of wild male.</p><ul><li>60.77 GB for Illumina HiSeq 4000: Illumina® TruSeq® Nano DNA Library Prep kits to generate sequencing libraries of genomic DNA</li><li>122.55 GB from PromethION platform (91.36 fold of the greater scaup’s genome)</li><li>63.43 Gb for Hi-C data</li></ul><h4 id="Genome-Assembly">Genome Assembly</h4><ol><li><strong>Quality Control</strong>:<ul><li>K = 17, the estimated genome size was 1,341.4 Mb, the heterozygosity was 0.47%, and the proportion of repetitive sequences was 42.28%</li><li>jellyfish (v2.2.7)</li></ul></li><li><strong>Assembly</strong>:<ul><li>assemble the genome with Oxford nanopore technologies (ONT) long reads</li><li>NextDenovo (v2.4.0)</li></ul></li><li><strong>Polish</strong>:<ul><li>increase the precision of single base with Illumina short reads</li><li>NextPolish12 (v1.3.1)<sup class="footnote-ref"><a href="#fn2" id="fnref2:1">[2:1]</a></sup></li></ul></li><li><strong>Scaffold Ordering</strong>:<ul><li>mount the contigs in preliminarily assembly onto chromosomes based on the signal strength after Hi-C data</li><li>ALLHiC (v0.9.8)<sup class="footnote-ref"><a href="#fn9" id="fnref9">[9]</a></sup> and Juicebox (v1.11.08)</li></ul></li></ol><table><thead><tr><th style="text-align:center">HiC Results for the global heat map of all the chromosomes.</th></tr></thead><tbody><tr><td style="text-align:center"><img src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41597-023-02142-x/MediaObjects/41597_2023_2142_Fig1_HTML.png" alt=""></td></tr><tr><td style="text-align:center"><a href="https://www.nature.com/articles/s41597-023-02142-x">© Shengyang Zhou</a></td></tr></tbody></table><h4 id="After-Assembly-v2">After Assembly</h4><ol><li>Assessment<ul><li>Burrows-Wheeler aligner14 (BWA) (v0.7.8) to map Illumina reads to the genome with matching rate was approximately 98.80%.</li><li>Merqury15 (v1.3) was ran to evaluate assembly quality value (QV), and a high QV (42.14)</li><li>Benchmarking Universal Single-Copy Orthologs16 (BUSCO) (v5.4.4) (use option “–augustus”) and Core Eukaryotic Genes Mapping Approach17 (CEGMA) (v2.5) were also used to assess the integrity</li><li>238 of 248 core eukaryotic genes were detected using CEGMA</li></ul></li><li>Comparison<ul><li>Mummer18 (v4.0.0) was used to identify the synteny between A. marila and tufted duck19 (Aythya fuligula) genomes to determine orthologous chromosome pairs, and we used TBtools20 (v1.112) to draw the synteny between their chromosomes.</li></ul></li><li>Annotation of repetitive sequences<ul><li>de novo prediction: Tandem Repeats Finder21 (TRF) (v4.09) to detect tandem repeat sequences</li><li>RepeatModeler (v2.0.3), RepeatScout22 (v1.0.6) and RECON (v1.08) were used to build a database of transposable element (TE)</li><li>RepeatProteinMask and RepeatMasker (v4.1.2-p1) were used for homology prediction with Repbase database23 and Dfam database24, the species parameter used was chicken.</li></ul></li><li>Gene structure prediction<ul><li><strong>Prediction Methods</strong>:<ul><li><strong>Ab Initio Prediction</strong>: Used software Augustus (v3.3.2), GlimmerHMM (v3.0.4), and Geneid (v1.4.5).</li><li><strong>Homology-Based Prediction</strong>: Utilized genomes and annotation files from six related species (Anser cygnoides, Anas platyrhynchos, Aythya fuligula, Cygnus olor, Cygnus atratus, Gallus gallus) downloaded from NCBI.</li><li><strong>RNA-Seq Prediction</strong>: Processed raw data from six transcriptomic samples using fastp (v0.23.1), assembled paired-end reads with SPAdes (v3.15.3), identified candidate coding regions using TransDecoder (v5.5.0), and clustered sequences using CD-hit (v4.8.1).</li></ul></li><li><strong>Integration</strong>:<ul><li><strong>Matching and Splicing</strong>: Protein sequences from related species were matched to the A. marila genome using Spaln (v2.4.6) and accurately spliced with GeneWise (v2.4.1).</li><li><strong>Gene Set Generation</strong>: Combined homology-based, RNA-Seq, and ab initio predictions using EvidenceModeler (EVM) (v1.1.1) and incorporated masked repeats.</li></ul></li></ul></li><li><strong>Databases and Tools</strong>:<ul><li><strong>DIAMOND</strong>: Used for sequence alignment against SwissProt, TrEMBL, NR (Non-Redundant Protein Sequence Database), Gene Ontology (GO), and Kyoto Encyclopedia of Genes and Genomes Orthology (KO) databases, with an e-value cutoff of 1e-5.</li><li><strong>InterPro</strong>: Utilized for classifying proteins into families and predicting domains and important sites using InterProScan (v5.53).</li></ul></li><li>Filtering and Verification of Gene Set for A. marila<ol><li><strong>Ortholog Identification</strong>:<ul><li><strong>OrthoFinder</strong>: Used to identify orthologs among A. marila and six related species.</li><li>Resulted in 4,086 unassigned genes, of which 3,421 were not annotated in any database.</li></ul></li><li><strong>Filtering Process</strong>:<ul><li>Most unannotated genes (3,417/3,421) were predicted by at least one de novo prediction software, with only four supported by other evidence.</li><li>Removal of these unassigned genes did not affect the BUSCO test results, indicating they may not represent real genes.</li></ul></li><li><strong>Final Gene Set</strong>:<ul><li>After filtering out unassigned genes without annotations and 159 prematurely terminated genes, 15,953 genes remained, including 182 partial genes.</li><li>98.96% of the final gene set was annotated.</li></ul></li></ol></li></ol><h3 id="Pig-Sscrofa11-1">Pig Sscrofa11.1</h3><p>Warr A, Affara N, Aken B, et al. An improved pig reference genome sequence to enable pig genetics and genomics research[J]. Gigascience, 2020, 9(6): giaa051.</p><p>TJ Tabasco<br>corrected and assembled using Falcon (v.0.4.0)<br>65-fold coverage (176 Gb) of the genome<br>3,206 contigs with a contig N50 of 14.5 Mb.</p><p>Compare<br>contigs were mapped to the previous draft assembly (Sscrofa10.2) using Nucmer<br>gap closure using PBJelly</p><table><thead><tr><th>Statistic</th><th>Sscrofa10.2</th><th>Sscrofa11</th><th>Sscrofa11.1</th><th>USMARCv1.0</th><th>GRCh38.p13</th></tr></thead><tbody><tr><td>Total sequence length</td><td>2,808,525,991</td><td>2,456,768,445</td><td>2,501,912,388</td><td>2,755,438,182</td><td>3,099,706,404</td></tr><tr><td>Total ungapped length</td><td>2,519,152,092</td><td>2,454,899,091</td><td>2,472,047,747</td><td>2,623,130,238</td><td>2,948,583,725</td></tr><tr><td>No. of scaffolds</td><td>9,906</td><td>626</td><td>706</td><td>14,157</td><td>472</td></tr><tr><td>Gaps between scaffolds</td><td>5,323</td><td>24</td><td>93</td><td>0</td><td>349</td></tr><tr><td>No. of unplaced scaffolds</td><td>4,562</td><td>583</td><td>583</td><td>14,136</td><td>126</td></tr><tr><td>Scaffold N50</td><td>576,008</td><td>88,231,837</td><td>88,231,837</td><td>131,458,098</td><td>67,794,873</td></tr><tr><td>Scaffold L50</td><td>1,303</td><td>9</td><td>9</td><td>9</td><td>16</td></tr><tr><td>No. of unspanned gaps</td><td>5,323</td><td>24</td><td>93</td><td>0</td><td>349</td></tr><tr><td>No. of spanned gaps</td><td>233,116</td><td>79</td><td>413</td><td>661</td><td>526</td></tr><tr><td>No. of contigs</td><td>243,021</td><td>705</td><td>1,118</td><td>14,818</td><td>998</td></tr><tr><td>Contig N50</td><td>69,503</td><td>48,231,277</td><td>48,231,277</td><td>6,372,407</td><td>57,879,411</td></tr><tr><td>Contig L50</td><td>8,632</td><td>15</td><td>15</td><td>104</td><td>18</td></tr><tr><td>No. of chromosomes*</td><td>*21</td><td>19</td><td>*21</td><td>*21</td><td>24</td></tr></tbody></table><p>pig (Sscrofa10.2, Sscrofa11.1, USMARCv1.0), human (GRCh38.p13)</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>Hu J, Song L, Ning M, Niu X, Han M, Gao C, Feng X, Cai H, Li T, Li F, Li H, Gong D, Song W, Liu L, Pu J, Liu J, Smith J, Sun H, Huang Y. A new chromosome-scale duck genome shows a major histocompatibility complex with several expanded multigene families. BMC Biol. 2024 Feb 5;22(1):31. doi: 10.1186/s12915-024-01817-0. PMID: 38317190; PMCID: PMC10845735. <a href="https://bmcbiol.biomedcentral.com/articles/10.1186/s12915-024-01817-0#Sec26">Paper</a> <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>Hu J, Fan JP, Sun ZY, Liu SL. NextPolish: a fast and efficient genome polishing tool for long-read assembly. Bioinformatics. 2020;36:2253–5. <a href="#fnref2" class="footnote-backref">↩︎</a> <a href="#fnref2:1" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>Bolger AM, Lohse M, Usadel B. Trimmomatic: a flexible trimmer for Illumina sequence data. Bioinformatics. 2014;30:2114–20. <a href="#fnref3" class="footnote-backref">↩︎</a></p></li><li id="fn4" class="footnote-item"><p>Durand NC, Shamim MS, Machol I, Rao SSP, Huntley MH, Lander ES, et al. Juicer Provides a One-Click System for Analyzing Loop-Resolution Hi-C Experiments. Cell Syst. 2016;3:95–8. <a href="#fnref4" class="footnote-backref">↩︎</a></p></li><li id="fn5" class="footnote-item"><p>Dudchenko O, Batra SS, Omer AD, Nyquist SK, Hoeger M, Durand NC, et al. De novo assembly of the Aedes aegypti genome using Hi-C yields chromosome-length scaffolds. Science. 2017;356:92–5. <a href="#fnref5" class="footnote-backref">↩︎</a></p></li><li id="fn6" class="footnote-item"><p>Durand NC, Robinson JT, Shamim MS, Machol I, Mesirov JP, Lander ES, et al. Juicebox Provides a Visualization System for Hi-C Contact Maps with Unlimited Zoom. Cell Syst. 2016;3:99–101. <a href="#fnref6" class="footnote-backref">↩︎</a></p></li><li id="fn7" class="footnote-item"><p>Xu MY, Guo LD, Gu SQ, Wang O, Zhang R, Peters BA, et al. TGS-GapCloser: A fast and accurate gap closer for large genomes with low coverage of error-prone long reads. Gigascience. 2020;9:giaa094–104. <a href="#fnref7" class="footnote-backref">↩︎</a></p></li><li id="fn8" class="footnote-item"><p>Zhou S, Xia T, Gao X, et al. A high-quality chromosomal-level genome assembly of Greater Scaup (Aythya marila)[J]. Scientific Data, 2023, 10(1): 254. <a href="#fnref8" class="footnote-backref">↩︎</a></p></li><li id="fn9" class="footnote-item"><p>Zhang, X., Zhang, S., Zhao, Q., Ming, R. &amp; Tang, H. Assembly of allele-aware, chromosomal-scale autopolyploid genomes based on Hi-C data. Nature Plants 5, 833–845 (2019). <a href="#fnref9" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">Whole Genome Sequencing (WGS)</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="WGS" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/WGS/"/>
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="NGS" scheme="https://karobben.github.io/tags/NGS/"/>
    
    <category term="Genome" scheme="https://karobben.github.io/tags/Genome/"/>
    
    <category term="WGS" scheme="https://karobben.github.io/tags/WGS/"/>
    
  </entry>
  
  <entry>
    <title>Simulated Annealing (SA)</title>
    <link href="https://karobben.github.io/2024/05/30/AI/SAnnealing/"/>
    <id>https://karobben.github.io/2024/05/30/AI/SAnnealing/</id>
    <published>2024-05-30T21:34:39.000Z</published>
    <updated>2024-05-30T23:35:08.957Z</updated>
    
    <content type="html"><![CDATA[<p>Video tutorial: <a href="https://www.youtube.com/watch?v=FyyVbuLZav8">Challenging Luck, 2021</a></p><p>Practicing Python code: <a href="https://github.com/challengingLuck/youtube/blob/master/sudoku/sudoku.py">challengingLuck: Using Annealing Algorithm to Solve the Sudo Challenge</a></p><blockquote><p>Simulated Annealing (SA) is a probabilistic technique used for finding an approximate solution to an optimization problem. It is particularly useful for problems where the search space is large and complex, and other methods might get stuck in local optima. Here’s a structured way to start learning about the Simulated Annealing algorithm:</p></blockquote><p>$$ P(E, E’, T) = \begin{cases}<br>1 &amp; \text{if } E’ &lt; E \\<br>\exp\left(\frac{-(E’ - E)}{T}\right) &amp; \text{if } E’ \ge E<br>\end{cases}<br>$$</p><p>This idea is similar to DNA annealing during PCR. During the temperature drop after the high-temperature mutation, the DNA gradually returns to the double strand with its reverse complement strand or the primer due to the decrease in entropy. Unlike DNA annealing, Simulated Annealing (SA) introduces random values to replace the original ones. After that, the “Energy” is calculated, and only when the new score is lower than the previous one is the new value accepted, continuing the iteration until the lowest value is found. It works like this:</p><p>Calculate the initial <code>E</code> → randomly mutate the value and calculate the new <code>E'</code> → if <code>E' ≤ E</code>, then accept the mutated element; otherwise, try another value → if <code>E'</code> meets the lowest <code>E</code>, stop; otherwise, continue until no smaller <code>E'</code> can be found.</p><p>As a result, you could expect that it would <mark>waste a lot of resources on exploration</mark> and easily <mark>fall into local optima</mark>.</p><p>An example of the SA apply in sudo challenge</p><p><img src="https://imgur.com/k4jbsQK.gif" alt="Simulated annealing in Sudo"><br><img src="https://imgur.com/uWGjeSm.png" alt="Simulated annealing in Sudo"><br>In this example, it actually <mark>failed</mark> to get the result because it <strong>fall into local optimal</strong>. It is a very good example to show the capability and limitations of the SA.</p><h2 id="SA-and-Stochastic-gradient-descent">SA and Stochastic gradient descent</h2><p>$$<br>w_{t+1} = w_t - \eta \nabla f(w_t; x_i)<br>$$</p><ul><li>$w$ is the parameter, weight matrix, for example. While $w_t$ is the old one and the $w_{t-1}$ is updated parameter.</li><li>$\eta$ is the learning rate</li><li>$x$ is the input</li></ul><blockquote><p><strong>Stochastic Gradient Descent (SGD)</strong> is an optimization algorithm used primarily for training machine learning models. It iteratively updates the model parameters by computing the gradient of the loss function using a randomly selected subset (mini-batch) of the training data, rather than the entire dataset. This randomness introduces variability in the updates, which helps escape local optima and speeds up convergence. The learning rate controls the step size of each update, determining how far the parameters move in the direction of the negative gradient. By continuously adjusting the parameters, SGD aims to minimize the loss function and improve the model’s performance.</p></blockquote><p>So, it is very similar to Stochastic gradient descent (SGD). But for SGD, there are a learning process from the data. SGD is primally based on the exploitation. But in SA, exploration has more contribution compared with SGD because it hugely relies on random generation first and evaluating later.</p><h2 id="SA-and-Genetic-Algorithm-GA">SA and Genetic Algorithm (GA)</h2><blockquote><p>What is GA?<br>Genetic Algorithms (GA) are evolutionary algorithms inspired by the principles of natural selection and genetics. They work by evolving a population of candidate solutions through successive generations. Each generation undergoes selection, where the fittest individuals are chosen based on their performance. These selected individuals then undergo crossover (recombination) to produce offspring that combine their parents’ characteristics. Additionally, mutation introduces random changes to some individuals to maintain genetic diversity within the population. This process of selection, crossover, and mutation allows GAs to explore a wide search space and balance between exploring new solutions and exploiting the best solutions found so far. This diversity helps GAs avoid getting trapped in local optima, making them effective for solving complex optimization problems, including those that are non-differentiable and non-convex.</p></blockquote><p>From a personal point of view, GA is like an upgraded version of SA. SA works at the level of a single individual, while GA operates at the population level. Similar to SA, GA evaluates and selects the “fitness scores” of each individual. The next generation introduces many random mutations, just like SA. However, unlike SA, GA also includes “crossover” steps, which can help enrich the “better phenotypes”.</p><table><thead><tr><th>Feature</th><th>Simulated Annealing (SA)</th><th>Stochastic Gradient Descent (SGD)</th><th>Genetic Algorithm (GA)</th></tr></thead><tbody><tr><td><strong>Approach</strong></td><td>Probabilistic, accepts worse solutions occasionally</td><td>Deterministic, updates in the direction of the gradient</td><td>Evolutionary, uses selection, crossover, and mutation</td></tr><tr><td><strong>Objective Function</strong></td><td>Non-differentiable and non-convex functions</td><td>Differentiable functions</td><td>Non-differentiable and non-convex functions</td></tr><tr><td><strong>Exploration vs. Exploitation</strong></td><td>Balances both, reduces acceptance of worse solutions over time</td><td>Primarily exploitation with some exploration via mini-batches</td><td>Balances both, uses population diversity to explore the search space</td></tr><tr><td><strong>Cooling Schedule / Learning Rate</strong></td><td>Uses a cooling schedule to reduce probability of accepting worse solutions</td><td>Uses a learning rate to control step size of updates</td><td>Uses selection pressure to favor better solutions and mutation rate to introduce diversity</td></tr><tr><td><strong>Population-Based</strong></td><td>No</td><td>No</td><td>Yes, operates on a population of solutions</td></tr><tr><td><strong>Escape Local Optima</strong></td><td>Yes, by accepting worse solutions with a probability</td><td>Limited, may get stuck in local optima</td><td>Yes, by maintaining a diverse population</td></tr><tr><td><strong>Gradient Requirement</strong></td><td>No</td><td>Yes</td><td>No</td></tr><tr><td><strong>Applications</strong></td><td>Combinatorial and continuous optimization without gradients</td><td>Training machine learning models, especially in deep learning</td><td>Optimization problems, including scheduling, design, and artificial intelligence</td></tr><tr><td><strong>Natural Inspiration</strong></td><td>Annealing in metallurgy</td><td>Gradient descent in calculus</td><td>Natural selection and genetics</td></tr><tr><td><strong>Operators</strong></td><td>Acceptance probability based on temperature</td><td>Gradient-based updates</td><td>Selection, crossover (recombination), and mutation</td></tr></tbody></table><blockquote><p>table from: ChatGPT4o</p></blockquote><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Simulated Annealing (SA) is a probabilistic technique used for finding an approximate solution to an optimization problem. It is particularly useful for problems where the search space is large and complex, and other methods might get stuck in local optima.</summary>
    
    
    
    <category term="AI" scheme="https://karobben.github.io/categories/AI/"/>
    
    <category term="Math" scheme="https://karobben.github.io/categories/AI/Math/"/>
    
    
    <category term="Math" scheme="https://karobben.github.io/tags/Math/"/>
    
    <category term="Algorithm" scheme="https://karobben.github.io/tags/Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>AI Tools for Protein Structures</title>
    <link href="https://karobben.github.io/2024/05/29/AI/protein3dml/"/>
    <id>https://karobben.github.io/2024/05/29/AI/protein3dml/</id>
    <published>2024-05-29T19:28:45.000Z</published>
    <updated>2024-06-01T17:42:53.026Z</updated>
    
    <content type="html"><![CDATA[<h2 id="trRosetta">trRosetta</h2><p>They inverted this network to generate new protein sequences from scratch, aiming to design proteins with structures and functions not found in <a href="http://nature.By">nature.By</a> conducting <strong>Monte Carlo sampling</strong> in sequence space and optimizing the predicted structural features, they managed to produce a variety of new protein sequences.</p><h2 id="RFdiffusion">RFdiffusion</h2><table><thead><tr><th style="text-align:center"></th><th style="text-align:left"></th></tr></thead><tbody><tr><td style="text-align:center"><img src="https://imgur.com/iCXildL.png" alt="RFdiffsion"></td><td style="text-align:left">Watson, Joseph L., et al<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup> published the RFdiffusion at <a href="https://github.com/RosettaCommons/RFdiffusion">github</a> in 2023. It fine-tune the <strong>RoseTTAFold</strong><sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup> and designed for tasks like: protein <strong>monomer</strong> design, protein <strong>binder</strong> design, <strong>symmetric oligomer</strong> design, <strong>enzyme active site</strong> scaffolding and symmetric <strong>motif scaffolding</strong> for therapeutic and <strong>metal-binding</strong> protein design. It is a very powerful tool according to the paper. It is based on the Denoising diffusion probabilistic models (<strong>DDPMs</strong>) which is a powerful class of machine learning models demonstrated to generate new photorealistic images in response to text prompts<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>.</td></tr></tbody></table><p>They use the ProteinMPNN<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup> network to subsequently design sequences encoding theses structure. The diffusion model is based on the <strong>DDPMs</strong>. It can not only design a protein from generation, but also able to predict multiple types of interactions as is shown of the left. It was based on the RoseTTAFold.</p><p><strong>Compared with AF2</strong></p><ul><li>AlphaFold2 is like a very smart detective that can figure out the 3D shape of a protein just by looking at its amino acid sequence. On the other hand, RFdiffusion is more like an architect that designs entirely new proteins with specific properties. Instead of just figuring out shapes, it creates new proteins that can do things like bind to specific molecules or perform certain reactions. This makes it incredibly useful for designing new therapies and industrial enzymes.</li></ul><style>pre {  background-color:#38393d;  color: #5fd381;}</style><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>Watson J L, Juergens D, Bennett N R, et al. De novo design of protein structure and function with RFdiffusion[J]. Nature, 2023, 620(7976): 1089-1100. <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>Baek M, et al. Accurate prediction of protein structures and interactions using a 3-track network. Science. July 2021. <a href="#fnref2" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>Ramesh, A. et al. Zero-shot text-to-image generation. in Proc. 38th International Conference on Machine Learning Vol. 139 (eds Meila, M. &amp; Zhang, T.) 8821–8831 (PMLR, 2021). <a href="#fnref3" class="footnote-backref">↩︎</a></p></li><li id="fn4" class="footnote-item"><p>Dauparas J, Anishchenko I, Bennett N, et al. Robust deep learning–based protein sequence design using ProteinMPNN[J]. Science, 2022, 378(6615): 49-56. <a href="#fnref4" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">AI Tools for Protein Structures</summary>
    
    
    
    <category term="AI" scheme="https://karobben.github.io/categories/AI/"/>
    
    <category term="LM" scheme="https://karobben.github.io/categories/AI/LM/"/>
    
    <category term="Protein" scheme="https://karobben.github.io/categories/AI/LM/Protein/"/>
    
    
    <category term="Machine Learning" scheme="https://karobben.github.io/tags/Machine-Learning/"/>
    
    <category term="AI" scheme="https://karobben.github.io/tags/AI/"/>
    
    <category term="3D" scheme="https://karobben.github.io/tags/3D/"/>
    
    <category term="Protein Structure" scheme="https://karobben.github.io/tags/Protein-Structure/"/>
    
  </entry>
  
  <entry>
    <title>Birds Ig</title>
    <link href="https://karobben.github.io/2024/05/23/LearnNotes/birdig/"/>
    <id>https://karobben.github.io/2024/05/23/LearnNotes/birdig/</id>
    <published>2024-05-23T18:37:09.000Z</published>
    <updated>2024-06-06T05:38:51.270Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Specific-in-Birds">Specific in Birds</h2><p>Until 2024/5/23, the only annotated bird in IMGT is Chicken. According to the IMGT, chicken heavy chain gene has only <a href="https://www.imgt.org/IMGTrepertoire/index.php?section=LocusGenes&amp;repertoire=genetable&amp;species=Chicken&amp;group=IGHV">1 functional V gene </a>, <a href="https://www.imgt.org/IMGTrepertoire/index.php?section=LocusGenes&amp;repertoire=genetable&amp;species=Chicken&amp;group=IGHV">3 functional D genes</a>, and <a href="https://www.imgt.org/IMGTrepertoire/index.php?section=LocusGenes&amp;repertoire=genetable&amp;species=Chicken&amp;group=IGHJ">1 J gene</a>. This is hugely difference from human or other mammals.</p><p>Birds have three classes of antibody: <strong>IgM</strong> (the only class in all vertebrates), <strong>IgY</strong>, and <strong>IgA</strong>. Not been directly determined but inferred from size estimates of the intact molecules of <strong>IgM</strong> and <strong>IgA</strong>, they could form <mark>polypeptide chains</mark><sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>. In addition, ducks have a smaller form of IgY, called IgY (ΔFc).</p><ul><li>IgM is the only class of antibody that is found in all vertebrate. IgM is larger than that of a true tetrameric IgM, such as occurs in teleost fish<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup> and thus both are likely to be pentameric.</li><li>IgY is the major low-molecular weight form of antibody found circulating in birds, where it has sometimes been referred to as IgG. An IgY-like molecule is likely to have been the evolutionary precursor of both IgG and IgE immunoglobulins<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup><sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>.</li></ul><h2 id="Chicken">Chicken</h2><p>The first avian genomic MHC map was the chicken minimal and essential one on chromosome 16. This map, spanning 92 kb and harboring 19 genes, was then extended to be 242 kb containing 46 genes<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup><sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup>.</p><blockquote><p><a href="https://www.imgt.org/IMGTrepertoire/LocusGenes/locusdesc/chicken/IGH/Galgal_IGHdesc.html">Chicken (Gallus gallus) IGH locus on chromosome 31</a></p><ul><li>The chicken (Gallus gallus) IGH locus is on chromosome 31. The orientation of the locus is reverse (REV).</li><li>The chicken (Gallus gallus) IGH locus spans 116 kilobases (kb), from 10 kb upstream of the most 5’ gene in the locus, IGHV1-83 §, to 10 kb downstream of the most 3’ gene in the locus, IGHJ (F). The Locus representation encompasses 120 kb.</li><li>The chicken (Gallus gallus) IGH locus consists of 94 IGHV genes belonging to 1 IGHV subgroup, 4 IGHD belonging to 1 IGHD set, 1 IGHJ gene belonging to 1 IGHJ set and 3 IGHC genes.</li><li>The IGHV genes span 97 kilobases (kb), the IGHD genes span 7251 bases (b) and the IGHJ gene span 12 kilobases (kb).<br>source: Imgt</li></ul></blockquote><p><a href="https://www.imgt.org/ligmdb/view?id=IMGT000014">https://www.imgt.org/ligmdb/view?id=IMGT000014</a></p><p>The generation of antibody binding-site diversity is very well understood for the chicken:</p><ul><li>Parvari R, Avivi A, Lentner F, Ziv E, Tel-Or S, Burstein Y, et al. Chicken immunoglobulin gamma-heavy chains: limited VH gene repertoire, combinatorial diversification by D gene segments and evolution of the heavy chain locus. EMBO J. 1988;7:739–44.</li><li>Reynaud CA, Anquez V, Dahan A, Weill JC. A single rearrangement event generates most of the chicken immunoglobulin light chain diversity. Cell. 1985;40:283–91.</li><li>Reynaud CA, Anquez V, Grimal H, Weill JC. A hyperconversion mechanism generates the chicken light chain preimmune repertoire. Cell. 1987;48:379–88.</li><li>Reynaud CA, Dahan A, Anquez V, Weill JC. Somatic hyperconversion diversifies the single Vh gene of the chicken with a high incidence in the D region. Cell. 1989;59:171–83.</li></ul><h2 id="Duck">Duck</h2><p>The newest Duck genome is available at BMC: <a href="https://bmcbiol.biomedcentral.com/articles/10.1186/s12915-024-01817-0">Jiaxiang Hu, et al; 2024</a><sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup>. The old one ZJU1.0<sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup> has (<a href="https://www.ncbi.nlm.nih.gov/datasets/genome/GCF_015476345.1/">GCF_015476345.1</a>) 33 chromosomes (not included sexual and mitochondira). For the SKLA1.0 (<a href="https://www.ncbi.nlm.nih.gov/datasets/genome/GCA_037218355.1/">GCA_037218355.1</a>), it covers 40 chromosomes (included in Z chromosome). For the ZJU1.0, they used 115 SMRT cells were sequenced with PacBio RS II. In SJKA1.0, they integrated Nanopore, Bionano, and Hi-C data. It also contains a complete genomic map of the MHC.</p><p>In E. W´ojcik and E. Smalec’s work in 2017<sup class="footnote-ref"><a href="#fn9" id="fnref9">[9]</a></sup>, they described 1-13 autosomes. In there karyotyping analysis result, the got about 84 dots for Anas platyrhynchos.</p><table><thead><tr><th style="text-align:center"><img src="https://imgur.com/YLYWzF0.png" alt="karyotype of Anas platyrhynchos"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.researchgate.net/publication/312024031_Constitutive_heterochromatin_in_chromosomes_of_duck_hybrids_and_goose_hybrids">© E. W´ojcik; 2017</a></td></tr></tbody></table><p>Anseriform birds (ducks and their relatives) are the closest relatives of the chickens which was well understood and be studied.</p><p>Ducks have the same hematopoietic tissues as chickens, including bone marrow, gut associated lymphoid tissue, spleen, thymus and the Bursa of Fabricius, a specialized organ for B lymphoid development. However, there is one notable difference. Ducks have lymph nodes, which are completely absent in chickens<sup class="footnote-ref"><a href="#fn10" id="fnref10">[10]</a></sup>.</p><blockquote><ol><li>a single functional rearrangement of the variable (V) region, like chicken.</li><li>generate diversity through gene conversion from a pool of pseudogenes.</li><li>V region element and the pseudogenes appear to consist of a single gene family (The same as the Chicken)</li><li>Further analysis of 26 heavy chain joining (JH) and 27 light chain JL segments shows there is use of a single J segment in ducks.<br>From: Lundqvist M L, et al.<sup class="footnote-ref"><a href="#fn1" id="fnref1:1">[1:1]</a></sup></li></ol></blockquote><p>The overwhelming evidence is that all birds express only a single class of immunoglobulin light (L) chain<sup class="footnote-ref"><a href="#fn11" id="fnref11">[11]</a></sup><sup class="footnote-ref"><a href="#fn12" id="fnref12">[12]</a></sup> most closely related to the λ chain of the mammals <sup class="footnote-ref"><a href="#fn13" id="fnref13">[13]</a></sup><sup class="footnote-ref"><a href="#fn14" id="fnref14">[14]</a></sup>. The suggestion of additional classes of L chain in the birds <sup class="footnote-ref"><a href="#fn15" id="fnref15">[15]</a></sup> has not been substantiated at the amino acid sequence or genetic level.</p><h3 id="Duck-IgY">Duck IgY</h3><p>Ducks IgY:</p><ul><li>secreted form</li><li>a receptor form with a hydrophobic membrane-spanning C-terminus</li><li>truncated form termed IgY(ΔFc)</li></ul><p>Difference and similarities in other species:</p><ul><li>No truncated form: Chickens express only the full-length and membrane-receptor forms of IgY<sup class="footnote-ref"><a href="#fn3" id="fnref3:1">[3:1]</a></sup>.</li><li>Has truncated form: A small form of IgY (5.7S) is produced by some species of turtles<sup class="footnote-ref"><a href="#fn16" id="fnref16">[16]</a></sup>.</li></ul><p>Duck immune response inept:</p><ul><li>lacking: precipitation, agglutination, complement fixation and opsonization<sup class="footnote-ref"><a href="#fn17" id="fnref17">[17]</a></sup><sup class="footnote-ref"><a href="#fn18" id="fnref18">[18]</a></sup> (related the lacks an Fc region).</li></ul><h3 id="Duck-IgA">Duck IgA</h3><p><strong>IgA</strong> has been described to date only in mammals and birds</p><ul><li><p>secretions of the gut, respiratory and reproductive tracts, as well as in tears, bile and (in mammals) the milk</p></li><li><p>IgA of mammals is typically a dimer.</p></li><li><p><strong>Duck IGH</strong>:</p><ol><li>a single family of VH sequences</li><li>a single expressed JH element</li><li>JH is immediately downstream of a D segment</li></ol></li><li><p><strong>Duck IGL</strong>:</p><ol><li>there are few functional coding VL and JL elements in the germline</li><li>diversification most likely arises in large measure from gene conversion events from an extensive suite of germline VL-related sequences; (Genomic Southern blot analysis showed that there is a large family of germline VL-related sequences in the mallard duck<sup class="footnote-ref"><a href="#fn11" id="fnref11:1">[11:1]</a></sup>)</li><li>It is not known whether there is a single functional V and J element in the duck L chain locus, however, that is the simplest explanation of the results.</li><li>muscovy duck were at least two functional VL genes<sup class="footnote-ref"><a href="#fn19" id="fnref19">[19]</a></sup>.</li><li>a single family of VL sequences</li></ol></li></ul><style>pre {  background-color:#38393d;  color: #5fd381;}</style><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>Lundqvist M L, Middleton D L, Radford C, et al. Immunoglobulins of the non-galliform birds: antibody expression and repertoire in the duck[J]. Developmental &amp; Comparative Immunology, 2006, 30(1-2): 93-100. <a href="#fnref1" class="footnote-backref">↩︎</a> <a href="#fnref1:1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>Leslie GA, Clem LW. Phylogeny of immunoglobulin structure and function. 3. Immunoglobulins of the chicken. J Exp Med. 1969;130:1337–52. <a href="#fnref2" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>Parvari R, Avivi A, Lentner F, Ziv E, Tel-Or S, Burstein Y, et al. Chicken immunoglobulin gamma-heavy chains: limited VH gene repertoire, combinatorial diversification by D gene segments and evolution of the heavy chain locus. EMBO J. 1988;7:739–44. <a href="#fnref3" class="footnote-backref">↩︎</a> <a href="#fnref3:1" class="footnote-backref">↩︎</a></p></li><li id="fn4" class="footnote-item"><p>Magor KE, Higgins DA, Middleton DL, Warr GW. One gene encodes the heavy chains for three different forms of IgY in the duck. J Immonol. 1994;153:5549–55. <a href="#fnref4" class="footnote-backref">↩︎</a></p></li><li id="fn5" class="footnote-item"><p>Kaufman J, Milne S, Göbel TW, Walker BA, Jacob JP, Auffray C, et al. The chicken B locus is a minimal essential major histocompatibility complex. Nature. 1999;401:923–5. <a href="#fnref5" class="footnote-backref">↩︎</a></p></li><li id="fn6" class="footnote-item"><p>Shiina T, Briles WE, Goto RM, Hosomichi K, Yanagiya K, Shimizu S, et al. Extended gene map reveals tripartite motif, C-type lectin, and Ig superfamily type genes within a subregion of the chicken MHC-B affecting infectious disease. J Immunol. 2007;178:7162–72. <a href="#fnref6" class="footnote-backref">↩︎</a></p></li><li id="fn7" class="footnote-item"><p>Hu J, Song L, Ning M, et al. A new chromosome-scale duck genome shows a major histocompatibility complex with several expanded multigene families[J]. BMC biology, 2024, 22(1): 31. <a href="#fnref7" class="footnote-backref">↩︎</a></p></li><li id="fn8" class="footnote-item"><p>Li J, Zhang J, Liu J, et al. A new duck genome reveals conserved and convergently evolved chromosome architectures of birds and mammals[J]. Gigascience, 2021, 10(1): giaa142. <a href="#fnref8" class="footnote-backref">↩︎</a></p></li><li id="fn9" class="footnote-item"><p><a href="https://www.researchgate.net/publication/312024031_Constitutive_heterochromatin_in_chromosomes_of_duck_hybrids_and_goose_hybrids">Wójcik E, Smalec E. Constitutive heterochromatin in chromosomes of duck hybrids and goose hybrids[J]. Poultry Science, 2017, 96(1): 18-26.<br></a> <a href="#fnref9" class="footnote-backref">↩︎</a></p></li><li id="fn10" class="footnote-item"><p>Flajnik MF, Miller KM, Du Pasquier L. Evolution of the immune system. In: Paul WE, editor. Fundamental immunology. 5th ed. Philadelphia: Lippincott Williams and Wilkins; 2003. p. 519–70. <a href="#fnref10" class="footnote-backref">↩︎</a></p></li><li id="fn11" class="footnote-item"><p>Magor KE, Higgins DA, Middleton DL, Warr GW. cDNA sequence and organization of the immunoglobulin light chain gene of the duck, Anas platyrhynchos. Dev Comp Immunol. 1994;18:523–31. <a href="#fnref11" class="footnote-backref">↩︎</a> <a href="#fnref11:1" class="footnote-backref">↩︎</a></p></li><li id="fn12" class="footnote-item"><p>Reynaud CA, Dahan A, Weill JC. Complete sequence of a chicken lambda light chain immunoglobulin derived from the nucleotide sequence of its mRNA. Proc Natl Acad Sci USA. 1983;80:4099–103. <a href="#fnref12" class="footnote-backref">↩︎</a></p></li><li id="fn13" class="footnote-item"><p>Grant JA, Sanders B, Hood L. Partial amino acid sequences of chicken and turkey immunoglobulin light chains. Homology with mammalian lambda chains. Biochemistry. 1971;10:3123–32. <a href="#fnref13" class="footnote-backref">↩︎</a></p></li><li id="fn14" class="footnote-item"><p>Kubo RT, Rosenblum IY, Benedict AA. The unblocked N-terminal sequence of chicken IgG lambda-like light chains. J Immunol. 1970;105:534–6. <a href="#fnref14" class="footnote-backref">↩︎</a></p></li><li id="fn15" class="footnote-item"><p>Leslie GA. Evidence for a second avian light chain isotype. Immunochemistry. 1977;14:149–51. <a href="#fnref15" class="footnote-backref">↩︎</a></p></li><li id="fn16" class="footnote-item"><p>Leslie GA, Clem LW. Phylogeny of immunoglobulin structure and function, VI. 17S, 7.5S and 5.7S anti-DNP of the turtle, Pseudamys scripta. J Immunol. 1972;108:1656–64. <a href="#fnref16" class="footnote-backref">↩︎</a></p></li><li id="fn17" class="footnote-item"><p>Grey HM. Duck immunoglobulins. II. Biologic and immunochemical studies. J Imunol. 1967;98:820–6. <a href="#fnref17" class="footnote-backref">↩︎</a></p></li><li id="fn18" class="footnote-item"><p>Humphrey BD, Calvert CC, Klasing KC. The ratio of full length IgY to truncated IgY in immune complexes affects macrophage phagocytosis and the acute phase response of mallard ducks (Anas platyrhynchos) Dev Comp Immunol. 2004;28:665–72. <a href="#fnref18" class="footnote-backref">↩︎</a></p></li><li id="fn19" class="footnote-item"><p>McCormack WT, Carlson LM, Tjoelker LW, Thompson CB. Evolutionary comparison of the avian IgL locus: combinatorial diversity plays a role in the generation of the antibody repertoire in some avian species. Int Immunol. 1989;1:332–41. <a href="#fnref19" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">The avian immune system exhibits a unique immunoglobulin (Ig) system characterized by distinct features absent in other vertebrates. Birds possess a specialized IgY, which serves as the functional equivalent to mammalian IgG and IgE, but with significant structural and functional differences. Unlike mammalian systems, birds utilize a limited number of germline gene segments and rely on gene conversion within the bursa of Fabricius to generate antibody diversity. This mechanism allows for a rapid and diverse immune response, showcasing the evolutionary adaptation of birds to their ecological niches and pathogen challenges.</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Notes/Biology/"/>
    
    <category term="Immunity" scheme="https://karobben.github.io/categories/Notes/Biology/Immunity/"/>
    
    
    <category term="Biology" scheme="https://karobben.github.io/tags/Biology/"/>
    
    <category term="Antibody" scheme="https://karobben.github.io/tags/Antibody/"/>
    
    <category term="Immunology" scheme="https://karobben.github.io/tags/Immunology/"/>
    
  </entry>
  
  <entry>
    <title>Antibody 12/23 rule</title>
    <link href="https://karobben.github.io/2024/05/18/LearnNotes/ab1223rule/"/>
    <id>https://karobben.github.io/2024/05/18/LearnNotes/ab1223rule/</id>
    <published>2024-05-18T14:49:22.000Z</published>
    <updated>2024-05-29T19:31:31.797Z</updated>
    
    <content type="html"><![CDATA[<h2 id="How-Does-Antibody-Fragments-Jointed-Together">How Does Antibody Fragments Jointed Together?</h2><p>We all know that antibodies are composed of V, D, and J segments, which originate from different locations on the chromosome. But how are they connected together after post-transcriptional modification? The 12/23 rule is the fundamental mechanism that ensures proper recombination of these segments.</p><blockquote><p>The V region, or V domain, of an immunoglobulin heavy or light chain is encoded by more than one gene segment. For the light chain, the V domain is encoded by two separate DNA segments. The first segment encodes the first 95–101 amino acids of the light chain and is termed a V gene segment because it encodes most of the V domain. The second segment encodes the remainder of the V domain (up to 13 amino acids) and is termed a joining or J gene segment<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>.</p></blockquote><h2 id="What-Is-12-23-Rule">What Is 12/23 Rule</h2><p>Video tutorial: <a href="https://www.youtube.com/watch?v=QTOBSFJWogE">Daniel Levy; 2013. VDJ Gene Recombination</a></p><p>The 12/23 rule is a principle in V(D)J recombination, a process crucial for generating the diversity of antibodies and T-cell receptors. It states that recombination can only occur between gene segments flanked by recombination signal sequences (RSS) with spacers of 12 base pairs (bp) and 23 bp. This ensures proper alignment and prevents inappropriate recombination events, maintaining the integrity and functionality of the immune system’s response.</p><table><thead><tr><th style="text-align:center"><img src="https://www.ncbi.nlm.nih.gov/books/NBK27140/bin/CH4F5.jpg" alt="12/23 rule illustration"></th></tr></thead><tbody><tr><td style="text-align:center">© Charles A. Janeway</td></tr></tbody></table><p>This image illustrates the 12/23 rule in the context of V(D)J recombination.</p><ol><li><p><strong>Recombination Signal Sequences (RSS)</strong>:</p><ul><li><strong>Heptamer</strong>: A conserved sequence of 7 base pairs.</li><li><strong>Nonamer</strong>: A conserved sequence of 9 base pairs.</li><li><strong>Spacer</strong>: The region between the heptamer and nonamer, either 12 or 23 base pairs long.</li></ul></li><li><p><strong>V(D)J Recombination Process</strong>:</p><ul><li><strong>Segments</strong>: V (Variable), D (Diversity), and J (Joining) segments.</li><li><strong>Rule Application</strong>: The 12/23 rule ensures that only segments with RSS of different spacers (12 and 23 bp) recombine, facilitating the correct assembly of these segments.</li></ul></li></ol><p>The image visually represents how the rule guides the alignment and recombination of V, D, and J gene segments, which is essential for generating the diversity of antibodies and T-cell receptors.</p><h2 id="How-It-Worked">How It Worked</h2><p>The heptamer and nonamer is the recombination signal sequences (RSSs). The (RAG1-RAG2)2 endonuclease complex (RAG) specifically recognizes and cleaves a pair of RSSs<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup></p><table><thead><tr><th style="text-align:center"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0959440X18301143-gr3.jpg" alt=""></th></tr></thead><tbody><tr><td style="text-align:center">© Ru H<sup class="footnote-ref"><a href="#fn2" id="fnref2:1">[2:1]</a></sup></td></tr></tbody></table><h2 id="How-Does-It-Applied">How Does It Applied</h2><h3 id="IgDetective">IgDetective</h3><p><a href="https://github.com/Immunotools/IgDetective">IgDetective</a>, published by Vikram Sirupurapu and Yana Safonova<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>, is a tool for detecting and naming antibodies based on the 12/23 rule. This tool leverages the stringent application of the 12/23 rule among mammals, making it suitable primarily for mammalian species.</p><ul><li>Test: not suitable for birds like chicken</li></ul><h3 id="williamdlees-Digger">williamdlees-Digger</h3><p>This is another <a href="https://github.com/williamdlees/digger">open source</a> tool developed by William D. Lees<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>, aimed at annotating the positions of V/D/J genes on newly assembled genomes. According to the results shown in the <a href="https://williamdlees.github.io/digger/_build/html/examples/human_igh.html">documentation</a>, it has very high accuracy.</p><p>Prerequisite:</p><ul><li>a set of known core coding region allele sequences</li><li>Position-weighted matrices</li></ul><p>Some technic details worthy to know:</p><ul><li>The search for V-sequences uses the parameters gapopen 5, gapextend 5, penalty -1, word_size 11.</li><li>D and J searches, word_size is reduced to 7 to reflect the shorter sequences</li><li>D sequences the evalue is set to 100 rather than the default of 10 to widen the search.<br>How it find the heptamers and nonamers:</li></ul><table><thead><tr><th>Type</th><th>Functionality criteria</th></tr></thead><tbody><tr><td>V</td><td>RSS nonamer and heptamer pass PWM thresholds, and match canonical consensus, if defined.<br>L-PART1 and L-PART2 pass PWM thresholds and splice to form a coding sequence with no STOP-CODONs that is in-frame with the V sequence.<br>V-REGION is in-frame and has first and second cysteines at the correct positions in the IMGT alignment.<br>No STOP-CODONs are present in the V-REGION before the second cysteine.</td></tr><tr><td>D</td><td>RSS nonamers and heptamers match canonical consensus, if defined.</td></tr><tr><td>J</td><td>RSS nonamer and heptamer pass PWM thresholds, and match canonical consensus, if defined.<br>The J-motif is found at the expected position relative to the end of the J sequence.<br>The donor splice is found at the expected position, given the length of the matched sequence.</td></tr></tbody></table><p><strong>Limitation:</strong> It only supports <mark>IMGT well-annotated species</mark> because it relies on germline annotation from the IMGT database.<br><strong>Merits:</strong> Easy used and to be understood (write by python).</p><table><thead><tr><th style="text-align:center"><img src="https://williamdlees.github.io/digger/_build/html/_images/igh_results.jpg" alt="Digger Results"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://williamdlees.github.io/digger/_build/html/examples/human_igh.html">© William D. Leeszs</a></td></tr></tbody></table><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">extract_refs -L IGH <span class="hljs-string">&quot;Gallus gallus&quot;</span><br>fix_macaque_gaps Gallus_gallus_IGHV_gapped.fasta \<br>    Gallus_gallus_IGHV_gapped_fixed.fasta IGH<br>cat Gallus_gallus_IGHV.fasta Gallus_gallus_IGHD.fasta Gallus_gallus_IGHJ.fasta \<br>    &gt; Gallus_gallus_IGHVDJ.fasta<br><br>parse_imgt_annotations --save_sequence IMGT000014.fasta \<br>   <span class="hljs-string">&quot;https://www.imgt.org/ligmdb/view.action?format=IMGT&amp;id=IMGT000014&quot;</span> \<br>      IMGT000014_genes.csv IGH<br><br>cat IMGT000014.fasta &gt; Mmul_051212.fasta<br><br><br>mkdir motifs<br><span class="hljs-built_in">cd</span> motifs<br>parse_imgt_annotations \<br>        <span class="hljs-string">&quot;https://www.imgt.org/ligmdb/view?format=IMGT&amp;id=IMGT000014&quot;</span> \<br>        IMGT000014_genes.csv IGH<br>calc_motifs IGH IMGT000014_genes.csv<br><span class="hljs-built_in">cd</span> ..<br><br>makeblastdb -<span class="hljs-keyword">in</span> Gallus_gallus_IGHV.fasta -dbtype nucl<br>makeblastdb -<span class="hljs-keyword">in</span> Gallus_gallus_IGHD.fasta -dbtype nucl<br>makeblastdb -<span class="hljs-keyword">in</span> Gallus_gallus_IGHJ.fasta -dbtype nucl<br><br>blastn -db Gallus_gallus_IGHV.fasta -query Mmul_051212.fasta -out mmul_IGHV.out \<br> -outfmt 7 -gapopen 5 -gapextend 5 -penalty -1 -word_size 11<br>blastn -db Gallus_gallus_IGHD.fasta -query Mmul_051212.fasta -out mmul_IGHD.out \<br> -outfmt 7 -gapopen 5 -gapextend 5 -penalty -1 -word_size 4 -evalue 100<br>blastn -db Gallus_gallus_IGHJ.fasta -query Mmul_051212.fasta -out mmul_IGHJ.out \<br> -outfmt 7 -gapopen 5 -gapextend 5 -penalty -1 -word_size 4<br><br><br><br>blastresults_to_csv mmul_IGHV.out mmul_ighvdj_<br>blastresults_to_csv mmul_IGHD.out mmul_ighvdj_ -a<br>blastresults_to_csv mmul_IGHJ.out mmul_ighvdj_ -a<br><br>find_alignments Gallus_gallus_IGHVDJ.fasta \<br>       Mmul_051212.fasta \<br>       <span class="hljs-string">&quot;mmul_ighvdj_nw_*.csv&quot;</span> \<br>       -ref imgt,Gallus_gallus_IGHVDJ.fasta \<br>       -align Gallus_gallus_IGHV_gapped_fixed.fasta \<br>       -motif_dir motifs \<br>       Mmul_051212.csv<br><br>digger ../../../Duck/data/GCA_015476345.1_ZJU1.0_genomic.fna \<br>   -v_ref Homo_sapiens_IGHV.fasta \<br>   -d_ref Homo_sapiens_IGHD.fasta \<br>   -j_ref Homo_sapiens_IGHJ.fasta \<br>   -v_ref_gapped Homo_sapiens_IGHV_gapped.fasta \<br>   -ref imgt,Homo_sapiens_IGHVDJ.fasta \<br>   -species Chicken  \<br>   -locus IGH \<br>   IMGT000035.csv<br><br><br></code></pre></td></tr></table></figure></div><h2 id="How-It-Really-Looks-Like-in-Human-Genome">How It Really Looks Like in Human Genome</h2><p>I randomly checked a few sequences from the homo genome and found that those regions from different V, D, and J genes are very similar. It could because that the 12/23 rule is not very stringent but flexible. But it could also caused by they are prevented to be recombined.</p><p><img src="https://imgur.com/jqUHyK3.png" alt=""></p><style>pre {  background-color:#38393d;  color: #5fd381;}</style><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>Janeway C, Travers P, Walport M, et al. Immunobiology: the immune system in health and disease[M]. New York: Garland Pub., 2001. <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>Ru H, Zhang P, Wu H. Structural gymnastics of RAG-mediated DNA cleavage in V (D) J recombination[J]. Current opinion in structural biology, 2018, 53: 178-186. <a href="#fnref2" class="footnote-backref">↩︎</a> <a href="#fnref2:1" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>Sirupurapu V, Safonova Y, Pevzner P A. Gene prediction in the immunoglobulin loci[J]. Genome research, 2022, 32(6): 1152-1169. <a href="#fnref3" class="footnote-backref">↩︎</a></p></li><li id="fn4" class="footnote-item"><p>Lees W D, Saha S, Yaari G, et al. Digger: directed annotation of immunoglobulin and T cell receptor V, D, and J gene sequences and assemblies[J]. Bioinformatics, 2024, 40(3): btae144. <a href="#fnref4" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">The 12/23 rule is fundamental in the V(D)J recombination process</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Notes/Biology/"/>
    
    <category term="Immunity" scheme="https://karobben.github.io/categories/Notes/Biology/Immunity/"/>
    
    
    <category term="Biology" scheme="https://karobben.github.io/tags/Biology/"/>
    
    <category term="Antibody" scheme="https://karobben.github.io/tags/Antibody/"/>
    
    <category term="Immunology" scheme="https://karobben.github.io/tags/Immunology/"/>
    
  </entry>
  
  <entry>
    <title>Multi-layer Neural Nets</title>
    <link href="https://karobben.github.io/2024/02/18/AI/ai-multilayer/"/>
    <id>https://karobben.github.io/2024/02/18/AI/ai-multilayer/</id>
    <published>2024-02-19T05:49:17.000Z</published>
    <updated>2024-05-31T23:00:51.048Z</updated>
    
    <content type="html"><![CDATA[<h2 id="From-linear-to-nonlinear-classifiers">From linear to nonlinear classifiers</h2><ul><li>Linear classifier<ul><li>a linear classifier computes $f(x) = argmax\ Wx$</li><li>The resulting classifier divides the x-space into Voronoi regions: convex regions with piece-wise linear boundaries</li></ul></li><li>Nonlinear classifier<ul><li>Not all classification problems have convex decision regions with PWL boundaries!</li><li>Here’s an example problem in which class 0 (blue) includes values of x near [0.8,0]<sup>T</sup>, but it also includes some values of x near [0.4,0.9]<sup>T</sup></li><li>You can’t compute this function using: $f(x) = argmax\ Wx$</li></ul></li><li>The solution: Piece-wise linear functions<ul><li>Nonlinear classifiers, can be learned using piece-wise linear classification boundaries</li><li>Nonlinear regression problems, can be learned using piece-wise linear regression</li><li>In the limit, as the number of pieces goes to infinity, the approximation approaches the desired solution</li></ul></li></ul><h2 id="Introduction">Introduction</h2><p>Video tutorial: <a href="https://www.youtube.com/watch?v=ErnWZxJovaM&amp;list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&amp;index=1">Intro to Deep Learning; Apr. 29, 2024</a><br>Slides PDF: <a href="http://introtodeeplearning.com/slides/6S191_MIT_DeepLearning_L1.pdf">Slides</a></p><h3 id="Perceptron-and-Neural-Network">Perceptron and Neural Network</h3><p>For multi Output Perceptron:</p><table><thead><tr><th style="text-align:center">Multi Output Perceptron</th><th style="text-align:center">Single Layer Neural Network</th></tr></thead><tbody><tr><td style="text-align:center"><img src="https://imgur.com/tL6UjLX.png" alt=""></td><td style="text-align:center"><img src="https://imgur.com/4YyvzOt.png" alt=""></td></tr><tr><td style="text-align:center">$$z_i = w_{0,i} + \sum^m_{j=1} x_j w_{j,i}$$</td><td style="text-align:center">$$ z_i = w_{0,i}^{(1)} + \sum_{j=1}^{m} x_j w_{j,i}^{(1)} $$  $$ \hat{y}_ i = g \left( w_ {0,i}^ {(2)} + \sum_ {j=1}^ {d_ 1} g(z_ j) w_ {j,i}^ {(2)} \right) $$</td></tr><tr><td style="text-align:center"><a href="https://www.youtube.com/watch?v=ErnWZxJovaM&amp;list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&amp;index=1">© Alexander Amini</a></td><td style="text-align:center"><a href="https://www.youtube.com/watch?v=ErnWZxJovaM&amp;list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&amp;index=1">© Alexander Amini</a></td></tr></tbody></table><p>By comparing them based on this illustration, we can see that the Perceptron and neural network architectures are very similar. The difference lies in the output parts. For a Perceptron, after the perceptron learns the $z$, the results are based directly on $g(z)$. However, in a neural network, after the model learns $z$, it still needs to learn the $w^{(2)}$, and the result is based on both $z$ and $w^{(2)}$. In this case, $z$ becomes a hidden layer.</p><p>For Deep neural network, we just simply increasing the layers of hidden layer which is $z_ n → z_ {n, m}$.</p><h2 id="Quantifying-Loss">Quantifying Loss</h2><p>By following the function above, we know that for a single layer neural net work with single output, $\hat{y} = g \left( w^ {(2)} + \sum_ {j=1}^ {d_ 1} g(z_ j) w_ {j}^ {(2)} \right) $ or just $\hat{y} = g(x^{(i)}; W)$. So, we could define that the loss: $\mathcal{L}(f(x^{(i)}; \mathbf{W}), y^{(i)})$. Hence, the Empirical Loss which measure the total loss should be:</p><p>$$<br>J(W) = \frac{1}{n} \sum^n_ {i=1} \mathcal{L}(f(x^{(i)}; \mathbf{W}), y^{(i)})<br>$$</p><p>According to the classification test or regression test, we could selected tow types of basic loss function:</p><p><strong>Binary Cross-Entropy Loss:</strong></p><ul><li>$ \mathcal{L} = -\frac{1}{N} \sum_{i=1}^{N} \left[ y^{(i)} \log(f(x^{(i)})) + (1 - y^{(i)}) \log(1 - f(x^{(i)})) \right] $</li></ul><p><strong>Mean Squared Error Loss:</strong></p><ul><li>$ \mathcal{L} = \frac{1}{N} \sum_{i=1}^{N} \left( y^{(i)} - f(x^{(i)}) \right)^2 $</li></ul><h2 id="Training">Training</h2><p>The logic of training is very simple and clear: we want to find the weight that <mark>achieve the lowest loss</mark>.</p><p>We random pick initial value of $w$ and updated when we find a new $w$ which could achieve lower loss. By doing this, we could compute the gradient: $ \frac{\partial J(W)}{\partial W} $</p><p>The way of update the weight is very similar to perceptron:</p><ul><li>$W \leftarrow W - \eta \frac{\partial J(w)}{\partial w} $</li></ul><h3 id="Backpropagation">Backpropagation</h3><p>Backpropagation is a key algorithm in training neural networks, which utilizes the chain rule to compute the gradient of the loss function with respect to each weight in the network. Let’s break down the images and the concepts step-by-step:</p><p>Backpropagation, short for “backward propagation of errors,” is a fundamental algorithm used to train artificial neural networks. It is based on the concept of gradient descent and helps in minimizing the error by adjusting the weights of the network. Here’s a step-by-step explanation and a guide on how to calculate it:</p><h3 id="Understanding-Backpropagation">Understanding Backpropagation</h3><ol><li><p><strong>Forward Pass:</strong></p><ul><li>Input data is passed through the neural network layer by layer to obtain the output.</li><li>Each layer performs a weighted sum of inputs, applies an activation function, and passes the result to the next layer.</li></ul></li><li><p><strong>Loss Calculation:</strong></p><ul><li>The network’s output is compared to the actual target output using a loss function (e.g., Mean Squared Error, Cross-Entropy Loss).</li><li>The difference between the predicted output and the actual output is the error.</li></ul></li><li><p><strong>Backward Pass (Backpropagation):</strong></p><ul><li>The error is propagated back through the network to update the weights.</li><li>This involves computing the gradient of the loss function with respect to each weight in the network.</li><li>Gradients indicate the direction and magnitude of the change required in the weights to minimize the error.</li></ul></li></ol><h3 id="Steps-in-Backpropagation">Steps in Backpropagation</h3><ol><li><p><strong>Initialization:</strong></p><ul><li>Initialize the weights and biases of the network with small random values.</li></ul></li><li><p><strong>Forward Pass:</strong></p><ul><li>For each layer $ l $, compute the input $ z^l $ and output $ a^l $:<ul><li>$z^l = W^l a^{l-1} + b^l$</li><li>$a^l = \sigma(z^l)$</li></ul></li><li>Here, $ W^l $ are the weights, $ b^l $ are the biases, $ \sigma $ is the activation function, and $ a^{l-1} $ is the output from the previous layer (the first $a$ is $x$ which is the input).</li></ul></li><li><p><strong>Compute Loss:</strong></p><ul><li>Compute the loss $ L $ using a suitable loss function.</li></ul></li><li><p><strong>Backward Pass:</strong></p><ul><li>Calculate the gradient of the loss with respect to the output of the last layer $ \delta^L $:<ul><li>$\delta^L = \nabla_a L \cdot \sigma’(z^L)$</li></ul></li><li>For each layer $ l $ from $ L-1 $ to 1, compute:<br>-$\delta^l = (\delta^{l+1} \cdot W^{l+1}) \cdot \sigma’(z^l)$</li><li>Update the weights and biases:<ul><li>$W^l = W^l - \eta \cdot \delta^l \cdot (a^{l-1}) ^T$</li><li>$b^l = b^l - \eta \cdot \delta^l$</li></ul></li><li>Here, $ \eta $ is the learning rate, and $ \sigma’ $ is the derivative of the activation function.</li></ul></li></ol><h3 id="Calculation">Calculation</h3><p>To actually calculate backpropagation, you need to:</p><ol><li><strong>Initialize weights and biases.</strong></li><li><strong>Perform a forward pass</strong> to compute the activations for each layer.</li><li><strong>Compute the loss</strong> using the output from the forward pass and the actual target values.</li><li><strong>Perform a backward pass</strong> to compute the gradients of the loss with respect to each weight.</li><li><strong>Update the weights and biases</strong> using the computed gradients and the learning rate.</li></ol><details><summary> Example Code (Python):</summary><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sigmoid</span>(<span class="hljs-params">x</span>):</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + np.exp(-x))<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sigmoid_derivative</span>(<span class="hljs-params">x</span>):</span><br>    <span class="hljs-keyword">return</span> x * (<span class="hljs-number">1</span> - x)<br><br><span class="hljs-comment"># Example input and output</span><br>x = np.array([[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>]])<br>y = np.array([[<span class="hljs-number">0</span>], [<span class="hljs-number">1</span>], [<span class="hljs-number">1</span>], [<span class="hljs-number">0</span>]])<br><br><span class="hljs-comment"># Initialize weights and biases</span><br>np.random.seed(<span class="hljs-number">42</span>)<br>W1 = np.random.rand(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br>b1 = np.random.rand(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>W2 = np.random.rand(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>)<br>b2 = np.random.rand(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br><br><span class="hljs-comment"># Learning rate</span><br>eta = <span class="hljs-number">0.1</span><br><br><span class="hljs-comment"># Training loop</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10000</span>):<br>    <span class="hljs-comment"># Forward pass</span><br>    z1 = np.dot(x, W1) + b1<br>    a1 = sigmoid(z1)<br>    z2 = np.dot(a1, W2) + b2<br>    a2 = sigmoid(z2)<br>    <span class="hljs-comment"># Loss calculation</span><br>    loss = <span class="hljs-number">0.5</span> * (y - a2)**<span class="hljs-number">2</span><br>    <span class="hljs-comment"># Backward pass</span><br>    delta2 = (a2 - y) * sigmoid_derivative(a2)<br>    delta1 = np.dot(delta2, W2.T) * sigmoid_derivative(a1)<br>    <span class="hljs-comment"># Update weights and biases</span><br>    W2 -= eta * np.dot(a1.T, delta2)<br>    b2 -= eta * np.<span class="hljs-built_in">sum</span>(delta2, axis=<span class="hljs-number">0</span>, keepdims=<span class="hljs-literal">True</span>)<br>    W1 -= eta * np.dot(x.T, delta1)<br>    b1 -= eta * np.<span class="hljs-built_in">sum</span>(delta1, axis=<span class="hljs-number">0</span>, keepdims=<span class="hljs-literal">True</span>)<br><br>print(<span class="hljs-string">&quot;Final output after training:&quot;</span>)<br>print(a2)<br></code></pre></td></tr></table></figure></div><p>This code demonstrates the basic steps of backpropagation in a simple neural network. By running this code, you can observe how the network learns to approximate the XOR function over time.</p></details><p>In a perceptron, weights and biases are updated by multiplying the error (loss) by the input and learning rate, and then adding this value to the current weights. This approach works because the weights for each input are independent, and the perceptron does not form a network. However, in a neural network, nearly every weight can influence every output. As a result, we cannot simply update the weights based on the error alone. Instead, we need to calculate the contribution of each weight to the overall error and adjust the weights accordingly. This process of calculating each weight’s contribution and updating them is known as backpropagation.</p><h3 id="Overview-of-the-Process">Overview of the Process</h3><ol><li><strong>Forward Pass</strong>: The input $ x $ is passed through the network to compute the output $ \hat{y} $.</li><li><strong>Loss Calculation</strong>: The loss function $ J(W) $ calculates the difference between the predicted output $ \hat{y} $ and the actual output.</li><li><strong>Backward Pass</strong>: Gradients are computed by propagating the error backward through the network, adjusting the weights to minimize the loss.</li></ol><p>The goal is to understand how a small change in one weight (e.g., $ w_2 $) affects the final loss $ J(W) $.</p><p>For the weight $ w_1 $, the gradient involves additional intermediate steps. Specifically:<br>$ \frac{\partial J(W)}{\partial w_1} = \frac{\partial J(W)}{\partial \hat{y}} \times \frac{\partial \hat{y}}{\partial z_1} \times \frac{\partial z_1}{\partial w_1} $</p><p>This decomposition shows that the gradient of the loss with respect to $ w_1 $ depends on:</p><ul><li>The gradient of the loss with respect to the output $ \hat{y} $</li><li>The gradient of $ \hat{y} $ with respect to the intermediate variable $ z_1 $</li><li>The gradient of $ z_1 $ with respect to the weight $ w_1 $</li></ul><h3 id="Why-Backpropagation">Why Backpropagation?</h3><p>Backpropagation efficiently computes these gradients using the chain rule. The key points are:</p><ul><li><strong>Efficiency</strong>: By reusing intermediate results (e.g., the gradient of the loss with respect to $ \hat{y} $), backpropagation avoids redundant calculations.</li><li><strong>Modularity</strong>: Gradients are computed layer by layer, allowing for modular network designs where each layer can be independently understood and modified.</li><li><strong>Training</strong>: These gradients are used to update the weights in a way that minimizes the loss function, allowing the network to learn from data.</li></ul><h3 id="Summary">Summary</h3><p>Backpropagation applies the chain rule to compute gradients of the loss function with respect to each weight in the network. These gradients are essential for updating the weights during training, thereby enabling the network to learn. Understanding the chain rule and how it applies to neural networks is crucial for grasping backpropagation.</p><h2 id="Batches">Batches</h2><p>Running backpropagation can be computationally expensive when calculating (\frac{\partial J(W)}{\partial w_1}) with a large training dataset. It is easy to run out of memory if too many threads are used. To mitigate this, one approach is to use a single data point to compute (\frac{\partial J_i(W)}{\partial w_1}), though this can introduce significant noise. A more effective strategy is to divide the training data into small batches, which can increase training efficiency and reduce noise. Common batch sizes used during training are 32 or 64.</p><h2 id="Strategies-for-Avoiding-Overfitting">Strategies for Avoiding Overfitting</h2><ol><li>Dropout:<ul><li>randomly set some activate as 0.</li><li>force network not relay on any node</li></ul></li><li>Early stopping:<ul><li>monitor the losing curve and stop the training before it had change to overfit</li></ul></li></ol><h2 id="NW-in-Action">NW in Action</h2><p>Let’s go through an example of using TensorFlow to build a two-layer neural network for a classification task using a dataset from scikit-learn. We will use the Iris dataset, which is a classic dataset for classification.</p><p>Notice: When TensorFlow runs a neural network, it automatically detects and utilizes available GPUs to accelerate the computation. This process is seamless and doesn’t typically require manual intervention.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> OneHotEncoder<br><br><span class="hljs-comment"># Load the Iris dataset</span><br>iris = datasets.load_iris()<br>X = iris.data<br>y = iris.target.reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br><br><span class="hljs-comment"># One-hot encode the target labels</span><br>encoder = OneHotEncoder(sparse=<span class="hljs-literal">False</span>)<br>y = encoder.fit_transform(y)<br><br><span class="hljs-comment"># Standardize the feature data</span><br>scaler = StandardScaler()<br>X = scaler.fit_transform(X)<br><br><span class="hljs-comment"># Split the dataset into training and test sets</span><br>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number">0.2</span>, random_state=<span class="hljs-number">42</span>)<br><br><span class="hljs-comment"># Define the model</span><br>model = tf.keras.models.Sequential([<br>    tf.keras.layers.Dense(<span class="hljs-number">10</span>, activation=<span class="hljs-string">&#x27;relu&#x27;</span>, input_shape=(X_train.shape[<span class="hljs-number">1</span>],)),<br>    tf.keras.layers.Dense(<span class="hljs-number">10</span>, activation=<span class="hljs-string">&#x27;relu&#x27;</span>),<br>    tf.keras.layers.Dense(<span class="hljs-number">3</span>, activation=<span class="hljs-string">&#x27;softmax&#x27;</span>)<br>])<br><br><span class="hljs-comment"># Compile the model</span><br>model.<span class="hljs-built_in">compile</span>(optimizer=<span class="hljs-string">&#x27;adam&#x27;</span>, loss=<span class="hljs-string">&#x27;categorical_crossentropy&#x27;</span>, metrics=[<span class="hljs-string">&#x27;accuracy&#x27;</span>])<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">PrintLossCallback</span>(<span class="hljs-params">tf.keras.callbacks.Callback</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">on_epoch_end</span>(<span class="hljs-params">self, epoch, logs=<span class="hljs-literal">None</span></span>):</span><br>        print(<span class="hljs-string">f&quot;Epoch <span class="hljs-subst">&#123;epoch + <span class="hljs-number">1</span>&#125;</span>, Loss: <span class="hljs-subst">&#123;logs[<span class="hljs-string">&#x27;loss&#x27;</span>]&#125;</span>, Accuracy: <span class="hljs-subst">&#123;logs[<span class="hljs-string">&#x27;accuracy&#x27;</span>]&#125;</span>&quot;</span>)<br><br><span class="hljs-comment"># Train the model with the callback</span><br>model.fit(X_train, y_train, epochs=<span class="hljs-number">100</span>, batch_size=<span class="hljs-number">32</span>, validation_split=<span class="hljs-number">0.1</span>, callbacks=[PrintLossCallback()])<br><br><br><span class="hljs-comment"># Evaluate the model on the test set</span><br>y_pred = model.predict(X_test)<br>test_loss, test_accuracy = model.evaluate(X_test, y_test)<br>print(<span class="hljs-string">f&quot;Test Accuracy: <span class="hljs-subst">&#123;test_accuracy * <span class="hljs-number">100</span>:<span class="hljs-number">.2</span>f&#125;</span>%&quot;</span>)<br><br></code></pre></td></tr></table></figure></div><pre>Epoch 96/1004/4 [==============================] - 0s 3ms/step - loss: 0.2099 - accuracy: 0.9532 - val_loss: 0.3162 - val_accuracy: 0.9167Epoch 96, Loss: 0.21823757886886597, Accuracy: 0.9351851940155029Epoch 97/1004/4 [==============================] - 0s 3ms/step - loss: 0.2010 - accuracy: 0.9522 - val_loss: 0.3123 - val_accuracy: 0.9167Epoch 97, Loss: 0.21543042361736298, Accuracy: 0.9351851940155029Epoch 98/1004/4 [==============================] - 0s 3ms/step - loss: 0.2175 - accuracy: 0.9366 - val_loss: 0.3079 - val_accuracy: 0.9167Epoch 98, Loss: 0.21266280114650726, Accuracy: 0.9351851940155029Epoch 99/1004/4 [==============================] - 0s 3ms/step - loss: 0.2047 - accuracy: 0.9428 - val_loss: 0.3040 - val_accuracy: 0.9167Epoch 99, Loss: 0.20983757078647614, Accuracy: 0.9351851940155029Epoch 100/1004/4 [==============================] - 0s 3ms/step - loss: 0.2070 - accuracy: 0.9376 - val_loss: 0.3008 - val_accuracy: 0.9167Epoch 100, Loss: 0.20734088122844696, Accuracy: 0.9351851940155029</pre><table><thead><tr><th style="text-align:center"></th><th style="text-align:left"></th></tr></thead><tbody><tr><td style="text-align:center"><img src="https://imgur.com/X2jtXE1.png" alt="neural network predicted results"></td><td style="text-align:left"><br><br><br><br>In this group of test data, there are ony one mistake.</td></tr></tbody></table><p>Another regression example write by torch</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">from</span> torch.optim.lr_scheduler <span class="hljs-keyword">import</span> StepLR<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">create_sequential_layers</span>():</span><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Task: Create neural net layers using nn.Sequential.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Requirements: Return an nn.Sequential object, which contains:</span><br><span class="hljs-string">        1. a linear layer (fully connected) with 2 input features and 3 output features,</span><br><span class="hljs-string">        2. a sigmoid activation layer,</span><br><span class="hljs-string">        3. a linear layer with 3 input features and 5 output features.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    block = torch.nn.Sequential(<br>        torch.nn.Linear(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>),<br>        torch.nn.Sigmoid(),<br>        torch.nn.Linear(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>)<br>    )<br>    <span class="hljs-keyword">return</span> block<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">create_loss_function</span>():</span><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Task: Create a loss function using nn module.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Requirements: Return a loss function from the nn module that is suitable for</span><br><span class="hljs-string">    multi-class classification.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> torch.nn.MSELoss()<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">NeuralNet</span>(<span class="hljs-params">torch.nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Initialize your neural network here.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-comment">################# Your Code Starts Here #################</span><br>        self.conv1 = nn.Conv1d(in_channels=<span class="hljs-number">1</span>, out_channels=<span class="hljs-number">5</span>, kernel_size=<span class="hljs-number">5</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">2</span>)<br>        self.relu = nn.LeakyReLU()<br>        <span class="hljs-comment"># Adjust the following layer sizes based on the output of your convolutional layer</span><br>        self.fc1 = nn.Linear(<span class="hljs-number">5</span> * <span class="hljs-number">2883</span>, <span class="hljs-number">69</span>)  <span class="hljs-comment"># Adjusted for flattened conv output</span><br>        self.output = nn.Linear(<span class="hljs-number">69</span>, <span class="hljs-number">5</span>)<br>        <span class="hljs-comment">################## Your Code Ends here ##################</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Perform a forward pass through your neural net.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Parameters:</span><br><span class="hljs-string">            x:      an (N, input_size) tensor, where N is arbitrary.</span><br><span class="hljs-string">        Outputs:</span><br><span class="hljs-string">            y:      an (N, output_size) tensor of output from the network</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment">################# Your Code Starts Here #################</span><br>        x = x.view(x.size(<span class="hljs-number">0</span>), <span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># Apply Conv1d</span><br>        x = self.conv1(x)<br>        x = self.relu(x)<br>        <span class="hljs-comment"># Flatten the output for the linear layer</span><br>        x = x.view(x.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)<br>        x = self.fc1(x)<br>        x = self.relu(x)<br>        y_pred = self.output(x)<br>        <span class="hljs-keyword">return</span> y_pred<br>        <span class="hljs-comment">################## Your Code Ends here ##################</span><br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train</span>(<span class="hljs-params">train_dataloader, epochs</span>):</span><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    The autograder will call this function and compute the accuracy of the returned model.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Parameters:</span><br><span class="hljs-string">        train_dataloader:   a dataloader for the training set and labels</span><br><span class="hljs-string">        test_dataloader:    a dataloader for the testing set and labels</span><br><span class="hljs-string">        epochs:             the number of times to iterate over the training set</span><br><span class="hljs-string">    Outputs:</span><br><span class="hljs-string">        model:              trained model</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment">################# Your Code Starts Here #################</span><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Implement backward propagation and gradient descent here.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    device = <span class="hljs-string">&quot;cpu&quot;</span><br>    model = NeuralNet().to(device)<br>    loss_fn = torch.nn.CrossEntropyLoss()  <span class="hljs-comment"># Suitable for regression tasks</span><br>    optimizer = torch.optim.Adamax(params=model.parameters(), lr=<span class="hljs-number">0.001</span>)<br>    scheduler = StepLR(optimizer, step_size=<span class="hljs-number">500</span>, gamma=<span class="hljs-number">0.1</span>)  <span class="hljs-comment"># Learning rate scheduler</span><br>    epoch_count = []<br>    train_loss_values = []<br>    test_loss_values = []   <br><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):  <span class="hljs-comment"># Loop over the dataset multiple times</span><br>        running_loss = <span class="hljs-number">0.0</span><br>        <span class="hljs-keyword">for</span> inputs, labels <span class="hljs-keyword">in</span> train_dataloader:<br>            train_set, train_labels = inputs.to(device), labels.to(device)  <span class="hljs-comment"># Move inputs and labels to the device</span><br>            model.train()<br>            y_pred = model(train_set)<br>            loss = loss_fn(y_pred, train_labels) <br>            <span class="hljs-comment"># Zero gradients, perform a backward pass, and update the weights</span><br>            optimizer.zero_grad()<br>            loss.backward()<br>            optimizer.step()<br>            <span class="hljs-comment">#scheduler.step()  # Update the learning rate           </span><br>    <span class="hljs-comment">################## Your Code Ends here ##################</span><br>    <span class="hljs-keyword">return</span> model<br></code></pre></td></tr></table></figure></div><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Multi-layer Neural Nets</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Class" scheme="https://karobben.github.io/categories/Notes/Class/"/>
    
    <category term="UIUC" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/"/>
    
    <category term="AI" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/AI/"/>
    
    
    <category term="Machine Learning" scheme="https://karobben.github.io/tags/Machine-Learning/"/>
    
    <category term="Data Science" scheme="https://karobben.github.io/tags/Data-Science/"/>
    
  </entry>
  
  <entry>
    <title>Hidden Markov Model</title>
    <link href="https://karobben.github.io/2024/02/12/LearnNotes/ai-hmm/"/>
    <id>https://karobben.github.io/2024/02/12/LearnNotes/ai-hmm/</id>
    <published>2024-02-12T06:59:06.000Z</published>
    <updated>2024-02-16T08:43:53.706Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://imgur.com/oMmL1Ln.png" alt=""></p><p>A Hidden Markov Model is a Bayes Network with these assumptions:<br>• <em>Y<sub>t</sub></em> depends only on <em>Y<sub>t-1</sub></em><br>• <em>X<sub>t</sub></em> depends only on <em>Y<sub>t</sub></em></p><p>The belief network conveys the independence assumption:<br>$$<br>for\ all\ i \geq 0, P(S_{i+1}|S_i) = P (S_1|S_0)<br>$$</p><p>$$<br>P(S_i = s) = \sum_{s’} P(S_{i+1} = s \mid S_i = s’) * P(S_i = s’)<br>$$</p><p>In the context of the equation you’re referring to, $ s $ and $ s’ $ represent states in a Markov chain. Typically, $ s $ is used to denote the current state, while $ s’ $ (read as “s prime”) denotes a subsequent or different state that the system can transition into from the current state $ s $.</p><p>The summation over $ s’ $ in the equation indicates that you’re summing over all possible subsequent states that the system can transition to from the current state $ s $. This is part of the definition of a stationary distribution for a Markov chain, where the probability of being in any given state $ s $ is equal to the sum of the probabilities of transitioning to state $ s $ from all possible previous states $ s’ $, weighted by the probability of being in state $ s’ $ at the previous time step.</p><h3 id="Key-advantage-of-a-hidden-Markov-model-Polynomial-time-complexity">Key advantage of a hidden Markov model: Polynomial-time complexity</h3><ul><li>Suppose there are <em>|y|</em> different speech sounds in English, and the length of the utterance is <em>d</em> centiseconds (<em>|y| ≈ 50, d ≈ 100</em>)</li><li>Without the HMM assumptions, to compute <em>f(x)= argmaxP(y<sub>1</sub>, … , y<sub>d</sub>|x<sub>1</sub>, … , x<sub>d</sub>)</em> requires a time complexity of<br><em>O{|y|<sup>d</sup>} ≈ 50<sup>100</sup></em></li><li>With an HMM, each variable has only one parent, so inference is <em>O{|y|<sup>d</sup>} ≈ 50<sup>2</sup></em></li><li>The computationally efficient algorithm that we use to compute <em>f(x)= argmaxP(y<sub>1</sub>, … , y<sub>d</sub>|x<sub>1</sub>, … , x<sub>d</sub>)</em> is called the Viterbi algorithm, named after the electrical engineer who first applied it to error correction coding.</li></ul><div class="admonition note"><p class="admonition-title">it works much better than bayes</p><p>Text generated by a naïve Bayes model (unigram model):</p><ul><li>Representing and speedily is an good apt or come can different natural here he the a in came the to of to expert gray come to furnishes the line message had be these…</li></ul><p>Text generated by a HMM (bigram model):</p><ul><li>The head and in frontal attack on an English writer that the character of this point is therefore another for the letters that the time of who ever told the problem for an unexpected…</li></ul></div><h3 id="Applications-of-HMMs">Applications of HMMs</h3><ul><li>Speech recognition HMMs:<ul><li>Observations are acoustic signals (continuous valued)</li><li>States are specific positions in specific words (so, tens of thousands)</li></ul></li><li>Machine translation HMMs:<ul><li>Observations are words (tens of thousands)</li><li>States are cross-lingual alignments</li></ul></li><li>Robot tracking:<ul><li>Observations are range readings (continuous)</li><li>States are positions on a map</li></ul></li></ul><h3 id="Viterbi-Algorithm">Viterbi Algorithm</h3><p>The Viterbi algorithm is a computationally efficient algorithm for computing the maximum a posteriori (MAP) state sequence<br>$$<br>f(x)= argmax_{y_1, … , y_d}P(y_1, … , y_d|x_1, … , x_d)<br>$$</p><h3 id="Notation">Notation</h3><ul><li><p>Initial State Probability:</p><ul><li>$ \pi_i = P(Y_1 = i)$</li></ul></li><li><p>Transition Probability:</p><ul><li>$a_{i,j} = P(Y_t=j| Y_{t-1} = i)$</li></ul></li><li><p>Observation Probabilities:</p><ul><li>$b_j(x_t) = P(X_t = x_t|Y_t=j)$</li></ul></li><li><p>Node Probability: Probability of the best path until node $ j $ at time $ t $</p></li></ul><p>$$<br>v_t(j) = \max_{y_1,…,y_{t-1}} P(Y_1 = y_1 ,…, Y_{t-1} = y_{t-1}, Y_t = j, X_0 = x_0, …, X_t = x_t)<br>$$</p><ul><li>Backpointer: which node precedes node $ j $ on the best path?</li></ul><p>$$<br>\psi_t(j) = \arg\max_{y_{t-1}} \max_{y_1,…,y_{t-2}} P(Y_1 = y_1 ,…, Y_{t-1} = y_{t-1}, Y_t = j, X_0 = x_0, …, X_t = x_t)<br>$$</p><h3 id="How-HMM-Worked">How HMM Worked</h3><p>Initiation → Iteration → Termination → Back-Tracing</p><ul><li>Initiation<br>$v_1(i) = \pi_ib_i(x_1)$</li><li>Iteration<br>$v_t(j) = max v_{t-1}(i)a_{i,j}b_j(x_t)$</li><li>Termination<br>$y_d = argmax v_d{i}$</li><li>Back-Tracing<br>$y_t = \psi_{t+1}(y_{t+1})$</li></ul><h3 id="Example-Question">Example Question</h3><p>Richard Feynman is an AI. He cannot see the weather, but he can see whether or not his creator, Elspeth Dunsany, brings an umbrella to work. Let $ R_t $ denote the event “it is raining on day $ t $,” and let $ U_t $ denote the event “Dr. Dunsany brings her umbrella on day $ t $.” Dr. Dunsany is an absent-minded professor; she often brings her umbrella when it’s not raining, and often forgets her umbrella when it’s raining. Richard’s model of Dr. Dunsany’s behavior includes the parameter $ P(R_1 = T) = 0.5 $, and the parameters shown in the tables below. What is $ P(R_2 = F, U_1 = T, U_2 = T) $?</p><table><thead><tr><th style="text-align:center">$ P(R_t = T | R_{t-1} = r_{t-1}) $</th><th style="text-align:center">$ r_{t-1} = F $</th><th style="text-align:center">$ r_{t-1} = T $</th></tr></thead><tbody><tr><td style="text-align:center">$ r_t = F $</td><td style="text-align:center">0.4</td><td style="text-align:center">0.1</td></tr><tr><td style="text-align:center">$ r_t = T $</td><td style="text-align:center">0.8</td><td style="text-align:center">0.7</td></tr></tbody></table><table><thead><tr><th style="text-align:left">$P(U_t = T | R_t = r_t)$</th><th style="text-align:center">$r_t = F$</th><th style="text-align:center">$r_t = T$</th></tr></thead><tbody><tr><td style="text-align:left">$ r_{t-1} = F $</td><td style="text-align:center">0.4</td><td style="text-align:center">0.1</td></tr><tr><td style="text-align:left">$ r_{t-1} = T $</td><td style="text-align:center">0.8</td><td style="text-align:center">0.7</td></tr></tbody></table><ul><li><p>Initial State Probability:</p><ul><li>$ P(R_1 = T) = 0.5 $</li></ul></li><li><p>Transition Probabilities:</p><ul><li>$ P(R_t = T | R_{t-1} = F) = 0.8 $</li><li>$ P(R_t = T | R_{t-1} = T) = 0.7 $</li><li>$ P(R_t = F | R_{t-1} = F) = 0.4 $</li><li>$ P(R_t = F | R_{t-1} = T) = 0.1 $</li></ul></li><li><p>Observation Probabilities (Probability of Dr. Dunsany bringing her umbrella given the weather):</p><ul><li>$ P(U_t = T | R_t = F) = 0.4 $ (Probability she brings an umbrella when it’s not raining)</li><li>$ P(U_t = T | R_t = T) = 0.1 $ (Probability she brings an umbrella when it is raining)</li></ul></li></ul><p>These probabilities define the initial state distribution, the transition dynamics, and the observation model of a system, which are essential components of probabilistic models like Hidden Markov Models (HMMs).</p><p>The scenario you’ve presented involves conditional probabilities and is a typical example used in Bayesian inference or probabilistic models. Given the information in the image, we can calculate the probability that Dr. Dunsany brings her umbrella on day 2 given that it’s not raining on day 2, but it was raining on day 1.</p><p>The information given includes:</p><ol><li>The initial probability that it’s raining on day 1: $ P(R_1 = T) = 0.5 $</li><li>The conditional probabilities of bringing an umbrella given the weather:<ul><li>$ P(R_t = T | R_{t-1} = r_{t-1}) $: The probability that Dr. Dunsany brings an umbrella on day $ t $ given the weather on day $ t-1 $.</li><li>$ P(U_t = T | R_t = r_t) $: The probability that Dr. Dunsany brings an umbrella on day $ t $ given the weather on day $ t $.</li></ul></li></ol><p>With the tables provided, we can calculate the probability that Dr. Dunsany brings her umbrella on day 2 given the conditions specified.</p><p>We can apply the law of total probability to consider all possible weather scenarios from the previous day. Here is the formula based on the total probability theorem:</p><p>$ P(R_2 = F, U_1 = T, U_2 = T) = \\<br>\sum_{r_{t-1} \in {T, F}} P(R_2 = F | R_1 = r_{t-1}) \cdot P(U_1 = T | R_1 = r_{t-1}) \cdot P(U_2 = T | R_2 = F)<br>$</p><p>We would then substitute the values from the tables into the formula to calculate the desired probability. Would you like to proceed with this calculation?</p><style>pre {  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Hidden Markov Model</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Class" scheme="https://karobben.github.io/categories/Notes/Class/"/>
    
    <category term="UIUC" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/"/>
    
    <category term="AI" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/AI/"/>
    
    
    <category term="Machine Learning" scheme="https://karobben.github.io/tags/Machine-Learning/"/>
    
    <category term="Data Science" scheme="https://karobben.github.io/tags/Data-Science/"/>
    
  </entry>
  
  <entry>
    <title>Basic Mathematics Calculating</title>
    <link href="https://karobben.github.io/2024/02/11/LearnNotes/math-cal/"/>
    <id>https://karobben.github.io/2024/02/11/LearnNotes/math-cal/</id>
    <published>2024-02-12T04:58:46.000Z</published>
    <updated>2024-02-14T06:03:37.897Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Sum">Sum</h2><p>The sum symbol, represented by the Greek letter sigma (Σ), is widely used in mathematics to denote the summation of a sequence of numbers or expressions. When you see this symbol, it means you should add up a series of numbers according to the specified rule. Here’s a breakdown of how it’s typically used:</p><h3 id="Basic-Structure">Basic Structure</h3><p>The summation symbol is written as:</p><p>$$<br>\sum_{i=a}^{b} f(i)<br>$$</p><p>where:</p><ul><li>$i$ is the index of summation, which takes on each integer value from $a$ to $b$, inclusive.</li><li>$a$ is the lower limit of summation, the starting value of $i$.</li><li>$b$ is the upper limit of summation, the ending value of $i$.</li><li>$f(i)$ is the function of $i$ to be summed over the range from $a$ to $b$.</li></ul><h3 id="Examples">Examples</h3><ol><li><p><strong>Sum of the first 5 natural numbers</strong>:<br>$$<br>\sum_{i=1}^{5} i = 1 + 2 + 3 + 4 + 5 = 15<br>$$<br>Here, $f(i) = i$, and you sum the values of $i$ from 1 to 5.</p></li><li><p><strong>Sum of the squares of the first 3 positive integers</strong>:<br>$$<br>\sum_{i=1}^{3} i^2 = 1^2 + 2^2 + 3^2 = 1 + 4 + 9 = 14<br>$$<br>In this example, $f(i) = i^2$, so you square each $i$ from 1 to 3 and then add them together.</p></li><li><p><strong>Sum of a constant over a range</strong>:<br>Suppose you want to add the number 4, five times. The expression would be:<br>$$<br>\sum_{i=1}^{5} 4 = 4 + 4 + 4 + 4 + 4 = 20<br>$$</p><p>Here, $f(i) = 4$, which doesn’t depend on $i$. You’re essentially multiplying 4 by the number of terms (5 in this case).</p></li><li><p><strong>Two sums</strong><br>$$<br>\sum_{i=1}^ {5}\sum_{j=2}^ {6} ij<br>$$<br>For this, you sum over $j$ from 2 to 6 for each value of $i$ from 1 to 5, and then sum those results. It’s like computing a series within another series. The operation proceeds as follows:</p><ol><li>First, fix $i$ at its starting value, 1.</li><li>Then, for $i = 1$, sum over $j$ from 2 to 6, calculating $1 \cdot j$ for each $j$ and adding them together.</li><li>Repeat this process for each value of $i$ up to 5.</li><li>Finally, sum all the results from the inner summations together.</li></ol><p>Let’s compute this step-by-step to see the result.<br>The result of the double summation $\sum_{i=1}^ {5}\sum_{j=2}^ {6} ij$ is 300. This means that when you sum the product of $i$ and $j$ for each $i$ from 1 to 5 and each $j$ from 2 to 6, the total sum is 300.<br>PS: in python:</p> <div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python">N= <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">6</span>):<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>,<span class="hljs-number">7</span>):<br>        N += i*j<br></code></pre></td></tr></table></figure></div></li></ol><h3 id="How-to-Use">How to Use</h3><ul><li><strong>Identify the sequence</strong> you need to sum. This could be a series of numbers, functions of an index, or even a constant value repeated several times.</li><li><strong>Determine the starting and ending indices</strong> ($a$ and $b$, respectively) for your summation.</li><li><strong>Write down the function or value</strong> to be summed as $f(i)$ for each $i$ in the range from $a$ to $b$.</li><li><strong>Compute each term</strong> in the series and <strong>add them together</strong> to find the total sum.</li></ul><p>Summation notation is a powerful tool in mathematics, especially for dealing with sequences and series, and it’s widely used in various fields such as statistics, physics, and finance.</p><h2 id="Product-Notation">Product Notation</h2><p>Similarly, we have <mark>product notation</mark>, too. The product symbol is represented by the Greek letter pi (Π), not to be confused with the mathematical constant $\pi$ (pi) used for the ratio of a circle’s circumference to its diameter. The product symbol is used to denote the multiplication of a sequence of numbers or expressions, just like the sum symbol is used for addition.</p><p>$$<br>\prod_{i=a}^{b} f(i)<br>$$</p><p>where:</p><ul><li>$i$ is the index of multiplication, taking on each integer value from $a$ to $b$, inclusive.</li><li>$a$ is the lower limit of the product, the starting value of $i$.</li><li>$b$ is the upper limit of the product, the ending value of $i$.</li><li>$f(i)$ is the function of $i$ to be multiplied over the range from $a$ to $b$.</li></ul><h3 id="Examples-v2">Examples</h3><ol><li><p><strong>Product of the first 5 natural numbers</strong> (also known as $5!$, factorial of 5):</p><p>$$<br>\prod_{i=1}^{5} i = 1 \times 2 \times 3 \times 4 \times 5 = 120<br>$$</p><p>This multiplies the values of $i$ from 1 to 5.</p></li></ol><p>In mathematics and particularly in machine learning, besides the summation (Σ) and product (Π) notations, another frequently used notation is the integral symbol (∫). While the summation and product notations deal with discrete sequences, the integral symbol is used for continuous functions and is fundamental in calculus. Integrals play a crucial role in various aspects of machine learning, especially in optimization, probability distributions, and understanding the area under curves (such as ROC curves).</p><h2 id="Integral-Notation">Integral Notation</h2><p>The basic structure of an integral is:</p><p>$$<br>\int_{a}^{b} f(x) , dx<br>$$</p><p>where:</p><ul><li>$a$ and $b$ are the lower and upper limits of integration, respectively, defining the interval over which the function $f(x)$ is integrated.</li><li>$f(x)$ is the function to be integrated over $x$.</li><li>$dx$ represents an infinitesimally small increment of $x$, indicating that the integration is performed with respect to $x$.</li></ul><h3 id="Importance-in-Machine-Learning">Importance in Machine Learning</h3><ol><li><p><strong>Optimization</strong>: Many machine learning models involve optimization problems where the goal is to minimize or maximize some function (e.g., a loss function in neural networks or a cost function in logistic regression). Integrals are essential in solving continuous optimization problems, especially when calculating gradients or understanding the behavior of functions over continuous intervals.</p></li><li><p><strong>Probability Distributions</strong>: In the context of probabilistic models and statistics, integrals are used to calculate probabilities, expected values, and variances of continuous random variables. For example, the area under the probability density function (PDF) of a continuous random variable over an interval gives the probability of the variable falling within that interval.</p></li><li><p><strong>Feature Extraction and Signal Processing</strong>: In machine learning applications involving signal processing or feature extraction from continuous data, integrals are used to calculate various features and transform signals into more useful forms.</p></li><li><p><strong>Kernel Methods</strong>: In machine learning, kernel methods (e.g., support vector machines) utilize integrals in the formulation of kernel functions, which are essential in mapping input data into higher-dimensional spaces for classification or regression tasks.</p></li><li><p><strong>Deep Learning</strong>: In the training of deep neural networks, integrals may not be explicitly visible but are conceptually present in the form of continuous optimization and in the calculation of gradients during backpropagation.</p></li></ol><h3 id="Example">Example</h3><p>Consider the problem of finding the area under a curve, which is a fundamental concept in machine learning for evaluating model performance (e.g., calculating the area under the ROC curve (AUC) for classification problems). If $f(x)$ represents the curve, the area under $f(x)$ from $a$ to $b$ can be computed by the integral:</p><p>$$<br>\text{Area} = \int_{a}^{b} f(x) , dx<br>$$</p><h2 id="Other-Frequently-Used-Notations">Other Frequently Used Notations</h2><p>This integral computes the total area under $f(x)$ between $a$ and $b$, providing a measure of the model’s performance over that interval.</p><p>Integrals, along with summation and product notations, form the backbone of many mathematical operations in machine learning, from theoretical underpinnings to practical applications in data analysis, model evaluation, and optimization strategies.</p><p>Beyond summation (Σ), product (Π), and integral (∫) notations, there are several other mathematical symbols and concepts that are frequently used in machine learning and statistics. These include:</p><h3 id="Gradient-∇">Gradient (∇)</h3><p>The gradient is a vector operation that represents the direction and rate of the fastest increase of a scalar function. In machine learning, the gradient is crucial for optimization algorithms like gradient descent, which is used to minimize loss functions. The gradient of a function $f(x_1, x_2, \ldots, x_n)$ with respect to its variables is denoted by:</p><p>$$<br>\nabla f = \left( \frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, \ldots, \frac{\partial f}{\partial x_n} \right)<br>$$</p><h3 id="Partial-Derivative-∂">Partial Derivative (∂)</h3><p>The partial derivative represents the rate of change of a function of multiple variables with respect to one of those variables, keeping the others constant. It’s denoted by the symbol ∂. Partial derivatives are essential in the calculation of gradients and in the optimization of machine learning models.</p><h3 id="Expectation-E">Expectation (E)</h3><p>The expectation or expected value of a random variable is a fundamental concept in probability and statistics, denoted by $E[X]$ for a random variable $X$. It represents the average or mean value that $X$ takes over its probability distribution and is crucial in understanding the behavior of models, especially in probabilistic settings.</p><h3 id="Variance-Var-and-Standard-Deviation-σ">Variance (Var) and Standard Deviation (σ)</h3><p>Variance measures the spread of a random variable’s values and is denoted by $Var(X)$ or $\sigma^2$ for a random variable $X$. The standard deviation, $\sigma$, is the square root of the variance and provides a measure of the dispersion of data points around their mean value. These concepts are vital in assessing the reliability and performance of models.</p><h3 id="Covariance-and-Correlation">Covariance and Correlation</h3><p>Covariance and correlation measure the relationship between two random variables. Covariance indicates the direction of the linear relationship between variables, while correlation measures both the strength and direction of this linear relationship. Understanding these relationships is essential in features selection and in modeling the interactions between variables.</p><h3 id="Big-O-Notation-O">Big O Notation (O)</h3><p>Big O notation is used to describe the computational complexity of algorithms, which is crucial in machine learning for understanding the scalability and efficiency of models and algorithms. For example, an algorithm with a complexity of $O(n^2)$ means its execution time or space requirements increase quadratically as the input size $n$ increases.</p><h3 id="Matrix-Notations-and-Operations">Matrix Notations and Operations</h3><p>Matrices and vectors are fundamental in machine learning for representing and manipulating data. Operations such as matrix multiplication, transpose, and inversion are essential for linear algebra, which underpins many machine learning algorithms, including neural networks, PCA (Principal Component Analysis), and SVMs (Support Vector Machines).</p><p>Each of these mathematical concepts plays a crucial role in the formulation, analysis, and implementation of machine learning algorithms. They provide the theoretical foundation for understanding model behavior, optimizing performance, and evaluating outcomes in a wide range of applications.</p><h2 id="Matrix-Calculating">Matrix Calculating</h2><p>Matrix multiplication is a fundamental operation in linear algebra with extensive applications in mathematics, physics, engineering, computer science, and particularly in machine learning and data analysis. The way matrix multiplication is defined—by taking the dot product of rows and columns—might seem arbitrary at first, but it’s designed to capture several important mathematical and practical concepts.</p><p>Understanding how to perform basic operations with matrices—addition, subtraction, multiplication, and division (in a sense)—is crucial in linear algebra, which is foundational for many areas of mathematics, physics, engineering, and especially machine learning. Here’s a brief overview of each operation:</p><p>$$<br>\begin{pmatrix}<br>a_{11} &amp; \cdots &amp; a_{1j} \\<br>\vdots &amp; \ddots &amp; \vdots \\<br>a_{i1} &amp; \cdots &amp; a_{ij}<br>\end{pmatrix}<br>$$</p><p>Each element within the matrix is a pair $(i,j)$, where $i$ is the row index and $j$ is the column index.</p><h3 id="Matrix-Addition-and-Subtraction">Matrix Addition and Subtraction</h3><p>Matrix addition and subtraction are straightforward operations that are performed element-wise. This means you add or subtract the corresponding elements of the matrices. For these operations to be defined, the matrices must be of the same dimensions.</p><ul><li><p><strong>Addition</strong>: If $A$ and $B$ are matrices of the same size, their sum $C = A + B$ is a matrix where each element $c_{ij}$ is the sum of $a_{ij} + b_{ij}$.</p></li><li><p><strong>Subtraction</strong>: Similarly, the difference $C = A - B$ is a matrix where each element $c_{ij}$ is the difference $a_{ij} - b_{ij}$.</p></li></ul><h4 id="Example-v2">Example:</h4><p>If $A = \begin{pmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{pmatrix}$ and $B = \begin{pmatrix} 5 &amp; 6 \\ 7 &amp; 8 \end{pmatrix}$, then</p><ul><li>$A + B = \begin{pmatrix} 1+5 &amp; 2+6 \\ 3+7 &amp; 4+8 \end{pmatrix} = \begin{pmatrix} 6 &amp; 8 \\ 10 &amp; 12 \end{pmatrix}$</li><li>$A - B = \begin{pmatrix} 1-5 &amp; 2-6 \\ 3-7 &amp; 4-8 \end{pmatrix} = \begin{pmatrix} -4 &amp; -4 \\ -4 &amp; -4 \end{pmatrix}$</li></ul><h3 id="Matrix-Multiplication">Matrix Multiplication</h3><p>Matrix multiplication is more complex and involves a dot product of rows and columns. For two matrices $A$ and $B$ to be multiplied, the number of columns in $A$ must equal the number of rows in $B$. If $A$ is an $m \times n$ matrix and $B$ is an $n \times p$ matrix, the resulting matrix $C = AB$ will be an $m \times p$ matrix where each element $c_{ij}$ is computed as the dot product of the $i$th row of $A$ and the $j$th column of $B$.</p><h4 id="Example-v3">Example:</h4><p>If $A = \begin{pmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{pmatrix}$ and $B = \begin{pmatrix} 5 &amp; 6 \\ 7 &amp; 8 \end{pmatrix}$, then</p><ul><li>$AB = \begin{pmatrix} (1× 5 + 2× 7) &amp; (1× 6 + 2× 8) \\ (3× 5 + 4× 7) &amp; (3× 6 + 4× 8) \end{pmatrix} = \begin{pmatrix} 19 &amp; 22 \\ 43 &amp; 50 \end{pmatrix}$</li></ul><h3 id="Matrix-Division">Matrix Division</h3><p>Matrix division as such doesn’t exist in the way we think of division for real numbers. Instead, we talk about the inverse of a matrix. For matrix $A$ to “divide” another matrix $B$, you would multiply $B$ by the inverse of $A$, denoted as $A^{-1}$. This operation is only defined for square matrices (same number of rows and columns), and not all square matrices have an inverse.</p><ul><li><strong>Multiplying by the Inverse</strong>: If you want to solve for $X$ in $AX = B$, you can multiply both sides by $A^{-1}$, assuming $A^{-1}$ exists, to get $X = A^{-1}B$.</li></ul><h4 id="Example-v4">Example:</h4><p>If $A = \begin{pmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{pmatrix}$, and its inverse $A^{-1} = \begin{pmatrix} -2 &amp; 1 \\ 1.5 &amp; -0.5 \end{pmatrix}$, and you want to “divide” $B = \begin{pmatrix} 5 &amp; 6 \\ 7 &amp; 8 \end{pmatrix}$ by $A$, you would compute $A^{-1}B$.</p><h3 id="Key-Points">Key Points</h3><ul><li><strong>Addition/Subtraction</strong>: Element-wise operation requiring matrices of the same dimensions.</li><li><strong>Multiplication</strong>: Involves the dot product of rows and columns, requiring the number of columns in the first matrix to equal the number of rows in the second.</li><li><strong>Division</strong>: Not directly defined, but involves multiplying by the inverse of a matrix.</li></ul><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Basic Mathematics Calculating</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>Perceptron</title>
    <link href="https://karobben.github.io/2024/02/07/AI/ai-perceptron/"/>
    <id>https://karobben.github.io/2024/02/07/AI/ai-perceptron/</id>
    <published>2024-02-07T19:03:23.000Z</published>
    <updated>2024-06-01T00:27:21.427Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Perceptron">Perceptron</h2><p>Perceptron is invented before the loss function</p><h2 id="Linear-classifier-Definition">Linear classifier: Definition</h2><p>A linear classifier is defined by</p><p>$$<br>f(x) = \text{argmax } Wx + b<br>$$</p><p>$$ W \mathbf{x} + \mathbf{b} =  \begin{bmatrix} W_{1,1} &amp; \cdots &amp; W_{1,d} \\ \vdots &amp; \ddots &amp; \vdots \\ W_{v,1} &amp; \cdots &amp; W_{v,d} \end{bmatrix} \begin{bmatrix} x_1 \\ \vdots \\ x_d \end{bmatrix} + \begin{bmatrix} b_1 \\ \vdots \\ b_v \end{bmatrix} = \begin{bmatrix} \mathbf{w}_1^T \mathbf{x} + b_1 \\ \vdots \\ \mathbf{w}_v^T \mathbf{x} + b_v \end{bmatrix}<br>$$</p><p>where:</p><p>$w_k, b_k$ are the weight vector and bias corresponding to class $k$, and the argmax function finds the element of the vector $wx$ with the largest value.</p><table><thead><tr><th style="text-align:left">Multi-class linear classifier</th><th style="text-align:left"></th></tr></thead><tbody><tr><td style="text-align:left"><img src="https://imgur.com/TNWvhKX.png" alt=""></td><td style="text-align:left">$ f(\mathbf{x}) = \arg\max (W\mathbf{x} + \mathbf{b}) $ <br>The boundary between class ( k ) and class ( l ) is the line (or plane, or hyperplane) given by the equation: <li>$ (\mathbf{w}_k - \mathbf{w}_l)^T \mathbf{x} + (b_k - b_l) = 0 $</td></tr></tbody></table><h2 id="Gradient-descent">Gradient descent</h2><p>Suppose we have training tokens $(x_i, y_i)$, and we have some initial class vectors $w_1$ and $w_2$. We want to update them as</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center">$w_1 \leftarrow w_1 - \eta \frac{\partial \mathcal{L}}{\partial w_1}$<br>$w_2 \leftarrow w_2 - \eta \frac{\partial \mathcal{L}}{\partial w_2}$ <br> …where $\mathcal{L}$ is some loss function. What loss function makes sense?</td><td style="text-align:center"><img src="https://imgur.com/YaSOBI6.png" alt=""></td></tr></tbody></table><h2 id="Zero-one-loss-function">Zero-one loss function</h2><p>The most obvious loss function for a classifier is its classification error rate,</p><p>$$<br>\mathcal{L} = \frac{1}{n} \sum_{i=1}^{n} \ell(f(x_i), y_i)<br>$$</p><p>Where $\ell(\hat{y}, y)$ is the zero-one loss function,</p><p>$$<br>\ell(f(x), y) =<br>\begin{cases}<br>0 &amp; \text{if } f(x) = y \\<br>1 &amp; \text{if } f(x) \neq y<br>\end{cases}<br>$$</p><h3 id="Non-differentiable">Non-differentiable!</h3><p>The problem with the zero-one loss function is that it’s not differentiable:</p><p>$$<br>\frac{\partial \ell (f(\mathbf{x}), y)}{\partial f(\mathbf{x})} =<br>\begin{cases}<br>0 &amp; f(\mathbf{x}) \neq y \\<br>+\infty &amp; f(\mathbf{x}) = y^+ \\<br>-\infty &amp; f(\mathbf{x}) = y^-<br>\end{cases}<br>$$</p><h2 id="One-hot-vectors">One-hot vectors</h2><p>One-hot vectors, A <strong>one-hot vector</strong> is a binary vector in which all elements are 0 except for a single element that’s equal to 1.</p><p>Take binary classification as an example:</p><ul><li>class1: [1, 0]</li><li>class2: [0, 1]</li></ul><p>The number of element in the list equals the number of classes.</p><p>Consider the classifier</p><p>$$<br>f(x) =  \begin{bmatrix}<br>f_1(\mathbf{x}) \\<br>f_2(\mathbf{x})<br>\end{bmatrix} = \begin{bmatrix}<br>\mathbb{1}_ {\arg\max W\mathbf{x}=1} \\<br>\mathbb{1}_ {\arg\max W\mathbf{x}=2}<br>\end{bmatrix}<br>$$</p><p>…where (\mathbb{1}_P) is called the “indicator function,” and it means:</p><p>$$<br>\mathbb{1}_P =<br>\begin{cases}<br>1 &amp; P \text{ is true} \\<br>0 &amp; P \text{ is false}<br>\end{cases}<br>$$</p><h3 id="Loss">Loss</h3><h2 id="The-perceptron-loss">The perceptron loss</h2><p>Instead of a one-zero loss, the perceptron uses a weird loss function that gives great results when differentiated. The perceptron loss function is:</p><p>$$<br>\ell(\mathbf{x}, \mathbf{y}) = (f(\mathbf{x}) - \mathbf{y})^T (W \mathbf{x} + \mathbf{b})<br>$$</p><p>$$<br>= [f_1(\mathbf{x}) - y_1, \cdots, f_v(\mathbf{x}) - y_v]  \begin{pmatrix} \begin{bmatrix}<br>W_{1,1} &amp; \cdots &amp; W_{1,d} \\<br>\vdots &amp; \ddots &amp; \vdots \\<br>W_{v,1} &amp; \cdots &amp; W_{v,d}<br>\end{bmatrix}<br>\begin{bmatrix}<br>x_1 \\<br>\vdots \\<br>x_d<br>\end{bmatrix}<br>+<br>\begin{bmatrix}<br>b_1 \\<br>\vdots \\<br>b_v<br>\end{bmatrix}<br>\end{pmatrix}<br>$$</p><p>$$<br>= \sum_{k=1}^{v} (f_k(\mathbf{x}) - y_k)(\mathbf{w}_k^T \mathbf{x} + b_k)<br>$$</p><h2 id="The-perceptron-learning-algorithm">The perceptron learning algorithm</h2><ol><li><p>Compute the classifier output $\hat{y} = \arg\max_k (\mathbf{w}_k^T \mathbf{x} + b_k)$</p></li><li><p>Update the weight vectors as:</p></li></ol><p>$$<br>\mathbf{w}_k \leftarrow \mathbf{w}_k - \eta \frac{\partial \ell(\mathbf{x}, \mathbf{y})}{\partial \mathbf{w}_k} =<br>\begin{cases}<br>\mathbf{w}_k - \eta \mathbf{x} &amp; \text{if } k = \hat{y} \\<br>\mathbf{w}_k + \eta \mathbf{x} &amp; \text{if } k = y \\<br>0 &amp; \text{otherwise}<br>\end{cases}<br>$$</p><p>where $\eta \approx 0.01$ is the learning rate.</p><p>Because:</p><p>Because teh gradient of the perceptron loss is:</p><p>$$<br>\frac{\partial \ell(\mathbf{x}, \mathbf{y})}{\partial \mathbf{w}_k} =<br>\begin{cases}<br>\mathbf{x} &amp; \text{if } k = \hat{y} \\<br>-\mathbf{x} &amp; \text{if } k = y \\<br>0 &amp; \text{otherwise}<br>\end{cases}<br>$$</p><p>So, we could have:</p><p>$$<br>\mathbf{w}_k \leftarrow<br>\begin{cases}<br>\mathbf{w}_k - \eta \mathbf{x} &amp; k = \hat{y} \\<br>\mathbf{w}_k + \eta \mathbf{x} &amp; k = y \\<br>0 &amp; \text{otherwise}<br>\end{cases}<br>$$</p><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Perceptron</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Class" scheme="https://karobben.github.io/categories/Notes/Class/"/>
    
    <category term="UIUC" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/"/>
    
    <category term="AI" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/AI/"/>
    
    
    <category term="Machine Learning" scheme="https://karobben.github.io/tags/Machine-Learning/"/>
    
    <category term="Data Science" scheme="https://karobben.github.io/tags/Data-Science/"/>
    
  </entry>
  
  <entry>
    <title>FLUORESCENCE SPECTROSCOPY</title>
    <link href="https://karobben.github.io/2024/02/06/LearnNotes/fluorescence/"/>
    <id>https://karobben.github.io/2024/02/06/LearnNotes/fluorescence/</id>
    <published>2024-02-06T07:22:42.000Z</published>
    <updated>2024-02-09T02:16:47.409Z</updated>
    
    <content type="html"><![CDATA[<h2 id="FLUORESCENCE-SPECTROSCOPY">FLUORESCENCE SPECTROSCOPY</h2><div class="admonition note"><p class="admonition-title">What happens after the molecule is excited?</p><p><img src="https://imgur.com/nD2T2sw.png" alt="" />Fluorescence properties depend on what happens to the molecule during the ~10-8 sec during which it is excited. The decay after absorption includes 1. radiative decay ($K_f$) 2. Non-radiative decay($k_NR$)<br>Fluorescence happens very fast because it back to the ground state very fast. In general, the decay brings the electron from excited state to the ground state (decay defines as events per sec ($k_f$))<br>Nan-radiative decay (exp: form of heat), the decay faster and does not generate photon. The energy transfer into solid molecules and spreed away. They don't went to exited state and generate photons.</p></div><ul><li>the quantum yields for phosphorescence are usually very low because <mark>the radiative decay rates are slow compared to typical nonradiative rates</mark> and quenching processes<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>.</li></ul><h3 id="What-are-the-processes-of-non-radiative-decay">What are the processes of non-radiative decay?</h3><table><thead><tr><th style="text-align:center"></th><th style="text-align:left">Unit: sec<sup>-1</sup></th></tr></thead><tbody><tr><td style="text-align:center"><img src="https://imgur.com/uYOhyLM.png" alt=""></td><td style="text-align:left">Black = Non-radiative<br> Red = Radiative (photon)<br> ABS = absorption (10<sup>15</sup>)<br><strong>IC</strong> = internal conversion <br> (k<sub>IC</sub> ≈ 10<sup>11~12</sup>)<br> <strong>Q</strong> = quenching<br><strong>IX</strong>=intersystem crossing<br>S<sub>1</sub>→T<sub>0</sub>: 10<sup>8</sup>; T<sub>1</sub>→S<sub>0</sub>: 10<sup>2</sup><br> <strong>Chem</strong>=photochemistry<br>k<sub>f</sub> ≈ 10<sup>8</sup>; k<sub>p</sub> ≈ 10<sup>2</sup><br> <strong>F</strong> = fluorescence<br> <strong>P</strong> = phosphorescence<br> Trans = energy transfer<br>k<sub>collision</sub> ≈ 10<sup>10</sup> M<sup>-1</sup>sec<sup>-1</sup></td></tr></tbody></table><p>Only apart of electron went to the S<sub>1</sub> and they decay back to the ground state to generate fluorescence. Most of them when to S<sub>2</sub> and decay faster., In this case, less energy lost through fluorescence. Those change are internal Change. When they when to T<sub>1</sub> it transferred to other states (intersystem crossing) and generate phosphorescence. This state state decay very slow (phosphorescence decays for a few seconds or even more slow)</p><ul><li>Internal Conversion: energy loss due to collisions with solvent molecules<ul><li>collision rate = k<sub>coll</sub> [solvent]<ul><li>k<sub>coll</sub> ~10<sup>10</sup>M<sup>-1</sup>sec<sup>-1</sup></li><li>[slovent]: 55M for water</li><li>The rate of collision of a single molecule is ≈ 10<sup>11</sup>-10<sup>12</sup>sec<sup>-1</sup></li></ul></li><li><mark>S1-S2</mark>: Heat. Fast IC (10<sup>-11</sup>sec): heat loss to solvent, <strong>all excited molecules are in the lowest vibrational state</strong> of S<sub>1</sub></li><li><mark>S0-S1</mark>: Heat. Slow IC (10<sup>-8</sup>sec): due to larger energy gap, therefore fluorescence is possible.</li></ul></li></ul><div class="admonition note"><p class="admonition-title">What is the concentration of pure water?</p><li> 1 L water = 1000 g<li> water molecule = 18 g/mol<li> So 1 L water = 1000/18 =55 mol<li> [M] = 55 mol/1 L = 55 M</div><p>The processes from the S<sub>2</sub> to S<sub>1</sub> is very fast and easily be absorbed and stored in the solvent.<br>The processes from the S<sub>1</sub> to the S<sub>0</sub>, the processes relatively slow.<br>Concentration of bonds for solvent like water is very high, so it could store lots of energy.</p><h4 id="Solvent-reorganization-and-the-Stokes-Shift">Solvent reorganization and the Stokes Shift</h4><p>Measure fluorescence at fixed λ<sub>ex</sub> as a function of <em><strong>λ<sub>em</sub></strong></em><br><strong>Stokes shift</strong>: Emission spectrum is always red-shifted (lower energy) compared to the absorption spectrum</p><table><thead><tr><th style="text-align:center">Vibrational relaxation</th><th style="text-align:center">Solvent reorganization</th></tr></thead><tbody><tr><td style="text-align:center"><img src="https://chem.libretexts.org/@api/deki/files/79075/%253DScreen_shot_2011-03-14_at_11.08.58_AM.png?revision=1&amp;size=bestfit&amp;width=224&amp;height=274" alt=""></td><td style="text-align:center"><img src="https://upload.wikimedia.org/wikipedia/commons/f/fc/Stokes_shift_diagram.svg" alt=""></td></tr><tr><td style="text-align:center"><a href="https://chem.libretexts.org/Bookshelves/Physical_and_Theoretical_Chemistry_Textbook_Maps/Supplemental_Modules_(Physical_and_Theoretical_Chemistry)/Spectroscopy/Electronic_Spectroscopy/Jablonski_diagram">© libretexts.org</a></td><td style="text-align:center"><a href="https://en.wikipedia.org/wiki/Stokes_shift">© wikipedia</a></td></tr><tr><td style="text-align:center"></td><td style="text-align:center">Franck-Condon Overlap Factors<br>Prob (0’→2’) ≅ Prob (2’←0’) etc</td></tr></tbody></table><p>The vibrational relaxation looks almost symitry. So, the peaks from the solvent reorganization should corresponded the states change in the vibrational relaxation.<br>The emission shift (Stokes Shift) always as red-shifted (into right). So, the fluorescence always as less energy as the excited state.</p><table><thead><tr><th style="text-align:center">Solvent Effect</th></tr></thead><tbody><tr><td style="text-align:center"><img src="https://imgur.com/3c7E6y8.png" alt=""></td></tr></tbody></table><p>The larger, the more effects (?)</p><ol><li>Dipole changes after absorption. But the solvent dipole doesn’t change. But this is not the favorite result, the dipole of the molecule changes</li><li>(right) the solvent changes with the molecule. When the molecule back to the ground state and emitting fluorescence. But the solvent delay and change the ground the state of the molecule. It means the path from the S<sub>1</sub> to S<sub>0</sub> became shorter and the energy would used lesser. This phenomenon could be intensify by using more polar solvent.</li></ol><p>Absorption: ~ 10<sup>-15</sup> sec<br>Solvent reorganization (relaxation): ~ 10<sup>-10</sup> sec<br>Fluorescence: ~ 10<sup>-8</sup> sec<br>Step 1: Permanent Dipoles of solvent re-orient to adjust to the altered dipole of the excited fluorophore.<br>Step 2: The dipole-dipole interaction in turn stabilizes S1 and destabilizes S0.<br><strong>Requires</strong>:<br>1. solvent polarity (dielectric constant, ε)<br>2. mobility of solvent (reorientation of solvent dipoles)</p><h3 id="How-long-can-a-molecule-stay-in-its-excited-state">How long can a molecule stay in its excited state?</h3><p>Excite some molecules to $ S_1 $ with a brief pulse of light at $ t = 0 $, $ N_0^ * $ excited state molecules<br>Decay of the excited state population is exponential:<br>$$ \frac{dN^ *(t)}{dt} = -(k_ f + k_{NR})N^ *(t) $$</p><p>left: ?. right: Chemical rate total decay rate * total concentration</p><p>So: $ N ^ * (t) = N_ 0 ^ * e ^ {-(k_f+k_ {NR})t} = N_0 ^ * e^ {-t/\tau} \quad$<br>where $N ^ * (t)$ is the number of excited molecules at time <em><strong>t</strong></em>.</p><p>Define: fluorescence lifetime $ \tau $<br>$ \tau = \frac{1}{k_f + k_{NR}} $<br>the processes when 1/e ?</p><p>Hence, the equation for the decay of the excited state population:<br>$ N^ *(t) = N_0^ * e^ {-t/\tau} $</p><div class="admonition note"><p class="admonition-title">The meaning of the fluorescence lifetime</p><p><em><strong>τ</strong></em> has units of time (seconds) <br>$[N_ {t=\tau}^ *] = \frac{N_ 0^ *}{e} \approx 0/37N_ 0^ *$<br>After one lifetime following excitation, the probability of a molecule still being in the excited state is about 37%. The shorter the <em><strong>τ</strong></em> the faster the decay.<br>Commonly used fluorescence in biological system, the  <em><strong>τ</strong></em> ~ 1-10 ns</p></div><h4 id="How-bright-can-a-molecule-be">How bright can a molecule be?</h4><p><strong>Rate up</strong>: $S_ 0 \rightarrow S_ 1 = I_ 0$, unit: [# of photons absorbed/sec]<br><strong>Rate down</strong>: $S_ 1 \rightarrow S_ 0 = -(k_ f + k_ {NR}) \cdot N ^*(t)$<br><em>Unit</em>: [1/sec][# of photons]</p><p>$N^ *(t)$ = concentration of excited state molecules at any time, $t$<br>$k_  {NR}$ = sum of all non-radiative rate constants<br>$N^ *(t) = [S_1(t)]$, [# of molecules]</p><p>Steady state: rate up = rate down<br>$0 = \frac{dN ^ *(t)}{dt} = I_ 0 - (k_ f + k_ {NR}) N ^ *(t)$</p><p>In the steady state $N ^ *(t)$ is constant $= N ^ * _ {SS}$<br>$I_0 = (k_f + k_{NR}) N ^ *_{SS}$</p><h4 id="Fluorescence-quantum-yield-QY">Fluorescence quantum yield (QY)</h4><p>$Q_f$ (QY): fraction of excited-state molecules that relax to the ground state by emitting a photon.</p><p>photons/sec emitted in steady state</p><p>$$ Q_f = \frac{k_ f N^ *_ {SS}}{I_ 0} = \frac{k_ f N^ *_ {SS}}{(k_ f + k_{NR})N^ *_ {SS}} $$</p><p>Since $I_0 = (k_f + k_{NR})N^*_{SS}$</p><p>photons/sec absorbed in steady state</p><p><mark>Quantum yield</mark>: $Q_f = \frac{k_f}{(k_f + k_{NR})} = k_f \times \tau$</p><p>Recall $\tau = \frac{1}{(k_f + k_{NR})}$</p><h3 id="What-are-the-fluorophores-in-biological-systems">What are the fluorophores in biological systems?</h3><ul><li>Intrinsic Fluorescence of Proteins</li></ul><p>Absorption spectra Fluorescence spectra of amino acids in water “About 300 papers per year abstracted in Biological Abstracts report work that exploits or studies tryptophan (Trp) fluorescence in proteins…”<br>Vivian et al. Biophysical Journal 2001</p><table><thead><tr><th></th><th>Lifetime (nsec)</th><th>Absorption</th><th></th><th>Fluorescence</th><th></th></tr></thead><tbody><tr><td></td><td></td><td>Wavelength (nm)</td><td>Absorptivity (ε, M<sup>-1cm</sup>-1)</td><td>Wavelength (λmax, nm)</td><td>Quantum Yield (25°C)</td></tr><tr><td>Tryptophan</td><td>2.6</td><td>280</td><td>5,600</td><td>348</td><td>0.20</td></tr><tr><td>Tyrosine</td><td>3.6</td><td>274</td><td>1,400</td><td>303</td><td>0.14</td></tr><tr><td>Phenylalanine</td><td>6.4</td><td>257</td><td>200</td><td>282</td><td>0.04</td></tr></tbody></table><h2 id="Maturation-of-GFP">Maturation of GFP</h2><table><thead><tr><th style="text-align:center"><img src="https://zeiss-campus.magnet.fsu.edu/articles/probes/images/aequoreafpintrofigure1.jpg" alt=""></th></tr></thead><tbody><tr><td style="text-align:center"><img src="https://zeiss-campus.magnet.fsu.edu/articles/probes/images/aequoreafpintrofigure2.jpg" alt=""></td></tr><tr><td style="text-align:center"><img src="https://zeiss-campus.magnet.fsu.edu/articles/probes/images/aequoreafpintrofigure4.jpg" alt=""></td></tr><tr><td style="text-align:center"><a href="https://zeiss-campus.magnet.fsu.edu/print/probes/jellyfishfps-print.html">© zeiss</a></td></tr></tbody></table><table><thead><tr><th>Compound</th><th>Lifetime (nsec)</th><th>Wavelength (nm)(Absorption)</th><th>Absorptivity (ε, M<sup>-1</sup>cm<sup>-1</sup>)</th><th>Wavelength (λ<sub>max</sub>, nm) (Emission)</th><th>Quantum Yield (25°C)    (Emission)</th></tr></thead><tbody><tr><td>Tryptophan</td><td>2.6</td><td>280</td><td>5,600</td><td>348</td><td>0.20</td></tr><tr><td>Tyrosine</td><td>3.6</td><td>274</td><td>1,400</td><td>303</td><td>0.14</td></tr><tr><td>Phenylalanine</td><td>6.4</td><td>257</td><td>200</td><td>282</td><td>0.04</td></tr><tr><td>wtGFP</td><td>3.3/2.8</td><td>395/475</td><td>21,000</td><td>509</td><td>0.77</td></tr><tr><td>(Enhanced)</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>EGFP (F64L, S65T)</td><td>2.7</td><td>484</td><td>56,000</td><td>507</td><td>0.60</td></tr></tbody></table><h3 id="Fluorescence-Quenching">Fluorescence Quenching</h3><p>Quenching: reduce the fluorescent signal. Static and dynamic quenching causing the similar result. But the processes are totally different.</p><ol><li>Static quenching:</li></ol><ul><li>Formation of a <strong>“dark” complex of the ground state</strong> of the fluorophore and another molecule.</li></ul><ol start="2"><li>Dynamic quenching:</li></ol><ul><li>Collision between the <strong>excited state of the fluorophore</strong> and another molecule</li><li><strong>Enhancing the non-radiative decay</strong> to the ground state</li></ul><p>$$F = \sigma × 𝐼 × 𝑄Y$$</p><p>$F$: fluorescence intensity (photons/sec)<br>$\sigma$: absorption cross-section (cm<sup>2</sup>)<br>$I$: excitation light flux - photons/(cm<sup>2</sup> sec)<br>$QY$: Quantum yield (unitless)</p><p>Mirror-image rule: between the citation and the shifting spectrum, they are symmetry.</p><h3 id="Static-quenching-ground-state">Static quenching (ground state)</h3><p>Fluorescent species $A$ can associate with <strong>quencher</strong> $Q$ to form a non-fluorescent complex $AQ$:</p><p>$$<br>A + Q \leftrightarrow AQ<br>$$</p><p>The association constant $K_a$ is defined as:</p><p>$$<br>K_a = \frac{[AQ]}{[A][Q]}<br>$$</p><p>The ratio of the fluorescence intensities without and with the quencher present is given by:</p><p>$$<br>\frac{F_0}{F} = \frac{A_{tot}}{A} = \frac{[A] + [AQ]}{[A]}  = \frac{[A] + [A][Q]K_a}{[A]} \\ = 1 + [Q]K_a<br>$$</p><ul><li>Fluorescence depends on the concentration of the quencher, $[Q]$</li><li>Data analysis yields the association constant</li></ul><p>F is after quenching<br>It could quenching black radioactive object.</p><h3 id="Dynamic-quenching-collision-with-the-excited-state">Dynamic quenching: collision with the excited state</h3><table><thead><tr><th style="text-align:left"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:left"><li> $A + hv \rightarrow A^ *$ (excitation) <li> $ A^ * + Q \xrightarrow{k_Q} A + Q + \text{heat}$ (quenching) <li> $A ^ * \xrightarrow{k_f} A + hv’$ (fluorescence) <li> $k_Q$: second order rate constant for collisional quenching</td><td style="text-align:center"><img src="https://imgur.com/4rrQGDW.png" alt=""></td></tr></tbody></table><p>The diagram illustrates the energy levels $S_1$ and $S_0$, with $k_f$ representing the rate of fluorescence, $k_{NR}$ the non-radiative decay, and $[Q]k_Q$ the rate of quenching by the quencher $Q$. There’s also an illustrative depiction of a molecule $A^*$ being quenched by $Q$ within a radius of 50Å.</p><p>Only quenching excited molecule</p><p><img src="https://imgur.com/lcjPXNW.png" alt=""></p><p>The energy levels $S_1$ and $S_0$ are shown with $k_f$ representing the rate of fluorescence, $k_{NR}$ the non-radiative decay, and $[Q]k_Q$ the rate of quenching by the quencher $Q$.</p><ul><li><p>Rate of decay due to collision:<br>$$<br>\frac{d[S_1]}{dt} = -k_Q[Q][S_1]<br>$$</p></li><li><p>Total rate of decay: $S_1 \rightarrow S_0$:</p><ul><li>$ \frac{d[S_1]}{dt} = -k_f[S_1] - k_{NR}[S_1] - k_Q[Q][S_1] $</li><li>$ \frac{d[S_1]}{dt} = -(k_f + k_{NR} + k_Q[Q])[S_1] $</li></ul></li></ul><div class="admonition note"><p class="admonition-title">The quantum yield in the presence of a quencher:</p><p>$$ Q_f^{\theta} = \frac{k_f}{k_f + k_{NR} + k_Q[Q]} $$</p></div><p><strong>No Quencher:</strong>$Q_f^0 = \frac{k_f}{k_f + k_{NR}}$</p><p><strong>Plus quencher:</strong>$Q_f^{\theta} = \frac{k_f}{k_f + k_{NR} + k_Q[Q]}$</p><p>The ratio of fluorescence intensities without and with the quencher is given by:</p><p>$$<br>\frac{F_0}{F} = \frac{Q_f^ 0}{Q_f^ 0 + Q_f} \\ =  \frac{k_ f}{k_ f + k_ {NR}} \times \frac{k_ f + k_ {NR} + k_ Q[Q]}{k_ f}  \\<br>= 1 + \frac{k_Q[Q]}{k_f + k_{NR}} \\ = 1 + \tau_0 k_Q[Q]<br>$$</p><p>Where $\tau_0 = \frac{1}{k_f + k_{NR}}$ is the fluorescence lifetime (without quencher).</p><div class="admonition note"><p class="admonition-title">Define: the Stern-Volmer constant</p><p>$K_{SV} = k_Q \tau_0$<br>$ \frac{F_0}{F} = 1 + K_{SV} [Q] $</p></div><p>K<sub>SV</sub> measures <mark>the rate of quencher colliding</mark> into fluorophores at the excited state.<br>The more the fluorophore is protected from solvent, the smaller the value of K<sub>SV</sub>.</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:left"></th></tr></thead><tbody><tr><td style="text-align:center"><img src="https://imgur.com/HOnMo3v.png" alt=""></td><td style="text-align:left"><li>Slope: $K_{SV} = 8 M^{-1}$ <br> (It descripts how strong the quencher it is. The larger (sharper), the stronger.)<li>Separately measure $\tau_0 = 4 ns$                           <li>Calculate $k_Q = \frac{K_{SV}}{\tau_0} = 2 \times 10^9 M^{-1} sec^{-1}$</td></tr></tbody></table><h3 id="Dynamic-and-Static-quenching-have-the-same-dependence-on-Q">Dynamic and Static quenching have the same dependence on [Q]</h3><p>Dynamic quenching: $\frac{F_0}{F} = 1 + K_{SV} [Q]$<br>Static quenching: $\frac{F_0}{F} = 1 + K_a [Q]$</p><p>In each case, you will get a straight line if you plot $\frac{F_0}{F}$ vs $[Q]$</p><h3 id="How-can-one-distinguish-between-static-quenching-and-dynamic-quenching">How can one distinguish between static quenching and dynamic quenching?</h3><p>The differential equation for the decay of excited state molecules $N^*$ is given by:</p><p>$$<br>\frac{dN^ * (t)}{dt} = -(k_f + k_{NR} + k_Q[Q])N^ * (t)<br>$$</p><p>This leads to the solution:</p><p>$$<br>N^ * (t) = N ^  * _ 0 e ^ {-(k_f+k_{NR}+k_Q[Q])t}<br>$$</p><p>And equivalently:</p><p>$$<br>N^ * (t) = N ^ * _0 e^ {-\frac{t}{\tau}}<br>$$</p><p><strong>DYNAMIC QUENCHING:</strong> The <strong>lifetime of the excited state decreases</strong> as the concentration of the quencher is increased.</p><p>In the presence of a quencher, the lifetime $\tau$ is given by:</p><p>$$<br>\tau = \frac{1}{(k_f + k_{NR} + k_Q[Q])}<br>$$</p><h3 id="Dynamic-quenching">Dynamic quenching</h3><table><thead><tr><th style="text-align:center">Plus quencher</th><th style="text-align:center"><strong>No quencher</strong></th></tr></thead><tbody><tr><td style="text-align:center">$\tau = \frac{1}{(k_f + k_{NR} + k_Q[Q])}$</td><td style="text-align:center">$ \tau_0 = \frac{1}{(k_f + k_{NR})} $</td></tr><tr><td style="text-align:center">$Q_f^{+Q} = \frac{k_f}{k_f + k_{NR} + k_Q[Q]} $</td><td style="text-align:center">$ Q_f^{0} = \frac{k_f}{k_f + k_{NR}} $</td></tr></tbody></table><p>hence</p><p>$$<br>\frac{\tau_0}{\tau} = \frac{Q_f^ {0}}{Q_f^ {+Q}} \approx \frac{F_0}{F}<br>$$</p><p>Stern-Volmer plot will be the same if you plot lifetimes or fluorescence intensity</p><h3 id="Static-quenching-DOES-NOT-affect-the-lifetime-of-the-excited-state">Static quenching DOES NOT affect the lifetime of the excited state</h3><p>Static quenching (ground state)</p><p>$$<br>A + Q \leftrightarrow AQ<br>$$</p><p>$$<br>K_a = \frac{[AQ]}{[A][Q]}<br>$$</p><p>Fluorescent species $A$ can form a non-fluorescent complex $AQ$ with quencher $Q$. The association constant $K_a$ is defined as the ratio of the concentration of the complex to the product of the concentrations of $A$ and $Q$.</p><p>The ratio of the fluorescence intensities without and with the quencher is given by:</p><p>$$<br>\frac{F_0}{F} = \frac{A_{tot}}{A} = \frac{[A] + [AQ]}{[A]} = \frac{[A] + [A][Q]K_a}{[A]} = 1 + [Q]K_a<br>$$</p><p>The excited state species $A^*$ has the same properties in the presence of the static quencher. But there is less of it, so the fluorescence intensity decreases.</p><h3 id="If-both-static-and-dynamic-quenching-are-occurring-in-the-same-sample">If both static and dynamic quenching are occurring in the same sample</h3><p><img src="https://imgur.com/26OTvpP.png" alt=""></p><p>$$<br>\frac{F_0}{F} = (1 + k_Q \tau_0 [Q])(1 + K_a [Q]) = (1 + K_{SV} [Q])(1 + K_a [Q])<br>$$</p><h3 id="Trp94-H±His18-form-a-dark-complex-no">Trp94-(H±His18) form a dark complex: no</h3><p>fluorescence</p><p><strong>Trp94 + His18 ⇌ Trp94·(H+His18) DARK</strong></p><p>At acidic pH:</p><ul><li>Quantum yield of W94 (Qf) is <strong>decreased</strong>;</li><li>Fluorescence lifetime of W94 (τ₀) is <strong>unchanged</strong></li></ul><style>pre {  background-color:#38393d;  color: #5fd381;}</style><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>Hurtubise RJ (1990) Phosphorimetry: Theory, Instrumentation, and Applications, VCH, New York. <a href="#fnref1" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">FLUORESCENCE SPECTROSCOPY</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>SeqKit: A Cross-Platform and Ultrafast Toolkit for FASTA/Q File Manipulation</title>
    <link href="https://karobben.github.io/2024/02/05/Bioinfor/seqkit/"/>
    <id>https://karobben.github.io/2024/02/05/Bioinfor/seqkit/</id>
    <published>2024-02-05T21:00:06.000Z</published>
    <updated>2024-02-14T06:06:40.618Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Install">Install</h2><p>GitHub: <a href="https://github.com/shenwei356/seqkit">shenwei356/seqkit</a></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">wget https://github.com/shenwei356/seqkit/releases/download/v2.7.0/seqkit_linux_amd64.tar.gz<br>tar -zxvf seqkit_linux_amd64.tar.gz<br></code></pre></td></tr></table></figure></div><h3 id="Convert-the-Fastq-to-Fasta">Convert the Fastq to Fasta</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">seqkit fq2fa output_directory/output_prefix.extendedFrags.fastq -o output_directory/output_prefix.merged.fasta<br></code></pre></td></tr></table></figure></div><h3 id="Remove-Duplicated-Sequence">Remove Duplicated Sequence</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><code class="hljs bash">seqkit rmdup -s sequences.fasta -o unique_sequences.fasta -D counts.tsv<br></code></pre></td></tr></table></figure></div><ul><li><code>-s</code>: Specifies that duplicates should be identified based on sequence content.</li><li><code>[input_file]</code>: Replace this with the path to your input FASTA or FASTQ file.</li><li><code>-o [output_file]</code>: Specifies the output file. Replace <code>[output_file]</code> with the desired path for the file containing the sequences after duplicate removal.</li><li><code>-D</code>: write all removed duplicates (and counts) to this specified file.</li></ul><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">SeqKit provides a comprehensive suite of utilities for the efficient and high-throughput processing of FASTA/Q files. This toolkit allows for format conversion, subsequence extraction, quality control, and much more.</summary>
    
    
    
    <category term="Biology" scheme="https://karobben.github.io/categories/Biology/"/>
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/"/>
    
    <category term="Software" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Software/"/>
    
    <category term="Fasta/q" scheme="https://karobben.github.io/categories/Biology/Bioinformatics/Software/Fasta-q/"/>
    
    
    <category term="Bioinformatics" scheme="https://karobben.github.io/tags/Bioinformatics/"/>
    
    <category term="Fasta" scheme="https://karobben.github.io/tags/Fasta/"/>
    
    <category term="Sequencing" scheme="https://karobben.github.io/tags/Sequencing/"/>
    
  </entry>
  
  <entry>
    <title>Linear Regression</title>
    <link href="https://karobben.github.io/2024/02/05/AI/ai-linear/"/>
    <id>https://karobben.github.io/2024/02/05/AI/ai-linear/</id>
    <published>2024-02-05T18:26:13.000Z</published>
    <updated>2024-06-01T16:12:44.822Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Linear-Regression">Linear Regression</h2><h3 id="Vectors-and-Matrix">Vectors and Matrix</h3><p>In numpy, the dot product can be written np.dot(w,x) or w@x.<br>Vectors will always be column vectors. Thus:</p><p>$$<br>x =<br>\begin{bmatrix}<br>x_{1} \\<br>\vdots \\<br>x_{n}<br>\end{bmatrix}<br>, \quad w^T = [w_{1}, \ldots, w_{n}]<br>$$</p><p>$$<br>w^Tx = [w_{1}, \ldots, w_{n}]<br>\begin{bmatrix}<br>x_{1} \\<br>\vdots \\<br>x_{n}<br>\end{bmatrix}<br>= \sum_{i=1}^{n} w_{i}x_{i}<br>$$</p><p><br><br><br>$$<br>x =<br>\begin{bmatrix}<br>x_{1} \\<br>\vdots \\<br>x_{n}<br>\end{bmatrix}<br>, \quad<br>W =<br>\begin{bmatrix}<br>w_{1,1} &amp; \ldots &amp; w_{1,n} \\<br>\vdots &amp; \ddots &amp; \vdots \\<br>w_{m,1} &amp; \ldots &amp; w_{m,n}<br>\end{bmatrix}<br>$$</p><p>$$Wx =<br>\begin{bmatrix}<br>w_{1,1} &amp; \ldots &amp; w_{1,n} \\<br>\vdots &amp; \ddots &amp; \vdots \\<br>w_{m,1} &amp; \ldots &amp; w_{m,n}<br>\end{bmatrix}<br>\begin{bmatrix}<br>x_{1} \\<br>\vdots \\<br>x_{n}<br>\end{bmatrix} =<br>\begin{bmatrix}<br>\sum_{i=1}^{n} w_{1,i}x_{i} \\<br>\vdots \\<br>\sum_{i=1}^{n} w_{m,i}x_{i}<br>\end{bmatrix}<br>$$</p><h3 id="Vector-and-Matrix-Gradients">Vector and Matrix Gradients</h3><p>The gradient of a scalar function with respect to a vector or matrix is:<br>The symbol $\frac{\sigma f}{\sigma x_ 1}$ means “partial derivative of f with respect to <em>x<sub>1</sub></em>”</p><p>$$<br>\frac{\partial f}{\partial x} =<br>\begin{bmatrix}<br>\frac{\partial f}{\partial x_1} \\<br>\vdots \\<br>\frac{\partial f}{\partial x_n}<br>\end{bmatrix}<br>,<br>\quad<br>\frac{\partial f}{\partial W} =<br>\begin{bmatrix}<br>\frac{\partial f}{\partial w_{1,1}} &amp; \cdots &amp; \frac{\partial f}{\partial w_{1,n}} \\<br>\vdots &amp; \ddots &amp; \vdots \\<br>\frac{\partial f}{\partial w_{m,1}} &amp; \cdots &amp; \frac{\partial f}{\partial w_{m,n}}<br>\end{bmatrix}<br>$$</p><table><thead><tr><th style="text-align:center"><img src="https://www.researchgate.net/profile/Vladimir-Nasteski/publication/328146111/figure/fig4/AS:702757891751937@1544561946700/Visual-representation-of-the-linear-regression-22.ppm" alt=""></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://www.researchgate.net/publication/328146111_An_overview_of_the_supervised_machine_learning_methods?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6Il9kaXJlY3QiLCJwYWdlIjoiX2RpcmVjdCJ9fQ">© Vladimir Nasteski</a></td></tr></tbody></table><p>$$ f(x) = w^ T x + b = \sum_{j=0} ^{D-1} w_ j x_ j + b $$</p><ul><li>$f(x) = y$</li><li>Generally, we want to choose the weights and bias, <em>w</em> and <em>b</em>, in order to minimize the errors.</li><li>The errors are the vertical green bars in the figure at right, <em>ε = f(x) − y</em>.</li><li>Some of them are positive, some are negative. What does it mean to “minimize” them?<ul><li>$ f(x) = w^ T x + b = \sum_{j=0} ^{D-1} w_ j x_ j + b $</li></ul></li><li>Training token errors Using that notation, we can define a signed error term for every training token: <em>ε = f(x<sub>i</sub>) - y<sub>i</sub></em></li><li>The error term is positive for some tokens, negative for other tokens. What does it mean to minimize it?</li></ul><h3 id="Mean-squared-error">Mean-squared error</h3><p>Squared: tends to notice the big values and trying ignor small values.</p><p>One useful criterion (not the only useful criterion, but perhaps the most common) of “minimizing the error” is to minimize the mean squared error:<br>$$  \mathcal{L} = \frac{1}{2n} \sum_{i=1}^ {n} \varepsilon_i^ 2 = \frac{1}{2n} \sum_{i=1}^ {n} (f(x_ i) - y_ i)^ 2  $$<br>The factor $\frac{1}{2}$ is included so that, so that when you differentiate ℒ , the 2 and the $\frac{1}{2}$ can cancel each other.</p><div class="admonition note"><p class="admonition-title">MSE = Parabola </p><p>Notice that MSE is a non -negative quadratic function of <em>f(<strong>x</strong>~i~) = <strong>w</strong>^T^ x~i~ + b</em>, therefore it’s a non negative quadratic function of <em><strong>w</strong></em> . Since it’s a non -negative quadratic function of <em><strong>w</strong></em>, it has a unique minimum that you can compute in closed form! We won’t do that today.$\mathcal{L} = \frac{1}{2n} \sum_{i=1}^ {n} (f(x_ i) - y_ i)^ 2$</p></div><h3 id="The-iterative-solution-to-linear-regression-gradient-descent">The iterative solution to linear regression (gradient descent):</h3><ul><li>Instead of minimizing MSE in closed form, we’re going to use an iterative algorithm called gradient descent. It works like this:<ul><li>Start: random initial <em><strong>w</strong></em> and <em>b</em> (at <em>t=0</em>)</li><li>Adjust <em><strong>w</strong></em> and <em>b</em> to reduce MSE (<em>t=1</em>)</li><li>Repeat until you reach the optimum (<em>t = ∞</em>).</li></ul></li></ul><p>$ w \leftarrow w - \eta \frac{\partial \mathcal{L}}{\partial w} $<br>$ b \leftarrow b - \eta \frac{\partial \mathcal{L}}{\partial b} $</p><h4 id="Finding-the-gradient">Finding the gradient</h4><p>The loss function $ \mathcal{L} $ is defined as:<br>$$ \mathcal{L} = \frac{1}{2n} \sum_{i=1}^{n} L_i, \quad L_i = \varepsilon_i^2, \quad \varepsilon_i = w^T x_i + b - y_i $$<br>To find the gradient, we use the chain rule of calculus:<br>$$ \frac{\partial \mathcal{L}}{\partial w} = \frac{1}{2n} \sum_{i=1}^{n} \frac{\partial L_i}{\partial w}, \quad \frac{\partial L_i}{\partial w} = 2\varepsilon_i \frac{\partial \varepsilon_i}{\partial w}, \quad \frac{\partial \varepsilon_i}{\partial w} = x_i $$</p><p>Putting it all together,<br>$$ \frac{\partial \mathcal{L}}{\partial w} = \frac{1}{n} \sum_{i=1}^{n} \varepsilon_i x_i $$</p><p>• Start from random initial values of $w$ and $b(at\ t= 0)$.<br>• Adjust $w$ and $b$ according to:</p><p>$$ w \leftarrow w - \frac{\eta}{n} \sum_{i=1}^{n} \varepsilon_i x_i $$<br>$$ b \leftarrow b - \frac{\eta}{n} \sum_{i=1}^{n} \varepsilon_i $$</p><h4 id="Intuition">Intuition:</h4><ul><li>Notice the sign:<ul><li>$ w \leftarrow w - \frac{\eta}{n} \sum_{i=1}^{n} \varepsilon_i x_i $</li></ul></li><li>If $ \varepsilon_i $ is positive ($ f(x_i) &gt; y_i $), then we want to <mark>reduce</mark> $ f(x_i) $, so we make $ w $ less like $ x_i $</li><li>If $ \varepsilon_i $ is negative ($ f(x_i) &lt; y_i $), then we want to <mark>increase</mark> $ f(x_i) $, so we make $ w $ more like $ x_i $</li></ul><h3 id="Gradient-Descent">Gradient Descent</h3><ul><li>If $n$ is large, computing or differentiating MSE can be expensive.</li><li>The stochastic gradient descent algorithm picks one training token $(x_i, y_i)$ at random (“stochastically”), and adjusts $w$ in order to reduce the error a little bit for that one token:<br>$$ w \leftarrow w - \eta \frac{\partial \mathcal{L}_i}{\partial w} $$<br>…where<br>$$ \mathcal{L}_i = \varepsilon_i^2 = \frac{1}{2}(f(x_i) - y_i)^2 $$</li></ul><h3 id="Stochastic-gradient-descent">Stochastic gradient descent</h3><p>$$<br>\mathcal{L}_i = \varepsilon_i^2 = \frac{1}{2}(w^T x_i + b - y_i)^2<br>$$</p><p>If we differentiate that, we discover that:</p><p>$$<br>\frac{\partial \mathcal{L}_i}{\partial w} = \varepsilon_i x_i,<br>\quad<br>\frac{\partial \mathcal{L}_i}{\partial b} = \varepsilon_i<br>$$</p><p>So the stochastic gradient descent algorithm is:</p><p>$$<br>w \leftarrow w - \eta \varepsilon_i x_i,<br>\quad<br>b \leftarrow b - \eta \varepsilon_i<br>$$</p><h3 id="Code-Example">Code Example</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> functools <span class="hljs-keyword">import</span> partial<br><span class="hljs-keyword">from</span> matplotlib.animation <span class="hljs-keyword">import</span> FuncAnimation<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">updatew</span>(<span class="hljs-params">x, y, W, b, e=<span class="hljs-number">0.01</span></span>):</span><br>    E = np.<span class="hljs-built_in">sum</span>(W*x +b - y)<br>    W -= np.<span class="hljs-built_in">sum</span>(e*E*x)<br>    b -= e*E<br>    <span class="hljs-keyword">return</span> W, b<br><br>slope = <span class="hljs-number">1</span><br>intercept = <span class="hljs-number">3</span><br>std_dev = <span class="hljs-number">1</span><br>size = <span class="hljs-number">100</span>  <span class="hljs-comment"># Size of the dataset</span><br><br><span class="hljs-comment"># Generate x values</span><br>X = np.random.uniform(low=-<span class="hljs-number">10</span>, high=<span class="hljs-number">10</span>, size=size)<br><br><span class="hljs-comment"># Generate y values based on the equation y = x + 3</span><br><span class="hljs-comment"># Add normal distributed noise with standard deviation of 0.4</span><br>Y = slope * X + intercept + np.random.normal(<span class="hljs-number">0</span>, std_dev, size)<br><br>W = <span class="hljs-number">0</span><br>b = <span class="hljs-number">0</span><br>XX = []<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(X)):<br>    W,b = updatew(X[i], Y[i], W, b, <span class="hljs-number">.01</span>)<br>    XX +=[[W, b]]    <br><br>plt.plot(X, Y, <span class="hljs-string">&#x27;o&#x27;</span>)<br>plt.plot(X, X*W + b)<br>plt.text(-<span class="hljs-number">9</span>, <span class="hljs-number">9</span>, <span class="hljs-string">f&#x27;slop = <span class="hljs-subst">&#123;<span class="hljs-built_in">round</span>(W, <span class="hljs-number">2</span>)&#125;</span>\nintercept = <span class="hljs-subst">&#123;<span class="hljs-built_in">round</span>(b, <span class="hljs-number">2</span>)&#125;</span>&#x27;</span>)<br>plt.show()<br><br><span class="hljs-comment"># Your update function for the animation</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">update</span>(<span class="hljs-params">frame</span>):</span><br>    <span class="hljs-comment"># Update the data for the animated line plot, for example</span><br>    ln.set_data(X, X * XX[frame][<span class="hljs-number">0</span>] + XX[frame][<span class="hljs-number">1</span>] )<br>     <span class="hljs-comment"># Update the text for the current frame</span><br>    txt.set_text(<span class="hljs-built_in">str</span>(<span class="hljs-built_in">int</span>(frame)) +<span class="hljs-string">&#x27;: $y = &#123;:.2f&#125;x + &#123;:.2f&#125;$&#x27;</span>.<span class="hljs-built_in">format</span>(XX[frame][<span class="hljs-number">0</span>], XX[frame][<span class="hljs-number">1</span>]))<br>    <span class="hljs-keyword">return</span> ln, txt<br><span class="hljs-comment"># Set up the figure and the line to animate</span><br>fig, ax = plt.subplots()<br>ln, = ax.plot([], [], <span class="hljs-string">&#x27;r-&#x27;</span>, animated=<span class="hljs-literal">True</span>)<br>txt = ax.text(-<span class="hljs-number">9</span>, <span class="hljs-number">9</span>, <span class="hljs-string">&#x27;&#x27;</span>, animated=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># Create a text object at (-9, 9)</span><br><span class="hljs-comment"># Plot the background points</span><br>ax.plot(X, Y, <span class="hljs-string">&#x27;o&#x27;</span>)  <span class="hljs-comment"># Static background points</span><br><span class="hljs-comment"># Init function to set up the background of each frame (if necessary)</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">init</span>():</span><br>    ax.set_xlim(<span class="hljs-built_in">min</span>(X), <span class="hljs-built_in">max</span>(X))<br>    ax.set_ylim(<span class="hljs-built_in">min</span>(Y), <span class="hljs-built_in">max</span>(Y))<br>    txt.set_text(<span class="hljs-string">&#x27;&#x27;</span>)<br>    <span class="hljs-keyword">return</span> ln,<br><span class="hljs-comment"># Create the animation</span><br>ani = FuncAnimation(fig, update, frames=<span class="hljs-number">100</span>,<br>                    init_func=init, blit=<span class="hljs-literal">True</span>)<br>ani.save(<span class="hljs-string">&#x27;animation_drawing.gif&#x27;</span>, writer=<span class="hljs-string">&#x27;imagemagick&#x27;</span>, fps=<span class="hljs-number">10</span>)<br></code></pre></td></tr></table></figure></div><table><thead><tr><th style="text-align:center"><img src="https://imgur.com/1O0dz1d.png" alt="linear reguression"></th></tr></thead><tbody></tbody></table><p>PS: In the old script, I wasn’t fully understand how the linear regression works. So, I just made this script based on my personal understanding. So, you can find that I was using one dots from the set to calculate the loss and updates the $w$ and $b$ each time. But in real application situation, this way would make the updating process very noisy because single points could be very unreliable. According to the function above, we could use this function to update them:</p><ul><li>$ w \leftarrow w - \frac{\eta}{n} \sum_{i=1}^{n} \varepsilon_i x_i $</li><li>$ b \leftarrow b - \frac{\eta}{n} \sum_{i=1}^{n} \varepsilon_i $</li></ul><p>For using this function, two things you may like to change from the example:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># alter the weight and bias update function</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">updatew</span>(<span class="hljs-params">X, Y, W, b, e=<span class="hljs-number">0.01</span></span>):</span><br>    E = W*X +b - Y<br>    W -= np.<span class="hljs-built_in">sum</span>(E*X) * e/ <span class="hljs-built_in">len</span>(X)<br>    b -= np.<span class="hljs-built_in">sum</span>(E) * e/ <span class="hljs-built_in">len</span>(X)<br>    <span class="hljs-keyword">return</span> W, b<br><br><span class="hljs-comment"># starting the iteration and stop it manually</span><br><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>    W,b = updatew(X, Y, W, b, <span class="hljs-number">.05</span>)<br>    print(W, b)<br></code></pre></td></tr></table></figure></div><p>How do them different from each other?</p><table><thead><tr><th style="text-align:left"></th><th style="text-align:left">Single Points loss</th><th style="text-align:left">Summed loss</th></tr></thead><tbody><tr><td style="text-align:left">Last 5 rounds after so many iteration</td><td style="text-align:left"><pre>1.1539 2.8111<br>1.1540 2.8105<br>1.2018 2.8054<br>1.1999 2.8021<br>0.9239 2.8350</td><td style="text-align:left"><pre>0.9947 2.8171<br>0.9947 2.8171<br>0.9947 2.8171<br>0.9947 2.8171<br>0.9947 2.8171</pre></td></tr><tr><td style="text-align:left">Explained</td><td style="text-align:left">Because the result from a single point has significant noise, the jitter can never be eliminated, making it difficult to achieve local optimization.</td><td style="text-align:left">Because the loss is based on the entire dataset, it is very easy to achieve local optimization.</td></tr></tbody></table><p>This is why selecting an appropriate batch size during machine learning training is crucial. In the first example, the batch size is set to 1, while in the second, it equals the size of the training data. A very large batch size, such as using the entire dataset, can significantly increase the computational load, especially if the model is complex. Additionally, it may lead to the model getting stuck in local optima, which depends on the quality of the dataset. Therefore, choosing an appropriate batch size is essential for effective training.</p><hr><h2 id="Perceptron">Perceptron</h2><p>Perceptron is invented before the loss function</p><h3 id="Linear-classifier-Definition">Linear classifier: Definition</h3><p>A linear classifier is defined by</p><p>$$<br>f(x) = \text{argmax } Wx + b<br>$$</p><p>where:</p><p>$$<br>Wx + b =<br>\begin{bmatrix}<br>w_{1,1} &amp; \ldots &amp; w_{1,d} \\<br>\vdots &amp; \ddots &amp; \vdots \\<br>w_{v,1} &amp; \ldots &amp; w_{v,d}<br>\end{bmatrix}<br>\begin{bmatrix}<br>x_{1} \\<br>\vdots \\<br>x_{d}<br>\end{bmatrix}<br>+<br>\begin{bmatrix}<br>b_{1} \\<br>\vdots \\<br>b_{v}<br>\end{bmatrix}=<br>\begin{bmatrix}<br>w_{1}^T x + b_{1} \\<br>\vdots \\<br>w_{v}^T x + b_{v}<br>\end{bmatrix}<br>$$</p><p>$w_k, b_k$ are the weight vector and bias corresponding to class $k$, and the argmax function finds the element of the vector $wx$ with the largest value.<br>There are a total of $v(d + 1)$ trainable parameters: the elements of the matrix $w$.</p><h3 id="Example">Example</h3><p><img src="https://imgur.com/9kmw2fe.png" alt=""></p><p>Consider a two -class classification problem, with</p><ul><li>$W^T_1 = [w_{1,1}, w_{1,2}] = [2,1]$</li><li>$W^T_2 = [w_{2,1}, w_{2,2}] = [1,2]$</li></ul><p>Notice that in the two-class case, the equation</p><p>$$<br>f(x) = \text{argmax } Wx + b<br>$$</p><p>Simplifies to</p><p>$$<br>f(x) =<br>\begin{cases}<br>1 &amp; \ if\ w_1^T x + b_1 &gt; w_2^T x + b_2 \\<br>2 &amp; \ if\ w_1^T x + b_1 \leq w_2^T x + b_2<br>\end{cases}<br>$$</p><p>The class boundary is the line whose equation is<br>$$<br>(w_2 - w_1)^T x + (b_2 - b_1) = 0<br>$$</p><div class="admonition note"><p class="admonition-title">Extend: Multi-class linear classifier </p><p><img src="https://imgur.com/TNWvhKX.png" alt="" /></p><p>The boundary between class $k$ and class $l$ is the line (or plane, or hyperplane) given by the equation</p></div><table><thead><tr><th style="text-align:center">$f(x) = argmax Wx + b$</th><th style="text-align:center">$(w_k - w_l)^T x + (b_k - b_l) = 0$</th></tr></thead><tbody></tbody></table><p>The classification regions in a linear classifier are called Voronoi regions.<br>A <strong>Voronoi region</strong> is a region that is<br>• Convex (if $u$ and $v$ are points in the region, then every point on the line segment $\bar{u}\bar{v}$ connecting them is also in the region)<br>• Bounded by piece-wise linear boundaries</p><h3 id="Gradient-descent">Gradient descent</h3><p>Suppose we have training tokens $(x_i, y_i)$, and we have some initial class vectors $w_1$ and $w_2$. We want to update them as</p><p>$$<br>w_1 \leftarrow w_1 - \eta \frac{\partial \mathcal{L}}{\partial w_1}<br>$$</p><p>$$<br>w_2 \leftarrow w_2 - \eta \frac{\partial \mathcal{L}}{\partial w_2}<br>$$</p><p>…where $\mathcal{L}$ is some loss function. What loss function makes sense?</p><p><img src="https://imgur.com/YaSOBI6.png" alt=""></p><h4 id="Zero-one-loss-function">Zero-one loss function</h4><p>The most obvious loss function for a classifier is its classification error rate,</p><p>$$<br>\mathcal{L} = \frac{1}{n} \sum_{i=1}^{n} \ell(f(x_i), y_i)<br>$$</p><p>Where $\ell(\hat{y}, y)$ is the zero-one loss function,</p><p>$$<br>\ell(f(x), y) =<br>\begin{cases}<br>0 &amp; \text{if } f(x) = y \\<br>1 &amp; \text{if } f(x) \neq y<br>\end{cases}<br>$$</p><h4 id="Non-differentiable">Non-differentiable!</h4><p>The problem with the zero -one loss function is that it’s not differentiable:</p><p>$$<br>\frac{\partial \ell(f(x), y)}{\partial f(x)} =<br>\begin{cases}<br>0 &amp; \text{if } f(x) \neq y \\<br>+\infty &amp; \text{if } f(x) = y^+ \\<br>-\infty &amp; \text{if } f(x) = y^-<br>\end{cases}<br>$$</p><p>Integer vectors: One-hot vectors, A one-hot vector is a binary vector in which all elements are 0 except for a single element that’s equal to 1.</p><h3 id="One-hot-vectors">One-hot vectors</h3><p>A one-hot vector is a binary vector in which all elements are 0 except for a single element that’s equal to 1.</p><h4 id="Exp1-Binary-classifier">Exp1: Binary classifier</h4><p>$$<br>f(x) =<br>\begin{bmatrix}<br>f_1(x) \\<br>f_2(x)<br>\end{bmatrix} =<br>\begin{bmatrix}<br>1_{\arg\max Wx=1} \\<br>1_{\arg\max Wx=2}<br>\end{bmatrix}<br>$$</p><p>…where $1$ is called the “indicator function,” and it means:</p><p>$$<br>1_P =<br>\begin{cases}<br>1\ \ \ P\ is\ true\\<br>0\ \ \ P\ is\ false<br>\end{cases}<br>$$</p><h4 id="Exp2-Multi-Class">Exp2: Multi-Class</h4><p>Consider the classifier</p><p>$$<br>f(x) =<br>\begin{bmatrix}<br>f_1(x) \\<br>\vdots \\<br>f_v(x)<br>\end{bmatrix} =<br>\begin{bmatrix}<br>1_{\arg\max Wx=1} \\<br>\vdots \\<br>1_{\arg\max Wx=v}<br>\end{bmatrix}<br>$$</p><p>… with 20 classes. Then some of the classifications might look like this.</p><h4 id="One-hot-ground-truth">One-hot ground truth</h4><p>We can also use one-hot vectors to describe the ground truth. Let’s call the one-hot vector $y$, and the integer label $y$, thus</p><p>$$<br>y = \begin{bmatrix}<br>y_1 \\<br>y_2 \\ \end{bmatrix} = \begin{bmatrix}<br>1_{y=1} \\<br>2_{y=2} \end{bmatrix}<br>$$</p><p>Ground truth might differ from classifier output.</p><p>Instead of a one-zero loss, the perceptron uses a weird loss function that gives great results when differentiated. The perceptron loss function is:</p><p>$$<br>\ell(x, y) = (f(x) - y)^T (Wx + b)<br>$$</p><p>$$<br>= \left[ f_1(x) - y_1, \ldots, f_v(x) - y_v \right]<br>\left(\begin{bmatrix}<br>W_{1,1} &amp; \ldots &amp; W_{1,d} \\<br>\vdots &amp; \ddots &amp; \vdots \\<br>W_{v,1} &amp; \ldots &amp; W_{v,d}<br>\end{bmatrix}<br>\begin{bmatrix}<br>x_{1} \\<br>\vdots \\<br>x_{d}<br>\end{bmatrix}<br>+<br>\begin{bmatrix}<br>b_{1} \\<br>\vdots \\<br>b_{v}<br>\end{bmatrix}\right)<br>$$</p><p>$$<br>= \sum_{k=1}^{v} (f_k(x) - y_k)(W_k^T x + b_k)<br>$$</p><h4 id="The-perceptron-loss">The perceptron loss</h4><p>The perceptron loss function is defined as:</p><p>$$<br>\ell(x, y) = \sum_{k=1}^{v} (f_k(x) - y_k)(W_k^T x + b_k)<br>$$</p><p>Notice that:</p><p>$$<br>(f_k(x) - y_k) =<br>\begin{cases}<br>+1 &amp; \text{if } f_k(x) = 1, y_k = 0 \\<br>-1 &amp; \text{if } f_k(x) = 0, y_k = 1 \\<br>0 &amp; \text{otherwise}<br>\end{cases}<br>$$</p><p>So what the loss really means is:</p><p>$$<br>\ell(x, y) = (w_{\hat{y}}^T x + b_{\hat{y}}) - (w_y^T x + b_y)<br>$$</p><p>Where:</p><ul><li>$y$ is the correct class label for this training token</li><li>$\hat{y} = \arg\max_k (w_k^T x + b_k)$ is the classifier output</li><li>$\ell(x, y) &gt; 0$ if $\hat{y} \neq y$</li><li>$\ell(x, y) = 0$ if $\hat{y} = y$</li></ul><h3 id="Perceptron-learning-algorithm">Perceptron learning algorithm</h3><h4 id="Gradient-of-the-perceptron-loss">Gradient of the perceptron loss</h4><p>The perceptron loss function is:</p><p>$$<br>\ell(x, y) = (w_{\hat{y}}^T x + b_{\hat{y}}) - (w_y^T x + b_y)<br>$$</p><p>Its derivative is:</p><p>$$<br>\frac{\partial \ell(x, y)}{\partial w_k} =<br>\begin{cases}<br>x &amp; \text{if } k = \hat{y} \\<br>-x &amp; \text{if } k = y \\<br>0 &amp; \text{otherwise}<br>\end{cases}<br>$$</p><h4 id="The-perceptron-learning-algorithm">The perceptron learning algorithm</h4><ol><li><p>Compute the classifier output $\hat{y} = \arg\max_k (w_k^T x + b_k)$</p></li><li><p>Update the weight vectors as:</p></li></ol><p>$$<br>w_k \leftarrow w_k - \eta \frac{\partial \ell(x, y)}{\partial w_k} =<br>\begin{cases}<br>w_k - \eta x &amp; \text{if } k = \hat{y} \\<br>w_k + \eta x &amp; \text{if } k = y \\<br>w &amp; \text{otherwise}<br>\end{cases}<br>$$</p><p>where $\eta \approx 0.01$ is the learning rate.</p><h4 id="Special-case-two-classes">Special case: two classes</h4><p>If there are only two classes, then we only need to learn one weight vector, $w = w_1 - w_2$. We can learn it as:</p><ol><li><p>Compute the classifier output $\hat{y} = \arg\max_k (w_k^T x + b_k)$</p></li><li><p>Update the weight vectors as:</p></li></ol><p>$$<br>w \leftarrow<br>\begin{cases}<br>w - \eta x &amp; \text{if } \hat{y} \neq y, y = 2 \\<br>w + \eta x &amp; \text{if } \hat{y} \neq y, y = 1 \\<br>w &amp; \text{if } \hat{y} = y<br>\end{cases}<br>$$</p><p>where $\eta \approx 0.01$ is the learning rate. Sometimes we say $y \in {1, -1}$ instead of $y \in {1,2}$.</p><h2 id="Softmax">Softmax</h2><p>Key idea: $f_c(x) =$ posterior probability of cass $c$</p><ul><li>A perceptron has a one-hot output vector, in which $f_c(x) = 1$ if the<br>neural net thinks $c$ is the most likely value of $y$, and 0 otherwise</li><li>A softmax computes $f_c(x) \approx Pr(Y =c |x)$. The conditions for this to be true are:<ul><li>It needs to satisfy the axioms of probability:<br>$$ 0 \leq f_c(x) \leq 1, \quad \sum_{c=1}^{v} f_c(x) = 1$$</li><li>The weight matrix, $W$, is trained using a loss function that encourages $f(x)$ to approximate posterior probability of the labels on some training dataset:<br>$$f_c(x) \approx \Pr(Y = c|x)$$</li></ul></li></ul><h3 id="Softmax-satisfies-the-axioms-of-probability">Softmax satisfies the axioms of probability</h3><ul><li><p>Axiom #1, probabilities are non-negative $(f_k(x) \geq 0)$. There are many ways to do this, but one way that works is to choose:</p><p>$$<br>f_c(x) \propto \exp(w_c^T x + b_c)<br>$$</p></li><li><p>Axiom #2, probabilities should sum to one $(\sum_{k=1}^{v} f_k(x) = 1)$. This can be done by normalizing:</p></li></ul><p>$$<br>f(x) = [f_1(x), …, f_v(x)]^T<br>$$<br>$$<br>f_c(x) = \frac{\exp(w_c^T x + b_c)}{\sum_{k=0}^{v-1} \exp(w_k^T x + b_k)}<br>$$</p><p>where $w_k^T$ is the $k^{th}$ row of the matrix $W$.</p><h3 id="The-logistic-sigmoid-function">The logistic sigmoid function</h3><p>For a two-class classifier, we don’t really need the vector label. If we define $w = w_2 - w_1$ and $b = b_2 - b_1$, then the softmax simplifies to:</p><p>$$<br>f(Wx + b) =<br>\begin{bmatrix}<br>\text{Pr}(Y = 1|x) \\<br>\text{Pr}(Y = 2|x)<br>\end{bmatrix} =<br>\begin{bmatrix}<br>\frac{1}{1+e^ {-(w^ Tx+b)}} \\<br>\frac{e^ {-(w^ Tx+b)}}{1+e^ {-(w^ Tx+b)}}<br>\end{bmatrix} =<br>\begin{bmatrix}<br>\sigma(w^Tx + b) \\<br>1 - \sigma(w^Tx + b)<br>\end{bmatrix}<br>$$</p><p>… so instead of the softmax, we use a scalar function called the logistic sigmoid function:</p><p>$$<br>\sigma(z) = \frac{1}{1+e^{-z}}<br>$$</p><p>This function is called sigmoid because it is S-shaped.</p><p>For $z \to -\infty$, $\sigma(z) \to 0$</p><p>For $z \to +\infty$, $\sigma(z) \to 1$</p><h3 id="Gradient-descent-v2">Gradient descent</h3><p>Suppose we have training tokens $(x_i, y_i)$, and we have some initial class vectors $w_1$ and $w_2$. We want to update them as</p><p>$$<br>w_1 \leftarrow w_1 - \eta \frac{\partial \mathcal{L}}{\partial w_1}<br>$$</p><p>$$<br>w_2 \leftarrow w_2 - \eta \frac{\partial \mathcal{L}}{\partial w_2}<br>$$</p><p>…where $\mathcal{L}$ is some loss function. What loss function makes sense?</p><h3 id="Zero-one-loss-function-v2">Zero-one loss function</h3><p>The most obvious loss function for a classifier is its classification error rate,</p><p>$$<br>\mathcal{L} = \frac{1}{n} \sum_{i=1}^{n} \ell(\hat{f}(x_i), y_i)<br>$$</p><p>Where $\ell(\hat{y}, y)$ is the zero-one loss function,</p><p>$$<br>\ell(f(x), y) =<br>\begin{cases}<br>0 &amp; \text{if } f(x) = y \\<br>1 &amp; \text{if } f(x) \neq y<br>\end{cases}<br>$$</p><p>The problem with zero-one loss is that it’s not differentiable.</p><h3 id="A-loss-function-that-learns-probabilities">A loss function that learns probabilities</h3><p>Suppose we have a softmax output, so we want $f_c(x) \approx \Pr(Y = c|x)$. We can train this by learning $W$ and $b$ to maximize the probability of the training corpus. If we assume all training tokens are independent, we get:</p><p>$$<br>W, b = \underset{W,b}{\text{argmax}} \prod_{i=1}^{n} \Pr(Y = y_i|x_i) = \underset{W,b}{\text{argmax}} \sum_{i=1}^{n} \ln \Pr(Y = y_i|x_i)<br>$$</p><p>But remember that $f_c(x) \approx \Pr(Y = c|x)$! Therefore, maximizing the log probability of training data is the same as minimizing the cross entropy between the neural net and the ground truth:</p><p>$$<br>W, b = \underset{W,b}{\text{argmin}} -\frac{1}{n} \sum_{i=1}^{n} \mathcal{L}_ i, \quad \mathcal{L}_ i = - \log f_ {y_ i}(x_ i)<br>$$</p><h3 id="Cross-entropy">Cross-entropy</h3><p>This loss function:</p><p>$$<br>\mathcal{L} = - \ln f_{y}(x)<br>$$</p><p>is called cross-entropy. It measures the difference in randomness between:</p><ul><li>Truth: $Y = y$ with probability 1.0, $\ln(1.0) = 0$, minus the</li><li>Neural net estimate: $Y = y$ with probability $f_{y}(x)$.</li></ul><p>Thus</p><p>$$<br>\mathcal{L} = 0 - \ln f_{y}(x)<br>$$</p><h3 id="Gradient-of-the-cross-entropy-of-the-softmax">Gradient of the cross-entropy of the softmax</h3><p>Since we have these definitions:</p><p>$$<br>\mathcal{L} = - \ln f_{y}(x), \quad f_{y}(x) = \frac{\exp(z_{y})}{\sum_{k=1}^{v} \exp(z_{k})}, \quad z_{c} = w_c^T x + b_c<br>$$</p><p>Then:</p><p>$$<br>\frac{\partial \mathcal{L}}{\partial w_c} = \left( \frac{\partial \mathcal{L}}{\partial z_c} \right) \left( \frac{\partial z_c}{\partial w_c} \right) = \left( \frac{\partial \mathcal{L}}{\partial z_c} \right) x<br>$$</p><p>…where:</p><p>$$<br>\frac{\partial \mathcal{L}}{\partial z_c} =<br>\begin{cases}<br>f_{c}(x_i) - 1 &amp; c = y \\<br>f_{c}(x_i) &amp; c \neq y<br>\end{cases}<br>$$</p><h3 id="Similarity-to-linear-regression">Similarity to linear regression</h3><p>For linear regression, we had:</p><p>$$<br>\frac{\partial \mathcal{L}}{\partial w} = \epsilon x, \quad \epsilon = f(x) - y<br>$$</p><p>For the softmax classifier with cross-entropy loss, we have</p><p>$$<br>\frac{\partial \mathcal{L}}{\partial w_c} = \epsilon_c x<br>$$</p><p>$$<br>\epsilon_c =<br>\begin{cases}<br>f_c(x_i) - 1 &amp; c = y \text{ (output should be 1)} \\<br>f_c(x_i) &amp; \text{otherwise (output should be 0)}<br>\end{cases}<br>$$</p><h3 id="Similarity-to-perceptron">Similarity to perceptron</h3><p>Suppose we have a training token $(x, y)$, and we have some initial class vectors $w_c$. Using softmax and cross-entropy loss, we can update the weight vectors as</p><p>$$<br>w_c \leftarrow w_c - \eta \epsilon_c x<br>$$</p><p>…where</p><p>$$<br>\epsilon_c =<br>\begin{cases}<br>f_c(x_i) - 1 &amp; c = y_i \\<br>f_c(x_i) &amp; \text{otherwise}<br>\end{cases}<br>$$</p><p>In other words, like a perceptron,</p><p>$$<br>\epsilon_c =<br>\begin{cases}<br>\epsilon_c &lt; 0 &amp; c = y_i \\<br>\epsilon_c &gt; 0 &amp; \text{otherwise}<br>\end{cases}<br>$$</p><h3 id="Outline">Outline</h3><ul><li><p>Softmax:<br>$$ f_c(x) = \frac{\exp(w_c^T x + b_c)}{\sum_{k=1}^{v} \exp(w_k^T x + b_k)} \approx \Pr(Y = c|x) $$</p></li><li><p>Cross-entropy:<br>$$ \mathcal{L} = - \ln f_{y}(x) $$</p></li><li><p>Derivative of the cross-entropy of a softmax:<br>$$ \frac{\partial \mathcal{L}}{\partial w_c} = \epsilon_c x, \quad \epsilon_c =<br>\begin{cases}<br>f_c(x_i) - 1 &amp; c = y \text{ (output should be 1)} \\<br>f_c(x_i) &amp; \text{otherwise (output should be 0)}<br>\end{cases} $$</p></li><li><p>Gradient descent:<br>$$ w_c \leftarrow w_c - \eta \epsilon_c x $$</p></li></ul><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Linear Regression</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Class" scheme="https://karobben.github.io/categories/Notes/Class/"/>
    
    <category term="UIUC" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/"/>
    
    <category term="AI" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/AI/"/>
    
    
    <category term="Machine Learning" scheme="https://karobben.github.io/tags/Machine-Learning/"/>
    
    <category term="Data Science" scheme="https://karobben.github.io/tags/Data-Science/"/>
    
  </entry>
  
  <entry>
    <title>Learning Progress</title>
    <link href="https://karobben.github.io/2024/02/02/LearnNotes/ai-learning/"/>
    <id>https://karobben.github.io/2024/02/02/LearnNotes/ai-learning/</id>
    <published>2024-02-02T18:58:50.000Z</published>
    <updated>2024-02-14T05:54:24.454Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Learning">Learning</h2><div class="admonition note"><p class="admonition-title">Biological inspiration: Long-term potentiation</p><ol><li>A synapse is repeatedly stimulated<br></li><li>More dendritic receptors<br></li><li>More neurotransmitters<br></li><li>A stronger link between neurons</li></ol></div><ul><li>Mathematical Model this Biological Learning Model:<ul><li><em><strong>X</strong></em> = input signal; <em><strong>f(X)</strong></em> = output signal</li><li><strong>Learning</strong> = adjust the parameters of the learning machine so that <em><strong>f(x)</strong></em> becomes the function we want</li></ul></li><li>Mathematical Model of Supervised Learning<ul><li><em><strong>D = {(x<sub>1</sub>, y<sub>1</sub>), …, (x<sub>n</sub>, y<sub>n</sub>)}</strong></em> = training dataset containing pairs of (example signal <em><strong>x<sub>i</sub></strong></em>, desired system output <em><strong>y<sub>i</sub></strong></em>)</li><li><strong>Supervised Learning</strong> = adjust parameters of the learner to minimize <em><strong>E[ℓ(Y, f(X))]</strong></em></li><li><em><strong>ℓ</strong></em>: loss function</li></ul></li></ul><table><thead><tr><th style="text-align:center"><img src="https://imgur.com/228ikan.png" alt="loss-function"></th></tr></thead><tbody></tbody></table><h3 id="Decision-tree-learning-An-example">Decision tree learning: An example</h3><p>The Titanic sank. You were rescued. You want to know if your friend was also rescued. You can’t find them. Can you use machine learning methods to estimate the probability that your friend survived? (Calculate the possibility of your friend also be rescued)</p><ol><li>Gather data about as many of the passengers as you can.<ul><li>X = variables that describe the passenger, e.g., age, gender, number of siblings on board.</li><li>Y = 1 if the person is known to have survived</li></ul></li><li>Learn a function, f(X), that matches the known data as well as possible</li><li>Apply f(x) to your friend’s facts, to estimate their probability of survival</li></ol><p><strong>Decision-tree learning</strong>*:</p><ul><li>1st branch = variable that best distinguishes between groups with higher vs. lower survival rates (e.g., gender)</li><li>2nd branch = variable that best subdivides the remaining group</li><li>Quit when all people in a group have the same outcome, or when the group is too small to be reliably subdivided.</li></ul><table><thead><tr><th style="text-align:center"><img src="https://upload.wikimedia.org/wikipedia/commons/e/eb/Decision_Tree.jpg" alt="Decision-tree for Titanic"></th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://en.m.wikipedia.org/wiki/File:Decision_Tree.jpg">© wikipedia</a></td></tr></tbody></table><p>In each leaf node of this tree:</p><ul><li><p>Number on the left = probability of survival</p></li><li><p>Number on the right = percentage of all known cases that are explained by this node</p></li><li><p>A decision tree is an example of a parametric learner</p></li><li><p>The function <em><strong>f(x)</strong></em> is determined by some learned parameters</p></li><li><p>In this case, the parameters are:</p></li><li><p>Should this node split, or not?</p></li><li><p>If so, which tokens go to the right-hand child?</p></li><li><p>If not, what is <em><strong>f(x)</strong></em> at the current node?</p></li><li><p>Titanic shipwreck example:</p><ul><li>Θ = [Y, female, Y, age ≤ 9.5, N, f(x) = 0.73, …]</li></ul></li></ul><div class="admonition note"><p class="admonition-title">A mathematical definition of learning</p><ul><li>Environment: there are two random variables, X and Y, that are jointly distributed according to</li><li><em><strong>P(X,Y)</strong></em></li><li>Data: <em><strong>P(X, Y)</strong></em> is unknown, but we have a sample of training data</li><li><em><strong>D = {(x~1~, y~1~), ..., (x~n~, y~n~)}</strong></em></li><li>Objective: We would like a function � that minimizes the expected value of some loss function, <em><strong>ℓ(Y , f(x))</strong></em> :</li><li><em><strong>ℛ = E[ℓ(Y, f(x))]</strong></em></li><li>Definition of learning: Learning is the task of estimating the function <em><strong>f</strong></em>, given knowledge of <em><strong>D</strong></em>.</li></ul></div><h3 id="Training-vs-Test-Corpora">Training vs. Test Corpora</h3><ul><li><strong>Training Corpus</strong> = a set of data that you use in order to optimize the parameters of your classifier (for example, optimize which features you measure, how you use those features to make decisions, and so on).<ul><li>Measuring the training corpus accuracy is important for debugging: if your training algorithm is working, then training corpus error rate should always go down.</li></ul></li><li><strong>Test Corpus</strong> = a set of data that is non-overlapping with the training set (none of the test tokens are also in the training dataset) that you can use to measure the error rate.<ul><li>Measuring the test corpus error rate is the only way to estimate how your classifier will work on new data (data that you’ve never yet seen)</li></ul></li><li><strong>Training error</strong> is sometimes called “optimization error”. It happens because you haven’t finished optimizing your parameters.</li><li><strong>Test error</strong> = <mark>optimization error + generalization error</mark></li><li><strong>Evaluation Test Corpus</strong> = a dataset that is used only to test the ONE classifier that does best on DevTest. From this corpus, you learn how well your classifier will perform in the real world.</li></ul><h3 id="Early-stopping">Early stopping</h3><ul><li><p><strong>Learning</strong>: Given $\mathcal{D} = {(x_1, y_1), \ldots, (x_n, y_n)}$, find the function $f(X)$ that minimizes some measure of risk.</p></li><li><p><strong>Empirical risk</strong>: a.k.a. training corpus error:</p><ul><li>$R_{\text{emp}} = \frac{1}{n} \sum_{i=1}^{n} \ell(y_i, f(x_i))$</li></ul></li><li><p><strong>True risk</strong>, a.k.a. expected test corpus error:</p><ul><li>$R = \mathbb{E}[\ell(Y, f(X))] = R_{\text{emp}} + R_{\text{generalization}}$</li></ul></li><li><p>Usually, minimum test error and minimum dev error don’t occur at the same time</p></li><li><p>… but early stopping based on the test set is cheating,</p></li><li><p>… so early stopping based on the dev set is the best we can do w/o cheating.</p></li></ul><h2 id="Summary">Summary</h2><ul><li><strong>Biological inspiration</strong>: Neurons that fire together wire together. Given enough training examples <em><strong>(x<sub>i</sub>, y<sub>i</sub>)</strong></em>, can we learn a desired function so that <em><strong>f(x) ≈ y</strong></em>?</li><li><strong>Classification tree</strong>: Learn a sequence of if-then statements that computes <em><strong>f(x) ≈ y</strong></em></li><li><strong>Mathematical definition of supervised learning</strong>: Given a training dataset, <em><strong>D = {(x<sub>1</sub>, y<sub>1</sub>), …, (x<sub>n</sub>, y<sub>n</sub>)}</strong></em> , find a function <em><strong>f</strong></em> that minimizes the risk, <em><strong>ℛ = E[ℓ(Y, f(x))]</strong></em>.</li><li><strong>Overtraining</strong>: $ℛ_ {emp} = \frac{1}{n} \sum^n_{i=1} ℓ*y_i, f(x_i))$ reaches zero if you train long enough.</li><li><strong>Early Stopping</strong>: Stop when error rate on the dev set reaches a minimum</li></ul><style>pre {  background-color:#38393d;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Learning Progress</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Class" scheme="https://karobben.github.io/categories/Notes/Class/"/>
    
    <category term="UIUC" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/"/>
    
    <category term="AI" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/AI/"/>
    
    
    <category term="Machine Learning" scheme="https://karobben.github.io/tags/Machine-Learning/"/>
    
    <category term="Data Science" scheme="https://karobben.github.io/tags/Data-Science/"/>
    
  </entry>
  
  <entry>
    <title>Naive Bayes and Bayes NetWork</title>
    <link href="https://karobben.github.io/2024/02/01/LearnNotes/ai-bayes/"/>
    <id>https://karobben.github.io/2024/02/01/LearnNotes/ai-bayes/</id>
    <published>2024-02-02T05:20:50.000Z</published>
    <updated>2024-02-16T07:31:11.403Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Naive-Bayes">Naïve Bayes</h2><div class="admonition note"><p class="admonition-title">The problem with likelihood: Too many words</p><p>What does it mean to say that the words, x, have a particular probability?<br>Suppose our training corpus contains two sample emails:<br></p><ul><li>Email1: Y = spam, X =&quot;Hi there man – feel the vitality! Nice meeting you…&quot;<br></li><li>Email2: Y = ham, X =&quot;This needs to be in production by early afternoon…&quot;<br></li></ul><p>Our test corpus is just one email:<br></p><ul><li>Email1: X=&quot;Hi! You can receive within days an approved prescription for increased vitality and stamina&quot;<br>How can we estimate P(X=&quot;Hi! You can receive within days an approved prescription for increased vitality and stamina&quot;|Y = spam)?<br></li></ul></div><p>One thing we could do is:</p><ol><li>$P(W = \text{“hi”} | Y = \text{spam}), P(W = \text{“hi”} | Y = \text{ham})$</li><li>$P(W = \text{“vitality”} | Y = \text{spam}), P(W = \text{“vitality”} | Y = \text{ham})$</li><li>$P(W = \text{“production”} | Y = \text{spam}), P(W = \text{“production”} | Y = \text{ham})$</li></ol><p>Then the approximation formula for $P(X | Y)$ is given by:</p><p>$$ P(X = x | Y = y) \approx \prod_{i=1}^{n} P(W = w_i | Y = y) $$</p><p>In this context, $W$ represents a word in a document, $X$ represents the document itself, $Y$ represents the class (spam or ham), $w_i$ represents the $i$-th word in the document, and $n$ is the total number of words in the document. The product is taken over all words in the document, assuming that the words are conditionally independent of each other given the class label $Y$.</p><div class="admonition question"><p class="admonition-title">Why naïve Bayes is naïve?</p><p>We call this model &quot;naïve Bayes&quot; because the words aren't really conditionally independent given the label. For example, the sequence &quot;for you&quot; is more common in spam emails than it would be if the words &quot;for&quot; and &quot;you&quot; were conditionally independent.<br><strong>True Statement</strong>:<br></p><ul><li><em><strong>P(X = for you|Y= Spam &gt; P( W = for |Y = Spam)(P = you |= Spam)</strong></em><br>The naïve Bayes approximation simply says: estimating the likelihood of every word sequence is too hard, so for computational reasons, we'll pretend that sequence probability doesn't matter.<br></li></ul><p><strong>Naïve Bayes Approximation</strong>:<br></p><ul><li><em><strong>P(X = for you |Y = Spam) ≈ P(W = for |Y = Spam)P( W= you |Y= Spam)</strong></em><br>We use naïve Bayes a lot because, even though we know it's wrong, it gives us computationally efficient algorithms that work remarkably well in practice.</li></ul></div><h3 id="MPE-MAP-using-Bayes’-rule">MPE = MAP using Bayes’ rule</h3><p>$$<br>P(Y= y | X= x) = \frac{P(X =x| Y=y)P(Y = y)}{P(X =x)}<br>$$</p><p>Definition of conditional probability:</p><p>$$<br>P(Y|f(X), A) = \frac{P(f(X)|Y, A)P(Y|A)}{P(f(X)|A)}<br>$$</p><h3 id="Floating-point-underflow">Floating-point underflow</h3><p>That equation has a computational issue. Suppose that the probability of any given word is roughly <em><strong>P(W = W<sub>i</sub>|Y = y) ≈ 10<sup>-3</sup></strong></em>, and suppose that there are 103 words in an email. Then <em><strong>∏<sup>n</sup><sub>i=1</sub> P(W = W<sub>i</sub>|Y = y) = 10<sup>-309</sup></strong></em>,which gets rounded off to zero. This phenomenon is called “floating-point underflow”.</p><div class="admonition note"><p class="admonition-title">Solution</p><p>$$f(x) = \underset{y}{\mathrm{argmax}} \left( \ln P(Y = y) + \sum^n_{i=1} \ln P(W = w_i | Y = y) \right)$$</p></div><h3 id="Reducing-the-naivety-of-naive-Bayes">Reducing the naivety of naïve Bayes</h3><p>Remember that the bag-of-words model is unable to represent this fact:</p><ul><li><p><strong>True Statement</strong>:</p><ul><li><em><strong>P(X = for you|Y= Spam &gt; P( W = for |Y = Spam)(P = you |= Spam)</strong></em><br>Though the bag-of-words model can’t represent that fact, we can represent it using a slightly more sophisticated naïve Bayes model, called a “bigram” model.</li></ul></li><li><p>N-Grams:</p><ul><li>Unigram: a unigram (1-gram) is an isolated word, e.g., “you”</li><li>Bigram: a bigram (2-gram) is a pair of words, e.g., “for you”</li><li>Trigram: a trigram (3-gram) is a triplet of words, e.g., “prescription for you”</li><li>4-gram: a 4-gram is a 4-tuple of words, e.g., “approved prescription for you”</li></ul></li></ul><div class="admonition note"><p class="admonition-title">Bigram naïve Bayes</p><p>A bigram naïve Bayes model approximates the bigrams as conditionally independent, instead of the unigrams. For example,<br><em><strong>P(X = “approved prescription for you” | Y= Spam) ≈</strong></em><br><em><strong>P(B = “approved prescription” |Y = Spam) ×</strong></em><br><em><strong>P(B = “prescription for” | Y= Spam) ×</strong></em><br><em><strong>P(B = “for you” |Y = Spam)</strong></em></p></div><ul><li>The naïve Bayes model has two types of parameters:<ul><li>The a priori parameters: <em><strong>P(Y = y)</strong></em></li><li>The likelihood parameters: <em><strong>P(W = w<sub>i</sub>| Y = y)</strong></em></li></ul></li><li>In order to create a naïve Bayes classifiers, we must somehow estimate the numerical values of those parameters.</li><li>Model parameters: feature likelihoods <em><strong>P(Word | Class)</strong></em> and priors <em><strong>P(Class)</strong></em></li></ul><h3 id="Parameter-estimation-Prior">Parameter estimation: Prior</h3><p>The prior, <em><strong>P(x)</strong></em>, is usually estimated in one of two ways.</p><ul><li>If we believe that the test corpus is like the training corpus, then we just use frequencies in the training corpus:<br>$$<br>P(Y = Spam) = \frac{Docs(Y=Spam)}{Docs(Y=Spam) + Docs(Y \neq Spam)}<br>$$<br>where <em><strong>Docs(Y=Spam)</strong></em> means the number of documents in the training corpus that have the label Y=Spam.</li><li>If we believe that the test corpus is different from the training corpus, then we set <em><strong>P(Y = Spam)</strong></em> = the frequency with which we believe spam will occur in the test corpus.</li></ul><h3 id="Parameter-estimation-Likelihood">Parameter estimation: Likelihood</h3><p>The likelihood, ***P(W = w<sub>i</sub>|Y = y), is also estimated by counting. The “maximum likelihood estimate of the likelihood parameter” is the most intuitively obvious estimate:<br>$$<br>P(W=w_i| Y = Spam) = \frac{Count(W=w_i, Y = Spam)}{Count(Y = Spam)}<br>$$<br>where <em><strong>Count(W=w<sub>i</sub>, Y = Spam)</strong></em> means the number of times that the word <em><strong>w<sub>i</sub></strong></em> occurs in the Spam portion of the training corpus, and <em><strong>Count(Y = Spam)</strong></em> is the total number of words in the Spam portion.</p><h3 id="Laplace-Smoothing-for-Naive-Bayes">Laplace Smoothing for Naïve Bayes</h3><p>One of the biggest challenge for Bayes is it can’t handle unobserved situation.</p><ul><li><p>The basic idea: add $k$ “unobserved observations” to the count of every unigram</p><ul><li>If a word occurs 2000 times in the training data, Count = 2000+k</li><li>If a word occur once in training data, Count = 1+k</li><li>If a word never occurs in the training data, then it gets a pseudo-Count of $k$</li></ul></li><li><p>Estimated probability of a word that occurred Count(w) times in the training data:<br>$$ P(W = w) = \frac{k + \text{Count}(W = w)}{k + \sum_v (k + \text{Count}(W = v))} $$</p></li><li><p>Estimated probability of a word that never occurred in the training data (an “out of vocabulary” or OOV word):<br>$$ P(W = \text{OOV}) = \frac{k}{k + \sum_v (k + \text{Count}(W = v))} $$</p></li><li><p>Notice that<br>$$ P(W = \text{OOV}) + \sum_w P(W = w) = 1 $$</p></li></ul><h2 id="Bayesian-Networks">Bayesian Networks</h2><div class="admonition question"><p class="admonition-title">Why Network?</p><ul><li>Example: $Y$ is a scalar, but $X = [X_1, … , X_{100}]^T$ is a vector</li><li>Then, even if every variable is binary, $P(Y = y|X = x)$ is a table with $2^{101}$ numbers. Hard to learn from data; hard to use.</li></ul></div><p>A better way to represent knowledge: Bayesian network</p><ul><li>Each variable is a node.</li><li>An arrow between two nodes means that the child depends on the parent.</li><li>If the child has no direct dependence on the parent, then there is no arrow.</li></ul><h3 id="Space-Complexity-of-Bayesian-Network">Space Complexity of Bayesian Network</h3><pre class="mermaid">graph LR    B --> A    E --> A    A --> J    A --> M</pre><ul><li>Without the Bayes network: I have 5 variables, each is binary, so the probability distribution $P(B, E, A, M, J)$ is a table with $2^5 = 32$ entries.</li><li>With the Bayes network:<ul><li>Two of the variables, B and E, depend on nothing else, so I just need to know $P(B = ⊤)$ and $P(E = ⊤)$ — 1 number for each of them.</li><li>M and J depend on A, so I need to know $P(M = ⊤|A = ⊤)$ and $P(M = ⊤|A = ⊥)$ – 2 numbers for each of them.</li><li>A depends on both B and E, so I need to know $P(A = ⊤|B = b, E =e)$ for all 4 combinations of $(b, e)$</li><li>Total: 1+1+2+2+4 = 10 numbers to represent the whole distribution!</li></ul></li></ul><p>$$<br>P(B = T \mid J = T, M = T) = \frac{P(B = T, J = T, M = T)}{P(J = T, M = T)} \\<br>= \frac{P(B = T, J = T, M = T)}{P(J = T, M = T)} + \frac{P(B = L, J = T, M = T)}{P(J = T, M = T)} \\<br>= \sum_{e=T}^{L} \sum_{a=T}^{L} P(B = T, E = e, A = a, J = T, M = T) \\<br>= \sum_{e=T}^{L} \sum_{a=T}^{L} P(B = T) P(E = e) \ × \\<br>P(A = a \mid B = T, E = e) P(J = T \mid A = a) P(M = T \mid A = a)<br>$$</p><h3 id="Variables-are-independent-and-or-conditionally-independent">Variables are independent and/or conditionally independent</h3><h4 id="Independence">Independence</h4><pre class="mermaid">graph TDB --> AE --> A</pre><ul><li>Variables are independent if they have no common ancestors<br>$ P(B = \top, E = \top) = P(B = \top)P(E = \top)= P(B = \top) $</li></ul><p>!!! Independent variables may not be conditionally independent</p><ul><li>The variables B and E are not conditionally independent of one another given knowledge of A</li><li>If your alarm is ringing, then you probably have an earthquake OR a burglary. If there is an earthquake, then the conditional probability of a burglary goes down:<ul><li>$P(B = \top| E = \top, A = \top) \neq P(B = \top| E = \bot, A = \top)$</li></ul></li><li>This is called the “explaining away” effect. The earthquake “explains away” the alarm, so you become less worried about a burglary.</li></ul><h4 id="Conditional-Independence">Conditional Independence</h4><pre class="mermaid">graph TDA --> JA --> M</pre><ul><li>The variables J and M are conditionally independent of one another given knowledge of A</li><li>If you know that there was an alarm, then knowing that John texted gives no extra knowledge about whether Mary will text:<br>$P(M = \top | J = \top , A = \top)=P(M = \top | J = \bot, A = \top)= P(M = \top| A = \top)$</li></ul><div class="admonition note"><p class="admonition-title">Conditionally Independent variables may not be independent</p><ul><li>The variables J and M are not independent!</li><li>If you know that John texted, that tells you that there was probably an alarm. Knowing that there was an alarm tells you that Mary will probably text you too:</li><li>$P(M = \top| J = \top) \neq P(M= \top| J = \bot)$</li></ul></div><ul><li>Variables are conditionally independent of one another, given their common ancestors, if (1) they have no common descendants, and (2) none of the descendants of one are ancestors of the other<br>$ P(U = T, M = T \mid A = T) = P(U = T \mid A = T)P(M = T \mid A = T) $</li></ul><h4 id="How-to-tell-at-a-glance-if-variables-are-independent-and-or-conditionally-independent">How to tell at a glance if variables are independent and/or conditionally independent</h4><pre class="mermaid">graph LR    B --> A    E --> A    A --> J    A --> M</pre><ul><li>Variables are independent if they have no common ancestors<ul><li>$P(B = \top, E = \top) = P(B=\top)P(E =\top)$</li></ul></li><li>Variables are conditionally independent of one another, given their common ancestors, if:<ol><li>they have no common descendants, and</li><li>none of the descendants of one are ancestors of the other</li></ol><ul><li>$P(J = \top, M = \top| A = \top) = P(J = \top| A = \top) P (M = \top| A = \top)$</li></ul></li></ul><style>pre {  background-color:#EEFFEF ;  color: #5fd381;}</style>]]></content>
    
    
    <summary type="html">Naive Bayes and Bayes NetWork</summary>
    
    
    
    <category term="Notes" scheme="https://karobben.github.io/categories/Notes/"/>
    
    <category term="Class" scheme="https://karobben.github.io/categories/Notes/Class/"/>
    
    <category term="UIUC" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/"/>
    
    <category term="AI" scheme="https://karobben.github.io/categories/Notes/Class/UIUC/AI/"/>
    
    
    <category term="Machine Learning" scheme="https://karobben.github.io/tags/Machine-Learning/"/>
    
    <category term="Data Science" scheme="https://karobben.github.io/tags/Data-Science/"/>
    
  </entry>
  
</feed>
