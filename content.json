{"pages":[],"posts":[{"title":"Simulated Annealing (SA)","text":"Video tutorial: Challenging Luck, 2021 Practicing Python code: challengingLuck: Using Annealing Algorithm to Solve the Sudo Challenge Simulated Annealing (SA) is a probabilistic technique used for finding an approximate solution to an optimization problem. It is particularly useful for problems where the search space is large and complex, and other methods might get stuck in local optima. Here’s a structured way to start learning about the Simulated Annealing algorithm: $$ P(E, E’, T) = \\begin{cases} 1 &amp; \\text{if } E’ &lt; E \\\\ \\exp\\left(\\frac{-(E’ - E)}{T}\\right) &amp; \\text{if } E’ \\ge E \\end{cases} $$ This idea is similar to DNA annealing during PCR. During the temperature drop after the high-temperature mutation, the DNA gradually returns to the double strand with its reverse complement strand or the primer due to the decrease in entropy. Unlike DNA annealing, Simulated Annealing (SA) introduces random values to replace the original ones. After that, the “Energy” is calculated, and only when the new score is lower than the previous one is the new value accepted, continuing the iteration until the lowest value is found. It works like this: Calculate the initial E → randomly mutate the value and calculate the new E' → if E' ≤ E, then accept the mutated element; otherwise, try another value → if E' meets the lowest E, stop; otherwise, continue until no smaller E' can be found. As a result, you could expect that it would waste a lot of resources on exploration and easily fall into local optima. An example of the SA apply in sudo challenge In this example, it actually failed to get the result because it fall into local optimal. It is a very good example to show the capability and limitations of the SA. SA and Stochastic gradient descent $$ w_{t+1} = w_t - \\eta \\nabla f(w_t; x_i) $$ $w$ is the parameter, weight matrix, for example. While $w_t$ is the old one and the $w_{t-1}$ is updated parameter. $\\eta$ is the learning rate $x$ is the input Stochastic Gradient Descent (SGD) is an optimization algorithm used primarily for training machine learning models. It iteratively updates the model parameters by computing the gradient of the loss function using a randomly selected subset (mini-batch) of the training data, rather than the entire dataset. This randomness introduces variability in the updates, which helps escape local optima and speeds up convergence. The learning rate controls the step size of each update, determining how far the parameters move in the direction of the negative gradient. By continuously adjusting the parameters, SGD aims to minimize the loss function and improve the model’s performance. So, it is very similar to Stochastic gradient descent (SGD). But for SGD, there are a learning process from the data. SGD is primally based on the exploitation. But in SA, exploration has more contribution compared with SGD because it hugely relies on random generation first and evaluating later. SA and Genetic Algorithm (GA) What is GA? Genetic Algorithms (GA) are evolutionary algorithms inspired by the principles of natural selection and genetics. They work by evolving a population of candidate solutions through successive generations. Each generation undergoes selection, where the fittest individuals are chosen based on their performance. These selected individuals then undergo crossover (recombination) to produce offspring that combine their parents’ characteristics. Additionally, mutation introduces random changes to some individuals to maintain genetic diversity within the population. This process of selection, crossover, and mutation allows GAs to explore a wide search space and balance between exploring new solutions and exploiting the best solutions found so far. This diversity helps GAs avoid getting trapped in local optima, making them effective for solving complex optimization problems, including those that are non-differentiable and non-convex. From a personal point of view, GA is like an upgraded version of SA. SA works at the level of a single individual, while GA operates at the population level. Similar to SA, GA evaluates and selects the “fitness scores” of each individual. The next generation introduces many random mutations, just like SA. However, unlike SA, GA also includes “crossover” steps, which can help enrich the “better phenotypes”. Feature Simulated Annealing (SA) Stochastic Gradient Descent (SGD) Genetic Algorithm (GA) Approach Probabilistic, accepts worse solutions occasionally Deterministic, updates in the direction of the gradient Evolutionary, uses selection, crossover, and mutation Objective Function Non-differentiable and non-convex functions Differentiable functions Non-differentiable and non-convex functions Exploration vs. Exploitation Balances both, reduces acceptance of worse solutions over time Primarily exploitation with some exploration via mini-batches Balances both, uses population diversity to explore the search space Cooling Schedule / Learning Rate Uses a cooling schedule to reduce probability of accepting worse solutions Uses a learning rate to control step size of updates Uses selection pressure to favor better solutions and mutation rate to introduce diversity Population-Based No No Yes, operates on a population of solutions Escape Local Optima Yes, by accepting worse solutions with a probability Limited, may get stuck in local optima Yes, by maintaining a diverse population Gradient Requirement No Yes No Applications Combinatorial and continuous optimization without gradients Training machine learning models, especially in deep learning Optimization problems, including scheduling, design, and artificial intelligence Natural Inspiration Annealing in metallurgy Gradient descent in calculus Natural selection and genetics Operators Acceptance probability based on temperature Gradient-based updates Selection, crossover (recombination), and mutation table from: ChatGPT4o pre { background-color:#38393d; color: #5fd381; }","link":"/2024/05/30/AI/SAnnealing/"},{"title":"Perceptron","text":"Perceptron Perceptron is invented before the loss function Linear classifier: Definition A linear classifier is defined by $$ f(x) = \\text{argmax } Wx + b $$ $$ W \\mathbf{x} + \\mathbf{b} = \\begin{bmatrix} W_{1,1} &amp; \\cdots &amp; W_{1,d} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ W_{v,1} &amp; \\cdots &amp; W_{v,d} \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_d \\end{bmatrix} + \\begin{bmatrix} b_1 \\\\ \\vdots \\\\ b_v \\end{bmatrix} = \\begin{bmatrix} \\mathbf{w}_1^T \\mathbf{x} + b_1 \\\\ \\vdots \\\\ \\mathbf{w}_v^T \\mathbf{x} + b_v \\end{bmatrix} $$ where: $w_k, b_k$ are the weight vector and bias corresponding to class $k$, and the argmax function finds the element of the vector $wx$ with the largest value. There are a total of $v(d + 1)$ trainable parameters: the elements of the matrix $w$. Example Consider a two -class classification problem, with $W^T_1 = [w_{1,1}, w_{1,2}] = [2,1]$ $W^T_2 = [w_{2,1}, w_{2,2}] = [1,2]$ Notice that in the two-class case, the equation $$ f(x) = \\text{argmax } Wx + b $$ Simplifies to $$ f(x) = \\begin{cases} 1 &amp; \\ if\\ w_1^T x + b_1 &gt; w_2^T x + b_2 \\\\ 2 &amp; \\ if\\ w_1^T x + b_1 \\leq w_2^T x + b_2 \\end{cases} $$ The class boundary is the line whose equation is $$ (w_2 - w_1)^T x + (b_2 - b_1) = 0 $$ Extend: Multi-class linear classifier The boundary between class $k$ and class $l$ is the line (or plane, or hyperplane) given by the equation $f(x) = argmax Wx + b$ $(w_k - w_l)^T x + (b_k - b_l) = 0$ The classification regions in a linear classifier are called Voronoi regions. A Voronoi region is a region that is • Convex (if $u$ and $v$ are points in the region, then every point on the line segment $\\bar{u}\\bar{v}$ connecting them is also in the region) • Bounded by piece-wise linear boundaries Multi-class linear classifier $ f(\\mathbf{x}) = \\arg\\max (W\\mathbf{x} + \\mathbf{b}) $ The boundary between class ( k ) and class ( l ) is the line (or plane, or hyperplane) given by the equation: $ (\\mathbf{w}_k - \\mathbf{w}_l)^T \\mathbf{x} + (b_k - b_l) = 0 $ Gradient descent Suppose we have training tokens $(x_i, y_i)$, and we have some initial class vectors $w_1$ and $w_2$. We want to update them as $w_1 \\leftarrow w_1 - \\eta \\frac{\\partial \\mathcal{L}}{\\partial w_1}$$w_2 \\leftarrow w_2 - \\eta \\frac{\\partial \\mathcal{L}}{\\partial w_2}$ …where $\\mathcal{L}$ is some loss function. What loss function makes sense? Zero-one loss function The most obvious loss function for a classifier is its classification error rate, $$ \\mathcal{L} = \\frac{1}{n} \\sum_{i=1}^{n} \\ell(f(x_i), y_i) $$ Where $\\ell(\\hat{y}, y)$ is the zero-one loss function, $$ \\ell(f(x), y) = \\begin{cases} 0 &amp; \\text{if } f(x) = y \\\\ 1 &amp; \\text{if } f(x) \\neq y \\end{cases} $$ Non-differentiable! The problem with the zero-one loss function is that it’s not differentiable: $$ \\frac{\\partial \\ell (f(\\mathbf{x}), y)}{\\partial f(\\mathbf{x})} = \\begin{cases} 0 &amp; f(\\mathbf{x}) \\neq y \\\\ +\\infty &amp; f(\\mathbf{x}) = y^+ \\\\ -\\infty &amp; f(\\mathbf{x}) = y^- \\end{cases} $$ One-hot vectors One-hot vectors, A one-hot vector is a binary vector in which all elements are 0 except for a single element that’s equal to 1. Take binary classification as an example: class1: [1, 0] class2: [0, 1] The number of element in the list equals the number of classes. Consider the classifier $$ f(x) = \\begin{bmatrix} f_1(\\mathbf{x}) \\\\ f_2(\\mathbf{x}) \\end{bmatrix} = \\begin{bmatrix} \\mathbb{1}_ {\\arg\\max W\\mathbf{x}=1} \\\\ \\mathbb{1}_ {\\arg\\max W\\mathbf{x}=2} \\end{bmatrix} $$ …where (\\mathbb{1}_P) is called the “indicator function,” and it means: $$ \\mathbb{1}_P = \\begin{cases} 1 &amp; P \\text{ is true} \\\\ 0 &amp; P \\text{ is false} \\end{cases} $$ Loss Exp2: Multi-Class Consider the classifier $$ f(x) = \\begin{bmatrix} f_1(x) \\\\ \\vdots \\\\ f_v(x) \\end{bmatrix} = \\begin{bmatrix} 1_{\\arg\\max Wx=1} \\\\ \\vdots \\\\ 1_{\\arg\\max Wx=v} \\end{bmatrix} $$ … with 20 classes. Then some of the classifications might look like this. One-hot ground truth We can also use one-hot vectors to describe the ground truth. Let’s call the one-hot vector $y$, and the integer label $y$, thus $$ y = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\end{bmatrix} = \\begin{bmatrix} 1_{y=1} \\\\ 2_{y=2} \\end{bmatrix} $$ Ground truth might differ from classifier output. Instead of a one-zero loss, the perceptron uses a weird loss function that gives great results when differentiated. The perceptron loss function is: $$ \\ell(x, y) = (f(x) - y)^T (Wx + b) $$ $$ = \\left[ f_1(x) - y_1, \\ldots, f_v(x) - y_v \\right] \\left(\\begin{bmatrix} W_{1,1} &amp; \\ldots &amp; W_{1,d} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ W_{v,1} &amp; \\ldots &amp; W_{v,d} \\end{bmatrix} \\begin{bmatrix} x_{1} \\\\ \\vdots \\\\ x_{d} \\end{bmatrix} + \\begin{bmatrix} b_{1} \\\\ \\vdots \\\\ b_{v} \\end{bmatrix}\\right) $$ $$ = \\sum_{k=1}^{v} (f_k(x) - y_k)(W_k^T x + b_k) $$ The perceptron loss Instead of a one-zero loss, the perceptron uses a weird loss function that gives great results when differentiated. The perceptron loss function is: $$ \\ell(\\mathbf{x}, \\mathbf{y}) = (f(\\mathbf{x}) - \\mathbf{y})^T (W \\mathbf{x} + \\mathbf{b}) $$ $$ = [f_1(\\mathbf{x}) - y_1, \\cdots, f_v(\\mathbf{x}) - y_v] \\begin{pmatrix} \\begin{bmatrix} W_{1,1} &amp; \\cdots &amp; W_{1,d} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ W_{v,1} &amp; \\cdots &amp; W_{v,d} \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_d \\end{bmatrix} + \\begin{bmatrix} b_1 \\\\ \\vdots \\\\ b_v \\end{bmatrix} \\end{pmatrix} $$ $$ = \\sum_{k=1}^{v} (f_k(\\mathbf{x}) - y_k)(\\mathbf{w}_k^T \\mathbf{x} + b_k) $$ The perceptron learning algorithm Compute the classifier output $\\hat{y} = \\arg\\max_k (\\mathbf{w}_k^T \\mathbf{x} + b_k)$ Update the weight vectors as: $$ \\mathbf{w}_k \\leftarrow \\mathbf{w}_k - \\eta \\frac{\\partial \\ell(\\mathbf{x}, \\mathbf{y})}{\\partial \\mathbf{w}_k} = \\begin{cases} \\mathbf{w}_k - \\eta \\mathbf{x} &amp; \\text{if } k = \\hat{y} \\\\ \\mathbf{w}_k + \\eta \\mathbf{x} &amp; \\text{if } k = y \\\\ 0 &amp; \\text{otherwise} \\end{cases} $$ where $\\eta \\approx 0.01$ is the learning rate. Because: Because teh gradient of the perceptron loss is: $$ \\frac{\\partial \\ell(\\mathbf{x}, \\mathbf{y})}{\\partial \\mathbf{w}_k} = \\begin{cases} \\mathbf{x} &amp; \\text{if } k = \\hat{y} \\\\ -\\mathbf{x} &amp; \\text{if } k = y \\\\ 0 &amp; \\text{otherwise} \\end{cases} $$ So, we could have: $$ \\mathbf{w}_k \\leftarrow \\begin{cases} \\mathbf{w}_k - \\eta \\mathbf{x} &amp; k = \\hat{y} \\\\ \\mathbf{w}_k + \\eta \\mathbf{x} &amp; k = y \\\\ 0 &amp; \\text{otherwise} \\end{cases} $$ Special case: two classes If there are only two classes, then we only need to learn one weight vector, $w = w_1 - w_2$. We can learn it as: Compute the classifier output $\\hat{y} = \\arg\\max_k (w_k^T x + b_k)$ Update the weight vectors as: $$ w \\leftarrow \\begin{cases} w - \\eta x &amp; \\text{if } \\hat{y} \\neq y, y = 2 \\\\ w + \\eta x &amp; \\text{if } \\hat{y} \\neq y, y = 1 \\\\ w &amp; \\text{if } \\hat{y} = y \\end{cases} $$ where $\\eta \\approx 0.01$ is the learning rate. Sometimes we say $y \\in {1, -1}$ instead of $y \\in {1,2}$. pre { background-color:#38393d; color: #5fd381; }","link":"/2024/02/07/AI/ai-perceptron/"},{"title":"Linear Regression","text":"Linear Regression Vectors and Matrix In numpy, the dot product can be written np.dot(w,x) or w@x. Vectors will always be column vectors. Thus: $$ x = \\begin{bmatrix} x_{1} \\\\ \\vdots \\\\ x_{n} \\end{bmatrix} , \\quad w^T = [w_{1}, \\ldots, w_{n}] $$ $$ w^Tx = [w_{1}, \\ldots, w_{n}] \\begin{bmatrix} x_{1} \\\\ \\vdots \\\\ x_{n} \\end{bmatrix} = \\sum_{i=1}^{n} w_{i}x_{i} $$ $$ x = \\begin{bmatrix} x_{1} \\\\ \\vdots \\\\ x_{n} \\end{bmatrix} , \\quad W = \\begin{bmatrix} w_{1,1} &amp; \\ldots &amp; w_{1,n} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ w_{m,1} &amp; \\ldots &amp; w_{m,n} \\end{bmatrix} $$ $$Wx = \\begin{bmatrix} w_{1,1} &amp; \\ldots &amp; w_{1,n} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ w_{m,1} &amp; \\ldots &amp; w_{m,n} \\end{bmatrix} \\begin{bmatrix} x_{1} \\\\ \\vdots \\\\ x_{n} \\end{bmatrix} = \\begin{bmatrix} \\sum_{i=1}^{n} w_{1,i}x_{i} \\\\ \\vdots \\\\ \\sum_{i=1}^{n} w_{m,i}x_{i} \\end{bmatrix} $$ Vector and Matrix Gradients The gradient of a scalar function with respect to a vector or matrix is: The symbol $\\frac{\\sigma f}{\\sigma x_ 1}$ means “partial derivative of f with respect to x1” $$ \\frac{\\partial f}{\\partial x} = \\begin{bmatrix} \\frac{\\partial f}{\\partial x_1} \\\\ \\vdots \\\\ \\frac{\\partial f}{\\partial x_n} \\end{bmatrix} , \\quad \\frac{\\partial f}{\\partial W} = \\begin{bmatrix} \\frac{\\partial f}{\\partial w_{1,1}} &amp; \\cdots &amp; \\frac{\\partial f}{\\partial w_{1,n}} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\frac{\\partial f}{\\partial w_{m,1}} &amp; \\cdots &amp; \\frac{\\partial f}{\\partial w_{m,n}} \\end{bmatrix} $$ © Vladimir Nasteski $$ f(x) = w^ T x + b = \\sum_{j=0} ^{D-1} w_ j x_ j + b $$ $f(x) = y$ Generally, we want to choose the weights and bias, w and b, in order to minimize the errors. The errors are the vertical green bars in the figure at right, ε = f(x) − y. Some of them are positive, some are negative. What does it mean to “minimize” them? $ f(x) = w^ T x + b = \\sum_{j=0} ^{D-1} w_ j x_ j + b $ Training token errors Using that notation, we can define a signed error term for every training token: ε = f(xi) - yi The error term is positive for some tokens, negative for other tokens. What does it mean to minimize it? Mean-squared error Squared: tends to notice the big values and trying ignor small values. One useful criterion (not the only useful criterion, but perhaps the most common) of “minimizing the error” is to minimize the mean squared error: $$ \\mathcal{L} = \\frac{1}{2n} \\sum_{i=1}^ {n} \\varepsilon_i^ 2 = \\frac{1}{2n} \\sum_{i=1}^ {n} (f(x_ i) - y_ i)^ 2 $$ The factor $\\frac{1}{2}$ is included so that, so that when you differentiate ℒ , the 2 and the $\\frac{1}{2}$ can cancel each other. MSE = Parabola Notice that MSE is a non -negative quadratic function of f(x~i~) = w^T^ x~i~ + b, therefore it’s a non negative quadratic function of w . Since it’s a non -negative quadratic function of w, it has a unique minimum that you can compute in closed form! We won’t do that today. $\\mathcal{L} = \\frac{1}{2n} \\sum_{i=1}^ {n} (f(x_ i) - y_ i)^ 2$ The iterative solution to linear regression (gradient descent): Instead of minimizing MSE in closed form, we’re going to use an iterative algorithm called gradient descent. It works like this: Start: random initial w and b (at t=0) Adjust w and b to reduce MSE (t=1) Repeat until you reach the optimum (t = ∞). $ w \\leftarrow w - \\eta \\frac{\\partial \\mathcal{L}}{\\partial w} $ $ b \\leftarrow b - \\eta \\frac{\\partial \\mathcal{L}}{\\partial b} $ Finding the gradient The loss function $ \\mathcal{L} $ is defined as: $$ \\mathcal{L} = \\frac{1}{2n} \\sum_{i=1}^{n} L_i, \\quad L_i = \\varepsilon_i^2, \\quad \\varepsilon_i = w^T x_i + b - y_i $$ To find the gradient, we use the chain rule of calculus: $$ \\frac{\\partial \\mathcal{L}}{\\partial w} = \\frac{1}{2n} \\sum_{i=1}^{n} \\frac{\\partial L_i}{\\partial w}, \\quad \\frac{\\partial L_i}{\\partial w} = 2\\varepsilon_i \\frac{\\partial \\varepsilon_i}{\\partial w}, \\quad \\frac{\\partial \\varepsilon_i}{\\partial w} = x_i $$ Putting it all together, $$ \\frac{\\partial \\mathcal{L}}{\\partial w} = \\frac{1}{n} \\sum_{i=1}^{n} \\varepsilon_i x_i $$ • Start from random initial values of $w$ and $b(at\\ t= 0)$. • Adjust $w$ and $b$ according to: $$ w \\leftarrow w - \\frac{\\eta}{n} \\sum_{i=1}^{n} \\varepsilon_i x_i $$ $$ b \\leftarrow b - \\frac{\\eta}{n} \\sum_{i=1}^{n} \\varepsilon_i $$ Intuition: Notice the sign: $ w \\leftarrow w - \\frac{\\eta}{n} \\sum_{i=1}^{n} \\varepsilon_i x_i $ If $ \\varepsilon_i $ is positive ($ f(x_i) &gt; y_i $), then we want to reduce $ f(x_i) $, so we make $ w $ less like $ x_i $ If $ \\varepsilon_i $ is negative ($ f(x_i) &lt; y_i $), then we want to increase $ f(x_i) $, so we make $ w $ more like $ x_i $ Gradient Descent If $n$ is large, computing or differentiating MSE can be expensive. The stochastic gradient descent algorithm picks one training token $(x_i, y_i)$ at random (“stochastically”), and adjusts $w$ in order to reduce the error a little bit for that one token: $$ w \\leftarrow w - \\eta \\frac{\\partial \\mathcal{L}_i}{\\partial w} $$ …where $$ \\mathcal{L}_i = \\varepsilon_i^2 = \\frac{1}{2}(f(x_i) - y_i)^2 $$ Stochastic gradient descent $$ \\mathcal{L}_i = \\varepsilon_i^2 = \\frac{1}{2}(w^T x_i + b - y_i)^2 $$ If we differentiate that, we discover that: $$ \\frac{\\partial \\mathcal{L}_i}{\\partial w} = \\varepsilon_i x_i, \\quad \\frac{\\partial \\mathcal{L}_i}{\\partial b} = \\varepsilon_i $$ So the stochastic gradient descent algorithm is: $$ w \\leftarrow w - \\eta \\varepsilon_i x_i, \\quad b \\leftarrow b - \\eta \\varepsilon_i $$ Code Example import numpy as npfrom functools import partialfrom matplotlib.animation import FuncAnimationimport matplotlib.pyplot as pltdef updatew(x, y, W, b, e=0.01): E = np.sum(W*x +b - y) W -= np.sum(e*E*x) b -= e*E return W, bslope = 1intercept = 3std_dev = 1size = 100 # Size of the dataset# Generate x valuesX = np.random.uniform(low=-10, high=10, size=size)# Generate y values based on the equation y = x + 3# Add normal distributed noise with standard deviation of 0.4Y = slope * X + intercept + np.random.normal(0, std_dev, size)W = 0b = 0XX = []for i in range(len(X)): W,b = updatew(X[i], Y[i], W, b, .01) XX +=[[W, b]] plt.plot(X, Y, 'o')plt.plot(X, X*W + b)plt.text(-9, 9, f'slop = {round(W, 2)}\\nintercept = {round(b, 2)}')plt.show()# Your update function for the animationdef update(frame): # Update the data for the animated line plot, for example ln.set_data(X, X * XX[frame][0] + XX[frame][1] ) # Update the text for the current frame txt.set_text(str(int(frame)) +': $y = {:.2f}x + {:.2f}$'.format(XX[frame][0], XX[frame][1])) return ln, txt# Set up the figure and the line to animatefig, ax = plt.subplots()ln, = ax.plot([], [], 'r-', animated=True)txt = ax.text(-9, 9, '', animated=True) # Create a text object at (-9, 9)# Plot the background pointsax.plot(X, Y, 'o') # Static background points# Init function to set up the background of each frame (if necessary)def init(): ax.set_xlim(min(X), max(X)) ax.set_ylim(min(Y), max(Y)) txt.set_text('') return ln,# Create the animationani = FuncAnimation(fig, update, frames=100, init_func=init, blit=True)ani.save('animation_drawing.gif', writer='imagemagick', fps=10) PS: In the old script, I wasn’t fully understand how the linear regression works. So, I just made this script based on my personal understanding. So, you can find that I was using one dots from the set to calculate the loss and updates the $w$ and $b$ each time. But in real application situation, this way would make the updating process very noisy because single points could be very unreliable. According to the function above, we could use this function to update them: $ w \\leftarrow w - \\frac{\\eta}{n} \\sum_{i=1}^{n} \\varepsilon_i x_i $ $ b \\leftarrow b - \\frac{\\eta}{n} \\sum_{i=1}^{n} \\varepsilon_i $ For using this function, two things you may like to change from the example: # alter the weight and bias update functiondef updatew(X, Y, W, b, e=0.01): E = W*X +b - Y W -= np.sum(E*X) * e/ len(X) b -= np.sum(E) * e/ len(X) return W, b# starting the iteration and stop it manuallywhile True: W,b = updatew(X, Y, W, b, .05) print(W, b) How do them different from each other? Single Points loss Summed loss Last 5 rounds after so many iteration 1.1539 2.81111.1540 2.81051.2018 2.80541.1999 2.80210.9239 2.8350 0.9947 2.81710.9947 2.81710.9947 2.81710.9947 2.81710.9947 2.8171 Explained Because the result from a single point has significant noise, the jitter can never be eliminated, making it difficult to achieve local optimization. Because the loss is based on the entire dataset, it is very easy to achieve local optimization. This is why selecting an appropriate batch size during machine learning training is crucial. In the first example, the batch size is set to 1, while in the second, it equals the size of the training data. A very large batch size, such as using the entire dataset, can significantly increase the computational load, especially if the model is complex. Additionally, it may lead to the model getting stuck in local optima, which depends on the quality of the dataset. Therefore, choosing an appropriate batch size is essential for effective training. Perceptron Linear classifier: Definition A linear classifier is defined by $$ f(x) = \\text{argmax } Wx + b $$ where: $$ Wx + b = \\begin{bmatrix} w_{1,1} &amp; \\ldots &amp; w_{1,d} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ w_{v,1} &amp; \\ldots &amp; w_{v,d} \\end{bmatrix} \\begin{bmatrix} x_{1} \\\\ \\vdots \\\\ x_{d} \\end{bmatrix} + \\begin{bmatrix} b_{1} \\\\ \\vdots \\\\ b_{v} \\end{bmatrix}= \\begin{bmatrix} w_{1}^T x + b_{1} \\\\ \\vdots \\\\ w_{v}^T x + b_{v} \\end{bmatrix} $$ $w_k, b_k$ are the weight vector and bias corresponding to class $k$, and the argmax function finds the element of the vector $wx$ with the largest value. Gradient descent Suppose we have training tokens $(x_i, y_i)$, and we have some initial class vectors $w_1$ and $w_2$. We want to update them as $$ w_1 \\leftarrow w_1 - \\eta \\frac{\\partial \\mathcal{L}}{\\partial w_1} $$ $$ w_2 \\leftarrow w_2 - \\eta \\frac{\\partial \\mathcal{L}}{\\partial w_2} $$ …where $\\mathcal{L}$ is some loss function. What loss function makes sense? Transformation Transformations can be a powerful tool for addressing various issues with model assumptions or improving the model fit. Applying transformations can help meet the necessary assumptions of linear regression, which are linearity, constant variance, normality of residuals, and independence of errors. Common Transformations: Log, Square Root, Inverse, and Box-Cox Box-Cox Transformation: The Box-Cox transformation $ y_i^{(bc)} $ is defined as: $$ y_i^{(bc)} = \\begin{cases} \\frac{y_i^\\lambda - 1}{\\lambda} &amp; \\text{if } \\lambda \\neq 0 \\\\ \\ln(y_i) &amp; \\text{if } \\lambda = 0 \\end{cases} $$ This transformation is defined for $ y_i \\geq 0 $. It requires choosing an appropriate $ \\lambda $, which can be done using statistical libraries that maximize the likelihood or minimize skewness. Inverse Box-Cox Transformation: The inverse transformation, which is used to revert the transformed data back to its original scale, is given by: $$ y_i = \\begin{cases} \\left( | \\lambda y_i^{(bc)} + 1 |^{\\frac{1}{\\lambda}} \\right) &amp; \\text{if } \\lambda \\neq 0 \\\\ e^{y_i ^{(bc)}} &amp; \\text{if } \\lambda = 0 \\end{cases} $$ This transformation allows the original data values to be reconstructed from the transformed values, which is useful for interpretation and comparison with the original data scale after performing analyses or modeling on transformed data. Choosing $ \\lambda $** The value of $ \\lambda $ can significantly affect the skewness and homoscedasticity of the residuals in regression modeling. It is usually selected to maximize the log-likelihood function of obtaining the transformed data under a normal distribution assumption or through cross-validation procedures. Tools like R and Python offer built-in functions to automatically find the optimal $ \\lambda $ that best normalizes the data. For example, in R, the boxcox function from the MASS package can be used to estimate $ \\lambda $. How to find the λ Cross-validation consider choices of at different scales, e.g., λ ∈ {10−4, 10−3 ,10−2 ,10−1 ,1,10} for each λi, iteratively build new random Fold from Training Set fit Cross-Validation Train Set using compute MSE for current Fold on Validation set for each λi record average error σ and over all Folds λ with smallest error - largest λ within one σ. Regularization Regularization involves adding a penalty to the loss function that a model minimizes. This penalty typically discourages complex models by imposing a cost on having larger parameter values, thereby promoting simpler, more robust models. Types of Regularization Type Description Effect Equation L1 Regularization (Lasso) Adds the absolute value of the magnitude of coefficients as a penalty term. Leads to sparse models where some weights are zero, effectively performing feature selection. $ L = \\text{Loss} + \\lambda \\sum |\\beta_i| $ L2 Regularization (Ridge) Adds the squared magnitude of coefficients as a penalty term. Distributes weight more evenly across features, less robust to outliers than L1. $ L = \\text{Loss} + \\lambda \\sum \\beta_i^2 $ Elastic Net Combination of L1 and L2 regularization. Balances feature selection and robustness, useful for correlated features. $ L = \\text{Loss} + \\lambda_1 \\sum |\\beta_i| + \\lambda_2 \\sum\\beta_i^2 $ Role of Regularization in Modeling Preventing Overfitting: By penalizing large coefficients, regularization reduces the model’s tendency to memorize training data, thus helping it to generalize better to new, unseen data. Stability: Regularization can make the learning algorithm more stable by smoothing the optimization landscape. Handling Multicollinearity: In regression, multicollinearity can make the model estimation unstable and sensitive to noise in the data. Regularization helps by constraining the coefficients path. Regularization and $\\lambda$ In regularization, $ \\lambda $ (often called the regularization parameter) controls the strength of the penalty applied to the model. This is conceptually different from the $ \\lambda $ used in transformations like Box-Cox, though both involve tuning a parameter to achieve better model behavior: In Box-Cox transformations, $ \\lambda $ is selected to normalize the distribution of a variable or make relationships more linear. In regularization, $ \\lambda $ adjusts the trade-off between fitting the training data well (low bias) and keeping the model parameters small (low variance). Performance Residuals and Standardized Residuals Residuals: $e = y - \\hat{y} $ Mean Square Error: $m = \\frac{e^T e}{N}$ The equation you provided is for the standardized residual $ S_i $ in the context of regression analysis. Here’s a breakdown of the equation and its components: Standardized Residuals $$ S_i = \\frac{e_i}{\\sigma} = \\frac{e_i}{\\sqrt{\\frac{e^T e}{N} (1 - h_{i,i})}} $$ $ e_i $ is the residual for the $ i $-th observation, which is the difference between the observed value and the value predicted by the regression model. $ \\sigma $ is the estimated standard deviation of the residuals. $ e^T e $ is the sum of squared residuals. $ N $ is the number of observations. $ h_{i,i} $ is the leverage of the $ i $-th observation, a measure from the hat matrix that indicates the influence of the $ i $-th observation on its own predicted value. Explanation: Standardized Residuals: These are the residuals $ e_i $ normalized by an estimate of their standard deviation. Standardized residuals are useful for identifying outliers in regression analysis because they are scaled to have a variance of 1, except for their adjustment by the leverage factor. Leverage $ h_{i,i} $: The leverage is a value that indicates how far an independent variable deviates from its mean. High leverage points can have an unduly large effect on the estimate of regression coefficients. Square Root Denominator: The denominator of the standard deviation estimate involves the sum of squared residuals, which measures the overall error of the model, divided by the number of observations, adjusted for the leverage of each observation. This adjustment accounts for the fact that observations with higher leverage have a greater impact on the fit of the model and therefore should have less influence on the standardized residual. R2 $$ R^2 = \\frac{\\text{var}(\\hat{y})}{\\text{var}(y)} $$ $ \\text{var}(y) = \\frac{1}{N} \\sum_{i=1}^N (y_i - \\bar{y})^2 $ Cook’s distance Coefficients and prediction with full training set: $ y^{p} = X\\hat{\\beta} $ Coefficients and prediction excluding item i from training set: $ y_i^{p} = X\\hat{\\beta}_i $ Cook’s distance for point i: $$ \\text{Cook’s distance} = \\frac{(y^{p} - y_i^ {p})^ T (y^{p} - y_i^{p})}{dm} $$ Where: $d$ is the number of predictors (features) in the model, degree of freedom. $m = \\frac{e^T e}{N}$ is the mean squared error. $N$ is the number of observations in the dataset. pre { background-color:#38393d; color: #5fd381; }","link":"/2024/02/05/AI/ai-linear/"},{"title":"Multi-layer Neural Nets","text":"From linear to nonlinear classifiers Linear classifier a linear classifier computes $f(x) = argmax\\ Wx$ The resulting classifier divides the x-space into Voronoi regions: convex regions with piece-wise linear boundaries Nonlinear classifier Not all classification problems have convex decision regions with PWL boundaries! Here’s an example problem in which class 0 (blue) includes values of x near [0.8,0]T, but it also includes some values of x near [0.4,0.9]T You can’t compute this function using: $f(x) = argmax\\ Wx$ The solution: Piece-wise linear functions Nonlinear classifiers, can be learned using piece-wise linear classification boundaries Nonlinear regression problems, can be learned using piece-wise linear regression In the limit, as the number of pieces goes to infinity, the approximation approaches the desired solution Introduction Video tutorial: Intro to Deep Learning; Apr. 29, 2024 Slides PDF: Slides Perceptron and Neural Network For multi Output Perceptron: Multi Output Perceptron Single Layer Neural Network $$z_i = w_{0,i} + \\sum^m_{j=1} x_j w_{j,i}$$ $$ z_i = w_{0,i}^{(1)} + \\sum_{j=1}^{m} x_j w_{j,i}^{(1)} $$ $$ \\hat{y}_ i = g \\left( w_ {0,i}^ {(2)} + \\sum_ {j=1}^ {d_ 1} g(z_ j) w_ {j,i}^ {(2)} \\right) $$ © Alexander Amini © Alexander Amini By comparing them based on this illustration, we can see that the Perceptron and neural network architectures are very similar. The difference lies in the output parts. For a Perceptron, after the perceptron learns the $z$, the results are based directly on $g(z)$. However, in a neural network, after the model learns $z$, it still needs to learn the $w^{(2)}$, and the result is based on both $z$ and $w^{(2)}$. In this case, $z$ becomes a hidden layer. For Deep neural network, we just simply increasing the layers of hidden layer which is $z_ n → z_ {n, m}$. Quantifying Loss By following the function above, we know that for a single layer neural net work with single output, $\\hat{y} = g \\left( w^ {(2)} + \\sum_ {j=1}^ {d_ 1} g(z_ j) w_ {j}^ {(2)} \\right) $ or just $\\hat{y} = g(x^{(i)}; W)$. So, we could define that the loss: $\\mathcal{L}(f(x^{(i)}; \\mathbf{W}), y^{(i)})$. Hence, the Empirical Loss which measure the total loss should be: $$ J(W) = \\frac{1}{n} \\sum^n_ {i=1} \\mathcal{L}(f(x^{(i)}; \\mathbf{W}), y^{(i)}) $$ According to the classification test or regression test, we could selected tow types of basic loss function: Binary Cross-Entropy Loss: $ \\mathcal{L} = -\\frac{1}{N} \\sum_{i=1}^{N} \\left[ y^{(i)} \\log(f(x^{(i)})) + (1 - y^{(i)}) \\log(1 - f(x^{(i)})) \\right] $ Mean Squared Error Loss: $ \\mathcal{L} = \\frac{1}{N} \\sum_{i=1}^{N} \\left( y^{(i)} - f(x^{(i)}) \\right)^2 $ Training The logic of training is very simple and clear: we want to find the weight that achieve the lowest loss. We random pick initial value of $w$ and updated when we find a new $w$ which could achieve lower loss. By doing this, we could compute the gradient: $ \\frac{\\partial J(W)}{\\partial W} $ The way of update the weight is very similar to perceptron: $W \\leftarrow W - \\eta \\frac{\\partial J(w)}{\\partial w} $ Backpropagation Backpropagation is a key algorithm in training neural networks, which utilizes the chain rule to compute the gradient of the loss function with respect to each weight in the network. Let’s break down the images and the concepts step-by-step: Backpropagation, short for “backward propagation of errors,” is a fundamental algorithm used to train artificial neural networks. It is based on the concept of gradient descent and helps in minimizing the error by adjusting the weights of the network. Here’s a step-by-step explanation and a guide on how to calculate it: Understanding Backpropagation Forward Pass: Input data is passed through the neural network layer by layer to obtain the output. Each layer performs a weighted sum of inputs, applies an activation function, and passes the result to the next layer. Loss Calculation: The network’s output is compared to the actual target output using a loss function (e.g., Mean Squared Error, Cross-Entropy Loss). The difference between the predicted output and the actual output is the error. Backward Pass (Backpropagation): The error is propagated back through the network to update the weights. This involves computing the gradient of the loss function with respect to each weight in the network. Gradients indicate the direction and magnitude of the change required in the weights to minimize the error. Steps in Backpropagation Initialization: Initialize the weights and biases of the network with small random values. Forward Pass: For each layer $ l $, compute the input $ z^l $ and output $ a^l $: $z^l = W^l a^{l-1} + b^l$ $a^l = \\sigma(z^l)$ Here, $ W^l $ are the weights, $ b^l $ are the biases, $ \\sigma $ is the activation function, and $ a^{l-1} $ is the output from the previous layer (the first $a$ is $x$ which is the input). Compute Loss: Compute the loss $ L $ using a suitable loss function. Backward Pass: Calculate the gradient of the loss with respect to the output of the last layer $ \\delta^L $: $\\delta^L = \\nabla_a L \\cdot \\sigma’(z^L)$ For each layer $ l $ from $ L-1 $ to 1, compute: -$\\delta^l = (\\delta^{l+1} \\cdot W^{l+1}) \\cdot \\sigma’(z^l)$ Update the weights and biases: $W^l = W^l - \\eta \\cdot \\delta^l \\cdot (a^{l-1}) ^T$ $b^l = b^l - \\eta \\cdot \\delta^l$ Here, $ \\eta $ is the learning rate, and $ \\sigma’ $ is the derivative of the activation function. Calculation To actually calculate backpropagation, you need to: Initialize weights and biases. Perform a forward pass to compute the activations for each layer. Compute the loss using the output from the forward pass and the actual target values. Perform a backward pass to compute the gradients of the loss with respect to each weight. Update the weights and biases using the computed gradients and the learning rate. Example Code (Python): import numpy as npdef sigmoid(x): return 1 / (1 + np.exp(-x))def sigmoid_derivative(x): return x * (1 - x)# Example input and outputx = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])y = np.array([[0], [1], [1], [0]])# Initialize weights and biasesnp.random.seed(42)W1 = np.random.rand(2, 2)b1 = np.random.rand(1, 2)W2 = np.random.rand(2, 1)b2 = np.random.rand(1, 1)# Learning rateeta = 0.1# Training loopfor epoch in range(10000): # Forward pass z1 = np.dot(x, W1) + b1 a1 = sigmoid(z1) z2 = np.dot(a1, W2) + b2 a2 = sigmoid(z2) # Loss calculation loss = 0.5 * (y - a2)**2 # Backward pass delta2 = (a2 - y) * sigmoid_derivative(a2) delta1 = np.dot(delta2, W2.T) * sigmoid_derivative(a1) # Update weights and biases W2 -= eta * np.dot(a1.T, delta2) b2 -= eta * np.sum(delta2, axis=0, keepdims=True) W1 -= eta * np.dot(x.T, delta1) b1 -= eta * np.sum(delta1, axis=0, keepdims=True)print(&quot;Final output after training:&quot;)print(a2) This code demonstrates the basic steps of backpropagation in a simple neural network. By running this code, you can observe how the network learns to approximate the XOR function over time. In a perceptron, weights and biases are updated by multiplying the error (loss) by the input and learning rate, and then adding this value to the current weights. This approach works because the weights for each input are independent, and the perceptron does not form a network. However, in a neural network, nearly every weight can influence every output. As a result, we cannot simply update the weights based on the error alone. Instead, we need to calculate the contribution of each weight to the overall error and adjust the weights accordingly. This process of calculating each weight’s contribution and updating them is known as backpropagation. Overview of the Process Forward Pass: The input $ x $ is passed through the network to compute the output $ \\hat{y} $. Loss Calculation: The loss function $ J(W) $ calculates the difference between the predicted output $ \\hat{y} $ and the actual output. Backward Pass: Gradients are computed by propagating the error backward through the network, adjusting the weights to minimize the loss. The goal is to understand how a small change in one weight (e.g., $ w_2 $) affects the final loss $ J(W) $. For the weight $ w_1 $, the gradient involves additional intermediate steps. Specifically: $ \\frac{\\partial J(W)}{\\partial w_1} = \\frac{\\partial J(W)}{\\partial \\hat{y}} \\times \\frac{\\partial \\hat{y}}{\\partial z_1} \\times \\frac{\\partial z_1}{\\partial w_1} $ This decomposition shows that the gradient of the loss with respect to $ w_1 $ depends on: The gradient of the loss with respect to the output $ \\hat{y} $ The gradient of $ \\hat{y} $ with respect to the intermediate variable $ z_1 $ The gradient of $ z_1 $ with respect to the weight $ w_1 $ Why Backpropagation? Backpropagation efficiently computes these gradients using the chain rule. The key points are: Efficiency: By reusing intermediate results (e.g., the gradient of the loss with respect to $ \\hat{y} $), backpropagation avoids redundant calculations. Modularity: Gradients are computed layer by layer, allowing for modular network designs where each layer can be independently understood and modified. Training: These gradients are used to update the weights in a way that minimizes the loss function, allowing the network to learn from data. Summary Backpropagation applies the chain rule to compute gradients of the loss function with respect to each weight in the network. These gradients are essential for updating the weights during training, thereby enabling the network to learn. Understanding the chain rule and how it applies to neural networks is crucial for grasping backpropagation. Batches Running backpropagation can be computationally expensive when calculating (\\frac{\\partial J(W)}{\\partial w_1}) with a large training dataset. It is easy to run out of memory if too many threads are used. To mitigate this, one approach is to use a single data point to compute (\\frac{\\partial J_i(W)}{\\partial w_1}), though this can introduce significant noise. A more effective strategy is to divide the training data into small batches, which can increase training efficiency and reduce noise. Common batch sizes used during training are 32 or 64. Strategies for Avoiding Overfitting Dropout: randomly set some activate as 0. force network not relay on any node Early stopping: monitor the losing curve and stop the training before it had change to overfit NW in Action Let’s go through an example of using TensorFlow to build a two-layer neural network for a classification task using a dataset from scikit-learn. We will use the Iris dataset, which is a classic dataset for classification. Notice: When TensorFlow runs a neural network, it automatically detects and utilizes available GPUs to accelerate the computation. This process is seamless and doesn’t typically require manual intervention. import numpy as npimport tensorflow as tffrom sklearn import datasetsfrom sklearn.model_selection import train_test_splitfrom sklearn.preprocessing import StandardScalerfrom sklearn.preprocessing import OneHotEncoder# Load the Iris datasetiris = datasets.load_iris()X = iris.datay = iris.target.reshape(-1, 1)# One-hot encode the target labelsencoder = OneHotEncoder(sparse=False)y = encoder.fit_transform(y)# Standardize the feature datascaler = StandardScaler()X = scaler.fit_transform(X)# Split the dataset into training and test setsX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)# Define the modelmodel = tf.keras.models.Sequential([ tf.keras.layers.Dense(10, activation='relu', input_shape=(X_train.shape[1],)), tf.keras.layers.Dense(10, activation='relu'), tf.keras.layers.Dense(3, activation='softmax')])# Compile the modelmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])class PrintLossCallback(tf.keras.callbacks.Callback): def on_epoch_end(self, epoch, logs=None): print(f&quot;Epoch {epoch + 1}, Loss: {logs['loss']}, Accuracy: {logs['accuracy']}&quot;)# Train the model with the callbackmodel.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1, callbacks=[PrintLossCallback()])# Evaluate the model on the test sety_pred = model.predict(X_test)test_loss, test_accuracy = model.evaluate(X_test, y_test)print(f&quot;Test Accuracy: {test_accuracy * 100:.2f}%&quot;) Epoch 96/100 4/4 [==============================] - 0s 3ms/step - loss: 0.2099 - accuracy: 0.9532 - val_loss: 0.3162 - val_accuracy: 0.9167 Epoch 96, Loss: 0.21823757886886597, Accuracy: 0.9351851940155029 Epoch 97/100 4/4 [==============================] - 0s 3ms/step - loss: 0.2010 - accuracy: 0.9522 - val_loss: 0.3123 - val_accuracy: 0.9167 Epoch 97, Loss: 0.21543042361736298, Accuracy: 0.9351851940155029 Epoch 98/100 4/4 [==============================] - 0s 3ms/step - loss: 0.2175 - accuracy: 0.9366 - val_loss: 0.3079 - val_accuracy: 0.9167 Epoch 98, Loss: 0.21266280114650726, Accuracy: 0.9351851940155029 Epoch 99/100 4/4 [==============================] - 0s 3ms/step - loss: 0.2047 - accuracy: 0.9428 - val_loss: 0.3040 - val_accuracy: 0.9167 Epoch 99, Loss: 0.20983757078647614, Accuracy: 0.9351851940155029 Epoch 100/100 4/4 [==============================] - 0s 3ms/step - loss: 0.2070 - accuracy: 0.9376 - val_loss: 0.3008 - val_accuracy: 0.9167 Epoch 100, Loss: 0.20734088122844696, Accuracy: 0.9351851940155029 In this group of test data, there are ony one mistake. Another regression example write by torch import torchimport torch.nn as nnfrom torch.optim.lr_scheduler import StepLRdef create_sequential_layers(): &quot;&quot;&quot; Task: Create neural net layers using nn.Sequential. Requirements: Return an nn.Sequential object, which contains: 1. a linear layer (fully connected) with 2 input features and 3 output features, 2. a sigmoid activation layer, 3. a linear layer with 3 input features and 5 output features. &quot;&quot;&quot; block = torch.nn.Sequential( torch.nn.Linear(2, 3), torch.nn.Sigmoid(), torch.nn.Linear(3, 5) ) return blockdef create_loss_function(): &quot;&quot;&quot; Task: Create a loss function using nn module. Requirements: Return a loss function from the nn module that is suitable for multi-class classification. &quot;&quot;&quot; return torch.nn.MSELoss()class NeuralNet(torch.nn.Module): def __init__(self): &quot;&quot;&quot; Initialize your neural network here. &quot;&quot;&quot; super().__init__() ################# Your Code Starts Here ################# self.conv1 = nn.Conv1d(in_channels=1, out_channels=5, kernel_size=5, stride=1, padding=2) self.relu = nn.LeakyReLU() # Adjust the following layer sizes based on the output of your convolutional layer self.fc1 = nn.Linear(5 * 2883, 69) # Adjusted for flattened conv output self.output = nn.Linear(69, 5) ################## Your Code Ends here ################## def forward(self, x): &quot;&quot;&quot; Perform a forward pass through your neural net. Parameters: x: an (N, input_size) tensor, where N is arbitrary. Outputs: y: an (N, output_size) tensor of output from the network &quot;&quot;&quot; ################# Your Code Starts Here ################# x = x.view(x.size(0), 1, -1) # Apply Conv1d x = self.conv1(x) x = self.relu(x) # Flatten the output for the linear layer x = x.view(x.size(0), -1) x = self.fc1(x) x = self.relu(x) y_pred = self.output(x) return y_pred ################## Your Code Ends here ##################def train(train_dataloader, epochs): &quot;&quot;&quot; The autograder will call this function and compute the accuracy of the returned model. Parameters: train_dataloader: a dataloader for the training set and labels test_dataloader: a dataloader for the testing set and labels epochs: the number of times to iterate over the training set Outputs: model: trained model &quot;&quot;&quot; ################# Your Code Starts Here ################# &quot;&quot;&quot; Implement backward propagation and gradient descent here. &quot;&quot;&quot; device = &quot;cpu&quot; model = NeuralNet().to(device) loss_fn = torch.nn.CrossEntropyLoss() # Suitable for regression tasks optimizer = torch.optim.Adamax(params=model.parameters(), lr=0.001) scheduler = StepLR(optimizer, step_size=500, gamma=0.1) # Learning rate scheduler epoch_count = [] train_loss_values = [] test_loss_values = [] for epoch in range(epochs): # Loop over the dataset multiple times running_loss = 0.0 for inputs, labels in train_dataloader: train_set, train_labels = inputs.to(device), labels.to(device) # Move inputs and labels to the device model.train() y_pred = model(train_set) loss = loss_fn(y_pred, train_labels) # Zero gradients, perform a backward pass, and update the weights optimizer.zero_grad() loss.backward() optimizer.step() #scheduler.step() # Update the learning rate ################## Your Code Ends here ################## return model pre { background-color:#38393d; color: #5fd381; }","link":"/2024/02/18/AI/ai-multilayer/"},{"title":"AI Tools for Protein Structures","text":"trRosetta They inverted this network to generate new protein sequences from scratch, aiming to design proteins with structures and functions not found in nature.By conducting Monte Carlo sampling in sequence space and optimizing the predicted structural features, they managed to produce a variety of new protein sequences. RFdiffusion Watson, Joseph L., et al[1] published the RFdiffusion at github in 2023. It fine-tune the RoseTTAFold[2] and designed for tasks like: protein monomer design, protein binder design, symmetric oligomer design, enzyme active site scaffolding and symmetric motif scaffolding for therapeutic and metal-binding protein design. It is a very powerful tool according to the paper. It is based on the Denoising diffusion probabilistic models (DDPMs) which is a powerful class of machine learning models demonstrated to generate new photorealistic images in response to text prompts[3]. They use the ProteinMPNN[4] network to subsequently design sequences encoding theses structure. The diffusion model is based on the DDPMs. It can not only design a protein from generation, but also able to predict multiple types of interactions as is shown of the left. It was based on the RoseTTAFold. Compared with AF2 AlphaFold2 is like a very smart detective that can figure out the 3D shape of a protein just by looking at its amino acid sequence. On the other hand, RFdiffusion is more like an architect that designs entirely new proteins with specific properties. Instead of just figuring out shapes, it creates new proteins that can do things like bind to specific molecules or perform certain reactions. This makes it incredibly useful for designing new therapies and industrial enzymes. ImmuneBuilder ImmuneBuilder: Deep-Learning models for predicting the structures of immune proteins Method of ABodyBuilder2 First, the heavy and light chain sequences are fed into four separate deep-learning models to predict an ensemble of structures. The closest structure to the average is then selected and refined using OpenMM[5] to remove clashes and other stereo-chemical errors. The same pipeline is used for NanoBodyBuilder2 and TCRBuilder2. Training data set: 7084 structures from SAbDab. Filtering: No missing residues and resolution ≤ 3.5 Å Architect: The architecture of the deep learning model behind ABodyBuilder2 is an antibody-specific version of the structure module in AlphaFold-Multimer with several modifications Frame Aligned Point Error (FAPE) loss (like AFM) A set of deep learning models trained to accurately predict the structure of antibodies (ABodyBuilder2), nanobodies (NanoBodyBuilder2) and T-Cell receptors (TCRBuilder2). ImmuneBuilder generates structures with state of the art accuracy while being much faster than AlphaFold2. Experience it online: Google Colab GitHub: oxpig/ImmuneBuilder They have built three models ABodyBuilder2, an antibody-specific model NanoBodyBuilder2, a nanobody-specific model TCRBuilder2, a TCR-specific model. It compared the performance with other similar tools: homology modelling method; ABodyBuilder[6] general protein structure prediction method: AlphaFold-Multimer[7] antibody-specific methods: ABlooper[8] (ABL), IgFold[9] (IgF) and EquiFold[10] (EqF) How: compare 34 antibody structures recently added MethodCDR-H1CDR-H2CDR-H3Fw-HCDR-L1CDR-L2CDR-L3Fw-LABodyBuilder (ABB)1.531.093.460.650.710.551.180.59ABlooper (ABL)1.180.963.340.630.780.631.080.61IgFold (IgF)0.860.773.280.580.550.431.120.60EquiFold (EqF)0.860.803.290.560.470.410.930.54AlphaFold-M (AFM)0.860.682.900.550.470.400.830.54ABodyBuilder2 (AB2)0.850.782.810.540.460.440.870.57 What is an acceptable RMSD[11]? What is an acceptable RMSD? The experimental error in protein structures generated via X-ray crystallography has been estimated to be around 0.6Å for regions with organised secondary structures (such as the antibody frameworks) and around 1Å for protein loops. Side Chain Prediction ABlooper and IgFold only predict the position of backbones, leaving the side chain to OpenMM[5:1] and Rosetta[12], while EquiFold, AlphaFold-Multimer and ABodyBuilder2, all of which output all-atom structures. equifold Designing proteins to achieve specific functions often requires in silico modeling of their properties at high throughput scale and can significantly benefit from fast and accurate protein structure prediction. We introduce EquiFold, a new end-to-end differentiable, SE(3)-equivariant, all-atom protein structure prediction model. EquiFold uses a novel coarse-grained representation of protein structures that does not require multiple sequence alignments or protein language model embeddings, inputs that are commonly used in other state-of-the-art structure prediction models. Our method relies on geometrical structure representation and is substantially smaller than prior state-of-the-art models. In preliminary studies, EquiFold achieved comparable accuracy to AlphaFold but was orders of magnitude faster. The combination of high speed and accuracy make EquiFold suitable for a number of downstream tasks, including protein property prediction and design. https://github.com/Genentech/equifold IgFold Official repository for IgFold: Fast, accurate antibody structure prediction from deep learning on massive set of natural antibodies. The code and pre-trained models from this work are made available for non-commercial use (including at commercial entities) under the terms of the JHU Academic Software License Agreement. For commercial inquiries, please contact Johns Hopkins Tech Ventures at awichma2@jhu.edu. Try antibody structure prediction in Google Colab. https://github.com/Graylab/IgFold !!! Personal experience I feel that the IgFold is kind of horrible in CDRH3 regions. It predicted CDRH3 loop in an erect conformation incorrectly. It is worse than ABodyBuilder2. It is even slower than ABodyBuilder2, too. It only takes the perfect Fab sequences. Any longer seqeunces would end up as a mass. pre { background-color:#38393d; color: #5fd381; } Watson J L, Juergens D, Bennett N R, et al. De novo design of protein structure and function with RFdiffusion[J]. Nature, 2023, 620(7976): 1089-1100. ↩︎ Baek M, et al. Accurate prediction of protein structures and interactions using a 3-track network. Science. July 2021. ↩︎ Ramesh, A. et al. Zero-shot text-to-image generation. in Proc. 38th International Conference on Machine Learning Vol. 139 (eds Meila, M. &amp; Zhang, T.) 8821–8831 (PMLR, 2021). ↩︎ Dauparas J, Anishchenko I, Bennett N, et al. Robust deep learning–based protein sequence design using ProteinMPNN[J]. Science, 2022, 378(6615): 49-56. ↩︎ Eastman, P. et al. OpenMM 7: rapid development of high-performance algorithms for molecular dynamics. PLoS Comput. Biol. 13, e1005659 (2017). ↩︎ ↩︎ Leem, J., Dunbar, J., Georges, G., Shi, J. &amp; Deane, C. M. ABodyBuilder: automated antibody structure prediction with data-driven accuracy estimation. MAbs 8, 1259–1268 (2016). ↩︎ Evans, R. et al. Protein complex prediction with AlphaFold-Multimer. bioRxiv (2021). ↩︎ Abanades, B., Georges, G., Bujotzek, A. &amp; Deane, C. M. ABlooper: fast accurate antibody CDR loop structure prediction with accuracy estimation. Bioinformatics 38, 1877–1880 (2022). ↩︎ Ruffolo, J. A., Chu, L.-S., Mahajan, S. P. &amp; Gray, J. J. Fast, accurate antibody structure prediction from deep learning on massive set of natural antibodies. Nat. Commun. 14, 2389 (2023). ↩︎ Lee, J. H. et al. Equifold: Protein structure prediction with a novel coarse-grained structure representation. bioRxiv (2022). ↩︎ Eyal, E., Gerzon, S., Potapov, V., Edelman, M. &amp; Sobolev, V. The limit of accuracy of protein modeling: influence of crystal packing on protein structure. J. Mol. Biol. 351, 431–442 (2005).Return to ref 35 in article ↩︎ Alford, R. F. et al. The Rosetta all-atom energy function for macromolecular modeling and design. J. Chem. Theory Comput. 13, 3031–3048 (2017). ↩︎","link":"/2024/05/29/AI/protein3dml/"},{"title":"Free Software for Biology","text":"Free apps for biology Name Areas Data formats Platforms System Description FinchTV Sanger Sequencing Result abi Windows; Mac GUI FinchTV chromatogram viewer is a popular desktop application that was developed by Geospiza, Inc. for viewing trace data from Sanger DNA Sequencing (scf or ab1 file formats). We are making FinchTV freely available here as a service to the community. FinchTV does not collect location or usage data. IGV NGS data sam, fasta all Platforms GUI Integrative Genomics Viewer","link":"/2020/06/26/Bioinfor/Apps/"},{"title":"BatMeth2","text":"BatMeth2 Citation: Zhou Q, Lim J-Q, Sung W-K, Li G: An integrated package for bisulfite DNA methylation data analysis with Indel-sensitive mapping. BMC Bioinformatics 2019, 20:47. More information is in Github, 中文 I just tried the pipeline but I don’t know exactly how those all work. Maybe I’ll update this later Install Requirement gcc (v4.8) , gsl library, zlib R (ggplot2, pheatmap, xtable) samtools (suggest: v1.3.1) fastp, raw reads as input need ## gsl install: sudo apt-get install libgsl0ldbl libgsl0-dev./configuremakemake copy Example Data You can download the test data on here It contain files: input fastq.gz (paired end) genome file usage code and details gene annotation file BUILDING INDEX mkdir batmeth2indexcd batmeth2indexBatMeth2 build_index GENOME.fa # WGBS Data setBatMeth2 build_index rrbs GENOME.fa # RRBS Data setcd ../ Pipline Quick pipeline BatMeth2 pipel --aligner=no -1 R1.fq.gz -2 R2.fq.gz -g ./batmeth2index/genome.fa -o meth -p 6 --gff ./gene.gff -f 1 Step by Step mkdir batmeth2indexcd batmeth2indexBatMeth2 build_index genome.fa # WGBS Data setcd ../BatMeth2 align -g ./batmeth2index/genome.fa -i R1.fq.gz -i R2.fq.gz -p 6 -o meth.sam## Caculate DNA methylation levelBatMeth2 calmeth -g ./batmeth2index/genome.fa -i meth.sam -m meth## DNA methylation level distribution on gene/TE etcBatMeth2 annoation -o meth -G ./batmeth2index/genome.fa -gff ./gene.gff -m meth.methratio.txt -B -P --TSS --TTS --GENE## DNA methylation differential analysis exampleBatMeth2 batDMR -g ./batmeth2index/genome.fa -o_dm DM.txt -1 meth_loci.CG.txt -2 mutant_loci.CG.txt -L Visualization BatMeth2 methyPlot meth.methBins.txt meth.Methygenome.pdf 0.025 meth.Methylevel.1.txt meth.function.pdf TSS TTS meth.AverMethylevel.1.txt meth.Methenrich.pdf meth.annoDensity.1.txt meth.density.pdf meth meth.mCdensity.txt meth.mCdensity.pdf meth.mCcatero.txt jcmeth.mCcatero.pdf 0.6 0.1 0.1","link":"/2020/07/28/Bioinfor/BatMeth2/"},{"title":"ATAC-seq: A Powerful Tool for Mapping Gene Regulation","text":"Introduction: The regulation of gene expression is a complex process that involves the interplay of various factors, including transcription factors, enhancers, promoters, and silencers. Understanding the dynamics of gene regulation is essential for unraveling the mysteries of cellular development, differentiation, and disease progression. To address this challenge, researchers have developed a powerful tool called ATAC-seq, which enables the mapping of gene regulation at an unprecedented scale and resolution. In this blog, we will delve into the world of ATAC-seq and explore its applications, advantages, and limitations. What is ATAC-seq? ATAC-seq (Assay for Transposase-Accessible Chromatin sequencing) is a genomic technique that allows researchers to profile the open chromatin regions in a given cell type. Open chromatin regions are those that are accessible to a transposase enzyme, which is used to fragment the chromatin into smaller pieces. The resulting fragments are then sequenced, producing a map of open chromatin regions across the genome. Principle: The principle behind ATAC-seq is straightforward. The assay involves the following steps: Crosslinking: Cells are fixed with formaldehyde to create covalent bonds between proteins and DNA. Shearing: Chromatin is sheared into smaller fragments using a transposase enzyme. End repair and A-tailing: The 3’ ends of the fragmented DNA are repaired and modified to generate blunt ends. Sequencing library preparation: The modified DNA fragments are then prepared for sequencing using standard library preparation protocols. Sequencing: The sequencing step generates millions of reads that are then mapped back to the reference genome. Advantages: High resolution: ATAC-seq offers high resolution mapping of open chromatin regions, allowing researchers to identify regulatory elements at a genomic scale. Sensitivity: The technique is highly sensitive, capable of detecting rare regulatory elements that would be missed by other methods. Cost-effective: ATAC-seq is relatively cost-effective compared to other techniques such as ChIP-seq, which requires expensive antibodies and specialized equipment. Genome-wide analysis: ATAC-seq allows for genome-wide analysis of open chromatin regions, enabling researchers to identify patterns and trends in gene regulation. Identification of novel regulatory elements: ATAC-seq can identify novel regulatory elements that were previously unknown or unannotated, providing new insights into gene regulation. Investigation of gene regulation in specific cell types or tissues: ATAC-seq can be used to study gene regulation in specific cell types or tissues, providing valuable insights into cellular differentiation and development. Identification of disease-associated regulatory elements: ATAC-seq can be used to identify regulatory elements that are associated with diseases, providing new targets for therapeutic intervention. Monitoring of gene regulation changes over time: ATAC-seq can be used to monitor changes in gene regulation over time, providing insights into how gene regulation dynamics contribute to cellular processes. Limitations: Limited to accessible chromatin regions: ATAC-seq only maps open chromatin regions that are accessible to the transposase enzyme, which means that closed chromatin regions remain unmapped. Biases in sequencing libraries: Sequencing libraries can introduce biases in the form of overrepresented or underrepresented regions, which can impact downstream analyses. Interpretation challenges: Interpreting ATAC-seq data requires advanced computational skills and knowledge of bioinformatics tools and methods. Limited spatial resolution: ATAC-seq provides a snapshot of open chromatin regions at a particular time point, but does not provide information on the spatial organization of regulatory elements. Applications: Stem cell biology: ATAC-seq has been used to study the gene regulation landscape in stem cells, providing insights into pluripotency and lineage commitment. Cancer research: ATAC-seq has been applied to cancer research, identifying regulatory elements that are associated with tumor progression and metastasis. Developmental biology: ATAC-seq has been used to study the gene regulation landscape in the brain, providing insights into neural development, synaptic plasticity, and neurological disorders. Immunology: ATAC-seq has been applied to the study of immune cells, revealing regulatory elements that control immune cell function and differentiation. Plant biology: ATAC-seq has been used to study gene regulation in plants, providing insights into plant development, stress response, and photosynthesis. Microbiology: ATAC-seq has been used to study gene regulation in microbes, including bacteria and yeast, providing insights into the regulation of virulence factors and drug resistance. Drug discovery: ATAC-seq can be used to identify potential drug targets by analyzing the regulatory elements that control gene expression in diseased cells. Personalized medicine: ATAC-seq can be used to study gene regulation in individual patients, providing insights into personalized therapies and treatment strategies. Synthetic biology: ATAC-seq can be used to design and engineer gene circuits for synthetic biology applications, such as biofuels, drugs, and other valuable compounds. Summary In summary, ATAC-seq is a powerful tool for studying gene regulation and has a wide range of applications in various fields, from basic research to drug discovery and personalized medicine. Pipelines for ATAC-Seq Encodeproject: ATAC-seq Data Standards and Processing Pipeline ENCODE-DCC/atac-seq-pipeline Yiwei niu; 2019: ATAC-seq data analysis: from FASTQ to peaks John M. Gaspar; 2019; ATAC-seq Guidelines Lucille Delisle; 2023; ATAC-Seq data analysis Data Analysis Pipeline According to Fen Yan[1] pre-analysis: quality check and alignment core analysis: peak calling advanced analysis: peak differential analysis and annotation no differential peak analysis tools have been specifically developed motif enrichment footprinting nucleosome position analysis Fen Yan pre { background-color:#38393d; color: #5fd381; } Yan, F., Powell, D.R., Curtis, D.J. et al. From reads to insight: a hitchhiker’s guide to ATAC-seq data analysis. Genome Biol 21, 22 (2020). https://doi.org/10.1186/s13059-020-1929-3 ↩︎","link":"/2023/10/20/Bioinfor/ATAC-Seq/"},{"title":"Bioconda","text":"Bioconda 1. Install Location: link for Miniconda # this script might not work nowcurl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.shsh Miniconda3-latest-Linux-x86_64.sh For Zsh environment Conda would add code for initiate it at the end of the .bashrc. You may need to copy them in to the ~/.zshrc if you are using zsh. An example of codes after you run cat ~/.bashrc And then, you can start the conda by `source ~/.zshrc` or open a new terminal. # >>> conda initialize >>> # !! Contents within this block are managed by 'conda init' !! __conda_setup=\"$('/home/ken/miniconda3/bin/conda' 'shell.bash' 'hook' 2> /dev/null)\" if [ $? -eq 0 ]; then eval \"$__conda_setup\" else if [ -f \"/home/ken/miniconda3/etc/profile.d/conda.sh\" ]; then . \"/home/ken/miniconda3/etc/profile.d/conda.sh\" else export PATH=\"/home/ken/miniconda3/bin:$PATH\" fi fi unset __conda_setup # < conda initialize <","link":"/2020/07/28/Bioinfor/Bioconda/"},{"title":"Calcium Competent Cells","text":"Making Calcium Competent Cells graph TB DH5((DH5α)) LB_p(LB plate) LB_l(LB starter) LB(LB 1 L) Centrifuge2(Centrifuge) ice(ice bath 20-30 minutes) ice2(ice bath 20 minutes) Ca(CaCl2) CaCl2(85 mM CaCl2, 15% glycero) Eptube(1.5 ml Ep tube ) subgraph Day 1 DH5-->|Streak & over night|LB_p end subgraph Day 2 LB_p-->|over night| LB_l end subgraph Day 3 LB_l-->|10 ml 37C|LB LB-->|OD600 reaches 0.35-0.4|ice ice-->|Harvest: 3000g, 15 min, 4C|Centrifuge Centrifuge-->|Decant the supernatant|pellet MgCl2-->|100 mL resuspend|pellet pellet-->|Harvest: 2000g, 15 min, 4C|Centrifuge2 Centrifuge2-->|Decant the supernatant|pellet2 Ca-->|100 mL resuspend|pellet2 pellet2-->ice2 ice2 --> |Harvest: 2000g, 15 min, 4C|Centrifuge3 Centrifuge3-->|Decant the supernatant|pellet3 CaCl2-->|50 mL resuspend|pellet3 pellet3-->|Harvest: 1000g, 15 min, 4C,Decant the supernatant|pellet4 CaCl2-->|2 ml|pellet4 pellet4-->|OD600|200-250 200-250-->|Aliquot 50 μL|Eptube Eptube-->|liquid nitrogen to -80C|Store end Preparing for Day 2: Chill overnight at 4°C: 100 mM CaCl2 100 mM MgCl2 85 mM CaCl2, 15% gly cerol v/v Centrifuge rotor Day 1 Streak out frozen glycerol stock of bacterial cells (Top10, DH5α, etc.) onto an LB plate (no antibiotics since these cells do not have a plasmid in them). Work sterile. Grow plate overnight at 37°C. Day 2 Autoclave: 1 L LB (or your preferred media) 1 L of 100 mM CaCl2 1 L of 100 mM MgCl2 100 mL of 85 mM CaCl2, 15% glycerol v/v 4 centrifuge bottles and caps Lots of microfuge tubes Chill overnight at 4°C: 100 mM CaCl2 100 mM MgCl2 85 mM CaCl2, 15% glycerol v/v Centrifuge rotor Prepare starter culture of cells Select a single colony of E. coli from fresh LB plate and inoculate a 10 mL starter culture of LB (or your preferred media – no antibiotics). Grow culture at 37°C in shaker overnight. Notes: • You will have extra CaCl2 and MgCl2. These solutions can be saved and reautoclaved for the next time you make competent cells. • You can also substitute other media like SOB, 2xYT, etc. for the LB if you prefer. • All glassware should be detergent free. Presence of detergent reduces competency of cells. Day 3 Inoculate 1 L of LB media with 10 mL starter culture and grow in 37°C shaker. Measure the OD600 every hour, then every 15-20 minutes when the OD gets above 0.2. When the OD600 reaches 0.35-0.4, immediately put the cells on ice. Chill the culture for 20-30 minutes, swirling occasionally to ensure even cooling. Place centrifuge bottles on ice at this time. IMPORTANT NOTES: • It is important not to let the OD get any higher than 0.4. The OD should be carefully monitored and checked often, especially when it gets above 0.2, as the cells grow exponentially. It usually takes about 3 hours to reach an OD of 0.35 when using a 10 mL starter culture. • It is also very important to keep the cells at 4°C for the remainder of the procedure. The cells, and any bottles or solutions that they come in contact with, must be pre-chilled to 4°C. (Spin #1) Split the 1 L culture into four parts by pouring about 250 mL into ice cold centrifuge bottles. Harvest the cells by centrifugation at 3000g (~4000 rpm in the Beckman JA-10 rotor) for 15 minutes at 4°C. Decant the supernatant and gently resuspend each pellet in about 100 mL of ice cold MgCl2. Combine all suspensions into one centrifuge bottle. Make sure to prepare a blank bottle as a balance. (Spin #2) Harvest the cells by centrifugation at 2000g (~3000 rpm in the Beckman JA-10 rotor) for 15 minutes at 4°C. Decant the supernatant and resuspend the pellet in about 200 mL of ice cold CaCl2. Keep this suspension on ice for at least 20 minutes. Start putting 1.5 mL microfuge tubes on ice if not already chilled. (Spin #3) Harvest the cells by centrifugation at 2000g (~3000 rpm in the Beckman JA-10 rotor) for 15 minutes at 4°C. At this step, rinse a 50 mL conical tube with ddH2O and chill on ice. Decant the supernatant and resuspend the pellet in ~50 mL of ice cold 85 mM CaCl2, 15% glycerol. Transfer the suspension to the 50 mL conical tube. (Spin #4) Harvest the cells by centrifugation at 1000g (~2100 rpm in the Beckman GH-3.8 rotor) for 15 minutes at 4°C. Decant the supernatant and resuspend the pellet in 2 mL of ice cold 85 mM CaCl2, 15% glycerol. The final OD600 of the suspended cells should be ~ 200-250. Aliquot 50 μL into sterile 1.5 mL microfuge tubes and snap freeze with liquid nitrogen. Store frozen cells in the -80°C freezer. Advocation: This protocol belongs to berkeley.edu 2008. I just gently reset part of the sentences. If there are any offensive behaviors, please contact me and I’ll delete it","link":"/2020/06/29/Bioinfor/Competent_c/"},{"title":"Index of Bio-Database","text":"Compliment Bio-database I’ll keep updating when I used those databases. If you know more or find the update/died link on the page, please comment and I’ll update it. 我大概可能会继续更新这个页面。 如果你有建议/发现死链接/更新链接， 请告在评论区诉我我会更新的。 谢谢 INSD (国际核酸序列数据库） GenBank[1] (Update:06/06/20; 4.43913s) 美国国家生物技术信息中心（NCBI）所维护的供公众自由读取的、带注释的DNA序列的总数据库。 欧洲分子生物学实验室的DNA和RNA 序列库。 DNA Databank of Japan (Update:06/06/20; 0.163173s) DDBJ, 日本核酸数据库 GSDB, 由美国国家基因组资源中心（NCGR）维护的DNA序列关系数据库 TIGR DATAbase (Update:06/06/20; OutOfTime) 是世界上最大的cDNA数据库，还有大量的EST序列和人类基因索引（HGI）。 包括与DNA的复制、转录、修复等有密切关系的蛋白质因子。 BioSino (Update:06/06/20; 4.282226s) – 中国自主开发的核酸序列公共数据库。 CUTG (Update:06/06/20; 0.308161s) – Codon Usage, MM子使用频度表。 EPD (123) – Eukaryotic Promotor Database, 真核生物启动子数据库 MicroSatellite (paper) (Update:06/06/20; OutOfTime) – 微衛星片段數據 MTRD: Microorganism Tandem Repeats Database (Update:06/06/20; 3.29666s) KMD: Kazusa Marker Database (Update:06/06/20; 2.40133s) TRDB: Tandem Repeats Database (Update:06/06/20; 12.875825s) MICAS (Update:06/06/20; 4.741937s) SSRome (Update:06/06/20; 4.832473s) dbEST (Update:06/06/20; OutOfTime) – 这是GenBank的重要组成部分,它包含若干物种的已表达的序列标记信息. NUCLEOSOME – 数据库,收集实验测定的核小体数据,用于预测DNA中与组蛋白八聚体结合的位点. Protein Database PDB (RCSB) (Protein Data Bank): 3D structure SWISS-PROT: 是对数据人工审读很严格的库。 Uniprot: UniProt is the world’s leading high-quality, comprehensive and freely accessible resource of protein sequence and functional information. Negatome: Negative protein-protein interaction database. The Negatome is a collection of protein and domain pairs which are unlikely engaged in direct physical interactions. MMDB 蛋白质分子模型数据库。 Conserved domains and protein classification: Conserved domains are functional units within a protein that act as building blocks in molecular evolution and recombine in various arrangements to make proteins with different functions. Macromolecular structures: The 3D structures of biomolecules provide a wealth of information on their biological function and evolutionary relationships. HOBACGEN 数据库，包含按家族组织的所有细菌的蛋白质序列，有助于从各种细菌选取同源家族，作多序列联配和构建亲缘树。 BioMagResBank 简称BMRB，是关于多肽、蛋白质和核酸的核磁共振数据库。 PhosphoBase, 磷酸化位点数据库。 InterPro, 集成的蛋白质结构域和功能位点数据库。 Pfam MolMovDB, 耶鲁大学的生物信息学研究室维护的分子运动数据库。 O-GLYCBASE, 蛋白质糖基化位点数据库。 ORDB 嗅觉受体蛋白质序列数据库。 CarbBank 亦称CCSD，复杂碳水化合物结构数据库，通常与蛋白质结构数据库归在一起。 SCOP 大分子结构模拟和药物设计生物信息分析 Expasy (SIB Swiss Institute of Bioinformatics) PROSITE, 由专家根据生物知识审编的SWISS-PROT蛋白质序列中有生物意义的位点、模式和轮廓的数据库。 ENZYME, 基于命名系统的酶数据库。 http://www.expasy.ch/prosite/ SMART 是简单模块构架搜索工具的缩写。 ★ TMBase,跨膜蛋白数据库。 ftp://ulrec3.unil.ch/pub/tmbase 比较基因组学和蛋白质组学数据库: ★COG直系同源聚类数据库。 http://www.ncbi.nlm.nih.gov/COG/ 蛋白质组学相关信息分析 SWISS-2DPAGE http://us.expasy.org/ch2d/ SIENA-2DPAGE http://www.bio-mol.unisi.it/2d/2d.html Human 2D-PAGE Databases PROSITE http://us.expasy.org/prosite/ PRINTS http://www.sanger.ac.uk/Software/Pfam/ Transcriptional Factors A list of TF database: Gene expression regulatory sites and transcription factors JASPAR - JASPAR is a database of TF binding profiles and matrices for a wide range of eukaryotic TFs. It provides information on TF binding sites, PWMs, and DNA-binding domains. TRANSFAC(Update:06/06/20; 5.599736s) - TRANSFAC is a database of transcription factors, their binding sites, and DNA-binding domains. It also provides information on the regulatory networks of TFs and their interactions with other proteins. ENCODE - ENCODE is a project that aims to identify all functional elements in the human genome, including TF binding sites. It provides a comprehensive list of TF binding sites, regulatory networks, and gene expression data. ChIP-Atlas - ChIP-Atlas is a database of genome-wide TF binding profiles from ChIP-seq experiments. It provides information on TF binding sites, target genes, and functional annotations. Cistrome - Cistrome is a database of TF binding profiles and regulatory networks for a wide range of eukaryotic TFs. It also provides tools for analyzing and visualizing TF binding data. TRRD (Update:06/06/20; 0.817254s) – transcription regulatory regions of eukaryotic genes, 真核生物基因组转录调控区数据库。 OOTFD (Update:06/06/20; 11.796405s) – Molecular Informatics Resource for the Analysis of Gene Expression, 转录因子和基因表达数据库 scRNA-Seq DRSC scRNA-seq DataBase Crossing spices single cell RNA-seq database RNA序列和核糖体数据库: ★RNAmods,RNA修饰数据库。 ftp://medlib.med.utah.edu/library/RNAmods ★PLMItRNA基于FastA的绿色植物线粒体tRNA分子和tRNA基因的数据库。 http://www.ebi.ac.uk/services/ ★16SMDB、16S-likeMDB 、16SMDBexp 、23SMDB、 23S-likeMDBexp数据库，是一批16S和23S核糖体RNA突变数据库。 ftp://acad.fandm.edu/nar/ 基因图谱数据库: ★Rhdb,辐射杂交数据库。 ftp://ftp.ebi.ac.uk/pub/databases/RHdb ★HuGeMap,人类基因遗传图谱和物理图谱的分布式集成数据库。 ftp://ftp.ebi.ac.uk/pub/databases/RHdb/gm99.map ★英国Wellcome Trust是人类基因组计划的另一个主要资助者。 http://www.wellcome.ac.uk/ ★英国的Sanger中心的人类基因组计划网页，不仅有它们负责测序的染色体数据，还有到其他染色体数据的链接。 http://www.sanger.ac.uk/HGP/ ★ Sanger 中心是世界上最大的DAN测序中心之一。承担人类基因组计划的三分之一，集中在1、6、9、10、13、20、22和X。 http://www.sanger.ac.uk/HGP/stats.html ★LANL，美国洛斯阿拉莫斯国家实验室。 http://jgi.doe.gov/ ★UWGC，华盛顿大学基因中心，是国际上最活跃的测序中心之一。 ftp://ftp.genome.washington.edu/ ★DOGS，基因组尺寸数据库。 http://www.cbs.dtu.dk ★GenBank的/genomes/子目录： ftp://ftp.cbi.pku.edu.cn/pub/databases/genband/genomes/ ★ECDC,大肠杆菌菌株K12的基因序列库，包括基因、读框、调控区、启动子、终止子、tRNA和rRNA等。 ftp://ftp.ebi.ac.uk/pub/databases/ecdc ★NRSub,非冗余枯草芽孢杆菌DNA数据库，包括完全基因组、MM子使用表、基因图谱和基因家族。 ftp://ftplnig.ac.jp/pub/db/nrsub ★HIDB,流感嗜血菌完全基因组的原始数据库。 http://www.tigr.org:80/tdb/mdb/hidb/hidb.html ftp://ftp.tigr.org/pub/data/h_influenzae ★MJDB,詹氏甲烷球菌基因组数据库。 ftp://ftp.tigr.org/pub/data/m_jannaschii http://www.tigr.org/tdb/mdb/mjdb/mjdb.html ★LISTA,LISTA-HOP和LISTA-HON是酿酒酵母基因组中蛋白质编码序列及其同源性的数据库。 ftp://bioftp.unibas.ch ★FGSC,真菌遗传学信息中心。 http://www.fgsc.net/ 原生生物和线虫基因组: ★ AceDB,线虫综合数据库。 ftp://sanger.ac.uk/pub/acedb ftp://ncbi.nlm.nih.govrepository/acedb ftp://lirmm.lirmm.fr/pub/acedb ★关于线虫发育特别是化学感觉神经的研究。 昆虫基因组: ★斯坦福大学的果蝇基因组中心。 http://www.fruitfly.org/ ★MsqDB,蚊子基因数据库。 http://klab.agsci.colostate.edu/acedb/MsqDB-acedb.html ftp://klab.agsci.colostate.edu 啮齿动物基因组(主要是有关家鼠的数据库): ★ M.Musculus基因组库。 ftp://ncbi.nlm.mih.gov/genbank/genomes/M_muslulus ★ MGD,家鼠基因组库，现在又称MGI即家鼠基因组信息库。 http://www.informatics.jax.org/mgd.html ftp://ftp.informatics.jax.org/ 细胞器数据库: 主要是线粒体和叶绿体基因的数据。 ★ MitoNuc http://megasun.bch.umontreal.ca/gobase/ 拟南芥基因组: ★ MATDB,国际拟南芥基因组计划的数据汇总。 http://www.mips.biochem.mrg.de/desc/thal/ ★ AtDB,拟南芥基因组数据库。 ftp://genome-ftp.stanford.edu/pub/arabidopsis ★ TAIR,拟南芥信息资源。 http://www.arabidopsis.org/ 基因表达数据库: ★Flyview,果蝇基因表达数据库。 http://flyview.uni-muenster.de/ ★Flybrain,果蝇神经系统图谱和数据库。 http://flybrain.uni-freiburg.de/ ★Axeldb,非洲爪蟾基因表达数据库。 http://www.dkfz-heidelberg.de/abt0135/axeldb.html ★GXD,家鼠基因表达数据库。 http://www.informatics.jax.org/searches/gxdindex_form.html ★Collagen人类胶原数据库。 http://www.le.ac.uk//genetics/collagen/ ★人类PAX2等位基因变异数据库。 http://www.hgu.mrc.ac.uk/Softdata/PAX2/ ★人类PAX6等位基因突变数据库。 http://www.hgu.mrc.ac.uk/Softdata/PAX6/ ★ALFRED为Allele FREquency Database 的缩写。这是由耶鲁大学K.K.Kidd实验室维护的一个针对人口多样性和DNA多态性的等位基因数据库。 http://alfred.med.yale.edu/alfred/ ★KMDB由日本庆应义塾大学医学院建立的一组与人类疾病有关的基因突变数据库。 http://mutview.dmb.med.keio.ac.jp/ ★KMeyeDB人类疾病和眼病基因突变人类心脏病基因突变数据库。 http://mutview.dmb.med.keio.ac.jp/mutview3/kmeyedb/ ★KMearDB人类耳病基因突变数据库。 http://mutview.dmb.med.keio.ac.jp/ ★KMbrainDB人类脑病基因突变数据库。 http://mutview.dmb.med.keio.ac.jp/ ★KMcancerDB人类癌症基因突变数据库。 http://mutview.dmb.med.keio.ac.jp/ MTB家鼠肿瘤生物学数据库。 http://tumor.informatics.jax.org/ ★CFTR,囊性纤维变跨膜调控子突变数据库。 http://genet.sickkids.on.ca/cftr/ ★HIG,Anthony Nolan 骨髓和白血病基金会的人类白细胞抗体HLA住处30年前由E.A.Kabat建立的具有免疫学意义的蛋白质序列数据库。 http://www.anthonynolan.com/HIG/ ★我国水稻基因组计划针对水稻的籼稻亚种。 http://www.ncgr.ac.cn/ ★ WHEAT小麦基因图谱数据库。 http://wheat.pw.usda.gov/ ★ILDIS国际豆科植物数据库和信息服务。 http://www.ildis.org/LegumeWeb/ 基因组信息分析 1．基因组序列信息的提取和分析 dbEST http://www.ncbi.nlm.nih.gov/dbEST/index.html UniGene Transcription factor database 基因组信息分析 2．功能基因组相关信息分析 NCBI http://www.ncbi.nlm.nih.gov/ Entrez http://www.ncbi.nlm.nih.gov/Entrez OMIM 核酸序列的预测分析 重复序列分析 CENSOR http://www.girinst.org/ 数据库搜索 NCBI的BLAST http://www.ncbi.nlm.nih.gov/BLAST/ 编码区统计特性分析: ExPASy http://www.expasy.ch/tools/ Tmpred SignalP http://www.cbs.dtu.dk/services/SignalP/ 蛋白质结构和功能的预测分析蛋白质三维结构预测 : SWISS-MODEL http://www.expasy.ch/swissmod/SWISS-MODEL.html PSI-BLAST http://www.ncbi.nlm.nih.gov/BLAST/ 和引用情况。 ★最为方便的查询MEDLINE的方式，是通过NCBI的PubMed服务： http://www.ncbi.nlm.nih.gov/PubMed/ ★SCI是设在美国费城的科学信息研究所所提供的文献引用情况的检索服务。 http://webofscience.com/ ★ 位于美国麻省的Woods Hole海洋生物研究室有一个海洋动物数据库。 http://www.mbl.edu/ ★Integrated Database Retrieval Systems ★Entrez http://gdbwww.gdb.org/default.htm Funding for this project has been withdrawn. This valuable database will remain online, but it should be noted that no new entries will be recorded after 31st July 1998. Metabolism Database Lipid database: Lipid maps[2] A free resource sponsored by the Wellcome Trust Click me to show more The LIPID MAPS consortium has developed a number of online tools for performing tasks such as drawing lipid structures and predicting possible structures from mass spectrometry (MS) data. A simple online interface has been developed to enable an end-user to rapidly generate a variety of lipid chemical structures, along with corresponding systematic names and ontological information. The structure-drawing tools are available for six categories of lipids: (i) fatty acyls, (ii) glycerolipids, (iii) glycerophospholipids, (iv) cardiolipins, (v) sphingolipids and (vi) sterols. Within each category, the structure-drawing tools support the specification of various parameters such as chain lengths at a specific sn position, head groups, double bond positions and stereochemistry to generate a specific lipid structure. The structure-drawing tools have also been integrated with a second set of online tools which predict possible lipid structures from precursor-ion and product-ion MS experimental data. The MS prediction tools are available for three categories of lipids: (i) mono/di/triacylglycerols, (ii) glycerophospholipids and (iii) cardiolipins. The LIPID MAPS online tools are publicly available at SMILES是一个辅助性数据库，它搜集与代谢途径有关的化合物名称活着， 但是实在是不知道有啥用- - 谁知道给个留言呗 Reference: g863402758, 2016-10-28 Wilkinson, Mark D., et al. “The FAIR Guiding Principles for scientific data management and stewardship.” Scientific data 3.1 (2016): 1-9. ↩︎ Fahy, Eoin, et al. “LIPID MAPS online tools for lipid research.” Nucleic acids research 35.suppl_2 (2007): W606-W612. ↩︎","link":"/2020/07/28/Bioinfor/BioDB/"},{"title":"Denove Prokaryotic Genome with Spader","text":"Denove Prokaryotic Genome with Spader Data Download a paired fastq file: ERS011978_pass_1.fastq ERS011978_pass_2.fastq Filter low quality reads fastp -u 15 -i ERS011978_pass_1.fastq -I ERS011978_pass_2.fastq -o cut_ERS011978_pass_1.fastq -O cut_ERS011978_pass_2.fastq cut adapter on the end ##java -jar ~/Biosoft/Trimmomatic-0.38/trimmomatic-0.38.jar PE \\-threads 8 -phred33 input_forward.fq.gz input_reverse.fq.gz \\output_forward_paired.fq.gz output_forward_unpaired.fq.gz \\output_reverse_paired.fq.gz output_reverse_unpaired.fq.gz \\ILLUMINACLIP:TruSeq3-PE.fa:2:30:10 LEADING:3 TRAILING:3 \\SLIDINGWINDOW:4:15 MINLEN:36 Quick Through cut the adapter tail on the 1.fastq java -jar ~/Biosoft/Trimmomatic-0.38/trimmomatic-0.38.jar SE -threads 8 -phred33 cut_ERS011978_pass_1.fastq cut2_ERS011978_pass_1.fastq CROP:76mv cut2_ERS011978_pass_1.fastq cut_ERS011978_pass_1.fastq spade: sudo /home/ken/Biosoft/SPAdes-3.12.0-Linux/bin/spades.py -1 fastq/cut_ERS011978_pass_1.fastq -2 fastq/cut_ERS011978_pass_2.fastq -o /home/ken/ComGE/assembly3 state information ~/Biosoft/bbmap/stats.sh assembly3/scaffolds.fasta Predicted the genes by prodigal prodigal -i scaffolds.fasta -o my.genes -a Protein.fa Predicted the rRNA by barrnap barrnap --quiet scaffolds.fasta Other Pipeline Whole genome assembly workshop; © cornell EDU; 2019 # Preparemkdir /workdir/$USERcd /workdir/$USERcp /shared_data/assembly_workshop_2019/*fastq.gz ./# Trimjava -jar /programs/trimmomatic/trimmomatic-0.39.jar PE -phred33SRR1982238_1.fastq.gz SRR1982238_2.fastq.gz r1.fastq.gz u1.fastq.gz r2.fastq.gzu2.fastq.gz ILLUMINACLIP:/programs/trimmomatic/adapters/TruSeq3-PE-2.fa:2:30:10LEADING:10 TRAILING:10 SLIDINGWINDOW:4:15 MINLEN:150# assemblyexport OMP_NUM_THREADS=6/programs/spades/bin/spades.py -t 6 --careful --s1 u1.fastq.gz --pe1-1r1.fastq.gz --pe1-2 r2.fastq.gz -o spades_run# Assessmentcp -r /shared_data/assembly_workshop_2019/spades_results ./cd spades_resultsgrep &quot;=====&quot; spades.loggrep &quot;genome size&quot; spades.log/programs/quast-5.0.2/quast.py contigs.fasta/programs/quast-5.0.2/quast.py scaffolds.fastatail quast_results/*/report.txt# Evaluatewget https://busco.ezlab.org/datasets/bacillales_odb9.tar.gztar xvfz bacillales_odb9.tar.gzcp /programs/busco-3.1.0/config/config.ini /workdir/$USER/cp -r /programs/Augustus-3.3.2/config /workdir/$USER/export AUGUSTUS_CONFIG_PATH=/workdir/$USER/configexport BUSCO_CONFIG_FILE=/workdir/$USER/config.iniexport PYTHONPATH=/programs/busco-3.1.0/lib/python3.6/site-packagesexport PATH=/programs/busco-3.1.0/scripts:/programs/Augustus-3.3.2/bin:/programs/Augustus-3.3.2/scripts:$PATHrun_BUSCO.py --in ./contigs.fasta --lineage_path ./bacillales_odb9 --mode genome--out busco_bacillales --cpu 8cat run_busco_bacillales/short_summary_busco_bacillales.txt# Assemble PacBiocd /workdir/$USERcp /shared_data/assembly_workshop_2019/SRR10405213.fastq.gz .//programs/canu-1.8/Linux-amd64/bin/canu useGrid=false maxThreads=8maxMemory=24g -p ecoli -d /workdir/$USER/ecoli genomeSize=4.6m -pacbio-rawSRR10405213.fastq.gzcp -r /shared_data/assembly_workshop_2019/ecoli/ ./programs/minimap2-2.17/minimap2 -a ecoli/ecoli.contigs.fasta SRR10405213.fastq.gz | samtools view -b - &gt; ecoli.bamsamtools sort -@ 6 -m 5G -T ./ -o ecoli.sorted.bam ecoli.bamsamtools index ecoli.sorted.bamjava -jar /programs/pilon-1.23/pilon-1.23.jar --genome ecoli/ecoli.contigs.fasta--pacbio ecoli.sorted.bam --output ecoli.pilon","link":"/2020/07/28/Bioinfor/Denove-Prokaryotic-Genome-with-Spader/"},{"title":"Go Ontology","text":"Go Ontology general infr: happyxhz 2019 Uniprot to GO reference 1 : wangshicheng 2017 Enrichment Reference: 既见君子","link":"/2020/07/28/Bioinfor/GO_ontology/"},{"title":"Genome-Wide Profiling of Histone Modification with Chip-Seq (CD Genomics)","text":"Genome-Wide Profiling of Histone Modification with Chip-Seq (CD Genomics) reference: CD genimics, Genom-Wide Profiling of Histone Modifications with ChIP-Seq** Introduction to Histone Modifications There are at least 9 different types of post-translational modifications (PTM) have been found. Examples of Modeification Functions of PTM methylationacetylationphosphorylationubiquitylationsumoylation Change chromatin structuresRecruit histone modifierschange in gene expressionTranscriptional regulationchromosome packaging** DNA damage/repair** Major Types of Modification 1. Methylation 2. Acetylation 3. Phosphorylation 4. Ubiquitylation ubiquitin moiety (76-amino-acid peptide.) 5. Sumoylation CHIP-SEQ DATA ANALYSIS","link":"/2020/07/28/Bioinfor/Genome_Histone_Chip-Seq_CD-Genomics/"},{"title":"DNA Seq Pipeline and General Infor statistics","text":"pre { background-color:#38393d; color: #5fd381; } DNA seq Pipeline Quality Control Quality control can use fastQC. In DNA-seq data, we may find lots of overrepresented sequences from mitochondria and it is totally normal. Not like RNA-seq, we do not expect errors in GC content. mkdir fastQC/fastqc -o ./fastQC/ -t 7 reads.fq for loop for slumn system Example file: GFP-1_L1_1.fq.gz GFP-1_L1_2.fq.gz FQ_DB={dir for fastq}for i in $(ls $FQ_DB/* ); do SAMPLE=$(echo $i|sed 's=FQ/==;s/.fq.gz//') sed &quot;s/Hi/$SAMPLE\\_fQC/&quot; Model.sh &gt; script/$SAMPLE\\_fQC.sh echo fastqc -o fastQC -t 7 $i &gt;&gt; script/$SAMPLE\\_fQC.sh sbatch script/$SAMPLE\\_fQC.shdone Align to the Genome Choose appropriate short reads tools for your data. I heard that bwa was more suitable for short reads align, so it is frequently used in the miRNA-Seq pipeline. Bowtie is faster and can do better on longer reads alignment. According to this, if your reads are short like 50~70bp, you can choose bwa. If your reads are paired from 150~300bp, bowtie2 would work better. In the post from David, 2015; the best short-reads alignment tool is segemehl. Meanwhile, bwa was more sensitive than bowtie2. According to the Benchmark, the best tools for DNA-Seq is segemehl or BWA-MEM, the best tools for RNA-Seq is segemehl © ecSeq Bioinformatics Scripts for align all your fq Genome index bwa index Genome.fa Single end reads In this Part, we will map all reads from the same directory to the reference genome by using bwa. Because programs would fail sometimes and we need to run them again. So, we can check and run only when the results don’t exist. FQ_DB={Your Directory}DB={Your Reference Genome}for SAMPLE in $(ls $FQ_DB/*L001*|awk -F/ '{print $NF}'| awk -F_ '{print $1&quot;_&quot;$2}'| sort |uniq); do if [ -f $SAMPLE.sorted.bam ]; then echo $SAMPLE is done else echo $SAMPLE can not be find sed &quot;s/Hi/$SAMPLE/&quot; Model.sh &gt; script/$SAMPLE.sh echo cat $FQ_DB/$SAMPLE* \\| bwa mem $DB - -t 64 \\|samtools view -S -b -\\|samtools sort \\&gt; $SAMPLE.sorted.bam &gt;&gt; script/$SAMPLE.sh echo samtools index $SAMPLE.sorted.bam &gt;&gt; script/$SAMPLE.sh sbatch script/$SAMPLE.sh fidone## Check unexpected size of filerm $(du *.sorted.bam | awk '$1&lt;=100'| awk '{print $2}')## After removed failed files, we can excute the for loop againfor SAMPLE in $(ls $FQ_DB/*L001*|awk -F/ '{print $NF}'| awk -F_ '{print $1&quot;_&quot;$2}'| sort |uniq); do if [ -f $SAMPLE.sorted.bam ]; then echo $SAMPLE is done else echo $SAMPLE can not be find sed &quot;s/Hi/$SAMPLE/&quot; Model.sh &gt; script/$SAMPLE.sh echo mv $SAMPLE.sorted.sam $SAMPLE.sorted.bam &gt;&gt; script/$SAMPLE.sh echo samtools index $SAMPLE.sorted.bam &gt;&gt; script/$SAMPLE.sh sbatch script/$SAMPLE.sh fidone Then, move every thing to one directory. mkdir Bammv *bam* Bamrm *.err *.out # Clear logs Paired end reads Name Example of my Paired multiple-lines reads: S40_L001_R1_001.fastq.gz S40_L001_R2_001.fastq.gz S40_L002_R1_001.fastq.gz S40_L002_R2_001.fastq.gz S41_L001_R1_001.fastq.gz S41_L002_R1_001.fastq.gz S40 is two lines paired-ends sample, S41 is two lines single-ends sample. module load samtools bwamkdir scriptmkdir Logmkdir Bammkdir tmpFQ_DB={Your Directory}DB={Your Reference Genome}#FQ_DB=&quot;../../RNA_RAW/*/*/&quot;#DB=DB/Genome.fa# Get the unique sample names:# ls $Directory/*.gz| awk -F&quot;/&quot; '{print $NF}'| sed 's/_L00[12]_R[12]_001.fastq.gz//'| sort |uniqfor SAMPLE in $(ls $FQ_DB/*.gz| awk -F&quot;/&quot; '{print $NF}'| sed 's/_L00[12]_R[12]_001.fastq.gz//'| sort |uniq); do echo $SAMPLE; # check the exist of the result if [ -f Bam/$SAMPLE.sorted.bam ]; then echo $SAMPLE is done else # check the Number of the files. 4 means paired and 2 means unpaireds if [ $(ls $FQ_DB/$SAMPLE*|wc -l) -eq 4 ]; then echo Paired sed &quot;s/Hi/$SAMPLE/&quot; Model.sh &gt; script/$SAMPLE.sh echo cat $FQ_DB/$SAMPLE*L00[12]_R1_* \\&gt; tmp/$SAMPLE.R1.fq.gz &gt;&gt; script/$SAMPLE.sh echo cat $FQ_DB/$SAMPLE*L00[12]_R2_* \\&gt; tmp/$SAMPLE.R2.fq.gz &gt;&gt; script/$SAMPLE.sh echo bwa mem $DB tmp/$SAMPLE.R[12].fq.gz -t 64 \\|samtools view -S -b -\\|samtools sort \\&gt; $SAMPLE.sorted.bam &gt;&gt; script/$SAMPLE.sh echo samtools index $SAMPLE.sorted.bam &gt;&gt; script/$SAMPLE.sh echo mv $SAMPLE.sorted.bam $SAMPLE.sorted.bam.bai Bam &gt;&gt; script/$SAMPLE.sh echo rm tmp/$SAMPLE.R[12].fq.gz &gt;&gt; script/$SAMPLE.sh else echo Single sed &quot;s/Hi/$SAMPLE/&quot; Model.sh &gt; script/$SAMPLE.sh echo cat $FQ_DB/$SAMPLE* \\| bwa mem $DB - -t 64 \\|samtools view -S -b -\\|samtools sort \\&gt; $SAMPLE.sorted.bam &gt;&gt; script/$SAMPLE.sh echo samtools index $SAMPLE.sorted.bam &gt;&gt; script/$SAMPLE.sh echo mv $SAMPLE.sorted.sam $SAMPLE.sorted.bam &gt;&gt; script/$SAMPLE.sh echo samtools index $SAMPLE.sorted.bam &gt;&gt; script/$SAMPLE.sh echo mv $SAMPLE.sorted.bam $SAMPLE.sorted.bam.bai Bam &gt;&gt; script/$SAMPLE.sh fi sbatch script/$SAMPLE.sh fidone After checking the size of bam and re-run the failed files, each file has: Bam: all bam results and bam index Log: log files generated by sbatch. (Disposable) tmp： temporarily combined reads from different lines and should be cleaned. (Disposable) scripts: scripts for each sample from aligning to sort. (Disposable) Basic information Statistics . └── Bam │ ├── GFP-1.sorted.bam │ └── GFP-2.sorted.bam └── Model.sh mkdir Bam_stats scriptfor i in $(ls Bam/*.bam); do SAMPLE=$(echo $i| sed 's=Bam/==;s/.sorted.bam//'); if [ -f Bam_stats/$SAMPLE.stats.csv ]; then echo $SAMPLE is done else sed &quot;s/Hi/$SAMPLE\\_BamStat/&quot; Model.sh &gt; script/$SAMPLE\\_BamStat.sh echo samtools stats $i \\&gt; Bam_stats/$SAMPLE.stats.csv &gt;&gt; script/$SAMPLE\\_BamStat.sh sbatch script/$SAMPLE\\_BamStat.sh fidone After jobs are done, we can grep the SN infor from all samples into one: grep ^SN Bam_stats/*| sed 's/.stats.csv:SN//;s=Bam_stats/==' | awk -F&quot;\\t&quot; '{OFS=&quot;\\t&quot;; print $1,$2,$3}'| sed 's/://' &gt; SN_infor.csv Insert size statistics What is insert size © Frances S. Turner, 2014 Why there are negative insert sizes? Negative insert sizes can happen when the first read is mapped to the reverse strand. we can change it by using awk '{print sqrt(\\$0^2)}' Reference: accio, 2020 It might be help in ChIP-seq data. for i in $(ls Bam/SJ_*.bam); do SAMPLE=$(echo $i| sed 's=Bam/==;s/.sorted.bam//'); if [ -f Bam_stats/$SAMPLE.insert.csv ]; then echo $SAMPLE is done else sed &quot;s/Hi/$SAMPLE\\_BamStat/&quot; Model.sh &gt; script/$SAMPLE\\_BamInser.sh echo samtools view -f66 $i \\| cut -f9 \\| awk &quot;'{print sqrt(\\$0^2)}'&quot; \\&gt; Bam_stats/$SAMPLE.insert.csv &gt;&gt; script/$SAMPLE\\_BamInser.sh bash script/$SAMPLE\\_BamInser.sh &amp; fidone grep . Bam_stats/*.insert.csv| sed 's=Bam_stats/==;s/.insert.csv:/ /' &gt; Insert.csv Check the number of lines from each file and remove incorrect files. Visualization by ggplot2 Creat a directory, img, for storing the results. mkdir img library(ggplot2)library(stringr)library(reshape2)library(pheatmap)library(ggplotify)TB &lt;- read.table(&quot;SN_infor.csv&quot;, sep = '\\t')Norm_list &lt;- TB$V2[TB$V1==TB$V1[[1]]][TB$V3[TB$V1==TB$V1[[1]]] &gt;= 1000]## Bar plot 1: sort by total readsTB$V1 &lt;- factor(TB$V1, levels=as.character(na.omit(TB$V1[TB$V2=='raw total sequences'][order(TB$V3[TB$V2=='raw total sequences'])])))ggplot(TB, aes(V1,V3)) + geom_bar(stat = 'identity') + facet_wrap(~V2, scales = 'free') + theme_bw()+theme(strip.background = element_rect(fill = 'white'), strip.text.x = element_text(size = 10))ggsave(&quot;img/Stats_Sort_reads.png&quot;, w= 20, h= 10.9)## Bar plot 2; sort by 'reads length'TB$V1 &lt;- factor(TB$V1, levels=as.character(na.omit(TB$V1[TB$V2=='raw total sequences'][order(TB$V3[TB$V2=='average length'])])))ggplot(TB, aes(V1,V3)) + geom_bar(stat = 'identity') + facet_wrap(~V2, scales = 'free') + theme_bw()ggsave(&quot;img/Stats_Sort_AL.png&quot;, w= 20, h= 10.9)TB_w &lt;- reshape(TB, timevar = &quot;V1&quot;, idvar = &quot;V2&quot;, direction = 'wide')row.names(TB_w) &lt;- TB_w[[1]]TB_w &lt;- TB_w[-1]colnames(TB_w) &lt;- str_replace(colnames(TB_w), &quot;V3.&quot;, &quot;&quot;)# Corrolation PlotList &lt;- row.names(TB_w)[!is.na(data.frame(scale(t(TB_w)))[1,])]TB_ww &lt;- TB_w[row.names(TB_w)%in% List,]ggpairs(as.data.frame(t(TB_ww)))ggsave(&quot;123.png&quot;, w=30, h = 30)TB_cor &lt;- as.data.frame(cor(t(TB_ww)))corPLOT &lt;- function(COL, CUT=0.75){ Cor_tmp = data.frame( X = row.names(TB_cor)[order(abs(TB_cor[COL]))], Y = TB_cor[COL][order(abs(TB_cor[COL])),] ) Cor_tmp$X = factor(Cor_tmp$X, levels = Cor_tmp$X) ggplot(Cor_tmp, aes(Y, X, fill = Y)) + geom_bar( stat = 'identity') + geom_vline( xintercept = c(CUT, - CUT ), linetype = 2, color= 'grey') + geom_text(aes(x=CUT, y=1, label = CUT), hjust = -.1) + theme_bw() + ggtitle(COL) + theme(plot.title=element_text(hjust = .5)) ggsave(paste('img/Cor_', str_replace_all(COL, &quot; &quot;, &quot;_&quot;), &quot;.png&quot;, sep =&quot;&quot;), w= 7, h= 7)}TB_w[row.names(TB_w) %in% Norm_list,] &lt;- TB_w[row.names(TB_w) %in% Norm_list,]/c(TB_w[1,])TB_wS &lt;- as.data.frame(t(scale(t(TB_w))))TB_wS &lt;- TB_wS[!is.na(TB_wS[[1]]),]TB_w &lt;- TB_w[!is.na(TB_wS[[1]]),]TB_w[TB_w &gt; 1] &lt;- round(TB_w[TB_w &gt; 1],2)TB_w[TB_w &lt; 1] &lt;- paste(round(TB_w[TB_w &lt; 1]*100,2), &quot;%&quot;)#TB_w[row.names(TB_w) %in% Norm_list,] &lt;- round(TB_w[row.names(TB_w) %in% Norm_list,]*100,2)P &lt;- pheatmap(as.data.frame(scale(t(TB_wS))), display_numbers = t(TB_w[row.names(TB_w) %in% row.names(TB_wS),]), fontsize_col= 15)as.ggplot(P)ggsave(&quot;img/Stat_Pheatmap.png&quot;, w= 20, h = 10.9) Pheatmap Align Depth Plot Depth statistics are based on samtools: samtools depth -r UAS:0-10000 sorted.bam mkdir Depthfor i in $(ls Bam/*.bam);do SAMPLE=$(echo $i| sed 's=Bam/==;s/.sorted.bam//'); if [ -f Depth/$SAMPLE.csv ]; then echo $SAMPLE is done else sed &quot;s/Hi/$SAMPLE/&quot; Model.sh &gt; script/Depth_$SAMPLE.sh echo samtools depth -r UAS:0-10000 $i \\&gt; Depth/$SAMPLE.csv &gt;&gt; script/Depth_$SAMPLE.sh sbatch script/Depth_$SAMPLE.sh fidonerm *.err *.outgrep . Depth/*.csv| sed 's/.csv//;s/:/\\t/;s=Depth/==' &gt; Depth.csv library(ggplot2)library(stringr)library(reshape2)TB &lt;- read.table(&quot;Depth.csv&quot;)TB$V1 &lt;- as.character(TB$V1)TB2 &lt;- TB[TB$V3 %in% c(5300:5600),]TB_w &lt;- reshape(TB2[c(-2)], idvar = &quot;V1&quot;, timevar = &quot;V3&quot;, direction = 'wide')TB_w[is.na(TB_w)] &lt;- 0row.names(TB_w)= TB_w[[1]]TB_w = TB_w[-1]#HCLUST = hclust(dist(TB_w))TB$V1 &lt;- factor(TB$V1, levels= row.names(TB_w)[order(TB_w$V4.5400)])ggplot(TB, aes(V3, V4))+ geom_point() + facet_wrap(~V1) + xlim(5300,5500) + ylim(0, 100)+theme_bw() + theme(strip.text = element_text(size = 20), strip.background = element_rect(fill = 'white'))ggsave('img/Depth_UAS.png', w= 20,, h = 10.9) Model.sh #!/bin/sh#SBATCH --qos=normal # Quality of Service#SBATCH --job-name=Hi # Job Name#SBATCH --time=1-0:00:00 # WallTime#SBATCH --mem=256000#SBATCH --mail-user=123@qq.com#SBATCH --nodes=1 # Number of Nodes#SBATCH --ntasks-per-node=1 # Number of tasks (MPI processes)#SBATCH --cpus-per-task=1 # Number of threads per task (OMP threads)#SBATCH --output=Log/Hi.out ### File in which to store job output#SBATCH --error=Log/Hi.err ### File in which to store job error messages","link":"/2022/08/26/Bioinfor/DNA-seq/"},{"title":"Nanopre and PacBio based Genome Assembly","text":"Related Papers: Rayamajhi N, Cheng C H C, Catchen J M. Evaluating Illumina-, Nanopore-, and PacBio-based genome assembly strategies with the bald notothen, Trematomus borchgrevinki[J]. G3, 2022, 12(11): jkac192. Paper van Rengs W M J, Schmidt M H W, Effgen S, et al. A chromosome scale tomato genome built from complementary PacBio and Nanopore sequences alone reveals extensive linkage drag during breeding[J]. The Plant Journal, 2022, 110(2): 572-588. Paper Murigneux V, Rai S K, Furtado A, et al. Comparison of long-read methods for sequencing and assembly of a plant genome[J]. GigaScience, 2020, 9(12): giaa146. Paper Evaluating Illumina-, Nanopore-, and PacBio-based genome assembly strategies with the bald notothen, Trematomus borchgrevinki In this paper, they did long reads assembly and Long-reads, short-reads hybrid assembly comparing. The experiment organism is “Trematomus borchgrevinki” (fish), a cold specialized Antarctic notothenioid fish with an estimated genome size of 1.28 Gb © Gregory Sloop Sequencing Size: Nanopore: 24.29 Gb PacBio: 118.42 Gb Hybrid assemblies can generate higher contiguity they tend to suffer from lower quality. long-read-only assemblies can be optimized for contiguity by subsampling length-restricted raw reads. Long-read contig assembly is the current best choice and that assemblies from phase I and phase II were of lower quality. Strategies: Long-reads and short-reads hybrid: quickmerge Long-reads assembly independently: Canu and WTDBG2 assembly, assessed with QUAST 2 rounds of polishing with Pilon. (First round: SNPs adn indels, Second round: local reassembly) Gap filling with PBJELLY Long-reads only was assembly by variaties of tools. The yacrd (Marijon et al. 2020) it the tool to identify potential chimeric reads WTDBG2 was used to do the assembly For long-reads, comparing to short-reads assembled genome, it has high continuity but also more number of duplicated BUSCO genes. Chimeric reads are exist. In this paper, they also applied the subsampling to deleted chimeric reads. By cooperate with the limiting reads lengths, the PacBio reads assembly results could be improved. The number of contigs dropped from 10,848 to 4,409 with only 70 Gb of data (generated by sampling minimum and maximum read lengths of 10 and 40 kb) In this paper, the data shows that the assembly results from ONT reads are not as good as those from PacBio reads. However, because they used very different methods for pre-processing reads and assembly, the results are somewhat incomparable. Therefore, we can only conclude that the PacBio pipeline is more advanced. Comparison of long-read methods for sequencing and assembly of a plant genome This paper targets Macadamia jansenii, a type of tree. The PacBio data surprised others because it has higher coverage and longer reads than the typical ONT data. Therefore, cross-comparison is meaningless. However, they assembled the genome using multiple tools, so the internal data-type comparison is still valuable. © Ian Edwin Cock Category ONT PacBio BGI Mean Reads Length 7,962 20,575 2 × 100 Assembly Redbean v2.5, Flye v2.5, and Canu Redbean v2.5, Flye v2.5, and Canu SuperPlus v1.0, Supernova v2.1.1, TGS-GapCloser Data Size 24.9 Gb 65.2 Gb 74.5 Gb Largest Contigs 9,683,794 23,824,472 517,998 Scaffold 5,332 5,446 5,065 Scaffold N50 3.52 3.50 3.54 Contigs 6,022 5,717 19,954 Contigs N50(M) 1.04 1.60 0.036 BUSCO 1,963 (92.5) 1,983 (93.5) 1,873 (88.3) Hybrid assembly: MaSuRCA v3.3.3: Illumina + ONT/PacBio Flye v2.5 to perform the final assembly Diploid de novo genome assembly: PacBio reads was performed with FALCON v1.3.0 Assembly Evaluation: QUAST v5.0.2; publicly available reference genome of M. integrifolia v2 (Genbank accession: GCA_900631585.1); subjected to BUSCO v3.0.2 with the eudicotyledons_odb10 database (2,121 genes). In this result, the PacBio sequences dominate everything. This is because ultra-long ONT reads were not used here. Consequently, not only the length of the reads but also the accuracy and coverage of the ONT reads are lower than those of the PacBio. This comparison is extremely uneven. By comparing different long-reads assembly tools (Redbean, Flye, Falcon, Canu, Raven), the Rave is the best for both PacBio and ONT data. An interesting thing is, according to the paper, Rave supports the GPU-accelerate. But in this research, they only given 12 threads for Rave though, technically, we could give more than 1,000 of threads if we have a professional GPU. A chromosome scale tomato genome built from complementary PacBio and Nanopore sequences alone reveals extensive linkage drag during breeding graph LR; Nanopore-->|NECAT|Assembly1; PacBio-->|Hifiasm|Assembly2; Assembly1-->|quickmerge| Sinlge; Assembly2-->|quickmerge| Sinlge In this research, they target into the cultivated tomato (Solanum lycopersicum). They applied PacBio HiFi and ONT Nanopore sequencing to develop independent. After then, they merged the HiFi and ONT assemblies to generate a long-read-only assembly where all 12 chromosomes were represented as 12 contiguous sequences (N50 = 68.5 Mbp). © Gbenga Emmanuel Orunmolase ONT PacBio HiFi Data Size 100~ Gb (x2) 20~ Gb (x2) Assembled Contigs 100~300 700~2000 Computational Costs 3 days with 256 threads (NECAT) 2 hours with 128 threads (Hifiasm) Although the ONT has fewer contigs, it has a lower BUSCO (complete) percentage due to uncorrectable base errors. For the saturating test, they found that for PacBio HiFi reads, 20 Gb would be enough to finish a good assembly with Hifiasm. For longer ONT reads, 50 Gb could do a similar job with NECAT. After that, they conducted the merge test because they found partial complementarity of the assemblies as the breakpoints were different. After merging the two results, they obtained 12 super contigs, which correspond to the 12 chromosomes. Along with these 12 super contigs, they also obtained 54 contigs that could not be assembled into the 12 chromosomes; these could be chloroplast, mitochondrial, rDNA, and satellite repeat-derived sequences. MbTMV assembly pipeline (Merge ONT and PacBio results) Assembly result polishing nucmer (part of mummer v.4.0.0rc1) with the -l parameter to prevent invalid contig links quickmerge[1] was used to merge 2 assemblies with the parameter -c 7.0. A very interesting thing is they use a customized script to convert the Salsa2 output to Hi-C file and plot the contact plot with jucibox A recent comparison pointed out that PacBio HiFi reads tend to lead to better assembly of the barley (Hordeum vulgare) genome than ONT (Mascher et al., 2021) pre { // background-color:#38393d; color: #5fd381; } Chakraborty M, Baldwin-Brown J G, Long A D, et al. Contiguous and accurate de novo assembly of metazoan genomes with modest long read coverage[J]. Nucleic acids research, 2016, 44(19): e147-e147. GitHub ↩︎","link":"/2024/06/30/Bioinfor/LongReads/"},{"title":"IgCaller","text":"IgCaller is used extensively in immunology research to study B-cell receptor diversity and antibody generation mechanisms. Clinically, it helps identify clonal B-cell expansions, monitor minimal residual disease in leukemias and lymphomas, and analyze antibody responses to vaccines. Additionally, it supports therapeutic antibody development by identifying candidate antibodies from strong immune responses. It is an open-source tool designed to study human B cell Ig gene rearrangements. According to the documentation, it only supports the human hg19 or hg38 genome as the input reference, so the application of this tool is limited to humans. It requires selecting specific areas of the genome. I am currently working on nonhuman Ig. I may update with more details later when I work with human Ig. The basic use only requires the short reads aligned BAM file: IgCaller -I /path/to/IgCaller/IgCaller_reference_files/ -V hg19 -C ensembl -T /path/to/bams/tumor.bam -N /path/to/bams/normal.bam -R /path/to/reference/genome_hg19.fa -o /path/to/IgCaller/outputs/ Output: IgCaller returns a set of tab-separated files: tumor_sample_output_filtered.tsv: High confidence rearrangements passing the defined filters. tumor_sample_output_IGH.tsv: File containing all IGH rearrangements. tumor_sample_output_IGK.tsv: File containing all IGK rearrangements. tumor_sample_output_IGL.tsv: File containing all IGL rearrangements. tumor_sample_output_class_switch.tsv: File containing all CSR rearrangements. tumor_sample_output_oncogenic_IG_rearrangements.tsv: File containing all oncogenic IG rearrangements (translocations, deletions, inversions, and gains) identified genome-wide. More details: Nadeu, F., Mas-de-les-Valls, R., Navarro, A. et al. IgCaller for reconstructing immunoglobulin gene rearrangements and oncogenic translocations from whole-genome sequencing in lymphoid neoplasms. Nature Communications 11, 3390 (2020). https://doi.org/10.1038/s41467-020-17095-7. pre { background-color:#38393d; color: #5fd381; }","link":"/2024/06/24/Bioinfor/IgCaller/"},{"title":"MUMmer: Rapidly Genomes Alignment","text":"Installation: In linux, you could simply install it by apt install mummer. The version of the mummer is around 3.1. The version from Bioconda is little bit new than the apt source but still kind of old. If you install teh MUMmer from those 2 source, you’ll meet error when the reads is too long. NUCmer: Test target: Chicken Genome (GRCg6a) and Duck Genome (SKLA1.0) It could be RAM monster when you compare 2 Genome directly. Especially when you want to use the multiple threads, the RAM would be occupied very quick and the program would be killed. nucmer -maxmatch -c 100 -p output_prefix reference.fasta query.fastashow-coords -rcl output_prefix.delta &gt; output_prefix.coordscat output_prefix.coordsgrep -Ev &quot;^$|=|\\[&quot; result/test.coords| grep &quot;^ &quot;| awk 'BEGIN { OFS=&quot;\\t&quot;; print &quot;Ref_Start&quot;, &quot;Ref_End&quot;, &quot;Query_Start&quot;, &quot;Query_End&quot;, &quot;Length1&quot;, &quot;Length2&quot;, &quot;Identity&quot;, &quot;Ref&quot;, &quot;Query&quot; } {OFS=&quot;\\t&quot;; print $1, $2, $4, $5, $7, $8, $10, $12, $13}' &gt; test.coords But the problem is there are no such parameter for NUCmer to limited the use of RAM. The only way to solving this problem is split the genome into single sequences and processing one by one. [1] 70706 killed nucmer --maxmatch -c 100 -p result/Chicken-SKLA1.0 I was tried to extract the first chromosome (196,202,544 bp, 192M) from the Chicken align against the Duck genome (1.2 Gb) and it takes 41 GB RAM if you given only 1 thread. If you run it without given threads, it would run with 3 threads and the RAM would increased into 70 GB. So, it seams it is save to run with about 7 threads with this size of data. But after 1h 12min, it was killed because of the increased demand of RAM. If you use single thread, the RAM would increased in to 77 after about 1h and 12min. Finally, it takes 13h 3m. MUMmer MUMmer is focusing on the difference between the reference and the Subject. It output is very sample. It only contains the start, end, and the length of the reference. Based on this, we could know that they are forward or reverse-complemented. It doesn’t has the responded position for Subject chromosome. So, because of the low dimension information, it requires very low RAM and works very efficient. It could finishing calculation in a very short time. mummer -mum -b -c ref.fa sub.fa &gt; ref.mumsmummerplot --postscript --prefix=ref_qry ref.mumsgnuplot ref_qry.gp For visualization, you could use the package provide tools. You could also convert it into tables and visualize it with your favorite tools. So, after convert the mummer result into tsv by a python script, we could visualize the result with ggplot. pre { background-color:#38393d; color: #5fd381; }","link":"/2024/06/21/Bioinfor/MUMmer/"},{"title":"Odds Ratio","text":"Odds Ratio © psychscenehub 2020 ##Odds ratio Odds of an event happening is defined as the likelihood that an event will occur, expressed as a proportion of the likelihood that the event will not occur. Therefore, if A is the probability of subjects affected and B is probability of subjects not affected, then odds = A /B. Therefore, the odds of rolling four on a dice are 1/5 or 20%. Odds Ratio (OR) is a measure of association between exposure and an outcome. The OR represents the odds that an outcome will occur given a particular exposure, compared to the odds of the outcome occurring in the absence of that exposure. Important points about Odds ratio: Calculated in case-control studies as incidence of outcome is not known OR &gt;1 indicates increased occurrence of event OR &lt;1 indicates decreased occurrence of event (protective exposure) Look at CI and P value for statistical significance of value In rare outcomes OR = RR (RR = Relative Risk). This applies when the incidence of disease is &lt; 10% CLINICAL EXAMPLE AND CALCULATION In a study examining the association between estrogen (exposure) and endometrial carcinoma (outcome), the two by two table is shown below. Learning point: In a two by two table, for ease of calculation ensure that the outcome of interest is always at the top and the exposure on the left. annotations: cite from: psychscenehub copyright belongs to the psychscenehub.com","link":"/2020/07/28/Bioinfor/OddsRatio/"},{"title":"Entrez Direct: E-utilities on the UNIX Command Line","text":"Entrez Direct: E-utilities on the UNIX Command Line Install cd ~/bin/bashperl -MNet::FTP -e \\ '$ftp = new Net::FTP(&quot;ftp.ncbi.nlm.nih.gov&quot;, Passive =&gt; 1); $ftp-&gt;login; $ftp-&gt;binary; $ftp-&gt;get(&quot;/entrez/entrezdirect/edirect.tar.gz&quot;);'gunzip -c edirect.tar.gz | tar xf -rm edirect.tar.gzbuiltin exitexport PATH=$PATH:$HOME/edirect &gt;&amp; /dev/null || setenv PATH &quot;${PATH}:$HOME/edirect&quot;./edirect/setup.sh or, you can using Bioconda conda install -c bioconda entrez-direct Cookbook Origin: NCBI-Hackathons (Archive) Best Practices for EDirect: Please keep to &lt;50,000 expected hits (it simply won’t work) Please do not run from multiple processors on a compute farm Update to latest version For more information and documentation on EDirect, please see: Entrez Direct: E-utilities on the Unix Command Line Insiders Guide to Accessing NLM Data: EDirect Overview All items below come with no explicit or implicit warranty. All code is as-is and produced for the bioinformatics community, from the bioinformatics community. EDirect Scripts 1. Protein Description (optional): Written by: Peter Cooper Confirmed by: Ben Busby Databases: Taxonomy efetch -db nuccore -id NZ_AZKP01000022.1 -seq_start 149413 -seq_stop 154038 -format gbc | xtract -insd CDS INSDInterval_from INSDInterval_to protein_id product backs to: NZ_AZKP01000022.1 1 480 WP_024797446.1 DEAD/DEAH box helicaseNZ_AZKP01000022.1 501 3626 WP_024797445.1 site-specific DNA-methyltransferaseNZ_AZKP01000022.1 3629 4626 WP_024797444.1 DEAD/DEAH box helicase family protein 2. taxids of taxonomy Description (optional): Note: Options for parsing nodes.dmp from NCBI Taxonomy are cited in issue #25, intentionally left open Written by: Scott McGinnis (11/17/2017) Confirmed by: Databases: Taxonomy esearch -db taxonomy -query &quot;vertebrata[orgn]&quot; | efetch -db taxonomy -format docsum | xtract -pattern DocumentSummary -if Rank -equals family -element Id,Division,ScientificName,CommonName | more backs to: 3. SRA from BioProject Description: Given an SRA Run ID (e.g. SRR532256) that is a member of a BioProject that has additional runs, retrieve all the other run IDs. This is a variant of the BioProject call below. Written by: Rob Edwards (1/11/2018) Confirmed by: Databases: SRA, BioProject esearch -db sra -query &quot;SRR532256&quot; | efetch -format docsum | xtract -pattern Runs -ACC @acc -element &quot;&amp;ACC&quot; backs to SRA list: SRR545469 SRR539813 SRR532971 SRR532256 SRR532204 SRR532200 SRR532194 SRR532250 3.1 Get all SRA for a BioProject Description (optional): Written by: Bob Sanders (3/22/2017) Confirmed by: Databases: SRA, BioProject esearch -db bioproject -query &quot;PRJNA356464&quot; | elink -target sra | efetch -format docsum | \\xtract -pattern DocumentSummary -ACC @acc -block DocumentSummary -element &quot;&amp;ACC&quot; backs to SRA list: SRA507436 SRX2439829 SRP095511 SRS1874418 SRR5125027SRA507436 SRX2439828 SRP095511 SRS1874418 SRR5125026SRA507436 SRX2439826 SRP095511 SRS1874418 SRR5125024 3.2 Get latitiude and longitude for SRA Datasets (e.g. outbreaks and metagenomes) Description (optional): Written by: BB, Mike D, Rob Edwards (4/12/2017) Confirmed by: Databases: SRA, BioSample ## make a ID listecho &quot;SRA507436SRX2439829SRP095511SRS1874418SRR5125027&quot; |sed 's/SR/ SR/g'| tr &quot; &quot; '\\n' | sed '/^$/d' &gt; sra_ids.txt## runfor i in $(cat sra_ids.txt); do ll=$(esearch -db sra -query $i | \\elink -target biosample | efetch -format docsum | \\xtract -pattern DocumentSummary -block Attribute -if Attribute@attribute_name -equals lat_lon -element Attribute); \\echo -e &quot;$i\\t$ll&quot;; done backs to: SRA507436SRX2439829SRP095511SRS1874418SRR5125027 returns nothing - - 3.3 SRA sizes Description (optional): This retrieves the SRR id and the size in bp of the run from a file (ids.txt) of SRR IDs. You can also change bases to size_MBto get the size of the dataset in MB. Question: Does the size in MB include the sequence identifiers (i.e. the size of the file) or just the sequences? Written by: Rob Edwards (7/6/2017) Confirmed by: Databases: SRA ## make a ID listecho &quot;SRA507436SRX2439829SRP095511SRS1874418SRR5125027&quot; |sed 's/SR/ SR/g'| tr &quot; &quot; '\\n' | sed '/^$/d' &gt; ids.txt## Runepost -db sra -input ids.txt -format acc | esummary -format runinfo -mode xml | xtract -pattern Row -element Run,bases backs to: SRR5125024 36123158012SRR5125026 44717689640SRR5125027 26480446596 4 Gene 4.1 Gene Aliases Description (optional): Written by: NCBI Folks (12/14/2016) Confirmed by: Databases: gene esearch -db gene -query &quot;Liver cancer AND Homo sapiens&quot; | \\efetch -format docsum | \\xtract -pattern DocumentSummary -element Name OtherAliases OtherDesignations 4.2 Genomic.fa Download Description (optional): Written by: NCBI Folks (12/14/2016) Confirmed by: Peter Cooper (NCBI) and Wayne Matten (NCBI) (12/29/2016, v6.00) Databases: assembly wget `esearch -db assembly -query &quot;Leptospira alstonii[ORGN] AND latest[SB]&quot; | \\efetch -format docsum | \\xtract -pattern DocumentSummary -element FtpPath_RefSeq | \\awk -F&quot;/&quot; '{print $0&quot;/&quot;$NF&quot;_genomic.fna.gz&quot;}'` (For larger sets of data the above may fail as wget may not accept a very large number of arguments.The command below should work for all.)esearch -db assembly -query &quot;Leptospira alstonii[ORGN] AND latest[SB]&quot; | \\efetch -format docsum | \\xtract -pattern DocumentSummary -element FtpPath_RefSeq | \\awk -F&quot;/&quot; '{print $0&quot;/&quot;$NF&quot;_genomic.fna.gz&quot;}' | \\xargs wget backs to: --2020-05-18 17:45:54-- ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/001/569/445/GCF_001569445.1_ASM156944v1/GCF_001569445.1_ASM156944v1_genomic.fna.gz (try: 2) =&gt; ‘GCF_001569445.1_ASM156944v1_genomic.fna.gz’Connecting to ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)|130.14.250.13|:21... connected.Logging in as anonymous ... Logged in!==&gt; SYST ... done. ==&gt; PWD ... done.==&gt; TYPE I ... done. ==&gt; CWD (1) /genomes/all/GCF/001/569/445/GCF_001569445.1_ASM156944v1 ... done.==&gt; SIZE GCF_001569445.1_ASM156944v1_genomic.fna.gz ... 1311014==&gt; PASV ... done. ==&gt; REST 870800 ... done. ==&gt; RETR GCF_001569445.1_ASM156944v1_genomic.fna.gz ... done.Length: 1311014 (1.2M), 440214 (430K) remaining (unauthoritative)GCF_001569445.1_ASM156944v1_genomic.fna.gz 68%[+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++==&gt; ] 880.29K 404 B/s eta 6m 49s 4.3 organellar contigs from genbank Description (optional): Written by: NCBI Folks (12/14/2016) Confirmed by: Databases: nuccore esearch -db nuccore -query &quot;LKAM01&quot; | efetch -format fasta 4.4 Get protein sequences from nucleotide accessions Description (optional): Written by: NCBI Folks (12/14/2016) Confirmed by: Databases: nuccore, protein cat accs_file | epost -db nuccore -format acc | \\elink -target protein | efetch -format fasta 4.5 taxonomy (KPCOFG) for taxids Description (optional): Written by: NCBI Folks (12/14/2016) Confirmed by: Databases: taxonomy efetch -db taxonomy -id 9606,1234,81726 -format xml | \\xtract -pattern Taxon -tab &quot;,&quot; -first TaxId ScientificName \\-group Taxon -KING &quot;(-)&quot; -PHYL &quot;(-)&quot; -CLSS &quot;(-)&quot; -ORDR &quot;(-)&quot; -FMLY &quot;(-)&quot; -GNUS &quot;(-)&quot; \\-block &quot;*/Taxon&quot; -match &quot;Rank:kingdom&quot; -KING ScientificName \\-block &quot;*/Taxon&quot; -match &quot;Rank:phylum&quot; -PHYL ScientificName \\-block &quot;*/Taxon&quot; -match &quot;Rank:class&quot; -CLSS ScientificName \\-block &quot;*/Taxon&quot; -match &quot;Rank:order&quot; -ORDR ScientificName \\-block &quot;*/Taxon&quot; -match &quot;Rank:family&quot; -FMLY ScientificName \\-block &quot;*/Taxon&quot; -match &quot;Rank:genus&quot; -GNUS ScientificName \\-group Taxon -tab &quot;,&quot; -element &quot;&amp;KING&quot; &quot;&amp;PHYL&quot; &quot;&amp;CLSS&quot; &quot;&amp;ORDR&quot; &quot;&amp;FMLY&quot; &quot;&amp;GNUS&quot; backs to: 9606,Homo sapiens,Metazoa,Chordata,Mammalia,Primates,Hominidae,Homo1234,Nitrospira,-,Nitrospirae,Nitrospira,Nitrospirales,Nitrospiraceae,-81726,unidentified microorganism,-,-,-,-,-,- 5 Obtain UniProt IDs from gene symbols Description (optional): Written by: NCBI Folks (12/14/2016) Confirmed by: Databases: gene, protein esearch -db gene -query &quot;tp53[preferred symbol] AND human[organism]&quot; | \\elink -target protein | \\esummary | \\xtract -pattern DocumentSummary -element Caption SourceDb | \\grep -E '^[OPQ][0-9][A-Z0-9]{3}[0-9]\\|^[A-NR-Z][0-9]([A-Z][A-Z0-9]{2}[0-9]){1,2}' 6. Taxon IDs from genome accession numbers Description (optional): Written by: NCBI Folks (12/14/2016) Confirmed by: Databases: nuccore cat genome_accession.txt | \\epost -db nuccore -format acc | \\esummary | \\xtract -pattern DocumentSummary -element AccessionVersion TaxId 7. Convert article DOI to PMID Description (optional): Written by: NCBI Folks (12/14/2016) Confirmed by: Mike Davidson (NLM) (12/16/2016, v5.80) Databases: pubmed esearch -db pubmed -query &quot;10.1111/j.1468-3083.2012.04708.x&quot; | \\esummary | \\xtract -pattern DocumentSummary -block ArticleId -sep &quot;\\t&quot; -tab &quot;\\n&quot; -element IdType,Value | \\grep -E '^pubmed|doi' backs to: pubmed 23004926doi 10.1111/j.1468-3083.2012.04708.x 8. Access organism specific meta-data from NCBI genome database Description (optional): Written by: NCBI Folks (12/14/2016) Confirmed by: Databases: genome, bioproject esearch -db genome -query &quot;22954[uid]&quot; | \\elink -target bioproject | \\efetch -format xml | \\xtract -pattern DocumentSummary -element Salinity OxygenReq OptimumTemperature TemperatureRange Habitat 9. Get the status of records from PubMed search Description (optional): Written by: NCBI Folks (12/14/2016) Confirmed by: Mike Davidson (NLM) (12/16/2016, v5.80) Databases: pubmed esearch -db pubmed -query &quot;pde3a AND 2016[dp]&quot; | \\esummary | \\xtract -pattern DocumentSummary -element Id RecordStatus backs to: 28959341 PubMed28060719 PubMed - indexed for MEDLINE27975297 PubMed - indexed for MEDLINE27927168 PubMed - indexed for MEDLINE27865066 PubMed - indexed for MEDLINE27053290 PubMed - indexed for MEDLINE27765510 PubMed - indexed for MEDLINE27524442 PubMed - indexed for MEDLINE27662514 PubMed - indexed for MEDLINE27647936 PubMed - indexed for MEDLINE27633875 PubMed - indexed for MEDLINE27610941 PubMed - indexed for MEDLINE27502037 PubMed - indexed for MEDLINE27180831 PubMed - indexed for MEDLINE28959563 PubMed26934198 PubMed - indexed for MEDLINE26926596 PubMed - indexed for MEDLINE26656089 PubMed - indexed for MEDLINE26628038 PubMed - indexed for MEDLINE26460717 PubMed - indexed for MEDLINE26374610 PubMed - indexed for MEDLINE 9.1 Conduct a PubMed search and retrieve the results as a list of PMIDs Description (optional): Written by: Mike Davidson (2/22/2017) Confirmed by: Mike Davidson (NLM) (2/22/2017, v6.30) Databases: pubmed esearch -db pubmed -query &quot;seasonal affective disorder&quot; | efetch -format uid backs to: 3227703532252583321634583211148932108162... 10. Sort the hits by sequence length in nucleotide database Description (optional): Written by: NCBI Folks (12/14/2016) Confirmed by: Databases: nuccore esearch -db nuccore -query &quot;bacillus[orgn] AND biomol_rRNA[prop] AND 1500:1560[slen]&quot; | \\esummary | \\xtract -pattern DocumentSummary -element Slen Extra | \\sort -rnk 1 11. Getting meta data from assembly Description (optional): Written by: NCBI Folks (12/14/2016) Confirmed by: Databases: assembly esearch -db assembly -query &quot;mammals[orgn] AND latest[filter]&quot; | \\efetch -format docsum | \\xtract -pattern DocumentSummary -element Organism,SpeciesName,BioSampleAccn,LastMajorReleaseAccession \\-block Stat -if &quot;@category&quot; -equals chromosome_count -element Stat | \\grep -Pv &quot;\\t0$&quot; 12. Fetch HSPs from a BLAST hit in FASTA Description (optional): Written by: NCBI Folks (12/14/2016) Confirmed by: Databases: nuccore blastn -db nr -query in.fna -remote -outfmt &quot;6 sacc sstart send&quot; | \\xargs -n 3 sh -c 'efetch -db nuccore -id &quot;$0&quot; -seq_start &quot;$1&quot; -seq_stop &quot;$2&quot; -format fasta' 13. Get all Gene Ontology IDs for a given protein accession Description (optional): Written by: NCBI Folks (12/14/2016) Confirmed by: Databases: protien, biosystems epost -db protein -id BAD92651.1 -format acc | \\elink -target biosystems | \\efetch -format docsum | \\xtract -pattern externalid -element externalid | \\awk '{if ($0 ~ /GO/) print $0}' 14. Get the ten most frequently-occurring authors for a set of articles Description (optional): Searches PubMed for the string “traumatic brain injury athletes”, restricts results to those published in 2015 and 2016, retrieves the full XML records for each of the search results, extracts the last name and initials of every author on every record, sorts the authors by frequency of occurrence in the results set, and presents the top ten most frequently-occurring authors, along with the number of times that author appeared. Written by: Mike Davidson (NLM) (12/15/2016) Confirmed by: Mike Davidson (NLM) (12/16/2016) Databases: pubmed esearch -db pubmed -query &quot;traumatic brain injury athletes&quot; -datetype PDAT -mindate 2015 -maxdate 2016 | \\efetch -format xml | \\xtract -pattern Author -sep &quot; &quot; -element LastName,Initials | \\sort-uniq-count-rank | \\head -n 10 15. Get the ten funding agencies who are most active in funding articles on a particular topic Description (optional): Searches PubMed for the string “diabetes AND pregnancy”, restricts results to those published in 2014 through 2016, retrieves the full XML records for each of the search results, extracts the funding agencies for every grant on every record, sorts the agencies by frequency of occurrence in the results set, and presents the top ten most frequently-occurring agencies, along with the number of times that agency appeared. Written by: Mike Davidson (2/17/2017) Confirmed by: Mike Davidson (NLM) (v6.30, 2/17/2017) Databases: pubmed esearch -db pubmed -query &quot;diabetes AND pregnancy&quot; -datetype PDAT -mindate 2014 -maxdate 2016 | \\efetch -format xml | \\xtract -pattern Grant -element Agency | \\sort-uniq-count-rank | \\head -n 10 16. Look up the publication date for thousands of PMIDs (option one) Description (optional): Takes a file which contains a list of PMIDs (table_of_pubmed_ids) and uses cat to access the contents of the file, epost to post the PMIDs to the history server, efetch to retrieve the records and xtract to extract PMID and Publication Date. Written by: NCBI Folks (12/15/2016) Confirmed by: Mike Davidson (NLM) (v6.30, 2/17/2017) Databases: pubmed cat table_of_pubmed_ids | \\epost -db pubmed | \\efetch -format xml | \\xtract -pattern PubmedArticle -element MedlineCitation/PMID \\-block PubDate -sep &quot; &quot; -element Year,Month MedlineDate 17. Look up the publication date for thousands of PMIDs (option two) Description (optional): Takes a file which contains a list of PMIDs (table_of_pubmed_ids) and epost -input to access the contents of the file and post the PMIDs to the history server, efetch to retrieve the records and xtract to extract PMID and Publication Date. Written by: Mike Davidson (2/17/2017) Confirmed by: Mike Davidson (NLM) (v6.30, 2/17/2017) Databases: pubmed epost -input table_of_pubmed_ids -db pubmed | \\efetch -format xml | \\xtract -pattern PubmedArticle -element MedlineCitation/PMID \\-block PubDate -sep &quot; &quot; -element Year,Month MedlineDate 18. Find the first author for a set of PubMed records Description (optional): Outputs the PMID and first author’s last name and initials for one or more PubMed records Written by: Mike Davidson (2/17/2017) Confirmed by: Mike Davidson (NLM) (v6.30, 2/17/2017) Databases: pubmed efetch -db pubmed -id 16940437 -format xml | \\xtract -pattern PubmedArticle -element MedlineCitation/PMID \\-block Author -position first -sep &quot; &quot; -element LastName,Initials 19. Find the first author and any other authors who contributed equally for a set of PubMed records Description (optional): Outputs the PMID and first author’s last name and initials for one or more PubMed records. If the record indicates equal contributors to the first author, the last name and initials for all equal contributors will also be output, separated by commas. Written by: Mike Davidson (10/27/2017) Confirmed by: Mike Davidson (NLM) (v7.40, 10/27/2017) Databases: pubmed efetch -db pubmed -id 22358458,26877147 -format xml | \\xtract -pattern PubmedArticle -element MedlineCitation/PMID \\-block Author -position first -sep &quot; &quot; -tab &quot;, &quot; -element LastName,Initials -EQUAL Author@EqualContrib \\-block Author -if &quot;+&quot; -is-not 1 \\-and Author@EqualContrib -equals Y \\-and &quot;&amp;EQUAL&quot; -equals Y \\-sep &quot; &quot; -tab &quot;, &quot; -element LastName,Initials 20 Download GEO Data from a BioProject Accession Description (optional): Written by: NCBI Folks (12/16/2016) Confirmed by: Databases: gds esearch -db gds -query &quot;PRJNA313294[ACCN]&quot; | \\efetch -format docsum | \\xtract -pattern DocumentSummary -element FTPLink 21 Extract all MeSH Headings from a given PMID Description (optional): Retrieves the PMID of a PubMed record, followed by a pipe-delimitted list of MeSH Descriptors for a PMID. Written by: Mike Davidson (10/02/2017) Confirmed by: Mike Davidson (NLM) (v7.30, 10/02/2017) Databases: pubmed efetch -db pubmed -id 24102982 -format xml | \\xtract -pattern PubmedArticle -tab &quot;|&quot; -element MedlineCitation/PMID \\-block MeshHeading -tab &quot;|&quot; -element DescriptorName Extract all MeSH Headings and Subheadings from a given PMID Description (optional): Retrieves the PMID of a PubMed record, followed by a pipe-delimitted list of MeSH Descriptors and Qualifiers for a PMID. Each Descriptor is followed by any attached qualifiers, separated by “/”. Written by: Mike Davidson (10/02/2017) Confirmed by: Mike Davidson (NLM) (v7.30, 10/02/2017) Databases: pubmed efetch -db pubmed -id 24102982 -format xml | \\xtract -pattern PubmedArticle -tab &quot;|&quot; -element MedlineCitation/PMID \\-block MeshHeading -tab &quot;|&quot; -sep &quot;/&quot; -element DescriptorName,QualifierName Search for articles by authors affiliated with a specific institution by matching two partial affiliation strings. Description (optional): Searching PubMed for two affiliation strings ANDed together (e.g. “translational medicine[AD] AND thomas jefferson[AD]”) will retrieve all records that have both strings listed somewhere in the record’s Affiliation data, but does not require both strings be listed on the same author’s affiliation. To generate a list of PMIDs where both strings are present in the same affiliation element, use the following script. Written by: Mike Davidson (4/2/2018) Confirmed by: Mike Davidson (NLM) (v8.10, 4/2/2018) Databases: pubmed esearch -db pubmed -query &quot;translational medicine[ad] AND thomas jefferson[ad]&quot; | \\efetch -format xml | \\xtract -pattern PubmedArticle -PMID MedlineCitation/PMID \\-block Affiliation -if Affiliation -contains &quot;translational medicine&quot; -and Affiliation -contains &quot;thomas jefferson&quot; \\-tab &quot;\\n&quot; -element &quot;&amp;PMID&quot; | \\sort -n | uniq Search for PMC articles citing a gived PubMed articler; retrieve title, source, ID Description: Retrieve information about all PMC articles (wihich have free fulltext available) which cite a gived PubMed article Written by: Lukas Wagner (08/16/2018) Databases: pubmed, pmc esearch -db pubmed -query 23618408 | elink -name pubmed_pmc_refs -target pmc | \\efetch -format docsum | \\xtract -pattern DocumentSummary -element Title -element Source -block ArticleId -if &quot;IdType&quot; -equals pmcid -element Value Xtract Exp1: aquire infor inner a tag esearch -db bioproject -query &quot;PRJNA356464&quot; | elink -target sra | efetch -format docsum | \\xtract -pattern DocumentSummary -ACC @acc -block DocumentSummary -element &quot;&amp;ACC&quot; SRA507436 SRX2439829 SRP095511 SRS1874418 SRR5125027 SRA507436 SRX2439828 SRP095511 SRS1874418 SRR5125026 SRA507436 SRX2439827 SRP095511 SRS1874418 SRR5125025 SRA507436 SRX2439826 SRP095511 SRS1874418 SRR5125024 Example of single Runs &lt;Runs&gt; &lt;Run acc=&quot;SRR5125024&quot; total_spots=&quot;119613106&quot; total_bases=&quot;36123158012&quot; load_done=&quot;true&quot; is_public=&quot;true&quot; cluster_name=&quot;public&quot; static_data_available=&quot;true&quot;/&gt;&lt;/Runs&gt; As a result, we can aquire total spots with @total_spots","link":"/2020/07/28/Bioinfor/E-utilities/"},{"title":"NextDenovo: an efficient error correction and accurate assembly tool for noisy long reads","text":"Quick Start Tutorial Other related Long reads Assembly Tools, check the end of the post, for example: Falcon (Chin et al. 2016), Canu (Koren et al. 2017), WTDBG2 (Ruan and Li 2020), or Flye (Kolmogorov et al. 2019) NextDenovo Paper: Hu J, Wang Z, Sun Z, et al. NextDenovo: an efficient error correction and accurate assembly tool for noisy long reads[J]. Genome Biology, 2024, 25(1): 107. Background Third-generation long-read: PacBio has high-fidelity (HiFi) reads but they are relatively short (~ 15 kb). So, it is unable to span long tandem or highly homologous multi-copy repeats like centromeres. ONT sequencing can generate &gt; 100-kb “ultra-long” reads. CTA and ATC: “correction then assembly” (CTA, an assembler first corrects errors in the reads and then uses the corrected reads for assembly) and “assembly then correction” (ATC, an assembler uses error-prone reads to assemble the genome and then corrects errors in the assembled genome) are commonly used in assembly. CTA is much slower. But in terms of the assembly of segmental duplications/repeats, and especially for large plant genome assemblies, the CTA-based strategy usually has an enhanced ability to distinguish different gene copies and produce more accurate and continuous assemblies. NextDenovo is the tool of CTA-based assembly tool Steps Detecting Overlapping Reads Initial Detection: Detects overlapping reads (Fig. 1A). Filtering: Filters out alignments caused by repeats. Splitting: Splits chimeric seeds based on overlapping depth (Fig. 1B). Rough Correction with KSC Algorithm Algorithm Used: Kmer score chain (KSC) algorithm, used in NextPolish [19], for initial rough correction (Fig. 1C). Handling Repeated Regions Detection of Low-Score Regions (LSRs): Uses a heuristic algorithm during traceback within the KSC algorithm. Accurate Correction: Combines partial order alignment (POA) [20] and KSC. Collects subsections spanning LSRs and generates kmer sets at flanking sequences. Filters subsections with lower kmer scores. Creates pseudo-LSR seeds from top-ranked subsections using a greedy POA consensus algorithm. Maps and corrects pseudo-LSR seeds multiple times for accuracy. Integrates corrected LSRs back into the primary corrected seed (Fig. 1D). Pairwise Overlapping and Dovetail Alignments Two Rounds of Overlapping: First Round: Uses rapid detection parameters. Second Round: Applies rigorous parameters for accurate alignments. Graph Construction: Constructs a directed string graph. Removes transitive edges using the “best overlap graph” (BOG) algorithm. For repeat nodes, edges are only removed if below specific thresholds to maintain connectivity. Removes tips and resolves bubbles. Progressive Graph Cleaning Simplifying Subgraphs: Uses a progressive cleaning strategy with increasingly stringent thresholds. Breaks paths at nodes with multiple connections. Outputs contigs from broken linear paths. Reducing Misassemblies: Maps all seeds to contigs. Breaks contigs at lower mapping depth regions (LDRs) (Fig. 1E). Key Algorithms and Techniques KSC Algorithm: Used for initial rough correction and handling LSRs. Heuristic and Accurate Algorithms: For detecting and correcting LSRs. BOG Algorithm: For removing transitive edges in the graph. Error Correction NextDenovo is 1.63 times faster on real data compared to Consent, Canu, and Necat. As the read length increases, the time required for correction also increases. However, NextDenovo and Necat demonstrated only slight increases, while Canu exhibited a significant increase in processing time Installation # Prerequirementpip install paralleltask# Install from github git clone git@github.com:Nextomics/NextDenovo.gitcd NextDenovo &amp;&amp; make# TestnextDenovo test_data/run.cfg Run nextDenovo run.cfg Example of run.cfg [General] job_type = local job_prefix = nextDenovo task = all rewrite = yes deltmp = yes parallel_jobs = 22 input_type = raw read_type = ont # clr, ont, hifi input_fofn = input.fofn input_fofn2 = input2.fofn workdir = HG002_NA24385_son_assemble [correct_option] read_cutoff = 1k genome_size = 3g # estimated genome size sort_options = -m 50g -t 30 minimap2_options_raw = -t 8 pa_correction = 5 correction_options = -p 30 [assemble_option] minimap2_options_cns = -t 8 nextgraph_options = -a 1 Result Sequence: 01_rundir/03.ctg_graph/nd.asm.fasta Statistics: 01_rundir/03.ctg_graph/nd.asm.fasta.stat Assembly data: 109G+98G RAM utility: about 400GB. (You can also make it run with 64 RAM but it would takes much loger time to finish) Time: about 2 days. After Assembly Compare the result from the SKLA1.0 by MUMmer ~/software/mummer-4.0.0rc1/mummer -l 200 -threads 30 -qthreads 30 -mum -b -c data/NextDenovo_result.fa data/SKLA1.0.chrall.fa &gt; result/NextDenovo_SKLA1.0.mums According to this result, the first three chromosomes from bottom to top are chr1, chr2, and chr3. The x-axis, from left to right, is sorted by the length of the contigs. As we can see, the first contig represents the full length of chr3. Contigs 2, 3, and 7 represent chr1, while contigs 6, 8, and 9 are three pieces of chr2. Another very interesting result is that, except for chr2, both chr1 and chr3 are complemented and reversed. NextPolish NextPolish was also recomand. You can download and install by following the instruction form github. But I am not that luck to install it in my Ubuntu server. It come with the error: gcc -g -Wall -Wno-unused-function -O2 -DHAVE_PTHREAD -DUSE_MALLOC_WRAPPERS bwashm.o bwase.o bwaseqio.o bwtgap.o bwtaln.o bamlite.o bwape.o kopen.o pemerge.o maxk.o bwtsw2_core.o bwtsw2_main.o bwtsw2_aux.o bwt_lite.o bwtsw2_chain.o fastmap.o bwtsw2_pair.o main.o -o bwa -L. -lbwa -lm -lz -lpthread -lrt /usr/bin/ld: ./libbwa.a(rope.o):/raid/home/wenkanl2/BioTools/NextPolish/util/bwa/rle.h:33: multiple definition of `rle_auxtab'; ./libbwa.a(bwtindex.o):/raid/home/wenkanl2/BioTools/NextPolish/util/bwa/rle.h:33: first defined here /usr/bin/ld: ./libbwa.a(rle.o):/raid/home/wenkanl2/BioTools/NextPolish/util/bwa/rle.h:33: multiple definition of `rle_auxtab'; ./libbwa.a(bwtindex.o):/raid/home/wenkanl2/BioTools/NextPolish/util/bwa/rle.h:33: first defined here collect2: error: ld returned 1 exit status make[2]: *** [Makefile:30: bwa] Error 1 make[2]: Leaving directory '/raid/home/wenkanl2/BioTools/NextPolish/util/bwa' make[1]: *** [Makefile:19: bwa_] Error 2 make[1]: Leaving directory '/raid/home/wenkanl2/BioTools/NextPolish/util' make: *** [Makefile:18: all] Error 2 So, I tied install it with bioconda: conda install NextPolish nextpolish-1.4.1 | py311h99925d8_3 1.7 MB bioconda And them, it installed the version 1.4.1. Next, I tried the test: nextPolish test_data/run.cfg and it finished the test correctly: Type Length (bp) Count (#) N10 60501 1 N20 60501 1 N30 60501 1 N40 60501 1 N50 60501 1 N60 51048 2 N70 51048 2 N80 51048 2 N90 51048 2 Min. 51048 - Max. 60501 - Ave. 55774 - Total 111549 2 Options for NextPolish [sgs_option]: Polishing using short reads only [lgs_option]: Polishing using long reads only In Action: # prepare the short reads informationls data/WGS/*.fastq &gt; sgs.fofn# Start runningnohup nextPolish Polish.cfg &gt; Polish.log &amp; cfg file for this experiment: [General] job_type = local job_prefix = nextPolish task = default rewrite = yes rerun = 3 parallel_jobs = 20 multithread_jobs = 20 genome = result/NextDenovo_result.fa genome_size = auto workdir = ./01_rundir polish_options = -p {multithread_jobs} [sgs_option] sgs_fofn = ./sgs.fofn sgs_options = -max_depth 100 In this config file, it given the number of parallel jobs as 20 and multithread jobs as 20, which means the max threads allocated would be 20*20 = 400. So,be sure about that you have that much of threads for calculation or it would make the whole processes slower than normal. Other Long-Reads Assembly Tools LongStitch: Enhancing Genome Assembly with Long Reads LongStitch[1] is a powerful computational tool designed to improve the quality of genome assemblies by utilizing long-read sequencing data. It addresses common issues in genome assembly, such as errors and gaps, that are often introduced during the assembly of short-read sequences. It was published at 2021. Until the July 2024, it got 34 citations. It is an open source software and deposit in GitHub with 42 starts. Key features of LongStitch include: Error Correction: By aligning long reads to the existing genome assembly, LongStitch identifies and corrects misassemblies, leading to a more accurate genomic representation. Scaffolding: LongStitch leverages long reads to link contigs into scaffolds, significantly enhancing the continuity and completeness of the genome assembly. High-Quality Output: The resulting assemblies are more comprehensive and accurate, making them invaluable for further genomic analysis and research. LongStitch’s ability to handle repetitive regions and complex genomic structures makes it an essential tool for researchers aiming to achieve high-quality genome assemblies. pre { background-color:#38393d; color: #5fd381; } Coombe L, Li J X, Lo T, et al. LongStitch: high-quality genome assembly correction and scaffolding using long reads[J]. BMC bioinformatics, 2021, 22: 1-13. ↩︎","link":"/2024/06/26/Bioinfor/NextDenovo/"},{"title":"QIIME2","text":"QIIME2 還沒更新 ## 激活工作环境，需要几十秒source activate qiime2-2017.6## 检查是否安装成功，弹出程序帮助即成功qiime --help## 关闭工作环境：不用时关闭，不然你其它程序可能会出错source deactivate","link":"/2020/07/28/Bioinfor/QIIME2/"},{"title":"VCF processing","text":"More Processing Your SNP file with Python: Packt 2015","link":"/2020/09/05/Bioinfor/SNP_more/"},{"title":"Skill NetWork","text":"Skill NetWork graph TB; START(Bioinformatics) A1(Sequencing) A_A1(High-Throughput) AltS((Alternative Splicing)) WGCNA((WGCNA)) GeneFa((Gene Family)) SNP((SNP)) GO((GO)) KEGG((KEGG)) GSEA((GSEA)) START --> A1 A1 --> A_A1 A_A1 --> DNA-Seq A_A1 --> RNA-Seq A_A1 --> miRNA-Seq A_A1 --> Chip-Seq DNA-Seq --> Genome Genome --> SNP RNA-Seq RNA-Seq --> SNP RNA-Seq --> AltS RNA-Seq --> GeneFa RNA-Seq --> Expression Expression Expression --> WGCNA Expression --> GSEA Expression --> DEGs DEGs DEGs --> KEGG DEGs --> GO WGCNA GO -.-> WGCNA KEGG -.-> WGCNA DNA-Seq DEGs: Differential Expression Genes SNP: Single Nuclear polymorphism","link":"/2020/09/05/Bioinfor/SkillNet/"},{"title":"Understanding PacBio Sequencing: A Deep Dive for RNA-Seq Enthusiasts","text":"Introduction: For the seasoned RNA-Seq explorer, diving into the intricate realms of next-generation sequencing might be routine. But have you paused to marvel at PacBio sequencing, weighing its merits against other sequencing champions? Join us as we unravel PacBio’s mysteries, juxtapose it with its peers, and delve into its data analysis intricacies. What is PacBio Sequencing? © Pacific Biosciences, fondly termed PacBio, is the stalwart behind the long-read sequencing revolution. Standing distinct from short-read sequencers, PacBio devices unfurl considerably elongated reads, paving the path for precise assembly and a simplified data analysis voyage. PacBio vs. Other Sequencing Technologies: Short-Read Sequencing (e.g., Illumina): Advantages: High-throughput capabilities, economical for grand-scale endeavors, and a rich arsenal of tried-and-tested data tools. Disadvantages: The brevity of reads can muddle the assembly of repetitive domains and hinder the detection of structural variants. PacBio (Long-Read Sequencing): Advantages: Its prowess in reading extensive DNA fragments simplifies genome assembly and eases the identification of structural variants. A boon, particularly for genomes riddled with repetitive sequences. Disadvantages: A compromise on throughput in comparison to short-read sequencing and a heftier price tag. Nanopore Sequencing (e.g., Oxford Nanopore Technologies): Advantages: Astoundingly long reads, compact devices, and real-time sequencing insights. Disadvantages: A trade-off in accuracy vis-à-vis PacBio and an evolving, thus unpredictable, tech landscape. PacBio Sequencing Process © Chloé Baum Video Tutorial: - PacBio - RobEdwards; SDSU 1. SMRTbell Template Preparation: DNA is fragmented to the desired length, typically ranging from a few kilobases to over 20 kb. Fragmented DNA is treated to create blunt ends. Hairpin adaptors, called SMRTbell adaptors, are ligated to these blunt ends. This results in the formation of SMRTbell templates which are essentially circular molecules of DNA. 2. Primer Annealing and DNA Polymerase Binding: A sequencing primer is annealed to the SMRTbell template. High-fidelity DNA polymerase is then bound to the primer-annealed SMRTbell template. 3. Loading onto SMRT Cells: The polymerase-bound SMRTbell templates are loaded onto SMRT Cells. A SMRT Cell contains up to millions of zero-mode waveguides (ZMWs). Only a fraction of ZMWs capture a polymerase-bound SMRTbell, ensuring each ZMW contains a single molecule. 4. Zero-Mode Waveguides (ZMWs): ZMWs are nanophotonic structures that allow observation of individual fluorophores attached to nucleotides. They work by confining the observation volume to a zeptoliter level, thereby enabling the detection of single-molecule fluorescence while excluding background fluorescence. 5. Sequencing by Synthesis: The sequencing reaction involves the incorporation of fluorescently labeled nucleotides by the DNA polymerase. Each of the four DNA bases (A, T, C, G) is attached to a distinct fluorescent dye. As the polymerase adds a nucleotide to the growing DNA strand, the attached dye briefly fluoresces. The order in which these dyes fluoresce, as observed in real-time from the bottom of ZMWs, corresponds to the sequence of the template. 6. Continuous Long Reads: Due to the circular nature of the SMRTbell templates, the DNA polymerase can continue to sequence in a rolling-circle manner, producing long continuous reads from the same template. 7. Pulse Detection and Base Calling: The raw output from the sequencing process is a series of fluorescence pulses over time. Sophisticated algorithms analyze these pulses to detect and differentiate the fluorescent signals from each other and from the background noise. These detected pulses are then converted into a sequence of nucleotide bases, resulting in raw sequence reads. 8. Circular Consensus Sequencing (CCS): Since the polymerase can sequence the same SMRTbell template multiple times, it generates several subreads from the same molecule. These subreads are aligned and a consensus sequence is called, enhancing the accuracy of the read by averaging out the random errors. PacBio Data Analysis Pipeline: From raw data collation on PacBio devices to insightful report generation, the pipeline comprises: PacBio Data Analysis Pipeline: A Detailed Overview Raw Data Collection: Process: The sequencing run on a PacBio machine produces raw data files. Output: Files in formats like .h5 or .bam which encapsulate raw sequence reads, quality scores, and other metadata. Read Filtering and Quality Control: Process: Before analysis, raw reads undergo filtering to remove unwanted sequences. Tools: pbccs (Circular Consensus Sequencing) refines raw subreads to generate high-quality consensus sequences. Output: Filtered and high-quality sequence reads ready for further analysis. Genome Assembly (if de novo sequencing): Process: Assembling the filtered reads into contiguous sequences or “contigs”. Tools: Canu: Corrects, trims, and assembles in one go. Flye: Known for speed and scalability. HGAP: PacBio’s native assembler, optimized for their data. Output: Genome assembly in the form of contigs or scaffolds. Mapping (if resequencing): Process: Aligning or “mapping” the reads to a reference genome. Tools: pbmm2: Tailored for PacBio data. minimap2: Versatile and can align both PacBio and Oxford Nanopore data. Output: Alignment file, typically in BAM or SAM format. Variant Calling: Process: Post alignment, identify differences or “variants” between the sequenced data and the reference genome. Tools: DeepVariant: Uses deep learning for interpretation. PBSV: PacBio’s variant caller, adept at detecting larger structural variants. Output: List of variants, typically in VCF format. Annotation and Analysis: Process: Predicting genes, proteins, and other genomic elements in the assembled genome or called variants. Tools: Prokka (for prokaryotes) AUGUSTUS (for eukaryotes) Output: Annotated genome with predicted genes, regulatory elements, and other features. Visualization: Process: Visual representation of the data for easier interpretation. Tools: IGV (Integrative Genomics Viewer) GenomeBrowse Circos Output: Graphical representation of the data, such as genome maps, variant plots, etc. Downstream Analysis: Process: Additional analyses based on the research question. Comparative genomics: Comparing with other genomes. Transcriptomics: Gene expression analysis. Metagenomics: Analyzing community composition in mixed samples. Output: Specific insights or findings related to the research question. Report Generation: Process: Compiling all findings, methodologies, and conclusions into a comprehensive report. Output: Detailed report ready for review, publication, or sharing with stakeholders. This detailed pipeline provides a roadmap for PacBio data analysis, guiding researchers through each stage and ensuring that they obtain meaningful and actionable insights from their data. The different output formats Dimension .h5 Format .bam Format Definition A hierarchical data format designed to store and organize large amounts of data. The binary version of a Sequence Alignment/Map (SAM) format, used to store aligned sequence data. Usage in PacBio Earlier PacBio sequencing runs produced .h5 files as raw output. Used as a standard format for storing aligned PacBio reads. File Size Generally larger due to the comprehensive information it contains about the sequencing run, including raw pulse and signal data. Compressed and therefore more compact than its SAM counterpart. Size depends on the depth of sequencing. Content Contains raw sequence data, quality metrics, and other metadata about the sequencing run. Contains aligned sequence reads, quality scores, and alignment information against a reference genome. Advantages Comprehensive: Contains raw data and additional metadata which can be useful for in-depth analysis. Standardized: Widely accepted in bioinformatics pipelines and tools. Efficient storage with indexed access to alignments. Disadvantages File size can be substantial. Requires specific tools to extract relevant data. Does not contain the raw signal or pulse data, only the resultant sequence and its alignment. Associated Tools PacBio’s SMRT Analysis software can work with .h5 files. Numerous tools available, e.g., SAMtools, Picard, and many bioinformatics pipelines accept .bam files. Interoperability More specific to PacBio’s technology and less commonly used in generic bioinformatics pipelines. Highly interoperable and recognized as a standard format in genomics. Both .h5 and .bam formats have their specific utilities in the realm of PacBio sequencing. While .h5 offers a deeper dive into the raw data and sequencing intricacies, .bam provides a streamlined, standardized format for aligned sequence data, making it more amenable to various bioinformatics analyses. Spotlight on Tools: A Comparative Table Tool Type Advantages Disadvantages Canu Genome Assembler Tailored for high-noise single-molecule sequencing. All-in-one: corrects, trims, and assembles. Resource-intensive; demands hefty computational power. Flye Genome Assembler Efficient for PacBio &amp; Oxford Nanopore. Speedy and scalable. Might struggle with highly repetitive genomes. HGAP Genome Assembler PacBio’s native. Stellar for microbial genomes. Challenges with mammoth genomes. Demands high coverage. pbmm2 Mapping Tool Custom-made for PacBio data. Handles long-read errors well. PacBio-specific; lacks versatility. minimap2 Mapping Tool Swift and versatile. Aligns both PacBio and Oxford Nanopore data. Optimal results might need parameter fine-tuning. DeepVariant Variant Caller Harnesses deep learning for high accuracy. Adapted for long-reads. Computationally taxing. Might be overwhelming for ML novices. PBSV Variant Caller Fine-tuned for PacBio. Excels in detecting large structural variants. Exclusively for PacBio data. Conclusion: While RNA-Seq has its allure, navigating the PacBio seas can offer refreshing insights. With its long-read capabilities, PacBio emerges as a formidable contender in the sequencing arena. As with every tech marvel, it presents both opportunities and challenges. Yet, armed with the right tools and insights, one can sail smoothly through the PacBio waters, discovering genomic treasures along the way. To sequencing and beyond! More to know What is flank sequence In the context of PacBio sequencing, “flanking sequences” or “flanks” often refer to the sequences on either side of a particular region of interest within the DNA. These regions can be particularly important in various analyses such as structural variation detection, insertions, deletions, or when identifying the context of a specific mutation or sequence feature. However, when referring to “flank sequences” in relation to PacBio’s SMRTbell library preparation, it has a more specific meaning. For PacBio SMRT sequencing, the DNA of interest is ligated to hairpin adapters at both ends, creating a SMRTbell template. These hairpin adapters allow the DNA polymerase to read the same molecule multiple times, moving in a circular fashion. The sequences directly adjacent to these adapters on the SMRTbell template are often referred to as the “flanking sequences”. These flanking sequences are typically removed during data processing to retain only the sequence of interest. In the context of the raw PacBio reads, you might sometimes see remnants of these adapter sequences or the flanking regions, especially if there was any inefficiency in the adapter trimming process. If you’re dealing with PacBio data and want to identify or remove such sequences, tools and workflows provided by PacBio, such as the SMRT Link software suite, can help in the adapter trimming and filtering process. pre { background-color:#38393d; color: #5fd381; }","link":"/2023/10/30/Bioinfor/PacBio/"},{"title":"Tophat","text":"Tophat build a index bowtie2-build seaGenome.fna seaGenome.fna ##run tophat2 tophat2 -p 8 -i 20 -I 4000 --min-segment-intron 20 --max-segment-intron 4000 --min-coverage-intron 20 --max-coverage-intron 4000 --coverage-search --microexon-search -G Apostichopus_japonicus.gff --library-type fr-firststrand seaGenome.fna SRR771602.fastq~/Biosoft/cufflinks-2.2.1.Linux_x86_64/cufflinks -p 8 -b ../tophat/erecta.fna -u -o sample1 ../tophat/tophat_out/accepted_hits.bam merge the transcripts.gtf cuffmerge -o merged_asm -p 8 -s ../../tophat/erecta.fna list","link":"/2020/07/28/Bioinfor/Tophat/"},{"title":"TransDecoder","text":"TransDecoder github latest release Install By Bioconda conda install -c bioconda transdecoder Build from Source Downloading the file and make a test (16M) wget -c https://github.com/TransDecoder/TransDecoder/archive/TransDecoder-v5.5.0.tar.gztar -zxvf TransDecoder-v5.5.0.tar.gzcd TransDecoder-TransDecoder-v5.5.0/make test You are supposed to see the code below after execute make test -Fasta_retriever:: begin initializing for supertranscripts.fasta-Fasta_retriever:: done initializing for supertranscripts.fasta+ echo DoneDonemake[2]: Leaving directory '/home/ken/Bio/TransDecoder-TransDecoder-v5.5.0/sample_data/supertranscripts_example'make[1]: Leaving directory '/home/ken/Bio/TransDecoder-TransDecoder-v5.5.0/sample_data' If it comes with any Error during the make test, please see the ‘Debug’ at the end. Now, add the current directory to your $PATH: echo -e &quot;\\n#TransDecoder\\n export PATH=\\$PATH:$(pwd)&quot; &gt;&gt; ~/.bashrcsource ~/.bashrc So, it will add the line below to the end of the ~/.bashrc file. ##TransDecoder export PATH=$PATH:/home/ken/Bio/TransDecoder-TransDecoder-v5.5.0 Now, you can ENJOY the TransDecoder. Running TransDecoder Preparing a fasta file as HitMe.fa Extract the long open reading frames TransDecoder.LongOrfs -t HitMe.fa The result should be the longest_orfs.pep Debug E1; makeblastdb: command not found code ./runMe.sh: line 49: makeblastdb: command not foundmake[2]: *** [Makefile:2: test] Error 127make[2]: Leaving directory '/home/ken/Bio/TransDecoder-TransDecoder-v5.5.0/sample_data/cufflinks_example'make[1]: *** [Makefile:5: test] Error 2make[1]: Leaving directory '/home/ken/Bio/TransDecoder-TransDecoder-v5.5.0/sample_data'make: *** [Makefile:10: test] Error 2 ./runMe.sh: line 49: makeblastdb: command not found Why&amp;How Lake of blast+ sudo apt-get install ncbi-blast+ E2; hmmpress: command not found code ./runMe.sh: line 56: hmmpress: command not foundmake[2]: *** [Makefile:2: test] Error 127make[2]: Leaving directory '/home/ken/Bio/TransDecoder-TransDecoder-v5.5.0/sample_data/cufflinks_example'make[1]: *** [Makefile:5: test] Error 2make[1]: Leaving directory '/home/ken/Bio/TransDecoder-TransDecoder-v5.5.0/sample_data'make: *** [Makefile:10: test] Error 2 Why&amp;How Lake of hammper2 sudo apt-get install hmmer","link":"/2020/07/28/Bioinfor/TransDecoder/"},{"title":"Trimmomatic","text":"Trimmomatic Quick start Paired End: java -jar ~/Biosoft/Trimmomatic-0.38/trimmomatic-0.38.jar PE -threads 8 -phred33 input_forward.fq.gz input_reverse.fq.gz output_forward_paired.fq.gz output_forward_unpaired.fq.gz output_reverse_paired.fq.gz output_reverse_unpaired.fq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36 Single End: java -jar ~/Biosoft/Trimmomatic-0.38/trimmomatic-0.38.jar SE -threads 8 -phred33 SRR771602.fastq 2.fq ILLUMINACLIP:TruSeq3-SE:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36 Args HEADCROP:13 #Dorp 13 head basephred33 设置碱基的质量格式,如果不设置，默认的是-phred64trimlog file就是产生日志，包括如下部分内容：read的名字，留下来的序列的长度，第一个碱基的起始位置，从开始trimmed的长度，最后的一个碱基位于初始read的位置，最后trimmed的数量，其他步骤产生的日志LEADING:3 切除首端碱基质量小于3的碱基或者NTRAILING:3 切除末端碱基质量小于3的碱基或者ILLUMINACLIP: 1.adapter.lis:2:30:10 1.adapter.list为adapter文件，允许的最大mismatch 数，palindrome模式下匹配碱基数阈值：simple模式下的匹配碱基数阈值SLIDINGWINDOW:4:15 Windows的size是4个碱基，其平均碱基质量小于15，则切除MINLEN:36 最低reads长度为36CROP: 保留的reads长度HEADCROP: 在reads的首端切除指定的长度","link":"/2020/07/28/Bioinfor/Trimmomatic/"},{"title":"UNIPROT_API","text":"UNIPROT_API for more information, please visit: uniprot expample library(httr)isJobReady &lt;- function(jobId) { pollingInterval = 5 nTries = 20 for (i in 1:nTries) { url &lt;- paste(&quot;https://rest.uniprot.org/idmapping/status/&quot;, jobId, sep = &quot;&quot;) r &lt;- GET(url = url, accept_json()) status &lt;- content(r, as = &quot;parsed&quot;) if (!is.null(status[[&quot;results&quot;]]) || !is.null(status[[&quot;failedIds&quot;]])) { return(TRUE) } if (!is.null(status[[&quot;messages&quot;]])) { print(status[[&quot;messages&quot;]]) return (FALSE) } Sys.sleep(pollingInterval) } return(FALSE)}getResultsURL &lt;- function(redirectURL) { if (grepl(&quot;/idmapping/results/&quot;, redirectURL, fixed = TRUE)) { url &lt;- gsub(&quot;/idmapping/results/&quot;, &quot;/idmapping/stream/&quot;, redirectURL) } else { url &lt;- gsub(&quot;/results/&quot;, &quot;/results/stream/&quot;, redirectURL) }}files = list( ids = &quot;P21802,P12345&quot;, from = &quot;UniProtKB_AC-ID&quot;, to = &quot;UniRef90&quot;)r &lt;- POST(url = &quot;https://rest.uniprot.org/idmapping/run&quot;, body = files, encode = &quot;multipart&quot;, accept_json())submission &lt;- content(r, as = &quot;parsed&quot;)if (isJobReady(submission[[&quot;jobId&quot;]])) { url &lt;- paste(&quot;https://rest.uniprot.org/idmapping/details/&quot;, submission[[&quot;jobId&quot;]], sep = &quot;&quot;) r &lt;- GET(url = url, accept_json()) details &lt;- content(r, as = &quot;parsed&quot;) url &lt;- getResultsURL(details[[&quot;redirectURL&quot;]]) # Using TSV format see: https://www.uniprot.org/help/api_queries#what-formats-are-available url &lt;- paste(url, &quot;?format=tsv&quot;, sep = &quot;&quot;) r &lt;- GET(url = url, accept_json()) resultsTable = read.table(text = content(r), sep = &quot;\\t&quot;, header=TRUE) print(resultsTable)} From Cluster.ID Cluster.Name Common.taxon Size Date.of.creation 1 P21802 UniRef90_P21802 Cluster: Fibroblast growth factor receptor 2 Amniota 110 2022-04-27 2 P12345 UniRef90_P00507 Cluster: Aspartate aminotransferase, mitochondrial Mammalia 199 2022-04-27 Python for All infor import requestsResult = requests.post(url=&quot;https://rest.uniprot.org/uniprotkb/A6NNB3&quot;, data= {&quot;Accept&quot;:&quot;application/json&quot;})print(Result.json()) import requestsimport pandas as pddef Domain_anno(ID, POS): Result = requests.post(url=&quot;https://rest.uniprot.org/uniprotkb/&quot; + ID, data= {&quot;Accept&quot;:&quot;application/json&quot;}) Features = Result.json()['features'] TB = pd.DataFrame() for Loc in POS: for Chat in Features: try: if Loc &gt;= Chat['location']['start']['value'] and Loc &lt;= Chat['location']['end']['value']: print(Chat['type']) TMP= pd.DataFrame([[Chat['type'], Loc, Chat['description']]], columns=[&quot;Type&quot;, &quot;Loc&quot;, &quot;Discrip&quot;]) TB = pd.concat([TB, TMP]) except: print(Chat) return TB","link":"/2020/06/03/Bioinfor/UNIPROT_API/"},{"title":"Trinity","text":"Trinity Install Prerequisite sudo apt install cmakesudo apt-get install autoconf Rlease page If you come with the error below as making, try the full package. (See resolution at GitHub issue) Using gnu compiler for Inchworm and Chrysalis cd Inchworm && make make[1]: Entering directory '/home/ken/Bio/trinityrnaseq/Inchworm' make[1]: *** No targets specified and no makefile found. Stop. make[1]: Leaving directory '/home/ken/Bio/trinityrnaseq/Inchworm' make: *** [Makefile:32: inchworm_target] Error 2 cd trinityrnaseq*makemake test_all conda install conda install trinityconda install samtools bowtie bowtie2 bowtie rsem Troubleshoot jellyfish Error, cannot find jellyfish installed on this system. Be sure to install it. You can get it here: http://www.genome.umd.edu/jellyfish.html at /home/ken/Bio/trinityrnaseq-v2.11.0/Trinity line 3935. sudo apt install jellyfish Salmon Trinity Trinity-v2.11.0 requires salmon to be installed. Get it here: https://combine-lab.github.io/salmon/ at /home/ken/Bio/trinityrnaseq-v2.11.0/Trinity line 3973. sudo apt install salmon Quick start ~/Biosoft/trinityrnaseq-Trinity-v2.5.1/Trinity --seqType fq --max_memory 50G --single(--samples_file) --CPU 8 --full_cleanup~/Biosoft/trinityrnaseq-Trinity-v2.5.1/Analysis/DifferentialExpression/run_DE_analysis.pl --matrix MA-all-t0.01.matrix --method edgeR --samples sample Downstream Analysis Prerequisites BiocManager::install('edgeR')BiocManager::install('limma')BiocManager::install(&quot;qvalue&quot;)BiocManager::install('DESeq2')BiocManager::install('ctc')BiocManager::install(&quot;Biobase&quot;)install.packages('gplots')install.packages('ape')install.packages(&quot;fastcluster&quot;) Non-repeats Experiment (edgeR) ~/Biosoft/trinityrnaseq-Trinity-v2.8.4/Analysis/DifferentialExpression/run_DE_analysis.pl --matrix Intest.table --method edgeR --dispersion 0.1 Beware that It can recognize tab-separated matrix only. if your count or expression matrix was coma-separated, your can run sed -i s/,/\\t/g ${your matrix file} to change the separates. After waiting, you are supposed have an edger{*}.dir directory and all DEGs among each groups are stored in it. Volcano Plot and Heatmap After you finished with run_DE_analysis.pl process, cd edger{*}.dir and run codes below with your own args. ~/Biosoft/trinityrnaseq-Trinity-v2.8.4/Analysis/DifferentialExpression/analyze_diff_expr.pl --matrix ../Trinity_trans.TMM.EXPR.matrix -P 1e-3 -C 2 Sample file ## --samples_file tab-delimited text file indicating biological replicate relationships. ## ex. ## cond_A cond_A_rep1 A_rep1_left.fq A_rep1_right.fq ## cond_A cond_A_rep2 A_rep2_left.fq A_rep2_right.fq ## cond_B cond_B_rep1 B_rep1_left.fq B_rep1_right.fq ## cond_B cond_B_rep2 B_rep2_left.fq B_rep2_right.fq Group file If you have the sample file, you can use the sample file as the group file since the first two columns are the same # --samples tab-delimited text file indicating biological replicate relationships. # ex. # cond_A cond_A_rep1 # cond_A cond_A_rep2 # cond_B cond_B_rep1 # cond_B cond_B_rep2 Tricks If you don’t like the color of heatmap, you can can change the below lines in file: $TrinityFile/Analysis/DifferentialExpression/R/heatmap.3.R Errors My environment: ██████████████████ ████████ ken@manjaro ██████████████████ ████████ OS: Manjaro 21.0.7 Ornara ██████████████████ ████████ Kernel: x86_64 Linux 5.4.124-1-MANJARO ██████████████████ ████████ Uptime: 5m ████████ ████████ Packages: 1678 ████████ ████████ ████████ Shell: zsh 5.8 ████████ ████████ ████████ Resolution: 1920x1080 ████████ ████████ ████████ DE: GNOME 3.38.5 ████████ ████████ ████████ WM: Mutter ████████ ████████ ████████ WM Theme: Matcha-dark-sea ████████ ████████ ████████ GTK Theme: Matcha-sea [GTK2/3] ████████ ████████ ████████ Icon Theme: Papirus-Dark-Maia ████████ ████████ ████████ Font: Noto Sans 11 ████████ ████████ ████████ Disk: 769G / 1.5T (54%) CPU: Intel Xeon E3-1535M v6 @ 8x 4.2GHz [51.0°C] GPU: NVIDIA Quadro M2200 RAM: 3208MiB / 64042MiB Trinity version: trinityrnaseq-v2.12.0 Error code: htslib configure: error: cannot find required auxiliary files: config.guess config.submake[2]: *** [Makefile:10: htslib/version.h] Error 1make[2]: Leaving directory '/home/ken/Bio/trinityrnaseq-v2.12.0/trinity-plugins/bamsifter'make[1]: *** [Makefile:32: bamsifter_target] Error 2make[1]: Leaving directory '/home/ken/Bio/trinityrnaseq-v2.12.0/trinity-plugins'make: *** [Makefile:39: trinity_essentials] Error 2 configure: error: cannot find required auxiliary files: config.guess config.sub This problem comes the version of autoconf (see GitHub Issue) We can solve this by downgrade the version of autoconf. 2.69 works to me. Install the autoconf: andyguan01_2 2019 sudo pacman -R autoconfwget ftp://ftp.gnu.org/gnu/autoconf/autoconf-2.69.tar.gztar zxvf autoconf-2.69.tar.gzcd autoconf-2.69./configure --prefix=/usr/make &amp;&amp; make install","link":"/2020/07/28/Bioinfor/Trinity/"},{"title":"WGCNA","text":"WGCNA Lecture by Steven Horvath 2013, UCLA Though, it was designed for microarray data, but it applied in DNA methylation data, RNA-seq, miRNA-seq, Peptide Count data… NetWork: the value between notes is either 0 or 1 weighted network: the value is variable between notes (Connection is weighted). Unsigned Network and Signed Network Unsigned network: The value is from -1 to 1. (Both -1 and 1 means adjacent is 0, strongly correlated) Both high value and low (nagetive) value are correlated because of adjacent. Singed network: The correlation value is form 0-1. From unsigned correlation to singed network, Q&amp;A Reference: Peter 2017 Data Analysis Questions How many samples do I need? At least for 15 samples. More samples could robust and refined results. Noises may can’t be removed if you have less samples. Should I filter probesets or genes? Filtering genes by DEGs is not recommended since it completely invalidates the scale-free topology assumption, which is the indicator of the soft thresholding power. On the other hand, filtering gene by DE will lead to a set of correlated genes that will essentially form a single (or few high correlated) module respectively. What argument (option) settings are recommended? In general, we attempt to select suitable default which feat multiple applications and also, it is high reproducible. While for new calculations, you can customize argument. Signed Network The choice of Signed or Unsigned network is complicate, but generally, we prefer the Signed network. To construct Signed Networks, we usring: type = &quot;signed&quot; or type = &quot;signed hybrid&quot; in function such as accuracyMeasures, adjacency, chooseOneHubInEachModule, chooseTopHubInEachModule, nearestNeighborConnectivity, nearestNeighborConnectivityMS, orderBranchesUsingHubGenes, softConnectivity. Some functions useing networkType to select the signed. Robust correlation Generaly, we recommend to using default arguments to detect the correlation unless you have enough reason to believe there is no outlier measurment. You can using corFnc, cor, et al. to customizing your own detective. For more, please go to Tutorial Can WGCNA be used to analyze RNA-Seq data? Peter： Yes. As far as WGCNA is concerned, working with (properly normalized) RNA-seq data isn’t really any different from working with (properly normalized) microarray data. Suggestion: Removing low hits transcripts. Low counting transcripts tend to reflect noise. (for example, removing all features that have a count of less than say 10 in more than 90% of the samples) Normalization varianceStabilizingTransformation from DESeq2 is really useful. RPKM and FPKM is helpful, too. We can also using log2(x+1). Notions: Different algorithms have huge impact on the result of expression change, but have limit affect on WGCNA. Id data comes from different batch, We can use ComBat (Exp: 木头的博客) for batch effect removal. Finally, we usually check quantile scatterplots to make sure there are no systematic shifts between samples; if sample quantiles show correlations (which they usually do), quantile normalization can be used to remove this effect. Data heterogeneous Data heterogeneous can effect any statistical analysis. (Skip) Soft-thresholding power can’t get a good scale-free topology index no matter how high I set the soft-thresholding power. First, the user should ensure that variables (probesets, genes etc.) have not been filtered by differential expression with respect to a sample trait. Probability: Checking the clustering tree (exp); strong clusters in the tree indicates globally different groups of sample. It may caused by batch effects or heterogenous. Carefully adjust the samples before building topology index. If the one causing heterogenous you don’t remove, you can still chosen the soft thresholding power by the number of samples at table below. Number of samples Unsigned and signed hybrid networks Signed networks Less than 20 9 18 20-30 8 16 30-40 7 14 more than 40 6 12","link":"/2020/07/28/Bioinfor/WGCNA/"},{"title":"RNA-seq with Trinity","text":"RNA-seq with Trinity Downloading RNA-Seq sequences For this practicing, I found a group of mouse RNA-Seq which have replicates and the size of SRA is easy handle for your PC. SRR14962733 to SRR149627346 prefetch SRR14962733prefetch SRR14962734prefetch SRR14962735prefetch SRR14962736# orfor i in {3..6}; do prefetch SRR1496273$i;done download with ascp ##### Downloading the RNA-seqprefetch --ascp-path &quot;/usr/bin/ascp|/home/ken/.aspera/connect/etc/asperaweb_id_dsa.putty&quot; ERR025599 Seq Clean Turn sra to fastq ## move the result from default directory to localmv ~/ncbi/public/sra .##### Split SSR to fastqfastq-dump --defline-seq '@$sn[_$rn]/$ri' --split-files sra/*mkdir fastqmv *fastq fastq Quality control SRA download from NCBI doesn’t included the ASCII grades of the reads now. So, we can’t doing this for free-download reads. I’ll skip this step. ##### cut the low quality reads##basic command##fastp -u 15 -w 8 -i SRR7760055_1.fastq -o cut_SRR7760055_1.fastqfor i in $(ls *.fastq);do fastp -u 15 -w 8 -i $i -o cut_$i; mv fastp.html $i.html;done##### Trimmomatic cut the lower grade head or tail jodged by the quality reportjava -jar trimmomatic-0.38.jar SE -threads 8 -phred33 SRR771602.fastq 2.fq ILLUMINACLIP:TruSeq3-SE:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36 HEADCROP:10 CROP:87for i in $(ls cut_SRR77600*);do java -jar trimmomatic-0.38.jar SE -threads 8 -phred33 $i 2_$i ILLUMINACLIP:TruSeq3-SE:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36 HEADCROP:10 CROP:87done De-novo We recommend generating a single Trinity assembly based on combining all reads across all samples as inputs. cite: Tirnity wiki Now, waiting… # merge all readscat fastq/* &gt; all.fastq##TrnityTime1=$(date)Trinity --seqType fq --max_memory 55G --single all.fastq --CPU 8 --full_cleanupTime2=$(date) It takes me 81 min. errors Error, do not understand options: fastq/SRR14962734_1.fastq Result I made a mistake. With the codes above, I got only three sequences. So, I suspect that mabey this is not RNA-Seq but miRNA-seq. I looked back to the NCBI and checking carefully this time. Guess what? This is a miRNA-Seq! = = You can find the information in: Library: Name: … Strategy: miRNA-Seq Now, let’s repeat the codes above with another groups: SRR14962739-SRR14962742 # orfor i in {39..42}; do prefetch SRR149627$i;done check the time consuming: du all.fastqecho $Time1echo $Time2 14G all.fastq Sun Jul 4 06:20:58 PM CST 2021 Mon Jul 5 02:36:32 AM CST 2021 about 8 hours Statistical information of the result Trinity supplied a perl script to calculating and evaluating the result: TrinityStats.pl It has two group of results: Stats based on ALL transcript contigs: Stats based on ONLY LONGEST ISOFORM per ‘GENE’: {$path}/trinityrnaseq-v2.12.0/util/TrinityStats.pl trinity_out_dir.Trinity.fasta ################################ ## Counts of transcripts, etc. ################################ Total trinity 'genes': 41400 Total trinity transcripts: 42451 Percent GC: 49.50 ######################################## Stats based on ALL transcript contigs: ######################################## Contig N10: 6068 Contig N20: 4371 Contig N30: 3377 Contig N40: 2687 Contig N50: 2100 Median contig length: 426 Average contig: 991.80 Total assembled bases: 42102797 ##################################################### ## Stats based on ONLY LONGEST ISOFORM per 'GENE': ##################################################### Contig N10: 5781 Contig N20: 4155 Contig N30: 3202 Contig N40: 2543 Contig N50: 1982 Median contig length: 415 Average contig: 948.27 Total assembled bases: 39258319 Downstream Analysis We are processing the downstream analysis based on the scripts trinity supplied. Most of them are in the ${Trinity directory}/util/ TrinityStats.pl abundance_estimates_to_matrix.pl align_and_estimate_abundance.pl analyze_blastPlus_topHit_coverage.pl filter_low_expr_transcripts.pl insilico_read_normalization.pl retrieve_sequences_from_fasta.pl sift_bam_max_cov.pl TrinityStats.pl is for calculating the value of N50 Align and Abundance Estimate The script, align_and_estimate_abundance.pl, was used here to estimate the abundances of each transcripts from your transcriptome library. More details about this scripts is in trinity wiki Because we have replicates, we need a file to interpreted the groups. (group.csv) miR-31 miR-31_rep1 fastq/SRR14962739_1.fastq miR-31 miR-31_rep2 fastq/SRR14962740_1.fastq Scr-2 Scr-2_rep1 fastq/SRR14962741_1.fastq Scr-2 Scr-2_rep2 fastq/SRR14962742_1.fastq ~/Bio/trinityrnaseq-v2.12.0/util/align_and_estimate_abundance.pl --transcripts trinity_out_dir.Trinity.fasta --seqType fq --samples_file group.csv --est_method RSEM --aln_method bowtie --trinity_mode --prep_reference --output_dir rsem_outdir It could build index, pair the reads and counting the matched reads automatically. It using the file automatically generated by Trinity assembly to distinguish the gene and isoform. An example of trinity_{sample}.Trinity.fasta.gene_trans_map looks like below. Two columns are seperated by Tab which the first column is Gene ID and the second column is isoform ID. TRINITY_DN9652_c0_g1 TRINITY_DN9652_c0_g1_i2 TRINITY_DN9653_c0_g1 TRINITY_DN9653_c0_g1_i1 TRINITY_DN9630_c0_g1 TRINITY_DN9630_c0_g1_i1 TRINITY_DN9699_c0_g1 TRINITY_DN9699_c0_g1_i1 TRINITY_DN9681_c0_g1 TRINITY_DN9681_c0_g1_i1 TRINITY_DN9660_c0_g1 TRINITY_DN9660_c0_g1_i1 Not Trinity assembled results if you don't have this file, you can using parameters --gene_trans_map. The difference between this to parameters are explained in --help # --gene_trans_map file containing 'gene(tab)transcript' identifiers per line. # or # --trinity_mode Setting --trinity_mode will automatically generate the gene_trans_map and use it. After down, you’ll got a bunch of result. The abaundance file was in the directories miR-31_rep1, miR-31_rep2, Scr-2_rep1, Scr-2_rep2 as the statistic scripts, the result was divided into two groups, gene and isoforms: RSEM.genes.results RSEM.isoforms.results. This is where the count, TPM, and FPKM were generated and stored (If you are using RSEM). FPKM: fragments per kilobase transcript length per million fragments mapped TPM: transcripts per million transcripts # Check the results.head miR-31_rep1/RSEM.isoforms.results transcript_id gene_id length effective_length expected_count TPM FPKM IsoPct TRINITY_DN10000_c0_g1_i1 TRINITY_DN10000_c0_g1 3506 3457.00 489.00 10.97 6.58 100.00 TRINITY_DN10001_c0_g1_i1 TRINITY_DN10001_c0_g1 441 392.00 15.00 2.97 1.78 100.00 TRINITY_DN10002_c0_g1_i1 TRINITY_DN10002_c0_g1 5392 5343.00 2609.00 37.85 22.73 100.00 TRINITY_DN10003_c0_g1_i1 TRINITY_DN10003_c0_g1 1419 1370.00 1995.00 112.89 67.78 100.00 TRINITY_DN10004_c0_g1_i1 TRINITY_DN10004_c0_g1 3829 3780.00 1715.00 35.17 21.12 100.00 TRINITY_DN10005_c0_g1_i1 TRINITY_DN10005_c0_g1 2379 2330.00 1755.00 58.39 35.06 100.00 How it works with bowtie2 and RSEM By checking the log of Trinity, the codes from bowtie2 to RSEM could be: bowtie2 --no-mixed --no-discordant --gbar 1000 --end-to-end -k 200 &lt;br&gt;-q -x DB/dmel-all-transcript-r6.39.fasta.bowtie2 &lt;br&gt;-U Merged_FQ/CF-1_S1.S.fq.gz -p 64 | samtools view -@ 64 -F 4 -S -b |&lt;br&gt;samtools sort -@ 64 -n -o bowtie2.bamtouch bowtie2.bam.okconvert-sam-for-rsem bowtie2.bam bowtie2.bam.for_rsem## Just can't understand what happened heresamtools sort -n -@ 1 -m 1G -o bowtie2.bam.for_rsem.tmp.bam bowtie2.bamrsem-scan-for-paired-end-reads 1 bowtie2.bam.for_rsem.tmp.bam bowtie2.bam.for_rsem.bamrsem-sam-validator bowtie2.bam.for_rsem.bamrsem-parse-alignments /lustre/project/wdeng7/wliu15/kraken_RNA/DB/dmel-all-miRNA-r6.39.fasta.RSEM RSEM.temp/RSEM RSEM.stat/RSEM bowtie2.bam.for_rsem.bam 1 -tag XMrsem-build-read-index 32 1 0 RSEM.temp/RSEM_alignable.fqrsem-run-em /lustre/project/wdeng7/wliu15/kraken_RNA/DB/dmel-all-miRNA-r6.39.fasta.RSEM 1 RSEM RSEM.temp/RSEM RSEM.stat/RSEM -p 64rm -rf RSEM.temprsem-calculate-expression -p 64 --fragment-length-mean 200 &lt;br&gt;--fragment-length-sd 80 --no-bam-output --bam bowtie2.bam.for_rsem.bam DB/dmel-all-transcript-r6.39.fasta.RSEM RSEMtouch RSEM.isoforms.results.ok 0. prepare: build bowtie2 and RSEM index if there are not. Bowtie2 align reads from -U into indexed reference from -x and bowtie2.bam was created. After that, bowtie2.bam.ok was touched to mark this process is done bam was converted into bowtie2.bam.for_rsem.bam and started counting by using RSEM index Expression matrix Of course that trinity supplied a script, abundance_estimates_to_matrix.pl, do it for you as well. ~/Bio/trinityrnaseq-v2.12.0/util/abundance_estimates_to_matrix.pl --est_method RSEM \\ --gene_trans_map trinity_out_dir.Trinity.fasta.gene_trans_map \\ --out_prefix RSEM \\ --name_sample_by_basedir \\ Scr-2_rep1/RSEM.isoforms.results \\ Scr-2_rep2/RSEM.isoforms.results \\ miR-31_rep1/RSEM.isoforms.results \\ miR-31_rep2/RSEM.isoforms.results # my results of prefix is RSEMls RSEM* RSEM.gene.TMM.EXPR.matrix RSEM.gene.counts.matrix RSEM.isoform.TPM.not_cross_norm.runTMM.R RSEM.gene.TPM.not_cross_norm RSEM.isoform.TMM.EXPR.matrix RSEM.isoform.counts.matrix RSEM.gene.TPM.not_cross_norm.TMM_info.txt RSEM.isoform.TPM.not_cross_norm RSEM.gene.TPM.not_cross_norm.runTMM.R RSEM.isoform.TPM.not_cross_norm.TMM_info.txt Now, all the matrix were extracted from separated results of samples. move them into a new directory mkdir RSEM_resultmv RSEM* RSEM_result Errors libreadline /home/ken/miniconda3/envs/Biostation/lib/R/bin/exec/R: error while loading shared libraries: libreadline.so.6: cannot open shared object file: No such file or directory chech the libreadlines: ls /lib/libreadline.* /lib/libreadline.so /lib/libreadline.so.8 /lib/libreadline.so.8.1 The problem is this script is relying on an very old version. So, you can heck on the script, or cheat it. This is how I fool the script: sudo ln -s /lib/libreadline.so.8 /lib/libreadline.so.6 libncurses /home/ken/miniconda3/envs/Biostation/lib/R/bin/exec/R: error while loading shared libraries: libncurses.so.5: cannot open shared object file: No such file or directory The same as error 1 sudo ln -s /lib/libncursesw.so.6 /lib/libncurses.so.5 Low-Expression Reads Filter The results of the matrix are huge. we got 42451 pieces of isforms but lot’s of them are low expression gene we want to remove. You can achive this by using R. Trinity supplied the related scripts to handle with this, too. This is the function in R to down the same thing as the scripts from Trinity A &lt;- read.table(&quot;RSEM.isoform.TPM.not_cross_norm&quot;)Filter &lt;- function(A, Th){ tmp = A for(i in c(1:ncol(A))){ tmp = tmp[which(tmp[,i] &lt; Th),] } return(tmp)} In trinity, perl scripts, util/misc/count_matrix_features_given_MIN_TPM_threshold.pl, is aiming to that the genes/isoforms expressed above a minimum TPM expression threshold in any sample. ~/Bio/trinityrnaseq-v2.12.0/util/misc/count_matrix_features_given_MIN_TPM_threshold.pl \\ RSEM.isoform.TPM.not_cross_norm neg_min_tpm num_features -6771 1 -6758 2 -6185 3 -6092 4 . . . -4 36909 -3 41004 -2 42353 -1 42440 0 42451 In this result, -1 42440 means that 42440 isoforms’s TPM is larger than 1 in all samples. You can get the same result with the function in R above. (Filter(A, 1)) Ploting the result # write the result into a file~/Bio/trinityrnaseq-v2.12.0/util/misc/count_matrix_features_given_MIN_TPM_threshold.pl RSEM.isoform.TPM.not_cross_norm| tee isoform_matrix.TPM.not_cross_norm.counts_by_min_TPM Plot the result with R data = read.table(&quot;isoform_matrix.TPM.not_cross_norm.counts_by_min_TPM&quot;, header=T)plot(data, xlim=c(-100,0), ylim=c(0,100000), t='b') Filtering By the function above, you can easily filtering the matrix from the row matrix. Trinity also supplied a pl script to extracting the transcripts from your transcriptome (you fasta file) to build a new library. ~/Bio/trinityrnaseq-v2.12.0/util/filter_low_expr_transcripts.pl \\ --matrix RSEM.isoform.TPM.not_cross_norm \\ --transcripts ../trinity_out_dir.Trinity.fasta \\ --min_expr_any 5 Expression matrix QC Checking the replicates relied R packages: fastcluster, ~/Bio/trinityrnaseq-v2.12.0/Analysis/DifferentialExpression/PtR \\ --matrix RSEM_result/RSEM.isoform.counts.matrix \\ --samples group.csv --log2 --CPM \\ --min_rowSums 10 \\ --compare_replicates Processing replicate QC analysis for sample: miR-31 for plotting:: min.raw: 0.994299466204194 max.raw: 1 Processing replicate QC analysis for sample: Scr-2 for plotting:: min.raw: 0.993762297454055 max.raw: 1 You’ll get the PDF result like it’s show in Trnity wiki Checking all groups ~/Bio/trinityrnaseq-v2.12.0/Analysis/DifferentialExpression/PtR \\ --matrix RSEM_result/RSEM.isoform.counts.matrix \\ --samples group.csv --log2 --CPM \\ --min_rowSums 10 \\ --sample_cor_matrix PCA Analysis ~/Bio/trinityrnaseq-v2.12.0/Analysis/DifferentialExpression/PtR \\ --matrix RSEM_result/RSEM.isoform.counts.matrix \\ --samples group.csv --min_rowSums 10 --log2 \\ --CPM --center_rows \\ --prin_comp 3 Differential Expression Matrix Here we are supposed to using counts file for calculating. ~/Bio/trinityrnaseq-v2.12.0/Analysis/DifferentialExpression/run_DE_analysis.pl \\ --matrix RSEM_result/RSEM.gene.counts.matrix \\ --method voom \\ --samples_file group.csv a voom.******.dir directory was generated by default. You can also using edgeR/DESeq2 instead of voom Extracting and clustering differentially expressed transcripts Now, enter the directory generated above and run codes below ~/Bio/trinityrnaseq-v2.12.0/Analysis/DifferentialExpression/analyze_diff_expr.pl\\ --matrix ../RSEM_result/RSEM.gene.TMM.EXPR.matrix -P 1e-3 -C 2 Now, you can have the ugly heatmap ^_^ I tried those three different algorithms and get different results. Packages Number of DEGs edgeR 149 DESeq2 167 Voom 18 . ├── DB │ └── dmel-all-miRNA-r6.39.fasta ├── Merged_FQ │ └── CF-1_S1.S.fq.gz └── Trinity.map # Prepare bowtie2 referenncebowtie2-build --wrapper basic-0 DB/dmel-all-miRNA-r6.39.fasta DB/dmel-all-miRNA-r6.39.fasta.bowtie2# Prepare the RSEM reference# Here you can also using gtf by --gtf instead of --transcript-to-gene-maprsem-prepare-reference --transcript-to-gene-map Trinity.map DB/dmel-all-miRNA-r6.39.fasta DB/dmel-all-miRNA-r6.39.fasta.RSEM#rsem-synthesis-reference-transcripts DB/dmel-all-miRNA-r6.39.fasta.RSEM 0 1 Trinity.map DB/dmel-all-miRNA-r6.39.fasta## prepaire an working directorymkdir CF-1_S1_miRNA; cd CF-1_S1_miRNA# bowtie align first. After that, bowtie2.bam was generatedbowtie2 --no-mixed --no-discordant --gbar 1000 --end-to-end -k 200 -q -x ../DB/dmel-all-miRNA-r6.39.fasta.bowtie2 -U ../Merged_FQ/CF-1_S1.S.fq.gz -p 64 | samtools view -@ 64 -F 4 -S -b | samtools sort -@ 64 -n -o bowtie2.bam# touch this file to indicate bowtie2 process is donetouch bowtie2.bam.ok# convert = = I don't know why we need this stepconvert-sam-for-rsem bowtie2.bam bowtie2.bam.for_rsem# why they do it agian????# it seams like it can only do paired reads. So, it create another set when the reads are single endsamtools sort -n -@ 1 -m 1G -o bowtie2.bam.for_rsem.tmp.bam bowtie2.bamrsem-scan-for-paired-end-reads 1 bowtie2.bam.for_rsem.tmp.bam bowtie2.bam.for_rsem.bam#Conversion is completed. bowtie2.bam.for_rsem.bam will be checked by 'rsem-sam-validator'.rsem-sam-validator bowtie2.bam.for_rsem.bamrsem-parse-alignments ../DB/dmel-all-miRNA-r6.39.fasta.RSEM RSEM.temp/RSEM RSEM.stat/RSEM bowtie2.bam.for_rsem.bam 1 -tag XMrsem-build-read-index 32 1 0 RSEM.temp/RSEM_alignable.fqrsem-run-em ../DB/dmel-all-miRNA-r6.39.fasta.RSEM 1 RSEM RSEM.temp/RSEM RSEM.stat/RSEM -p 64rsem-calculate-expression -p 64 --fragment-length-mean 200 --fragment-length-sd 80 --no-bam-output --bam bowtie2.bam.for_rsem.bam ../DB/dmel-all-miRNA-r6.39.fasta.RSEM RSEM . └── CF-1_S1_miRNA ├── bowtie2.bam ├── bowtie2.bam.for_rsem.bam ├── bowtie2.bam.for_rsem.tmp.bam ├── bowtie2.bam.ok ├── RSEM.genes.results ├── RSEM.isoforms.results └── RSEM.stat Now, you can have the result from RSEM.genes.results, or isoform infromation from RSEM.isoforms.results. RSEM errors cmd: rsem-prepare-referencersem-prepare-reference --transcript-to-gene-map Trinity.map DB/Updated_Drosophila_Viruses.fasta DB/Updated_Drosophila_Viruses.fasta.RSEM rsem-synthesis-reference-transcripts DB/Updated_Drosophila_Viruses.fasta.RSEM 0 1 Trinity.map DB/Updated_Drosophila_Viruses.fasta FASTA file DB/Updated_Drosophila_Viruses.fasta contains an unknown character, ~ (ASCII code 126), at line 24057, position 43! \"rsem-synthesis-reference-transcripts DB/Updated_Drosophila_Viruses.fasta.RSEM 0 1 Trinity.map DB/Updated_Drosophila_Viruses.fasta\" failed! Plase check if you provide correct parameters/options for the pipeline! The error code is contains an unknown character, ~ (ASCII code 126), at line 24057, position 43! in the second line. By following this codes and check the line 24057, we can find &quot;~&quot; in the sequence. AGCGCATTGGAGCGGGATTCCGGATCTTACTTCGATGTGGCT~CCCCTCACTC~GCATTG After cleaned all &quot;~&quot; by using sed, the code passed. Another Example in Slurm Server # load modulemodule load trinity/2.8.5module load bwa bowtie2/2.3.3 rsem/1.2.31 samtools/1.5# Prepar the group listfor SAMPLE in $(ls ../../RNA_RAW/*/*/*fastq.gz |awk -F &quot;/&quot; '{print $NF}'| sed 's/_L00[12]_R[12]_001.fastq.gz//'| sort |uniq); do echo $SAMPLEdonels ../../RNA_RAW/*/*/*fastq.gz &gt; group.csv pre { background-color:#38393d; color: #5fd381; } digraph{ rankdir = \"LR\" subgraph A{ rank = same node [shape = box, color = \"orange\", style = \"filled\"] DS [label = \"Seq Downloading\", URL = \"#Downloading-RNA-Seq-sequences\", fontcolor=blue] Split [lable = \"SSR split\"] QC [label = \"Quality control &\\nFilter\", shape = diamond, URL = \"#Seq-Clean\", fontcolor=blue] DN [label = \"de-novo\", URL = \"#De-novo\", fontcolor=blue] Trans [label = \"transcriptome\", URL=\"#Result\", fontcolor=blue] N50 [label = \"Statistical\\ninformation (N50)\", URL= \"#Statistical-information-of-the-result\", fontcolor=blue] DSA [label = \"Downstream Analysis\", URL=\"#Downstream-Analysis\", fontcolor=blue] Quantification [URL = \"#Align-and-Abundance-Estimate\", fontcolor=blue ] EM [label = \"Expression Matrix\", URL = \"#Expression-matrix\", fontcolor=blue] DS -> Split -> QC ->DN -> Trans -> N50 -> DSA -> Quantification -> EM } subgraph B { rank = same node [shape = \"box\", color = \"skyblue\", style = \"filled\"] PF [label = \"prefetch\\n(sra-tools)\"] FD [label = \"fastq-dump\\n(sra-tools)\"] FQC [label = \"fastp\\nfastQC\"] TR [label = \"Trinity\"] Trim[label = \"trimmomatic\"] } subgraph C{ edge [style = \"dotted\"] PF -> DS FD -> Split FQC -> QC TR -> DN {rank=same; Trim -> \"Adapter remove\"} } QC -> \"Adapter remove\" -> DN } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });","link":"/2020/07/28/Bioinfor/RNA-seq-with-Trinity/"},{"title":"RNA-Seq, Annotation and Enrichment","text":"Swiss-Prot Annotation prerequisite Prepare Softwares downloads latest blast+ wget -c https://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/ncbi-blast-2.12.0+-x64-linux.tar.gztar -zxvf ncbi-blast-2.12.0+-x64-linux.tar.gzcd ncbi-blast-2.12.0+/bin Prepare Database Download the latest version from Uniport for example, we’d like to download the reviewed database: wget -c https://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.fasta.gzgzip -d uniprot_sprot.fasta.gzdu -h uniprot_sprot.fasta 268M uniprot_sprot.fasta ~/Bio/blast/ncbi-blast-2.12.0+/bin/makeblastdb -in uniprot_sprot.fasta -dbtype prot -parse_seqids -out Swissls Swiss.pdb Swiss.pin Swiss.pos Swiss.psq Swiss.pto Swiss.phr Swiss.pog Swiss.pot Swiss.ptf uniprot_sprot.fasta Blast mkdir Annotationcd Annotationblastx -query ../trinity_out_dir.Trinity.fasta -out blast.out -db /run/media/ken/BackUP/blastdb/Swiss -outfmt &quot;6 qacc sacc evalue stitle sblastname&quot; -evalue 1e-5 -max_target_seqs 1 -num_threads 8 -max_hsps 1head blast.out qacc sacc evalue stitle sblastname TRINITY_DN1_c0_g1_i1 P31792 4.12e-31 Pol polyprotein (Fragment) OS=Feline endogenous virus ECE1 OX=11766 GN=pol PE=3 SV=1 N/A TRINITY_DN10_c0_g1_i1 P63088 3.52e-16 Serine/threonine-protein phosphatase PP1-gamma catalytic subunit OS=Rattus norvegicus OX=10116 GN=Ppp1cc PE=1 SV=1 N/A TRINITY_DN12_c0_g1_i1 Q61092 0.0 Laminin subunit gamma-2 OS=Mus musculus OX=10090 GN=Lamc2 PE=1 SV=2 N/A TRINITY_DN13_c0_g1_i1 P09405 1.17e-14 Nucleolin OS=Mus musculus OX=10090 GN=Ncl Module Species For example, this group of transcripts is belongs to Mus musculus (house mouse), we can find well annotated protein from NCBI Genome We can using this from NCBI (Link) gzip -d GCF_000001635.27_GRCm39_protein.faa.gz~/Bio/blast/ncbi-blast-2.12.0+/bin/makeblastdb -in GCF_000001635.27_GRCm39_protein.faa -dbtype prot -parse_seqids -out Mus_musculus~/Bio/blast/ncbi-blast-2.12.0+/bin/blastx -query ../trinity_out_dir.Trinity.fasta -out blast.out_Mus -db /run/media/ken/BackUP/blastdb/Swiss -outfmt &quot;6 qacc sacc evalue stitle sblastname&quot; -evalue 1e-5 -max_target_seqs 1 -num_threads 8 -max_hsps 1 TB &lt;- read.table(&quot;G5M_S45_Unmap/RSEM.isoforms.results&quot;, header = T)TB2 &lt;- TB[TB$expected_count&gt;0,]TB2 &lt;- TB2[TB2$length &gt;= 200,]TB2 &lt;- TB2[order(TB2$FPKM),]TB2 &lt;- TB2[TB2$expected_count&gt;100,]write.table(TB2$transcript_id, &quot;tmp.id&quot;, row.names = F, col.names = F, quote = F) for i in $(cat tmp.id); do echo $i $(samtools depth G50-FE_TUMOR-a_S37_Unmap/sorted.bam -r $i|wc -l ); done &gt; tmp.cs Len_TB &lt;- read.table(&quot;tmp.csv&quot;)TB2$T_len &lt;- Len_TB$V2[match(TB2$transcript_id, Len_TB$V1)]TB3 &lt;- TB2[TB2$T_len / TB2$length &gt; 0.7,]paste(TB3$transcript_id[grep(&quot;_i1$&quot;, TB3$transcript_id)], collapse = &quot;|&quot;)","link":"/2021/07/21/Bioinfor/annotation/"},{"title":"Online Blast with Biopython","text":"Quick Start source: © Biopython from Bio.Blast import NCBIWWWfrom Bio.Blast import NCBIXMLsequence_data = open(&quot;blast_example.fasta&quot;).read()result_handle = NCBIWWW.qblast(&quot;blastn&quot;, &quot;nt&quot;, sequence_data)E_VALUE_THRESH = 1e-20with open('results.xml', 'w') as save_file: blast_results = result_handle.read() save_file.write(blast_results)print(sequence_data)E_VALUE_THRESH = 1e-20for record in NCBIXML.parse(open(&quot;results.xml&quot;)): if record.alignments: print(&quot;\\n&quot;) print(&quot;query: %s&quot; % record.query[:100]) for align in record.alignments: print(&quot;match: %s &quot; % align.title[:100]) >gnl|alu|X55502_HSAL000745 (Alu-J) TGCCTTCCCCATCTGTAATTCTGGCACTTGGGGAGTCCAAGGCAGGATGATCACTTATGC CCAAGGAATTTGAGTACCAAGCCTGGGCAATATAACAAGGCCCTGTTTCTACAAAAACTT TAAACAATTAGCCAGGTGTGGTGGTGCGTGCCTGTGTCCAGCTACTCAGGAAGCTGAGGC AAGAGCTTGAGGCTACAGTGAGCTGTGTTCCACCATGGTGCTCCAGCCTGGGTGACAGGG CAAGACCCTGTCAAAAGAAAGGAAGAAAGAACGGAAGGAAAGAAGGAAAGAAACAAGGAG AG query: gnl|alu|X55502_HSAL000745 (Alu-J) match: gi|120310614|gb|AC190318.8| Rhesus Macaque BAC CH250-278P13 () complete sequence match: gi|149944763|gb|AC204073.5| Rhesus Macaque BAC CH250-450C10 () complete sequence match: gi|218436709|dbj|AP007219.1| Macaca fuscata fuscata DNA, clone: MSB2-167F16, complete sequence match: gi|1777294620|ref|XM_009195938.4| PREDICTED: Papio anubis SEC14 like lipid binding 5 (SEC14L5), tran Tricks Blast Sequence from Uniprot with Organism Option From: zorbax; Biostars 2020 import urllib.requestfrom Bio import SeqIOfrom Bio.Blast import NCBIWWWurl = 'https://www.uniprot.org/uniprot/Q9LZP9.fasta'urllib.request.urlretrieve(url, &quot;chain_N.faa&quot;)record = SeqIO.read(&quot;chain_N.faa&quot;, format=&quot;fasta&quot;)result_handle = NCBIWWW.qblast('blastp', 'nr', record.seq, entrez_query=&quot;txid3702[ORGN]&quot;) Download best matched seq from the blast result from Bio import Entrez# Tell NCBI who you areEntrez.email=&quot;example@outlook.com&quot;# Acquire the sequences# If you are searching for DNA sequences, then db=&quot;nucleotide&quot;handle = Entrez.efetch( db=&quot;protein&quot;, id=&quot;NP_172363.1&quot;, rettype=&quot;fasta&quot;, retmode=&quot;text&quot;)print(handle.read()) Esearch in terminal We can use esearch to dwonload the fast file source: NCBI Book conda install -c bioconda entrez-direct# for nucleotideesearch -db nucleotide -query &quot;KAG7629426.1&quot; | efetch -format fasta# for protein sequencesesearch -db protein -query &quot;KAG7629426.1&quot; | efetch -format fasta Practices Find the homologs gene from 10 different species by blast organism information: NCBI Find a list of organism from Bio.Blast import NCBIWWWfrom Bio.Blast import NCBIXMLfrom Bio import SeqIOfrom Bio import Entrezimport urllib.requestOrgan_list = [&quot;9527&quot;, &quot;499232&quot;, &quot;9597&quot;, &quot;9601&quot;, &quot;61851&quot;, &quot;716690&quot;, &quot;9480&quot;, &quot;9521&quot;, &quot;174599&quot;, &quot;37295&quot;, &quot;1861701&quot;, &quot;1812036&quot;, &quot;30596&quot;, &quot;9604&quot;, &quot;9504&quot;, &quot;9480&quot;]for i in Organ_list: record = SeqIO.read(&quot;chain_N.faa&quot;, format=&quot;fasta&quot;) result_handle = NCBIWWW.qblast('blastp', 'nr', record.seq, entrez_query=&quot;txid&quot;+ i +&quot;[ORGN]&quot;) with open('results.xml', 'w') as save_file: blast_results = result_handle.read() save_file.write(blast_results) E_VALUE_THRESH = 1e-20 Num = 0 for record in NCBIXML.parse(open(&quot;results.xml&quot;)): Num += 1 if record.alignments: print(&quot;\\n&quot;) print(&quot;query: %s&quot; % record.query[:100]) for align in record.alignments: align.title.split(&quot;|&quot;)[1] if Num &lt; 4: A = align.title handle = Entrez.efetch( db=&quot;protein&quot;, id=A.split(&quot;|&quot;)[1], rettype=&quot;fasta&quot;, retmode=&quot;text&quot;) print(handle.read()) for(i in c(“BLOSUM62”, “PAM250”)){ seq_1 &lt;- “MRSSPGNMERIVICLMVIFLGTLVHKSSSQGQDRHMIRMRQLIDIVDQLKNYVNDLVPEFLPAPEDVETNCEWSAFSCFQKAQLKSANTGNNERIINVSIKKLKRKPPSTNAGRRQKHRLTCPSCDSYEKKPPKEFLERFKSLLQKMIHQHLSSRTHGSEDS” seq_2 &lt;- “MERTLVCLVVIFLGTVAHKSSPQGPDRLLIRLRHLIDIVEQLKIYENDLDPELLSAPQDVKGHCEHAAFACFQKAKLKPSNPGNNKTFIIDLVAQLRRRLPARRGGKKQKHIAKCPSCDSYEKRTPKEFLERLKWLLQKMIHQHLS” globalAlign_CHRNA2 &lt;- pairwiseAlignment(seq_1, seq_2, substitutionMatrix = i, gapOpening = -12, gapExtension = -2, scoreOnly = FALSE) substr(globalAlign_CHRNA2@pattern, 1, nchar(globalAlign_CHRNA2@pattern)) substr(globalAlign_CHRNA2@subject, 1, nchar(globalAlign_CHRNA2@subject)) print(globalAlign_CHRNA2@score) }","link":"/2021/10/15/Bioinfor/biopython-blast/"},{"title":"Blast+","text":"Blast+ latest release Installation For Ubuntu or Debian (Deepin, like me) sudo apt-get install ncbi-blast+ For other distributions: wget -c https://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/ncbi-blast-2.12.0+-x64-linux.tar.gztar -zxvf ncbi-blast-2.12.0+-x64-linux.tar.gzcd ncbi-blast-2.12.0+/bin Quick Start make blast base makeblastdb -in db.fasta -dbtype prot/nucl -parse_seqids -out dbname model of uniprot annotation blastx -query T0.05.fa -out blast.out -db /media/ken/Base/blastdb/uniprot_sprot.fasta -outfmt &quot;6 qacc sacc evalue pident qcovs&quot; -evalue 1e-5 -max_target_seqs 1 -num_threads 8 -max_hsps 1 Output explanation for “6 qacc sacc evalue pident qcovs”: “qacc”: Query ID “sacc”: Subject ID “evalue”: Evalue “pident”: Identity (Percentage) “qcovs”: Query coverage Different Commands BLASTP: For comparing Protein sequences to Protein databases. BLASTN: For comparing Nucleotide sequences to Nucleotide databases. BLASTX: For comparing a Nucleotide query sequence translated in all reading frames to a Protein database. TBLASTN: For comparing a Protein sequence to a Nucleotide database that is translated in all reading frames. TBLASTX: For comparing the six-frame translations of a Nucleotide query sequence against the six-frame translations of a Nucleotide database. Output format Options 6, 7 and 10 can be additionally configured to produce a custom format specified by space delimited format specifiers. The supported format specifiers are: qseqid means Query Seq-id qgi means Query GI qacc means Query accesion qaccver means Query accesion.version qlen means Query sequence length sseqid means Subject Seq-id sallseqid means All subject Seq-id(s), separated by a ';' sgi means Subject GI sallgi means All subject GIs sacc means Subject accession saccver means Subject accession.version sallacc means All subject accessions slen means Subject sequence length qstart means Start of alignment in query qend means End of alignment in query sstart means Start of alignment in subject send means End of alignment in subject qseq means Aligned part of query sequence sseq means Aligned part of subjecnit sequence evalue means Expect value bitscore means Bit score score means Raw score length means Alignment length pident means Percentage of identical matches nident means Number of identical matches mismatch means Number of mismatches positive means Number of positive-scoring matches gapopen means Number of gap openings gaps means Total number of gaps ppos means Percentage of positive-scoring matches frames means Query and subject frames separated by a '/' qframe means Query frame sframe means Subject frame btop means Blast traceback operations (BTOP) staxid means Subject Taxonomy ID ssciname means Subject Scientific Name scomname means Subject Common Name sblastname means Subject Blast Name sskingdom means Subject Super Kingdom staxids means unique Subject Taxonomy ID(s), separated by a ';' (in numerical order) sscinames means unique Subject Scientific Name(s), separated by a ';' scomnames means unique Subject Common Name(s), separated by a ';' sblastnames means unique Subject Blast Name(s), separated by a ';' (in alphabetical order) sskingdoms means unique Subject Super Kingdom(s), separated by a ';' (in alphabetical order) stitle means Subject Title salltitles means All Subject Title(s), separated by a '' sstrand means Subject Strand qcovs means Query Coverage Per Subject qcovhsp means Query Coverage Per HSP qcovus means Query Coverage Per Unique Subject (blastn only) pre { background-color:#38393d; color: #5fd381; }","link":"/2020/07/28/Bioinfor/blast/"},{"title":"Biopython: The quickest way to biuld and visualize tree with python","text":"Align your Sequence Set your arguments INPUT = &quot;&quot;OUTPUT = &quot;&quot;ARG_TREE = &quot;&quot; # NJ / UPGMA Import libraries import osfrom Bio.Align.Applications import ClustalwCommandlinefrom Bio import AlignIOfrom Bio import Phylo Pre-align cwline = ClustalwCommandline(&quot;clustalw2&quot;, infile= INPUT, outfile = OUTPUT + &quot;.fasta&quot;, output= &quot;fasta&quot; )print(cwline)stdout, stderr = cwline() clustalw2 -infile=Base.fa -outfile=assignment2.fasta -output=fasta Trimming the gap Gap from the head and tail could have huge effects on the result of the tree. So, we should avoid the side effects from the gaps because of the length-difference. Here, we just counting the gaps from the head and tail of each sequences and retain the largest number. On the other hand, the numbers’ of gap extension were printed out so you can customize your own. ## reading the alignmentsalign = AlignIO.read(OUTPUT + &quot;.fasta&quot;, &quot;fasta&quot;)## Count the longest space on the headGap_head = 0Gap_tail = 0Gap_list_head = []Gap_list_tail = []for seq_tmp in align: Num = 0 while seq_tmp[Num] == &quot;-&quot;: Num +=1 Gap_list_head += [Num] if Num &gt; Gap_head: Gap_head = Num## Count the longest space on the tailfor seq_tmp in align: Num = 0 while seq_tmp[::-1][Num] == &quot;-&quot;: Num +=1 Gap_list_tail += [Num] if Num &gt; Gap_tail: Gap_tail = Numprint(&quot;\\nGap head list: &quot;, Gap_list_head, &quot;\\nGap head tail: &quot;, Gap_list_tail)print(&quot;\\nGap head: &quot;, Gap_head, &quot;\\nGap head: &quot;, Gap_tail)## Count the longest space on the head# Alignment objects can be manipulated# slice alignmentalign_slice = align[:, Gap_head : len(seq_tmp)-Gap_tail]print (&quot;Slice of alignment from position &quot; + str(Gap_head) + &quot; to &quot; + str(Gap_tail) +&quot;\\n&quot;)print(align_slice)## wirte it outF = open(OUTPUT + &quot;_scliced.fa&quot;, 'w')F2 = open(OUTPUT + &quot;_gap.fa&quot;, 'w')for Seq_tmp in align_slice: F.write(&quot;&gt;&quot; + Seq_tmp.id+&quot;\\n&quot;) F2.write(&quot;&gt;&quot; + Seq_tmp.id+&quot;\\n&quot;) Seq_seq = str(Seq_tmp.seq) F2.write(Seq_seq+&quot;\\n&quot;) Seq_seq = Seq_seq.replace(&quot;-&quot;,&quot;&quot;) F.write(Seq_seq+&quot;\\n&quot;)F.close()F2.close() Gap head list: [115, 115, 86, 86, 86, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 91, 170, 70, 115, 117, 0, 115, 115, 192] Gap head tail: [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 0, 0, 12] Gap head: 192 Gap head: 13 Slice of alignment from position 192 to 13 Alignment with 28 rows and 167 columns Build the tree ### Make Phylogenetic Treecwline = ClustalwCommandline(&quot;clustalw2&quot;, infile= OUTPUT + &quot;_gap.fa&quot;, clustering = ARG_TREE, bootstrap = 1000)print(cwline)stdout, stderr = cwline()tree = Phylo.read(OUTPUT.split(&quot;.&quot;)[0]+&quot;_gap.phb&quot;, &quot;newick&quot;)Phylo.draw_ascii(tree)# select the 3 sequences in the top branch of phylo treealign_branch = align_slice[0:3]print(align_branch) , XP_009431258.3 | | , XP_005584739.1 | | |,| NP_001036203.1 ||| ||| XP_011717782.1 || |, XP_011852471.1 || || NP_001277233.1 || ,| XP_025230146.1 || |, AAU95547.1 || || XP_011803362.1 || || XP_010378328.1 | | , XP_033039886.1 |,| |||__ XP_037851661.1 ||| |||________ XP_026309478.1 || || ___ XP_011926036.1 ||,| ||||_____ XP_017738318.1 ||| | | _______________ XP_024205865.1 | |_________| | |_______________ XP_024205864.1 | | | |_________________________________________ NP_175517.1 | | XP_008962016.1 | | XP_030866972.1 | | XP_009250187.1 | | XP_004041225.1 | | XP_004041226.1 | | XP_002827755.1 | | XP_002827754.1 _| , sp|P01241|SOMA_HUMAN | | XP_002827756.1 | | XP_024090242.1 Visualizing it with ggtree Reference: ggplot2 extensions; 2016 args &lt;- commandArgs(trailingOnly = TRUE)print(&quot;Input&quot;, str(args))library(&quot;ggtree&quot;)tree &lt;- read.tree(args)ggtree(tree, branch.length = 'none') + geom_text2(aes(subset=!isTip, label=node), hjust= 1.5, vjust = -0.5) + geom_tiplab() + xlim(NA, 15 + length(strsplit(tree$tip.label[1], &quot;*&quot;)[[1]])/2.5)ggsave(paste(args, &quot;.png&quot;, sep=&quot;&quot;)) ### save the tree as pngPATH_lib = os.path.dirname(__file__)CMD = &quot;Rscript &quot; + PATH_lib + &quot;/lib/R/ggtree.R &quot; + OUTPUT + &quot;_gap.phb&quot;print(CMD)os.system(CMD) How to use The quickest way: input file: sample.fasta output file prefix: result tree type: UPGMA Seq2tree.py -i sample.fasta -o result -t UPGMA results: result.fasta: original aligned file (with gaps) result_gap.fa: Trimmed file (with gaps) result_scliced.Trimmed file (without gaps) result_gap.phb: Tree file result_gap.phb.png: Tree visualizing with ggtree digraph{ node [shape = box] A [label = \"Align Sequences\"; URL = \"#Pre-align\", fontcolor = \"steelblue\"] B [label = \"Trimming gaps\"; URL = \"#Trimming-the-gap\", fontcolor = \"steelblue\"] C [label = \"Build tree\"; URL = \"#Build-the-tree\", fontcolor = \"steelblue\"] D [label = \"Visualize the tree\"; URL = \"#Visualizing-it-with-ggtree\", fontcolor = \"steelblue\"] A -> B -> C -> D } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });","link":"/2021/10/22/Bioinfor/biopython-seq2tree/"},{"title":"RNA Seq: Alternative Splicing","text":"Please check this update this is a test. lol SpliceTools Bisbee; paper rMATS Some background In seminar recording form OHSU Informatics, they talked about how rMATS worked and the limits of rMATS in overlapped genes and complicated splicing events. Julian Epigenetics and alternative splicing Splicing and transcription can be regulated by epigenetic modifications, such as alterations in histone and DNA structures[1][2]. The organization of chromatin can regulate the splicing process by influencing the availability and recruitment of splicing factors[3]. Alternative spoicing could also be affect by histonmadification[4] and DNA modificatiom, like cytosine methylation[5] Softwares for study alternative splicing © Magdalena J. Koziol, 2018 Tool Biological Replicates Model Experimental Design Reference JunctionSeq Yes Exon &amp; Junction Design Matrix [6] Tuxedo 2 Yes Isoform, Exon &amp; Junction Design Matrix [7] DEXSeq Yes Exon Design Matrix [8] MATS No Exon &amp; Junction Two Sample [9] MISO No Isoform Two Sample [10] Cuffdiff 2 Yes Isoform &amp; Exon Two Groups [11] DSGseq Yes Exon Two Groups [12] DiffSplice Yes Exon &amp; Junction Two Groups [13] ARH-seq Yes Exon &amp; Junction Two Sample [14] rMARS rMATS (multivariate analysis of transcript splicing ) is a computational tool to detect differential alternative splicing events from RNA-Seq data. The statistical model of MATS calculates the P-value and false discovery rate that the difference in the isoform ratio of a gene between two conditions exceeds a given user-defined threshold. From the RNA-Seq data, MATS can automatically detect and analyze alternative splicing events corresponding to all major types of alternative splicing patterns. MATS handles replicate RNA-Seq data from both paired and unpaired study design. (© Xing Lab) © Xing Lab Unpaired Replicates. Other Related Tools MISO, SpliceTrap, ALEXA- seq, and rSeqDiff are designed for two-sample com- parison and do not handle replicates. Cufflinks, FDM, and DiffSplice use the Jensen–Shannon divergence metric to detect differential isoform proportion while accounting for vari- ability among replicates. (rMATS) Pipelines form the paper SRS35482: → mapped into Ensembl transcripts (TopHat) → unmapped reads mapped into Genom h1g (TopHat) → rMATS sudo apt install libgsl-dev cmake cythonpip install Cythongit clone https://github.com/Xinglab/rmats-turbo.gitcd rmats-turbo./build_rmatsrmats.py --b1 path1 --b2 path2 --gtf ../Mutation/Yuwei_data/DATA/genes.gtf -t single --readLength 50 --nthread 4 --od output --tmp tmp_outputrmats.py --b1 path1 --b2 path2 --gtf ../DB/dmel-all-r6.39.gtf -t single --readLength 50 --nthread 4 --od output --tmp tmp_output Aligner Choose For aternative splicing, we have to use intron awareness aligners like tophat, hisat, stat, etc. Other well known aligners like bowtie and bwa should be avoided only you have significant reasons. Tophat In the paper of rMATS, they choosed Tophat as the aligner. You can’t add parameters at the end of the commands. All arguments should following tophat and tha last three is index + reads tophat -G *.gtf -p &lt;threads&gt; -o &lt;out_dir&gt; &lt;bowtie_index&gt; &lt;reads1,reads2,...&gt; &lt;reads1,reads2,...&gt;hisat2 [options]* -x &lt;ht2-idx&gt; {-1 &lt;m1&gt; -2 &lt;m2&gt; | -U &lt;r&gt;} [-S &lt;sam&gt;]# build indexhisat2-build -p 16 genome.fa genomehisat2 -p 40 -x hisat2-index -U A.fq -S out.samfor SAMPLE in CF TF; do echo ../Merge_Tri_FQ/$SAMPLE*; sed &quot;s/Hi/ht2_$SAMPLE/;s/128/32/&quot; ../Model.sh &gt; script/$SAMPLE\\_ht2.sh echo hisat2 -x ../DB/dmel-all-chromosome-r6.39 -p 40 -S ht2_$SAMPLE.sam -U $(ls ../Merge_Tri_FQ/$SAMPLE*| tr &quot;\\n&quot; &quot;,&quot;| sed 's/,$/\\n/') &gt;&gt; script/$SAMPLE\\_ht2.sh sbatch script/$SAMPLE\\_ht2.shdone PS: An interesting thing is you can’t build ‘hisat index’ with ‘gz’ file. So, we need to decompress it before building the index. Lol Differential Expression and Differential Splicing. © K. Vitting-Seerup; 2017 Run with test data In the official documentation, they applied a small group of test data: Thanks for Yunze Liu, I knwo that we just need to download the human gtf for tarting the test. I tried two set of parameters and the results end the same. But I do have different number of results from genome compared with Yunze Liu’s result which means we used different gtf (Mine has less genes). The reference I used is from ucsc: hg19 GTF and Test data from documentation . ├── 231ESRP.25K.rep-1.bam ├── 231ESRP.25K.rep-1.bam.bai ├── 231ESRP.25K.rep-1.R1.fastq ├── 231ESRP.25K.rep-1.R2.fastq ├── 231ESRP.25K.rep-2.bam ├── 231ESRP.25K.rep-2.bam.bai ├── 231ESRP.25K.rep-2.R1.fastq ├── 231ESRP.25K.rep-2.R2.fastq ├── 231EV.25K.rep-1.bam ├── 231EV.25K.rep-1.bam.bai ├── 231EV.25K.rep-1.R1.fastq ├── 231EV.25K.rep-1.R2.fastq ├── 231EV.25K.rep-2.bam ├── 231EV.25K.rep-2.bam.bai ├── 231EV.25K.rep-2.R1.fastq ├── 231EV.25K.rep-2.R2.fastq ├── b1.txt ├── b2.txt ├── hg19.ensGene.gtf ├── s1.txt └── s2.txt python ../Github/rmats-turbo/rmats.py --b1 b1.txt --b2 b2.txt --gtf hg19.ensGene.gtf --od bam_test --tmp bam_tmp -t paired --readLength 50 --cstat 0.0001 --libType fr-unstrandedpython ../Github/rmats-turbo/rmats.py --b1 b1.txt --b2 b2.txt -t paired --readLength 50 --nthread 4 --od test --tmp tmp_output --gtf hg19.ensGene.gtf Done processing each gene from dictionary to compile AS events Found 39321 exon skipping events Found 2115 exon MX events Found 13456 alt SS events There are 8337 alt 3 SS events and 5119 alt 5 SS events. Found 6244 RI events Repeats and non-repeats results wc CFT*/*| awk '{print $4,$1}'| tr '/' ' '| awk '{print $2,$1,$3}'|sort | column -t -s' ' MXE.MATS.JCEC.txt CFTF 350 MXE.MATS.JCEC.txt CFTF_s 109 MXE.MATS.JC.txt CFTF 349 MXE.MATS.JC.txt CFTF_s 109 RI.MATS.JCEC.txt CFTF 31 RI.MATS.JCEC.txt CFTF_s 17 RI.MATS.JC.txt CFTF 31 RI.MATS.JC.txt CFTF_s 17 SE.MATS.JCEC.txt CFTF 857 SE.MATS.JCEC.txt CFTF_s 334 SE.MATS.JC.txt CFTF 849 SE.MATS.JC.txt CFTF_s 333 The first column is rMATS results. the second column is result folder. The last column is the number of row for each file. CFTF is triplicate result and CFTF_s is single result. We can find that triplicate result have more counts. Visualization Tools: Xinglab/rmats2sashimiplot This tool is based ob python2, not python3! Quickies way to install it: conda create --name Splicing -c bioconda rmats2sashimiplot python=2.7 An example of code could be: (Omics-Hunter) rmats2sashimiplot --b1 231ESRP.25K.rep-1.bam,231ESRP.25K.rep-2.bam --b2 231EV.25K.rep-1.bam,231EV.25K.rep-2.bam -t SE -e bam_test/SE.MATS.JC.txt --l1 SampleOne --l2 SampleTwo --exon_s 1 --intron_s 5 -o test_events_output Errors ImportError: No module named _bsddb mv: cannot stat '/mnt/cypress/kraken_RNA/asp2/plot/Sashimi_plot/2R:24671294:24688185:+.pdf': No such file or directory It is because you lack of conda install -c conda-forge bsddb3 Plot the result by position By using the rmats2sashimiplot tool, you can create a plot of the output by specifying a region with the -c option. However, this can be prone to errors. Based on my experience, there are several factors that should be considered: It is recommended that each position should have its own directory, as the tool generates an index for that position which may not update even if the parameters are changed. It is possible to assign a random position, but it is preferable to assign a position based on the position of exons. If there are no genes located within the region that has been specified, an error will occur. png result It appears that the rmats2sashimiplot tool is not capable of producing the result as a PNG image format. As a solution, we can use other tools such as pdftoppm to convert the generated PDF file to the PNG format. For instance, a command example to convert a file named p1.pdf to a PNG file named p1.png with a resolution of 1000 can be: pdftoppm p1.pdf p1.png -png -r 1000. Result Explanation result ES（Exon skipping）：外显子跳跃。外显子在前体mRNA剪接形成成熟mRNA过程中被跳过，最终没有出现在某些成熟mRNA上【发生跳跃的外显子和其两侧的内含子都被剪切掉；上游和下游的外显子被直接连着一起保留在剪切后的产物中】 RI（Retained intron）：内含子保留。前体mRNA在剪接形成成熟mRNA的过程中，部分内含子被保留下来【某一段核苷酸序列在一个剪切体中是外显子的一部分，而在与之对照的剪切体中却是内含子而被剪切掉】 AD（Alternate Donor site）或A5SS（Alternative 5’ splice site）：5’端可变剪接。前体mRNA在剪接形成成熟mRNA的过程中，5’端边界发生不同方式的剪接，导致5‘端外显子有所延长 AA（Alternate acceptor site）或A3SS（Alternative 3’ splice site）：3’端可变剪接。前体mRNA在剪接形成成熟mRNA的过程中，3’端边界发生不同方式的剪接，导致3‘端外显子有所延长 AT（Alternate terminator）或Alternative last exon：第一个外显子发生改变 AP（Alternate promoter）或Alternative first exon：最后一个外显子发生改变 ME（Mutually exclusive exon）：外显子选择性跳跃。形成的两种不同的转录本中，两转录本之间相同的外显子称为constitutive exon， 不同的外显子称为inclusive exon，inclusive exon不能同时存在与同一转录本中， 只能分别存在于不同转录本中 from: Yunze Liu An Example of “SE” results ID GeneID geneSymbol chr strand exonStart_0base exonEnd upstreamES upstreamEE downstreamES downstreamEE ID IJC_SAMPLE_1 SJC_SAMPLE_1 IJC_SAMPLE_2 SJC_SAMPLE_2 IncFormLen SkipFormLen PValue FDR IncLevel1 IncLevel2 IncLevelDifference 2365 \"FBgn0283521\" \"lola\" chr2R - 10515834 10516051 10510524 10511004 10532038 10532119 2365 69,54,77 2,0,6 7,6 3,15 98 49 3.09913051888e-08 6.84584054917e-07 0.945,1.0,0.865 0.538,0.167 0.584 2366 \"FBgn0283521\" \"lola\" chr2R - 10527065 10527219 10524804 10525862 10532038 10532119 2366 4,0,9 7,6,7 5,3 0,0 98 49 1.0012167162e-07 2.0676289395e-06 0.222,0.0,0.391 1.0,1.0 -0.796 2341 \"FBgn0250823\" \"gish\" chr3R + 16282080 16282408 16274953 16275169 16289630 16289839 2341 400,517,475 57,86,82 33,40 40,43 98 49 0 0.0 0.778,0.75,0.743 0.292,0.317 0.453 2358 \"FBgn0250823\" \"gish\" chr3R + 16299590 16299689 16297174 16297345 16301822 16302372 2358 4,8,4 0,0,0 1,0 2,1 98 49 1.12175272649e-06 2.04962226569e-05 1.0,1.0,1.0 0.2,0.0 0.9 2356 \"FBgn0250823\" \"gish\" chr3R + 16299590 16299689 16297174 16297345 16300568 16300865 2356 1,0,0 0,1,0 1,0 0,0 98 49 1 1.0 1.0,0.0,NA 1.0,NA -0.5 2359 \"FBgn0250823\" \"gish\" chr3R + 16299590 16299689 16298469 16298550 16301244 16301351 2359 486,567,539 562,650,571 113,125 34,32 98 49 0 0.0 0.302,0.304,0.321 0.624,0.661 -0.334 There are lot’s of columns. Let’s check them one by one. ID: A ID for this specific events. Numeric. GeneID: The ID of the event-location. Comes from the gtf file you given geneSymbol: The name of the genes. ‘lola’ for example. chr: chromosome name. It would add a chr at the head of each chromosome’s name. Don’t worry about this feature in rmats2sashimiplot. You just need the name as the same from gff file. strand: the direction of the gene. exonStart_0base: pre { background-color:#38393d; color: #5fd381; } Luco RF, Allo M, Schor IE, Kornblihtt AR, Misteli T. 2011 Epigenetics in alternative Pre-mRNA splicing. Cell 144, 16–26. (doi:10.1016/j.cell.2010.11.056) ↩︎ Khan DH, Jahan S, Davie JR. 2012 Pre-mRNA splicing: role of epigenetics and implications in disease. Adv. Biol. Regul. 52, 377–388. (doi:10.1016/j.jbior.2012.04.003) ↩︎ Gunderson FQ, Johnson TL. 2009 Acetylation by the transcriptional coactivator Gcn5 plays a novel role in co-transcriptional spliceosome assembly. PLoS Genet. 5, e1000682. (doi:10.1371/journal.pgen.1000682) ↩︎ Spies N, Nielsen CB, Padgett RA, Burge CB. 2009 Biased chromatin signatures around polyadenylation sites and exons. Mol. Cell 36, 245–254. (doi:10.1016/j.molcel.2009.10.008) ↩︎ Ehrlich M, Ehrlich KC. 2014 DNA cytosine methylation and hydroxymethylation at the borders. Epigenomics 6, 563–566. (doi:10.2217/epi.14.48) ↩︎ Deamer D, Akeson M, Branton D. 2016 Three decades of nanopore sequencing. Nat. Biotechnol. 34, 518–524. (doi:10.1038/nbt.3423) ↩︎ Blake JA et al. 2015 Gene ontology consortium: going forward. Nucleic Acids Res. 43, D1049–D1056. (doi:10.1093/nar/gku1179) ↩︎ Le Nove`re N. 2015 Quantitative and logic modelling of molecular and gene networks. Nat. Rev. Genet. 16, 146–158. (doi:10.1038/nrg3885) ↩︎ Fisher J, Henzinger TA. 2007 Executable cell biology. Nat. Biotechnol. 25, 1239–1249. (doi:10.1038/nbt1356) ↩︎ Markowetz F. 2010 How to understand the cell by breaking it: network analysis of gene perturbation screens. PLoS Comput. Biol. 6, e1000655. (doi:10. 1371/journal.pcbi.1000655) ↩︎ Bellman RE. 1957 Dynamic programming. Princeton, NJ: Princeton University Press. ↩︎ Robinson MD, McCarthy DJ, Smyth GK. 2010 edgeR: a Bioconductor package for differential expression analysis of digital gene expression data. Bioinformatics 26, 139–140. (doi:10.1093/ bioinformatics/btp616) ↩︎ Gao D, Kim J, Kim H, Phang TL, Selby H, Tan AC, Tong T. 2010 A survey of statistical software for analysing RNA-seq data. Hum. Genomics 5, 56–60. (doi:10.1186/1479-7364-5-1-56) ↩︎ Kitano H. 2002 Systems biology: a brief overview. Science 295, 1662–1664. (doi:10.1126/science.1069492) ↩︎","link":"/2022/11/07/Bioinfor/alternative-splicing/"},{"title":"Cellpose","text":"CellPose CellPose is an awesome machine learning-based tool that could segment cells very easily. The pre-trained model could suit multiple scenarios and fit the basic usages. And it can do more than cell segmentation (Though the cell pose looks fancy, I still didn’t know who to work with the results.) To learn more, please read the documentation from cellpose import modelsfrom cellpose.io import imread# model_type='cyto' or model_type='nuclei'model = models.Cellpose(gpu=False, model_type='cyto')files = ['img0.tif', 'img1.tif']imgs = [imread(f) for f in files]masks, flows, styles, diams = model.eval(imgs, diameter=None, channels=[0,1], flow_threshold=0.4, do_3D=False) pre { background-color:#38393d; color: #5fd381; }","link":"/2022/12/21/Bioinfor/cellpose/"},{"title":"","text":"CD-HIT Documentation: CD-HIT CD-HIT (Cluster Database at High Identity with Tolerance) is a widely used bioinformatics tool designed to cluster biological sequences (such as DNA, RNA, or proteins) to reduce sequence redundancy and improve the efficiency of other sequence analyses. It’s particularly useful when dealing with large datasets, such as those frequently encountered in genomics and proteomics studies. Here are some key features and uses of CD-HIT: Sequence Clustering: CD-HIT efficiently clusters similar sequences together based on a user-defined similarity threshold. For example, if you set a threshold of 90%, the tool will group sequences that are 90% identical into the same cluster. Reduction of Redundancy: By clustering similar sequences, CD-HIT helps in reducing redundancy in the dataset. This is particularly important when creating sequence databases or when analyzing large datasets where many sequences may be very similar or nearly identical. Speed and Efficiency: CD-HIT is known for its speed and low memory usage, making it suitable for handling very large datasets that are common in modern high-throughput sequencing projects. Multiple Applications: It’s used in a variety of applications, such as creating non-redundant sequence databases, preparing datasets for further analyses (like phylogenetic studies), or in metagenomics for analyzing diversity and similarity of species. Customizable Parameters: Users can customize several parameters, such as the identity threshold for clustering, the word size for initial comparisons, and memory usage, allowing for flexibility depending on the specific requirements of the data or the analysis. Output Files: CD-HIT generates two main types of output files - one containing the clustered sequences and another (.clstr file) detailing the composition of each cluster. CD-HIT is a command-line tool, which means it is run from a terminal or command prompt and offers great flexibility in scripting and automation within bioinformatics pipelines. The tool is an essential part of the toolkit for biologists and bioinformaticians dealing with large-scale sequence data. Example cd-hit -i Trunked.fa -o cdhit/Trunked_$x.fa -c $x -M 32000 -d 0 -T 8 -n 5 -aL 0.8 -s 0.95 -uS 0.2 -sc 1 -sf 1 The command you’ve provided is for CD-HIT, a widely used bioinformatics tool for clustering and comparing protein or nucleotide sequences. CD-HIT helps to significantly reduce the redundancy of large datasets by clustering similar sequences together based on a specified sequence identity threshold. This is particularly useful in tasks like constructing databases or preparing datasets for other analyses where redundancy might be an issue. Let’s break down the components of your command: cd-hit: This invokes the CD-HIT program. -i Trunked.fa: The -i option specifies the input file. Here, the input file is Trunked.fa, which likely contains a collection of nucleotide or protein sequences in FASTA format. -o cdhit/Trunked_$x.fa: The -o option specifies the output file. This command will create an output file in the cdhit directory with a name based on the value of the variable $x. The $x seems to be a shell variable that would be replaced with its value when the command runs. -c $x: The -c option sets the sequence identity threshold. Sequences are clustered together if they are similar to each other above this threshold. The exact value is determined by the variable $x. -M 32000: This sets the maximum available memory (in MB). 32000 here means 32,000 MB, or 32 GB of RAM. -d 0: The -d option is for the description length to show in the .clstr output file. 0 means it will show the full sequence defline. -T 8: This specifies the number of threads to use. 8 means the program will run on 8 threads, enabling parallel computation for faster processing. -n 5: For protein sequences, this sets the word length for the initial match. 5 is typically used for thresholds between 0.7 and 0.8. -aL 0.8: This sets the alignment coverage for the longer sequence. 0.8 means 80% of the longer sequence must be covered in the alignment. -s 0.95: This sets the alignment coverage for the shorter sequence. 0.95 means 95% of the shorter sequence must be included in the alignment. -uS 0.2: This specifies the maximum unmatched percentage of the shorter sequence. 0.2 means up to 20% of the shorter sequence can be unmatched. -sc 1: This option, when set to 1, sorts clusters by decreasing size. -sf 1: This option, when set to 1, sorts fasta sequence by cluster size. Each of these options tailors the behavior of CD-HIT to your specific requirements, influencing how sequences are clustered and how the output is formatted and organized. The use of shell variables (like $x) suggests that this command is part of a script where the value of $x is dynamically set, allowing for flexible application of the command with different parameters. Read the cd-hit Result as pandas dataframe import pandas as pd# Initialize lists to store datasequence_names = []cluster_ids = []# Open the .clstr file and parse itwith open('your_file.clstr', 'r') as file: current_cluster_id = None for line in file: if line.startswith('&gt;Cluster '): current_cluster_id = line.split()[1] else: # Extracting sequence name parts = line.split() seq_name = parts[2].strip('&gt;').split('...')[0] sequence_names.append(seq_name) cluster_ids.append(current_cluster_id)# Create a DataFramedf = pd.DataFrame({'Sequence Name': sequence_names, 'Cluster ID': cluster_ids})# Display the DataFrameprint(df) Trouble Shooting Fatal Error: Too low cluster threshold for the word length. Increase the threshold or the tolerance, or decrease the word length. Program halted !! The error message you’re encountering, “Fatal Error: Too low cluster threshold for the word length. Increase the threshold or the tolerance, or decrease the word length. Program halted !!”, indicates a conflict between the parameters you’ve set in CD-HIT, particularly relating to the sequence identity threshold and the word length. In CD-HIT, the “word length” refers to the length of the initial exact match that the algorithm looks for when comparing sequences. The “cluster threshold” is the percentage similarity required for two sequences to be clustered together. When the cluster threshold is set too low relative to the word length, the program cannot effectively perform the initial sequence matching, leading to this error. To resolve this issue, you can: Increase the Threshold: Increase the sequence identity threshold (-c parameter). If it’s currently very low, increasing it will make the clustering less stringent. For instance, if you have set -c 0.6 (60% identity), try increasing it to 0.7 or higher. Decrease the Word Length: Decrease the word length (-n parameter). A lower word length means the program will look for shorter exact matches in the initial step, which can be more tolerant of low similarity thresholds. However, be cautious, as too low a word length might make the process slower and less efficient. Adjust Tolerance: If your dataset includes very diverse sequences and you need to maintain a low threshold, you might have to adjust other parameters to balance the sensitivity and specificity of the clustering. Remember that the appropriate values for these parameters can vary depending on your specific dataset and the objectives of your analysis. It might require some experimentation to find the right balance for your needs. pre { background-color:#38393d; color: #5fd381; }","link":"/2023/12/13/Bioinfor/cdhit/"},{"title":"CPAT","text":"CPAT Quick start cpat.py -g Tinity.fna -d ~/Biosoft/CPAT-1.2.4/dat/Human_logitModel.RData -x ~/Biosoft/CPAT-1.2.4/dat/Human_Hexamer.tsv -o output -r 指定参考基因组 -g 输入的转录本序列。如果是BED格式，必须-r指定参考基因组；如果是FASTA格式，不需要指定参考基因组，即使使用-r参数也会被忽略。 -d 预制好的模型（Prebuilt training model）（CPAT自带人、鼠、果蝇、斑马鱼的模型） -x 预制好的六聚体频率表（Prebuilt hexamer frequency table）（CPAT自带人、鼠、果蝇、斑马鱼的六聚体频率表） -o 输出","link":"/2020/07/28/Bioinfor/cpat/"},{"title":"cufflinks","text":"cufflinks run cufflinks the result of tophat is needed ~/Biosoft/cufflinks-2.2.1.Linux_x86_64/cufflinks -p 8 -b ../tophat/erecta.fna -u -o sample1 ../tophat/tophat_out/accepted_hits.bam gtf merging (without fasta.file result) cuffmerge -o merged_asm -p 8 -s ../../tophat/erecta.fna list cuffquant (For count the reads) cuffquant -o cuffquant2 -p 8 -b Genome.fna -u Genome.gff tophat.bam##Exp:cuffquant -o cuffquant2 -p 8 -b ../../data/Genome/A.japonicus/Apostichopus_japonicus.fna -u ../../data/Genome/A.japonicus/Apostichopus_japonicus.gff 2dpe/accepted_hits.bam (the result of cuffquant is binary file you can run cuffnorm to transfor this binary file to readable file.) cuffcompare for stattistics (useless) cuffcompare -o cuffcmp -r genome.gtf -s genome.fasta sample1.gtf##Exp:cuffcompare -o cuffcmp2 -r ../../data/Genome/A.japonicus/Apostichopus_japonicus.gff -s ../../data/Genome/A.japonicus/Apostichopus_japonicus.fna cufflinks2/transcripts.gtf merge the fpkm cuffnorm -L 0dpe,3dpe,7dpe,14dpe,21dpe -p 8 ../../data/Genome/A.japonicus/Apostichopus_japonicus.gff cuffquant2/abundances.cxb cuffquant3/abundances.cxb cuffquant4/abundances.cxb cuffquant5/abundances.cxb cuffquant6/abundances.cxb -o cuffnorm cuffdiff … similar to the same as the cuffnorm. cuffdiff -L A1,B2 -o cuffdiff2 -p 8 -u -b ../../data/Genome/A.japonicus/Apostichopus_japonicus.fna ../../data/Genome/A.japonicus/Apostichopus_japonicus.gff cuffquant2/abundances.cxb cuffquant2/abundances.cxb","link":"/2020/07/28/Bioinfor/cufflinks/"},{"title":"Install DGI-DB at local PC","text":"Install DGI-DB at local PC GitHub: griffithlab Installation: follow the instruct of: INSTALL-OSX or INSTALL-LINUX during the installation, you can spend your time on learn something about ruby if you never heard it before. An interactive quick tutorial you can find here Error inf: You need to install GraphViz (https://graphviz.org) to use this Gem. gem install ruby-graphviz No idea why it doesn’t work. I can open the web with develop-model only but get error when I try to searching the entities. Failed…","link":"/2021/01/28/Bioinfor/dgi_db/"},{"title":"表观基因组介绍","text":"表观基因组介绍 1. DNA 5mC (5-methylcytosine) 6mA (6-Methyladenine) 基因表达调控, 染色体失活,等位基因, 印记基因,胚胎发育, 细胞全能性, 癌症. 1, 细菌防御机制.2, 环境压力, 胚胎发育. 案例: 1. 果蝇 PRE (polycomb response element): 招募组蛋白, H3K27me3, 而达到抑制表达效果 细胞印记: 在果蝇发育转录因子会调节某些蛋白表达, 并甲基化作为记号. 后期, 转录因子不在表达, 有甲基化的记号的基因, 继续表达. 2. 开放染色质区, 于调节蛋白结合, 从而调控表达 MEISI, HOXA9, PUI 2. RNA m6A: 基因表达, 可变剪切, mRNA寿命, 影响翻译m5A 3. 液体活检的应用 cfDNA Methylation 在癌症患者中普遍低通过血液中的 cfDNA Methylation 值, 来逆推器官Methylation 值 4. 发育 Hongshan Gou et al. The DNA methylation landscape of human early embryos. Nature. 2014; 511 Stubbs et al. Multi-tissue DNA methylation age predictor in mouse. Genome Biology. 2017; 18:68. 5. 神经 羟甲基化: 脑部, 神经 6. 测序原理 重亚硫酸盐测序基本原理 WGBS RRBC 随机打碎, 全基因组测序 酶切富集, 高CG区 氧化-重亚硫酸盐测序 转座酶已接近染色质测序 Tn5 转座酶, 接切割富集基因组开放部分(没有与组蛋白结合的DNA) DNA免疫共沉淀","link":"/2020/07/28/Bioinfor/epigenome/"},{"title":"Fasta Sequences Align| Karobben","text":"Fasta Sequences Align Quick look about the data Suppose there is a fasta file name as LYSV-NCBI.fasta Have a quick look grep &quot;&gt;&quot; LYSV-NCBI.fasta |wcwc LYSV-NCBI.fastaecho $(wc LYSV-NCBI.fasta| awk '{print $2}')-$(grep &quot;&gt;&quot; LYSV-NCBI.fasta |wc |awk '{print $2}')|bc 124 1114 836318250 19116 1282572 LYSV-NCBI.fasta18002 As you can see, there are 124 sequences and roughly about 18002 bases Let’s have a quick look at the sequences by Seq-view Seq-view1.3 -i LYSV-NCBI.fasta ClustalW2 Install url: click me wget http://www.clustal.org/download/current/clustalw-2.1.tar.gztar -zxvf clustalw-2.1.tar.gzcd clustalw-2.1/./configuremakemake install clustalw2 -QUICKTREE -OUTPUT=FASTA -INFILE=LYSV-NCBI.fasta It takes less than 20 mins Quick look Seq-view1.3 -i LYSV-NCBI.fasta -a 90 ALign prarmeters UPGAM Tree clustalw2 -QUICKTREE -OUTPUT=FASTA -INFILE=LYSV-NCBI.fasta -CLUSTERING=UPGMA -BOOTSTRAP=1000clustalw2 -QUICKTREE -OUTPUT=FASTA -INFILE=LYSV-NCBI.fasta -CLUSTERING=NJ -BOOTSTRAP=1000 PS: ClustalW well not change the &quot; ’ &quot; from the name of the sequence which may cause trouble in the tree file. Muscle apt install muscletime muscle -in LYSV-NCBI.fasta -out 123.fa real 17m59.470suser 17m59.034ssys 0m0.256s It takes about 18min as well as ClustelW2 Tcoffee Source: 🏠 T-Coffee Protein sequences # Defaultt_coffee sample_seq1.fasta# Quickt_coffee sample_seq1.fasta -mode quickaln# Consistent (M-Coffee combines the most common MSA packages)t_coffee sample_seq1.fasta -mode mcoffee# Structure (Expresso finds structures homologous to your sequences)t_coffee sample_seq1.fasta -mode expresso# Homology (PSI-Coffee enriches your dataset with homologous sequences)t_coffee sample_seq1.fasta -mode psicoffee# Accurate (combines Structures and Homology)t_coffee sample_seq1.fasta -mode accurate DNA sequences # Defaultt_coffee sample_dnaseq1.fasta# Functional (Pro-Coffee increases accuracy of functional DNA regions )t_coffee sample_dnaseq1.fasta -mode procoffee RNA sequences # Defaultt_coffee sample_rnaseq1.fasta# Structure 2D (R-Coffee uses predicted secondary structures)t_coffee sample_rnaseq1.fasta -mode rcoffee# Structure 3D (R-Coffee combined with Consan structural alignments)t_coffee sample_rnaseq1.fasta -mode rcoffee_consan# Accurate (RM-Coffee use M-Coffee and secondary structure predictions)t_coffee sample_rnaseq1.fasta -mode rmcoffee Full Tutorial: 🏠🏠🏠","link":"/2020/07/27/Bioinfor/faAlign/"},{"title":"fastp","text":"Fastp Location: Github Install ## get source (you can also use browser to download from master or releases)git clone https://github.com/OpenGene/fastp.git## buildcd fastpmake## Installsudo make install Just download the build version: wget http://opengene.org/fastp/fastpchmod a+x fastp Bioconda conda install -c bioconda fastp Usage fastp -i in.fq -o out.fq## for paired end data (gzip compressed)fastp -i in.R1.fq.gz -I in.R2.fq.gz -o out.R1.fq.gz -O out.R2.fq.gz Some Examples delete reads with mean score value >= 20 To remove reads with a mean quality score lower than 20 using fastp, you can use the -e option. This option sets the minimum mean quality score required for a read to be kept. If the mean quality score of a read is below this threshold, the read will be discarded. for single end: fastp -i input.fq -o filtered_output.fq -e 20 for paired-ends: fastp -i in1.fq -I in2.fq -o out1.fq -O out2.fq -e 20","link":"/2020/07/28/Bioinfor/fastp/"},{"title":"FastQC","text":"FastQC Quick start mkdir ./fastQC/~/Biosoft/FastQC/fastqc -o ./fastQC/ -t 7 reads.fq","link":"/2020/07/28/Bioinfor/fastqc/"},{"title":"Chip-Seq, from Know to Unknown &#x3D; &#x3D;","text":"CHIP-Seq General infor: CD_Genome.pdf aaaaaaaaaaaaaaaaaaaaaaaaaaaa © wiki ChIP-sequencing, also known as ChIP-seq, is a method used to analyze protein interactions with DNA. ChIP-seq combines chromatin immunoprecipitation (ChIP) with massively parallel DNA sequencing to identify the binding sites of DNA-associated proteins. It can be used to map global binding sites precisely for any protein of interest. Previously, ChIP-on-chip was the most common technique utilized to study these protein–DNA relations.wiki Captures DNA targets for transcription factors or histone modifications across the entire genome of any organism. Defines transcription factor binding sites. Reveals gene regulatory networks in combination with RNA sequencing and methylation analysis. Offers compatibility with various input DNA samples –illumina Library preparation At the day of 2022-09-12, Illumina high light the product: “TruSeq ChIP Library Preparation Kit”. According to their statements, it have a high sensitivity and high compatibility. It requires 5 ng ChIP-derived DNA. Illumina; 2022/09 Data Processing Illumina; 2022/09 suggests using MACS2 to identify enriched regions, and HOMER to discover motifs within these regions. Input: Treatment Samples Control samples Output: Interactive Annotated Peak/Motif Explorer Alignment files (BAMs) Annotation, Peak, and Motif files. Pipeline from CD Genomics Tool Notes Web address Short-read aligners BWA (Burrows-Wheeler Aligner) Fast and efficient; based on the Burrows-Wheeler transform http://bio-bwa.sourceforge.net Bowtie Similar to BWA, part of suite of tools that includes TopHat and CuffLinks for RNA-seq processing http://bowtie-bio.sourceforge.net GSNAP (Genomic Short-read Nucleotide Alignment Program) Considers a set of variant allele inputs to better align to heterozygous sites http://research-pub.gene.com/gmap Wikipedia list of aligners A comprehensive list of available short-read aligners, with descriptions and links to download the software http://en.wikipedia.org/wiki/List_of_ sequence_alignment_software#Short- Read_Sequence_Alignment Peak callers MACS (Model-based Analysis for ChIP-seq) Fits data to a dynamic Poisson distribution; works with and without control data http://liulab.dfci.harvard.edu/MACS PeakSeq Takes into account differences in mappability of genomic regions; enrichment based on FDR (false-discovery rate) calculation http://info.gersteinlab.org/PeakSeq ZINBA (Zero-Inflated Negative Binomial Algorithm) Can incorporate multiple genomic factors, such as mappability and GC content; can work with point-source and broad-source peak data http://code.google.com/p/zinba Pipeline from EncodeProject © ENCODE: Replicated Experiments To be notice EncodeProject list a different pipeline for treating Hitone ChiP-seq and Transcription Factor ChiP-seq. Why different: If you’re looking at transcription factors, then you should use a peak finder like MACS (http://liulab.dfci.harvard.edu/MACS/) to search for enrichment of your TF compared to a background samples such as input or no-ab control. If however, you are profiling a fairly well characterised histone mark such as H3K9ac or H3K4me3 then you can simply count the reads that map near the promoters as a proxy for gene activation/repression. This can be done with Bedtools, © Mark Ziemann, 2015 Tutorials General Information: crazyhottommy; 2015 Tutorial from simonvh, 2018 Tutorial from IGR-lab, 2022 Tutorial from 生信技能树, 2018 Detailed Tutorial from jmzeng1314, 2018 Post analysis by R package: EpigeneticsCSAMA; 2016 More post analysis with bioconductor: brc from rockefeller edu, 2021 Example of ChiP-seq reports from commercial 生工生物： CHIPSEQ 项目报告.pdf ChIP-seq 检测报告 联川生物ChIP-seq 项目结题报告 示范ChIP-Seq结题报告 Part 2; Practice A quick Tutorial from 宸宇卿 Source: Step1 Step2 Environment Settel sra-toolkit: prepare data from NCBI sudo apt install sra-toolkit Data Preparation Prepare directories and Dowload test data mkdir ChiPcd ChiPmkdir Raw_fq# Downlaod data with a for loop.for ((i=593;i&lt;601;i++)) ;do prefetch SRR1042$i ;done# mkdir a new dir for storying our rawdata and split them into two files (Paired ends).mv ~/ncbi/public/sra/SRR1042* Raw_fq/cd Raw_fqfor i in $(ls);do fastq-dump --defline-seq '@$sn[_$rn]/$ri' --split-files $i; done fastp to remove the header and and low quality reads and fastqc to check the quality of the reads, agian. fastp -i in.R1.fg.gz -I in.R2.fg.g -o out.R1.fg.gz -O out.R2.fg.gzfastqc -o outdir -t 6 out.R1.fg.gz out.R2.fg.gz In for loop: rm -rf *.sracd ..mkdir Fastp FastQCfor i in $(ls Raw_fq/*); do SAMPLE=$(echo $i |awk -F&quot;/&quot; '{print $2}') fastp -i $i -o Fastp/$SAMPLE fastqc -o FastQC -t 6 Fastp/$SAMPLEdone Reference Genome NCBIm hg19 mkdir hg19cd hg19wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/405/GCF_000001405.40_GRCh38.p14/GCF_000001405.40_GRCh38.p14_genomic.fna.gz https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/405/GCF_000001405.40_GRCh38.p14/GCF_000001405.40_GRCh38.p14_genomic.gff.gzbwa index GCF_000001405.40_GRCh38.p14_genomic.fna.gzcd .. Map the reads into reference genome By following steps from above, you should get directories like below. Quality trimmed reads are in Fastp. Since they are single ends, we can easily align them into reference genome with less codes then paired one. . ├── Fastp │ ├── SRR1042593_1.fastq │ ├── SRR1042594_1.fastq │ ├── SRR1042595_1.fastq │ ├── SRR1042596_1.fastq │ ├── SRR1042597_1.fastq │ ├── SRR1042598_1.fastq │ ├── SRR1042599_1.fastq │ └── SRR1042600_1.fastq ├── FastQC ├── hg19 └── Raw_fq mkdir BamDB=hg19/GCF_000001405.40_GRCh38.p14_genomic.fna.gzfor i in $( ls Fastp/*); do SAMPLE=$(echo $i|sed 's=Fastp/==;s/_1.fastq//') echo $SAMPLE bwa mem $DB $i -t 6 |samtools view -S -b - |samtools sort &gt; $SAMPLE.sorted.bam samtools index $SAMPLE.sorted.bam mv $SAMPE* Bamdone Insert size. An example of insert size for Chip-seq result. MACS: peak calling Documentation: macs3-project/MACS; github pip install macs3macs3 callpeak -t Bam/SRR1042593.sorted.bam -c Bam/SRR1042598.sorted.bam -f BAM -g hs -n test -B -q 0.01 -g size of the genome. It can be 1.0e+9 or 1000000000, or shortcuts:'hs' for human (2.7e9), 'mm' for mouse (1.87e9), 'ce' for C. elegans (9e7) and 'dm' for fruitfly (1.2e8), Default:hs Results: . ├── test_control_lambda.bdg ├── test_model.r ├── test_peaks.narrowPeak ├── test_peaks.xls ├── test_summits.bed └── test_treat_pileup.bdg Output Log: INFO @ Mon, 26 Sep 2022 11:33:39: # Command line: callpeak -t Bam/SRR1042593.sorted.bam -c Bam/SRR1042598.sorted.bam -f BAM -g hs -n test -B -q 0.01 # ARGUMENTS LIST: # name = test # format = BAM # ChIP-seq file = ['Bam/SRR1042593.sorted.bam'] # control file = ['Bam/SRR1042598.sorted.bam'] # effective genome size = 2.70e+09 # band width = 300 # model fold = [5, 50] # qvalue cutoff = 1.00e-02 # The maximum gap between significant sites is assigned as the read length/tag size. # The minimum length of peaks is assigned as the predicted fragment length \"d\". # Larger dataset will be scaled towards smaller dataset. # Range for calculating regional lambda is: 1000 bps and 10000 bps # Broad region calling is off # Paired-End mode is off INFO @ Mon, 26 Sep 2022 11:33:39: #1 read tag files... INFO @ Mon, 26 Sep 2022 11:33:39: #1 read treatment tags... INFO @ Mon, 26 Sep 2022 11:33:41: 1000000 reads parsed . . . INFO @ Mon, 26 Sep 2022 11:35:12: 50000000 reads parsed INFO @ Mon, 26 Sep 2022 11:35:19: 50255304 reads have been read. INFO @ Mon, 26 Sep 2022 11:35:19: #1 tag size is determined as 51 bps INFO @ Mon, 26 Sep 2022 11:35:19: #1 tag size = 51.0 INFO @ Mon, 26 Sep 2022 11:35:19: #1 total tags in treatment: 16355294 INFO @ Mon, 26 Sep 2022 11:35:19: #1 user defined the maximum tags... INFO @ Mon, 26 Sep 2022 11:35:19: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) INFO @ Mon, 26 Sep 2022 11:35:20: #1 tags after filtering in treatment: 9821254 INFO @ Mon, 26 Sep 2022 11:35:20: #1 Redundant rate of treatment: 0.40 INFO @ Mon, 26 Sep 2022 11:35:20: #1 total tags in control: 50255304 INFO @ Mon, 26 Sep 2022 11:35:20: #1 user defined the maximum tags... INFO @ Mon, 26 Sep 2022 11:35:20: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) INFO @ Mon, 26 Sep 2022 11:35:20: #1 tags after filtering in control: 47926382 INFO @ Mon, 26 Sep 2022 11:35:20: #1 Redundant rate of control: 0.05 INFO @ Mon, 26 Sep 2022 11:35:20: #1 finished! INFO @ Mon, 26 Sep 2022 11:35:20: #2 Build Peak Model... INFO @ Mon, 26 Sep 2022 11:35:20: #2 looking for paired plus/minus strand peaks... INFO @ Mon, 26 Sep 2022 11:35:23: #2 Total number of paired peaks: 5877 INFO @ Mon, 26 Sep 2022 11:35:23: #2 Model building with cross-correlation: Done INFO @ Mon, 26 Sep 2022 11:35:23: #2 finished! INFO @ Mon, 26 Sep 2022 11:35:23: #2 predicted fragment length is 211 bps INFO @ Mon, 26 Sep 2022 11:35:23: #2 alternative fragment length(s) may be 211 bps INFO @ Mon, 26 Sep 2022 11:35:23: #2.2 Generate R script for model : test_model.r INFO @ Mon, 26 Sep 2022 11:35:23: #3 Call peaks... INFO @ Mon, 26 Sep 2022 11:35:23: #3 Pre-compute pvalue-qvalue table... INFO @ Mon, 26 Sep 2022 11:37:56: #3 In the peak calling step, the following will be performed simultaneously: INFO @ Mon, 26 Sep 2022 11:37:56: #3 Write bedGraph files for treatment pileup (after scaling if necessary)... test_treat_pileup.bdg INFO @ Mon, 26 Sep 2022 11:37:56: #3 Write bedGraph files for control lambda (after scaling if necessary)... test_control_lambda.bdg INFO @ Mon, 26 Sep 2022 11:37:56: #3 Pileup will be based on sequencing depth in treatment. INFO @ Mon, 26 Sep 2022 11:37:56: #3 Call peaks for each chromosome... INFO @ Mon, 26 Sep 2022 11:39:10: #4 Write output xls file... test_peaks.xls INFO @ Mon, 26 Sep 2022 11:39:10: #4 Write peak in narrowPeak format file... test_peaks.narrowPeak INFO @ Mon, 26 Sep 2022 11:39:10: #4 Write summits bed file... test_summits.bed INFO @ Mon, 26 Sep 2022 11:39:10: Done! Visual IGV The peak(s) with the best Pvalue. The first track is test_control_lambda.bdg file. the last track is from test_peaks.narrowPeak file. The color of each bar seems corrosponded the P-value. The 5th peak has the lowest p-value and the darkest blue. An example of Unreliable peak. Tow peaks were called based on 3th and 5th but can not be found between 4th and 6th which are biological repeats. ggplot samtools depth Bam/SRR1042593.sorted.bam &gt; SRR1042593.csvsamtools depth Bam/SRR1042598.sorted.bam &gt; SRR1042598.csv library(ggplot2)A &lt;- read.table(&quot;SRR1042593.csv&quot;)A$Sample = &quot;SRR1042593&quot;B &lt;- read.table(&quot;SRR1042598.csv&quot;)B$Sample = &quot;SRR1042598&quot;TB &lt;- rbind(A,B)BED &lt;- read.table(&quot;test_peaks.xls&quot;, header=T)TMP&lt;-TB[TB$V2 %in% c(.9*BED$start[BED$X.log10.pvalue==max(BED$X.log10.pvalue)]:1.1*BED$end[BED$X.log10.pvalue==max(BED$X.log10.pvalue)),]TMP &lt;- TB[TB$V2&gt;= BED$start[BED$X.log10.pvalue==max(BED$X.log10.pvalue)],]TMP &lt;- TMP[TMP$V2&lt;= BED$end[BED$X.log10.pvalue==max(BED$X.log10.pvalue)],]ggplot(TMP, aes(V2, V3)) + geom_bar(stat = 'identity') + facet_grid(~Sample) After Peak calling There is a pipeline echo hello wold hello wold pre { background-color:#38393d; color: #5fd381; }","link":"/2022/09/12/Bioinfor/chipseq/"},{"title":"Extract Fasta from VCF","text":"Extract only a part of genes In this part, we’ll try to extract specific region of sequence from genome and substitute the SNP sites in python Basic Tech: Let’s assume: 1: A → C 4: TAT → TA 5: A → C 10: C → AC,G There are two things we have to highlight: Conflict between 4:TAT and 5: A→C In this situation, we simply select the TA because it can reduce the calculation. 10: C→ AC,G we simply select the first one. import pandas as pdVCF = pd.DataFrame([[1,&quot;A&quot;,&quot;C&quot;], [4, &quot;TAT&quot;, &quot;TA&quot;], [5,&quot;A&quot;,&quot;C&quot;], [10, &quot;G&quot;, &quot;AC,C&quot;]], columns=[&quot;Pos&quot;, &quot;Ref&quot;, &quot;Alt&quot;])STR = 'ATCTATCACGCATAGCTAGCTAGTCA'TB = pd.DataFrame([*STR])TB['Ref'] = &quot;&quot;TB['Alt'] = &quot;&quot;TB.iloc[VCF.Pos-1,1] = VCF.Ref.to_list()TB.iloc[VCF.Pos-1,2] = [i.split(&quot;,&quot;)[0] for i in VCF.Alt.to_list()]TB.head() 0 Ref Alt 0 A A C 1 T 2 C 3 T TAT TA 4 A A C !!! Now, we can fill the blank in Alt with Reference: TB.Alt[TB.Alt==&quot;&quot;] = TB[0][TB.Alt==&quot;&quot;].to_list()TB.head() 0 Ref Alt 0 A A C 1 T T 2 C C 3 T TAT TA 4 A A C !!! Last but not least step is fold the table based on the Ref (Exp, 4:TAT) TB[&quot;Len&quot;] = [len(i)-1 for i in TB.Ref]TB.Len[TB.Len&lt;0]=0TB[&quot;DEL&quot;] = 0TB[&quot;DEL_mark&quot;] = 0TB.DEL =TB.Len.to_list()[:1] +TB.Len.to_list()[:-1]TB.DEL_mark += TB.DELTB.DEL[TB.DEL&gt;1] = TB.DEL_mark[TB.DEL&gt;1]-1while TB.DEL.max()!=0: TB.DEL =TB.DEL.to_list()[:1] +TB.DEL.to_list()[:-1] TB.DEL_mark += TB.DEL TB.DEL[TB.DEL&gt;0] = TB.DEL[TB.DEL&gt;0]-1STR2 = &quot;&quot;.join(TB.Alt[TB.DEL_mark==0].to_list())# Print Alignment resultsfrom Bio.pairwise2 import format_alignmentalignments = pairwise2.align.globalxx(STR, STR2)print(format_alignment(*alignments[0])) A-TCTATCACG-C-ATAGCTAGCTAGTCA |||| ||| | ||||||||||||||| -CTCTA-CAC-ACCATAGCTAGCTAGTCA Score=23 index.js-let strRegExp = '(?&lt;=^\\n)(^!!! *)(note|info|todo|warning|attention|caution|failure|missing|fail|error)(.*\\n)((^ {4}.*\\n|^\\n)+)';+let strRegExp = '(?&lt;=^\\n)(^!!! *)(note|info|todo|warning|attention|caution|failure|missing|fail|error|question)(.*\\n)((^ {4}.*\\n|^\\n)+)'; Why pandas? Because we can now extract any part of sequence based on the annotation information from gtf file. Prepare a csv file which contains the information of location you want: CHROM START END NAME Dirc mitochondrion_genome 1480 2988 COX1 + mitochondrion_genome 3083 3754 COX2 + This script only works on specific example (Drosophila mitochondria Genes in genome V6.39 from Flybase) echo -e &quot;CHROM\\tSTART\\tEND\\tNAME\\tDirc&quot; &gt; Target.csvgrep -i &quot;^mitochondrion_genome&quot; genes.gtf| \\ grep -v transcript_symbol| \\ awk '{OFS=&quot;\\t&quot;; print $1,$4,$5,$12,$7}'| \\ sed 's/[&quot;;]//g' &gt;&gt; Target.csv An script could be like: import gzipimport pandas as pdfrom Bio import SeqIOfrom Bio import pairwise2from Bio.pairwise2 import format_alignmentdef get_vcf_names(vcf_path): with gzip.open(vcf_path, &quot;rt&quot;) as ifile: for line in ifile: if line.startswith(&quot;#CHROM&quot;): vcf_names = [x for x in line.split('\\t')] break ifile.close() return vcf_namesVCF_file = &quot;G1FFH.vcf.gz&quot;Genome = &quot;../Mito.fa&quot;Target = &quot;Target.csv&quot;SAMPLE = VCF_file.replace(&quot;.vcf.gz&quot;, &quot;&quot;)names = get_vcf_names(VCF_file)vcf = pd.read_csv('G1FFH.vcf.gz', compression='gzip', comment='#', header=None, names=names, sep='\\t')TARGET = pd.read_csv(Target, sep='\\t')for seq_record in SeqIO.parse(Genome, &quot;fasta&quot;): if seq_record.id in TARGET.CHROM.unique(): print(&quot;Chrom:&quot;, seq_record.id) TB = pd.DataFrame([*seq_record.seq]) TB['REF'] = &quot;&quot; TB['ALT'] = &quot;&quot; TB.iloc[vcf.POS-1,1] = vcf.REF.to_list() TB.iloc[vcf.POS-1,2] = [i.split(&quot;,&quot;)[0] for i in vcf.ALT.to_list()] TB.ALT[TB.ALT==&quot;&quot;] = TB[0][TB.ALT==&quot;&quot;].to_list() TB.head() TB[&quot;Len&quot;] = [len(i)-1 for i in TB.REF] TB.Len[TB.Len&lt;0]=0 TB[&quot;DEL&quot;] = 0 TB[&quot;DEL_mark&quot;] = 0 TB.DEL =TB.Len.to_list()[:1] +TB.Len.to_list()[:-1] TB.DEL_mark += TB.DEL TB.DEL[TB.DEL&gt;1] = TB.DEL_mark[TB.DEL&gt;1]-1 while TB.DEL.max()!=0: TB.DEL =TB.DEL.to_list()[:1] +TB.DEL.to_list()[:-1] TB.DEL_mark += TB.DEL TB.DEL[TB.DEL&gt;0] = TB.DEL[TB.DEL&gt;0]-1 TMP = TB.ALT[TB.DEL_mark==0] F = open(SAMPLE + &quot;_&quot; + seq_record.id +&quot;.fa&quot;, &quot;w&quot;) F.close() F = open(SAMPLE + &quot;_&quot; + seq_record.id +&quot;.fa&quot;, &quot;a&quot;) LIST = [] for i in range(len(TARGET[TARGET.CHROM==seq_record.id])): FROM =TARGET.START[TARGET.CHROM==seq_record.id][i] END = TARGET.END[TARGET.CHROM==seq_record.id][i] print(FROM,END) STR1 = &quot;&quot;.join(TB[0][TB.index.isin(range(FROM-1,END))].to_list()) STR2 = &quot;&quot;.join(TMP[TMP.index.isin(range(FROM-1,END))].to_list()) F.write(&quot;&gt;&quot;+TARGET.NAME[TARGET.CHROM==seq_record.id][i] + &quot;_&quot; + SAMPLE + &quot;\\n&quot; + STR2 + &quot;\\n&quot; ) LIST += range(FROM-1,END) #F.write(&quot;&gt;NonHit_&quot; + SAMPLE + &quot;\\n&quot; + &quot;&quot;.join(TMP[~TMP.index.isin(LIST)]) + &quot;\\n&quot; ) F.close() reference: d.vitale199, 2021, how to read the VCF files with python pandas. This script was uploaded into GitHub:Karobben/Bio_tools A demo would be like: python vcf2fasta.py -g Genome.fa -v File.vcf.gz -t Target.csv Other Methods For a whole chromosome vcf2fasta rlebron88, 2016 git clone https://github.com/rlebron88/vcf2fasta.gitpython vcf2fasta/vcf2fasta.py -v &lt;VCF file from the sample&gt; -f &lt;reference FASTA file&gt; -o &lt;FASTA file from the sample&gt; Limitations: ONLY ONE SEQUENCE/CHROMOSOME PER VCF. USE “X” TO REFER TO THE SEQUENCE OF REF IN THE VCF FILE. IF THERE IS MORE THAN ONE ALT, THE FIRST IS USED. DO NOT USE multiFASTA. vcftools MatthewP, 2018: vcftools has a command vcf-consensus which can convert VCF to FASTA file if you got the reference bgzip -c file.vcf &gt; file.vcf.gztabix -fp vcf file.vcf.gzcat Reference.fasta | vcf-consensus file.vcf.gz &gt; file.fa Python scripts Python Scripts: – Didn’t be test. Peal scripte: – Didn’t be test. Python code from Jared Andrews, 2017: consensus = FastaVariant('yourgenome.fasta', 'variants.vcf.gz', het=True, hom=True)out = open(&quot;variants.fasta&quot;, &quot;w&quot;)for chrom in consensus.keys: for var in consensus[chrom].variants_sites: record = consensus[chrom][var-1:var] print(record, file=out)out.close() pre { background-color:#38393d; color: #5fd381; }","link":"/2022/09/16/Bioinfor/fastafromvcf/"},{"title":"Genome Annotation","text":"Extract Genes from Non-annotated Genome For de-novo assembled genomes, gtf from reference genome is not match the position of de-novo genomes because there are many novel deletions, insertions, etc. So, we can not using than to locate genes, introns, or extrons. There are a few things we can achieve this goal: genome annotation align the reference genes into your genome call them from the vcf file directly Call genes from VCF file This is the trickiest way. Because if we have the variation files, we can call the genes based on the location of reference gtf. And we even don’t need to assemble our genomes. Cons: - We have only SNP information - Structure variation like inversion and duplication cannot be found. Genome Annotation One of easiest way to extract genes from non-annotated Genome is annotate it. MITOS WebServer. In this server, you just need to submit your fasta file and wait. A quick test of mitochondria genome shows it can not only annotate genes, but also annotate tRNA: Name Start Stop Strand Length Structure trnI(atc) 1 65 + 65 svg ps nad5-1_a 58 120 + 63 trnQ(caa) 97 165 - 69 svg ps trnM(atg) 171 239 + 69 svg ps svg are secondary structure of the tRNA. By compaired with the reference gtf file, the general quality f this annitations is good. tRNA prediction has a very high positive ratio. Most of genes were annotated as well as tRNAs. You can download the BED fiel, GFF file, or other type of annotation formats. All annotated genes: pre { background-color:#38393d; color: #5fd381; }","link":"/2022/09/16/Bioinfor/genefromgenome/"},{"title":"Build A Personal BioDatabase with Mysql","text":"Build A Personal BioDatabase with Mysql This is my first time to try build a Database on my own. I’m recording my experience and the structure of this database here in order to prevent me from forgetting how to retrieve or update the data in it. Before doing this, I spend a few hours to taught myself about Mysql and recorded all my notes at blog Please feel free to check the Mysql grammar before running codes below if you are an newbies like me. I’ll start to do this with few questions: Why I’d like to build a database What I database I’d like to have Which features does this DB will have Why and What Generally, I am writing a paper about the diet-switch experiment which has a few RNA-seq data-set. It could give me a great help if there is a database which targeted to the diet-gene interaction. But, I can’t find a one. Though, I know that gene regulated by nutrition effect could mostly contributed to of the effects like immune system depress, stress response, etc. But it do help researches focusing the interactions they may interested rather than searching blindly among more than 20 thousands of genes from RNA-seq or other high-throughput results. So, I decided to write a database which target to the how the genes responded to nutrition effects. Due to the limited of the experience and capability, I’ll store the well verified and reliable data, WB and qPCR for instance, only and maybe I’ll considerate the NGS data in the feature. It could be very fun to deal with large quantity of data, you know, as a user, definitely not a manager. Which At present, I think there are few separate tables I’d like to have Species (KEGG Organisms: has (I just like this elegant abstract)) Species Taxonomy (A complex-version like NCBI taxonomy or sample version like KEGG Organisms?) Gene Annotation (I’ll try, at least.) Other IDs GO entry Kegg ID Kegg map Food entities (not too much experience about that. But the name will basically based on the paper) Regulation Net Gene Annotation table This is one of the most important table since the clarity of entities is pretty important for gene-related database since a common gene could have to many names. Gene Annotation At present, I’d like the gene has the entities like below: (mostly contributed by uniprot database) UniProtID: P04637 UniprotName: P53_HUMAN Gene name: P53 Organism: Homo sapiens (Human) Function: Acts as a tumor suppressor in many tumor type… GO-Molecular-function: ATP binding;chaperone binding… GO-Biological-process: autophagy;B cell lineage commitment KEGG: hsa7157 (https://www.genome.jp/dbget-bin/www_bget?hsa:7157) KEGG maps: hsa01522;hsa01524;hsa04010… Diet protocol Diet id Diet name Diet Protocol Citation Regulation Diet id Diet_secular (Soy protein) Diet_specific () Diet_SN () Specious Specious_muta Genes Ratio (up/down) Experiment (WB/qPCR/NGS) Codes Create DB CREATE DATABASE IF NOT EXISTS `fgidb`;USE fgidb;-- Create a tableCREATE TABLE regulation_net( Diet_id INT NOT NULL AUTO_INCREMENT, Diet_secular VARCHAR(100), Diet_specific VARCHAR(100), Diet_SN VARCHAR(100), Specious VARCHAR(100), Organs VARCHAR(100), Specious_muta VARCHAR(100), Morphology VARCHAR(1000), Genes VARCHAR(100), Ratio VARCHAR(100), Validation VARCHAR(100), Citation VARCHAR(1000), submission_date VARCHAR(1000), PRIMARY KEY ( Diet_id ) )ENGINE=InnoDB DEFAULT CHARSET=utf8;INSERT INTO regulation_net (Diet_secular, Specious,Specious_muta, Genes, Morphology, submission_date ) VALUES (&quot;Fish Oil&quot;, 'mmu', 'C57BL/6J Mice', 'CPT1A_MOUSE', 'Upregulates Intestinal Lipid Metabolism; Reduces Body Weight Gain' , NOW());SELECT * from regulation_net WHERE Diet_id=1;UPDATE regulation_net SET Citation='Dietary Fish Oil Upregulates Intestinal Lipid Metabolism and Reduces Body Weight Gain in C57BL/6J Mice' WHERE Diet_id=1; INPUT and OUTPUT Input -- insert and replaceDROP TABLE regulation_tmp;CREATE TABLE regulation_tmp( Diet_id INT NOT NULL AUTO_INCREMENT, Diet_secular VARCHAR(100), Diet_specific VARCHAR(100), Diet_SN VARCHAR(100), Specious VARCHAR(100), Specious_muta VARCHAR(100), Morphology VARCHAR(1000), Genes VARCHAR(100), Ratio VARCHAR(100), Validation VARCHAR(100), Citation VARCHAR(1000), subm VARCHAR(100), PRIMARY KEY ( Diet_id ) )ENGINE=InnoDB DEFAULT CHARSET=utf8;LOAD DATA INFILE '/var/lib/mysql-files/regulation_net.csv' REPLACEINTO TABLE regulation_netFIELDS TERMINATED BY ','OPTIONALLY ENCLOSED BY '&quot;'LINES TERMINATED BY '\\n';SELECT * FROM regulation_netUNION ALLSELECT * FROM regulation_tmpORDER BY Diet_id; output -- output as csvSELECT * FROM regulation_net;SELECT * INTO OUTFILE '/var/lib/mysql-files/regulation_net.csv'FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '&quot;'LINES TERMINATED BY '\\n'FROM regulation_net;","link":"/2021/01/31/Bioinfor/food_gene_db/"},{"title":"Short reads aligner compartment","text":"Introduction BWA Burrows-Wheeler Aligner According to the Documentation BWA is a software package for mapping low-divergent sequences against a large reference genome, such as the human genome. It consists of three algorithms: BWA-backtrack, BWA-SW and BWA-MEM. BWA-backtrack: It is designed for Illumina sequence reads up to 100bp, BWA-MEM: BWA-MEM and BWA-SW share similar features such as long-read support (70bp to 1Mbp) and split alignment. It is generally recommended for high-quality queries as it is faster and more accurate. It also has better performance than BWA-backtrack for 70-100bp Illumina reads. QS There are three algorithms, which one should I choose? For 70bp or longer Illumina, 454, Ion Torrent and Sanger reads, assembly contigs and BAC sequences, BWA-MEM is usually the preferred algorithm. For short sequences, BWA-backtrack may be better. BWA-SW may have better sensitivity when alignment gaps are frequent. What is the tolerance of sequencing errors? Bwa-back is mainly designed for sequencing error rates below 2%. WA-SW and BWA-MEM both tolerate more errors given longer alignment. Simulation suggests that they may work well given 2% error for an 100bp alignment, 3% error for a 200bp, 5% for 500bp and 10% for 1000bp or longer alignment. Does BWA find chimeric reads? Yes, both BWA-SW and BWA-MEM are able to find chimera. BWA usually reports one alignment for each read but may output two or more alignments if the read/contig is a chimera. Does BWA work on reference sequences longer than 4GB in total? Yes. Since 0.6.x, all BWA algorithms work with a genome with total length over 4GB. However, individual chromosome should not be longer than 2GB. PS chimeric reads: Chimeric reads occur when one sequencing read aligns to two distinct portions of the genome with little or no overlap. Chimeric reads are indicative of structural variation. Chimeric reads are also called split reads. After aligning with bwa mem, chimeric reads will have an SA tag as described on page 7 of the SAM format specification. To find them all you have to do is extract them using grep. donfreed, 2014. In the documentation, it mentioned that bwa aln is for find the SA reads. Bowtie2 Bowtie 2 is an ultrafast and memory-efficient tool for aligning sequencing reads to long reference sequences. It is particularly good at aligning reads of about 50 up to 100s or 1,000s of characters, and particularly good at aligning to relatively long (e.g. mammalian) genomes. Bowtie 2 indexes the genome with an FM Index to keep its memory footprint small: for the human genome, its memory footprint is typically around 3.2 GB. Bowtie 2 supports gapped, local, and paired-end alignment modes. What isn’t Bowtie 2? Bowtie 2 is geared toward aligning relatively short sequencing reads to long genomes. That said, it handles arbitrarily small reference sequences (e.g. amplicons) and very long reads (i.e. upwards of 10s or 100s of kilobases), though it is slower in those settings. It is optimized for the read lengths and error modes yielded by typical Illumina sequencers. Bowtie 2 does not support alignment of colorspace reads. (Bowtie 1 does.) Documentation Bowtie2 could awareness splicing because it cut reads into even shorter before doing alignment. PS What is colorspace reads: Short answer: color space refers to the native format of ABI SoLID technology. Color space is translated to nucleotide, or base space (same thing) so that it can be understood. That technology is not growing in market share, so in the next few years it will become less common. ABI is putting most of their effort behind the Ion Torrent now. swbarnes2, 2012 Test Data >1_Perfect_match TAATTCCCAAGATGAAGTTCCTGATCATCCTTGCCCTGGCTGTGGCCGCC >2_Intron_insertion TAATTCCCAAGATGAAGTTCCTGATTGCTGATCGATCGTAGCTAGCTAGCTAGCTAGCTAGCTACGTGCATCAGTCGATCAGTACGTCAGATGCTGTCGATCGTAGTCGATCGATGCTAGCTAGCTAGCTGCATAGTAGCTGCATGCTAGCTGCTAGCTCAGTAGCTCGTGCATGCATGCATCATCCTTGCCCTGGCTGTGGCCGCC >3_Intron_insertion TAATTCCCATGCTGATCGTGACTGCTGATCGATCGTGCTAGTCGATGCTCGTGCATGCTGCATGCTAGCTAGCTAGCTGACTGATCGTACGTCAGTGCATGCATGCTAGCTAGTAGCTAGCTAGCTAGCTCAGTCAGTCAGTCGATCGATGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGTCGATGCTAGCTAGCTAGCTCAGTCAGTAGCTCAGTCGAGCTGTGTGTGCTAGCACTACGTGTCGATGTGTCAGTAGATGAAGTTCCTGATCATCCTTGCCCTGGCTGTGGCCGCC >4_Cross_Chrm_L TAATTCCCAAGATGAAGTTCCTGATTGCTGATCGATCGTAGCTAGCTAGCTAGCTAGCTAGCTACGTGCATCAGTCGATCAGTACGTCAG >5_Cross_Chrm_R ATGCTGTCGATCGTAGTCGATCGATGCTAGCTAGCTAGCTGCATAGTAGCTGCATGCTAGCTGCTAGCTCAGTAGCTCGTGCATGCATGCATCATCCTTGCCCTGGCTGTGGCCGCC >6_Small_deletion_3 TAATTCCCAAGATGAAGTTCCTATCCTTGCCCTGGCTGTGGCCGCC >6_deletion_10 TAATTCCCAAGATGAAGTTCTTGCCCTGGCTGTGGCCGCC >6_deletion_20 TAATTCCCAAGATGAAGTTCTGTGGCCGCC >7_Samll_insertion_3 TAATTCCCAAGATGAAGTTCCTGATGATCATCCTTGCCCTGGCTGTGGCCGCC >8_SNP TAATTCCCAAGATGAAGTTCCTGATTATCCTTGCCCTGGCTGTGGCCGCC Build reference DB (index) module load trinity/2.8.5module load bwamodule load bowtie2module load rsemfor i in $(grep &quot;&gt;&quot; Ref.fa|sed 's/&gt;//'); do grep -A 1 $i Ref.fa &gt; $i.fa; donefor i in $(ls *.fa);do bwa index $i bowtie2-build $i $i bowtie-build $i $idone Aligning for i in $(ls DB/*.fa) do SAMPLE=$(echo $i| sed 's=DB/=='); bwa mem $i test.fq | grep -v ^@ &gt; $SAMPLE.bwa.sam bowtie2 -x $i -U test.fq|grep -v ^@ &gt; $SAMPLE.bowtie2.sam bowtie $i test.fq|grep -v ^@ &gt; $SAMPLE.bowtie.samdonegrep . *.sam| sed 's/.sam:/\\t/'|awk -F&quot;\\t&quot; '{print $1&quot;\\t&quot;$4}' | awk -F&quot;.&quot; '{print $1&quot;\\t&quot;$NF}'&gt; Result Results Format of sam file: A00327:224:HW2JVDRXY:1:1101:1253:1000 0 1_Perfect_match 1 60 50M * 0 0 TAATTCCCAAGATGAAGTTCCTGATCATCCTTGCCCTGGCTGTGGCCGCC #FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF NM:i:0 MD:Z:50 AS:i:50 XS:i:0 Columns Abbr. Exp Describe 1 QNAME A003… Query (pair) NAME 2 FLAG 0 bitwise FLAG 3 RNAME 1_Perfect_match Reference sequence NAME 4 POS 1 1-based leftmost POSition/coordinate of clipped sequence 5 MAPQ 60 MAPping Quality (Phred-scaled) 6 CIAGR 50M extended CIGAR string 7 MRNM * Mate Reference sequence NaMe (‘=’ if same as RNAME) 8 MPOS 0 1-based Mate POSistion 9 ISIZE 0 Inferred insert SIZE 10 SEQ TAAT… query SEQuence on the same strand as the reference 11 QUAL FFFF… query QUALity (ASCII-33 gives the Phred base quality) 12 OPT NM:i:0 MD:Z:50 AS:i:50 XS:i:0 variable OPTional fields in the format TAG:VTYPE:VALUE Reference bowtie2 bowtie bwa 1_Perfect_match 1_Perfect_match 1_Perfect_match 1_Perfect_match 2_Intron_insertion * NA * 3_Intron_insertion * NA 3_Intron_insertion 4_Cross_Chrm_L * NA * 5_Cross_Chrm_R * NA * 6_deletion_10 * NA * 6_deletion_20 * NA * 6_Small_deletion_3 6_Small_deletion_3 NA 6_Small_deletion_3 7_Samll_insertion_3 7_Samll_insertion_3 NA 7_Samll_insertion_3 8_SNP 8_SNP 8_SNP 8_SNP Ref 1_Perfect_match 1_Perfect_match 1_Perfect_match Aligning Reads with Multiple Hits Using Bowtie2 By default, Bowtie2 reports only one alignment (the best one) for each read. However, you can configure it to report multiple alignments using the -k or -a options: k : Report up to alignments per read (useful for getting multiple alignments if they exist). a: Report all valid alignments (this can produce a large output if there are many alignments). Example command to report up to 5 alignments per read: bowtie2 -x index -U reads.fq -k 5 -S output.sam TopHat Unlike BWA and bowtie2, TopHat is a intron awareness aligner. It not only automatically split mapped and unmapped bam, but also given variation results like ‘junction’, ‘deletion’, and ‘insertion’ bed files. But the align performance of TopHat2 is not optimistic from some comparison. column name of 'junction.bed': [seqname] [start] [end] [id] [score] [strand] [thickStart] [thickEnd] [r,g,b] [block_count] [block_sizes] [block_locations] &quot;seqname&quot;: chromosome &quot;start&quot;: is the start position of the leftmost read that contains the junction. &quot;end&quot;: is the end position of the rightmost read that contains the junction. &quot;id&quot;: is the junctions id, e.g. JUNC0001 &quot;score&quot;: is the number of reads that contain the junction. &quot;strand&quot;: is either + or -. &quot;thickStart&quot; and &quot;thickEnd&quot;: don't seem to have any effect on display for a junctions track. TopHat sets them as equal to start and end respectively. &quot;r.g.b&quot;: &quot;r&quot;,&quot;g&quot; and &quot;b&quot; are the red, green, and blue values. They affect the colour of the display. &quot;block_count&quot;: The block_count will always be 2. The two blocks specify the regions on either side of the junction. &quot;block_sizes&quot;: &quot;block_sizes&quot; tells you how large each region is. &quot;block_locations&quot;: it tells you, relative to the &quot;start&quot; being 0, where the two blocks occur. Therefore, the first block_location will always be zero. from: Alex124, 2012 basic use: tophat -G sample.gtf -p 40 -o output_dir Genome.bowtie2.index Sample.fq.gz More infor for bed fromat: UCSC Hisat2 hisat2 -x indexed_genome -p 40 -U sample.fq.gz | samtools view -S -b - &gt; result.bam Others Ryan Musich, et al using 48 fubgi’s RNA-seq samples, Erysiphe necator, to compare the results of aligners bowtie2, bwa, hisat2, Mummer4, star, and tophat2. They found that bowtie2 and bwa have less unmapped reads. TopHat2 is the worst which has arround 80% unmapped reads. Bowtie2 and bwa have a similar positive result but bwa consume much less time. © Ryan Musich, et al., 2021 Grzegorz M. Boratyn, et al. developed a new tool Magic-BLAST for improving the accuracy of RNA-seq reads aligning. They compared the © Grzegorz M. Boratyn, et al. pre { background-color:#38393d; color: #5fd381; }","link":"/2022/09/25/Bioinfor/fq-aligner/"},{"title":"Immunoglobulin BLAST (Igblast), a Blast Tool Specific for Antibodies","text":"Key Features of IgBLAST Identification of V(D)J segments: IgBLAST can identify variable (V), diversity (D), and joining (J) gene segments in IG or TCR sequences. Clonotype Analysis: It helps in determining clonotypes based on V(D)J segment usage, providing insights into the diversity and clonality of IG or TCR repertoires. Somatic Hypermutation Analysis: It identifies somatic hypermutations in IG sequences and can compare these to germline sequences, which is critical in understanding adaptive immune responses. Flexible Input Options: IgBLAST can process both nucleotide and protein sequences, and it supports various input formats. Detailed Alignment Information: It provides detailed alignment results that include information about gene segments, framework regions, complementarity-determining regions (CDRs), and mutations. Integration with Other Databases: The results can be linked to other NCBI databases for additional information and analysis. IgBLAST is widely used in immunology and related fields for studying B cell and T cell receptor repertoire, which is crucial for understanding immune responses, vaccine development, and in the study of autoimmune diseases and cancer. Local Set Up Basically, you can use the online service: NCBI igblast Set up by following the official documentation: NCBI igblast set up Here is an example of set up by using conda from nicwulab/SARS-CoV-2_Abs conda create -n Abs -c bioconda \\ python=3.9 \\ igblastconda activate Abs# install pyir and use it to set up the blast databasepip3 install crowelab_pyirpyir setup Error in setup During handling of the above exception, another exception occurred: Traceback (most recent call last): File \"/mnt/Data/PopOS/miniconda/envs/bio311/lib/python3.11/site-packages/crowelab_pyir/data/bin/setup_germline_library.py\", line 112, in for line in urllib.request.urlopen(locus_url): ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ . . . urllib.error.URLError: In the pyir, it is using 'http' and download the data failed. By following the error code, we could find the script and alter the 'http' to 'https'. It should solving the problem. In this case, I high light the most important part in the error code with red. For make a quick correction, we could run: sed -i 's/http:/https:/g' /mnt/Data/PopOS/miniconda/envs/bio311/lib/python3.11/site-packages/crowelab_pyir/data/bin/setup_germline_library.py prepare the DataBase run the blast igblastn -query result/test.fasta \\ -germline_db_V imgt_database/human_nuc/IGV.fasta \\ -germline_db_J imgt_database/human_nuc/IGJ.fasta \\ -germline_db_D imgt_database/human_nuc/IGD.fasta \\ -organism human -domain_system kabat \\ -auxiliary_data imgt_database/optional_file/human_gl.aux \\ -out result/igblast_output -germline_db_V Germline database name -organism The organism for your query sequence. Supported organisms include human, mouse, rat, rabbit and rhesus_monkey for Ig and human and mouse for TCR. Custom organism is also supported but you need to supply your own germline annotations (see IgBLAST web site for details) Default = `human' pyir If you installed pyir, we could use the pyir to do the igblast with less parameters. pyir -m 60 result/clean_split.fa --outfmt tsv -o result/clean Key parameters: --sequence_type {nucl,prot} default: nucl -m MULTI, --multi MULTI Number of threads -o, --out default: inputfile.json.gz --outfmt {tsv,lsjson,dict,json} suggest: tsv --igdata IGDATA Path to your IGDATA directory. -r, --receptor {Ig,TCR} The receptor you are analyzing, immunoglobulin or t cell receptor -s, --species {human,mouse...} The Species you are analyzing {human,mouse,rabbit,rat,rhesus_monkey} Q&amp;A Can I annotate the light chain and heavy chain simultaneously? IgBLAST is designed to analyze immunoglobulin (IG) sequences, including both heavy and light chains. However, it typically processes and analyzes these chains separately. When you input a sequence that contains both heavy and light chains, IgBLAST might only process the first recognizable sequence, which in your case appears to be the heavy chain. To analyze both heavy and light chains using IgBLAST, you generally need to input them as separate sequences. This means splitting your combined sequence into two parts - one for the heavy chain and the other for the light chain - and then running IgBLAST for each part individually. There isn't a parameter in IgBLAST that allows for the simultaneous analysis of both heavy and light chains when they are combined into a single sequence. The tool's algorithm is designed to identify and annotate the V(D)J segments of a single chain at a time, as the structure and sequence features of heavy and light chains are distinct. If you are consistently working with sequences that contain both chains, you may need to develop a preprocessing step in your workflow to separate these chains before analysis. Alternatively, if such a tool is essential for your work, you might need to look into other bioinformatics tools or custom scripting to first identify and separate the heavy and light chain sequences before feeding them into IgBLAST. pre { background-color:#38393d; color: #5fd381; }","link":"/2023/12/21/Bioinfor/igblast/"},{"title":"Gene Set Enrichment Analysis (GESA) in R","text":"How it works and why it matters Here is an example explained by ChatGPT Suppose we have a gene expression dataset consisting of 6 genes (A, B, C, D, E, and F) and 3 samples (S1, S2, and S3), and we want to test whether a pre-defined gene set called “MySet” is enriched in this dataset. Here’s the dataset: Gene S1 S2 S3 A 1 2 1 B 2 4 1 C 3 6 2 D 4 8 3 E 1 2 1 F 2 4 1 The first step in GSEA is to rank the genes based on their correlation with the phenotype of interest. In this example, we will use the sum of expression values across samples as the phenotype. The ranked list of genes based on this phenotype is: Gene Rank D 15 C 11 B 7 F 7 A 4 E 4 The second step is to calculate an enrichment score for the gene set “MySet” by walking down the ranked list of genes, and computing a running sum of the signed correlation between each gene and the phenotype. If a gene is in “MySet”, its correlation is positive; otherwise, it is negative. The enrichment score is the maximum deviation from zero of the running sum. Here’s the calculation: Gene Rank In MySet? Correlation Running Sum D 15 No -1 -1 C 11 No -1 -2 B 7 Yes +1 -1 F 7 Yes +1 0 A 4 Yes +1 1 E 4 No -1 0 The maximum deviation from zero of the running sum is 1, which occurs at gene A. Therefore, the enrichment score for “MySet” is 1. This example demonstrates the basic steps of GSEA, but in practice, GSEA is often applied to much larger datasets and gene sets, and the significance of the enrichment score is assessed using statistical tests such as permutation tests or gene set permutation tests. GESA In clusterProfiler, there are functions designed to do GESA based on GO and KEGG gene sets. Here I am trying to show you how to do GESA with your customized data set. There are two main functions which are GSEA from clusterProfiler and fgsea from fgsea. A quick enrichment analysis could be done by example data. library(clusterProfiler)library(plyr)library(fgsea)# loading example data setdata(examplePathways)data(exampleRanks)fgseaRes &lt;- fgsea(examplePathways, exampleRanks, nperm=1000, maxSize=500, minSize = 10))TERM2GENE = ldply(examplePathways, data.frame)gse &lt;- GSEA(gene = rev.default(exampleRanks) , TERM2GENE = TERM2GENE)#gseaplot(gse, by = &quot;all&quot;, title = gse$Description[1], geneSetID = 1) Default Parameters for Two Functions fgsea GSEA fgsea( pathways, stats, nperm, minSize = 1, maxSize = Inf, nproc = 0, gseaParam = 1, BPPARAM = NULL) GSEA( geneList, exponent = 1, nPerm = 1000, minGSSize = 10, maxGSSize = 500, pvalueCutoff = 0.05, pAdjustMethod = &quot;BH&quot;, TERM2GENE, TERM2NAME = NA, verbose = TRUE, seed = FALSE, by = &quot;fgsea&quot;) Check the Results from Tow Functions List &lt;- gse$Description[c(1,30,100)]gse[gse$Description %in% List]fgseaRes[fgseaRes$pathway %in% List,] Description setSize enrichmentScore NES pvalue p.adjust qvalues rank leading_edge 5991611_Processive_synthesis_on_the_C-strand_of_the_telomere 11 0.747047513123146 1.92204468456492 0.00374531835205993 0.0280713464604887 0.0209222578082764 2110 tags=82%, list=18%, signal=67% 5990978_M_G1_Transition 63 0.578846390178477 2.27421327922627 0.00154320987654321 0.0161091249574396 0.012006522946795 1970 tags=48%, list=16%, signal=40% 5991851_Mitotic_Prometaphase 82 0.725326964773323 2.96349021486606 0.0015527950310559 0.0161091249574396 0.012006522946795 1042 tags=54%, list=9%, signal=49% pathway pval padj ES NES nMoreExtreme size 5991611_Processive_synthesis_on_the_C-strand_of_the_telomere 0.001865672 0.0307185 0.7470475 1.919031 0 11 5990978_M_G1_Transition 0.001545595 0.0307185 0.5788464 2.236994 0 63 5991851_Mitotic_Prometaphase 0.001492537 0.0307185 0.7253270 2.976492 0 82 According to the comparison from above, their p-values are similar. But GSEA has a smaller p.adjust. Other wise, Enrichment score and NES are the same. Number of results length(examplePathways)nrow(fgseaRes)nrow(GSEA(gene = rev.default(exampleRanks) , TERM2GENE = TERM2GENE, pvalueCutoff = 1)@result) [1] 1457 [1] 757 [1] 757 In this result, we can find that the number of results is the same. Some of the gene sets are filtered out because of their size. Result visualization Both two packages have functions for Visualizing their results. Function plotEnrichment is more friendly to customized data. What a surprise is it has plotGseaTable function which from fgsea could show multiple results in a table-like panel. Though this graphic is not fancy but could be very helpful in some situations. gseaplot(gse, geneSetID = &quot;5991851_Mitotic_Prometaphase&quot;)plotEnrichment(examplePathways[['5991851_Mitotic_Prometaphase']], exampleRanks)# Example of using gse result# plotEnrichment(gse@geneSets[['5991851_Mitotic_Prometaphase']], exampleRanks)plotGseaTable(examplePathways[List], exampleRanks, fgseaRes, gseaParam=0.5) gseaplot from clusterProfiler plotEnrichment from fgsea Check the Data Formats and Fabric a group of GeneList &amp; GeneSets exampleRanks: 170942 109711 18124 12775 72148 16010 -63.33703 -49.74779 -43.63878 -41.51889 -33.26039 -32.77626 examplePathways: $`186589_Late_stage_branching_morphogenesis_pancreatic_bud_precursor_cells` [1] \"11925\" \"15205\" \"21410\" \"246086\" The above two lists show a quick view of example data. exampleRanks is an increasing/decreasing numeric vector. examplePathways is a list that contains the name of each set and genes under each set. An example of generating your own data: set.seed(1)GeneList &lt;- sample(seq(-100,100,0.01), 100)names(GeneList) &lt;- paste(&quot;Gene&quot;, c(1:100), sep=&quot;_&quot;)GeneSet &lt;- append(list(names(GeneList)[1:50]), list(names(GeneList)[40:100]))names(GeneSet) &lt;- c(&quot;Set1&quot;, &quot;Set2&quot;)# List table for clusterProfilerTERM2GENE_exp = ldply(GeneSet, data.frame)# Sort the GeneListGeneList &lt;- sort(GeneList, decreasing = T)fgseaRes &lt;- fgsea(GeneSet, GeneList, nperm=1000, maxSize=500, minSize = 10)gse &lt;- GSEA(gene = GeneList , TERM2GENE = TERM2GENE_exp, pvalueCutoff = 1) pathway pval padj ES NES nMoreExtreme size Set1 0.845140032948929 0.980519480519481 0.20117826706011 0.764831637359588 512 50 Set2 0.980519480519481 0.980519480519481 0.156182133808093 0.582211034023132 603 61 Description setSize enrichmentScore NES pvalue p.adjust qvalues rank leading_edge Set1 50 0.20117826706011 0.750929659683889 0.834633385335413 0.971742543171115 0.971742543171115 34 tags=38%, list=34%, signal=50% Set2 61 0.156182133808093 0.586558400598972 0.971742543171115 0.971742543171115 0.971742543171115 18 tags=18%, list=18%, signal=38% Enrichment Plot library(enrichplot)gseaplot2(gse, geneSetID = 1, title = gse$Description[1], color = 'salmon', pvalue_table = TRUE)gseaplot2(gse, geneSetID = 1:7, title = &quot;GSEA&quot;, color = 'salmon', pvalue_table = TRUE) geneSetID = 1 geneSetID = 1:7 What is nPerm The nominal p value estimates the statistical significance of the enrichment score for a single gene set. However, when you are evaluating multiple gene sets, you must correct for gene set size and multiple hypothesis testing. Because the p value is not adjusted for either, it is of limited value when comparing gene sets. The FDR is adjusted for gene set size and multiple hypotheses testing while the p value is not. When a top gene set has a small nominal p value and a high FDR value, it generally indicates that it is not as significant when compared with other gene sets in the empirical null distribution. This could be because you do not have enough samples, the biological signal is subtle, or the gene sets do not represent the biology in question very well. On the other hand, the FDR is based on two distributions of all gene sets; if only one of many gene sets is enriched, that gene set is likely to have a high FDR. Finally, a top gene set with a high nominal p value and a low FDR value, generally indicates a negative result: the gene set itself is not significant and other sets are weaker. In the GSEA report, a p value of zero (0.0) indicates an actual p value of less than 1/number-of-permutations. For example, if the analysis performed 100 permutations, a reported p value of 0.0 indicates an actual p value of less than 0.01. For a more accurate p value, increase the number of permutations performed by the analysis. Typically, you will want to perform 1000 permutations (phenotype or gene_set). (If you attempt to perform significantly more than 1000 permutations, GSEA may run out of memory.) From: © gsea-msigdb.org More FAQ could be found at: software.broadinstitute.org Other things you need to know ES (enrichment score): reflects the degree to which a gene-set is overrepresented at the top or bottom of a ranked list of genes. NES (normalized enrichment score): NES corrects for differences in ES between gene-sets due to differences in gene-set sizes. It enables to compare the scores of the different tested gene-sets with each other. NES = actual ES / mean of all ESs obtained from all random permutations for the single gene-set that is being tested nom p-value: The nominal p value estimates the statistical significance of the enrichment score for a single gene set. The p-value is calculated from the null distribution. Using gene-set permutation, the null distribution is created by generating, for each permutation, a random gene set the same size as your specified gene set by selecting that number of genes from all of the genes in your expression data set (or pre-ranked list), and then calculating the enrichment score for that randomly selected gene set. The distribution of those enrichment scores across all of the permutations constitutes the null distribution. FDR: corrects for multiple hypothesis testing and enable a more correct comparison of the different tested gene-sets with each other. note: for a given gene-set S and observed NES, called NES*, FDR is [% of all NES (including permutations) &gt;= NES*] / [% of all observed NES (=NES for all tested gene-sets) &gt;= NES*] relationships between ES, pvalue , NES and FDR: pvalue is calculated from ES FDR is calculated from NES the higher the ES or NES and the lowest the FDR or pvalue NES above 1.4 will usually give significant results © BADER LAB, 2016 pre { background-color:#38393d; color: #5fd381; }","link":"/2022/10/03/Bioinfor/gsea/"},{"title":"IdTrackerAI","text":"Set up/Install Documentation how to install correct pytorch and cuda: https://pytorch.org/get-started/previous-versions/ conda create -y --name idtrackerai python=3.7 Tensorflow=2.0.0 cudatoolkit=11.3.1 pytorch=1.10.0conda activate idtrackeraipip install &quot;idtrackerai[gui]&quot; General information for utility As shown above, the interface is very user-friendly. It can be divided into six regions: Video Load Arguments for Tracking Arguments for Object Segmentation: Blob Intensity: This represents the threshold of the targets based on the grey value, which ranges from 0 (dark) to 255 (light). Blob Area: This is the area of the object, measured in pixels. Tracking Related Arguments Number of Objects and their corresponding sizes: Objects that are significantly larger than others usually indicate occlusion from multiple targets. Area to illustrate the segmentation results for the current frame. First, we use this interface to select the most appropriate parameters and Save parameters as a **.toml file. Then, we simply need to run the following command: idtrackerai --load mix.toml --track This command will load the parameters from the .toml file and initiate the tracking process. Idtracker Data analysis import numpy as npimport trajectorytools as ttimport matplotlib.pyplot as plttrajectories_file_path = 'trajectories/trajectories_wo_gaps.npy'trajectories_dict = np.load(trajectories_file_path, allow_pickle=True).item()trajectories = trajectories_dict['trajectories']tr = tt.Trajectories.from_positions(trajectories)fig, ax_trajectories = plt.subplots(figsize=(5,5))frame_range = range(13883) for i in range(tr.number_of_individuals): ax_trajectories.plot(tr.s[frame_range,i,0], tr.s[frame_range,i,1]) ax_trajectories.set_aspect('equal','box') ax_trajectories.set_title('Trajectories',fontsize=24) ax_trajectories.set_xlabel('X (BL)',fontsize=24) ax_trajectories.set_ylabel('Y (BL)',fontsize=24)fig.savefig(&quot;trajectory2.png&quot;) With video import cv2from matplotlib import colorsPalette = [&quot;#B03D3B&quot;, &quot;#B86C3D&quot;, &quot;#BF8040&quot;, &quot;#ACC144&quot;, &quot;#78C144&quot;, &quot;#47C291&quot;, &quot;#478BC2&quot;, &quot;#4760C2&quot;, &quot;#574BC3&quot;, &quot;#834BC3&quot;, &quot;#C34BAB&quot;, &quot;#C14465&quot;, &quot;#DEB59C&quot;, &quot;#D7DF9F&quot;, &quot;#A7DF9F&quot;, &quot;#9FDFD9&quot;, &quot;#A3B3E0&quot;, &quot;#D0A3E0&quot;, &quot;#E2A7CD&quot;, &quot;#361712&quot;, &quot;#1A3913&quot;, &quot;#132B39&quot;, &quot;#2D1339&quot;, &quot;#391330&quot;]Num = 0#V_loc = '/mnt/Ken_lap/Vlog/upload/promE-GFP/20210622_promE-GFP_C0074_Trim.mp4'V_loc = '/mnt/Ken_lap/Vlog/upload/promE-fru-IR-v330035/20220116-promE-v330035-298d-C0379_Trim-2.mp4'#V_loc = '/mnt/Ken_lap/Vlog/upload/elav-GS-fru-IR-V330035/20220123C0394_Trim.mp4'cap=cv2.VideoCapture(V_loc)fourcc = cv2.VideoWriter_fourcc(*'XVID')out = cv2.VideoWriter('output.avi',fourcc, 30.0, (1920,1080))while (True): ret,frame=cap.read() for id in range(len(trajectories[0])): XY = np.array(trajectories[Num][id], dtype = int) C = np.array(colors.to_rgba(Palette[id]))[:-1] * 225 cv2.putText(frame, str(id) ,(XY[0], XY[1]), cv2.FONT_HERSHEY_COMPLEX, 1, C, 2) #cv2.imshow(&quot;video&quot;,frame) Num +=1 out.write(frame) #if cv2.waitKey(30)&amp;0xFF==ord('q'): # cv2.destroyAllWindows() # breakout.release() import numpy as npimport trajectorytools as ttimport matplotlib.pyplot as pltimport jsonF = open(&quot;data/csv/20220116-promE-v330035-298d-C0379_Trim-2.mp4_.json&quot;, 'r').read()Dict = json.loads(F)trajectories = np.array([[Dict[i][ii]['body'][:2] for ii in np.sort([ii for ii in Dict['12'].keys()])] for i in Dict.keys()])tr = tt.Trajectories.from_positions(trajectories)fig, ax_trajectories = plt.subplots(figsize=(5,5))frame_range = range(30*30) for i in range(tr.number_of_individuals): ax_trajectories.plot(tr.s[frame_range,i,0], tr.s[frame_range,i,1]) ax_trajectories.set_aspect('equal','box') ax_trajectories.set_title('Trajectories',fontsize=24) ax_trajectories.set_xlabel('X (BL)',fontsize=24) ax_trajectories.set_ylabel('Y (BL)',fontsize=24) ax_trajectories.set_aspect(.5)fig.savefig(&quot;20220123C0394_Trim_30.png&quot;)import cv2from matplotlib import colorsPalette = [&quot;#B03D3B&quot;, &quot;#B86C3D&quot;, &quot;#BF8040&quot;, &quot;#ACC144&quot;, &quot;#78C144&quot;, &quot;#47C291&quot;, &quot;#478BC2&quot;, &quot;#4760C2&quot;, &quot;#574BC3&quot;, &quot;#834BC3&quot;, &quot;#C34BAB&quot;, &quot;#C14465&quot;, &quot;#DEB59C&quot;, &quot;#D7DF9F&quot;, &quot;#A7DF9F&quot;, &quot;#9FDFD9&quot;, &quot;#A3B3E0&quot;, &quot;#D0A3E0&quot;, &quot;#E2A7CD&quot;, &quot;#361712&quot;, &quot;#1A3913&quot;, &quot;#132B39&quot;, &quot;#2D1339&quot;, &quot;#391330&quot;]V_list = {&quot;20210622_promE-GFP_C0074_Trim.mp4&quot;: '/mnt/8A26661926660713/Vlog/upload/promE-GFP/20210622_promE-GFP_C0074_Trim.mp4', &quot;20220116-promE-v330035-298d-C0379_Trim-2.mp4&quot;: '/mnt/8A26661926660713/Vlog/upload/promE-fru-IR-v330035/20220116-promE-v330035-298d-C0379_Trim-2.mp4', &quot;20220123C0394_Trim.mp4&quot;: '/mnt/8A26661926660713/Vlog/upload/elav-GS-fru-IR-V330035/20220123C0394_Trim.mp4'}def Video_output(Video, V_loc): loc = [i for i in os.listdir(&quot;data/csv&quot;) if Video in i and &quot;json&quot; in i][0] F = open(&quot;data/csv/&quot; + loc , 'r').read() Dict = json.loads(F) trajectories = np.array([[Dict[i][ii]['body'][:2] for ii in np.sort([ii for ii in Dict['12'].keys()])] for i in Dict.keys()]) tr = tt.Trajectories.from_positions(trajectories) Num = 0 cap=cv2.VideoCapture(V_loc) fourcc = cv2.VideoWriter_fourcc(*'XVID') out = cv2.VideoWriter(Video + &quot;_30.avi&quot;, fourcc, 20.0, (1920,1080)) List = [] while Num &lt;= 900: ret,frame=cap.read() List += [trajectories[Num]] List = List[-100:] for Trace in List: for id in range(len(Trace)): XY = np.array(Trace[id] * (1920, 1080), dtype = int) C = np.array(colors.to_rgba(Palette[id]))[:-1] * 225 cv2.putText(frame, &quot;.&quot; ,(XY[0], XY[1]), cv2.FONT_HERSHEY_COMPLEX, 1, C, 2) Trace = List[-1] for id in range(len(Trace)): XY = np.array(Trace[id] * (1920, 1080), dtype = int) C = np.array(colors.to_rgba(Palette[id]))[:-1] * 225 cv2.putText(frame, str(id) ,(XY[0], XY[1]), cv2.FONT_HERSHEY_COMPLEX, 1, C, 2) cv2.imshow(&quot;video&quot;,frame) Num +=1 out.write(frame) if cv2.waitKey(30)&amp;0xFF==ord('q'): cv2.destroyAllWindows() out.write(frame) break cv2.destroyAllWindows() out.write(frame)for Video in V_list.keys(): Video_output(Video, V_list[Video]) pre { background-color:#38393d; color: #5fd381; }","link":"/2023/01/24/Bioinfor/idtracker/"},{"title":"IGV","text":"pre { background-color:#38393d; color: #5fd381; } IGV Dowload https://software.broadinstitute.org/software/igv/download open: bash igv.sh build index bowtie2-build --threads 8 genome.fa genome.fa build sam file bowtie2 -p 8 -q --no-unal -k 20 -x genome.fa -U reads.fq -S bowtie2.sambowtie2 -p 8 -q --no-unal -k 20 -x genome.fa -1 reads_1.fq -2 reads_2.fq -S bowtie2.sam##Exp:bowtie2 -p 8 -q --no-unal -k 20 -x Trinity.fasta -U SRR771602.fastq -S bowtie2.sam sam to bam samtools view -b -S bowtie2.sam &gt; bowtie2.bamsamtools sort bowtie2.bam -o bowtie2.coordSorted.bam &gt; bowtie2.coordSorted.bamsamtools index bowtie2.coordSorted.bamsamtools faidx Trinity.fasta IGV ~/Biosoft/IGV_2.4.10/igv.sh -g Trinity.fasta bowtie2.coordSorted.bam","link":"/2020/07/28/Bioinfor/igv/"},{"title":"KEGG API","text":"KEGG API list of all pathways: curl https://rest.kegg.jp/list/pathway/dme path:dme00010 Glycolysis / Gluconeogenesis - Drosophila melanogaster (fruit fly) path:dme00020 Citrate cycle (TCA cycle) - Drosophila melanogaster (fruit fly) path:dme00030 Pentose phosphate pathway - Drosophila melanogaster (fruit fly) list of all organisms gene ID curl https://rest.kegg.jp/list/dme dme:Dmel_CG40494 CDS X:127449..140340 RhoGAP1A; Rho GTPase activating protein at 1A, isoform A dme:Dmel_CR43552 miRNA X:133385..133502 mir-4915-RA dme:Dmel_CG17131 CDS X:140318..200663 tyn; trynity, isoform A dme:Dmel_CG17707 CDS X:complement(142731..148426) CG17707; uncharacterized protein, isoform B dme:Dmel_CG3038 CDS X:complement(243954..245856) CG3038; uncharacterized protein, isoform C dme:Dmel_CG2995 CDS X:245978..254650 G9a; G9a, isoform B dme:Dmel_CG42376 CDS X:254876..255524 CG42376; uncharacterized protein, isoform A pathway information curl https://rest.kegg.jp/get/dme00010 ENTRY dme00010 Pathway NAME Glycolysis / Gluconeogenesis - Drosophila melanogaster (fruit fly) DESCRIPTION Glycolysis is the process of converting glucose into pyruvate and generating small amounts of ATP (energy) and NADH (reducing power). It is a central pathway that produces important precursor metabolites: six-carbon compounds of glucose-6P and fructose-6P and three-carbon compounds of glycerone-P, glyceraldehyde-3P, glycerate-3P, phosphoenolpyruvate, and pyruvate [MD:M00001]. Acetyl-CoA, another important precursor metabolite, is produced by oxidative decarboxylation of pyruvate [MD:M00307]. When the enzyme genes of this pathway are examined in completely sequenced genomes, the reaction steps of three-carbon compounds from glycerone-P to pyruvate form a conserved core module [MD:M00002], which is found in almost all organisms and which sometimes contains operon structures in bacterial genomes. Gluconeogenesis is a synthesis pathway of glucose from noncarbohydrate precursors. It is essentially a reversal of glycolysis with minor variations of alternative paths [MD:M00003]. CLASS Metabolism; Carbohydrate metabolism PATHWAY_MAP dme00010 Glycolysis / Gluconeogenesis MODULE dme_M00001 Glycolysis (Embden-Meyerhof pathway), glucose => pyruvate [PATH:dme00010] dme_M00002 Glycolysis, core module involving three-carbon compounds [PATH:dme00010] dme_M00003 Gluconeogenesis, oxaloacetate => fructose-6P [PATH:dme00010] dme_M00307 Pyruvate oxidation, pyruvate => acetyl-CoA [PATH:dme00010] DBLINKS GO: 0006096 0006094 ORGANISM Drosophila melanogaster (fruit fly) [GN:dme] GENE Dmel_CG8094 Hex-C; hexokinase C [KO:K00844] [EC:2.7.1.1] Dmel_CG32849 Hex-t2; Hex-t2 [KO:K00844] [EC:2.7.1.1] Dmel_CG3001 Hex-A; hexokinase A, isoform C [KO:K00844] [EC:2.7.1.1] Dmel_CG33102 Hex-t1; Hex-t1 [KO:K00844] [EC:2.7.1.1] KEGG modules curl https://rest.kegg.jp/list/md md:M00951 Cremeomycin biosynthesis, aspartate/3,4-AHBA => cremeomycin md:M00952 Benzoxazinoid biosynthesis, indoleglycerol phosphate => DIMBOA-glucoside md:M00953 Mugineic acid biosynthesis, methionine => 3-epihydroxymugineic acid md:M00956 Lysine degradation, bacteria, L-lysine => succinate md:M00957 Lysine degradation, bacteria, L-lysine => glutarate => succinate/acetyl-CoA md:M00958 Adenine ribonucleotide degradation, AMP => Urate md:M00959 Guanine ribonucleotide degradation, GMP => Urate md:M00960 Lysine degradation, bacteria, L-lysine => D-lysine => succinate md:M00961 Betacyanin biosynthesis, L-tyrosine => amaranthin md:M00962 Psilocybin biosynthesis, tryptophan => psilocybin md:M00963 Chanoclavine aldehyde biosynthesis, tryptophan => chanoclavine-I aldehyde md:M00964 Fumigaclavine biosynthesis, chanoclavine-I aldehyde => fumigaclavine C md:M00965 Vindoline biosynthesis, tabersonine => vindoline Another Project curl https://rest.kegg.jp/get/hsa05130/image --output test.pngcurl https://rest.kegg.jp/get/hsa05130/conf --output test &lt;img src=&quot;test.png&quot;&gt;&lt;button title =&quot;123&quot;; style=&quot;background-color: #0075eb; width: 50px;position: absolute; left: 485px; top: 959px;&quot;&gt;ITGB1&lt;/button&gt;&lt;div class=&quot;dropdown&quot; style=&quot;background-color: #eb0027; width: 50px;position: absolute; left: 750px; top: 1788px;&quot;&gt;&lt;button class=&quot;dropbtn&quot; style=&quot;background-color: #eb0027&quot;&gt;NAIP&lt;/button&gt;&lt;div class=&quot;dropdown-content&quot;&gt;&lt;a &gt;Name&lt;/a&gt;&lt;a &gt;Name&lt;/a&gt;&lt;a &gt;Name&lt;/a&gt;&lt;/div&gt;&lt;style&gt; .dropbtn { background-color: black; color: white; padding: #px; font-size: #px; border: none; } .dropdown { position: relative; display: inline-block; } .dropdown-content { display: none; position: absolute; background-color: lightgrey; min-width: #px; z-index: 1; } .dropdown-content a { color: black; padding: #px #px; text-decoration: none; display: block; } .dropdown-content a:hover {background-color: white;} .dropdown:hover .dropdown-content {display: block;} .dropdown:hover .dropbtn {background-color: grey;}&lt;/style&gt; pre { background-color:#38393d; color: #5fd381; }","link":"/2022/10/28/Bioinfor/kegg-api/"},{"title":"miRNA pipeline","text":"miRNA pipeline 1 fastq dum fastq-dump * reads length distribution from intetnet python scripts from collections import CounterSeq_read = &quot;fastp_cut.fq&quot;output = &quot;fastp.distribution&quot;with open(Seq_read,'r') as Fileout, open('srg1.r1.paired.results.txt','w') as Filein: i = 4 dic, arr = {}, [] while True: line = Fileout.readline() i += 1 if i%4 == 2: arr.append(len(str(line))) if not line: break dic = Counter(arr)result = ''for k,v in dic.items(): result = result +str(k)+&quot;\\t&quot;+str(v)+&quot;\\n&quot;fo = open(output, &quot;w&quot;)fo.write(result) R scripts save_name=&quot;fastp.pdf&quot;table_name = &quot;fastp.distribution&quot;library(ggplot2)A &lt;- read.table(table_name)ggplot(A,aes(x=V1,y=V2)) +geom_bar(stat=&quot;identity&quot;)ggsave(save_name) 2 fastQC for i in $(ls *.fastq);domkdir QC_$i~/Biosoft/FastQC/fastqc -o QC_$i -t 7 $idonemkdir 2-QCmv QC* 2-QC/mkdir 1-readsmv E* 1-reads/ 3 alignment mkdir 3-aligncd 3-alignfor i in $(ls ../1-reads/ERR219785*.fastq);dobowtie2 -p 8 -x /media/ken/Data/CrippsLab/DB_D.melanogaster/Genome -U ../1-reads/$i -S $i.Genome.samdonemv ../1-reads/*.sam .cd ..for i in $(ls ERR219785*.fastq);dobowtie2 -p 8 -x /media/ken/Data/DB/miRNA/hairpin -U $i -S $i.hairpin.samdonemv *.sam 3-alignfor i in $(ls ERR219785*.fastq);dobowtie2 -p 8 -x /media/ken/Data/DB/miRNA/mature -U $i -S $i.hairpin.samdonemv *.sam 3-align 4 counts samtools view -SF 4 2.sam |perl -alne '{$h{$F[2]}++}END{print &quot;$_\\t$h{$_}&quot; foreach sort keys %h }' &gt; 2-hairpin.counts","link":"/2020/07/28/Bioinfor/miRNA_pipleine/"},{"title":"Juicer: a One-Click System for Analyzing Loop-Resolution Hi-C Experiments","text":"Prerequisite : conda install bwa # for short reads alignmentconda install samtools # for reading the align results Resources: Paper: Durand NC, Shamim MS, Machol I, Rao SSP, Huntley MH, Lander ES, et al. Juicer Provides a One-Click System for Analyzing Loop-Resolution Hi-C Experiments. Cell Syst. 2016;3:95–8. GitHub Source code: aidenlab/juicer Example Pipeline: ENCODE-DCC/hic-pipeline Forums: 3d-genomics; google. They suggest to talk and ask on the google group rather than the github issue because you could got faster responds there. For working on hic-pipeline, if you want to run it in local machine, make sure that docker is installed. I don’t have docker installed, so, I’ll giving this try up. When you got the mistake and want run again, make sure remove those directories first. rm -rf /home/wenkanl2/Tomas/20240614_DuckGenome/myJuicerDir/aligned Juicer in Action According to the documentation, there are 5 steps for running this juicer: Download genome fasta file, put in references folder Run bwa index on the fasta file At the same time, run generate_site_positions.py on the fasta file + your restriction enzyme (see this site about the restriction site file format) Once generate_site_positions is done, run awk 'BEGIN{OFS=\"\\t\"}{print $1, $NF}' mygenome_myenzyme.txt &gt; mygenome.chrom.sizes (where mygenome is your genome, like hg19, and myenzyme is your enzyme, like MboI) Run juicer.sh with the flags -z &lt;path to genome fasta file&gt;, -p &lt;path to mygenome.chrom.sizes&gt;, and -y &lt;path to mygenome_myenzyme.txt&gt; 1. Prepare Your Data The data download from NCBI is not applicable for this pipeline. We need to adapt the name of each reads. According to the error codes (-: Aligning files matching /myJuicerDir/fastq/_R*.fastq*, we could know that the name of the reads should be *_R*.fastq*. Specified, according to the test data, the name of the paired ends reads should be: *_R1*.fastq* and *_R2*.fastq. So, make sure you have the correct name for each of reads. 3. Generate Restriction Site It seams like you’d like to naming your ref genome first. For example, it automatically supplies the hg19 and hg38. If you list the restriction_site directory, it has hg19_MboI.txt Before running the pipeline, we need to ready the restriction_site file, too. Here is a script from juicer to help us to generate it: misc/generate_site_positions.py. It works as below. To be notice, the helpers said that Usage: ./generate_site_positions.py [location]. But the genome here means the name of the genome. In the example, I give it ZJU1.0. The third parameter [location] is the location of the genome fasta file. With the code below, they would output the file ZJU1.0_HindIII.txt python generate_site_positions.py HindIII ZJU1.0 GCF_015476345.1_ZJU1.0_genomic.fnamv ZJU1.0_HindIII.txt ../restriction_sites/ Here is the few supported name of restriction enzymes: 'HindIII' : 'AAGCTT', 'DpnII' : 'GATC', 'MboI' : 'GATC', 'Sau3AI' : 'GATC', 'Arima' : [ 'GATC', 'GANTC' ], 4. Create Chromosome Size File awk 'BEGIN{OFS=&quot;\\t&quot;}{print $1, $NF}' restriction_sites/ZJU1.0_HindIII.txt &gt; ZJU1.0.chrom.sizes # HiCCUPSscripts/common/juicer_tools hiccups --ignore_sparsity aligned/inter_30.hic aligned/inter_30_loops# APA: scripts/common/juicer_tools apa aligned/inter_30.hic aligned/inter_30_loops apa_results In the test data, it generally takes 90GB RAM and 7 GB of GPU RAM 5. Run with the New Parameters &lt;myJuicerDir&gt;/scripts/juicer.sh -D &lt;myJuicerDir&gt; Result I didn’t processing the Juicer successfully yet. It was always exit at post data processing. I get the aligned result successfully. But it seems like failed to find the loop and get the apa_resutls. So, according to the ChatGPT4o, we expected to get the results below after juicer: Contact Maps: These are heatmap-like visualizations showing the frequency of interactions between different regions of the genome. .hic Files: The primary output format of Juicer, .hic files contain the processed Hi-C data, which can be visualized using tools like Juicebox. Statistics and Quality Metrics; Genome-Wide Interaction Profiles; Contact Frequency Plots; and Visualizations in Juicebox In the aligned directory, we got 2 .hic file, one is inter_30.hic, another is inter.hic. According to ChatGPT4o, inter.hic typically contains the raw or minimally processed interaction data. inter_30.hic contains interaction data that has been normalized and possibly filtered to remove noise and low-quality interactions. The “30” in the name usually refers to a specific bin size (e.g., 30 kb). And typically, the inter_30.hic file or another similarly named file with a specific bin size (e.g., inter_5.hic, inter_10.hic) is considered the final, high-quality result suitable for detailed analysis. Troubleshooting HiCCUPS: GPUs are not installed so HiCCUPs cannot be run (-: Postprocessing successfully completed, maps too sparse to annotate or GPUs unavailable (-: ***! Error! Either inter.hic or inter_30.hic were not created Either inter.hic or inter_30.hic were not created. Check for results Check if cuda is installed appropriate. If so, Check if it is in your working environment. How to add it in your working environment: (edit your ~/.bashrc or ~/.zshrc file) export PATH=\"/usr/local/cuda-8.0/bin:$PATH\" export LD_LIBRARY_PATH=\"/usr/local/cuda-8.0/lib64:$LD_LIBRARY_PATH\" Or you could add the --cpu flag on file scripts/common/juicer_postprocessing.sh - if hash nvcc 2&gt;/dev/null- then- ${juicer_tools_path} hiccups ${hic_file_path} ${hic_file_path%.*}&quot;_loops&quot;+ ${juicer_tools_path} hiccups --cpu ${hic_file_path} ${hic_file_path%.*}&quot;_loops&quot;- if [ $? -ne 0 ]; then- echo &quot;***! Problem while running HiCCUPS&quot;;- exit 1- fi-else- echo &quot;GPUs are not installed so HiCCUPs cannot be run&quot;;-fi When the if hash nvcc 2&gt;/dev/null detected that the nvcc doesn’t in the environment, it would exit. So, you may like to delete the entail if statement. HiCCUPS: Picked up _JAVA_OPTIONS: -Xmx150000m -Xms150000m Reading file: /home/wenkanl2/Tomas/20240614_DuckGenome/myJuicerDir/aligned/inter_30.hic No valid configurations specified, using default settings Warning Hi-C map is too sparse to find many loops via HiCCUPS. Exiting. To disable sparsity check, use the --ignore_sparsity flag. As it suggests, you need to add the --ignore_sparsity flag. But, again, you can only make this change by alter scripts/common/juicer_postprocessing.sh if hash nvcc 2&gt;/dev/nullthen- ${juicer_tools_path} hiccups ${hic_file_path} ${hic_file_path%.*}&quot;_loops&quot;+ ${juicer_tools_path} hiccups --ignore_sparsity ${hic_file_path} ${hic_file_path%.*}&quot;_loops&quot; if [ $? -ne 0 ]; then echo &quot;***! Problem while running HiCCUPS&quot;; exit 1 fielse echo &quot;GPUs are not installed so HiCCUPs cannot be run&quot;;fi 0 loops 100% 0 loops written to file: ... HiCCUPS complete According to this post answer by Neva Durand, it could be the data is too sparse. Yes, it’s an order of magnitude too few reads to find loops. You need to do deeper sequencing / more replicates and then combine them. You need at least 1 billion reads. Otherwise your experiments simply don’t have the depth to determine loops (with any algorithm). Not including fragment map Error while reading graphs file: java.io.FileNotFoundException: /home/wenkanl2/Tomas/20240614_DuckGenome/myJuicerDir/aligned/inter_30_hists.m (No such file or directory) Start preprocess Writing header Writing body java.lang.RuntimeException: No reads in Hi-C contact matrices. This could be because the MAPQ filter is set too high (-q) or because all reads map to the same fragment. at juicebox.tools.utils.original.Preprocessor$MatrixZoomDataPP.mergeAndWriteBlocks(Preprocessor.java:1650) at juicebox.tools.utils.original.Preprocessor$MatrixZoomDataPP.access$000(Preprocessor.java:1419) at juicebox.tools.utils.original.Preprocessor.writeMatrix(Preprocessor.java:832) at juicebox.tools.utils.original.Preprocessor.writeBody(Preprocessor.java:582) at juicebox.tools.utils.original.Preprocessor.preprocess(Preprocessor.java:346) at juicebox.tools.clt.old.PreProcessing.run(PreProcessing.java:116) at juicebox.tools.HiCTools.main(HiCTools.java:96) real 2m7.365s user 0m33.647s sys 0m49.450s Picked up _JAVA_OPTIONS: -Xmx150000m -Xms150000m Error reading datasetnull java.io.EOFException at htsjdk.tribble.util.LittleEndianInputStream.readFully(LittleEndianInputStream.java:138) at htsjdk.tribble.util.LittleEndianInputStream.readLong(LittleEndianInputStream.java:80) at htsjdk.tribble.util.LittleEndianInputStream.readDouble(LittleEndianInputStream.java:100) at juicebox.data.DatasetReaderV2.readFooter(DatasetReaderV2.java:470) at juicebox.data.DatasetReaderV2.read(DatasetReaderV2.java:235) at juicebox.tools.utils.original.NormalizationVectorUpdater.updateHicFile(NormalizationVectorUpdater.java:78) at juicebox.tools.clt.old.AddNorm.run(AddNorm.java:84) at juicebox.tools.HiCTools.main(HiCTools.java:96) real 0m0.706s user 0m1.229s sys 0m0.399s /home/wenkanl2/Tomas/20240614_DuckGenome/myJuicerDir/scripts/common/juicer_postprocessing.sh: option requires an argument -- g Usage: /home/wenkanl2/Tomas/20240614_DuckGenome/myJuicerDir/scripts/common/juicer_postprocessing.sh [-h] -j -i -m -g ***! Error! Either inter.hic or inter_30.hic were not created Either inter.hic or inter_30.hic were not created. Check for results Other Pipelines for Hi-C Data Hi-C Processing Pipeline HiC-Pro: an optimized and flexible pipeline for Hi-C data processing HiCUP: pipeline for mapping and processing Hi-C data Babraham Bioinformatics: HiCUP (Hi-C User Pipeline) HiC Data Standards and Processing Pipeline nf-core/hic pre { background-color:#38393d; color: #5fd381; } test { background-color:#38393d; color: #5fd381; }","link":"/2024/06/27/Bioinfor/juicer/"},{"title":"edgeR","text":"edgeR: empirical analysis of DGE in R cite: Mark D. Robinson, Davis J. McCarthy, Gordon K. Smyth, edgeR: a Bioconductor package for differential expression analysis of digital gene expression data, Bioinformatics, Volume 26, Issue 1, 1 January 2010, Pages 139–140, https://doi.org/10.1093/bioinformatics/btp616 An overdispersed Poisson model is used to account for both biological and technical variability. Empirical Bayes methods are used to moderate the degree of overdispersion across transcripts, improving the reliability of inference. The methodology can be used even with the most minimal levels of replication, provided at least one phenotype or experimental condition is replicated. Why EdgeR For microarrays, the abundance of a particular transcript is measured as afluorescence intensity, effectively a continuous response Digital gene expression (DGE) data the abundance is observed as a count Therefore, procedures that are successful for microarray data are not directly applicable to DGE data . edgeR is designed for the analysis of replicated count-based expression data and is an implementation of methology developed by Robinson and Smyth[1][2]. It initially developed for serial analysis of gene expression (SAGE) As a result, edgeR may also be useful in other experiments that generate counts, such as ChIP-seq, in proteomics experiments where spectral counts are used to summarize the peptide abundance[3] or in barcoding experiments where several species are counted [4]. Digital gene expression: Digital gene expression (DGE) is a sequence-based approach for gene expression analyses, that generates a digital output at an unparalleled level of sensitivity[5]. Serial analysis of gene expression (SAGE): Serial analysis of gene expression, or SAGE, is an experimental technique designed to gain a direct and quantitative measure of gene expression. The SAGE method is based on the isolation of unique sequence tags (9-10 bp in length) from individual mRNAs and concatenation of tags serially into long DNA molecules for a lump-sum sequencing[6]. Spam test Spam test2 Method In limma (Smyth, 2004), where an empirical Bayes model is used to moderate the probe-wise variances. In edgeR: We assume the data can be summarized into a table of counts We model the data as negative binomial (NB) distributed $$ Y_ {gi} \\sim NB(M_ i p_ {gj},\\phi_g) $$ For gene $_ g$ and sample $_ i$: $M_i$: the library size (total number of reads), $ϕ_g$: the dispersion $p _{gj}$: is the relative abundance of gene $_g$ in experimental group $_j$ to which sample $_i$ belongs. We use the NB parameterization where: the mean is $\\mu_ {gi} = M_ i p_ {gj}$ the variance is $μ_ {gi}(1+ \\mu _ {gi} \\phi _g)$ For differential expression analysis: the parameters of interest are $p_ {gj}$. The NB distribution is reduced to Poisson when $ \\phi_g = 0$. In some DGE applications, technical variation can be treated as Poisson. In general, $\\phi_g$ represents the coefficient of variation of biological variation between the samples. In this way, our model is able to separate biological from technical variation. limma: dispersion estimates -&gt; topTags: tabulate the top differentially expressed genes -&gt; plotSmear: MA plot More There are a few terms and algorithms I do not understand. So, I’ll update this page later. Robinson MD, Smyth GK. Moderated statistical tests for assessing differences in tag abundance, Bioinformatics, 2007, vol. 23 (pg. 2881-2887) ↩︎ [Robinson MD, Smyth GK. Small sample estimation of negative binomial dispersion, with applications to SAGE data, Biostatistics, 2008, vol. 9 (pg. 321-332)] ↩︎ Andersson AF, et al. Comparative analysis of human gut microbiota by barcoded pyrosequencing, PLoS ONE, 2008, vol. 3 pg. e2836 ↩︎ Wong JWH, et al. Computational methods for the comparative quantification of proteins in label-free LCn-MS experiments, Brief. Bioinform., 2008, vol. 9 (pg. 156-165) ↩︎ Rodríguez-Esteban, G., González-Sastre, A., Rojo-Laguna, J.I. et al. Digital gene expression approach over multiple RNA-Seq data sets to detect neoblast transcriptional changes in Schmidtea mediterranea . BMC Genomics 16, 361 (2015). https://doi.org/10.1186/s12864-015-1533-1 ↩︎ Yamamoto M, Wakatsuki T, Hada A, Ryo A. Use of serial analysis of gene expression (SAGE) technology. J Immunol Methods. 2001 Apr;250(1-2):45-66. doi: 10.1016/s0022-1759(01)00305-2. PMID: 11251221. ↩︎","link":"/2021/04/07/Bioinfor/paper-edger/"},{"title":"IMGT®: the international ImMunoGeneTics information system®","text":"What is IMGT IMGT® provides a range of databases, tools, and web resources focused on the immune system, particularly on the genetic and structural aspects of immunoglobulins (IG), T cell receptors (TCR), major histocompatibility complex (MHC) of all vertebrate species, and related proteins of the immune system (RPI) of any species. These resources are crucial for research in various fields, including immunology, genetics, bioinformatics, drug design, and personalized medicine. Key features and offerings of IMGT® include: Databases: IMGT® offers several databases containing detailed information on IG, TCR, and MHC sequences and structures, along with RPI. These databases are meticulously curated and regularly updated. Analysis Tools: IMGT® provides tools for sequence analysis, gene identification, and 3D structure determination. IMGT/V-QUEST, for instance, is a widely used tool for the analysis of IG and TCR sequences. Standardized Nomenclature: IMGT® has established a standardized nomenclature for the description of IG and TCR genetic components, which is essential for consistent communication and research in the field. Educational Resources: The system also offers educational resources for those new to the field of immunogenetics, including tutorials, glossaries, and comprehensive descriptions of the molecular components of the immune system. Research and Clinical Applications: The information and tools provided by IMGT® are invaluable for various applications, including research in immunology, genetics, and autoimmunity, as well as in clinical settings for antibody engineering, diagnosis, and understanding of immune disorders. Main Service of the IMGT Category Name Description/Focus Area Databases IMGT/GENE-DB Database for immunoglobulin (IG) and T cell receptor (TCR) genes of all vertebrate species. IMGT/3Dstructure-DB Database for 3D structures of IG, TCR, MHC, and RPI (related proteins of the immune system). IMGT/LIGM-DB A comprehensive database of IG and TCR nucleotide sequences from various species. IMGT/PRIMER-DB Database of primers and probes for IG and TCR gene sequences. IMGT/PROTEIN-DB Database for IG, TCR, MHC, and RPI protein sequences and structures. Analysis Tools IMGT/V-QUEST Tool for the analysis of IG and TCR nucleotide sequences. Identifies V, D, and J gene segments and alleles. IMGT/JunctionAnalysis Tool focused on detailed analysis of the V-J and V-D-J junctions of IG and TCR sequences. IMGT/HighV-QUEST High-throughput version of IMGT/V-QUEST for next-generation sequencing (NGS) data. IMGT/DomainGapAlign Tool for the analysis of IG, TCR, and RPI domain sequences and comparison with IMGT reference directory. IMGT/Collier-de-Perles Tool for two-dimensional (2D) graphical representation of IG and TCR variable domains. Resources IMGT Education Educational resources, including tutorials, glossaries, and comprehensive descriptions of immunogenetics. IMGT Scientific chart Standardized nomenclature and classification for IG, TCR, and MHC of humans and other vertebrates. IMGT Repertoire Compilation of allelic polymorphisms and protein displays for variable (V), diversity (D), and joining (J) genes. Other Services IMGT/Therapeutic Information on therapeutic antibodies and fusion proteins for immune applications. IMGT/mAb-DB Specific database for monoclonal antibodies (mAbs). What is IMGT/V-QUEST database? IMGT/V-QUEST is a specialized database and analysis tool that is part of the broader IMGT®, the international ImMunoGeneTics information system®. This system is a high-quality integrated knowledge resource specializing in immunoglobulins (IG), T cell receptors (TCR), major histocompatibility complex (MHC) of all vertebrate species, and related proteins of the immune system (RPI) of any species. IMGT/V-QUEST specifically provides detailed analysis of nucleotide sequences for immunoglobulins (IG) and T cell receptors (TCR). It is widely used in immunology and related research fields for tasks such as: Sequence Analysis: It allows for the identification and delimitation of V, D, and J genes and alleles in the input sequences. This is crucial for understanding the genetic basis of the immune response. Clonotype Characterization: Researchers use it to characterize the clonotypes (unique T cell or B cell receptor sequences) in an individual’s immune repertoire, which is important in studies of immune system diversity and response. Somatic Hypermutation Studies: It helps in the analysis of somatic hypermutations, which are critical for understanding adaptive immunity and processes like affinity maturation. Comparative Immunology: By providing a comprehensive and curated database of IG and TCR sequences across different species, it aids in comparative immunology studies. As of my last update in April 2023, IMGT/V-QUEST continues to be a valuable resource for immunologists, molecular biologists, and other researchers studying the adaptive immune system. The database is regularly updated to include new findings and sequences, ensuring its relevance and usefulness in the field. Something You May Want to Know c16 &gt; g, Q6 &gt; E (++−) means that the nt mutation (c &gt; g) leads to an AA change at codon 6 with the same hydropathy (+) and volume (+) but with different physicochemical properties (−) classes ( 12 )[^Pommié_04]. What is IMGT-Ontology? IMGT/Ontology is a key component of IMGT®, the international ImMunoGeneTics information system®. It represents the first ontology for immunogenetics and immunoinformatics and is a foundational aspect of the IMGT® information system. Developed by Marie-Paule Lefranc and her team, IMGT/Ontology provides a standardized vocabulary and a set of concepts that are essential for the consistent annotation, description, and comparison of the immune system’s components across different species. So, IMGT/Ontology is more of a set of criteria or a framework rather than a specific tool or software. Key features and aspects of IMGT/Ontology include: 1. Standardized VocabularyIMGT/Ontology provides a controlled vocabulary for the description of immunogenetic sequences. This includes terms for genes, alleles, and other genetic elements relevant to immunogenetics. 2. Classification CriteriaIt establishes clear and standardized criteria for the classification of immunoglobulins (IG), T cell receptors (TCR), and major histocompatibility complex (MHC) molecules. This classification is crucial for the accurate comparison and analysis of these molecules. 3. Identification of Key ConceptsThe ontology identifies and defines key concepts in immunogenetics, such as gene segment functionality, recombination features, and junctional diversity. These concepts are critical for understanding the adaptive immune response. 4. IMGT-ONTOLOGY AxiomsThese are the rules that define the relations between the concepts and are used for the annotation and description of the IG, TCR, and MHC sequences in the IMGT® databases and tools. 5. Facilitating Data Integration and AnalysisBy providing a common framework and language, IMGT/Ontology enables the integration, analysis, and sharing of immunogenetic data across different research projects and databases. 6. Support for Research and Clinical ApplicationsThe standardized approach of IMGT/Ontology supports various research and clinical applications, including antibody engineering, vaccine development, and the study of immune responses. IMGT-ONTOLOGY axioms and concepts Seven IMGT-ONTOLOGY axioms have been defined: ‘IDENTIFICATION’ [1], ‘DESCRIPTION’ [2], ‘CLASSIFICATION’ [3], ‘NUMEROTATION’ [4][5], ‘LOCALIZATION’, ‘ORIENTATION’, and ‘OBTENTION’. They constitute the Formal IMGT-ONTOLOGY or IMGT-Kaleidoscope [6]. © IMGT Education IMGT/Ontology is a critical resource for researchers and professionals in immunology, genetics, bioinformatics, and related fields. It ensures that data and analyses are consistent, reproducible, and interoperable, which is vital in advancing our understanding of the immune system and in developing immunotherapy and other medical applications. The oldest paper about ontology: 1999: Ontology for immunogenetics: the IMGT-ONTOLOGY [7] The first ontology to be developed for immunogenetics. ‘An ontology is a specification of conceptualization’ (Gruber, 1993). Covers four main concepts: ‘IDENTIFICATION’, ‘DESCRIPTION’, ‘CLASSIFICATION’ and ‘OBTENTION’. 2008: IMGT-Kaleidoscope, the formal IMGT-ONTOLOGY paradigm[8] seven axioms, ‘IDENTIFICATION’, ‘DESCRIPTION’, ‘CLASSIFICATION’, ‘NUMEROTATION’, ‘LOCALIZATION’, ‘ORIENTATION’ and ‘OBTENTION’ References IMGT®: Ontology (IMGT-ONTOLOGY) Duroux P, Kaas Q, Brochet X, et al. IMGT-Kaleidoscope, the formal IMGT-ONTOLOGY paradigm[J]. Biochimie, 2008, 90(4): 570-583. Giudicelli V, Lefranc M P. Imgt-ontology 2012[J]. Frontiers in genetics, 2012, 3: 79. Lefranc M P. Immunoglobulin and T cell receptor genes: IMGT® and the birth and rise of immunoinformatics[J]. Frontiers in immunology, 2014, 5: 22. Other References Brochet X, Lefranc M P, Giudicelli V. IMGT/V-QUEST: the highly customized and integrated system for IG and TR standardized VJ and VDJ sequence analysis[J]. Nucleic acids research, 2008, 36(suppl_2): W503-W508. pre { background-color:#38393d; color: #5fd381; } Lefranc, M.-P. From IMGT-ONTOLOGY IDENTIFICATION Axiom to IMGT Standardized Keywords: For Immunoglobulins (IG), T Cell Receptors (TR), and Conventional Genes. Cold Spring Harb Protoc., 1;2011(6): 604-613. pii: pdb.ip82. doi: 10.1101/pdb.ip82(2011) PMID:21632792. ↩︎ Lefranc, M.-P. From IMGT-ONTOLOGY DESCRIPTION Axiom to IMGT Standardized Labels: For Immunoglobulin (IG) and T Cell Receptor (TR) Sequences and Structures. Cold Spring Harb Protoc., 1;2011(6): 614-626. pii: pdb.ip83. doi: 10.1101/pdb.ip83 (2011) PMID:21632791. ↩︎ Lefranc, M.-P. From IMGT-ONTOLOGY CLASSIFICATION Axiom to IMGT Standardized Gene and Allele Nomenclature: For Immunoglobulins (IG) and T Cell Receptors (TR). Cold Spring Harb Protoc., 1;2011(6): 627-632. pii: pdb.ip84. doi: 10.1101/pdb.ip84 (2011) PMID:21632790. ↩︎ Lefranc, M.-P. “IMGT Collier de Perles for the Variable (V), Constant ©, and Groove (G) Domains of IG, TR, MH, IgSF, and MhSF” Cold Spring Harb Protoc. 2011 Jun 1;2011(6). pii: pdb.ip86. doi: 10.1101/pdb.ip86. PMID: 21632788 ↩︎ Lefranc, M.-P. IMGT Unique Numbering for the Variable (V), Constant ©, and Groove (G) Domains of IG, TR, MH, IgSF, and MhSF. Cold Spring Harb Protoc., 1;2011(6). pii: pdb.ip85. doi: 10.1101/pdb.ip85 (2011) PMID: 21632789 ↩︎ Duroux P et al., IMGT-Kaleidoscope, the Formal IMGT-ONTOLOGY paradigm. Biochimie, 90:570-83. Epub 2007 Sep 11 (2008) PMID:17949886 ↩︎ Giudicelli V, Lefranc M P. Ontology for immunogenetics: the IMGT-ONTOLOGY[J]. Bioinformatics, 1999, 15(12): 1047-1054. ↩︎ Duroux P, Kaas Q, Brochet X, et al. IMGT-Kaleidoscope, the formal IMGT-ONTOLOGY paradigm[J]. Biochimie, 2008, 90(4): 570-583. ↩︎","link":"/2023/12/25/Bioinfor/imgt/"},{"title":"Find novo transcripts based on Trinity de-nove assembly","text":"Why De novo? Though we can get well quantified data by running alternative splicing processing. But the structure and the number of isoforms for each gene are kind of ambiguous. By de-novo transcripts assembling, we can technically get the full length of the transcripts and we may find some new transcripts and even new genes. Also, gene fusion could be easily told and illustrated. With some help from other tools, blast+ for instance, we can visualize them very well when against them to a reference genome and other standard isoforms. The bad side of the approach is that there is a high false positive rate. My previous sequencing experience tells me that some transcripts may never be detected even by PCR. And the transcripts could look weird because they might be fused with other genes, LncRNA, miRNA, etc., to form a very long and unreliable form. Also, you may never find a transcript from the standard isoform even from the control. And sometimes you can find the intron region is not appropriately spliced. But those are all normal and possible. Because the Trinity algorithm is not perfect. Those “abnormal” transcripts could be a false positive result or something different does happen here and have some biological meanings. But most of the time, I believe the first result. As a result, though this tech might looks fancy and could get a very beautiful result, it is worthy to be verified by other means and be talked very carefully. Find novo transcripts based on Trinity de-nove assembly This post is based on the Slurm system. The main steps are included in: De-novo Assembly by Trinity (Trinity) Local align the Gene into the Trinscriptom (Biopython, blast+) Align the Transcripts into the Genome (blast+) Visualization (ggbio) Prepare a file for the group and locations S39_ ../../RNA_RAW/S39_L001_R1_001.fastq.gz S39_ ../../RNA_RAW/S39_L001_R2_001.fastq.gz S39_ ../../RNA_RAW/S39_L002_R1_001.fastq.gz ... Pipeline Step 1: Assembly and Make Blast DB module load trinity/2.8.5module load jellyfishmodule load ncbi-blast/2.12.0+mkdir scriptmkdir Transcirptonsmkdir LOGfor SAMPLE in $(awk '{print $1}' File.list | sort |uniq); do # if the result not exist: if [ -f Transcirptons/$SAMPLE.fa ]; then echo $SAMPLE else sed &quot;s/--job-name=GATK/--job-name=$SAMPLE/;s/--output=Hi.out/--output=LOG\\/$SAMPLE.out/;s/--error=Hi.err/--error=LOG\\/$SAMPLE.err/&quot; Model.sh &gt; script/$SAMPLE.sh echo Trinity --seqType fq --CPU 64 --max_memory 60G --output trinity_$SAMPLE --single $(grep $SAMPLE File.list| awk '{print $2}'| tr &quot;\\n&quot; &quot;,&quot;| sed 's/,$/ /') &gt;&gt; script/$SAMPLE.sh echo cp trinity_$SAMPLE/Trinity.fasta Transcirptons/$SAMPLE.fa &gt;&gt; script/$SAMPLE.sh echo makeblastdb -in Transcirptons/$SAMPLE.fa -dbtype nucl -parse_seqids -out Transcirptons/$SAMPLE &gt;&gt; script/$SAMPLE.sh echo rm -rf trinity_$SAMPLE &gt;&gt; script/$SAMPLE.sh sbatch script/$SAMPLE.sh fidone Step 1: Target Genes mkdir Genesmkdir Trans_annomkdir Genome_posGENOME=../DB/BDGP6.32GTF=../DB/Drosophila_melanogaster.BDGP6.32.104.chr.EGFP.GAL4.mCD8GFP.gtfGENE=Mmp1CHROM=$(grep -w \\&quot;$GENE\\&quot; $GTF| awk '{print $1}'| head -n 1)START=$(grep -w \\&quot;$GENE\\&quot; $GTF| awk '{print $4}'| sort -n | head -n 1)TOEND=$(grep -w \\&quot;$GENE\\&quot; $GTF| awk '{print $5}'| sort -n | tail -n 1)python GeneExtract.py -g $GENE -c $CHROM -s $START -e $TOEND -f $GENOME.fa -o Genes/$GENE.fafor SAMPLE in $(ls Transcirptons| grep &quot;.fa&quot;| sed 's/.fa//'); do if [ -f Genome_pos/$SAMPLE-$GENE.csv ]; then echo $SAMPLE is done else sed &quot;s/Hi/$SAMPLE\\_blt/&quot; Model.sh &gt; script/$SAMPLE\\_$GENE\\_blt.sh echo &quot;blastn -query Genes/$GENE.fa -db Transcirptons/$SAMPLE -outfmt '6 qacc sacc evalue qstart qend sstart send' -evalue 1e-1 -max_target_seqs 1000 -num_threads 8 -max_hsps 10000 &gt; Trans_anno/$SAMPLE-$GENE.csv&quot; &gt;&gt; script/$SAMPLE\\_$GENE\\_blt.sh echo &quot;grep -A 1 -wE \\$(awk '{print \\$2}' Trans_anno/$SAMPLE-$GENE.csv| sort | uniq| tr '\\n' '|' | sed 's/|$/\\n/') Transcirptons/$SAMPLE.fa| grep -v '^--' &gt; Trans_anno/$SAMPLE-$GENE.fa&quot; &gt;&gt; script/$SAMPLE\\_$GENE\\_blt.sh echo &quot;blastn -query Trans_anno/$SAMPLE-$GENE.fa -db $GENOME -outfmt '6 qacc sacc evalue qstart qend sstart send' -evalue 1e-1 -max_target_seqs 1000 -num_threads 8 -max_hsps 10000 &gt; Genome_pos/$SAMPLE-$GENE.csv&quot; &gt;&gt; script/$SAMPLE\\_$GENE\\_blt.sh sbatch script/$SAMPLE\\_$GENE\\_blt.sh fidone grep . Genome_pos/*Mmp1*| sed 's/:/\\t/;s=Genome_pos/==;s/__Mmp1.csv//' &gt; Mmp1.csv library(ggplot2)library(reshape2)library(stringr)library(GenomicFeatures)GENE = &quot;Mmp1&quot;GTF &lt;- read.table(&quot;../DB/Drosophila_melanogaster.BDGP6.32.104.chr.EGFP.GAL4.mCD8GFP.gtf&quot;, sep ='\\t')GTF2 &lt;- GTF[grep(&quot;transcript_id&quot;, GTF$V9),]GTF2$TranID &lt;- as.data.frame(str_split_fixed(as.data.frame(str_split_fixed(GTF2$V9, &quot;transcript_id &quot;, 2))[[2]], &quot;;&quot;, 2))[[1]]GTF2$GENE &lt;- as.data.frame(str_split_fixed(as.data.frame(str_split_fixed(GTF2$V9, &quot;gene_name &quot;, 2))[[2]], &quot;;&quot;, 2))[[1]]GTF2 &lt;- GTF2[GTF2$V3 %in% c(&quot;exon&quot;, &quot;start_codon&quot;, &quot;stop_codon&quot;),]wh = GTF2$V4[grep(GENE, GTF2$V9)]TB &lt;- read.table(&quot;Mmp1.csv&quot;)TB$ID=paste(TB$V1, TB$V2)TB$X1 = apply(TB[c(&quot;V7&quot;,&quot;V8&quot;)], 1, min)TB$X2 = apply(TB[c(&quot;V7&quot;,&quot;V8&quot;)], 1, max)TB$Y = as.numeric(as.factor(TB$ID))*-1 +1#autoplot(txdb, which= Trans[GENE][[1]], gap.geom = &quot;chevron&quot;)#SAMPLE = c(&quot;CF-1_S1&quot;, &quot;CF-2_S2&quot;, &quot;CF-3_S3&quot;, &quot;wt_10day_1_S27&quot;, &quot;wt_10day_2_S28&quot;, &quot;wt_10day_3_S29&quot;, &quot;TF-1_S7&quot;, &quot;TF-2_S8&quot;, &quot;TF-3_S9&quot;, &quot;TM-1_S10&quot;, &quot;TM-2_S11&quot;, &quot;TM-3_S12&quot;, &quot;G15F_S46&quot;, &quot;G15-M_TUMOR-a_S35&quot;, &quot;G15-M_TUMOR-b_S36&quot;, &quot;G17F_S51&quot;, &quot;G17M_S32&quot;, &quot;G1F1_S31&quot;, &quot;G1F2_S47&quot;, &quot;G1M1_S48&quot;, &quot;G1M2_S49&quot;, &quot;G2M_S50&quot;, &quot;G50-FE_TUMOR-a_S37&quot;, &quot;G50-FE_TUMOR-b_S38&quot;, &quot;G5M_S45&quot;, &quot;MG1T10-1_S32&quot;, &quot;MG1T10-2_S33&quot;, &quot;MG1T10-3_S34&quot;, &quot;NICD_SxlRF1_S39&quot;, &quot;NICD_SxlRF2_S40&quot;, &quot;NICD_TraR2F1_S33&quot;, &quot;NICD_TraR2F2_S34&quot;, &quot;NICD_TraR2F3_S35&quot;, &quot;NICD_TraR3F1_S36&quot;, &quot;NICD_TraR3F2_S37&quot;, &quot;NICD_TraR3F3_S38&quot;)# TB &lt;- TB[TB$V1 %in% SAMPLE,]RegionPlot &lt;- function(GENE){ MAX = max(as.numeric(as.matrix(GTF2[GTF2$GENE==GENE,c(&quot;V4&quot;, &quot;V5&quot;)]))) MIN = min(as.numeric(as.matrix(GTF2[GTF2$GENE==GENE,c(&quot;V4&quot;, &quot;V5&quot;)]))) CHM = head(GTF2[GTF2$GENE==GENE,&quot;V1&quot;],1) tmp_GTF = GTF2[GTF2$V4 &gt;= MIN,] tmp_GTF = tmp_GTF[tmp_GTF$V5 &lt;= MAX,] tmp_GTF = tmp_GTF[tmp_GTF$V1 == CHM,] tmp_TB = TB[-c(17,27),] ggplot()+ theme_bw()+ geom_line(data=tmp_GTF, aes(x= V4, y=TranID, group=TranID))+ geom_tile(data=tmp_GTF, aes(x=(V4+V5)/2, y=TranID, width= abs(V5-V4), height= .9, color=V3), fill='grey')+ scale_color_manual(values = c(&quot;black&quot;,&quot;red&quot;,&quot;blue&quot;)) + geom_line(data=tmp_TB, aes(x= V7, y=ID, group=Y), size=1, alpha= .6)+ geom_tile(data=tmp_TB, aes(x= (X1+X2)/2, width= abs(V8-V7),y=ID, height= .9,fill=V1), size=1, color=&quot;black&quot;)+ xlim(c(MIN, MAX))+ facet_grid(V1~., space = 'free', scales = 'free')}RegionPlot_fact &lt;- function(GENE){ MAX = max(as.numeric(as.matrix(GTF2[GTF2$GENE==GENE,c(&quot;V4&quot;, &quot;V5&quot;)]))) MIN = min(as.numeric(as.matrix(GTF2[GTF2$GENE==GENE,c(&quot;V4&quot;, &quot;V5&quot;)]))) CHM = head(GTF2[GTF2$GENE==GENE,&quot;V1&quot;],1) tmp_GTF = GTF2[GTF2$V4 &gt;= MIN,] tmp_GTF = tmp_GTF[tmp_GTF$V5 &lt;= MAX,] tmp_GTF = tmp_GTF[tmp_GTF$V1 == CHM,] tmp_TB = TB[-c(17,27),] TRANS_list = list() for( TRANS in unique(tmp_GTF$TranID)){ tmp_Tran_TB &lt;- tmp_GTF[tmp_GTF$TranID == TRANS,c(&quot;V4&quot;,&quot;V5&quot;)] C_tmp = c() for(i in c(1:nrow(tmp_Tran_TB))){ C_tmp = c(C_tmp, c(tmp_Tran_TB[i,1]:tmp_Tran_TB[i,2])) } tmp = list(C_tmp) names(tmp) = TRANS TRANS_list &lt;- append(TRANS_list, tmp) } Seq_list = list() for( TRANS in unique(tmp_TB$ID)){ tmp_Tran_TB &lt;- tmp_TB[tmp_TB$ID == TRANS,c(&quot;X1&quot;,&quot;X2&quot;)] C_tmp = c() for(i in c(1:nrow(tmp_Tran_TB))){ C_tmp = c(C_tmp, c(tmp_Tran_TB[i,1]:tmp_Tran_TB[i,2])) } tmp = list(C_tmp) names(tmp) = TRANS Seq_list &lt;- append(Seq_list, tmp) } RESULT = data.frame() for(TRANS in names(TRANS_list)){ for(Seq in names(Seq_list)){ Cover1 = table(TRANS_list[[TRANS]] %in% Seq_list[[Seq]])['TRUE'][[1]]/ length(TRANS_list[[TRANS]]) Cover2 = table(Seq_list[[Seq]] %in% TRANS_list[[TRANS]])['TRUE'][[1]]/ length(Seq_list[[Seq]]) RESULT = rbind(RESULT, data.frame(TRANS=TRANS, Seq=Seq, Cover1= Cover1, Cover2 = Cover2)) } } RESULT[is.na(RESULT)] &lt;- 0 RESULT$Cover = apply(RESULT[3:4], 1, sum) RESULT &lt;- RESULT[order(RESULT$Cover,decreasing = T),] RESULT &lt;- RESULT[!duplicated(RESULT$Seq),] LIST =c() for( i in unique(RESULT$TRANS)){ LIST= c(LIST, c(i, as.character(RESULT$Seq[RESULT$TRANS == i]))) } tmp_GTF$TranID &lt;- factor(tmp_GTF$TranID, levels= unique(LIST)) tmp_TB$ID &lt;- factor(tmp_TB$ID, levels= LIST) tmp_GTF$TranID &lt;- factor(tmp_GTF$TranID, levels= unique(LIST)) colnames(tmp_GTF)[c(4,5,10)] &lt;- c(&quot;X1&quot;, &quot;X2&quot;, &quot;ID&quot;) tmp_TB['V3'] &lt;- &quot;exon&quot; TB_plot &lt;- rbind(tmp_GTF[c(&quot;X1&quot;, &quot;X2&quot;, &quot;ID&quot;, &quot;V3&quot;)], tmp_TB[c(&quot;X1&quot;, &quot;X2&quot;, &quot;ID&quot;, &quot;V3&quot;)]) TB_plot$ID &lt;- factor(TB_plot$ID, levels=rev.default(LIST)) TB_plot$TRANS &lt;- RESULT$TRANS[match(TB_plot$ID, RESULT$Seq)] TB_plot$TRANS[is.na(TB_plot$TRANS)] &lt;- TB_plot$ID[is.na(TB_plot$TRANS)] TB_plot$Cove = RESULT$Cover1[match(TB_plot$ID, RESULT$Seq)] TB_plot$Cove[is.na(TB_plot$Cove)] &lt;- 1 ggplot(TB_plot[TB_plot$Cove &gt;=.5,], aes(fill=TRANS))+ theme_bw()+ geom_line(aes(x= X1, y=ID, group=ID))+ geom_tile(aes(x=(X1+X2)/2, y=ID, width= abs(X2-X1), height= .9, color=V3), fill='grey')+ scale_color_manual(values = c(&quot;black&quot;,&quot;red&quot;,&quot;blue&quot;)) + xlim(c(MIN, MAX)) + facet_grid(TRANS~., space = 'free', scales = 'free')}library(ggbio)library(GenomicFeatures)library(clusterProfiler)library(org.Dm.eg.db)library(Rsamtools)txdb &lt;- makeTxDbFromGFF(file=&quot;../DB/Drosophila_melanogaster.BDGP6.32.104.chr.EGFP.GAL4.mCD8GFP.gtf&quot;, format=&quot;gtf&quot;)Trans &lt;- transcriptsBy(txdb, &quot;gene&quot;)tmp &lt;- bitr(names(Trans), fromType=&quot;FLYBASE&quot;, toType=&quot;SYMBOL&quot;, OrgDb=&quot;org.Dm.eg.db&quot;)names(Trans)[!is.na(tmp[[2]][match(names(Trans), tmp[[1]])])] &lt;- tmp[[2]][match(names(Trans), tmp[[1]])][!is.na(tmp[[2]][match(names (Trans), tmp[[1]])])]bam&lt;-BamFile(file=&quot;../Bam/G50-FE_TUMOR-a_S37Aligned.sortedByCoord.out.bam&quot;, index=&quot;../Bam/G50-FE_TUMOR-a_S37Aligned.sortedByCoord.out.bam.bai&quot;)RegionPlot_ggbio &lt;-function(GENE, SAMPLE=&quot;G50-FE_TUMOR-a_S37&quot;){ P1 &lt;- autoplot(txdb, which= Trans[[GENE]])+ theme_bw() tmp = range(Trans[[GENE]]) rg = c(tmp@ranges@start, tmp@ranges@start+tmp@ranges@width) wh = as(c(paste(tmp@seqnames@values, &quot;:&quot;, tmp@ranges@start, &quot;-&quot;, tmp@ranges@start+tmp@ranges@width, sep =&quot;&quot;)), &quot;GRanges&quot;) MAX = wh@ranges@start + wh@ranges@width MIN = wh@ranges@start CHM = wh@seqnames@values tmp_TB = TB[-c(17,27),] tmp_TB &lt;- tmp_TB[tmp_TB$V1==SAMPLE,] tmp_TB$V2 &lt;- factor(tmp_TB$V2, levels=unique(tmp_TB$V2)) P_TRANS &lt;- ggplot()+ theme_bw()+ scale_color_manual(values = c(&quot;black&quot;,&quot;red&quot;,&quot;blue&quot;)) + geom_line(data=tmp_TB, aes(x= V7, y=V2, group=Y), size=1, alpha= .6, show.legend = F)+ geom_tile(data=tmp_TB, aes(x= (X1+X2)/2, width= abs(V8-V7),y=V2, height= .5,fill=V1), size=1, color=&quot;black&quot;, show.legend = F)+ xlim(c(MIN, MAX))+theme(axis.text.y = element_blank())+ geom_text(data=tmp_TB, aes(x= MIN, y=as.numeric(V2)+.5, label=V2), vjust = .5, hjust =0, size = 3.5) P2 &lt;- autoplot(bam, which =wh, stat = &quot;coverage&quot;) + theme_bw() + theme(legend.position=&quot;none&quot;) + coord_cartesian(xlim =c(wh@ranges@start, wh@ranges@start + wh@ranges@width)) tracks(Coverage=P2, Transcripts=P1, Trans= P_TRANS, heights = c(0.4, Trans[[GENE]]@seqnames@lengths * .1, length(unique(tmp_TB$V2))*.1), title=SAMPLE) + ylab(&quot;&quot;) H = 2.58 + (Trans[[GENE]]@seqnames@lengths +length(unique(tmp_TB$V2))) *.48 ggsave(paste('img/', SAMPLE,&quot;_&quot;,GENE,&quot;.png&quot;,sep=&quot;&quot;), w= 10, h = H)}# for loopfor(SAMPLE in unique(TB$V1)){ print(SAMPLE) if(SAMPLE != &quot;G50-FE_TUMOR-b_S38&quot;){ BAM = paste(&quot;../Bam/&quot;,SAMPLE,&quot;Aligned.sortedByCoord.out.bam&quot;, sep=&quot;&quot;) BAI = paste(&quot;../Bam/&quot;,SAMPLE,&quot;Aligned.sortedByCoord.out.bam.bai&quot;, sep=&quot;&quot;) bam&lt;-BamFile(file= BAM, index= BAI) RegionPlot_ggbio(GENE, SAMPLE) }} Plot for single Sample with Depth Add this to GeneExtract.py import argparsefrom Bio import SeqIOparser = argparse.ArgumentParser()parser.add_argument('-g','--gene') parser.add_argument('-o','--output') parser.add_argument('-c','--chrom') parser.add_argument('-s','--start', type =int) parser.add_argument('-e','--end', type=int) parser.add_argument('-f','--fasta') ##获取参数args = parser.parse_args()GENE= args.geneCHROM= args.chromSTART= args.startTOEND= args.endGENOME= args.fastaOUT= args.outputfor seq_record in SeqIO.parse(GENOME, &quot;fasta&quot;): if seq_record.id == CHROM: F =open(OUT, 'w') F.write(&quot;&gt;&quot; + GENE+&quot;\\n&quot;) F.write(str(seq_record.seq[START-1:TOEND]) + &quot;\\n&quot;) F.close()","link":"/2022/08/18/Bioinfor/mrna-trinity-new/"},{"title":"Extract Information from PDB and Visualize with Pyvista","text":"Quick Codes from Bio.PDB import PDBParserimport numpy as npimport pyvista as pv# Parse the PDB fileparser = PDBParser()structure = parser.get_structure(&quot;1nnc&quot;, &quot;PDB/1nnc.pdb&quot;)# Extract 3D coordinates and print atom namespoints = []for model in structure: for chain in model: for residue in chain: for atom in residue: points.append(atom.get_coord()) print(f&quot;Atom Name: {atom.get_name()}, Coordinates: {atom.get_coord()}&quot;)# Convert to a numpy arraypoints_array = np.array(points)# Create a PyVista point cloudpoint_cloud = pv.PolyData(points_array)point_cloud.plot(point_size=5, color='red') In this updated script: The print statement within the innermost loop (for atom in residue:) prints the name of each atom and its coordinates. atom.get_name() retrieves the name of the atom. atom.get_coord() retrieves the 3D coordinates of the atom. Remember to replace &quot;protein_id&quot; and &quot;path_to_your_pdb_file.pdb&quot; with the appropriate identifiers and file path for your PDB file. This script will print the name and coordinates of each atom in the console and plot the points in 3D using PyVista. You can further modify this script to include more details or to format the output as per your requirement. The Name of Atoms Certainly! In the context of a Protein Data Bank (PDB) file, atoms within proteins are named according to standard conventions that reflect their chemical properties and their position within the protein structure. Here’s a breakdown of what different atom names typically signify: Element Symbol: The first part of an atom’s name usually represents its element symbol from the periodic table. For example, “C” stands for Carbon, “N” for Nitrogen, “O” for Oxygen, “S” for Sulfur, and so on. Amino Acid Context: Atoms are part of amino acids in proteins. Each amino acid has a specific set of atoms. For instance, in the amino acid glycine, you might find atoms named “CA” (alpha carbon), “N” (amino nitrogen), “O” (carbonyl oxygen), etc. Position in Amino Acid: Alpha Carbon (CA): This is the central carbon atom to which the amino group (NH2), carboxyl group (COOH), hydrogen (H), and the R group (side chain) are attached in amino acids. Backbone Atoms: These include “N” (the amide nitrogen), “CA” (alpha carbon), and “C” (the carbonyl carbon). These atoms form the backbone of the protein chain. Side Chain Atoms: Atoms in the side chain (or R group) of an amino acid are denoted by different names depending on their position and chemical nature. For example, in the amino acid lysine, you might see names like “CG”, “CD”, “CE” - these are carbon atoms in the side chain, labeled in order from the alpha carbon. Hydrogen Atoms: These are often denoted by “H” followed by additional characters to specify their position. For example, “HA” might be a hydrogen attached to the alpha carbon. Prosthetic Groups or Non-standard Residues: In addition to standard amino acids, proteins may have non-standard residues or prosthetic groups like heme in hemoglobin. These will have their own unique naming conventions based on their molecular structure. Alternate Locations: Sometimes an atom can occupy multiple positions due to structural flexibility. These are often indicated by an additional character like “A” or “B” following the atom name. Understanding these naming conventions can help in interpreting the structure and function of the protein, as the 3D arrangement of these atoms determines the protein’s shape and reactive sites. In practical use, this information is crucial for tasks like modeling protein-ligand interactions, understanding enzyme active sites, or studying protein folding and dynamics. Show the Alpha Carbon Only from Bio.PDB import PDBParserimport numpy as npimport pyvista as pv# Parse the PDB fileparser = PDBParser()structure = parser.get_structure(&quot;Mos99&quot;, &quot;PDB/Mos99_WT_NA_monomer.pdb&quot;)# Extract 3D coordinates and print atom namespoints = []for model in structure: for chain in model: for residue in chain: for atom in residue: if atom.get_name() == &quot;CA&quot;: points.append(atom.get_coord()) #print(f&quot;Atom Name: {atom.get_name()}, Coordinates: {atom.get_coord()}&quot;)# Convert to a numpy arraypoints_array = np.array(points)# Create a PyVista point cloudpoint_cloud = pv.PolyData(points_array)point_cloud.plot(point_size=5, color='red') Convert it into Mesh # select the dots on the surfacefrom sklearn.neighbors import NearestNeighborsimport numpy as np# Assuming 'points_array' is your numpy array of 3D pointspoints = points_array.copy()# Use KNN to find the nearest neighborsnbrs = NearestNeighbors(n_neighbors=10).fit(points)distances, indices = nbrs.kneighbors(points)# Determine a threshold distance for surface pointsthreshold_distance = np.percentile(distances, 90) # adjust as needed# Identify surface pointssurface_points = points[np.max(distances, axis=1) &gt; threshold_distance]point_cloud = pv.PolyData(surface_points)#point_cloud = pv.PolyData(points_array)volume = point_cloud.delaunay_3d(alpha = 4)shell = volume.extract_geometry()shell.plot(show_edges=True) Visualize a Single Amino Acid chain_id = 'A' # Replace with the relevant chain IDresidue_number = 100 # Replace with the residue number of the amino acid# Extract coordinatesamino_acid_data = []for model in structure: for chain in model: if chain.get_id() == chain_id: for residue in chain: if residue.get_id()[1] == residue_number: for atom in residue: amino_acid_data.append((atom.get_coord(), atom.element, atom.get_id())) tmp = residue print(residue.get_full_id(), residue.get_resname())# Separate coordinates, elements, and atom namescoordinates, elements, atom_names = zip(*amino_acid_data)coordinates = np.array(coordinates)# find bounds:def infer_bonds(coords, max_bond_length=2): bonds = [] num_atoms = len(coords) for i in range(num_atoms): for j in range(i+1, num_atoms): if np.linalg.norm(coords[i] - coords[j]) &lt; max_bond_length: bonds.append((i, j)) return bonds# Infer bondsbonds = infer_bonds(coordinates)# Plot all# Map elements to RGB colors (customize this as needed)element_colors = { &quot;C&quot;: [0, 0, 0], # Carbon (black) &quot;N&quot;: [0, 0, 255], # Nitrogen (blue) &quot;O&quot;: [255, 0, 0], # Oxygen (red) &quot;S&quot;: [255, 255, 0], # Sulfur (yellow) # Add more elements and colors as required}# Create an array to store RGB colorsrgb_colors = np.array([element_colors.get(element, [125, 125, 125]) for element in elements]) # Default grey# Create a PyVista plotterplotter = pv.Plotter()# Plot atomsfor coord, color in zip(coordinates, rgb_colors): sphere = pv.Sphere(radius=0.5, center=coord) plotter.add_mesh(sphere, color=color)# Plot bondsfor bond in bonds: start, end = coordinates[bond[0]], coordinates[bond[1]] line = pv.Line(start, end) plotter.add_mesh(line, color='grey', line_width=3)# Show plotplotter.show() In this case, in the atom_names: CA: alpha carbon C: the carbon from Cα-COOH N: The N from Cα-NH3 rest of atoms are coming from side chain. Turn IT into Dictionary Protein_dic = {}for model in structure: for chain in model: chain_dic = {} for residue in chain: chain_dic.update({residue.get_id()[1]: residue}) Protein_dic.update({chain.get_id(): chain_dic}) Check the Adjacent Side Chain by Side Chain def Get_atom(Res): R = [] for atom in Res: if len(Res) == 4: R += [atom.get_coord()] else: if atom.get_id() not in ['N', 'CA', &quot;C&quot;, &quot;O&quot;]: R += [atom.get_coord()] R = np.array(R) return RAA_list = ['ALA', 'ARG', 'ASN', 'ASP', 'CYS', 'GLN', 'GLU', 'GLY', 'HIS', 'ILE', 'LEU', 'LYS', 'MET', 'PHE', 'PRO', 'SER', 'THR', 'TRP', 'TYR', 'VAL']Residues = []for chain in Protein_dic.keys(): for pos in Protein_dic[chain]: if Protein_dic[chain][pos].get_resname() in AA_list: Residues += [[chain, pos, Protein_dic[chain][pos].get_resname(), np.mean(Get_atom(Protein_dic[chain][pos]), axis=0)]]# plot hte residues position# Convert to a numpy arraypoints_array = np.array([i[-1] for i in Residues])# Create a PyVista point cloudpoint_cloud = pv.PolyData(points_array)point_cloud.plot(point_size=5, color='red')# mesh# Assuming 'points_array' is your numpy array of 3D pointspoints = points_array.copy()# Use KNN to find the nearest neighborsnbrs = NearestNeighbors(n_neighbors=5).fit(points)distances, indices = nbrs.kneighbors(points)# Determine a threshold distance for surface pointsthreshold_distance = np.percentile(distances, 90) # adjust as needed# Identify surface pointssurface_points = points[np.max(distances, axis=1) &gt; threshold_distance]surface_res = np.array(Residues)[np.max(distances, axis=1) &gt; threshold_distance]point_cloud = pv.PolyData(surface_points)#point_cloud = pv.PolyData(points_array)volume = point_cloud.delaunay_3d(alpha = 10)shell = volume.extract_geometry()shell.plot(show_edges=True) Check the Residua Local environment nbrs = NearestNeighbors(n_neighbors=6).fit(surface_points)distances, indices = nbrs.kneighbors(surface_points)Loc_res = {}; [Loc_res.update({i[1]:i[2]}) for i in Residues if i [0]=='A']# rm duplicatedNet_charge = {&quot;ALA&quot;:0, &quot;ARG&quot;:+1, &quot;ASN&quot;:0, &quot;ASP&quot;:-1, &quot;CYS&quot;:0, &quot;GLN&quot;:0, &quot;GLU&quot;:-1, &quot;GLY&quot;:0, &quot;HIS&quot;:+1, &quot;ILE&quot;:0, &quot;LEU&quot;:0, &quot;LYS&quot;:+1, &quot;MET&quot;:0, &quot;PHE&quot;:0, &quot;PRO&quot;:0, &quot;SER&quot;:0, &quot;THR&quot;:0, &quot;TRP&quot;:0, &quot;TYR&quot;:0, &quot;VAL&quot;:0}res_pos = np.array([[surface_res[ii][1] for ii in i[:5]] for i in indices])res_pos = np.unique(res_pos, axis= 0)res_name = [[Loc_res[ii] for ii in i] for i in res_pos]Charge_av = [sum([Net_charge[ii] for ii in i]) for i in res_name]Loc_net = {}[Loc_net.update({i[0]:ii}) for i,ii in zip(res_pos, Charge_av)]values = [Loc_net[i[1]] for i in surface_res]point_cloud = pv.PolyData(surface_points)point_cloud[&quot;values&quot;] = values#point_cloud = pv.PolyData(points_array)volume = point_cloud.delaunay_3d(alpha = 10)shell = volume.extract_geometry()plotter = pv.Plotter()plotter.add_mesh(volume, scalars=&quot;values&quot;, cmap=&quot;coolwarm&quot;)plotter.add_scalar_bar(color='black') # Set scalar bar font color to blackplotter.set_background(color='white')plotter.show()shell.plot(show_edges=True, scalars=&quot;values&quot;, cmap=&quot;coolwarm&quot;) Camera Position In PyVista, you can easily get and set the camera position to ensure a consistent view across different plots. The camera position in PyVista is defined by a tuple of three elements: Camera Position: The location of the camera in the 3D space. Focal Point: The point in the 3D space that the camera is looking at. View Up: A vector that defines the ‘up’ direction in the view of the camera. Here’s how you can get and then set the camera position: Getting the Camera Position After you have displayed your plot once, you can retrieve the camera position: import pyvista as pv# [Your code to create and display the mesh]# Create a plotter and add the meshplotter = pv.Plotter()plotter.add_mesh(mesh)plotter.show()# Q to quite the polt# Get the camera positioncamera_position = plotter.camera_position Setting the Camera Position When you create a new plot and want to use the same camera position, you can set it like this: # Create a new plotterplotter = pv.Plotter()# Add the mesh to the new plotterplotter.add_mesh(mesh)# Set the camera position to the saved oneplotter.camera_position = camera_position# Show the plot with the set camera positionplotter.show() Remember, you should retrieve and set the camera position after and before calling show(), respectively. This method ensures that every time you plot your mesh, the view will be identical, assuming the mesh and other plot settings remain the same. pre { background-color:#38393d; color: #5fd381; }","link":"/2023/12/08/Bioinfor/pdbpyvista/"},{"title":"Visualize the Protein Mesh with pyvista","text":"Prerrequirement pymol collada pyvista All libraries could be installed by pip Save the Mesh Information with Pymol after loaded your model: Example file: 2a6d Target: Extract the mesh information of CDR region from a antibody PS: output may takes a while. bg_color whitecolor deepblue, 2a6dselect CDR1, 2a6d and chain B and resi 31-35select CDR2, 2a6d and chain B and resi 50-66select CDR3, 2a6d and chain B and resi 99-110create cdr, CDR1 CDR2 CDR3show mesh, cdrcolor hotpink, cdrhide allshow surface, cdrsave object.stl, cdr Load It with pyvista import pyvista as pvmesh = pv.read('object.stl')mesh.plot()plotter = pv.Plotter(off_screen=True)plotter.add_mesh(mesh)plotter.show(screenshot=&quot;myscreenshot.png&quot;) Model Manipulation Rotate the Model # Rotate the meshangle = 45 # Angle in degreesmesh.rotate_x(angle) # Rotate 45 degrees around the x-axis# mesh.rotate_y(angle) # Rotate around the y-axis# mesh.rotate_z(angle) # Rotate around the z-axis# For rotation around an arbitrary axis (e.g., [1, 1, 1]), use:# mesh.rotate_vector([1, 1, 1], angle)# Now you can plot the rotated meshplotter = pv.Plotter()plotter.add_mesh(mesh)plotter.show() Move the Model import pyvista as pv# Assume 'mesh' is your PyVista mesh# ...# Translate the meshtranslation_vector = [10, 0, 0] # This will move the mesh 10 units along the x-axismesh.translate(translation_vector)# Now you can plot the translated meshplotter = pv.Plotter()plotter.add_mesh(mesh)plotter.show() pre { background-color:#38393d; color: #5fd381; }","link":"/2023/12/06/Bioinfor/pymol2pyvista/"},{"title":"Pymol: the best protein structure viewer","text":"View and Themes background color bg_color grey30 Display Amino Acid set seq_view, onset seq_view_format, 0 Add something Add Hydrogen bonds Add Hydrogen bonds: PyMOL tutorial Action → find → polar contacts → select from menu © PyMOL tutorial Remove something cite: © Jan-Philip Gehrcke; 2011 # removing hydrogensremove (hydro)remove hydrogens# removing waterremove resn hoh# removing solventremove solvent Get informations Chain information get_chains 4fqi cmd.get_chains: ['A', 'B', 'C', 'H', 'L'] PyMOL>replace C,4,4 Amino Acid Sequence source: pymolwiki print(cmd.get_fastastr('all'))# for only show chain B:print(cmd.get_fastastr('5WL2 and chain B')) >5WL2_H QVQLVQSGAEVKKPGSSVKVSCKASGGTFSSYAISWVRQAPGQGLEWMGGIIPIFGTANYAQKFQGRVTI TADESTSTAYMELSSLRSEDTAVYYCARHGNYYYYSGMDVWGQGTTVTVSSASTKGPSVFPLAPSSKSTS GGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKP SNTKVDKRVEPKSCHHHHHH >5WL2_L QSVLTQPPSVSEAPRQRVTISCSGSSSNIGNNAVNWYQQLPGKAPKLLIYYDDLLPSGVSDRFSGSKSGT SASLAISGLQSEDEADYYCAAWDDSLNGAVFGGGTQLTVLGQPKAAPSVTLFPPSSEELQANKATLVCLI SDFYPGAVTVAWKADSSPVKAGVETTTPSKQSNNKYAASSYLSLTPEQWKSHRSYSCQVTHEGSTVEKTV APTECS ... Object manipulation movement rotate y,-.2, 4fqhrotate x,-.2, 4fqhrotate z,-.2, 4fqh hide chain hide representation [,object]hide representation [,(selection)]hide (selection) Show Chain show cartoon, Mos99 and chain A chain B Colors for Pymol pymolwiki: Colors’ name and values Assign the name of color into an object # assign the color into an objectcolor red, Mos99# assign the color into selected molecules select part1, Mos99 and chain A and resi 50+56+60color hotpink, part1 Example of set a color by RGB value and assign it into an object set_color red2, [1,0.3,0.01]color red2, Mos99 Strcture align © Pymol fetch 1oky 1t46, async=0# 1) default with outlier rejectionalign 1oky, 1t46# 2) with alignment object, save to clustalw filealign 1oky, 1t46, object=alnobjsave alignment.aln, alnobj# 3) all-atom RMSD (no outlier rejection) and without superpositionalign 1oky, 1t46, cycles=0, transform=0 Partial structure align Cite: Queen’s University align 5cha and resi 1-100, 2xxl and resi 300-400# or in short form:align structure2 &amp; i. 1-100, structure 1 &amp; i. 300-400# Furthermore, you may wish to restrict the alignment to just the backbone atoms, so you can say:align structure2 and resi 1-100 and name n+ca+c+o, structure1 and resi 300-400 and name n+ca+c+o# or in short form:align structure2 &amp; i. 1-100 &amp; n. n+ca+c+o, structure1 &amp; i. 300-400 &amp; n. n+ca+c+o Align chains align 5cha and chain A+B+C, 2xxl and chain A Atom Atom color ## change the whole proteins colorcolor grey90, 2xxlcolor grey80, 2xxl 5cha # 2 proteins Select Atom Select Properties PyMolselect aas, resn ASP+GLU in 2xxl Create a variate ass which contain all ASP and GLU residues. pre { background-color:#38393d; color: #5fd381; } Distance In pymol, you cannot calculate the distance between 2 residues. You can only do it on molecules. For calculate the distance between 2 residues, we could use alpha carbon (CA) as the reference distance my_distance, 1tzg and chain P and resi 4 and name CA, 1tzg_H_L_P and chain H and resi 50 and name CA For searching the nearest distance between 2 residues, a easiest way is using python pymol module. But when if you could use python, than, maybe Biopython could be a better choice. from pymol import cmd# Load the structures (skip if already loaded)cmd.load(&quot;1tzg.pdb&quot;)cmd.load(&quot;1tzg_H_L_P.pdb&quot;)# Select atoms in the specified residuesresidue1 = &quot;1tzg and chain P and resi 4&quot;residue2 = &quot;1tzg_H_L_P and chain H and resi 50&quot;# Get atom identifiers for both residuesatoms1 = cmd.get_model(residue1).atomatoms2 = cmd.get_model(residue2).atom# Iterate over all atom pairs and calculate distancesMIN = 1000for atom1 in atoms1: for atom2 in atoms2: distance = cmd.get_distance(f&quot;{residue1} and name {atom1.name}&quot;, f&quot;{residue2} and name {atom2.name}&quot;) print(f&quot;Distance between {atom1.name} in residue {atom1.resi} and {atom2.name} in residue {atom2.resi}: {distance:.2f} Å&quot;) if distance &lt;= MIN: MIN = distance Zoom In pymol, you could zoom into a specific residues. Those different codes works differently. But they could achieve similar effects. zoom 1tzg and chain A and resi 51center 1tzg and chain A and resi 51orient 1tzg and chain A and resi 51 Location Moving Transition # Moving the entire chain A 10 unit from 8a95 cmd.translate([10.0, 0.0, 0.0], '8a95 and chain A')cmd.rotate('z', 45, chain_to_move)","link":"/2021/09/17/Bioinfor/pymol/"},{"title":"RNA-structure and Prediction","text":"RNA Structure and Prediction Like protein, RNA also has secondary structure, tertiary structure, and quaternary stricture, too. © wiki] In Secondary Structure, it could form: Double helix Stem-loop structure Pseudoknots wikipedia listed a bunch of tools for RNA secondary structure prediction. Online structure prediction servers: Mathews Lab RNAfold RAN Secondary Structure Format. DB format (Dot bracket) Unpaired nucleotides are indicated with the . or : characters. Matching pairs of parentheses indicate base pairs. To indicate non-nested base pairs (pseudoknots), additional brackets may be used: [], {}, or &lt;&gt;. Example: GGUGCAUGCCGAGGGGCGGUUGGCCUCGUAAAAAGCCGCAAAAAAUAGCAUGUAGUACC ((((((((((((((.[[[[[[..))))).....]]]]]]........)))))...)))) Secondary Structure Predict Seq: UGAGUGGUGUUGUUGGCUGCAUUAUGAUGUUGGUUAUAUUCUGGUUUUCUUCCACUCAACAACAACAACAACACGCAGUAGUAGAAGCAACAACAAGCAUAUAACCAACAUCAUAAUGCAGCCAACAACACCACUCA Website: RANfold Result: RNA Secondary Structure Plot RNAplot from ViennaRNA RNAplot tmp.db # RNAfold results RRNA in R install.package(&quot;RRNA&quot;)library(RRNA)coord=ct2coord(ct)ct=makeCt( &quot;(((((((((((((((((((((((((((((((((((((((.((.(((((((((.(((..((.................))))).)))).)).))).)).)))))))))))))))))))))))))))))))))))))))&quot;, &quot;UGAGUGGUGUUGUUGGCUGCAUUAUGAUGUUGGUUAUAUUCUGGUUUUCUUCCACUCAACAACAACAACAACACGCAGUAGUAGAAGCAACAACAAGCAUAUAACCAACAUCAUAAUGCAGCCAACAACACCACUCA&quot;)RNAPlot(coord,hl=c(&quot;GGGUUU&quot;,&quot;AAAUUU&quot;),seqcols=c(2,4),labTF=F) Python pip install RNA forgi pre { background-color:#38393d; color: #5fd381; }","link":"/2022/11/15/Bioinfor/rna-structure/"},{"title":"Common Contaminants in NGS","text":"Common Contaminants in Proteomic Data Sample: Drosophila Melanogaster Tag Annotation From Tax_Id=9606 Human Human: Duraing experiments Bos taurus Cattle Antibody or so Q9U6Y5 Green fluorescent protein (GFP-Cter-HisTag) GFP protein Genetic inserted tags P00761 TRYP_PIG Trypsin from pig Keratin Common contamination from air, skin, nail, or hair P15636 Protease I precursor Lysyl endopeptidase Achromobacter lyticus NA Common Contaminants from DNA-seq Microbiome from Ultrapure Water System UPW systemLocation of sampling portsNearest neighbor(s) of main strain in BLAST search of GenBankNo. of isolates (% total)UPWS-1Before UV254 (polishing loop)Ralstonia pickettii8 (13)Bradyrhizobium sp.3 (5)Flavobacterium sp.3 (5)Burkholderia sp.4 (6.7)Stenotrophomonas sp.5 (8.3)Mycobacterium sp.4 (6.7)Bacillus sp.8 (13.3)Other25 (41)UPWS-1DLRalstonia pickettii8 (24)Bradyrhizobium sp.12 (36)Pseudomonas saccharophilia4 (12)Other9 (27)UPWS-2After UV254, UV185, and final filters (0.1 μm)Bradyrhizobium sp.6 (60)Other4 (40)UPWS-3DLRalstonia pickettii4 (66)Bradyrhizobium sp.1 (17)Other1 (17)UPWS-4DL and DL (return loop)Bradyrhizobium sp.4 (25)Pseudomonas saccharophilia4 (25)Sphingomonas sp.4 (25)Other4 (25)UPWS-5DLRalstonia pickettii6 (100)UPWS-6DL, storage tank, before UV254 and after UV254Pseudomonas fluorescens6 (28)Ralstonia pickettii5 (24)Pseudomonas saccharophilia1 (5)Bradyrhizobium sp.2 (10)Sphingomonas sp.3 (14)Other4 (19) © Leonid A. Kulakov, et al., 2002 [1] pre { background-color:#38393d; color: #5fd381; } Kulakov LA, McAlister MB, Ogden KL, Larkin MJ, O’Hanlon JF (April 2002). “Analysis of bacteria contaminating ultrapure water in industrial systems”. Applied and Environmental Microbiology. 68 (4): 1548–55. doi:10.1128/AEM.68.4.1548-1555.2002. PMC 123900. PMID 11916667. ↩︎","link":"/2022/09/20/Bioinfor/proteomic-contaminants/"},{"title":"samtools","text":"samtools span .tag { background-color:#38393d; color: #5fd381; } Quick start samtools sort -@ 30 any.sam &gt; sorted.bamsamtools index sorted.bamsamtools tview sorted.bam Trinity.fasta -p &quot;ID:35&quot; -d T &gt; resultsamtools tview sorted.bam ../../2-Trinity/Trinity.fasta -p &quot;comp0_c0_seq1:35&quot; -d H &gt; 123.html *.bam file *.fasta file -p posation, fasta name and star posation of the fasta : Install wget -c https://github.com/samtools/samtools/releases/download/1.12/samtools-1.12.tar.bz2tar -xjf samtools-1.12.tar.bz2cd samtools-1.12ls./configuremake &amp; make install Install through conda conda install sra-tools Sorting by bam files samtools sort bwa.bam -o bwa.sorted.bam &gt; bwa.sorted.bam Index samtools faidx genome.fna Depth count samtools depth -r 2R:24687896-24687900 out.bam 2R 24687896 41 2R 24687897 41 2R 24687898 41 2R 24687899 41 2R 24687900 41 Reads counts in bam # counting all readssamtools view -c SAMPLE.bam# orsamtools view SAMPLE.bam |wc# counting only mapped readssamtools view -c -F 260 SAMPLE.bam Time cousts for -c and wc -c |wc -l 0m16.497s 0m44.720s","link":"/2020/07/28/Bioinfor/samtools/"},{"title":"FPKM, RPKM, CPM, TPM, TMM in RNA-Seq","text":"RPKM/FPKM (reads/fragments per kilobase of transcript per million reads mapped) $$ FPKM_ i = \\frac{q_ i}{l_ i × \\sum_ i{q_ i}}×10^ 9 $$ $q_i$ is raw read or fragment counts, $l_i$ is feature (i.e., gene or transcript) length RPKM is for single ends reads, a read is a unit. FPKM is for paired ends reads, a paired reads is a unit. TPM (transcript per million) $$ TPM_ i = \\frac{q_ i/l_ i}{\\sum_ j{q_ i/l_ i}}×10^ 6 $$ 0 where $q_i$ denotes reads mapped to transcript, $l_i$ is the transcript length, and $\\sum_ j{q_ i/l_ i}$ corresponds to the sum of mapped reads to transcript normalized by transcript length. The TPM measure can easily be converted to FPKM: $TPM_ i = \\frac{FPKM_ i}{\\sum_ j{FPKM_ i}}×10^ 6$ CPM (counts per million reads mapped (CPM) $$ CPM_ i = \\frac{q_ i}{\\sum_ i{q_ i}} × 10^ 6 $$ The simplest RNA-seq feature expression unit reports normalized counts, or the number of reads that align to a particular feature after correcting for sequencing depth and transcriptome composition bias. Normalized counts are the most popular unit among differential expression analysis methods (including edgeR). However, feature length normalization is skipped, with the important consequence that within-sample differential feature expression analysis is not possible. Shortcomings Example 1: We have 2 genes: Length Sample1 Sample2 Gene1 100 200 200 Gene2 2400 0 1200 CPM &lt;- function(TB) {}FPKM &lt;- function(TB) {}TPM &lt;- function(TB) {} Others TMM (trimmed mean of M values frpm edgeR) RLE (Relative Log Expression from DESeq) MRN (Median Ratio Normalization) Though, TPM, RPKM, and FPKM are designed to normalize the expression levels of genes, it suitable for the comparison within a sample, not cross samples[1]. According to Dillies[2], normalization algorithms could be divided into two groups: library size concept (TMM and DESeq) or distribution adjustment of read counts (Total Counts, RPKM, Quantile from limma). The hypothesis of TMMP and DESeq is that most of genes are not DE and the both propose a scaling factor based on a mean, median, or ratio. Based on Real data and simulated date, TMM and DESeq’s performance are acceptable, but RPKM and total counts of genes are not suggested to be used on the down stream analysis[2:1][1:1]. On the other hand, RPKM, FPKM, and TPM tend to perform poorly when transcript distribution differ between samples[3]. In another reseach, the title is without replicates RNA-Seq, but the data set is triplicates shows that the results from TMM, RLE, and MRN are really similar[4]. And for more complicated comparison, MRN might be better[5]. pre { background-color:#38393d; color: #5fd381; } Zhao, Y., Li, MC., Konaté, M.M. et al. TPM, FPKM, or Normalized Counts? A Comparative Study of Quantification Measures for the Analysis of RNA-seq Data from the NCI Patient-Derived Models Repository. J Transl Med 19, 269 (2021). https://doi.org/10.1186/s12967-021-02936-w ↩︎ ↩︎ Dillies MA, Rau A, Aubert J, Hennequet-Antier C, Jeanmougin M, Servant N, Keime C, Marot G, Castel D, Estelle J, et al. A comprehensive evaluation of normalization methods for Illumina high-throughput RNA sequencing data analysis. Brief Bioinform. 2013;14:671–83. ↩︎ ↩︎ Conesa A, Madrigal P, Tarazona S, Gomez-Cabrero D, Cervera A, McPherson A, Szczesniak MW, Gaffney DJ, Elo LL, Zhang X, Mortazavi A. A survey of best practices for RNA-seq data analysis. Genome Biol. 2016;17:13. ↩︎ Maza E (2016) In Papyro Comparison of TMM (edgeR), RLE (DESeq2), and MRN Normalization Methods for a Simple Two-Conditions-Without-Replicates RNA-Seq Experimental Design. Front. Genet. 7:164. doi: 10.3389/fgene.2016.00164 ↩︎ Maza, E., Frasse, P., Senin, P., Bouzayen, M., and Zouine, M. (2013). Comparison of normalization methods for differential gene expression analysis in RNA-Seq experiments: a matter of relative size of studied transcriptomes. Commun. Integr. Biol. 6:e25849. doi: 10.4161/cib.25849 ↩︎","link":"/2022/10/04/Bioinfor/rnaseq-norm/"},{"title":"abi processing","text":"Processing Sanger Sequencing file (abi) wiht Python or R In R, you can using sangerseqR to reading ab1 file. An example can see: Karobben 2020 Python Biopython from Bio import SeqIOhandle = open(&quot;test.ab1&quot;, &quot;rb&quot;)for record in SeqIO.parse(handle, &quot;abi&quot;): print(record) Trace plot Biopython: Click hear Package sanger-sequencing Link Can’t find any examples… Perl ABIF Convert abi to Scf reference: stock overflow convert_trace -out_format scf &lt; trace.ab1 &gt; trace.scf Convert ab1 to excel Working Manual: ab1_organizer pip install ab1_organizerab1_organizer.py -f ./path/to/zip/file -t ./path/to/order/table.xlsx Base Calling GitHub: tracy Documentation Paper (PS: It seems like we need to download some files from google. So, as you can see, it’s not easy for the people in China mainland to install it.) It is a great app for basecalling, alignment, assembly and deconvolution of sequencing chromatogram files. Installation apt install \\ build-essential g++ \\ cmake \\ git-all \\ liblzma-dev \\ zlib1g-dev \\ libbz2-dev \\ liblzma-dev \\ libboost-date-time-dev \\ libboost-program-options-dev \\ libboost-system-dev \\ libboost-filesystem-dev \\ libboost-iostreams-devgit clone --recursive https://github.com/gear-genomics/tracy.gitcd tracy/make allmake install./bin/tracy -h","link":"/2020/09/05/Bioinfor/sanger_seq/"},{"title":"Phylogenetic Tree","text":"What is Phylogenetic Tree A phylogenetic tree is a diagram representing the evolutionary relationships among species or other entities based on their genetic or physical characteristics. The branches of the tree indicate how these species have evolved from common ancestors. The tree can be rooted, showing the most recent common ancestor, or unrooted, illustrating relationships without a common origin point. Constructed using data like DNA sequences or morphological traits, these trees are essential in studying evolutionary biology, tracking disease evolution, and in conservation efforts. They provide a visual representation of the evolutionary history and connections between different forms of life. (GPT4) General Ideas of Phylogenetic Tree Source: Evo 101, Berkeley Distance Matrix (GPT4) More related source could be found at academic accelerator A distance matrix, in general, is a table used to show the distance between elements in a set. In the context of phylogenetics, it represents the genetic distance between various species or sequences. A distance matrix in phylogenetics is a tool to quantify and visualize the genetic distances between different species or sequences. This matrix forms the basis for constructing phylogenetic trees, which depict the evolutionary relationships and history among the species studied. 1. General Distance Matrix This is a square matrix where the elements represent the distances between pairs of objects. In the matrix, each row and column represents an object, and each cell in the matrix shows the distance between the two objects. The distances can be based on various metrics, depending on the context (e.g., physical distance, similarity in characteristics, etc.). 2. Distance Matrix in Phylogenetics In phylogenetics, the distance matrix represents genetic distances between different species or DNA sequences. The genetic distance can be based on differences in DNA, RNA, or protein sequences, indicating how much genetic change has occurred between the sequences. The distances are often calculated using methods that count the number of differences between sequences (like nucleotide substitutions) or more complex models that account for the rate of evolution and types of mutations. 3. How it Works in Phylogenetics Data Collection: First, genetic data (like DNA sequences) from different species or organisms are collected. Distance Calculation: Algorithms calculate the genetic distance between each pair of sequences. These calculations can be straightforward (like counting differences) or complex (accounting for evolutionary models). Matrix Formation: These distances are then arranged in a matrix format, where each row and column represents a species or sequence, and each cell shows the genetic distance between them. Tree Construction: Phylogenetic trees can be constructed using this matrix. Methods like UPGMA (Unweighted Pair Group Method with Arithmetic mean) or neighbor-joining are used to create trees that best reflect the distances in the matrix. Analysis: The resulting tree is analyzed to understand evolutionary relationships, like which species are more closely related based on the genetic distances. © academic accelerator How to make the sense of the dendrogram? This graph illustrates the distance matrix and how it gives sense to the phylogenetic tree. According to the tree, the distance between b and c is 1+2=3. Similarly, we can deduce from the tree that the distance between a and d is 4+4+1=9. Methods for Calculating the Distance Matrix (GPT4) In phylogenetics, there are several methods to calculate the distance matrix, each with its own approach to measuring genetic distances between sequences. These methods vary in complexity and the types of evolutionary changes they consider. Here are some commonly used methods: 1. Simple Counting Methods These involve counting the number of differences (e.g., nucleotide or amino acid substitutions) between each pair of sequences. One example is the Hamming distance, which is simply the number of positions at which the corresponding elements (nucleotides or amino acids) are different. 2. Corrected Distance Methods These methods account for multiple changes at the same site and unseen changes due to evolutionary processes. An example is the Jukes-Cantor model, which corrects for multiple substitutions at the same site by assuming that all changes occur at the same rate. 3. Model-Based Methods These use complex models of sequence evolution, accounting for factors like different rates of substitution between different nucleotides or amino acids, transition/transversion bias, and others. Examples include the Kimura 2-parameter model and the Tamura-Nei model, which provide more sophisticated ways to estimate genetic distances by incorporating specific evolutionary assumptions. 4. Maximum Likelihood and Bayesian Methods These are more computationally intensive methods that use probabilistic models of sequence evolution. They estimate the likelihood of observing the data given various possible evolutionary histories and can provide more accurate estimates of genetic distances. Each of these methods has its own strengths and limitations, and the choice of method often depends on the specifics of the data and the research question. Simple counting methods are straightforward but may underestimate distances, especially when sequences have diverged significantly. Corrected distance and model-based methods provide more accurate estimates by considering the complexities of molecular evolution, but they require more computational resources and deeper understanding of evolutionary models. Maximum likelihood and Bayesian methods are highly accurate but computationally demanding. In practice, the choice of method is often a balance between the need for accuracy and the availability of computational resources, as well as the evolutionary characteristics of the organisms being studied. Different Ways to Illustrate the Tree (By GGTREE) © YuLab@SMU Something You’d Like to Know About Phylogenetic Trees (Chat4) When working with phylogenetic trees, there are several key points and common misconceptions to be aware of: 1. Tree Topology Matters More Than Branch Length The branching pattern (topology) of the tree indicates the evolutionary relationships among the species or genes in the tree. However, unless explicitly stated, the length of the branches might not represent evolutionary time or genetic distance. 2. Branch Points (Nodes) Represent Common Ancestors Each node where branches diverge represents the most recent common ancestor of the groups branching off from that node. 3. Reading the Tree Correctly A common misunderstanding is the way to interpret the tree's layout. The tree should be read as a series of branching events, not as a left-to-right progression. The order of groups along the tips of the branches doesn't necessarily indicate any specific type of progression or superiority. 4. Phylogenetic Trees Are Hypothetical These trees are based on the best available data and the most accurate methods at the time. As new data emerge, the tree might be modified. 5. Rooted vs. Unrooted Trees Rooted trees have a single ancestral lineage (usually at the base) that serves as a common ancestor for all the entities in the tree. Unrooted trees do not show an ancestral root and are used to illustrate the relationships between different lineages without assuming their descent from a common ancestor. 6. Monophyletic, Paraphyletic, and Polyphyletic Groups Misunderstanding these terms can lead to confusion. Monophyletic groups include an ancestor and all its descendants, paraphyletic groups include an ancestor and some but not all descendants, and polyphyletic groups are characterized by members that do not share a recent common ancestor in the context of the tree. 7. Convergent Evolution Can Be Misleading Sometimes, unrelated species may appear closely related due to similar selective pressures rather than shared ancestry, a phenomenon known as convergent evolution. 8. Horizontal Gene Transfer Especially in bacterial phylogenetics, horizontal gene transfer can complicate the interpretation of evolutionary relationships. Understanding these points can help in correctly interpreting phylogenetic trees and avoiding common misconceptions. It’s also important to remember that phylogenetics is a constantly evolving field, with new methods and data continually refining our understanding of evolutionary relationships. Beyond the Distance Matrix (Chat4) Phylogenetic trees can also be constructed without using a distance matrix. The construction of phylogenetic trees can be broadly categorized into two main approaches: distance-based methods and character-based methods. While distance-based methods do rely on distance matrices, character-based methods do not. Here’s a brief overview of these approaches: Distance-Based Methods: These methods, such as UPGMA (Unweighted Pair Group Method with Arithmetic Mean) and Neighbor-Joining (exp, -QUICKTREE from clustalW), rely on a distance matrix that represents the genetic distance (differences) between pairs of taxa. The matrix is used to construct a tree that represents these distances as accurately as possible. Character-Based Methods: These methods do not use a distance matrix. Instead, they directly analyze the character states (such as DNA, RNA, or protein sequences) of the taxa being studied. There are two primary types of character-based methods: Maximum Parsimony: This method identifies the tree that requires the smallest number of evolutionary changes. It looks for the tree that explains the data with the least amount of complexity, without involving a distance matrix. Maximum Likelihood and Bayesian Methods: These are statistical methods that evaluate different possible phylogenetic trees and choose the tree that is most likely to have produced the observed set of data. These methods are based on explicit models of evolutionary change and do not rely on a pre-calculated distance matrix. Each method has its advantages and limitations, and the choice of method can depend on the type of data available, the computational resources, and the specific objectives of the study. Character-based methods, especially those involving statistical approaches like Maximum Likelihood and Bayesian Inference, have become increasingly popular due to their ability to incorporate complex models of evolutionary change and handle large datasets effectively. The Difference Between NJ-Tree and ML-Tree (Chat4) The popularity and suitability of the Neighbor-Joining (NJ) and Maximum Likelihood (ML) methods for constructing phylogenetic trees depend on the specific requirements and constraints of the research being conducted. Both methods have their advantages and limitations, and their appropriateness can vary based on factors like data complexity, computational resources, and the level of accuracy needed. Popularity Neighbor-Joining (NJ): Historically, NJ has been very popular, particularly in earlier studies, due to its computational efficiency. It’s well-suited for large datasets where quick, preliminary analyses are needed. NJ’s simplicity and speed made it a go-to method for many researchers, especially before the widespread availability of powerful computational resources. Maximum Likelihood (ML): With the increase in computational power and the development of more sophisticated software, ML has gained substantial popularity, especially in more recent studies. It is often preferred for its ability to provide more accurate and statistically robust trees, especially for complex datasets. Feature Neighbor-Joining (NJ) Maximum Likelihood (ML) Speed and Efficiency Fast and efficient, ideal for large datasets and quick analyses. Slower and computationally intensive, especially with larger datasets. Accuracy Less accurate for complex evolutionary models; sensitive to rate variation and sampling errors. More accurate and statistically robust across a wide range of datasets. Evolutionary Models Does not explicitly model evolutionary processes. Incorporates explicit models of sequence evolution, handling varying rates of evolution better. Computational Resources Less demanding, suitable for limited computational resources. Requires significant computational power for large and complex datasets. Statistical Support Limited statistical measures for tree support. Provides robust statistical measures (like bootstrap values) for tree support. Use Case Suitable for preliminary or rapid analyses when computational resources are limited. Preferred for detailed, accurate phylogenetic analyses where computational resources are available. Complexity and Understanding Simpler to understand and use. Requires a good understanding of evolutionary models and statistical methods. Conclusion The choice between NJ and ML largely depends on the specific requirements of your phylogenetic analysis. For preliminary or rapid analyses with large datasets, NJ remains popular due to its speed. However, for in-depth studies where accuracy and model-based statistical rigor are crucial, ML is often considered superior, albeit at the cost of greater computational demand. With ongoing advancements in computational methods and resources, ML is becoming increasingly accessible and popular in phylogenetic studies. Maximum Likelihood Maximum Likelihood (ML) is a statistical method used in the construction of phylogenetic trees, which represent the evolutionary relationships among various species or genetic sequences. This method is based on the principle of finding the tree topology (i.e., the arrangement of branches and nodes) that has the highest probability of producing the observed set of genetic data. Here’s a simplified explanation of how it works: Model of Sequence Evolution: ML requires a model of sequence evolution. This model includes parameters such as the rates of different types of mutations (e.g., transitions and transversions in nucleotide sequences), the frequency of each nucleotide or amino acid, and potentially other factors like the rate at which different parts of the sequence evolve. These models attempt to approximate the real biological processes that lead to changes in genetic sequences over time. Tree Topologies: The algorithm considers different possible tree topologies. A topology is a specific arrangement of species or sequences on a tree, indicating how they are related to each other. Calculating Likelihoods: For each tree topology, the likelihood that the observed data (genetic sequences of the species or taxa being studied) would evolve according to the specified model is calculated. This involves complex computations where the algorithm assesses the probability of changes occurring along the branches of the tree to result in the observed sequences at the tree’s tips (leaves). Comparing Trees: The likelihoods of different tree topologies are compared. The tree with the highest likelihood is considered the best estimate of the true evolutionary relationships among the sequences. This is because, under the chosen model, this tree would be the most likely to produce the observed data. Optimization and Searching: Because there are usually an extraordinarily large number of possible tree topologies (increasing exponentially with the number of sequences), it’s impractical to evaluate every possible tree. Therefore, heuristic algorithms are used to search tree space efficiently, focusing on those areas where higher likelihood trees are more likely to be found. Statistical Testing: Often, statistical methods such as bootstrap analysis are used to test the reliability of the tree. This involves resampling the data and recalculating trees to see how often certain groupings appear, providing a measure of confidence in the tree’s branches. Maximum Likelihood is favored for its statistical rigor and its ability to provide a clear criterion (likelihood) for choosing among trees. However, it is computationally intensive, especially for large datasets, and the results can be sensitive to the choice of the evolutionary model. Despite these challenges, ML remains a popular and powerful method in phylogenetic analysis. A Simple Practice In this practice, we generated genetic data for two species and their common ancestor. We then used the Jukes-Cantor model to calculate the likelihood of the observed sequences given a tree topology and a mutation rate. Here’s a summary of the process and results: Generated Data: We created random genetic sequences for a common ancestor and two descendant species. Jukes-Cantor Model: This model was used to estimate the likelihood of one sequence evolving into another under a uniform mutation rate. Initial Likelihood Calculation: For the given tree topology (where the common ancestor is the parent of both species), we calculated the likelihood of this tree using a mutation rate of 0.1. The likelihood was found to be approximately 20.46. Optimization: We used an optimization algorithm to find the mutation rate that maximizes the likelihood of the observed data given the tree structure. The optimal mutation rate was found to be 1.0. Optimized Likelihood: Recalculating the likelihood with the optimized mutation rate, we obtained an improved likelihood of approximately 7.05. This demonstration shows how Maximum Likelihood is used in phylogenetics to find the most likely tree structure and parameters (like mutation rate) that explain the observed genetic data. In real-world scenarios, the data and models are much more complex, and the computations are more intensive, but the underlying principles remain the same. ​ # Corrected implementation for demonstrating Maximum Likelihood in phylogenetics# Generate a simple example dataset with direct ancestor-descendant relationshipsnp.random.seed(0)# Assume we have two species and their common ancestordata = { &quot;Common_Ancestor&quot;: np.random.choice(['A', 'T', 'G', 'C'], 10), &quot;Species_A&quot;: np.random.choice(['A', 'T', 'G', 'C'], 10), &quot;Species_B&quot;: np.random.choice(['A', 'T', 'G', 'C'], 10)}df = pd.DataFrame(data)print(&quot;Generated Genetic Data:\\n&quot;, df)# Define a simple model of sequence evolutiondef jukes_cantor_model(seq1, seq2, mu): &quot;&quot;&quot; Jukes-Cantor model to calculate the likelihood of seq2 evolving from seq1 under a uniform mutation rate mu. &quot;&quot;&quot; diff = sum(c1 != c2 for c1, c2 in zip(seq1, seq2)) same = len(seq1) - diff p_diff = 3/4 * (1 - np.exp(-4/3 * mu)) p_same = 1/4 + 1/4 * np.exp(-4/3 * mu) likelihood = (p_diff ** diff) * (p_same ** same) return likelihood# Function to calculate the likelihood of a tree given the datadef tree_likelihood(tree, data, mu): &quot;&quot;&quot; Calculate the likelihood of a given tree topology. The tree is represented as a dictionary where keys are nodes and values are the sequences. &quot;&quot;&quot; likelihood = 1.0 for parent, child in tree.items(): parent_seq = data[parent] child_seq = data[child] likelihood *= jukes_cantor_model(parent_seq, child_seq, mu) return -log(likelihood) # negative log-likelihood for optimization# Example tree topology (parent: child)tree_example = { &quot;Common_Ancestor&quot;: &quot;Species_A&quot;, &quot;Common_Ancestor&quot;: &quot;Species_B&quot;,}# Assume a mutation rate (mu)mu = 0.1# Calculate the likelihood of this treelikelihood = tree_likelihood(tree_example, df, mu)print(&quot;\\nLikelihood of the tree:&quot;, likelihood)# Now we will use optimization to find the mutation rate that maximizes the likelihooddef optimize_mu(mu, tree, data): return tree_likelihood(tree, data, mu)result = minimize(optimize_mu, x0=mu, args=(tree_example, df), bounds=[(0.001, 1)])optimal_mu = result.x[0]print(&quot;\\nOptimal mutation rate:&quot;, optimal_mu)# Recalculate the likelihood with the optimized mutation rateoptimized_likelihood = tree_likelihood(tree_example, df, optimal_mu)print(&quot;\\nOptimized likelihood of the tree:&quot;, optimized_likelihood) Generated Genetic Data: Common_Ancestor Species_A Species_B 0 A T G 1 C G C 2 T A C 3 A C G 4 C G A 5 C A T 6 C A T 7 C A T 8 T G T 9 C T A Likelihood of the tree: 20.463275567320334 Optimal mutation rate: 1.0 Optimized likelihood of the tree: 7.05394379820434 Things You’d Like to Know Pairwise Comparisons: In the ML approach, the focus is not typically on pairwise comparisons between sequences (as it is in methods like distance matrix or neighbor-joining). Instead, ML evaluates the likelihood of entire tree topologies. It looks at how likely it is for a given tree structure, with its branching pattern and lengths, to have produced the observed set of genetic sequences under a specific evolutionary model. Likelihood Calculations: For each possible tree topology, ML calculates the likelihood that the proposed tree would result in the observed data (e.g., DNA, RNA, or protein sequences). This calculation involves estimating the probability of changes in the sequences along each branch of the tree. The likelihood depends on both the tree topology (how the branches are arranged) and the model parameters (like mutation rates). Optimization: The goal is to find the tree topology (and associated model parameters) that maximizes the likelihood. Due to the vast number of possible trees, especially with larger datasets, heuristic search algorithms are used to navigate the space of possible trees efficiently. Likelihood Matrix: Unlike methods that rely on a distance matrix, ML doesn’t typically produce a matrix of pairwise likelihoods. Instead, it directly evaluates the likelihood of entire tree topologies. Resulting Tree: The end result of an ML analysis is a single tree (or sometimes a set of trees) that has the highest likelihood given the data and the chosen model. This tree represents the estimated evolutionary relationships among the sequences. Dendrogram/Phylogenetic Tree: The final output is a phylogenetic tree (often visualized as a dendrogram) that represents the hypothesized evolutionary relationships among the species or sequences analyzed. This tree is based on the topology that provided the highest likelihood. In summary, while ML involves complex calculations involving the entire tree, it doesn’t use a pairwise likelihood matrix in the same way that distance-based methods use a distance matrix. The primary focus of ML is on evaluating and comparing the likelihoods of different tree topologies to find the one that best explains the observed data under a given evolutionary model. pre { background-color:#38393d; color: #5fd381; }","link":"/2023/12/18/Bioinfor/phylogenetic/"},{"title":"Pseudotime Analysis with Monocle: A Beginner&#39;s Guide","text":"Psudotime Analysis Introduction In the complex world of cellular dynamics and differentiation, tracking the progression of individual cells can seem like tracking a grain of sand on a beach. Fortunately, pseudotime analysis using tools like Monocle has made it more accessible. But what is pseudotime? And why should we use Monocle for it? Let’s dive in. What is Pseudotime? Pseudotime is a computational concept used to order cells based on their progression in a particular process, like differentiation. Rather than relying on actual time (which isn’t available in static single-cell datasets), pseudotime arranges cells in a continuum that reflects their progression state. In simple words, it’s like retracing the journey of a cell from its starting point to its destination, based on markers or genes it expresses. Why Do We Use Pseudotime Analysis? Mode details in Monocle Choosing Genes for Trajectory: Monocle selects genes that define cellular progress for its machine learning approach. This feature selection is vital as it impacts the trajectory shape. While some low-expressed genes can be noisy, they might hold essential cellular information. Monocle identifies genes with meaningful variations to structure the data. Users can either let Monocle autonomously choose genes (unsupervised) or input known genes to guide the trajectory (semi-supervised). Dimensionality Reduction: After gene selection, Monocle reduces the data’s dimensionality using the Reversed Graph Embedding algorithm. Pseudotime Cell Ordering: Monocle projects expression data into a reduced dimension space to determine the cellular trajectory. It presumes a tree-structured trajectory with a root and leaves. Monocle’s objective is to best fit this tree to the data. Cells begin at the root and move along the trajectory, making decisions at branches until reaching a leaf. A cell’s pseudotime is the distance from its position back to the root. How Does Monocle Work? Monocle stands out in the world of pseudotime analysis because of its robustness and flexibility. Here’s a simplified overview of how it functions: Expression Data Input: Monocle takes in single-cell RNA-sequencing data. Each cell’s gene expression profile serves as a unique identifier of its state. Dimensionality Reduction: The vastness of gene expression data is reduced into manageable dimensions using techniques like DDRTree or UMAP. Trajectory Construction: Using the reduced dimensions, Monocle constructs a trajectory that orders cells based on their progression. Pseudotime Assignment: Cells are then assigned a pseudotime value based on their position in the trajectory. What Makes Monocle Special? Several tools offer pseudotime analysis, but Monocle has some distinct advantages: Handling Complex Trajectories: Monocle can discern branched trajectories, which is crucial when cells can differentiate into multiple types. Flexibility: It is amenable to various types of analyses beyond just pseudotime, such as differential expression analysis across trajectories. Comparison with Other Techniques Monocle vs. Wanderlust: While both are used for trajectory analysis, Wanderlust was primarily designed for mass cytometry data. Monocle offers a more generalized approach, suitable for scRNA-seq data. Monocle vs. Slingshot: Slingshot is another tool for pseudotime analysis of scRNA-seq data. While Slingshot excels in simplicity and user-friendly plotting functions, Monocle’s capability to handle more complex trajectories gives it an edge in certain scenarios. Pros and Cons of Using Monocle Advantages: Robust in handling complex cellular trajectories. Suitable for various analyses. Well-documented and supported by an active community. Disadvantages: Might have a steeper learning curve for beginners. Certain computations can be time-intensive. Conclusion Pseudotime analysis using Monocle offers a deep dive into cellular dynamics, helping researchers unravel mysteries of cell fate decisions, disease progression, and more. While it’s one of many tools available, its capability to deal with complexity makes it a choice worth considering. Like any tool, its efficacy is determined by the skill and knowledge of the user, so if you’re looking to use Monocle, investing time in understanding its nuances will be immensely rewarding. Pepeline from Seurat to Monocle First, we need to use the SeuratWrappers library to conver the Seurat object into Monocle manageble data[1]. # remotes::install_github('cole-trapnell-lab/monocle3')library(Signac)library(Seurat)library(SeuratWrappers)library(monocle3)library(Matrix)library(ggplot2)library(patchwork)erythroid.cds &lt;- as.cell_data_set(seurat_object)erythroid.cds &lt;- cluster_cells(cds = erythroid.cds, reduction_method = &quot;UMAP&quot;)# try a subset if R is killed due to lack of RAM erythroid.cds &lt;- learn_graph(erythroid.cds, use_partition = TRUE)# select the root cell (a list of cell tags)hsc &lt;- readLines(&quot;../vignette_data/hsc_cells.txt&quot;)erythroid.cds &lt;- order_cells(erythroid.cds, reduction_method = &quot;UMAP&quot;, root_cells = hsc)plot_cells( cds = erythroid.cds, color_cells_by = &quot;pseudotime&quot;, show_trajectory_graph = TRUE) MonoCle pre { background-color:#38393d; color: #5fd381; } 2023; Signac; Building trajectories with Monocle 3 ↩︎","link":"/2023/10/19/Bioinfor/scMonocle/"},{"title":"Integrating scRNA-Seq and scATAC-Seq Data: A Primer","text":"Single-cell sequencing technologies have revolutionized our understanding of cellular heterogeneity. Among these technologies, scRNA-Seq and scATAC-Seq stand out for their ability to profile gene expression and chromatin accessibility, respectively. But how can we integrate these two types of data to gain a more comprehensive view of cellular states? Let’s dive in! Other tutorial: Seurat tutorial Understanding the Data scRNA-Seq: Provides gene expression levels in individual cells. The resulting matrix has genes as rows and cells as columns, with values representing gene expression levels. scATAC-Seq: Profiles chromatin accessibility at specific genomic regions. The resulting matrix has genomic regions (peaks) as rows and cells as columns, with binary values indicating accessibility. The Challenge At first glance, these matrices seem incompatible. One provides gene-centric information, while the other is focused on genomic regions. So, how can we integrate them? From Peaks to Genes A common approach is to associate scATAC-Seq peaks with nearby genes. This can transform the scATAC-Seq matrix into a gene-by-cell matrix, similar to scRNA-Seq. Strategies include: Assigning each peak to the nearest gene’s transcription start site (TSS). Using tools that provide more sophisticated peak-to-gene assignment methods. Integration Using Latent Spaces Tools like Seurat don’t directly merge the matrices. Instead, they: Identify shared “latent spaces” or underlying patterns in the data. Find features (genes) that are highly variable in both datasets to serve as “anchors.” Use these anchors to align the datasets in a shared latent space. Once integrated, joint analyses, such as clustering, can identify cell types present in both datasets. Example Integration Workflow From Peak to Seurat Object A Seurat Object for ATAC data need more things than RNA matrix. Except peak matrix as the ChromatinAssay object, we still need to ready the Chromosome annatation file for gene activity estimation. We also need the Fragment Object. library(Signac)library(Seurat)# read the peak counts matrixpeaks &lt;- readRDS('norm_peak_counts.rds')# convert it as ChromatinAssay object. We can define the type of genome here. But I chooce not.chromatinassay &lt;- CreateChromatinAssay(counts = peaks)#, genome = &quot;dm6&quot;)atac_seurat &lt;- CreateSeuratObject(counts = chromatinassay, assay = &quot;ATAC&quot;)# read meta infors for the cells if you havecell_predictions &lt;- readRDS(&quot;cell_predictions.rds&quot;)atac_seurat@meta.data &lt;- cbind(atac_seurat@meta.data, cell_info_all)# if you have pre-ran demention redundance data like UMAPatac_seurat[[&quot;UMAP&quot;]] &lt;- CreateDimReducObject(embeddings = as.matrix(cell_info_all[c(&quot;UMAP_1&quot;, &quot;UMAP_2&quot;)]), key = &quot;UMAP_&quot;, assay = DefaultAssay(atac_seurat))atac_seurat &lt;- NormalizeData(atac_seurat)atac_seurat &lt;- FindVariableFeatures(atac_seurat)# add Fragments object for gene activity countingfragments &lt;- CreateFragmentObject('fragments.tsv.gz', cells = colnames(x = atac_seurat), verbose = FALSE, tolerance = 0.5)Fragments(atac_seurat) &lt;- fragments# Annotation information# cite: https://github.com/stuart-lab/signac/discussions/1088library(AnnotationHub)ah &lt;- AnnotationHub()query(ah, &quot;EnsDb&quot;)ahDb &lt;- query(ah, pattern = c(&quot;Drosophila&quot;, &quot;EnsDb&quot;))flygenome &lt;- ahDb[[19]]annotations &lt;- GetGRangesFromEnsDb(ensdb = flygenome)seqlevelsStyle(annotations) &lt;- 'NCBI'Annotation(atac_seurat) &lt;- annotations# save the ATAC Seurat object to avoid the creating againsaveRDS(atac_seurat, 'scATAC.rds') Integration # Normalize and find variable features for both datasetsatac_seurat &lt;- NormalizeData(atac_seurat)atac_seurat &lt;- FindVariableFeatures(atac_seurat)rna_seurat &lt;- NormalizeData(rna_seurat)rna_seurat &lt;- FindVariableFeatures(rna_seurat)# run the lsi demaintion dungrationpbmc.atac &lt;- RunTFIDF(pbmc.atac)pbmc.atac &lt;- FindTopFeatures(pbmc.atac, min.cutoff = &quot;q0&quot;)pbmc.atac &lt;- RunSVD(pbmc.atac)# estimate the gene activities of the feature genes gene.activities &lt;- GeneActivity(pbmc.atac, features = VariableFeatures(pbmc.rna))pbmc.atac[[&quot;ACTIVITY&quot;]] &lt;- CreateAssayObject(counts = gene.activities)DefaultAssay(pbmc.atac) &lt;- &quot;ACTIVITY&quot;pbmc.atac &lt;- NormalizeData(pbmc.atac)pbmc.atac &lt;- ScaleData(pbmc.atac, features = rownames(pbmc.atac)) Anchors identifycation This step would take lots of time. # Identify anchorstransfer.anchors &lt;- FindTransferAnchors(reference = rna_seurat, query = atac_seurat, features = VariableFeatures(object = rna_seurat), reference.assay = &quot;RNA&quot;, query.assay = &quot;ACTIVITY&quot;, reduction = &quot;cca&quot;) Label transfer After identifying anchors, we can transfer annotations from the scRNA-seq dataset onto the scATAC-seq cells. The annotations are stored in the seurat_annotations field, and are provided as input to the refdata parameter. The output will contain a matrix with predictions and confidence scores for each ATAC-seq cell. celltype.predictions &lt;- TransferData(anchorset = transfer.anchors, refdata = rna_seurat$seurat_annotations, weight.reduction = atac_seurat[[&quot;lsi&quot;]], dims = 2:30)atac_seurat &lt;- AddMetaData(atac_seurat, metadata = celltype.predictions) Co-embedding scRNA-seq and scATAC-seq datasets # note that we restrict the imputation to variable genes from scRNA-seq, but could impute the# full transcriptome if we wanted togenes.use &lt;- VariableFeatures(rna_seurat)# if your rna_seurat is integrated result, I believe you'ld prefer use `assay = &quot;integrated&quot;`refdata &lt;- GetAssayData(rna_seurat, assay = &quot;RNA&quot;, slot = &quot;data&quot;)[genes.use, ]# refdata (input) contains a scRNA-seq expression matrix for the scRNA-seq cells. imputation# (output) will contain an imputed scRNA-seq matrix for each of the ATAC cellsimputation &lt;- TransferData(anchorset = transfer.anchors, refdata = refdata, weight.reduction = atac_seurat[[&quot;lsi&quot;]], dims = 2:30)atac_seurat[[&quot;RNA&quot;]] &lt;- imputationcoembed &lt;- merge(x = rna_seurat, y = atac_seurat)# Finally, we run PCA and UMAP on this combined object, to visualize the co-embedding of both# datasetscoembed &lt;- ScaleData(coembed, features = genes.use, do.scale = FALSE)coembed &lt;- RunPCA(coembed, features = genes.use, verbose = FALSE)coembed &lt;- RunUMAP(coembed, dims = 1:30)DimPlot(coembed, group.by = c(&quot;orig.ident&quot;, &quot;seurat_annotations&quot;)) © Seurat Conclusion Integrating scRNA-Seq and scATAC-Seq data provides a holistic view of cellular states, combining gene expression and chromatin accessibility information. While the integration process might seem daunting, understanding the underlying principles and using the right tools can make it achievable and insightful. pre { background-color:#38393d; color: #5fd381; }","link":"/2023/10/16/Bioinfor/scATAC/"},{"title":"Understanding and Tackling Batch Effects in Single-Cell RNA-Seq Analysis","text":"The Challenge of Batch Effects In the world of single-cell RNA sequencing (scRNA-seq), one of the most prevailing challenges is the presence of batch effects. These are technical non-biological variations that arise when samples are processed in separate runs or under slightly different conditions. If not accounted for, batch effects can overshadow true biological differences, leading to misinterpretations. Why Remove Batch Effects? Imagine studying the effects of a drug on cell populations, with samples processed both before and after treatment. If the ‘before’ samples were processed in one batch and the ‘after’ samples in another, any difference you observe might be due to this batch variation rather than the drug effect. Removing batch effects ensures that: Biological variations are distinguishable from technical variations. Combined data from multiple batches can be analyzed together without biases. Results are consistent, reproducible, and truly reflective of biological phenomena. Approaches to Counter Batch Effects Several methods have been developed to correct for batch effects. Here, we’ll delve into three popular methods used within the Seurat package: Harmony, fastMNN, and SCTransform. A Comparative Glimpse: Feature Harmony fastMNN (batchelor) SCTransform Method Operates in PCA space to adjust principal components. Uses Mutual Nearest Neighbors to align cells. Regresses out unwanted variation and stabilizes variance. Use Cases Integrating datasets from different conditions, protocols, or platforms. Integrating datasets with batch effects. Faster than original MNN. Alternative to traditional normalization in Seurat. Prepares data for analysis. Advantages Preserves biological structures well; robust to complex batch effects. Designed for scRNA-seq batch correction; faster than original MNN; corrects severe batch effects. Stabilizes variance; can handle large datasets efficiently. Disadvantages Can be computationally intensive with large datasets. Requires a good selection of mutual nearest neighbors. Not specifically a batch correction method; often combined with other methods. Deep Dive into the Methods: Harmony: Ideal for integrating multiple scRNA-seq datasets. Harmony adjusts the principal components of the data such that inter-batch differences are minimized while retaining biological variation. fastMNN (from the batchelor package): This method identifies mutual nearest neighbors between batches, assuming that these pairs of cells represent the same cell type across batches. It’s an optimized and faster variant of the original MNN algorithm. SCTransform: More than a batch correction technique, SCTransform is a robust normalization method. It prepares the data for downstream analysis, including batch correction, by regressing out unwanted sources of variation. Final Thoughts: Batch effect correction is a crucial step in scRNA-seq data processing. By choosing the right method tailored to your dataset’s needs, you can unveil genuine biological insights without being misdirected by technical noises. Always visualize and interpret results at each step, ensuring that biological variation remains the highlight of your study. In Action Seurat offers several methods to correct for batch effects, ensuring that variations across batches don’t obscure the biological signals you’re interested in. Here’s a step-by-step guide to remove batch effects using Seurat: Install and Load Seurat: First, ensure you’ve installed and loaded the Seurat package. install.packages('Seurat')library(Seurat) Data Integration (Using Harmony, SCTransform, and others): Seurat offers various integration methods like Harmony, fastMNN, and SCTransform. Here, I’ll showcase using SCTransform followed by RunPCA and Harmony: # List of Seurat Objects from different batchesseurat_list &lt;- list(batch1_seurat, batch2_seurat, ...)# SCTransform normalizationseurat_list &lt;- lapply(seurat_list, function(x) { x &lt;- SCTransform(x, verbose = FALSE)})# Identify anchors for integrationanchors &lt;- FindIntegrationAnchors(object.list = seurat_list, normalization.method = &quot;SCT&quot;, anchor.features = 2000, verbose = FALSE)# Integrate dataintegrated_data &lt;- IntegrateData(anchorset = anchors, normalization.method = &quot;SCT&quot;, verbose = FALSE) If you prefer using Harmony specifically: library(harmony)integrated_data &lt;- RunPCA(integrated_data, features = VariableFeatures(object = integrated_data))integrated_data &lt;- RunHarmony(integrated_data, group.by.vars = &quot;batch&quot;) Scale and Run Linear Dimensional Reduction: integrated_data &lt;- ScaleData(integrated_data, verbose = FALSE)integrated_data &lt;- RunPCA(integrated_data, verbose = FALSE) Cluster and Visualize Integrated Data: Using UMAP or t-SNE to visualize the integrated data is a great way to confirm if the batch effects have been mitigated. integrated_data &lt;- RunUMAP(integrated_data, reduction = &quot;harmony&quot;, dims = 1:30)DimPlot(integrated_data, group.by = &quot;batch&quot;) Optional - Regression of unwanted sources of variation: If you are aware of specific unwanted sources of variation, you can regress them out using the vars.to.regress parameter in the ScaleData function. seurat_object &lt;- ScaleData(seurat_object, vars.to.regress = &quot;batch&quot;) Remember, the removal of batch effects should be done carefully. Overcorrection might lead to loss of genuine biological variation. It’s always a good practice to visualize and interpret the results at each step, ensuring the intended correction. Lastly, Seurat’s integration methods and their parameters might evolve with time, so always consult the latest Seurat documentation or vignettes to ensure you’re using the most effective and up-to-date approaches. Harmony, fastMNN, and SCTransform are all methods to handle batch effects and data normalization in single-cell RNA-seq data, but they operate based on different principles and have distinct purposes. In summary: Harmony and fastMNN are batch-correction methods that work to align datasets from different batches or conditions. SCTransform is a normalization method that prepares the data for further analysis, including batch correction. When dealing with batch effects, researchers often first normalize the data using SCTransform and then apply batch correction methods like Harmony or fastMNN to the transformed data. This two-step approach ensures that the data is both normalized and free of batch effects, making downstream analyses like clustering and differential expression more reliable. Other tutorial: 2023; X10 Genomics: Batch Effect Correction 2023; Seurat: Introduction to scRNA-seq integration pre { background-color:#38393d; color: #5fd381; }","link":"/2023/10/03/Bioinfor/scRNA-batch/"},{"title":"scRNA-Seq: makers explore","text":"Seurat is a popular R package for single-cell RNA sequencing (scRNA-seq) data analysis. If you’ve already processed your data and assigned cell identities (classes), then finding differentially expressed genes (DEGs) between two different classes is a common next step. Here’s a brief step-by-step guide on how to identify DEGs between two cell types or classes using Seurat: Setup: First, make sure you have the Seurat library loaded. library(Seurat) Differential Expression: Use the FindMarkers function in Seurat to identify DEGs. You can specify the two groups you are interested in by setting the ident.1 and ident.2 parameters. For example, if you have two classes named “ClassA” and “ClassB”, you can identify DEGs between these two classes as follows: de_genes &lt;- FindMarkers(object = your_seurat_object, ident.1 = &quot;ClassA&quot;, ident.2 = &quot;ClassB&quot;, min.pct = 0.25, logfc.threshold = 0.25, group.by = &quot;Final_id&quot;) |++++++++++++++++++++++++++++++++++++++++++++++++++| 100% elapsed=29s your_seurat_object is your Seurat object. min.pct is the minimum percentage of cells where the gene must be detected in either of the two groups. logfc.threshold is the minimum log-fold change threshold. group.by is the colname from metadata Inspect Results: The resulting de_genes data frame will contain differentially expressed genes between “ClassA” and “ClassB”. It will include columns for the average expression in each class, the percentage of cells expressing the gene in each class, the log fold-change, and the adjusted p-value (among other metrics). Filter Based on Significance: You might want to filter out genes based on a significance threshold, for instance, an adjusted p-value less than 0.05: significant_genes &lt;- de_genes[de_genes$p_val_adj &lt; 0.05, ] Visualize: You can also visualize the expression of significant genes across different classes using feature plots or violin plots in Seurat. Remember, the parameters like min.pct, logfc.threshold, and the p-value cutoff should be chosen based on your specific dataset and research questions. Adjust them as necessary to balance sensitivity and specificity. Violin Plot VlnPlot(OL3, idents = c(&quot;GMC1&quot;, &quot;GMC2&quot;, &quot;GMC3*&quot;), features = &quot;N&quot;, group.by = &quot;Pred_cl&quot;) VlnPlot(OL3, idents = c(&quot;GMC1&quot;, &quot;GMC2&quot;, &quot;GMC3*&quot;), features = row.names(de_genes), group.by = &quot;Pred_cl&quot;) pre { background-color:#38393d; color: #5fd381; }","link":"/2023/10/04/Bioinfor/scRNA-marker/"},{"title":"A Beginner&#39;s Guide to scRNA-Seq Data Integration","text":"Single-cell RNA sequencing (scRNA-seq) has revolutionized our understanding of cellular heterogeneity and function. However, integrating datasets, especially from different labs or experiments, can be challenging. In this guide, we’ll walk through the process of integrating scRNA-seq datasets using Seurat and provide tips for newcomers to the field. Why Integrate scRNA-Seq Data? Integrating multiple scRNA-seq datasets allows researchers to compare or combine data from different experiments, conditions, or labs. This is crucial when aiming to: Combine datasets to increase sample size. Compare conditions across different experiments. Mitigate batch effects arising from different experimental conditions. The Seurat Integration Workflow Seurat, a popular R package for scRNA-seq data analysis, provides a robust framework for data integration. Here’s a step-by-step guide: Preprocessing Before integration, preprocess each dataset separately. This includes: Filtering cells. Normalizing data. Identifying variable features. library(Seurat)#DefaultAssay(seurat_obj1) &lt;- &quot;RNA&quot;#DefaultAssay(seurat_obj2) &lt;- &quot;RNA&quot;seurat_obj1 &lt;- NormalizeData(seurat_obj1)seurat_obj2 &lt;- NormalizeData(seurat_obj2)seurat_obj1 &lt;- FindVariableFeatures(seurat_obj1, selection.method = &quot;vst&quot;, nfeatures = 2000)seurat_obj2 &lt;- FindVariableFeatures(seurat_obj2, selection.method = &quot;vst&quot;, nfeatures = 2000) Performing log-normalization 0% 10 20 30 40 50 60 70 80 90 100% [----|----|----|----|----|----|----|----|----|----| **************************************************| Calculating gene variances 0% 10 20 30 40 50 60 70 80 90 100% [----|----|----|----|----|----|----|----|----|----| **************************************************| Calculating feature variances of standardized and clipped values 0% 10 20 30 40 50 60 70 80 90 100% [----|----|----|----|----|----|----|----|----|----| **************************************************| Why nfeatures = 2000 The nfeatures parameter, when set to 2000 in the context of Seurat functions like FindVariableFeatures, specifies that the function should identify the top 2,000 most variable genes in the dataset. These variable genes are often used in downstream analyses, such as PCA, because they capture significant biological and technical variability that can help differentiate cell populations. The choice of 2000 as the number of variable features is somewhat arbitrary but has become a common default in many scRNA-seq workflows. Here’s why: Historical Precedence: Early scRNA-seq datasets were smaller, and selecting the top 2,000 variable genes was found to be a good balance between computational efficiency and capturing meaningful biological variability. Computational Efficiency: Using a subset of genes (like the top 2,000 variable genes) instead of the entire transcriptome makes downstream computations (like PCA, clustering, and UMAP/t-SNE embedding) faster and more memory-efficient. Biological Relevance: Genes that are variably expressed across cells often represent key markers that can differentiate cell types or states. By focusing on these genes, one can often capture the major axes of variation in the data. However, it’s essential to understand that 2000 is not a magic number, and depending on the specific dataset and research question, a different number might be more appropriate. Here are some considerations: Dataset Size: For larger datasets with more cells, you might benefit from selecting more than 2,000 variable genes. Conversely, for smaller datasets, a smaller number might suffice. Biological Question: If you’re interested in subtle subpopulations or rare cell types, you might need to consider more genes to capture this granularity. Exploration: It’s often beneficial to experiment with different numbers of variable features to see how it impacts downstream analyses. For instance, you can try 1,000, 2,000, 3,000, etc., and observe how it affects clustering or the resolution of cell populations in UMAP/t-SNE plots. In summary, while nfeatures = 2000 is a commonly used default, it’s crucial to understand its implications and adjust it as needed based on the specifics of your dataset and research goals. The method 'vst' refers to “Variance Stabilizing Transformation.” In the context of Seurat and scRNA-seq data analysis, the VST method is used to identify highly variable genes across single cells. Here’s a brief overview of the VST method: Variance Stabilizing Transformation (VST): Purpose: The main goal of VST is to stabilize the variance across the mean of the data. In the context of gene expression data, this means making the variance of gene expression values more consistent across different expression levels. Why It’s Important: In raw count data, the variance often increases with the mean. This means that highly expressed genes naturally have higher variability just due to the nature of the data. VST aims to correct for this, allowing for the identification of genes that are genuinely variable across cells, not just because of their expression level. How It Works: Without diving too deep into the math, VST uses a transformation that makes the variance of the data approximately constant across different mean values. This transformation is data-driven and is estimated from the data itself. Application in Seurat: In Seurat’s FindVariableFeatures function, when the method is set to 'vst', the function will use the VST approach to identify genes that are highly variable after accounting for the relationship between variance and mean expression. Comparison to Other Methods: Another common method used in Seurat for identifying variable genes is 'mean.var.plot', which fits a loess curve to the relationship between variance and mean expression. The VST method is often more robust, especially for larger datasets, but it’s always a good idea to understand and consider the implications of the method you’re using. In summary, the VST method in Seurat is a way to identify highly variable genes in a manner that accounts for and corrects the relationship between variance and mean expression. This helps in pinpointing genes that are genuinely variable across cells, which can be crucial for downstream analyses like clustering and dimensionality reduction. Identify Anchors Seurat uses the concept of “anchors” to identify correspondences between cells in different datasets. These anchors are then used for data integration. # FindIntegrationAnchors is really time consuming. Active peranchor.features &lt;- SelectIntegrationFeatures(object.list = list(seurat_obj1, seurat_obj2), nfeatures = 2000)anchor.set &lt;- FindIntegrationAnchors(object.list = list(seurat_obj1, seurat_obj2), anchor.features = anchor.features) Scaling features for provided objects |++++++++++++++++++++++++++++++++++++++++++++++++++| 100% elapsed=11s Finding all pairwise anchors | | 0 % ~calculating Running CCA Merging objects Finding neighborhoods Finding anchors Found 55971 anchors Filtering anchors Retained 18262 anchors |++++++++++++++++++++++++++++++++++++++++++++++++++| 100% elapsed=04h 16m 22s Integration Seurat uses “anchors” to identify correspondences between cells in different datasets. These anchors are then used for data integration. integrated.data &lt;- IntegrateData(anchorset = anchor.set)saveRDS(integrated.data, &quot;integrated.rds&quot;) Merging dataset 2 into 1 Extracting anchors for merged samples Finding integration vectors Finding integration vector weights 0% 10 20 30 40 50 60 70 80 90 100% [----|----|----|----|----|----|----|----|----|----| **************************************************| Integrating data Here, the integration steps are done. The following steps is for checking the integration quality and results. Downstream Analysis After integration, you can proceed with: Scaling the data. Running PCA. Clustering cells. Visualizing data using UMAP or t-SNE. integrated.data &lt;- ScaleData(integrated.data, verbose = FALSE)integrated.data &lt;- RunPCA(integrated.data, npcs = 30, verbose = FALSE)integrated.data &lt;- FindNeighbors(integrated.data, dims = 1:30)integrated.data &lt;- FindClusters(integrated.data, resolution = 0.5)integrated.data &lt;- RunUMAP(integrated.data, dims = 1:30)DimPlot(integrated.data, group.by = &quot;orig.ident&quot;) 3. Tips for Newbies in scRNA-Seq Integration For those new to scRNA-seq integration, here are some essential tips: Quality Control: Ensure thorough QC on each dataset before and after integration. Visual Inspection: Use UMAP/t-SNE plots and heatmaps to visually inspect your data. Parameter Tuning: Adjust parameters based on your specific datasets. Biological Validation: Validate your findings with external data or experimental validation. Computational Considerations: Ensure you have enough memory and computational resources. Documentation: Keep detailed notes and consider using tools like R Markdown. Stay Updated: The field of scRNA-seq is rapidly evolving. Stay updated with the latest methods and best practices. Seek Feedback: Discuss your results with colleagues or experts in the field. 4. Conclusion Integrating scRNA-seq datasets can be challenging, especially for newcomers. However, with the right tools, a systematic approach, and a focus on the underlying biology, it’s possible to derive meaningful insights from integrated datasets. As with all bioinformatics tasks, continuous learning and practice are key to mastering scRNA-seq data integration. Errors Error when running normalization: NormalizeData(seurat_obj1) Performing log-normalization 0% 10 20 30 40 50 60 70 80 90 100% [----|----|----|----|----|----|----|----|----|----| **************************************************| Error: Cannot add a different number of cells than already present Solution: seurat_obj1[[&quot;RNA&quot;]] &lt;- NormalizeData(seurat_obj1[[&quot;RNA&quot;]]) duplicated cell-name In CheckDuplicateCellNames(object.list = object.list) : Some cell names are duplicated across objects provided. Renaming to enforce unique cell names. new.names1 &lt;- paste0(colnames(seurat_obj1), &quot;_P40&quot;)seurat_obj1 &lt;- RenameCells(object = seurat_obj1, new.names = new.names1)# For seurat_obj2, add &quot;_batch2&quot; as a suffixnew.names2 &lt;- paste0(colnames(seurat_obj2), &quot;_P50&quot;)seurat_obj2 &lt;- RenameCells(object = seurat_obj2, new.names = new.names2) pre { background-color:#38393d; color: #5fd381; }","link":"/2023/10/03/Bioinfor/scRNA-integration/"},{"title":"SeqKit: A Cross-Platform and Ultrafast Toolkit for FASTA&#x2F;Q File Manipulation","text":"Install GitHub: shenwei356/seqkit wget https://github.com/shenwei356/seqkit/releases/download/v2.7.0/seqkit_linux_amd64.tar.gztar -zxvf seqkit_linux_amd64.tar.gz Convert the Fastq to Fasta seqkit fq2fa output_directory/output_prefix.extendedFrags.fastq -o output_directory/output_prefix.merged.fasta Remove Duplicated Sequence seqkit rmdup -s sequences.fasta -o unique_sequences.fasta -D counts.tsv -s: Specifies that duplicates should be identified based on sequence content. [input_file]: Replace this with the path to your input FASTA or FASTQ file. -o [output_file]: Specifies the output file. Replace [output_file] with the desired path for the file containing the sequences after duplicate removal. -D: write all removed duplicates (and counts) to this specified file. pre { background-color:#38393d; color: #5fd381; }","link":"/2024/02/05/Bioinfor/seqkit/"},{"title":"Diving Into Single-Cell RNA-Seq Analysis: A Beginner’s Guide","text":"Welcome to the fascinating world of single-cell RNA-Seq analysis! If you’re a budding scientist, curious learner, or someone looking to understand the intricacies of cellular biology, you’re in for a treat. This guide is tailored for newbies and aims to make the complex world of single-cell RNA-Seq analysis approachable and intriguing. What is Single-Cell RNA-Seq Analysis? © rebuildingakidney.org RNA-Seq stands for RNA sequencing, a revolutionary technique that helps scientists understand the expression of genes within a cell. In traditional RNA-Seq, we study the averaged gene expression of thousands of cells, but this approach has its limitations. It’s like trying to understand the flavor profile of a smoothie by tasting it – you know the overall taste, but you can’t pinpoint the individual fruits that contribute to it. This is where Single-Cell RNA-Seq (scRNA-Seq) analysis steps in! It allows scientists to examine the gene expression at the individual cell level, unraveling the unique role and state of each cell, akin to tasting each fruit separately! Why Should You Learn It? 1. Unveiling Cellular Diversity: scRNA-Seq analysis reveals the immense diversity and specialization of cells in an organism, helping us understand how different cells contribute to the function and development of tissues and organs. 2. Disease Understanding &amp; Treatment: It plays a crucial role in understanding various diseases at the cellular level, thereby aiding in the development of targeted treatments and personalized medicine. 3. Cutting-Edge Research: By learning scRNA-Seq analysis, you’re diving into a field at the forefront of biological and medical research, opening doors to various career and research opportunities. How to Learn Single-Cell RNA-Seq Analysis 1. Online Courses &amp; Tutorials: Many platforms offer specialized courses in scRNA-Seq analysis. Websites like Coursera, edX, and LinkedIn Learning host beginner-friendly courses to help you understand the basics and get hands-on experience. 2. Workshops &amp; Seminars: Keep an eye out for workshops, webinars, and seminars conducted by universities, research institutions, and organizations. These events often provide insights into the latest developments and practical applications of scRNA-Seq analysis. 3. Research Papers &amp; Journals: Scientific journals and publications are treasure troves of information. Websites like PubMed and Google Scholar can be your go-to resources for the latest research papers on scRNA-Seq analysis. 4. Join Online Communities: Platforms like Reddit, Stack Overflow, and Biostars have dedicated forums for scRNA-Seq where you can ask questions, share knowledge, and connect with other learners and experts. 5. Practical Experience: Nothing beats hands-on experience! Use publicly available datasets to practice and apply what you’ve learned. Websites like NCBI’s GEO or EMBL-EBI’s ArrayExpress are great places to find datasets. 6. Coding Skills: Familiarity with programming languages like R and Python can be extremely beneficial. If you’re new to coding, consider taking introductory courses available on Codecademy, Kaggle, or DataCamp. Integration Analysis The FindTransferAnchors() and TransferData() functions were introduced in Seurat v3. Seurat v3 was a significant release that incorporated many new methods, especially for the integration and alignment of multiple datasets. Before Seurat v3, data integration and label transfer were more cumbersome and less streamlined. If you’re using an older version of Seurat and want to leverage these functions, you should consider upgrading to at least Seurat v3 or the latest available version. Always refer to the official Seurat documentation and changelogs for detailed information about function availability and updates across different versions. Integrating scRNA-Seq and scATAC-Seq data is one of the powerful applications of FindTransferAnchors() and TransferData() in Seurat v3 and later. Despite being two distinct types of sequencing data – one capturing gene expression (scRNA-Seq) and the other capturing chromatin accessibility (scATAC-Seq) – the underlying assumption is that similar cell types/states in both datasets should have correlated patterns in gene expression and chromatin accessibility. Here’s how it generally works: Representation in a Shared Space: Before finding anchors, both scRNA-Seq and scATAC-Seq data are transformed into a lower-dimensional space (like PCA space). For scRNA-Seq, this is straightforward. For scATAC-Seq, peak (or gene activity) scores can be used, which summarize the chromatin accessibility signals into a gene-centric score. Finding Anchors: FindTransferAnchors() is then used to find anchors between the datasets. Despite the data’s different origins, the method identifies mutual nearest neighbors in the shared reduced-dimensional space. Data Transfer: Once anchors are identified, TransferData() can be used to transfer labels (like cell type annotations) from scRNA-Seq data to scATAC-Seq data or vice versa. This transfer can also be used to infer gene activity scores in scATAC-Seq data based on scRNA-Seq data. Integrative Analysis: After the data transfer, one can perform joint analyses on the two datasets, leveraging the strengths of both data types. For instance, a certain cell type identified in scRNA-Seq data can be examined in scATAC-Seq data to understand the regulatory elements (enhancers, promoters) that might be driving its gene expression patterns. A few things to note: The integration doesn’t mean that the two datasets are forced to look identical. Instead, the goal is to identify and leverage the shared structure between them. Appropriate preprocessing is crucial. For scATAC-Seq, one typically uses a “gene activity matrix”, which provides an estimation of gene activity based on nearby chromatin accessibility. This integration can be powerful, but like all methods, it requires careful interpretation and validation. The Seurat team has provided vignettes and tutorials on this topic, demonstrating how to integrate scRNA-Seq and scATAC-Seq data using their toolkit. If you’re planning to apply this to your data, it’s a good idea to refer to their official resources for step-by-step guidance. Final Thoughts Diving into single-cell RNA-Seq analysis can seem daunting initially, but remember, every expert was once a beginner. Be patient, stay curious, and don’t hesitate to ask questions. The journey might be challenging, but the rewards, insights, and knowledge you’ll gain along the way are incredibly fulfilling. Happy learning! pre { background-color:#38393d; color: #5fd381; }","link":"/2023/09/28/Bioinfor/scRNA-start/"},{"title":"Single Cell RNA-Seq Notes","text":"Single Cell RNA-Seq Notes Video materials: Human Cell Atlas: Day 1: HCA Latin America Single-Cell RNA-SEQ Data Analysis Workshop (Virtual) Challenges Barcodes errors © Dana Pe’er 2021 5000 cells in, but get 200,000 barcides identified. Sbarcity Sbarcity makes the noise is high and the protocols for bulk RNA-seq are not compectable for scRNA-Seq. Demension © Dana Pe’er 2021 Reduce demention based on linear projection (PCA) is not compectable for hide dementional data © Dana Pe’er 2021 Batch effects © Dana Pe’er 2021 Path walk: psudotime © Dana Pe’er 2021 Nuclear RNS-Seq Different between single cell RNA-Seq and single Nuclear RNA-Seq © Dana Pe’er 2021 Chromium Next GEM Single Cell 5’ Reagent Kits v2 (Dual Index) From: X10 Genomics © X10 Genomics Gel Bead- Read 1 Barcode×16 UMI×10 TSO ×13 rGrGrG an Illumina R1 sequence (read 1 sequencing primer) a 16 nt 10x Barcode. a 10 nt unique molecular identifier (UMI) 13 nt unique molecular identifier (TSO) are released and mixed with the cell lysate and a Master Mix containing reverse transcription (RT) reagents and poly(dT) RT primers. Incubation of the GEMs produces 10x Barcoded, full-length cDNA from polyadenylated mRNA. What are UMI and TSO? (Chat4) In single-cell sequencing, both Unique Molecular Identifiers and Template Switch Oligos (TSOs) play vital roles. Let’s explore what they do and why they are important: Unique Molecular Identifiers (UMI) Error Reduction: Unique Molecular Identifiers (UMIs) are unique sequences added to each molecule before amplification. They help in distinguishing genuine sequences from PCR duplicates, allowing for accurate quantification and detection of DNA or RNA molecules. Quantification: UMIs allow for the absolute quantification of nucleic acid molecules in a sample, crucial for understanding gene expression levels in single-cell studies. Reducing Amplification Bias: By identifying original molecules, UMIs mitigate PCR amplification biases, leading to more representative sequencing data. Template Switch Oligos (TSOs) cDNA Synthesis and Amplification: In single-cell RNA sequencing, TSOs are used during the reverse transcription of mRNA to cDNA. They have a unique sequence that attaches to the 3’ end of the cDNA. When the reverse transcriptase enzyme reaches the end of the mRNA template, it switches templates to this oligo, effectively adding a known sequence to the cDNA. Full-Length cDNA: TSOs facilitate the generation of full-length cDNA, especially important for accurately characterizing the transcriptome of a single cell. Tagging for Sequencing: The known sequence added by TSOs serves as a universal priming site for subsequent PCR amplification and sequencing, ensuring that all cDNA molecules are uniformly represented. Why are They Needed? Accuracy: Both MIs and TSOs improve the accuracy of single-cell sequencing by reducing errors and biases, crucial in studies where detecting low-abundance transcripts or minor genetic variations is essential. Representativeness: They help ensure that the sequencing data is representative of the original cellular content, which is vital for understanding cellular heterogeneity and the function of individual cells within tissues. Enhanced Detection: These elements enhance the detection of rare transcripts and genetic variations, which might otherwise be lost or misinterpreted in the noise of sequencing errors and biases. Quantitative Analysis: They enable quantitative analysis of gene expression, which is crucial for comparing different cells or understanding dynamic processes within cells. In summary, Molecular Identifiers and Template Switch Oligos are integral to the reliability, fidelity, and comprehensiveness of single-cell sequencing, enabling researchers to delve deeper into the complexities of cellular biology at an individual cell level. 5ʹ Gene Expression (GEX) Library Construction","link":"/2021/10/31/Bioinfor/sigcellnote1/"},{"title":"scVDJ-Seq Pipeline (CellRanger)","text":"scVDJ-Seq V(D)J Library Construction V (Variable): These are gene segments that code for the variable region of an antibody or T-cell receptor. The variable region is responsible for binding to antigens. D (Diversity): These segments are found in some classes of antibodies and in T-cell receptors. They provide an additional level of diversity to the antigen-binding region. J (Joining): These gene segments join with the V (and D, where present) segments to complete the variable region of the receptor. C (Constant): The constant region of the antibody or T-cell receptor is encoded by these segments. This region does not vary much between different antibodies and is responsible for the effector functions of the antibody, such as recruiting other parts of the immune system. Pipeline © 10X Genomics Install CellRanger Click the Link and fill out the information and you could get the download page # download the software (expired)curl -o cellranger-7.2.0.tar.gz &quot;https://cf.10xgenomics.com/releases/cell-exp/cellranger-7.2.0.tar.gz?Expires=1703232056&amp;Key-Pair-Id=APKAI7S6A5RYOXBWRPDA&amp;Signature=hm5oQoPrhuNznBtqCREVSaH34WF-Fute6XHYRDUIvIsajK~sFKYuonBEUQsxRJ1oKmxuuAhmtJg3N-mEQU2dr223oXTTr9e70gFlx9-3qgR7cvAhbZXMMGPMhOVVixoEF2GaE1~x0LA4KLXG3xu4mDGsBn4u870Ql~~OfhYBF5bHcqV6hf8X-YPXNG8TbRZMe-dqcogRTPYpeOpfKBtvPs63CDJ3YgC2Bahci4jYuo2v7MZDTR018C~X-3qwgRMIPKCMZFInEjpkfds34TJ0yP3uwAprvpR~S3WCngKKzSmAQszkDMqSB2eXZw6~FF~6oFIIYV~-DmPV~a7DO416nQ__&quot;# decompress and installtar -zxvf cellranger-7.2.0.tar.gz# add this directory in your pathexport PATH=$(pwd):$PATH# You may wish to add this command to your ~/.bashrc or ~/.zshrc for convenience.# for get the full command, you can run `echo export PATH=$(pwd):\\$PATH` and add the print out result at the end of the ~/.bashrc or ~/.zshrc Reference # Download the reference## Human reference (GRCh38) - 2020-Acurl -O &quot;https://cf.10xgenomics.com/supp/cell-exp/refdata-gex-GRCh38-2020-A.tar.gz&quot;## Mouse reference (mm10) - 2020-Acurl -O &quot;https://cf.10xgenomics.com/supp/cell-exp/refdata-gex-mm10-2020-A.tar.gz&quot;## Human (GRCh38) and mouse (mm10) reference - 2020-Acurl -O &quot;https://cf.10xgenomics.com/supp/cell-exp/refdata-gex-GRCh38-and-mm10-2020-A.tar.gz&quot;## Human V(D)J reference (GRCh38)curl -O &quot;https://cf.10xgenomics.com/supp/cell-vdj/refdata-cellranger-vdj-GRCh38-alts-ensembl-7.1.0.tar.gz&quot;## Mouse V(D)J reference (GRCm38)curl -O &quot;https://cf.10xgenomics.com/supp/cell-vdj/refdata-cellranger-vdj-GRCm38-alts-ensembl-7.0.0.tar.gz&quot; Run Documentation: 10X Genomics cellranger vdj --id=sample345 \\ --reference=/opt/refdata-cellranger-vdj-GRCh38-alts-ensembl-7.1.0 \\ --fastqs=/home/jdoe/runs/HAWT7ADXX/outs/fastq_path \\ --sample=mysample \\ --localcores=8 \\ --localmem=64 \\ --chain IG Or De-novo cellranger vdj --id=test_VDJ --denovo \\ --inner-enrichment-primers data/Primer.txt \\ --fastqs=fastq_path \\ --sample=test_VDJ \\ --localcores=60 \\ --localmem=256 --chain IG Command and Arguments: cellranger vdj: This is the main command being run. `cellranger` is the software package, and `vdj` specifies that you are running the V(D)J analysis pipeline, which is used for assembling and annotating V(D)J sequences from single-cell RNA-Seq data. --id=sample345: This sets the unique identifier for the run. Here, the identifier is `sample345`. This ID is used to name the output directory. --reference=...: This specifies the reference dataset to be used for the analysis. The provided path (`/opt/refdata-cellranger-vdj-GRCh38-alts-ensembl-7.1.0`) points to a reference dataset for human V(D)J sequences. --fastqs=...: This indicates the directory where the FASTQ files are located. FASTQ files are the input files for the Cell Ranger software, containing the sequenced reads. --sample=mysample: This specifies the name of the sample to be analyzed. It should match the sample name in the FASTQ files. --localcores=8: This parameter tells Cell Ranger to use 8 CPU cores for the computation. This setting helps to optimize the use of available computational resources. --localmem=64: This allocates 64 GB of memory (RAM) for the run. This parameter is crucial for ensuring the software has enough memory to process the data without crashing. When the Job is Done A successful cellranger vdj run should conclude with a message similar to this: Outputs: - Run summary HTML: /home/jdoe/runs/sample345/outs/web_summary.html - Run summary CSV: /home/jdoe/runs/sample345/outs/metrics_summary.csv - Clonotype info: /home/jdoe/runs/sample345/outs/clonotypes.csv - Filtered contig sequences FASTA: /home/jdoe/runs/sample345/outs/filtered_contig.fasta - Filtered contig sequences FASTQ: /home/jdoe/runs/sample345/outs/filtered_contig.fastq - Filtered contigs (CSV): /home/jdoe/runs/sample345/outs/filtered_contig_annotations.csv - All-contig FASTA: /home/jdoe/runs/sample345/outs/all_contig.fasta - All-contig FASTA index: /home/jdoe/runs/sample345/outs/all_contig.fasta.fai - All-contig FASTQ: /home/jdoe/runs/sample345/outs/all_contig.fastq - Read-contig alignments: /home/jdoe/runs/sample345/outs/all_contig.bam - Read-contig alignment index: /home/jdoe/runs/sample345/outs/all_contig.bam.bai - All contig annotations (JSON): /home/jdoe/runs/sample345/outs/all_contig_annotations.json - All contig annotations (BED): /home/jdoe/runs/sample345/outs/all_contig_annotations.bed - All contig annotations (CSV): /home/jdoe/runs/sample345/outs/all_contig_annotations.csv - Barcodes that are declared to be targetted cells: /home/jdoe/runs/sample345/outs/cell_barcodes.json - Clonotype consensus FASTA: /home/jdoe/runs/sample345/outs/consensus.fasta - Clonotype consensus FASTA index: /home/jdoe/runs/sample345/outs/consensus.fasta.fai - Contig-consensus alignments: /home/jdoe/runs/sample345/outs/consensus.bam - Contig-consensus alignment index: /home/jdoe/runs/sample345/outs/consensus.bam.bai - Clonotype consensus annotations (CSV): /home/jdoe/runs/sample345/outs/consensus_annotations.csv - Concatenated reference sequences: /home/jdoe/runs/sample345/outs/concat_ref.fasta - Concatenated reference index: /home/jdoe/runs/sample345/outs/concat_ref.fasta.fai - Contig-reference alignments: /home/jdoe/runs/sample345/outs/concat_ref.bam - Contig-reference alignment index: /home/jdoe/runs/sample345/outs/concat_ref.bam.bai - Loupe V(D)J Browser file: /home/jdoe/runs/sample345/outs/vloupe.vloupe - V(D)J reference: fasta: regions: /home/jdoe/runs/sample345/outs/vdj_reference/fasta/regions.fa donor_regions: /home/jdoe/runs/sample345/outs/vdj_reference/fasta/donor_regions.fa reference: /home/jdoe/runs/sample345/outs/vdj_reference/reference.json - AIRR Rearrangement TSV: /home/jdoe/runs/sample345/outs/airr_rearrangement.tsv - All contig info (ProtoBuf format): /home/jdoe/runs/sample345/outs/vdj_contig_info.pb Waiting 6 seconds for UI to do final refresh. Pipestance completed successfully! Once cellranger vdj has successfully completed, you can browse the resulting summary HTML file in any supported web browser, open the .vloupe file in Loupe V(D)J Browser, or refer to the Understanding Output section to explore the data by hand. Trouble Shoot Too Low to Meet the Required Threshold [error] Pipestance failed. Error log at: MockC_cs/SC_VDJ_ASSEMBLER_CS/SC_MULTI_CORE/MULTI_CHEMISTRY_DETECTOR/VDJ_CHEMISTRY_DETECTOR/DETECT_VDJ_RECEPTOR/fork0/chnk0-u22ea849f77/_errors Log message: V(D)J Chain detection failed for Sample VDJ-B-293-redo-1 in \"/raid/home/wenkanl2/MokC_sc/1_primary_seq\". Total Reads = 1000000 Reads mapped to TR = 30 Reads mapped to IG = 28665 In order to distinguish between the TR and the IG chain the following conditions need to be satisfied: - A minimum of 10000 total reads - A minimum of 5.0% of the total reads needs to map to TR or IG - The number of reads mapped to TR should be at least 3.0x compared to the number of reads mapped to IG or vice versa Please check the input data and/or specify the chain via the --chain argument. The problem here is with the proportion of reads mapping to TR and IG. Even though you have a significant number of reads mapped to IG, the number of reads mapped to TR is too low to meet the required thresholds. Resolution: The message suggests checking the input data or specifying the chain via the --chain argument. Explicitly specify whether you are analyzing T-cell receptors (TR) or Immunoglobulins (IG) by using the --chain flag in your Cell Ranger command. For example, assume that it is B cell data, we could add --chain IG to solve this problem pre { background-color:#38393d; color: #5fd381; }","link":"/2023/12/21/Bioinfor/scvdj-seq/"},{"title":"SNP Calling: GATK","text":"SNP Calling: GATK 1. build bwa index bwa index genome.fna##Exp:bwa index Apostichopus_japonicus.fna 2. reads Mapping bwa mem -t 4 -R '@RG\\tID:foo\\tPL:illumina\\tSM:E.coli_K12' genome.fna reada_1.fq reads_2.fq | samtools view -Sb - &gt; bwa.bam##Exp:bwa mem -t 4 -R '@RG\\tID:foo\\tPL:illumina\\tSM:E.coli_K12' Apostichopus_japonicus.fna SRR771602.fastq | samtools view -Sb - &gt; AJ.bam 3. sort by samtools samtools sort bwa.bam -o bwa.sorted.bam &gt; bwa.sorted.bamsamtools faidx genome.fna##Exp:samtools sort AJ.bam -o AJ.sorted.bam &gt; AJ.sorted.bam##Exp:samtools faidx Apostichopus_japonicus.fna 4. Maker PCR repeats gatk MarkDuplicates -I bwa.sorted.bam -O bwa.sorted.markdup.bam -M bwa.sorted.markdup_metrics.txt##Exp:gatk MarkDuplicates -I AJ.sorted.bam -O AJ.sorted.markdup.bam -M AJ.sorted.markdup_metrics.txtsamtools index bwa.sorted.markdup.bam 5. Prepare a dict file gatk CreateSequenceDictionary -R genome.fna -O genome.dict##Exp:gatk CreateSequenceDictionary -R Apostichopus_japonicus.fna -O Apostichopus_japonicus.dict 6. Build intermidia file, gvcf file gatk HaplotypeCaller -R genome.fna --emit-ref-confidence GVCF -I bwa.sorted.markdup.bam -O bwa.g.vcf##Exp:gatk HaplotypeCaller -R Apostichopus_japonicus.fna --emit-ref-confidence GVCF -I AJ.sorted.markdup.bam -O AJ.g.vcf 7. Finally gatk GenotypeGVCFs -R genome.fna -V bwa.g.vcf -O bwa.vcf##Exp:gatk GenotypeGVCFs -R Apostichopus_japonicus.fna -V AJ.g.vcf -O AJ.vcf Another Example: 炎季宏, 2018","link":"/2020/07/28/Bioinfor/snp_gatk/"},{"title":"sratools","text":"sratools GitHub There are some dependency problems. So, conda would be the easist way to get this tool. Install conda install -c bioconda sra-tools Don’t install it with BioConda!!! Don’t install it with BioConda!!! Don’t install it with BioConda!!! I tried it at 2023/11/29 and 2024/06. It could download 2.8 automatically but prefetch doesn’t work. So, please use the way below. Or download and configure wget https://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/3.0.0/sratoolkit.3.0.0-ubuntu64.tar.gztar -xvzf sratoolkit.3.0.0-ubuntu64.tar.gz# if you are using bash environment rather than zsh, change zshrc tp bashrcecho PATH=\\$PATH:$(pwd)/sratoolkit.3.0.0-ubuntu64/bin &gt;&gt; ~/.zshrcsource ~/.zshrc#configure sratoolsvdb-config --interactive After executing vdb-config, you can see an interactive environment board as below. You can input c to select CACHE. You can also select it by mouse and then input enter. Then, you need to give a directory for the category: process-local location:-[choose]+[choose] /tmp After that, save your change and you can use sratools, now. SRA data download prefetch --ascp-path &quot;/usr/bin/ascp|/home/ken/.aspera/connect/etc/asperaweb_id_dsa.putty&quot; ERR02559 sra to fastq fastq-dump is a command-line utility within the SRA Toolkit that converts SRA (Sequence Read Archive) files into FASTQ format. FASTQ is a widely used file format for storing nucleotide sequences along with their quality scores. This tool allows researchers to extract and utilize raw sequencing data from SRA databases for further analysis. fastq-dump --split-files --gzip SRRXXXXXXX The --split-files argument in fastq-dump is specifically related to paired-end sequencing data. It splits the output into two FASTQ files, one for each read of the pair (e.g., your_file_1.fastq and your_file_2.fastq). It was suggested to add the --split-3 parameter at the same time so the unpaired reads could go to the *.fastq file, while the paired reads would go to the *_1.fastq and *_2.fastq. If you are handling single-end sequencing data, you can ignore this parameter as it is not needed. The output will be a single FASTQ file containing all the reads. For third-generation sequencing data (such as those produced by PacBio or Oxford Nanopore technologies), there are a few special considerations and parameters to keep in mind: PacBio Data: Use --skip-technical to skip technical reads. Use --clip to remove adapter sequences. fastq-dump --skip-technical --clip your_file.sra Oxford Nanopore Data: Use --readids to include read IDs in the output. Use --minReadLen to set a minimum read length to filter out shorter reads. fastq-dump --readids --minReadLen 1000 your_file.sra These parameters help in properly extracting and preparing the data for downstream analysis, ensuring that the specific characteristics of third-generation sequencing reads are adequately handled. Faster?? My sra file is very large, the fastq-dump takes lots of time for single file, is there any way to speed it up? Unfortunately, fastq-dump could not run in multiple threads. So, it reach its fast already. Good news is you could also use fasterq-dump from the same package which comes from the same tool packs. Here is an example: fasterq-dump --split-files --threads 8 your_file.sra For trinity fastq-dump --defline-seq '@$sn[_$rn]/$ri' --split-files file.sraTrinity --seqType fq --max_memory 55G --single Seq.fastq --CPU 8 --full_cleanup","link":"/2020/07/28/Bioinfor/sratools/"},{"title":"SNP Calling: samtools","text":"SNP Calling: samtools pre { background-color:#38393d; color: #5fd381; } 1. sort by samtools samtools sort bwa.bam -o bwa.sorted.bam &gt; bwa.sorted.bamsamtools faidx genome.fna##Exp:samtools sort AJ.bam -o AJ.sorted.bam &gt; AJ.sorted.bam##Exp:samtools faidx Apostichopus_japonicus.fna 2. SNP calling samtools mpileup -guSDf genome.fasta abc.bam | bcftools view -cvNg - &gt; abc.vcf Reference: Kevin Blighe, 2019 bcftools mpileup --redo-BAQ --min-BQ 30 --per-sample-mF \\ --annotate FORMAT/AD,FORMAT/ADF,FORMAT/ADR,FORMAT/DP,FORMAT/SP,INFO/AD,INFO/ADF,INFO/ADR \\ -f &quot;${Ref_FASTA}&quot; \\ &quot;${repBAM1}&quot; &quot;${repBAM2}&quot; &quot;${repBAM3}&quot; &quot;${repBAM4}&quot; | \\bcftools call --multiallelic-caller --variants-only &gt; out.vcf ; Annotation Convert gtf to bed file Alex Reynolds; 20011 # install# sudo apt install bedopsconvert2bed -i gtf &lt;Drosophila_melanogaster.BDGP6.32.104.chr.EGFP.GAL4.mCD8GFP.gtf&gt; Dme.bed There are some problems for the conversion. Error: Potentially missing gene or transcript ID from GTF attributes (malformed GTF at line [1]?) Here is one of the resolution from russhh; 2019 and it works for me. cat input.gtf.gz | gunzip - | grep transcript_id | grep gene_id | convert2bed --do-not-sort --input=gtf - &gt; output.bed bcftools annotate the vcf file SemiQuant, 2015 # install bedtools: sudo apt-get install bedtoolsbedtools sort -i Dme.bed &gt; Dme_sort.bed# install bgzip: sudo apt-get install tabixbgzip Dme_sort.bedtabix -p bed Dme_sort.bed.gzbgzip variants.vcftabix -s1 -b2 -e3 variants.vcf.gzbcftools annotate -a Dme_sort.bed.gz \\ -h Header_file.hdr \\ -c CHROM,FROM,TO,TAG,ID variants.vcf.gz# orbcftools annotate \\ -a genes.bed.gz \\ -c CHROM,FROM,TO,GENE \\ -h &lt;(echo '##INFO=&lt;ID=GENE,Number=1,Type=String,Description=&quot;Gene name&quot;&gt;') \\ variants.vcf.gz Consequence Annotation By SnpEff Document: SnpEff Chinese Exampel: 牧羊的男孩儿; 2019 install snpeff conda install -c bioconda snpeff tree genomes genomes ├── Dme │ └── genesls genes.gtf └── genes.fa echo &quot;data.dir = genomes/&quot; &gt; snpEff.configecho &quot;Dme.genome:Dme&quot; &gt;&gt; snpEff.configjava -Xmx4G -jar /home/ken/Soft/snpEff/snpEff/snpEff.jar build -gff3 Dme There some reason sed -i &quot;/^EGFP/d&quot; genomes/Dme/genes.gtfsed -i &quot;/^GAL4/d&quot; genomes/Dme/genes.gtfsed -i &quot;/^mCD8GFP/d&quot; genomes/Dme/genes.gtf Download prebuild database # Eeck the database avalablejava -jar snpEff.jar databases| grep Drosophila_melanogaster# Failed test from other blog mkdir snpEffcd snpEff ###进入snpEff目录下mkdir data ###新建data目录cd data ####进入data目录下mkdir genomes ####新建genomes目录mkdir ecoli ###新建ecoli目录cd genomeswget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/005/845/GCF_000005845.2_ASM584v2/GCF_000005845.2_ASM584v2_genomic.fna.gzgzip -d GCF_000005845.2_ASM584v2_genomic.fna.gzmv GCF_000005845.2_ASM584v2_genomic.fna ecoli.facd ../ecoliwget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/005/845/GCF_000005845.2_ASM584v2/GCF_000005845.2_ASM584v2_genomic.gff.gzgzip -d GCF_000005845.2_ASM584v2_genomic.gff.gzmv GCF_000005845.2_ASM584v2_genomic.gff genes.gffcd ../../ #回到snpEff目录下echo &quot;ecoli.genome:ecoli&quot; &gt;&gt; snpEff.config Mu protocol for Drosophila tree data data ├── Dme │ └── genes.gtf └── genomes └── Dme.fa cd data/Dme# sudo install gffreadgffread -g ../genomes/Dme.fa -x cds.fa genes.gtf# Using TransDecoder to translate the cds file into protein sequenceTransDecoder.LongOrfs -t cds.faTransDecoder.Predict -t cds.famkdir dir BioSeq TransDecoder installation: Karobben; 2020 There is an interesting conflicate between two fiels I download. The Protine file is starded by Flybase ID. The cds file is started by Gene Name. But The Database was using Transcript id That rediculase. mkdir dir BioSeq for i in $(grep &quot;&gt;&quot; protein.fa| awk '{print $1}'| sed 's/&gt;//'); do Name=$(grep -w $i genes.gtf| tr &quot;;&quot; &quot;\\n&quot; |grep transcript_id|head -n 1| awk '{print $2}'| sed 's/&quot;//g') sed -i 's/&gt;'$i'/&gt;'$Name'/' protein.fadonefor i in $(grep &quot;&gt;&quot; cds.fa| awk '{print $1}'| sed 's/&gt;//'); do Name=$(grep -w $i genes.gtf| tr &quot;;&quot; &quot;\\n&quot; |grep transcript_id|head -n 1| awk '{print $2}'| sed 's/&quot;//g') sed -i 's/&gt;'$i'/&gt;'$Name'/' cds.fadone GTF=pd.read_csv(&quot;genes.gtf&quot;, header=2, sep='\\t')GTF_list = list(set(GTF.iloc[:,0].to_list()))from Bio import SeqIOSeq1='cds.fa'Name_l = []for seq_record in SeqIO.parse(Seq1, &quot;fasta&quot;): Anot = [] try: # for we can find the flybase id in gtf file Anot = [i for i in GTF_list if seq_record.id in i][0].split(&quot;;&quot;) except: # try it in the parent id Pat_list = [i for i in seq_record.description.split(&quot;;&quot;) if &quot;parent=&quot; in i][0].replace(&quot; &quot;,'').replace(&quot;parent=&quot;, &quot;&quot;).split(&quot;,&quot;) for P_id in Pat_list: try: Anot = [i for i in GTF_list if P_id in i][0].split(&quot;;&quot;) except: 1 == 1 Tra_ID = [i for i in Anot if &quot;transcript_id&quot; in i][0].split(&quot; &quot;)[-1].replace('&quot;', &quot;&quot;) Name_l += [Tra_ID] Test for samplifed Genom sed -i &quot;/^EGFP/d&quot; genes.gtfsed -i &quot;/^GAL4/d&quot; genes.gtfsed -i &quot;/^mCD8GFP/d&quot; genes.gtf# Generate the CDSgffread -g ../genomes/Dme.fa -x cds.fa genes.gtf from Bio import SeqIOfrom Bio.Seq import translateSeq1='cds.fa'Name_l = []for seq_record in SeqIO.parse(Seq1, &quot;fasta&quot;): seq_record.seq = translate(seq_record.seq)[:-1] Name = seq_record.description.split(&quot;FlyBase:&quot;)[-1].split(&quot;,&quot;)[0].split(&quot;;&quot;)[0] Name_l += [Name] SeqIO.write(seq_record, &quot;BioSeq/&quot;+Name+&quot;.fa&quot;, &quot;fasta&quot;) It works with lots of stop codon in protein fasta file. For Real Genome conda create -n snpeff python=3.7# simplify the gtfsed -i &quot;/^EGFP/d&quot; genes.gtfsed -i &quot;/^GAL4/d&quot; genes.gtfsed -i &quot;/^mCD8GFP/d&quot; genes.gtfsnpEff build -gtf22 DmesnpEff Dme vcf/test.vcf &gt; test.ann.vcf","link":"/2020/07/28/Bioinfor/snp_samtools/"},{"title":"SNP is fun: Tricks for dealing with VCF files","text":"Extrack Fasta from VCF file basic usage: MatthewP, 2019: cat ref.fa | vcf-consensus your_file.vcf.gz &gt; out.fa bgzip -c file.vcf &gt; file.vcf.gztabix -fp vcf file.vcf.gzcat ref.fa | vcf-consensus file.vcf.gz &gt; out.fa Extrack Mitonchondira Genome Only grep -E &quot;mitochondrion_genome|#&quot; ../VCF3/ActtsNICD18WDF_aln_pe_bqsr.bam.vcf &gt; file.vcfbgzip -c file.vcf &gt; file.vcf.gztabix -fp vcf file.vcf.gzcat ref.fa | vcf-consensus file.vcf.gz &gt; out.fa Check the highly mutated Genes for line in {1..13};do GENE=$(grep -i mitochondrion_genome ../../Yuwei_data/DATA/genes.gtf | grep mRNA| awk 'NR=='$line'{print $12}') SL=$(grep -i mitochondrion_genome ../../Yuwei_data/DATA/genes.gtf | grep mRNA| awk 'NR=='$line'{print $4}'); SR=$(grep -i mitochondrion_genome ../../Yuwei_data/DATA/genes.gtf | grep mRNA| awk 'NR=='$line'{print $5}') echo $GENE grep -i mitochon ../VCF3/* | awk '$2&gt;='$SL''| awk '$2 &lt;='$SR'' | awk -F: '{print $1}'| uniq -c| grep -iv h_done for loop .. ├── VCF3 └── VCF3_mt └── Mito.fa vcf files are in VCF3, script is running in VCF3_mt. Mito.fa is the Reference for i in $(ls ../VCF3/*); do file=$(echo $i|sed 's=../VCF3/==;s/_aln_pe_bqsr.bam.vcf//') grep -E &quot;mitochondrion_genome|#&quot; $i &gt; $file.vcf bgzip -c $file.vcf &gt; $file.vcf.gz tabix -fp vcf $file.vcf.gz cat Mito.fa| vcf-consensus $file.vcf.gz &gt; $file.fadone#rm -f *vcf*# Change the Namesfor i in $(ls *.fa| grep -v Mito); do NAME=$(echo $i| sed 's/.fa//'); sed -i &quot;s/&gt;/&gt;$NAME /&quot; $i;donecat *.fa &gt; All.fa# Quick Tree with ClustalWclustalo -QUICKTREE -OUTPUT=FASTA -INFILE=All.faclustalw -QUICKTREE -OUTPUT=FASTA -INFILE=All.fasta -CLUSTERING=NJ -BOOTSTRAP=1000 library(&quot;ggtree&quot;)tree &lt;- read.tree(&quot;/run/user/1000/gvfs/sftp:host=129.81.246.249,user=ken/home/ken/Mutation/Raw_VCF/VCF3_mt/All.dnd&quot;)ggplot(tree, aes(x, y)) + geom_tree() + theme_tree() + geom_tiplab(size=5, color=&quot;purple&quot;) +xlim(NA, 0.04) Visualization SNP ratiol change Cat all vcf files into one grep -v &quot;#&quot; *.vcf| awk '{OFS=&quot;\\t&quot;; print $1,$2,$4,$5}' |sed 's/:/\\t/' &gt; All_vcf.csv Visualization by ggplot library(ggplot2)library(stringr)library(patchwork)TB &lt;- read.table(&quot;G3_all_vcf.csv&quot;)colnames(TB) &lt;- c(&quot;Sample&quot;, &quot;Chrom&quot;, &quot;Loc&quot;, &quot;Ref&quot;, &quot;Alt&quot;)TB$SNP &lt;- paste(TB$Ref, TB$Alt)TB &lt;- TB[TB$Ref %in% c(&quot;A&quot;, &quot;G&quot;, &quot;T&quot;, &quot;C&quot;),]TB &lt;- TB[TB$Alt %in% c(&quot;A&quot;, &quot;G&quot;, &quot;T&quot;, &quot;C&quot;),]TB$SNP &lt;- str_replace_all(TB$SNP, &quot;G T&quot;, &quot;C A&quot;)TB$SNP &lt;- str_replace_all(TB$SNP, &quot;G A&quot;, &quot;C T&quot;)TB$SNP &lt;- str_replace_all(TB$SNP, &quot;G C&quot;, &quot;C G&quot;)TB$SNP &lt;- str_replace_all(TB$SNP, &quot;A G&quot;, &quot;T C&quot;)TB$SNP &lt;- str_replace_all(TB$SNP, &quot;A T&quot;, &quot;T A&quot;)TB$SNP &lt;- str_replace_all(TB$SNP, &quot;A C&quot;, &quot;T G&quot;)ggplot(TB, aes(Sample, fill= SNP)) + geom_bar(show.legend = F) + theme_bw()+ theme(axis.text.x = element_text(angle = 90,hjust = 1, vjust = .5))TB2 &lt;- cbind(TB,as.data.frame(str_split_fixed(TB$Sample, &quot;_&quot;, 2)))TB2$V1 &lt;- factor(TB2$V1, levels =c(&quot;BRAT-1&quot;, &quot;BRAT-2&quot;, &quot;MBT-1&quot;, &quot;MBT-2&quot;, &quot;AURA&quot;, &quot;LGL&quot;))TB2$Sample &lt;- factor(TB2$Sample, levels =unique(TB2$Sample[order(TB2$V2)]))P &lt;- ggplot(TB2[TB2$V2!=&quot;Donor&quot;,], aes(Sample, fill= SNP)) + geom_bar() + theme_bw()+ theme(axis.text.x = element_text(angle = 90,hjust = 1, vjust = .5)) + facet_grid( ~V1, space = 'free', scales = 'free')P1 &lt;- P + coord_cartesian(y=c(0, 25000), expand = F) + theme(strip.background = element_blank(), axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank(), panel.border = element_blank(), axis.line.y.left = element_line())P2 &lt;- P + coord_cartesian(y=c(0, 200), expand = F)+ theme(strip.background = element_blank(), axis.title.y = element_blank(), strip.text = element_blank(), legend.position = &quot;None&quot;, panel.border = element_blank(), axis.line.y.left = element_line(), axis.line.x.bottom = element_line())GGlay = 'AAAB'P1 +P2 +plot_layout(design = GGlay)","link":"/2022/08/18/Bioinfor/snpfun/"},{"title":"Single cell RNA-Seq Practice: Seurat","text":"Single cell RNA-seq Data processing This is my first time to learn siRNA-Seq. The protocol are based on Seurat. Please go and reading more information from Seurat. The codes are derectly copied from Seurat and so, if you are confuzed about my moves, please go to the link below and check by yourselves. For new users of Seurat, we suggest starting with a guided walk through of a dataset of 2,700 Peripheral Blood Mononuclear Cells (PBMCs) made publicly available by 10X Genomics. This tutorial implements the major components of a standard unsupervised clustering workflow including QC and data filtration, calculation of high-variance genes, dimensional reduction, graph-based clustering, and the identification of cluster markers. –Seurat Source code: © Seurat 2021 Downlaod Practice Data Data set: Peripheral Blood Mononuclear Cells (PBMC) freely available from 10X Genomics. wget https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gztar -zxvf pbmc3k_filtered_gene_bc_matrices.tar.gztree filtered_gene_bc_matrices/hg19 filtered_gene_bc_matrices/hg19 ├── barcodes.tsv ├── genes.tsv └── matrix.mtx head -n 4 filtered_gene_bc_matrices/hg19/* ==> filtered_gene_bc_matrices/hg19/barcodes.tsv filtered_gene_bc_matrices/hg19/genes.tsv filtered_gene_bc_matrices/hg19/matrix.mtx","link":"/2021/10/30/Bioinfor/sigcell1/"},{"title":"False Positives Made by Trinity","text":"Long repeat sequences Query_47 183 CATAAATAAATAAATATACATTTAAATGCAACTTAACGAATCGGCCCTCGACTTATATCC 242 X 13400713 ............................................................ 13400654 Query_47 243 TACtatattatataatatatatatatatataCACATTCGCACCAAACACCCACAATCACA 302 X 13400653 ...............................T.T... 13400617 2R 16574732 ........................................................ 16574677 Query_47 303 ACCACAAACACATCCTCGTAGATTAAGGCCCAAATGTTTGTTATGCCACTTGTTATCGCG 362 2R 16574676 ............................................................ 16574617 Query_47 363 ACGTTTGATTAAAGCTAACAAAACTGAT 390 2R 16574616 ............................ 16574589 pre { background-color:#38393d; color: #5fd381; }","link":"/2022/09/21/Bioinfor/trinity-false/"},{"title":"TCGA Database with R","text":"TCGA Database Reference: Documentation Bioconductor BiocManager::install('TCGAbiolinks')library(TCGAbiolinks)library(SummarizedExperiment)library(dplyr)library(DT)projects &lt;- TCGAbiolinks:::getGDCprojects()$project_idprojects &lt;- projects[grepl('^TCGA',projects,perl=T)]# query is not downloading data, is making the correct query format for download the data query &lt;- GDCquery(project = projects, data.category = &quot;Transcriptome Profiling&quot;, data.type = &quot;Gene Expression Quantification&quot;, workflow.type = &quot;STAR - Counts&quot;) # After get the correct query, you can start to download it in the localGDCdownload(query = query, method = &quot;api&quot;, files.per.chunk = 60, directory = &quot;mRNA&quot;)# counts &lt;- GDCprepare(query,save = TRUE, save.filename = &quot;all_tumor_htseq_raw_counts.rda&quot;)data &lt;- GDCprepare(query = query)expdat &lt;- GDCprepare(query = query, directory = &quot;mRNA&quot;) If the query is correct, you would see the red codes below and you could start to download the data now. -------------------------------------- o GDCquery: Searching in GDC database -------------------------------------- Genome of reference: hg38 -------------------------------------------- oo Accessing GDC. This might take a while... -------------------------------------------- ooo Project: TCGA-ESCA ooo Project: TCGA-SARC ooo Project: TCGA-CESC ooo Project: TCGA-UCEC -------------------- oo Filtering results -------------------- ooo By data.type ooo By workflow.type ---------------- oo Checking data ---------------- ooo Checking if there are duplicated cases ooo Checking if there are results for the query ------------------- o Preparing output ------------------- Check the group and counts information # Check the mate informationas.data.frame(colData(data))# Check Exression countsassay(data)[1:6,1:4] TCGA-DX-A6Z0-01A-13R-A36F-07 TCGA-X2-A95T-01A-11R-A37L-07 TCGA-DX-A6BF-01A-11R-A30C-07 TCGA-DX-A1L1-01A-11R-A24X-07 ENSG00000000003.15 3415 861 316 4004 ENSG00000000005.6 340 4 14 0 ENSG00000000419.13 2296 905 938 3935 ENSG00000000457.14 594 454 85 595 ENSG00000000460.17 626 318 62 458 ENSG00000000938.13 259 138 271 381 pre { background-color:#38393d; color: #5fd381; } why download data Sometimes, you may receive errors: Error in GDCquery(project = projects[3], data.category = \"Transcriptome Profiling\", : Please set a valid workflow.type argument from the list below: => STAR - Counts You can’t turn the “GDCprepare” results into data directly. You need to download it first and convert it by “GDCprepare”. See details in github Differential Expression Genes Reference: rdrr.io I am failed to get the expression matrix by using GDCprepare. According to [© g27182818, 2022], it caused by STAR-Count files has more infor than GDCprepare need. What ever, a modified solution could be like codes below: library('TCGAbiolinks')library(stringr)project_name &lt;- &quot;TCGA-CHOL&quot;# Defines the query to the GDCquery &lt;- GDCquery(project = project_name, data.category = &quot;Transcriptome Profiling&quot;, data.type = &quot;Gene Expression Quantification&quot;, experimental.strategy = &quot;RNA-Seq&quot;, workflow.type = &quot;STAR - Counts&quot;)# Get metadata matrixmetadata &lt;- query[[1]][[1]]# Get main directory where data is storedmain_dir &lt;- file.path(&quot;mRNA&quot;, project_name)# Get file list of downloaded filesfile_list &lt;- file.path(&quot;mRNA&quot;, project_name,list.files(main_dir,recursive = TRUE)) # Read first downloaded to get gene namestest_tab &lt;- read.table(file = file_list[1], sep = '\\t', header = TRUE)# Delete header lines that don't contain usefull informationtest_tab &lt;- test_tab[-c(1:4),]# STAR counts and tpm datasetstpm_data_frame &lt;- data.frame(test_tab[,1])count_data_frame &lt;- data.frame(test_tab[,1])# Append cycle to get the complete matrixfor (i in c(1:length(file_list))) { # Read table test_tab &lt;- read.table(file = file_list[i], sep = '\\t', header = TRUE) # Delete not useful lines test_tab &lt;- test_tab[-c(1:4),] # Column bind of tpm and counts data tpm_data_frame &lt;- cbind(tpm_data_frame, test_tab[,7]) count_data_frame &lt;- cbind(count_data_frame, test_tab[,4]) # Print progres from 0 to 1 print(i/length(file_list))}ID_list &lt;- as.data.frame(str_split_fixed(file_list, '/', 7))[[6]]row.names(count_data_frame) &lt;- count_data_frame[[1]]count_data_frame &lt;- count_data_frame[-1]colnames(count_data_frame) &lt;- metadata$cases[match(ID_list, metadata$id)]N_control = length(which(as.numeric(gsub(&quot;[^0-9.-]&quot;, &quot;&quot;, as.data.frame(str_split_fixed(metadata$cases, '-', 5))[[4]])) &gt;= 10)) The meaning of the barcode © NIH, GDC Label Identifier for Value Value Description Possible Values Analyte Molecular type of analyte for analysis D The analyte is a DNA sample See Code Tables Report Plate Order of plate in a sequence of 96-well plates 182 The 182nd plate 4-digit alphanumeric value Portion Order of portion in a sequence of 100 - 120 mg sample portions 1 The first portion of the sample 01-99 Vial Order of sample in a sequence of samples C The third vial A to Z Project Project name TCGA TCGA project TCGA Sample Sample type 1 A solid tumor Tumor types range from 01 - 09, normal types from 10 - 19 and control samples from 20 - 29. See Code Tables Report for a complete list of sample codes Center Sequencing or characterization center that will receive the aliquot for analysis 1 The Broad InstituteGCC See Code Tables Report Participant Study participant 1 The first participant from MD Anderson for GBM study Any alpha-numeric value TSS Tissue source site 2 GBM (brain tumor) sample from MD Anderson See Code Tables Report So, the most important information for us is the sample type: Tumor types range from 01 - 09, normal types from 10 - 19 and control samples from 20 - 29. See Code Tables Report for a complete list of sample codes Abbreviations of projects Study Abbreviation Study Name LAML Acute Myeloid Leukemia ACC Adrenocortical carcinoma BLCA Bladder Urothelial Carcinoma LGG Brain Lower Grade Glioma BRCA Breast invasive carcinoma CESC Cervical squamous cell carcinoma and endocervical adenocarcinoma CHOL Cholangiocarcinoma LCML Chronic Myelogenous Leukemia COAD Colon adenocarcinoma CNTL Controls ESCA Esophageal carcinoma FPPP FFPE Pilot Phase II GBM Glioblastoma multiforme HNSC Head and Neck squamous cell carcinoma KICH Kidney Chromophobe KIRC Kidney renal clear cell carcinoma KIRP Kidney renal papillary cell carcinoma LIHC Liver hepatocellular carcinoma LUAD Lung adenocarcinoma LUSC Lung squamous cell carcinoma DLBC Lymphoid Neoplasm Diffuse Large B-cell Lymphoma MESO Mesothelioma MISC Miscellaneous OV Ovarian serous cystadenocarcinoma PAAD Pancreatic adenocarcinoma PCPG Pheochromocytoma and Paraganglioma PRAD Prostate adenocarcinoma READ Rectum adenocarcinoma SARC Sarcoma SKCM Skin Cutaneous Melanoma STAD Stomach adenocarcinoma TGCT Testicular Germ Cell Tumors THYM Thymoma THCA Thyroid carcinoma UCS Uterine Carcinosarcoma UCEC Uterine Corpus Endometrial Carcinoma UVM Uveal Melanoma","link":"/2022/12/06/Bioinfor/tcga/"},{"title":"String DB","text":"String Database Download Specious Network Link to downloading the networks An example of download files: Link file: 7227.protein.physical.links.full.v11.5.txt Protein annotation: 7227.protein.info.v11.5.txt.gz TB &lt;- read.table(&quot;7227.protein.links.detailed.v11.5.txt&quot;, header = T)dim(TB)str(TB) [1] 4343798 10 'data.frame': 4343798 obs. of 10 variables: $ protein1 : chr \"7227.FBpp0070001\" \"7227.FBpp0070001\" \"7227.FBpp0070001\" \"7227.FBpp0070001\" ... $ protein2 : chr \"7227.FBpp0293850\" \"7227.FBpp0087873\" \"7227.FBpp0079990\" \"7227.FBpp0080090\" ... $ neighborhood : int 0 0 0 0 0 0 0 0 0 0 ... $ fusion : int 0 0 0 0 0 0 0 0 0 0 ... $ cooccurence : int 0 0 0 0 0 0 0 0 0 0 ... $ coexpression : int 151 153 167 298 446 371 242 371 373 238 ... $ experimental : int 0 0 0 0 0 0 0 0 0 0 ... $ database : int 0 0 0 0 0 0 0 0 0 0 ... $ textmining : int 0 0 0 0 0 0 0 0 0 0 ... $ combined_score: int 150 152 167 298 446 371 241 371 373 237 ... Protein 1: Start protein Protein 2: Connections from Protein 1 to protein 2 neighborhood: Physical neighborhood on the Genome fusion: raw fusion score for COG mode (deprecated). cooccurence: raw cooccurence score for COG mode (deprecated). coexpression: expression patterns in a group of RNA-Seq are similar experimental: experimental score (derived from experimental data, such as, affinity chromatography). database: database score (derived from curated data of various databases). textmining: textmining score (derived from co-occurring mentioning of gene/protein names in abstracts). combined_score: scores in total From: Table: network.score_types Starting Point How do I select a reasonable score cut-off value for my analysis? You can use the score cut-off to limit the number of interactions to those that have higher confidence and are more likely to be true positives. Setting the cutoff lower will increase coverage but also a fraction of false positives. You have to choose some arbitrary number based on the number of interactions you need for your analysis. What is co-occurrence A type of phylogenetic profile – the patterns of the presence or absence of orthologs across many organisms© Pan-Jun Kim, 2011 Example in R library(ggplot2)library(stringr)library(igraph)library(reshape2)Anno &lt;- read.csv(&quot;7227.protein.info.v11.5.txt&quot;, sep ='\\t', header = T, quote = &quot;&quot;)Anno[[1]] &lt;- str_remove(Anno[[1]], &quot;7227.&quot;)TB &lt;- read.table(&quot;7227.protein.links.detailed.v11.5.txt&quot;, header = T)TB2 &lt;- TB[c(&quot;protein1&quot;, &quot;protein2&quot;, &quot;fusion&quot;, &quot;cooccurence&quot;, &quot;coexpression&quot;, &quot;experimental&quot;)]TB2$protein1 &lt;- str_remove(TB2$protein1, &quot;7227.&quot;)TB2$protein2 &lt;- str_remove(TB2$protein2, &quot;7227.&quot;)TB_df &lt;- apply(TB2[-c(1:2)], 1, sum)N = 18+ which.max(density(TB_df[which(TB_df&gt;0)])$y[-c(1:18)])X = density(TB_df[which(TB_df&gt;0)])$x[N]Y = density(TB_df[which(TB_df&gt;0)])$y[N]ggplot() + geom_density(aes(x= TB_df[which(TB_df&gt;0)])) + theme_bw() + geom_vline(xintercept = X) + geom_text(aes(x= X, y = Y, label= round(X, 2)), hjust = 0, vjust = 0)# LISTLIST &lt;- c(&quot;FBpp0070483&quot;, &quot;FBpp0288697&quot;, &quot;FBpp0304573&quot;, &quot;FBpp0305946&quot;, &quot;FBpp0300852&quot;, &quot;FBpp0083503&quot;, &quot;FBpp0297544&quot;, &quot;FBpp0085082&quot;, &quot;FBpp0288660&quot;, &quot;FBpp0077739&quot;, &quot;FBpp0081139&quot;, &quot;FBpp0293081&quot;, &quot;FBpp0079676&quot;, &quot;FBpp0288515&quot;, &quot;FBpp0297890&quot;, &quot;FBpp0304299&quot;, &quot;FBpp0306192&quot;, &quot;FBpp0074686&quot;, &quot;FBpp0070417&quot;, &quot;FBpp0086911&quot;, &quot;FBpp0289616&quot;)# Try threshold at 2000# TB3 &lt;- TB2[which(TB_df&gt;1000),]TB3 &lt;- rbind(TB2[TB2$protein1 %in% LIST,], TB2[TB2$protein2 %in% LIST,])TB_df &lt;- apply(TB3[-c(1:2)], 1, sum)TB3 &lt;- TB3[which(TB_df&gt;150),]length(unique(c(TB3$protein1, TB3$protein2 )))# 173; we have 173 unique proteins# plot it with igraphTB3$CN = 1TB4 &lt;- reshape(TB3[c(&quot;protein1&quot;, &quot;protein2&quot;, &quot;CN&quot;)], idvar = &quot;protein1&quot;, timevar = &quot;protein2&quot;, direction = &quot;wide&quot;)rownames(TB4) &lt;- TB4[[1]]TB4 &lt;- TB4[-1]colnames(TB4) &lt;- str_remove(colnames(TB4), &quot;CN.&quot;)TB4[is.na(TB4)] &lt;- 0network=graph_from_adjacency_matrix(as.matrix(TB4) , mode='undirected', diag=T )TB4.Size &lt;- as.data.frame(table(c(TB3$protein1, TB3$protein2 )))TB4.Size &lt;- TB4.Size[match(colnames(TB4),TB4.Size$Var1),]TB4.Size$Anno &lt;- Anno[[2]][match(TB4.Size$Var1,Anno[[1]])]TB4.Size$Anno2 = &quot;&quot;TB4.Size$Anno2[which(TB4.Size$Freq&gt;=100)] &lt;- TB4.Size$Anno[which(TB4.Size$Freq&gt;=100)]##DefauTB4.Size$Anno2 = &quot;&quot;set.seed(1)par(mar=c(0,0,0,0))plot(network, vertex.size= log(TB4.Size$Freq +1), vertex.label = TB4.Size$Anno2 , vertex.label.size= log(TB4.Size$Freq +1) , vertex.frame.color= adjustcolor(&quot;salmon&quot;, alpha.f = .5), vertex.color = adjustcolor(&quot;salmon&quot;, alpha.f = .5), edge.color = adjustcolor(&quot;grey&quot;, alpha.f = .1), layout = layout_nicely)lay = layout_with_graphopt(network)R = max(abs(lay))lay_Y = abs(asin(sin(lay[,2]/sqrt(lay[,1]^2 + lay[,2]^2))) * R)lay_X = abs(acos(cos(lay[,1]/sqrt(lay[,1]^2 + lay[,2]^2))) * R)lay_X[lay[,1]&lt;0] &lt;- lay_X[lay[,1]&lt;0] * -1lay_Y[lay[,2]&lt;0] &lt;- lay_Y[lay[,2]&lt;0] * -1LX &lt;- 2*(lay_X -lay[,1]) #+ lay[,1]LY &lt;- 2*(lay_Y -lay[,2]) #+ lay[,2]LAY &lt;- matrix(c(LX, LY) , ncol = 2)#layout_with_mds#layout_nicely#layout_with_graphopt pre { background-color:#38393d; color: #5fd381; }","link":"/2023/01/09/Bioinfor/string-db/"},{"title":"百度统计 API","text":"百度统计 API 详细介绍:https://tongji.baidu.com/api/manual/Chapter2/openapi.html 1. 登录百度开发者中心控制台,获取code 将 http://openapi.baidu.com/oauth/2.0/authorize?response_type=code&amp; client_id={CLIENT_ID}&amp; redirect_uri={REDIRECT_URI}&amp; scope=basic&amp;display=popup 按照对应关系 设置信息 对应参数API Key {CLIENT_ID}Secret Key {CLIENT_SECRET}回调URI {REDIRECT_URI} 填入对应信息 注意: 1.“{}” 不能保留, 直接删掉. 我之前卡了好久, 就是因为没有删去中括号.2.REDIRECT_URI 建议使用活网站, 不然跳转的时候, 会等很久很久.然后直接黏贴在浏览器里,便可Example: http://openapi.baidu.com/oauth/2.0/authorize?response_type=code&amp; client_id=m2OY4t4oBs59XG2Sasdads&amp; redirect_uri=https://www.baidu.com&amp; scope=basic&amp;display=popup 第一次会显示登录的信息, 登陆后,会跳转到你的REDIRECT_URI. 死网站则会是空白页面. 这时候, 查看地址后面会多出一个 ?code=XXXXXX这个code很重要. 2. 获取 token http://openapi.baidu.com/oauth/2.0/token?grant_type=authorization_code&amp; code={CODE}&amp; client_id={CLIENT_ID}&amp; client_secret={CLIENT_SECRET}&amp; redirect_uri={REDIRECT_URI} 这一步, code 填上 刚刚获取的code, 然后下面三个和之前一样. 黏贴如浏览器这样就可以获得access_token 了, 有的access_token, 就可以为所欲为了~ 3. API 使用 获取url 地址:https://tongji.baidu.com/api/debug/# 3.1 获取设置网站的 ID: https://openapi.baidu.com/rest/2.0/tongji/config/getSiteList? access_token={you_token} 4. 打包成Python函數 python API 打包函數: import time, requestsTOKEN = &quot;&quot;def Tongji(TOKEN): TIME =time.strftime(&quot;%Y%m%d&quot;, time.localtime()) def Get_UV(TOKEN,ID,TIME): #Aquiring PV and UV inform mation by ID (History and today) A = &quot;https://openapi.baidu.com/rest/2.0/tongji/report/getData?access_token=&quot; + TOKEN B = &quot;&amp;site_id=&quot;+str(ID) C = &quot;&amp;start_date=20200120&amp;end_date=&quot;+TIME D = &quot;&amp;metrics=pv_count%2Cvisitor_count&amp;method=overview%2FgetTimeTrendRpt&quot; url = A+B+C+D Data = requests.get(url).json() UVPV_list = Data['result']['items'][1] PV_T = UVPV_list[-1][0] if PV_T ==&quot;--&quot;: PV_T = 0 UV_T = UVPV_list[-1][1] if UV_T ==&quot;--&quot;: UV_T = 0 # PV = [] UV = [] for i in UVPV_list: if i[0] != &quot;--&quot;: PV+=[i[0]] if i[1] != &quot;--&quot;: UV+=[i[1]] # PV = str(sum(PV))+&quot;+&quot;+str(PV_T) UV = str(sum(UV))+&quot;+&quot;+str(UV_T) return PV,UV def Location_Get(TOKEN, TIME): # aquiring location-distribution information by province today url1 = &quot;https://openapi.baidu.com/rest/2.0/tongji/report/getData?access_token=&quot; url2 = TOKEN +&quot;&amp;site_id=14350939&amp;start_date=&quot; url3 = TIME + &quot;&amp;end_date=&quot;+TIME+&quot;&amp;metrics=pv_count&amp;method=overview%2FgetDistrictRpt&quot; url = url1+url2+url3 Data = requests.get(url).json() Location = &quot;&quot; for i in Data['result']['items'][0]: Location += i[0] +'\\n' Location_N = &quot;&quot; for i in Data['result']['items'][1]: Location_N += str(i[0]) +'\\n' return Location,Location_N def Location_Get_C(TOKEN, TIME): # Aquring location-distribution information by Country today url1 = &quot;https://openapi.baidu.com/rest/2.0/tongji/report/getData?access_token=&quot; url2 = TOKEN +&quot;&amp;site_id=14350939&amp;start_date=&quot; url3 = TIME + &quot;&amp;end_date=&quot;+TIME+&quot;&amp;metrics=pv_count&amp;method=visit%2Fworld%2Fa&quot; url = url1+url2+url3 Data = requests.get(url).json() Location = &quot;&quot; for i in Data['result']['items'][0]: Location += i[0]['name'] +'\\n' Location_N = &quot;&quot; for i in Data['result']['items'][1]: Location_N += str(i[0]) +'\\n' return Location,Location_N def New_Visitor_Get(TOKEN, TIME): # Aquring the ratio of the new visiter today url1 = &quot;https://openapi.baidu.com/rest/2.0/tongji/report/getData?access_token=&quot; url2 = TOKEN + &quot;&amp;site_id=14350939&amp;start_date=&quot; url3 = TIME + &quot;&amp;end_date=&quot; + TIME + &quot;&amp;metrics=new_visitor_ratio&amp;method=source%2Fall%2Fa&quot; url = url1 + url2 +url3 Data = requests.get(url).json() # return &quot;新訪客比例 &quot;+str(Data['result']['sum'][0][0])+&quot;%&quot; def main(): # Aquiring Domains' Name and ID url1= &quot;https://openapi.baidu.com/rest/2.0/tongji/config/getSiteList?access_token=&quot;+TOKEN List = requests.get(url1).json() Domain = List['list'][0]['domain'] Domain_ID = List['list'][0]['site_id'] Sub_domain = [[Domain,Domain_ID]] Sub_List = List['list'][0]['sub_dir_list'] for i in Sub_List: Sub_domain += [[i['name'],i['sub_dir_id']]] Result = {} for i in Sub_domain: PV,UV = Get_UV(TOKEN,i[1],TIME) Result.update({i[0]:{&quot;PV&quot;:PV,&quot;UV&quot;:UV}}) Name = &quot;&quot; PV = &quot;&quot; UV = &quot;&quot; for i in Result: Name += i + &quot;\\n&quot; PV += Result[i]['PV']+&quot;\\n&quot; UV += Result[i]['UV']+&quot;\\n&quot; New_Vis_N = New_Visitor_Get(TOKEN, TIME) Location,Location_N = Location_Get(TOKEN, TIME) Location_C,Location_C_N = Location_Get_C(TOKEN, TIME) return Name,PV,UV,Location,Location_N,Location_C,Location_C_N,New_Vis_NName,PV,UV,Location,Location_N,Location_C,Location_C_N,New_Vis_N = Tongji(TOKEN)","link":"/2020/07/28/Blog/Baidu_statistic/"},{"title":"Whole Genome Sequencing (WGS)","text":"Whole Genome Sequencing (WGS) Whole-genome sequencing (WGS) is a comprehensive method for analyzing entire genomes. Genomic information has been instrumental in identifying inherited disorders, characterizing the mutations that drive cancer progression, and tracking disease outbreaks. Rapidly dropping sequencing costs and the ability to produce large volumes of data with today’s sequencers make whole-genome sequencing a powerful tool for genomics research. (Illumina) Illumina WGS KEY WHOLE-GENOME SEQUENCING METHODS Large whole-genome sequencing Small whole-genome sequencing De novo sequencing Targeting to species without reference genome Phased sequencing Human whole-genome sequencing optimized for human Long-reads sequencing Examples from Publications SKLA1.0 (Duck) A chromosome-scale Beijing duck assembly (SKLA1.0[1]) by integrating Nanopore, Bionano, and Hi-C data covers 40 chromosomes, improves the contig N50 of the previous duck assembly with highest contiguity (ZJU1.0) of more than a 5.79-fold and contains a complete genomic map of the MHC. © Olivia Crowe Species: Anas platyrhynchos (a native breed in China, using a hierarchical and hybrid approach) Reads types: Nanopore, Bionano, and Hi-C data. 71-fold normal and 24-fold ultra-long Nanopore reads 117-fold 150bp paired-end Illumina reads for polishing 216-fold optical map reads and 234-fold PE150 Hi-C Result: 40 chromosomes, improves the contig N50 of the previous duck assembly with highest contiguity (ZJU1.0) of more than a 5.79-fold a complete genomic map of the MHC Solved challenges: traditional assembly tools have not enabled proper genomic draft of highly repetitive and GC-rich sequences, such as the MHC Something I don’t understand: C18 Duck? heterozygosity estimation: why they do it? How could it help on the genome assembly? What is BUSCO score? Steps for Genome assembly: Estimate Genome Heterozygosity Before starting the assembly, the genome heterozygosity of the C18 duck was estimated. The heterozygosity was found to be as low as 0.58% (Additional file 1: Table S1 and Additional file 2: Fig. S1-S3). Assemble Genome with Nanopore Reads Using 71-fold normal and 24-fold ultra-long Nanopore reads, the duck genome was assembled into 151 contigs covering a total length of 1.22 Gb with a contig N50 of 32.81 Mb (Additional file 1: Table S2-S3). NextDenovo: Clean and assembly Polish Contigs with Illumina Reads The 151 contigs were then polished with 912 million 150-bp Illumina pair-end reads, corrected, and integrated with high-quality optical maps (Additional file 1: Table S4-S5). This effort generated 69 scaffolds with a scaffold N50 of 72.53 Mb (Additional file 1: Table S6). Nextpolish-1.2.3[2]: polished three rounds Use Hi-C Data for Scaffold Ordering A total of 274 Gb PE150 Hi-C data was used to order and orient the duck scaffolds, correct mis-joined sections, and merge overlaps, resulting in 40 super-scaffolds (Additional file 1: Table S7). Trimmomatic-0.36[3]; Juicer software-1.5[4]; 3d-DNA package-180922[5]; Juicebox-1.13.01[6] Perform Gap Filling Gap filling was performed using 95-fold corrected Nanopore reads to remove gaps, generating the final duck assembly (SKLA1.0), representing 1.16 Gb of the genomic sequence, approximately 99.11% of the estimated genome size (Table 1). Gapcloser-0.56[7] Chromosome Coverage and Comparison Since the duck contains 80 chromosomes (diploid, 2n=80), it was inferred that this duck assembly had covered all chromosomes except W (Additional file 1: Table S8). The SKLA1.0 assembly was compared with the previous duck BGI_duck_1.0 assembly, the ZJU1.0 assembly, and two high-quality avian reference genomes (chicken GRCg6a and zebra finch bTaeGut1.4.pri). These analyses indicated that the SKLA1.0 assembly represents a major improvement over the previous assemblies in terms of contiguity, completeness, and chromosome size. The contiguity and completeness of SKLA1.0 is also higher than that of the zebra finch bTaeGut1.4.pri and the chicken GRCg6a (Fig. 1a–d and Table 1). After Assembly Funannotate pipeline and the GETA pipeline together with a manual curation of key gene families: 17,896 duck coding genes. Quality was validated by number of coding genes, # of transcripts, # of gaps, and BUSCO score. Visualization: Bionano map-SOLVE ASM2904224v1: Greater scaup (Aythya marila) First high-quality chromosome-level genome assembly of A. marila[8], with a final genome size of 1.14 Gb, scaffold N50 of 85.44 Mb, and contig N50 of 32.46 Mb. A total of 154.94 Mb of repetitive sequences were identified. 15,953 protein-coding genes were predicted in the genome, and 98.96% of genes were functionally annotated. © Olivia Crowe Nanopore long reads, errors corrected using Illumina short reads Quality: Final size: 1.14 Gb, scaffold N50 of 85.44 Mb, and contig N50 of 32.46 Mb. 106 contigs were clustered and ordered onto 35 chromosomes based on Hi-C data, covering approximately 98.28% of the genome BUSCO assessment showed that 97.0% of the highly conserved genes Source: muscle tissue of wild male. 60.77 GB for Illumina HiSeq 4000: Illumina® TruSeq® Nano DNA Library Prep kits to generate sequencing libraries of genomic DNA 122.55 GB from PromethION platform (91.36 fold of the greater scaup’s genome) 63.43 Gb for Hi-C data Genome Assembly Quality Control: K = 17, the estimated genome size was 1,341.4 Mb, the heterozygosity was 0.47%, and the proportion of repetitive sequences was 42.28% jellyfish (v2.2.7) Assembly: assemble the genome with Oxford nanopore technologies (ONT) long reads NextDenovo (v2.4.0) Polish: increase the precision of single base with Illumina short reads NextPolish12 (v1.3.1)[2:1] Scaffold Ordering: mount the contigs in preliminarily assembly onto chromosomes based on the signal strength after Hi-C data ALLHiC (v0.9.8)[9] and Juicebox (v1.11.08) HiC Results for the global heat map of all the chromosomes. © Shengyang Zhou After Assembly Assessment Burrows-Wheeler aligner14 (BWA) (v0.7.8) to map Illumina reads to the genome with matching rate was approximately 98.80%. Merqury15 (v1.3) was ran to evaluate assembly quality value (QV), and a high QV (42.14) Benchmarking Universal Single-Copy Orthologs16 (BUSCO) (v5.4.4) (use option “–augustus”) and Core Eukaryotic Genes Mapping Approach17 (CEGMA) (v2.5) were also used to assess the integrity 238 of 248 core eukaryotic genes were detected using CEGMA Comparison Mummer18 (v4.0.0) was used to identify the synteny between A. marila and tufted duck19 (Aythya fuligula) genomes to determine orthologous chromosome pairs, and we used TBtools20 (v1.112) to draw the synteny between their chromosomes. Annotation of repetitive sequences de novo prediction: Tandem Repeats Finder21 (TRF) (v4.09) to detect tandem repeat sequences RepeatModeler (v2.0.3), RepeatScout22 (v1.0.6) and RECON (v1.08) were used to build a database of transposable element (TE) RepeatProteinMask and RepeatMasker (v4.1.2-p1) were used for homology prediction with Repbase database23 and Dfam database24, the species parameter used was chicken. Gene structure prediction Prediction Methods: Ab Initio Prediction: Used software Augustus (v3.3.2), GlimmerHMM (v3.0.4), and Geneid (v1.4.5). Homology-Based Prediction: Utilized genomes and annotation files from six related species (Anser cygnoides, Anas platyrhynchos, Aythya fuligula, Cygnus olor, Cygnus atratus, Gallus gallus) downloaded from NCBI. RNA-Seq Prediction: Processed raw data from six transcriptomic samples using fastp (v0.23.1), assembled paired-end reads with SPAdes (v3.15.3), identified candidate coding regions using TransDecoder (v5.5.0), and clustered sequences using CD-hit (v4.8.1). Integration: Matching and Splicing: Protein sequences from related species were matched to the A. marila genome using Spaln (v2.4.6) and accurately spliced with GeneWise (v2.4.1). Gene Set Generation: Combined homology-based, RNA-Seq, and ab initio predictions using EvidenceModeler (EVM) (v1.1.1) and incorporated masked repeats. Databases and Tools: DIAMOND: Used for sequence alignment against SwissProt, TrEMBL, NR (Non-Redundant Protein Sequence Database), Gene Ontology (GO), and Kyoto Encyclopedia of Genes and Genomes Orthology (KO) databases, with an e-value cutoff of 1e-5. InterPro: Utilized for classifying proteins into families and predicting domains and important sites using InterProScan (v5.53). Filtering and Verification of Gene Set for A. marila Ortholog Identification: OrthoFinder: Used to identify orthologs among A. marila and six related species. Resulted in 4,086 unassigned genes, of which 3,421 were not annotated in any database. Filtering Process: Most unannotated genes (3,417/3,421) were predicted by at least one de novo prediction software, with only four supported by other evidence. Removal of these unassigned genes did not affect the BUSCO test results, indicating they may not represent real genes. Final Gene Set: After filtering out unassigned genes without annotations and 159 prematurely terminated genes, 15,953 genes remained, including 182 partial genes. 98.96% of the final gene set was annotated. Pig Sscrofa11.1 Warr A, Affara N, Aken B, et al. An improved pig reference genome sequence to enable pig genetics and genomics research[J]. Gigascience, 2020, 9(6): giaa051. TJ Tabasco corrected and assembled using Falcon (v.0.4.0) 65-fold coverage (176 Gb) of the genome 3,206 contigs with a contig N50 of 14.5 Mb. Compare contigs were mapped to the previous draft assembly (Sscrofa10.2) using Nucmer gap closure using PBJelly Statistic Sscrofa10.2 Sscrofa11 Sscrofa11.1 USMARCv1.0 GRCh38.p13 Total sequence length 2,808,525,991 2,456,768,445 2,501,912,388 2,755,438,182 3,099,706,404 Total ungapped length 2,519,152,092 2,454,899,091 2,472,047,747 2,623,130,238 2,948,583,725 No. of scaffolds 9,906 626 706 14,157 472 Gaps between scaffolds 5,323 24 93 0 349 No. of unplaced scaffolds 4,562 583 583 14,136 126 Scaffold N50 576,008 88,231,837 88,231,837 131,458,098 67,794,873 Scaffold L50 1,303 9 9 9 16 No. of unspanned gaps 5,323 24 93 0 349 No. of spanned gaps 233,116 79 413 661 526 No. of contigs 243,021 705 1,118 14,818 998 Contig N50 69,503 48,231,277 48,231,277 6,372,407 57,879,411 Contig L50 8,632 15 15 104 18 No. of chromosomes* *21 19 *21 *21 24 pig (Sscrofa10.2, Sscrofa11.1, USMARCv1.0), human (GRCh38.p13) pre { background-color:#38393d; color: #5fd381; } Hu J, Song L, Ning M, Niu X, Han M, Gao C, Feng X, Cai H, Li T, Li F, Li H, Gong D, Song W, Liu L, Pu J, Liu J, Smith J, Sun H, Huang Y. A new chromosome-scale duck genome shows a major histocompatibility complex with several expanded multigene families. BMC Biol. 2024 Feb 5;22(1):31. doi: 10.1186/s12915-024-01817-0. PMID: 38317190; PMCID: PMC10845735. Paper ↩︎ Hu J, Fan JP, Sun ZY, Liu SL. NextPolish: a fast and efficient genome polishing tool for long-read assembly. Bioinformatics. 2020;36:2253–5. ↩︎ ↩︎ Bolger AM, Lohse M, Usadel B. Trimmomatic: a flexible trimmer for Illumina sequence data. Bioinformatics. 2014;30:2114–20. ↩︎ Durand NC, Shamim MS, Machol I, Rao SSP, Huntley MH, Lander ES, et al. Juicer Provides a One-Click System for Analyzing Loop-Resolution Hi-C Experiments. Cell Syst. 2016;3:95–8. ↩︎ Dudchenko O, Batra SS, Omer AD, Nyquist SK, Hoeger M, Durand NC, et al. De novo assembly of the Aedes aegypti genome using Hi-C yields chromosome-length scaffolds. Science. 2017;356:92–5. ↩︎ Durand NC, Robinson JT, Shamim MS, Machol I, Mesirov JP, Lander ES, et al. Juicebox Provides a Visualization System for Hi-C Contact Maps with Unlimited Zoom. Cell Syst. 2016;3:99–101. ↩︎ Xu MY, Guo LD, Gu SQ, Wang O, Zhang R, Peters BA, et al. TGS-GapCloser: A fast and accurate gap closer for large genomes with low coverage of error-prone long reads. Gigascience. 2020;9:giaa094–104. ↩︎ Zhou S, Xia T, Gao X, et al. A high-quality chromosomal-level genome assembly of Greater Scaup (Aythya marila)[J]. Scientific Data, 2023, 10(1): 254. ↩︎ Zhang, X., Zhang, S., Zhao, Q., Ming, R. &amp; Tang, H. Assembly of allele-aware, chromosomal-scale autopolyploid genomes based on Hi-C data. Nature Plants 5, 833–845 (2019). ↩︎","link":"/2024/06/17/Bioinfor/wholegenomesequencing/"},{"title":"Biology meetings information","text":"Meetings 科学网会议系统 from bs4 import BeautifulSoupfrom urllib.request import urlopenimport resource = &quot;http://meeting.sciencenet.cn/index.php?s=/Category/mth_meeting&amp;mth=2021-07&quot;html = urlopen(source).read().decode('utf-8')soup = BeautifulSoup(html, features='lxml')Meeting_list = soup.find_all(&quot;div&quot;,{&quot;class&quot;:&quot;col-md-6&quot;})Num_m = len(Title)for Meeting in Meeting_list: Tmp, Date = Get_Inf(Meeting) print(Date, Tmp)def Get_Inf(Meeting): try: Title = Meeting.find(&quot;span&quot;,{&quot;class&quot; : &quot;aa&quot;}).get_text() except: Title = &quot;404&quot; # try: Tail = Meeting.find(&quot;a&quot;).get('href') # html = urlopen(source+&quot;/&quot;+Tail).read().decode('utf-8') soup = BeautifulSoup(html, features='lxml') Text = soup.get_text() # date_pattern=&quot;(\\d{1,4}年)((([0?][1-9])月)|(([1?][0-2])月)|([1-9]月)?)(([0?][1-9]日)|([1?][0-9]日)|([2?][1-9]日)|([3][0-1]日)?)&quot; res=re.search(date_pattern,Text) Date = res.group() except: Date = &quot;404&quot; # return Title, Date&quot;会议时间：&quot; in Text","link":"/2021/07/13/Blog/Biomeeting/"},{"title":"BiliBili API","text":"BiliBili API 来源:https://github.com/StuPeter/Bilibili_Views_spider/blob/master/BiliSpider.py ##!/usr/bin/env python ## _*_ coding:utf-8 _*_ ## @Version : 1.0 ## @Time : 2018/10/25## @Author : 圈圈烃## @File : BiliSpider## @Description:import requestsimport jsonclass BiliSpider: def __init__(self): self.online_api = &quot;https://api.bilibili.com/x/web-interface/online&quot; # 在线人数 self.video_api = &quot;https://api.bilibili.com/x/web-interface/archive/stat?&amp;aid=%s&quot; # 视频信息 self.newlist_api = &quot;https://api.bilibili.com/x/web-interface/newlist?&amp;rid=%s&amp;pn=%s&amp;ps=%s&quot; # 最新视频信息 self.region_api = &quot;https://api.bilibili.com/x/web-interface/dynamic/region?&amp;rid=%s&amp;pn=%s&amp;ps=%s&quot; # 最新动态信息 self.member_api = &quot;http://space.bilibili.com/ajax/member/GetInfo&quot; # 用户信息 self.stat_api = &quot;https://api.bilibili.com/x/relation/stat?vmid=%s&quot; # 用户关注数和粉丝总数 self.upstat_api = &quot;https://api.bilibili.com/x/space/upstat?mid=%s&quot; # 用户总播放量和总阅读量 self.follower_api = &quot;https://api.bilibili.com/x/relation/followings?vmid=%s&amp;pn=%s&amp;ps=%s&quot; # 用户关注信息 self.fans_api = &quot;https://api.bilibili.com/x/relation/followers?vmid=%s&amp;pn=%s&amp;ps=%s&quot; # 用户粉丝信息 # def get_api(api_url): headers = { &quot;Accept&quot;: &quot;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8&quot;, &quot;Accept-Encoding&quot;: &quot;gzip, deflate, br&quot;, &quot;Accept-Language&quot;: &quot;zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2&quot;, &quot;Host&quot;: &quot;api.bilibili.com&quot;, &quot;Referer&quot;: &quot;https://www.bilibili.com/&quot;, &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36&quot;, } res = requests.get(api_url, headers=headers) res_dict = res.json() return res_dict # def get_online(self): &quot;&quot;&quot; 获取在线信息 all_count: 最新投稿 web_online: 在线人数 :return: &quot;&quot;&quot; online_dic = BiliSpider.get_api(self.online_api) return online_dic # def get_video_info(self, aid): &quot;&quot;&quot; 获取视频信息 :param aid: 视频id :return: &quot;&quot;&quot; res = BiliSpider.get_api(self.video_api %aid) # print(res) return res # def get_newlist_info(self, rid, pn, ps): &quot;&quot;&quot; 获取最新视频信息 :param rid: 二级标题的id (详见tid_info.txt) :param pn: 页数 :param ps: 每页条目数 1-50 :return: &quot;&quot;&quot; res = BiliSpider.get_api(self.newlist_api %(rid, pn, ps)) return res # def get_region_info(self, rid, pn, ps): &quot;&quot;&quot; 获取最新视频信息 :param rid: 二级标题的id (详见tid_info.txt) :param pn: 页数 :param ps: 每页条目数 1-50 :return: &quot;&quot;&quot; res = BiliSpider.get_api(self.region_api %(rid, pn, ps)) return res # def get_member_info(self, mid): &quot;&quot;&quot; 获取用户信息 :param mid:用户id :return: &quot;&quot;&quot; post_data = { &quot;crsf&quot;: &quot;&quot;, &quot;mid&quot;: mid, } header = { &quot;Host&quot;: &quot;space.bilibili.com&quot;, &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:63.0) Gecko/20100101 Firefox/63.0&quot;, &quot;Accept&quot;: &quot;application/json, text/plain, */*&quot;, &quot;Accept-Encoding&quot;: &quot;gzip, deflate, br&quot;, &quot;Accept-Language&quot;: &quot;zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2&quot;, &quot;Referer&quot;: &quot;https://www.bilibili.com/&quot;, } res = requests.post(self.member_api, data=post_data, headers=header) member_dic = json.dumps(res.json(), ensure_ascii=False) return member_dic # def get_stat_info(self, vmid): &quot;&quot;&quot; 获取某用户的关注数和粉丝总数 :param vmid: 用户id :return: &quot;&quot;&quot; res = BiliSpider.get_api(self.stat_api % vmid) return res # def get_upstat_info(self, mid): &quot;&quot;&quot; 获取某用户的总播放量和总阅读量 :param mid: 用户id :return: &quot;&quot;&quot; res = BiliSpider.get_api(self.upstat_api % mid) return res # def get_follower_info(self, vmid, pn, ps): &quot;&quot;&quot; 获取某用户关注者信息 :param vmid:用户id :param pn: 页数 最多5页 :param ps: 每页条目数 1-50 :return: &quot;&quot;&quot; res = BiliSpider.get_api(self.follower_api %(vmid, pn, ps)) return res # def get_fans_info(self, vmid, pn, ps): &quot;&quot;&quot; 获取某用户粉丝信息 :param vmid:用户id :param pn: 页数 最多5页 :param ps: 每页条目数 1-50 :return: &quot;&quot;&quot; res = BiliSpider.get_api(self.fans_api %(vmid, pn, ps)) return resif __name__ == '__main__': bili = BiliSpider() res = bili.get_member_info(&quot;330626607&quot;) print(res)","link":"/2020/07/28/Blog/BiliBili-API/"},{"title":"Covid: nCov Data by Python","text":"Covid: nCov Data by Python Websites Intsall pip install Covid Python package to get information regarding the novel corona virus provided by Johns Hopkins university and worldometers.info 1. John Hopkins University API 優點：有經緯度信息，方便畫地圖缺點：國內鏈接速度較慢 Get All Data from covid import Covidcovid = Covid()covid.get_data() 理論上你將獲得： [ { 'id': '53', 'country': 'China', 'confirmed': 81020, 'active': 9960, 'deaths': 3217, 'recovered': 67843, 'latitude': 30.5928, 'longitude': 114.3055, 'last_update': 1584097775000 }, {... 實際上： Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; File &quot;/usr/local/lib/python3.7/site-packages/covid/john_hopkins/covid.py&quot;, line 137, in get_data return [CovidModel(**case[&quot;attributes&quot;]).dict() for case in cases] File &quot;/usr/local/lib/python3.7/site-packages/covid/john_hopkins/covid.py&quot;, line 137, in &lt;listcomp&gt; return [CovidModel(**case[&quot;attributes&quot;]).dict() for case in cases] File &quot;pydantic/main.py&quot;, line 338, in pydantic.main.BaseModel.__init__pydantic.error_wrappers.ValidationError: 1 validation error for CovidModelRecovered none is not an allowed value (type=type_error.none.not_allowed) 不過並不影響你獲取單個國際或地區的數據： Get Data by Country italy_cases = covid.get_status_by_country_id(115) { 'id': '115', 'country': 'Italy', 'confirmed': 24747, 'active': 20603, 'deaths': 1809, 'recovered': 2335, 'latitude': 41.8719, 'longitude': 12.5674, 'last_update': 1584318130000} 國家編號獲取： countries = covid.list_countries() [{'id': '18', 'name': 'US'}, {'id': '22', 'name': 'Brazil'},... Other Datas ##Get Total Active casesactive = covid.get_total_active_cases()##Get Total Confirmed casesconfirmed = covid.get_total_confirmed_cases()##Get Total Recovered casesrecovered = covid.get_total_recovered()##Get Total Deathsdeaths = covid.get_total_deaths() 2. Worldometers.info 速度快，但是沒有經緯度信息 covid = Covid(source=&quot;worldometers&quot;)##Get Datacovid.get_data() [{'country': 'North America', 'confirmed': 2258033, 'new_cases': 4166, 'deaths': 135128, 'rec... 畫圖 因爲種種原因- - 我放棄使用python了，還是用R的ggplot的好。 哼哼 = = 1. 數據獲取 from covid import Covidcovid = Covid()countries = covid.list_countries()covid.get_status_by_country_id(int(countries[0]['id']))## 多線程快速獲取import multiprocessing as mpdef worker(i, return_dict): '''worker function''' Result = covid.get_status_by_country_id(int(countries[i]['id'])) return_dict[Result] = Result print(Result)def multicore(Pool=10): pool = mp.Pool(processes=Pool) #return_dict = manager.dict() for i in range(10): # Working function &quot;echo&quot; and the arg 'i' multi_res = [pool.apply_async(worker,(i,return_dict))] pool.close() pool.join()if __name__ == '__main__': manager = mp.Manager() return_dict = manager.dict() jobs = [] Num = 0 for i in range(10): Num +=1 print (Num) p = mp.Process(target=worker, args=(i,return_dict)) jobs.append(p) p.start() for proc in jobs: proc.join() = = 放棄了- - 太慢了","link":"/2020/07/28/Blog/ConvData_python/"},{"title":"Unmapped reads Annotations","text":"Why Unmapped Reads Though we expect that the microbes are free in normal/healthy animal tissue, organ, or brain, we still get a few unmapped reads from NGS. And most of them are contributed by microbes. A Gouin, et al., 2014[1] studied those unmapped reads from 33 plants and believed that those sequences may contribute to the divergence between host plant specialized biotypes. To identify those unmapped reads, lots of pipelines and tools are developed. Mara Sangiovanni, 2019[2] published the DecontaMiner for investigating the presence of contamination. Zifan Zhu, 2019[3] released MicroPro to study the know and unknown microbes based on the unmapped reads. Not only in DNA-seq, but RNA-seq could also find lots of unmapped reads and they could be meaningful, too. Artur Gurgul, et al., 2022 [4] found those unmapped reads not only comes from contamination but also come from the hosts and could be used to refine the reference genome. For example, Majid Kazemian, 2015[5] find lots of new or abnormal transcripts from human cancer RNA-seq. A few de novo contigs from unmapped reads could not align to humans but other few kinds of Primates have positive effects on the tumor cell. Possible sources of unmapped reads: Biology Issue Human (From the technician) symbionts/pathogens Viruses Bacteria fungi other parasites (exp, mites) repetitive elements (some alignment tools would ignore them)[4:1] genetic variation SCGB1A1 gene(RNA-seq) [4:2] absent or misassembled in the reference genome[6] Not well-identified Genes[4:3] non-coding RNA (RNA-seq)[4:4] Technical Issue primer-dimer formation[7] Cloning/Expression Vecters Once we realized the existence and significance of unmapped reads, we need to find a way to annotate and analyze them. Kraken2 and bracken could be good choose. Published Pipeline A Gouin, 2014[1:1]: Host: 33 pea aphid Host Genome; mitochondrial genome; primary bacterial symbiont; several secondary symbiont genomes reported for the pea aphid. Main Steps Software Function Find unmapped reads Bowtie2 align to Reference Genome Find unmapped reads Samtools extract unmaped reads Unmapped reads assembly Prinseq trimme the quality below 20 within a window of 10 nucleotides, and only sequences of at least 66 nucleotides in length were retained Unmapped reads Analysis Compareads Find similar reads between two sets of reads in an assembly-free manner Unmapped reads assembly ABySS Unmapped reads de novo assembling Unmapped reads assembly Bowtie2 align unmapped reads to assembled Contigs Contigs analysis BLASTClust Found homologous large contigous. Contigs analysis BLASTn Found homologous contigous Unmapped reads assembly readFilter only reads for which 68% of the length was covered by 31-mers present at least 100 times in the data set were retained Unmapped reads assembly SPAdes De novo assembly Potentially divergent Mummer Global aligner, against reference: &gt;80% identity and &gt;500 bp were retained Contigs analysis GeneMarkS+ Predict the protein from de novo contigs. Contigs analysis Blastp Predicted protein annotation Potentially divergent Stampy An aligner performs well when divergent is high. Potentially divergent GATK SNP calling PS: Why Bowtie2: the percentage of unmapped reads was higher than for Bowtie2 (on average over the 33 individuals, 6.1% vs 3.7% for BWA and Bowtie2, respectively) DecontaMiner, 2019[2:1] © Mara Sangiovanni, et al. 2019 MicroPro, 2019[3:1] Align reads to Reference-based known microbial by Centrifuge The average mapping rate for each dataset is about 35–40%. Cross-assembly by: Megahit and Minia 3 Megahit performed better in real data analysis. MetaBAT 2.12.1 to binning Abundance estimate achived by BWA-aln Predicting phenotypes using random forests About viral: Step 1: Known viral abundance extraction Step 2: Unknown viral feature detection Step 3: Predicting phenotypes based on viral abundance PS: Corss-assembly: Using reads from different samples to assemble: Increasing the coverage of contigs.B. Papudeshi; 2018 Unmapped human RNA-Seq data and their association with cancer © Majid Kazemian, 2015 Exploring the unmapped DNA and RNA reads in a songbird genome © Veronika N. Laine, 2015 About Bracken Jen Lu; 2017: If a 150bp read is 100% identical to two different species, Kraken will assign it to their lowest common ancestor (LCA), which could be at the genus level or higher. But some reads within a particular sample usually come from the unique (or species-specific) portion of the genome. Bracken uses this information, plus information about the similarity between the sister species, to “push down” reads from the genus level to the species level. Other background information: Challenges in benchmarking metagenomic profilers; Nature Methods To be notices, Kraken2 and Bracken is DNA-to-DNA strategy. The abundance of the reads is relative to the nucleotide, not species individual. © Zheng Sun, 2021 Why Kraken Lu J., et al. showed that comparing to QiiMe, Kraken2 has uncompetable speed in annotation and the results from kraken-bracken are even better than QiiMe[8]. I think it’s time for QiiMe move a room for Kraken2 now. © Lu J. Unmapped reads Prepare your working directories . ├── Bam ├── FQ_unmapped ├── Parasites ├── Log ├── Model.sh └── script Bam: Aligned bam files FQ_unmapped: Storing the unmapped reads from .bam Parasites: Directory for store Clean.fa which contains some contamination seqs and cloning vectors. Log: Directory for logs Model.sh: A script with slurm parameters. script: script for A Quick Pipeline from Genomics Tutorial; 2020: Prepare Database Prepare your vector sequence in `vector.fa` mkdir Parasitescd Parasiteswget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/010/205/GCF_000010205.1_ASM1020v1/GCF_000010205.1_ASM1020v1_genomic.fna.gzwget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/239/435/GCF_000239435.1_ASM23943v1/GCF_000239435.1_ASM23943v1_genomic.fna.gzwget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/255/335/GCF_000255335.2_Mocc_1.1/GCF_000255335.2_Mocc_1.1_genomic.fna.gzcurl -OJX GET &quot;https://api.ncbi.nlm.nih.gov/datasets/v1/genome/accession/GCA_024678965.1/download?include_annotation_type=GENOME_GFF,RNA_FASTA,CDS_FASTA,PROT_FASTA&amp;filename=GCA_024678965.1.zip&quot; -H &quot;Accept: application/zip&quot;gunzip *sed &quot;s/&gt;/&gt;Mite_/&quot; *.fna &gt; Clean.faunzip GCA_024678965.1.zipsed &quot;s/&gt;/&gt;nematodes_/&quot; ncbi_dataset/data/GCA_024678965.1/GCA_024678965.1_AAFC-BrLi-01_v2_genomic.fna &gt;&gt; Clean.facat vector.fa &gt;&gt; Clean.fa Unmapped reads extraction Align to Reference Genome → Unmapped reads extract → Kraken2 annotation → Bracken Abundance estimation. Technically, you can find the unmapped reads by samtools view *.bam| awk '$3==&quot;*&quot;'. But I don’t know why the number of reads is less than the result from samtools stats. So, the easiest way to achieve this is: Single end: samtools fastq -@ 8 -f 4 Bam/S10_aln_pe_bqsr.bam &gt; s.fq.gz Paired end: samtools fastq -@ 8 -f 4 Bam/10_aln_pe_bqsr.bam -1 1.fq.gz -2 2.fq.gz -s s.fq.gz In this code, reads would be split into 3 files: 1.fq.gz, 2.fq.gz, and s.fq.gz. The first two are paired reads and the 3rd is unpaired reads. In Kraken classification under paired parameter, unpaired reads in fq file would be ignored. So, we need to store them independently and run kraken twice. If some samples are single ends, the result cannot be stored with this command. But the reads would be printed into log file: Log/*.out. So, we can compress it into fq.gz module load samtoolsSUFFIX=_aln_pe_bqsr.bamBAM=BamOUT_dir=FQ_unmappedmkdir $OUT_dir script Logfor i in $(ls $BAM/*.bam); do SAMPLE=$(echo $i| awk -F&quot;/&quot; '{print $NF}'| sed &quot;s/$SUFFIX//&quot;); if [ -f $OUT_dir/$SAMPLE\\_1.fq.gz ]; then echo $SAMPLE is done else sed &quot;s/Hi/$SAMPLE/&quot; Model.sh &gt; script/$SAMPLE\\_fq.sh echo &quot;samtools fastq -@ 8 -f 4 $i -1 $OUT_dir/$SAMPLE&quot;&quot;_1.fq.gz -2 $OUT_dir/$SAMPLE&quot;&quot;_2.fq.gz -s $OUT_dir/$SAMPLE&quot;&quot;_s.fq.gz&quot; &gt;&gt; script/$SAMPLE\\_fq.sh sbatch script/$SAMPLE\\_fq.sh fidone# Check for Single Endsfor i in $(du Log/*.out | grep -v ^0|awk '{print $2}');do SAMPLE=$(echo $i| sed 's=Log/==;s/.out//') sed &quot;s/Hi/Single_$SAMPLE/&quot; Model.sh &gt; script/$SAMPLE\\_fq_s.sh echo gzip -c $i \\&gt; $OUT_dir/$SAMPLE\\_s.fq.gz &gt;&gt; script/$SAMPLE\\_fq_s.sh sbatch script/$SAMPLE\\_fq_s.shdone# Finally, remove emplty fq filesrm $(du $OUT_dir/*| grep &quot;^4&quot;$'\\t'|awk '{print $2}')# Check the number of samples is correct or notls $OUT_dir/*|sed 's/_[12s].fq.gz//'|sort|uniq |wc -l 131 Here I have 131 samples in total. And result is 131 which means I didn’t miss any of them. If you are not using slurm syste, this code may help for SAMPLE in $(du FQ_unmapped/_s.fq.gz | grep ^4$'\\t'| awk -F&quot;/&quot; '{print $NF}'| sed 's/_s.fq.gz//'); do i=$(ls $BAM/.bam| grep $SAMPLE) echo $SAMPLE $i samtools fastq -@ 8 -f 4 $i &gt; FQ_unmapped/$SAMPLE_s.fq.gzdone Align into Cleaning database and counts cd Parasitesbwa index Clean.facd .. Here we already know that the fq ends as 1_fq.gz is Paired reads, s_fq.gz is unpaired reads. So, we can do: FQ_DB=FQ_unmappedDB=ParasitesDB_FA=Parasites/Clean.faOUTPUT=Bam_cleanmkdir $OUTPUT# Pairedfor SAMPLE in $(ls $FQ_DB/*_1.fq.gz| sed &quot;s=$FQ_DB/==;s/_[12].fq.gz//&quot;); do if [ -f $SAMPLE.P.sorted.bam ]; then echo $SAMPLE is done else echo $SAMPLE can not be find sed &quot;s/Hi/$SAMPLE\\_P_$DB/&quot; Model.sh &gt; script/$SAMPLE\\_P_$DB.sh echo bwa mem $DB_FA $FQ_DB/$SAMPLE\\_1.fq.gz $FQ_DB/$SAMPLE\\_1.fq.gz -t 64 \\|samtools view -S -b -\\|samtools sort \\&gt; $SAMPLE.P.sorted.bam &gt;&gt; script/$SAMPLE\\_P_$DB.sh echo samtools index $SAMPLE.P.sorted.bam &gt;&gt; script/$SAMPLE\\_P_$DB.sh sbatch script/$SAMPLE\\_P_$DB.sh fidone# Singlefor SAMPLE in $(ls $FQ_DB/*_s.fq.gz| sed &quot;s=$FQ_DB/==;s/_s.fq.gz//&quot;); do if [ -f $SAMPLE.S.sorted.bam ]; then echo $SAMPLE is done else echo $SAMPLE can not be find Clean echo bwa mem $DB_FA $FQ_DB/$SAMPLE\\_s.fq.gz -t 64 \\|samtools view -S -b -\\|samtools sort \\&gt; $SAMPLE.S.sorted.bam &gt;&gt; script/$SAMPLE\\_S_$DB.sh echo samtools index $SAMPLE.S.sorted.bam &gt;&gt; script/$SAMPLE\\_S_$DB.sh sbatch script/$SAMPLE\\_S_$DB.sh fidone## Check unexpected size of filerm $(du *.sorted.bam | awk '$1&lt;=100'| awk '{print $2}')## After removed failed files, we can excute the for loop again#.#.#.## finally, we can mv all bam into another directorymv *.sorted.* $OUTPUT Counting results There are two bam files. One is paired result, another is single end result. For avoid counting them twice in paired result, we can samply sort and uniq them. The only problem is it would consume lots of memory and time. for SAMPLE in $(ls Bam_clean/*.bam| sed 's/.[PS].sorted.bam//;s=Bam_clean/=='| sort |uniq); do sed &quot;s/Hi/$SAMPLE_Clean_count/&quot; Model.sh &gt; script/$SAMPLE.bam_count.sh echo &quot;cat Bam_clean/$SAMPLE.[PS].sorted.bam| samtools view| awk '{print $1,$3}'| awk -F&quot;_&quot; '{print $1}'| sort|uniq| awk '{print $2}'|sort| uniq -c |sed 's/^ *//'&gt; Bam_Stats/$SAMPLE.Clean.csv&quot; &gt;&gt; script/$SAMPLE.bam_count.sh sbatch script/$SAMPLE.bam_count.shdone extract unmapped reads again Codes folded for extract reads again module load samtoolsBAM=Bam_cleanOUT_dir=FQ_splitmkdir $OUT_dir script Log## paired-end readsfor i in $(ls $BAM/*.P.sorted.bam); do SAMPLE=$(echo $i| awk -F&quot;/&quot; '{print $NF}'| sed &quot;s/.P.sorted.bam//&quot;); if [ -f $OUT_dir/$SAMPLE\\_1.fq.gz ]; then echo $SAMPLE is done else sed &quot;s/Hi/$SAMPLE/&quot; Model.sh &gt; script/$SAMPLE\\_fq.sh echo &quot;samtools fastq -@ 8 -f 4 $i -1 $OUT_dir/$SAMPLE&quot;&quot;_1.fq.gz -2 $OUT_dir/$SAMPLE&quot;&quot;_2.fq.gz -s $OUT_dir/$SAMPLE&quot;&quot;_s.fq.gz&quot; &gt;&gt; script/$SAMPLE\\_fq.sh sbatch script/$SAMPLE\\_fq.sh fidone# Check for Single Endsfor i in $(ls $BAM/*.S.sorted.bam); do SAMPLE=$(echo $i| awk -F&quot;/&quot; '{print $NF}'| sed &quot;s/.S.sorted.bam//&quot;); sed &quot;s/Hi/$SAMPLE/&quot; Model.sh &gt; script/$SAMPLE\\_fq.sh echo &quot;samtools fastq -@ 8 -f 4 $i| gzip -f &gt; $OUT_dir/$SAMPLE&quot;&quot;_s.fq.gz&quot; &gt;&gt; script/$SAMPLE\\_fq.sh sbatch script/$SAMPLE\\_fq.shdone# Finally, remove emplty fq filesrm $(du $OUT_dir/*| grep &quot;^4&quot;$'\\t'|awk '{print $2}')# Check the number of samples is correct or notls $OUT_dir/*|sed 's/_[12s].fq.gz//'|sort|uniq |wc -l A Quick Pipeline Example Create a virtual environment and install tools Prepare the test data (fastq) Prepare the database (virus Kraken database) Run the result Bracken correction More annotation database could be found: GitHub Kraken2 DataBase # 1. Creat a virtual environmentconda create --yes -n kraken -c bioconda kraken2 brackenconda activate kraken# 2. Download Test datawget -O mappings.tar.gz https://osf.io/g5at8/downloadtar xvzf mappings.tar.gzmkdir krakencd kraken# 3. download annotation databasemkdir Viralcd Viralwget https://genome-idx.s3.amazonaws.com/kraken/k2_viral_20220607.tar.gztar -zxvf k2_viral_20220607.tar.gzcd ..# 4. Run the resutlsDB=Viral# 5. Branken correctionkraken2 --use-names --threads 4 --db PlusPFP --fastq-input --report $DB.report --gzip-compressed --paired ../mappings/evol1.sorted.unmapped.R1.fastq.gz ../mappings/evol1.sorted.unmapped.R2.fastq.gz &gt; $DB.krakenbracken -d $DB -i $DB.report -o $DB.bracken -r 300 -l S -t 2 Pipeline for Paired reads mkdir Kraken_result FQ_splitFQ=FQ_splitDB=PlusPFPDB_L=../kraken/PlusPFP# pairedfor SAMPLE in $(ls $FQ/*_1.fq.gz| sed &quot;s/_1.fq.gz//;s=$FQ/==&quot;); do if [ -f Kraken_result/$SAMPLE\\_$DB\\_P.bracken ];then echo $SAMPLE is done else echo Try $SAMPLE sed &quot;s/Hi/Kra_$SAMPLE/&quot; Model.sh &gt; script/kraken_$SAMPLE\\_P.sh echo kraken2 --use-names --threads 64 --db $DB_L --fastq-input --report Kraken_result/$SAMPLE\\_$DB\\_P.report --gzip-compressed --paired $FQ/$SAMPLE\\_1.fq.gz $FQ/$SAMPLE\\_2.fq.gz \\&gt; Kraken_result/$SAMPLE\\_$DB\\_P.kraken &gt;&gt; script/kraken_$SAMPLE\\_P.sh echo bracken -d $DB_L -i Kraken_result/$SAMPLE\\_$DB\\_P.report -o Kraken_result/$SAMPLE\\_$DB\\_P.bracken -r 300 -l S -t 2 &gt;&gt; script/kraken_$SAMPLE\\_P.sh sbatch script/kraken_$SAMPLE\\_P.sh fidone# sanglefor SAMPLE in $(ls $FQ/*_s.fq.gz| sed &quot;s/_s.fq.gz//;s=$FQ/==&quot;); do if [ -f Kraken_result/$SAMPLE\\_$DB\\_S.bracken ];then echo $SAMPLE is done else echo Try $SAMPLE sed &quot;s/Hi/Kra_$SAMPLE/&quot; Model.sh &gt; script/kraken_$SAMPLE\\_S.sh echo kraken2 --use-names --threads 64 --db $DB_L --fastq-input --report Kraken_result/$SAMPLE\\_$DB\\_S.report --gzip-compressed --paired $FQ/$SAMPLE\\_s.fq.gz $FQ/$SAMPLE\\_s.fq.gz \\&gt; Kraken_result/$SAMPLE\\_$DB\\_S.kraken &gt;&gt; script/kraken_$SAMPLE\\_S.sh echo bracken -d $DB_L -i Kraken_result/$SAMPLE\\_$DB\\_S.report -o Kraken_result/$SAMPLE\\_$DB\\_S.bracken -r 300 -l S -t 2 &gt;&gt; script/kraken_$SAMPLE\\_S.sh sbatch script/kraken_$SAMPLE\\_S.sh fidone For other levels: Levels: D → K → P → C → O → F → G → S EXP: D Eukaryota K Metazoa P Chordata C Mammalia O Primates F Hominidae G Homo S Homo sapiens DB=PlusPFPLEVEL=Gfor SAMPLE in $(ls FQ_split/*.fq.gz| sed 's/_[12].fq.gz//;s=FQ_split/=='|sort |uniq); do bracken -d $DB -i Kraken_result/$SAMPLE\\_$DB.report -o Kraken_result/$SAMPLE\\_$DB\\_$LEVEL.bracken -r 300 -l $LEVEL -t 2done Combine them into one csv: grep . Kraken_result/*.bracken| head -n 1| sed 's/:/\\t/;s=Kraken_result/==;s/_PlusPFP.bracken//' &gt; bracken.csvgrep -v &quot;taxonomy_id&quot; Kraken_result/*.bracken| sed 's/:/\\t/;s=Kraken_result/==;s/_PlusPFP.bracken//' &gt;&gt; bracken.csvgrep &quot;sequences unclassified&quot; Log/Kra_*.err| grep -v nan| awk '{print $1,$2,$NF}'| sed 's/[:/()%]//g;s/LogKra_//;s/.err//' &gt; Unclassed.csv Extract unclassified reads # record unclassified readsfor i in $(ls Kraken_result/*.kraken); do OUT=$(echo $i| sed 's=Kraken_result/==;s/.kraken/.uc.list/') grep ^U $i| awk '{print $2}' &gt; Log/$OUTdoneRED_dir=FQ_splitOUT_dir=FQ_split2mkdir $OUT_dirmkdir $OUT_dir/$RED_dir# extract unclassified reads with seqkitfor i in $(ls Log/*.uc.list) do echo $i; if [ $(echo $i| sed 's/_S.uc.list//') != $i ] ; then sed &quot;s/Hi/seqkit_S_$SAMPLE/&quot; Model.sh &gt; script/$SAMPLE\\_S.sh READ_1=$(echo $i | sed &quot;s=Log=$RED_dir=;s/_PlusPFP_P.uc.list/_s.fq.gz/&quot;) seqkit grep -n -f $i $READ_1 &gt; $OUT_dir/$READ_1 else sed &quot;s/Hi/seqkit_S_$SAMPLE/&quot; Model.sh &gt; script/$SAMPLE\\_P.sh READ_1=$(echo $i | sed &quot;s=Log=$RED_dir=;s/_PlusPFP_P.uc.list/_1.fq.gz/&quot;) READ_2=$(echo $i | sed &quot;s=Log=$RED_dir=;s/_PlusPFP_P.uc.list/_2.fq.gz/&quot;) seqkit grep -n -f $i $READ_1 &gt; $OUT_dir/$READ_1 seqkit grep -n -f $i $READ_2 &gt; $OUT_dir/$READ_2 fidone Visualization in R library(ggplot2)library(ggrepel)TB &lt;- read.table(&quot;Unclassed.csv&quot;)TB$Total &lt;- TB$V2/TB$V3*100ggplot(TB, aes(x=Total, y= V3)) + geom_point() + geom_text_repel(aes(label= V1)) + theme_bw() + coord_cartesian(ylim = c(0,100), expand = F) Ratio of unclassified Reads Download SuperKingdom table from NCBI wget ftp://ftp.ncbi.nih.gov/pub/taxonomy/taxcat.tar.Ztar -zxvf taxcat.tar.Z Abbr. Kingdom A Archaea B Bacteria E Eukaryota V Viruses and Viroids U Unclassified O Other (exp. Plasmids) library(ggplot2)library(reshape2)library(stringr)library(pheatmap)library(ggrepel)TB &lt;- read.csv(&quot;bracken.csv&quot;, sep= '\\t', header = T)Kingdom &lt;- read.table(&quot;categories.dmp&quot;)TB$SK &lt;- Kingdom$V1[match(TB$taxonomy_id, Kingdom$V2)]colnames(TB)[1]=&quot;Sample&quot;SAMPLE = head(unique(TB$Sample), 10)#SAMPLE = unique(TB$Sample[-grep(&quot;[AT][TA]|[Hh][Oo][Ss][tT]|NICD|G17&quot;, TB$Sample)])TMP &lt;- TB[TB$Sample %in% SAMPLE,]TMP$Sample &lt;- as.factor(as.character(TMP$Sample))#TMP$Sample &lt;- factor(TMP$Sample, levels = unique(TMP$Sample)[c(1:10,14:18,21,11:13,19:20)])TB_w &lt;- reshape(TB[c(1,2,8)], timevar = &quot;Sample&quot;, idvar = 'name', direction = 'wide')row.names(TB_w) &lt;- TB_w[[1]]TB_w &lt;- TB_w[-1]colnames(TB_w) &lt;- str_replace(colnames(TB_w), &quot;fraction_total_reads.&quot;, &quot;&quot;)TB_w[is.na(TB_w)] &lt;- 0TB_wS &lt;- as.data.frame(t(scale(t(TB_w))))TB_wS&lt;- TB_wS[!is.na(TB_wS[[1]]),]pheatmap(TB_wS)# PCATB_wS.pca &lt;- prcomp(t(TB_wS),scale. = F)TB_wS.pca= data.frame(TB_wS.pca$x)TB_wS.pca$Group = &quot;Other&quot;TB_wS.pca$Group[grep(&quot;MH&quot;,row.names(TB_wS.pca))] &lt;- &quot;MH&quot;TB_wS.pca$Group[grep(&quot;FH&quot;,row.names(TB_wS.pca))] &lt;- &quot;FH&quot;ggplot(TB_wS.pca, aes(PC1,PC2, color=Group)) + geom_point()+ theme_bw() + geom_text_repel(aes(label=row.names(TB_wS.pca)))ggplot(TB_wS.pca[TB_wS.pca$Group %in% c(&quot;FH&quot;, &quot;MH&quot;),], aes(PC1,PC2, color=Group)) + geom_point()+ theme_bw() + geom_text_repel(aes(label=row.names(TB_wS.pca[TB_wS.pca$Group %in% c(&quot;FH&quot;, &quot;MH&quot;),])))+ stat_ellipse(lwd=1,level = 0.75)#ggplot(TB, aes(Sample, fraction_total_reads, fill=name)) + geom_bar(stat = 'identity', position = 'fill') Type Graphics Pheatmap PCA Barplot ggplot(TB, aes(Sample, new_est_reads, fill=name)) + theme_bw()+ geom_bar(stat = 'identity', position = &quot;fill&quot;, show.legend = F)+ theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5))+ facet_grid(SK~.)+ geom_text_repel(aes(label=name), color = &quot;black&quot;, show.legend = F, position = position_fill(vjust= .5)) Relationship with unmapped reads and unclassified reads . ├── Bam_stats │ └── SAMPLE.stats.csv └── Kraken_result ├── SAMPLE_PlusPFP.bracken ├── SAMPLE_PlusPFP_bracken.report ├── SAMPLE_PlusPFP.kraken └── SAMPLE_PlusPFP.report Bams_stats is generated by samtools stats SAMPLE.bam &gt; SAMPLE.stats.csv In Kraken, when you use paired reads, it would only show the number of the paired reads which means you only get a half size of the reads compared to the result from samtools stats. As a result, we need to multiply them by 2 during visualization. echo -e &quot;Sample\\tTotal\\tUnmapped\\tClassified\\tUnClassified&quot; &gt; Counts_Ratio.csvfor i in $(ls Bam_stats/| sed 's/.stats.csv//'); do UNMAP=$(grep -w &quot;reads unmapped&quot; Bam_stats/$i.stats.csv| awk -F&quot;\\t&quot; '{print $3}') TOTAL=$(grep -w &quot;raw total sequences:&quot; Bam_stats/$i.stats.csv| awk -F&quot;\\t&quot; '{print $3}') CLASF=$(grep -c ^C Kraken_result/$i\\_PlusPFP.kraken) UNCLF=$(grep -c ^U Kraken_result/$i\\_PlusPFP.kraken) echo -e &quot;$i\\t$TOTAL\\t$UNMAP\\t$CLASF\\t$UNCLF&quot;done &gt;&gt; Counts_Ratio.csv library(ggplot2)library(reshape2)library(pheatmap)library(ggplotify)library(ggkaboom)TB &lt;- read.table(&quot;Counts_Ratio.csv&quot;, header =T)#TB$Sample &lt;- as.character(as.numeric(TB$Sample))TB$Classified &lt;- TB$Classified*2TB$UnClassified &lt;- TB$UnClassified*2TB2 &lt;- TBTB2[3:5] &lt;- TB2[3:5]/TB2[[2]]TB2[2:5] &lt;- scale(TB2[2:5])row.names(TB2) &lt;- TB2[[1]]TB2 &lt;-TB2[-1]P &lt;- pheatmap(t(TB2))as.ggplot(P)ggsave(&quot;img/Number_Pheat.png&quot;, h= 7.5, w = 12)# for Bar fill plotTB_bar &lt;- TBTB_bar$Mapped &lt;- TB_bar$Total -TB_bar$ UnmappedTB_bar &lt;- TB_bar[c(&quot;Sample&quot;, &quot;Mapped&quot;, &quot;Classified&quot;, &quot;UnClassified&quot;)]#TB_bar_r &lt;- TB_bar[2:4]/TB$Total#row.names(TB_bar_r) &lt;- TB$SampleTB.hclust &lt;- hclust(dist(TB2))TB_L &lt;- melt(TB_bar)TB_L$Sample &lt;- factor(TB_L$Sample, levels=TB.hclust$labels[TB.hclust$order])P &lt;- ggplot(TB_L, aes(Sample, value, fill= variable)) + geom_bar(stat = 'identity', position = 'fill')+theme_bw() + scale_fill_manual( values= c(&quot;OliveDrab2&quot;, &quot;deepskyblue&quot;, &quot;salmon&quot;)) + theme(axis.text.x = element_text(angle= 270, hjust=0, vjust = .5))Kaboom_break(P, c(0, 0.04, 0, 1), R=c(2, 1))ggsave(&quot;img/Number_Bar.png&quot;, h= 7.5, w = 12)# Not FillTB_bar2 &lt;- melt(TB[c(&quot;Sample&quot;, &quot;Total&quot;, &quot;Unmapped&quot;, &quot;UnClassified&quot;)])TB_bar2$Sample &lt;- factor(TB_bar2$Sample, levels=TB.hclust$labels[TB.hclust$order])P &lt;- ggplot(TB_bar2, aes(Sample, value, fill= variable)) + geom_bar(stat = 'identity', position = position_identity() )+ scale_fill_brewer(palette = &quot;Set2&quot;)+ theme_bw() + theme(axis.text.x = element_text(angle= 270, hjust=0, vjust = .5))Kaboom_break(P, c(0, 20000000, 0, 200000000), R=c(2, 1))ggsave(&quot;img/Number_raw.png&quot;, h= 7.5, w = 12)## UnclassifiedTB_L$Sample &lt;- factor(TB_L$Sample, levels=TB$Sample[order(TB$UnClassified/TB$Classified)])P &lt;- ggplot(TB_L[TB_L$variable!=&quot;Mapped&quot;,], aes(Sample, value, fill= variable)) + geom_bar(stat = 'identity', position = 'fill')+theme_bw() + scale_fill_manual( values= c(&quot;deepskyblue&quot;, &quot;salmon&quot;)) + theme(axis.text.x = element_text(angle= 270, hjust=0, vjust = .5))ggsave(&quot;img/Number_Bar_classR.png&quot;, h= 7.5, w = 12) Header One Header Two Full Taxonomic information based on ID Some times, we’d like to analyze the Eucariaotic or Viral independently. Them, we need to find the phlums of them based on taxonomic ID. etetoolkit Can help find the phylums efficiently. conda create -n ete3 python=3conda activate ete3conda install -c etetoolkit ete3 ete_toolchainete3 build checkete3 ncbiquery --search 1204725 2162 13000163 420247 --info By aquriring specific information, SuperKingdom here, we can also use “E-utilities” from NCBI efetch -db taxonomy -id 9606,1234,81726 -format xml | \\xtract -pattern Taxon -tab &quot;,&quot; -first TaxId ScientificName \\-group Taxon -KING &quot;(-)&quot; -PHYL &quot;(-)&quot; -CLSS &quot;(-)&quot; -ORDR &quot;(-)&quot; -FMLY &quot;(-)&quot; -GNUS &quot;(-)&quot; \\-block &quot;*/Taxon&quot; -match &quot;Rank:superkingdom&quot; -SKIN ScientificName \\-block &quot;*/Taxon&quot; -match &quot;Rank:kingdom&quot; -KING ScientificName \\-block &quot;*/Taxon&quot; -match &quot;Rank:phylum&quot; -PHYL ScientificName \\-block &quot;*/Taxon&quot; -match &quot;Rank:class&quot; -CLSS ScientificName \\-block &quot;*/Taxon&quot; -match &quot;Rank:order&quot; -ORDR ScientificName \\-block &quot;*/Taxon&quot; -match &quot;Rank:family&quot; -FMLY ScientificName \\-block &quot;*/Taxon&quot; -match &quot;Rank:genus&quot; -GNUS ScientificName \\-group Taxon -tab &quot;,&quot; -element &quot;&amp;SKIN&quot; &quot;&amp;KING&quot; &quot;&amp;PHYL&quot; &quot;&amp;CLSS&quot; &quot;&amp;ORDR&quot; &quot;&amp;FMLY&quot; &quot;&amp;GNUS&quot; ID=$(awk -F&quot;\\t&quot; '{print $3}' bracken.csv | sort |uniq| grep -v tax| tr '\\n' &quot;,&quot;| sed 's/,$/\\n/')efetch -db taxonomy -id $ID -format xml | \\xtract -pattern Taxon -tab &quot;,&quot; -first TaxId ScientificName \\-group Taxon -KING &quot;(-)&quot; -PHYL &quot;(-)&quot; -CLSS &quot;(-)&quot; -ORDR &quot;(-)&quot; -FMLY &quot;(-)&quot; -GNUS &quot;(-)&quot; \\-block &quot;*/Taxon&quot; -match &quot;Rank:superkingdom&quot; -SKIN ScientificName \\-block &quot;*/Taxon&quot; -match &quot;Rank:kingdom&quot; -KING ScientificName \\-block &quot;*/Taxon&quot; -match &quot;Rank:phylum&quot; -PHYL ScientificName \\-block &quot;*/Taxon&quot; -match &quot;Rank:class&quot; -CLSS ScientificName \\-block &quot;*/Taxon&quot; -match &quot;Rank:order&quot; -ORDR ScientificName \\-block &quot;*/Taxon&quot; -match &quot;Rank:family&quot; -FMLY ScientificName \\-block &quot;*/Taxon&quot; -match &quot;Rank:genus&quot; -GNUS ScientificName \\-group Taxon -tab &quot;\\t&quot; -element &quot;&amp;SKIN&quot; &quot;&amp;KING&quot; &quot;&amp;PHYL&quot; &quot;&amp;CLSS&quot; &quot;&amp;ORDR&quot; &quot;&amp;FMLY&quot; &quot;&amp;GNUS&quot; &gt; Taxonomy.csv Other plots Taxonomy from species name in r pre { background-color:#38393d; color: #5fd381; } Gouin, A., Legeai, F., Nouhaud, P. et al. Whole-genome re-sequencing of non-model organisms: lessons from unmapped reads. Heredity 114, 494–501 (2015). https://doi.org/10.1038/hdy.2014.85 ↩︎ ↩︎ Sangiovanni, M., Granata, I., Thind, A. et al. From trash to treasure: detecting unexpected contamination in unmapped NGS data. BMC Bioinformatics 20 (Suppl 4), 168 (2019). https://doi.org/10.1186/s12859-019-2684-x ↩︎ ↩︎ Zhu, Z., Ren, J., Michail, S. et al. MicroPro: using metagenomic unmapped reads to provide insights into human microbiota and disease associations. Genome Biol 20, 154 (2019). https://doi.org/10.1186/s13059-019-1773-5 ↩︎ ↩︎ Gurgul, A., Szmatoła, T., Ocłe sources of unmapped reads are various: they may derive from characterized or unchoń, E. et al. Another lesson from unmapped reads: in-depth analysis of RNA-Seq reads from various horse tissues. J Appl Genetics 63, 571–581 (2022). https://doi.org/10.1007/s13353-022-00705-z ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ Kazemian, Majid, et al. “Comprehensive assembly of novel transcripts from unmapped human RNA‐Seq data and their association with cancer.” Molecular systems biology 11.8 (2015): 826. https://doi.org/10.15252/msb.156172 ↩︎ Laine, V.N., Gossmann, T.I., van Oers, K. et al. Exploring the unmapped DNA and RNA reads in a songbird genome. BMC Genomics 20, 19 (2019). https://doi.org/10.1186/s12864-018-5378-2 ↩︎ De Bourcy, Charles FA, et al. “A quantitative comparison of single-cell whole genome amplification methods.” PloS one 9.8 (2014): e105585. ↩︎ Lu J, Salzberg S L. Ultrafast and accurate 16S rRNA microbial community analysis using Kraken 2[J]. Microbiome, 2020, 8(1): 1-11. ↩︎","link":"/2022/08/30/Bioinfor/unmapped-reads/"},{"title":"Hexo: batch | Maintain you md files with batchs&#x2F;scripts","text":"Substitute Sometimes, we want to change the category, let’s say, from [Notes, Biology, Paper] to [Notes, Paper, Biology]. It is not a good idea to rewrite them one by one. In fact, sed can help. BASHstrA=&quot;\\[Notes,\\ Biology,\\ Paper\\]&quot;strB=&quot;\\[Notes,\\ Paper,\\ Biology\\]&quot;## Ender your hexo blog directorycd ${Hexo}## searching for all postsfind source -name &quot;*.md&quot;## Check the match patterngrep &quot;$strA&quot; $(find source -name &quot;*.md&quot;)## Select one of the file from above to test the substitute patternsed &quot;s/$strA/$strB/&quot; mtGenome.md| head## once the substitution was successful, we can run it on all posts.sed -i &quot;s/$strA/$strB/&quot; $(find source -name &quot;*.md&quot;) Check the match pattern With the sed grammar above, we shall substitute all strA with strB. But sometimes, we may go too far. To avoid replacing something unintentionally, we’d like to make sure each matching pattern is unique. We can achieve this with bash commands. ## Count the match pattern to make sure it is uniq:grep &quot;$strA&quot; $(find source -name &quot;*.md&quot;)| awk -F&quot;:&quot; '{print $1}'| uniq -c In this case, we use grep to search all matching patterns in all files. By piping it to awk, the name of the files has remained. Finally, we calculate the files and find Hexo_post.md has two matches. 1 source/_posts/Blog/hexo_lived2d_busuanzi.md 1 source/_posts/Blog/Hexo_math.md 2 source/_posts/Blog/Hexo_post.md 1 source/_posts/Blog/Hexo_search.md We can also achieve this with uniq -d and only Hexo_post.md will be printed out. In this situation, we need to change our matching string to avoid mismatches. Final Check Before you run sed -i, you can still make a final check: sed &quot;s/$strA/$strB/&quot; $(find source -name &quot;*.md&quot;)| grep &quot;$strB&quot;|wc by comparing the counts of result by grep. substitute Html site Replace Sit1 with Sit2 SIT1=&quot;https://www.electronjs.org/app-img/hexo-client/hexo-client-icon-128.png&quot;SIT2=&quot;https://blog.kritner.com/2019/03/19/Hexo-local-configuration/hexo-logo-avatar.png&quot;strA=$(echo $SIT1|sed 's=/=\\\\/=g')strB=$(echo $SIT2|sed 's=/=\\\\/=g')## Ender your hexo blog directorycd ${Hexo}## As before, you show try it before rewritesed -i &quot;s/$strA/$strB/&quot; $(find source -name &quot;*.md&quot;) Citation File=23.mdcp $File $File.mdCites=$(grep &quot;^\\[&quot; $File|sort|uniq)sed -i '/^\\[/d' $File.mdecho -e &quot;---\\n$Cites&quot; &gt;&gt; $File.md Before $File- BSFL meal increased the abundance of beneficial microorganisms that contribute to the health of the host such as lactic acid[^Huyben_2019][^Terova_2019][^Rimoldi_2019]and butyrate[^Terova_2019].[^Rimoldi_2019]: Rimoldi S, Gini E, Iannini F, Gasco L, Terova G. The effects of dietary insect meal from Hermetia illucens prepupae on autochthonous gut microbiota of rainbow trout (Oncorhynchus mykiss). Animals (2019) 9(4):143. doi: 10.3390/ani9040143[^Liu_H_2018]: Liu H, Wang J, He T, Becker S, Zhang G, Li D, et al. Butyrate: a double-edged sword for health? Adv Nutr (2018) 9(1):21–9. doi: 10.1093/advances/nmx009- The anti-inflammatory properties of microbe-derived butyrate in gut and its role in enhancing intestinal barrierfunction and mucosal immunity are well studied in human[^Liu_H_2018].[^Huyben_2019]: Huyben D, Vidaković A, Hallgren SW, Langeland M. High-throughput sequencing of gut microbiota in rainbow trout (Oncorhynchus mykiss) fed larval and pre-pupae stages of black soldier fly (Hermetia illucens). Aquaculture (2019) 500:485–91. doi: 10.1016/j.aquaculture.2018.10.034- It is also possible that the short-chain fatty acids including butyrate produced by gut microbiota might induce the expression of host defense peptides and prevent inflammation in the gut as observed in mammals and birds[^Wu_J_2020].[^Terova_2019]: Terova G, Rimoldi S, Ascione C, Gini E, Ceccotti C, Gasco L. Rainbow trout (Oncorhynchus mykiss) gut microbiota is modulated by insect meal from Hermetia illucens prepupae in the diet. Rev Fish Biol Fish (2019) 29:465–86. doi: 10.1007/s11160-019-09558-y After I removed blank lines by hand to make it neatly. $File.md- BSFL meal increased the abundance of beneficial microorganisms that contribute to the health of the host such as lactic acid[^Huyben_2019][^Terova_2019][^Rimoldi_2019]and butyrate[^Terova_2019].- The anti-inflammatory properties of microbe-derived butyrate in gut and its role in enhancing intestinal barrierfunction and mucosal immunity are well studied in human[^Liu_H_2018].- It is also possible that the short-chain fatty acids including butyrate produced by gut microbiota might induce the expression of host defense peptides and prevent inflammation in the gut as observed in mammals and birds[^Wu_J_2020].---[^Huyben_2019]: Huyben D, Vidaković A, Hallgren SW, Langeland M. High-throughput sequencing of gut microbiota in rainbow trout (Oncorhynchus mykiss) fed larval and pre-pupae stages of black soldier fly (Hermetia illucens). Aquaculture (2019) 500:485–91. doi: 10.1016/j.aquaculture.2018.10.034[^Liu_H_2018]: Liu H, Wang J, He T, Becker S, Zhang G, Li D, et al. Butyrate: a double-edged sword for health? Adv Nutr (2018) 9(1):21–9. doi: 10.1093/advances/nmx009[^Rimoldi_2019]: Rimoldi S, Gini E, Iannini F, Gasco L, Terova G. The effects of dietary insect meal from Hermetia illucens prepupae on autochthonous gut microbiota of rainbow trout (Oncorhynchus mykiss). Animals (2019) 9(4):143. doi: 10.3390/ani9040143[^Terova_2019]: Terova G, Rimoldi S, Ascione C, Gini E, Ceccotti C, Gasco L. Rainbow trout (Oncorhynchus mykiss) gut microbiota is modulated by insect meal from Hermetia illucens prepupae in the diet. Rev Fish Biol Fish (2019) 29:465–86. doi: 10.1007/s11160-019-09558-y","link":"/2021/03/09/Blog/Hexo_batch/"},{"title":"Hexo: Personalize Code Block","text":"Hexo: Personalize Code Block Date: 1 July 2020 Find the source code css for code block is in themes/landscape/source/css/_partial/highlight.styl So, you can personalize your code block by rewrite it. For me, I want to create deepin-terminal style cold block By checking the source code, we can know that the code block is in a &lt;table&gt; So, if I want to add a guider bar as picture above, I need add an element before the tag figure. Here is my example: source $code-block background: rgb(65, 65, 65) margin: 0 article-padding * -1 padding: 15px article-padding border-style: solid border-color: color-border border-width: 1px 0 overflow: auto color: highlight-foreground line-height: font-size * line-height font-family: monospace; font-size: 18px; border-radius: 0px 0px 0px 0px; ummmm… I cant remember exactly what am I done, but I made it… Cheers!!! Mac style Code Block Reference: 马猴小站 I tried to following with this tutorial from the link above and found it didn’t work. So, I gave it up to recording the changes I made. But soon, I found that it works only on the new pages I created. So, I deleted all md posts after bake up and copied them to the source directory. After I ran hexo g, it worked, all pages got new style cold-blocks. But the problem is I totally forgot which changes I made. = = This is the part of change I can remember: CSS file: .highlight-wrap[data-rel] { position: relative; overflow: hidden; border-radius: 5px;/*box-shadow: 0 10px 30px 0px rgba(0, 0, 0, 0.4);*/ -webkit-box-shadow: 18px 18px 15px 0px rgba(0,0,0,0.4); /*Shadow of the code block*/ box-shadow: 5px 5px 15px 0px rgba(0,0,0,0.4); margin: 35px 0; margin-top: 10px; margin-bottom: 25px;}.highlight-wrap[data-rel] ::-webkit-scrollbar { height: 10px;}.highlight-wrap[data-rel] ::-webkit-scrollbar-track { -webkit-box-shadow: inset 0 0 6px rgba(0,0,0,0.3); border-radius: 10px;}.highlight-wrap[data-rel] ::-webkit-scrollbar-thumb { border-radius: 10px; -webkit-box-shadow: inset 0 0 6px rgba(0,0,0,0.5);}.highlight-wrap[data-rel]::before { content: attr(data-rel); height: 38px; line-height: 38px; background: #21252b;/*background: #108414de;*/ color: #fff; font-size: 16px;/*position: absolute;*/ top: 0; left: 0; width: 100%;/*font-family: 'Source Sans Pro', sans-serif;*/ font-weight: bold; padding: 0px 80px; text-indent: 15px; float: left;}.highlight-wrap[data-rel]::after { content: ' '; position: absolute; -webkit-border-radius: 50%; border-radius: 50%; background: #fc625d; width: 12px; height: 12px; top: 0; left: 20px; margin-top: 13px; -webkit-box-shadow: 20px 0px #fdbc40, 40px 0px #35cd4b; -webkit-box-shadow: 20px 0px #fdbc40, 40px 0px #35cd4b; box-shadow: 20px 0px #fdbc40, 40px 0px #35cd4b; z-index: 3;}","link":"/2020/07/01/Blog/Hexo_code/"},{"title":"Hexo: Footnotes","text":"Hexo: Footnotes Reference: 张慕晖 2018 We can using hexo-renderer-markdown-it to achieve this. But before we install it, we need to remove the default widget hexo-renderer-marked. Besides hexo-render-markdwon-it doesn’t have checkbox plugin. So, you’d like to downloads markdown-it-task-checkbox, too. npm un hexo-renderer-marked --savenpm i hexo-renderer-markdown-it --savenpm install markdown-it-task-checkbox --save Codes for _config.yml ## Markdown-it config### Docs: https://github.com/celsomiranda/hexo-renderer-markdown-it/wikimarkdown: # 渲染设置 render: # 置为true时，html内容保持不变；置为false时，html内容将被转义成普通字符串 html: true # 是否生成与XHTML完全兼容的标签（虽然我不懂是什么意思） xhtmlOut: false # 置为true时，每个换行符都被渲染成一个&lt;br&gt;（即Hexo的默认表现）；置为false时，只有空行才会被渲染为&lt;br&gt;（GFM的默认表现） breaks: true # 是否自动识别链接并把它渲染成链接 linkify: true # 是否自动识别印刷格式（意思是把(c)渲染为©这样的） typographer: true # 如果typographer被设置为true，则该选项用于设置将dumb quotes（&quot;&quot;）自动替换为smart quotes quotes: '“”‘’' # 设置所需插件 plugins: - markdown-it-abbr - markdown-it-footnote - markdown-it-ins - markdown-it-sub - markdown-it-sup - markdown-it-task-checkbox # 锚点设置（因为我没有尝试相关内容，所以就不翻译相关说明了） anchors: level: 2 collisionSuffix: 'v' permalink: true permalinkClass: header-anchor permalinkSymbol: ¶ Grammar for Footnotes As you can see[^2], the order of the footnotes is doesn't matter[^1].[^2]: Word: see[^1]: Word: matter Result Before: Now: ( You can see the codes at above) As you can see[1], the order of the footnotes is doesn’t matter[2]. Word: see ↩︎ Word: matter ↩︎","link":"/2020/08/04/Blog/Hexo_footnotes/"},{"title":"Hexo 正文部分的編號消失","text":"Hexo 正文部分列表編號消失 Date: 24 June 2020 在atom本地插件中， 看起來是這樣的， 有序號的話， 看起來比較有條理。 hexo 以後， 就不對勁了， 序號都消失了， 問題是還，到處都找不到攻略， 似乎就我一個人有這樣的問題 查看控制檯，可以發現， 明明是&lt;li&gt;， 但是卻沒有li的圓點標誌，所以肯定是css設置了什麼。最後在themes/landscape/source/css/_partial/archive.styl中找到了: li list-style-type:none; 刪掉以後，才發現 = =這個代碼， 是我自己加的。。。當時做title的時候，發現前面有個小點， 就直接加了個全局 - - 在前面加上 title 的標籤後， 就一切正常了。 唉- -哭了 .title_index li list-style-type:none;","link":"/2020/06/23/Blog/Hexo_list/"},{"title":"Hexo: live2d","text":"Hexo: live2d Project: github EEEEEEYHNModels downloads: github summerscar Install install the widget at the hexo’s directory of your blog npm install --save hexo-helper-live2d Models Make a directory for storing the models at your hexo’s directory mkdir live2d_models## Downloadsgit clone https://github.com/summerscar/live2dDemo## Modelsmv live2dDemo/assets/shizuku live2d_models/ Moving the models you like from live2dDemo/assets/ (from git clone) to live2d_models (in your hexo’s directory) Config Add configuration in hexo’s _config.yml file or theme’s _config.yml. (PS: I tried to add configuration at theme’s _config.yml file first and it didn’t work for me) live2d: enable: true scriptFrom: local pluginRootPath: live2dw/ pluginJsPath: lib/ pluginModelPath: assets/ tagMode: false log: false model: use: shizuku display: position: right #left width: 150 height: 300 mobile: show: true react: opacity: 0.7 Final Result","link":"/2020/07/29/Blog/Hexo_live2d/"},{"title":"Hexo with Github","text":"如何优雅的白嫖博客服务 (hexo + github) Date: 2020/6/14 Main Tutorial Other related resource: pengwenwu/skill-tree 原博客已经写的很清楚了， 这里我简单开始创建文件夹, 然后记录一下我遇到的问题。 Quick to build a hexo folder Before doing that, make sure the version of nodejs: node -v v18.8.0 If the version is below 16, please upgrade it. Brian Boucheron, 2020: Upgrade Node.js wget https://raw.githubusercontent.com/nvm-sh/nvm/v0.38.0/install.shbash install.shsource ~/.bashrcnvm list-remotenvm install v18.8.0 sudo apt install npmhexo init hexocd hexonpm install node#npm install -g hexo-clinpm install npm error npm install -g hexo-cli npm ERR! code EINTEGRITY npm ERR! sha512-XlPzRtnsdrUfTSkLJPACQgWByybB56E79H8xIjGWj0GL+J/VqENsgc+GER0ytFwrP/6YKCerXdaUWOYMcv6aiA== integrity checksum failed when using sha512: wanted sha512-XlPzRtnsdrUfTSkLJPACQgWByybB56E79H8xIjGWj0GL+J/VqENsgc+GER0ytFwrP/6YKCerXdaUWOYMcv6aiA== but got sha512-BdyVintFFu5qQX0AtuwgmXxphBU1V+VL9+8GPemcM9Q86MPG+MCTA26bCyEyzUqDPVBm7xF3gjACaOwMBEmAZQ==. (653 bytes) npm ERR! A complete log of this run can be found in: npm ERR! /home/ken/.npm/_logs/2020-06-14T05_36_46_129Z-debug.log Solution: npm cache verifynpm install -g hexo-cli reference: 天魂_TH 2017 2. npm Download Change the mirror if you in China npm config set registry https://registry.npm.taobao.org reference: 慢读慢写 2018 3. Start the Service: 4. Director Structure .├── 1├── _config.yml├── db.json├── node_modules├── package.json├── package-lock.json├── public├── scaffolds├── source└── themes After you run hexo g, all .md files in source directory would be turned to html files and stored at publish directory which you can upload to GitHub. the home page public/index.html is stored at source/_posts/hello-world.md. 5. Plunges flow and mermaid support reference: 慧行说 2018 npm install --save hexo-filter-flowchartnpm install --save hexo-filter-mermaid-diagramsnpm install --save hexo-filter-sequencenpm install hexo-renderer-pug hexo-renderer-stylus If you have any trouble with mermaid, please went to see: 荒野之萍 2019 RSS feed reference: 試毅_思伟 2019 npm install hexo-generator-feed _config.yml ## Extensionsplugins: hexo-generator-feed##Feed Atomfeed: type: atom path: atom.xml limit: 20 Word count reference: 李瑞豪 2018 npm i --save hexo-wordcount Other tutorials:IT自学不成才 2019 Comments utterances: LitStronger 2020 6. New Category: hexo new page categories A new directory categories would be create in source Customize your theme reference: dxs雪松 2017 ~/hexofolder$ tree -L 1 themes/landscape/ themes/landscape/├── _config.yml├── Gruntfile.js├── languages├── layout├── LICENSE├── package.json├── README.md├── scripts└── source Adding head index reference: 锦瑟华年 2015 Insert the codes below after &lt;%- post.content %&gt; in the file themes/landscape/layout/_partial/article.ejs &lt;!-- Table of Contents --&gt;&lt;% if (!index){ %&gt; &lt;div id=&quot;toc&quot; class=&quot;toc-article&quot;&gt; &lt;strong class=&quot;toc-title&quot;&gt;文章目录&lt;/strong&gt; &lt;%- toc(post.content) %&gt; &lt;/div&gt;&lt;% } %&gt; Adding codes below at themes/landscape/source/css/_partial/article.styl /*toc*/.toc-article z-index:999; background: #eee; border: 1px solid #bbb; border-radius: 10px; margin: 1.5em 0 0.3em 1.5em; padding: 0em 1em 0 1em; max-width: 400px; max-height: 500px; overflow: auto.toc-title font-size: 120%;##toc line-height: 1em; font-size: 0.9em; padding-top: 10px; float: right.toc padding-top: 10px; margin: 1em; line-height: 1.8em;.toc-child margin-left: 1em.title_index li list-style-type:none;##nav display:block; background: salmon; border: 1px solid #bbb; border-radius: 100px; max-width: 100%;##nav li a display:block; max-width: 100%;##nav li ul position: fixed; right: 0; bottom:5%; display:none; width:80%;##nav li:hover ul display:block; final style.css file /* -2.5 Scroll To Up */.back-to-top { position: fixed; bottom: 10px; right: 10px; border-radius:1000px}.back-to-top i { display: block; width: 36px; height: 36px; line-height: 36px; color: #fff; font-size: 14px; text-align: center; border-radius: 30px; background-color: #F97794; -webkit-transition: all 0.3s ease-in-out; -moz-transition: all 0.3s ease-in-out; -o-transition: all 0.3s ease-in-out; transition: all 0.3s ease-in-out;}.title_index { position: fixed; z-index:999; bottom: 40px; right: -9px;}/*toc*/.toc-article { background: #eee; border: 1px solid #bbb; border-radius: 10px; margin: 1.5em 0 0.3em 1.5em; padding: 0em 1em 0 1em; max-width: 400px; max-height: 500px; overflow: auto}.toc-title { font-size: 120%}##toc { padding-top: 10px; line-height: 1em; font-size: 0.9em; float: right}.toc{ padding-top: 10px; margin: 1em; line-height: 1.8em;}.toc-child { margin-left: 1em}.title_index li { list-style-type:none;}##nav { display:block; z-index: 10; background: salmon; border: 1px solid #bbb; border-radius: 100px; max-width: 100%;}##nav li a { display: block; max-width: 100%;}##nav li ul { position: fixed; right: 0; bottom:5%; display:none; width:80%;}##nav li:hover ul { display:block;} 最终效果: http://kuangqi.me/tricks/enable-table-of-contents-on-hexo/ Uploaded the Wrong Director I am working on the directory: “NoteBK” and usually, it would upload the “.deploy” or “publish” directory only. But somehow, it uploaded the “NoteBK” directory instead. I think it misunderstood the config file. During the first time of hexo deploy, you’ll get an error code that tells you to run git config --global --add safe.directory .../NoteBK/.deploy_git first. If you didn’t include the .deploy_git at the end, it would set your NoteBK as the default directory and upload them all. In this case, your GitHub Pages would fail to generate. So, you need to make sure to configure git correctly. Upload need the password even you added your ssh key In the config file (_config.yml), you need to change the git into ssh deploy: Username: Karobben type: git- repo: https://github.com/Karobben/Karobben.github.io.git + repo: git@github.com:Karobben/Karobben.github.io.git branch: master","link":"/2020/06/13/Blog/Hexo_gitpage/"},{"title":"Hexo: Math Function","text":"Hexo: Make a Post For the theme NexT user Scripts and engines are embedded already. You can enable it by altering the parameters at _config.yml by following the instructor post by 醉渔 2019 Insert the script reference: Guohua Wu 2013[1] Insert the codes below at themes/landscape/layout/_partial/head.ejs in your hexo directory. (At here, my theme is “landscape”) &lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&gt;&lt;/script&gt; According from the original post[1:1], we are supposed to make some modifications on a few other files. But I just found it is fine without a further alteration. So, I stopped at this steps. If you can have a visitation on the post if you want to check out by yourselves. $$ P(t)= \\frac{KP_{0}e^{rt}}{K + P_0(e^{rt} - 1)} $$ Guohua Wu; hexo数学公式; Gitpage; 2013; link ↩︎ ↩︎","link":"/2020/06/29/Blog/Hexo_math/"},{"title":"Hexo: Make a Post","text":"Hexo: Make a Post Date: 30 June 2020 hexo new page post It will make source/post and source/post/index.md hexo new test source/_posts/test.md is build Customize Front-matter Format Front-matter is the head in your post title: {{ title }}date: {{ date }}toc: truedescription:url:excerpt:tags:category:cover:thumbnail:priority: 10000covercopy: '© Karobben' We can alter the default value of it by recording it in {Hexo}/scaffolds/post.md [1] luckyforefforts; 2020; CSDN; hexo博客front-matter格式; ↩︎","link":"/2020/06/29/Blog/Hexo_post/"},{"title":"Graphviz","text":"Graphviz 1 Quick Start digraph F { rankdir = LR; edge [style=solid]; node [style=filled, font=Courier]; subgraph M { rank = same; Start [label = &quot;Lamp doesn't work&quot;, shape = box, fillcolor = &quot;#FF0000&quot; ]; End [label = &quot;Repair lamp&quot; , shape = box, color = coral]; Con1 [label = &quot;Lamp plugged in?&quot;, shape = diamond, color = green, size = 3]; Con2 [label = &quot;Bulb burned out?&quot;, shape = diamond, color = green, size = 3]; } subgraph C { rank = same; RB [label = &quot;Replace bulb&quot;, shape = box, color = deepskyblue1]; AP [label = &quot;Plug in lamp&quot;, shape = box, color = deepskyblue1]; } Start -&gt; Con1; Con1 -&gt; AP [label = &quot;No&quot;]; Con1 -&gt; Con2 [label = &quot;Yes&quot;]; Con2 -&gt; RB [label = &quot;Yes&quot;]; Con2 -&gt; End [label = &quot;No&quot;]; AP -&gt; End RB -&gt; End} ``$`graphvizdigraph F { rankdir = LR; &quot;node1&quot; [ label = &quot;{&lt;f1&gt; ADP |&lt;f2&gt; Pi }&quot; shape = &quot;record&quot; ]; &quot;node2&quot; [ label = &quot;&lt;f0&gt; ATP| &lt;f1&gt; Ca&quot; shape = &quot;record&quot; ]; node2:f0 -&gt; node1:f1}``$` remove the “$” from code above More exemples: http://graphviz.org/gallery/ 2 Parameters 2.1 Structure Source:https://graphviz.gitlab.io/_pages/doc/info/lang.html graph : [ strict ] (graph | digraph) [ ID ] '{' stmt_list '}'stmt_list : [ stmt [ ';' ] stmt_list ]stmt : node_stmt| edge_stmt| attr_stmt| ID '=' ID| subgraphattr_stmt : (graph | node | edge) attr_listattr_list : '[' [ a_list ] ']' [ attr_list ]a_list : ID '=' ID [ (';' | ',') ] [ a_list ]edge_stmt : (node_id | subgraph) edgeRHS [ attr_list ]edgeRHS : edgeop (node_id | subgraph) [ edgeRHS ]node_stmt : node_id [ attr_list ]node_id : ID [ port ]port : ':' ID [ ':' compass_pt ]| ':' compass_ptsubgraph : [ subgraph [ ID ] ] '{' stmt_list '}'compass_pt : (n | ne | e | se | s | sw | w | nw | c | _) A -&gt; {B C}is equivalent toA -&gt; BA -&gt; C color for edge Official Documentation Source: http://graphviz.org/documentation/ Nodes,edges … Souce: https://graphviz.gitlab.io/_pages/doc/info/attrs.html Node shapes Source: https://graphviz.gitlab.io/_pages/doc/info/shapes.html Edge shapes digraph F { rankdir =&quot;LR&quot; A -&gt; B [arrowhead = &quot;box&quot;, color=&quot;green&quot;] A -&gt; C [arrowhead = &quot;crow&quot;, style = &quot;dotted&quot;] A -&gt; D [arrowhead = &quot;dot&quot;, weight = 10] A -&gt; E [arrowhead = &quot;diamond&quot;, headport=&quot;s&quot;] A -&gt; F [arrowhead = &quot;none&quot;] A -&gt; G [arrowhead = &quot;icurve&quot;] subgraph cluster_0{ B C D style=filled; color=lightgrey; node [style=filled,color=white]; label = &quot;process #1&quot;; }} Source: https://graphviz.gitlab.io/_pages/doc/info/arrows.html Color Source: https://graphviz.gitlab.io/_pages/doc/info/colors.html Edge headport / tailport A -&gt; n [headport = &quot;n&quot;] headport = “n”,“ne”,“e”,“se”,“s”,“sw”,“w”,“nw”,“c”,“_”. Style A -&gt; dashed [ style = &quot;dashed&quot;] style = “dashed”, “dotted”, “solid”, “invis”, “bold”, “tapered” Multi-color a -&gt; b [dir=both color=&quot;red:blue&quot;] c -&gt; d [dir=none color=&quot;green:red;0.25:blue&quot;] Cluster style=filled;color=lightgrey;node [style=filled,color=white];label = &quot;This is a cluster&quot;; Model For more please visit: 使用graphviz绘制流程图（2015版）http://icodeit.org/2015/11/using-graphviz-drawing/ digraph F { rankdir = LR; \"node1\" [ label = \"{ ADP | Pi}\" shape = \"record\" ]; \"node2\" [ label = \" ATP| Ca\" shape = \"record\" ]; node2:f0 -> node1:f1 } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });digraph F { rankdir =\"LR\" A -> B [arrowhead = \"box\", color=\"green\"] A -> C [arrowhead = \"crow\", style = \"dotted\"] A -> D [arrowhead = \"dot\", weight = 10] A -> E [arrowhead = \"diamond\", headport=\"s\"] A -> F [arrowhead = \"none\"] A -> G [arrowhead = \"icurve\"] subgraph cluster_0{ B C D A style=filled; color=lightgrey; node [style=filled,color=white]; label = \"process #1\"; } } var viz = new Viz(); var code = document.getElementById(\"graphviz-1-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-1\").append(element) });digraph{ A -> B [headport = \"\"] A -> n [headport = \"n\"] A -> ne [headport = \"ne\"] A -> e [headport = \"e\"] A -> se [headport = \"se\"] A -> s [headport = \"s\"] e -> C C -> sw [headport = \"sw\"] C -> w [headport = \"w\"] C -> nw [headport = \"nw\"] C -> c [headport = \"c\"] C -> _ [headport = \"_\"] C -> D [headport = \"\", weight=2] } var viz = new Viz(); var code = document.getElementById(\"graphviz-2-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-2\").append(element) });digraph{ subgraph A{ rank = same A B } A -> dashed [ style = \"dashed\"] A -> dotted [ style = \"dotted\"] A -> solid [ style = \"solid\"] B -> invis [ style = \"invis\"] B -> bold [ style = \"bold\"] B -> tapered [ style = \"tapered\"] } var viz = new Viz(); var code = document.getElementById(\"graphviz-3-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-3\").append(element) });digraph G { a -> b [dir=both color=\"red:blue\"] c -> d [dir=none color=\"green:red;0.25:blue\"] } var viz = new Viz(); var code = document.getElementById(\"graphviz-4-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-4\").append(element) });digraph{ subgraph cluster_0{ B C D A style=filled; color=lightgrey; node [style=filled,color=white]; label = \"This is a cluster\"; } } var viz = new Viz(); var code = document.getElementById(\"graphviz-5-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-5\").append(element) });digraph{ subgraph cluster_0{ A area = 1 label = \"color = red\\nfontcolor = blue\"; fontcolor = \"blue\"; color = \"red\" } subgraph cluster_1{ B bgcolor = red label = \"bgcolor = red;\\n fontname = SimHei\\n fontsize = 20\"; fontname = \"SimHei\" fontsize = 20 } subgraph cluster_2{ C fillcolor = \"blue:red\" style=filled gradientangle = 45 label = \"style=filled;\\nfillcolor = blue:red;\\ngradientangle = 45\"; } } var viz = new Viz(); var code = document.getElementById(\"graphviz-6-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-6\").append(element) });digraph{ subgraph cluster_0{ A -> AAAAAA label = \"labeljust=r\\n labelloc=c\"; labeljust=r margin = 2 } subgraph cluster_1{ B -> BBBBBB label = \"labeljust=l\\n labelloc=b\"; labeljust=l labelloc=b } } var viz = new Viz(); var code = document.getElementById(\"graphviz-7-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-7\").append(element) });digraph{ A -> B -> C -> D -> E -> F -> A model=\"circuit\" } var viz = new Viz(); var code = document.getElementById(\"graphviz-8-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-8\").append(element) });digraph{ model=\"subset\" A -> B -> C -> D -> E -> F -> A } var viz = new Viz(); var code = document.getElementById(\"graphviz-9-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-9\").append(element) });digraph G { layout=neato size=\"7,10\" page=\"8.5,11\" center=\"\" node[width=.25,height=.375,fontsize=9] fcfpr1_1_2t_17 -> 341411; fcfpr1_1t_1 -> 341411; rdlfpr2_0_rdlt_4 -> 341411; fpfpr1_0_1t_1 -> 341411; fpfpr1_1_2t_11 -> 341411; rtafpr1_1_2t_28 -> 341411; rtafpr1_1_3t_6 -> 341411; rdlfpr1_1t_1 -> 358866; rtafpr1_1_3t_6 -> 358866; tmfpr1_1_3t_5 -> 358930; fcfpr1_1_3t_9 -> 358930; pcfpr1_1_3t_7 -> 358930; fpfpr1_1_3g_1 -> 358930; fpfpr1_1_3t_1 -> 358930; aufpr1_1_3t_1 -> 358930; rtafpr1_0_3g_1 -> 358930; rtafpr1_1_3t_6 -> 358930; msgfpr1_1_1g_12 -> 371943; rtafpr1_1_1g_8 -> 371943; rtafpr1_1_1t_35 -> 371943; rtafpr1_1_1t_45 -> 371943; rtafpr1_1_3t_6 -> 371943; tlfpr2_0_rdlg_2 -> 374300; fcfpr1_1_3t_8 -> 374300; fcfpr1_1_3t_9 -> 374300; rtafpr1_1_3t_6 -> 374300; fcfpr1_0_5g_1 -> 371942; fcfpr1_1_1t_19 -> 371942; fcfpr1_1_3t_9 -> 371942; fcfpr1_1_3t_9 -> 374700; tymsgfpr1_1_3t_3 -> 374700; fpfpr1_1_3t_1 -> 374700; rtafpr1_1_3t_7 -> 374700; fcfpr1_1_3g_2 -> 374741; fcfpr1_1_3t_9 -> 374741; fpfpr1_1_3t_1 -> 374741; rtafpr1_1_3t_7 -> 374741; fcfpr1_1_1t_18 -> 374886; fcfpr1_1_3t_9 -> 374886; fpfpr1_1_3t_1 -> 374886; rtafpr1_1_3t_7 -> 374886; fcfpr1_1_3t_9 -> 375039; fpfpr1_1_3t_1 -> 375039; fcfpr1_1_3t_42 -> 375507; fcfpr1_1_3t_9 -> 375507; rdlfpr2_0_rdlt_158 -> 375507; rtafpr1_1_3t_7 -> 375507; rtafpr1_1_3t_71 -> 375507; dbfpr1_1_3t_2 -> 375507; fcfpr1_1_3t_9 -> 375508; rdlfpr1_1g_13 -> 375508; rtafpr1_1_3t_7 -> 375508; rtafpr2_1_rdlg_1 -> 375508; dbfpr1_1_3t_2 -> 375508; fcfpr1_1_3t_9 -> 375519; fpfpr1_1_3g_1 -> 375519; fpfpr1_1_3t_1 -> 375519; fcfpr1_1_3t_9 -> 377380; rdlfpr1_1g_16 -> 377380; rdlfpr1_1t_100 -> 377380; fcfpr1_0_2g_1 -> 377719; fcfpr1_1_3t_10 -> 377719; fcfpr1_1_3t_7 -> 377719; fcfpr1_1_3t_9 -> 377719; rdlfpr2_0_rdlg_12 -> 377719; rdlfpr2_0_rdlt_108 -> 377719; rdlfpr2_0_rdlt_27 -> 377719; rdlfpr2_0_rdlt_30 -> 377719; fcfpr1_1_3t_9 -> 377763; fcfpr1_1_3t_9 -> 379848; fpfpr1_1_3t_1 -> 379848; fcfpr1_1_3t_9 -> 380571; fcfpr1_1_3t_9 -> 380604; fpfpr1_1_3t_1 -> 380604; fcfpr1_1_3t_9 -> 381211; fpfpr1_1_3t_1 -> 381211; fcfpr1_1_3t_9 -> 381835; fcfpr1_1_3t_9 -> 381897; fcfpr1_1_3t_9 -> 381901; fpfpr1_1_3t_1 -> 381901; fcfpr1_1_3t_9 -> 382103; rtafpr1_1_3t_7 -> 382103; fcfpr1_1_3t_9 -> 382161; fcfpr1_1_3t_9 -> 383174; fpfpr1_1_3t_1 -> 383174; rtafpr1_1_3t_7 -> 383174; fpfpr1_1_3g_1 -> 352010; fpfpr1_1_3t_1 -> 352010; fpfpr1_1_3t_1 -> 382409; fpfpr1_1_3t_1 -> 382827; fpfpr1_1_3t_1 -> 382928; rtafpr1_1_3t_7 -> 382928; tlfpr1_1_1t_5 -> 358224; tymsgfpr1_1_1t_23 -> 358224; tymsgfpr1_1_3t_3 -> 358224; rcfpr0_0_1t_9 -> 358224; rcfpr1_1_1t_5 -> 358224; odfpr0_0_1t_8 -> 358224; odfpr1_1_1t_6 -> 358224; ecdsgfpr1_1_1t_4 -> 358224; tymsgfpr1_1_1t_18 -> 358900; tymsgfpr1_1_3t_3 -> 358900; rcfpr1_1_1t_100 -> 358900; rcfpr1_1_1t_22 -> 358900; rcfpr1_1_1t_37 -> 358900; odfpr1_1_1t_21 -> 358900; tymsgfpr1_1_3t_3 -> 372568; rcfpr1_1_1t_30 -> 372568; odfpr1_1_1t_31 -> 372568; tlfpr1_1_1t_20 -> 375557; tymsgfpr1_1_1t_24 -> 375557; tymsgfpr1_1_3t_3 -> 375557; rcfpr1_1_1t_11 -> 375557; odfpr1_1_1t_9 -> 375557; ecdsgfpr1_1_1t_19 -> 375557; rtafpr1_1_1g_14 -> 376956; rtafpr1_1_1t_64 -> 376956; rtafpr1_1_2t_18 -> 376956; rtafpr1_1_3t_30 -> 376956; rtafpr1_1_3t_7 -> 376956; rtafpr1_1_3t_7 -> 379339; rtafpr1_1_1t_14 -> 379422; rtafpr1_1_1t_20 -> 379422; rtafpr1_1_3t_7 -> 379422; rtafpr1_1_3t_7 -> 383039; fcfpr1_1_1t_18 -> 359471; fcfpr2_0_1t_1 -> 359471; fcfpr2_0_1t_2 -> 359471; ccsfpr2_0_1t_99 -> 359471; fcfpr1_1_3t_42 -> 384096; rtafpr1_1_3t_71 -> 384096; tlfpr1_0_4g_4 -> 354290; rcfpr0_0_1t_9 -> 354290; odfpr0_0_1t_8 -> 354290; pagfpr1_1_1t_23 -> 354290; rcfpr1_1_1t_5 -> 379864; rcfpr1_1_1t_100 -> 382574; rcfpr1_1_1t_22 -> 382574; rcfpr1_1_1t_37 -> 382574; rcfpr1_1_1t_30 -> 370706; rcfpr1_1_1t_30 -> 377908; rcfpr1_1_1t_30 -> 377924; rcfpr1_1_1t_30 -> 377971; rcfpr1_1_1t_30 -> 377980; odfpr1_1_1t_31 -> 377980; rcfpr1_1_1t_30 -> 378362; rcfpr1_1_1t_30 -> 378656; rcfpr1_1_1t_30 -> 378666; rcfpr1_1_1t_30 -> 379169; odfpr1_1_1t_31 -> 379169; rcfpr1_1_1t_110 -> 379341; rcfpr1_1_1t_30 -> 379341; rcfpr1_1_1t_62 -> 379341; odfpr1_1_1t_31 -> 379341; rcfpr1_1_1t_30 -> 379972; rcfpr1_1_1t_30 -> 380298; rcfpr1_1_1t_30 -> 380448; rcfpr1_1_1t_30 -> 380475; odfpr1_1_1t_31 -> 380475; rcfpr1_1_1t_30 -> 380526; odfpr1_1_1t_31 -> 357430; rcfpr1_1_1t_11 -> 379968; odfpr1_1_1t_9 -> 379968; ccsfpr2_0_1t_99 -> 359100; ccsfpr2_0_1t_99 -> 376529; ccsfpr2_0_1t_99 -> 377801; ccsfpr2_0_1t_99 -> 379126; ccsfpr2_0_1t_99 -> 379212; ccsfpr2_0_1t_99 -> 380285; ccsfpr2_0_1t_99 -> 380963; ccsfpr2_0_1t_99 -> 384909; tlfpr1_0_4g_4 -> 358471; odfpr0_0_1t_7 -> 358471; odfpr1_0_1t_36 -> 358471; odfpr1_0_3t_18 -> 358471; odfpr1_0_3t_21 -> 358471; tlfpr1_0_4g_4 -> 375024; tlfpr1_0_4g_4 -> 375027; rcfpr1_1_1t_110 -> 381710; rcfpr1_1_1t_62 -> 381710; rcfpr1_1_1t_110 -> 381775; rcfpr1_1_1t_62 -> 381775; rcfpr1_1_1t_110 -> 382436; fcfpr1_1_3t_34 -> 382528; rcfpr1_1_1t_110 -> 382528; rtafpr1_1_3t_48 -> 382528; rcfpr1_1_1t_110 -> 382566; rcfpr1_1_1t_110 -> 382572; odfpr0_0_1t_7 -> 353506; rcfpr1_0_1t_35 -> 370509; odfpr0_0_1t_7 -> 370509; odfpr0_0_1t_7 -> 370510; odfpr1_0_1t_38 -> 370510; tlfpr1_0_4g_5 -> 354546; rcfpr1_1_1t_61 -> 354546; odfpr1_0_3t_18 -> 354546; odfpr1_0_3t_20 -> 354546; odfpr1_0_3t_18 -> 354757; odfpr1_0_3t_20 -> 354757; odfpr1_0_3t_18 -> 354766; odfpr1_0_3t_20 -> 354766; odfpr1_0_3t_18 -> 354771; odfpr1_0_3t_20 -> 354771; odfpr1_0_3t_18 -> 354785; odfpr1_0_3t_23 -> 354785; odfpr1_0_3t_24 -> 354785; odfpr1_0_3t_18 -> 354878; odfpr1_0_3t_23 -> 354878; odfpr1_0_3t_24 -> 354878; odfpr1_0_3t_18 -> 355080; odfpr1_0_3t_23 -> 355080; odfpr1_0_3t_24 -> 355080; odfpr1_0_3t_18 -> 355288; odfpr1_0_3t_23 -> 355288; odfpr1_0_3t_24 -> 355288; odfpr2_0_03t_13 -> 355288; odfpr1_0_3t_18 -> 355800; odfpr1_0_3t_21 -> 355800; odfpr1_0_3t_18 -> 356116; odfpr1_0_3t_21 -> 356116; odfpr1_0_3t_18 -> 356741; odfpr1_0_3t_21 -> 356741; odfpr1_0_3t_18 -> 357340; odfpr1_0_3t_21 -> 357340; odfpr1_0_3t_18 -> 357538; odfpr1_0_3t_21 -> 357538; odfpr1_0_3t_18 -> 357769; odfpr1_0_3t_21 -> 357769; odfpr1_0_3t_18 -> 357793; odfpr1_0_3t_21 -> 357793; odfpr1_0_3t_18 -> 358155; odfpr1_0_3t_21 -> 358155; odfpr1_0_3t_18 -> 358157; odfpr1_0_3t_21 -> 358157; odfpr1_0_3t_18 -> 358159; odfpr1_0_3t_21 -> 358159; odfpr1_0_3t_18 -> 358584; odfpr1_0_3t_21 -> 358584; odfpr1_0_3t_18 -> 360104; odfpr1_0_3t_21 -> 360104; odfpr1_0_3t_18 -> 360144; odfpr1_0_3t_21 -> 360144; odfpr1_0_3t_18 -> 360672; odfpr1_0_3t_21 -> 360672; odfpr1_0_3t_5 -> 360672; odfpr1_0_3t_18 -> 360839; odfpr1_0_3t_21 -> 360839; odfpr1_0_3t_18 -> 371187; tlfpr1_0_3g_5 -> 373300; odfpr1_0_3t_12 -> 373300; odfpr1_0_3t_18 -> 373300; odfpr1_0_3t_18 -> 375134; odfpr1_0_5t_18 -> 375134; rcfpr0_0_1t_10 -> 375319; odfpr1_0_3t_18 -> 375319; odfpr1_0_3t_36 -> 375319; odfpr1_0_5t_17 -> 375319; odfpr1_0_5t_19 -> 375319; odfpr1_0_3t_18 -> 375499; odfpr1_0_3t_18 -> 377220; odfpr1_0_5t_21 -> 377220; tlfpr1_0_3g_7 -> 377562; tlfpr1_1_1t_3 -> 377562; odfpr1_0_3t_18 -> 377562; odfpr1_0_3t_36 -> 377562; odfpr1_0_5t_20 -> 377562; odfpr1_0_3t_18 -> 378108; odfpr1_0_3t_6 -> 378108; odfpr1_0_5t_20 -> 354221; odfpr0_0_1t_7 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; tlfpr1_0_3g_5 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; odfpr0_0_1t_8 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rcfpr1_1_1t_61 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; fcfpr1_1t_1 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; odfpr1_0_3t_18 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; tlfpr1_0_3g_7 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rcfpr1_1_1t_62 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; ccsfpr2_0_1t_99 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; tymsgfpr1_1_3t_3 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rcfpr0_0_1t_9 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rtafpr1_1_1t_14 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rtafpr1_1_3t_30 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rcfpr1_1_1t_110 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; dbfpr1_1_3t_2 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rtafpr1_1_1g_8 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rcfpr1_1_1t_30 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; tlfpr1_1_1t_20 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rtafpr1_1_1t_64 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; tlfpr2_0_rdlg_2 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rtafpr1_1_2t_28 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; tlfpr1_1_1t_3 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; odfpr1_1_1t_6 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; fpfpr1_1_3t_1 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; aufpr1_1_3t_1 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; fcfpr1_1_3t_34 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rcfpr1_1_1t_5 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; fcfpr1_1_1t_18 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; odfpr1_0_3t_36 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; tlfpr1_1_1t_5 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; fcfpr1_1_1t_19 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; odfpr1_1_1t_9 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; fcfpr1_1_3t_7 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rcfpr1_1_1t_37 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; fcfpr1_1_3t_8 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; odfpr1_1_1t_21 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; fcfpr1_1_3t_9 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rdlfpr2_0_rdlt_27 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; fcfpr1_1_3g_2 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rtafpr1_1_1t_35 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; odfpr1_0_5t_20 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; fpfpr1_1_3g_1 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; odfpr1_0_5t_21 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; fpfpr1_1_2t_11 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; ecdsgfpr1_1_1t_19 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; odfpr1_0_1t_36 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rtafpr1_1_1g_14 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; tymsgfpr1_1_1t_23 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; tymsgfpr1_1_1t_24 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; odfpr1_0_1t_38 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; fcfpr1_0_2g_1 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rdlfpr1_1t_1 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rcfpr0_0_1t_10 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rcfpr1_1_1t_100 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rdlfpr2_0_rdlt_108 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; pcfpr1_1_3t_7 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; odfpr1_0_3t_20 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; ecdsgfpr1_1_1t_4 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; tmfpr1_1_3t_5 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; odfpr1_0_3t_21 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; fpfpr1_0_1t_1 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; odfpr1_0_3t_23 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rcfpr1_1_1t_22 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; pagfpr1_1_1t_23 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rtafpr1_1_3t_71 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rtafpr1_1_2t_18 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rdlfpr2_0_rdlt_158 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rtafpr1_1_3t_6 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; odfpr1_0_3t_24 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rtafpr1_1_3t_7 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rtafpr1_0_3g_1 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rtafpr1_1_1t_20 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rdlfpr1_1g_13 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rcfpr1_0_1t_35 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; fcfpr1_1_2t_17 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rtafpr2_1_rdlg_1 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rdlfpr2_0_rdlt_4 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rdlfpr1_1g_16 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; fcfpr2_0_1t_1 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; fcfpr2_0_1t_2 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rdlfpr1_1t_100 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; msgfpr1_1_1g_12 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rdlfpr2_0_rdlt_30 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; odfpr1_0_3t_5 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; tlfpr1_0_4g_4 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; fcfpr1_1_3t_42 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; odfpr1_0_3t_6 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; tlfpr1_0_4g_5 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rtafpr1_1_3t_48 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; odfpr1_0_5t_17 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; odfpr1_0_5t_18 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; tymsgfpr1_1_1t_18 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; odfpr1_0_5t_19 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; fcfpr1_1_3t_10 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; fcfpr1_0_5g_1 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; odfpr1_0_3t_12 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; odfpr2_0_03t_13 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rcfpr1_1_1t_11 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; odfpr1_1_1t_31 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rdlfpr2_0_rdlg_12 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; rtafpr1_1_1t_45 [label=\"\",shape=circle,height=0.12,width=0.12,fontsize=1]; } var viz = new Viz(); var code = document.getElementById(\"graphviz-10-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-10\").append(element) });","link":"/2020/06/26/Blog/Graphviz/"},{"title":"Hexo Weather Widget","text":"1min Hexo 博客添加天氣插件 Date: 20 June 2020 Reference: cungudafa 代碼獲取 進入中國天氣官網，免費登錄後就可以直接獲取代碼,(可用微信，QQ等三方登錄): https://cj.weather.com.cn/plugin/pc 頁面如下，支持半個性化定製: 代碼插入 我的是默認landscape主題，我選擇自己寫個小文件，然後導入。 複製代碼後， 寫入了 themes/landscape/layout/_partial/Weather.ejs文件。之後在themes/landscape/layout/layout.ejs文件中，插入位置如下。 &lt;% if (theme.sidebar &amp;&amp; theme.sidebar !== 'bottom'){ %&gt; &lt;%- partial('_partial/sidebar', null, {cache: !config.relative_link}) %&gt; &lt;!-- Weather Plug--&gt; &lt;%- partial('_partial/Weather', null, {cache: !config.relative_link}) %&gt;&lt;% } %&gt; 小調一下位置， 最終顯示結果：","link":"/2020/06/19/Blog/Hexo_widget_weather/"},{"title":"Hexo: local search","text":"Local search for hexo blog hexo 配置本地搜索 注意: Main Tutorial: 梦中程序员 進入博客根目錄， 然後下載插件 npm isntall hexo-generator-search --save 下載配置文件 git clone https://gitee.com/sjclub/hexo-search-plugin.git 部署配置文件複製js腳本到主題的source/js/目錄下 cp hexo-search-plugin/plugin/*.js themes/landscape/source/js/ 並添加入配置中。 我的例子：編輯 themes/landscape/layout/_partial/after-footer.ejs 在最後行加入 &lt;!-- Searche Module--&gt;&lt;script src=&quot;&lt;%- config.root %&gt;js/search.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;&lt;%- config.root %&gt;js/load.js&quot;&gt;&lt;/script&gt; 把search.styl放到主题下的source文件夹下的css目录下 cp hexo-search-plugin/plugin/search.styl themes/landscape/source/css 插入styl在themes/landscape/layout/_partial/head.ejs文件的 &lt;%- css('css/style') %&gt;後面， 加上 &lt;%- css('css/search') %&gt; 插入search.ejs 這樣就就能看見了 最後配置 config 6.1 更目錄 _config.yml search: path: search.xml field: post content: true 6.2 主題下的 _config.yml local_search: enable: true #搜索开关 location: &quot;right: 50px;top: 30px;&quot; #搜索框位置top/left/bottom/right facade: &quot;&quot; #搜索框样式 hexo g 就可以了看見了 public 下多了一個 search.xml。 這個就是搜索的文件了。不過，我在 hexo s -g的狀態下， 搜索是無效的。上傳了以後， 反而可以了。 23333 上一張效果圖, 搜個函數試試～ 最后 直接使用的話，移動版網頁是無法使用這個功能的。 猜測應該是， 作者認爲在手小屏幕的情況下彈出這個框太醜了， 所以就關掉了。如果想要打開這個功能， 只需要在 load.js中的21行，if ($('.local-search').size() &amp;&amp; !isMobile.any()) { 把&amp;&amp; !isMobile.any()刪除， 手機端就也能正常使用了！","link":"/2020/06/22/Blog/Hexo_search/"},{"title":"在博客下面添加评论区gittack","text":"在博客下面添加评论区gittack 主流程： https://www.jianshu.com/p/4242bb065550 如何注册一个Github Application：https://blog.csdn.net/xingkaifan/article/details/81105352 代码配置：https://blog.csdn.net/Madridcrls7/article/details/80871596 &lt;!-- Link Gitalk 的支持文件 --&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;https://unpkg.com/gitalk/dist/gitalk.css&quot;&gt;&lt;script src=&quot;https://unpkg.com/gitalk@latest/dist/gitalk.min.js&quot;&gt;&lt;/script&gt;&lt;div id=&quot;gitalk-container&quot;&gt;&lt;/div&gt; &lt;script type=&quot;text/javascript&quot;&gt; var gitalk = new Gitalk({ // gitalk的主要参数 clientID: '复制刚才生成的clientID', clientSecret: '复制刚才生成的clientSecret', repo: '用于存放的仓库', owner: 'GitHub的用户名', admin: ['Github的用户名'], id:window.location.pathname, }); gitalk.render('gitalk-container');&lt;/script&gt;&lt;!-- Gitalk end --&gt; 配置成功后， 会显示 这时候只要登录，留下评论，就可以初始化了～！！ Enjoy!~ st=>start: 登录GitHub op1=>operation: 新建一个Repository op2=>operation: 打开主页设置 op3=>operation: 选择开发者设置 op4=>operation: 创建OAuth app op5=>operation: 添加代码 op5=>operation: 初始化评论 e=>end: 完成!! Enjoy！ st->op1(right); op1->op2 op2(right)->op3 op3->op4 op4(right)->op5 op5->e{\"theme\":\"simple\",\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"flowchart-0-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"flowchart-0-options\").value)); var diagram = flowchart.parse(code); diagram.drawSVG(\"flowchart-0\", options);","link":"/2020/06/26/Blog/Html_gittalk/"},{"title":"Kivy, Input Methods","text":"Kivy, Input Methods Thank for the help of 毛毛虫 from a Kivy QQ Group Add the codes below at the begin of your main.py from kivy.uix.dropdown import DropDownfrom kivy.core.window import WindowBasefrom kivy.core.text import LabelBase, DEFAULT_FONTfrom kivy.resources import resource_add_path## Custmer Functions### Crawler for DBresource_add_path(&quot;./font&quot;)LabelBase.register(DEFAULT_FONT, 'FZYanZQKSJF.ttf')WindowBase.softinput_mode = &quot;below_target&quot; And for doing so, make sure you are not using Gboard! not using Gboard! not using Gboard!","link":"/2020/10/31/Blog/Kivy_chinese/"},{"title":"Kivy, Examples of Action bar","text":"Kivy Action bar Origin from: ikolim 2019 main.py from kivy.app import Appfrom kivy.uix.boxlayout import BoxLayoutfrom kivy.uix.screenmanager import ScreenManager, Screenfrom kivy.lang import Builderclass WelcomeScreen(Screen): passclass FirstScreen(Screen): passclass SecondScreen(Screen): passclass ScreenManager(ScreenManager): passclass CrimePrevention(BoxLayout): passBuilder.load_file(&quot;main.kv&quot;)class TestApp(App): title = 'Kivy ScreenManager &amp; ActionBar Demo' def build(self): return CrimePrevention()if __name__ == '__main__': TestApp().run() main.kv ##:kivy 1.11.0##:import sp kivy.metrics.sp##:import dp kivy.metrics.dp&lt;CrimePrevention&gt;: orientation: 'vertical' canvas.before: Color: rgb: .6, .6, .6 Rectangle: pos: self.pos size: self.size # source: 'data/background.png' SomeMenu_ActionBar: id: ActionBar ScreenManager: id: sm WelcomeScreen: FirstScreen: SecondScreen:&lt;SomeMenu_ActionBar@ActionBar&gt;: ActionView: id: ActionView HiddenIcon_ActionPrevious: ActionGroup: id: App_ActionGroup mode: 'spinner' text: 'Jump to Screen' ActionButton: text: 'Crime Prediction' on_release: app.root.ids.sm.current = 'second' ActionButton: text: 'Forum' on_release: app.root.ids.sm.current = 'second' ActionButton: text: 'Probable Suspect' on_release: app.root.ids.sm.current = 'second' ActionGroup: id: App_ActionGroup mode: 'spinner' text: 'App' ActionButton: text: 'Settings' on_press: app.open_settings() ActionButton: text: 'Quit' on_press: app.get_running_app().stop() ActionGroup: id: File_ActionGroup mode: 'spinner' text: 'File' ActionButton: text: 'Open' ActionButton: text: 'Save'&lt;HiddenIcon_ActionPrevious@ActionPrevious&gt;: title: '' # app.title if app.title is not None else 'Action Previous' with_previous: False app_icon: '' app_icon_width: 0 app_icon_height: 0 size_hint_x: None width: len(self.title) * 10&lt;WelcomeScreen&gt;: name: 'welcome' Label: text: 'Welcome Screen' font_size: sp(50)&lt;FirstScreen&gt;: name: 'first' Label: text: 'First Screen'&lt;SecondScreen&gt;: name: 'second' BoxLayout: orientation: 'vertical' Label: text: 'Predict Crime' font_size: 50 BoxLayout: Button: text: 'Back to Main Menu' font_size: 30 on_release: app.root.ids.sm.current = 'first' Button: text: 'get random colour screen' font_size: 30 on_release: app.root.ids.sm.current = 'first'","link":"/2020/10/28/Blog/Kivy_actionbar/"},{"title":"Kivy, Examples in Github","text":"Kivy, Examples of News Feed Denkneb/kivy_news Repository git clone https://github.com/Denkneb/kivy_news.gitcd kivy_newspython3 main.py Instead of grasp news from webs, it’ll pop up in your web-browser… So, I’d like to skip from this codes. Dashboard JanezSedeljsak","link":"/2020/10/25/Blog/Kivy_newfeed/"},{"title":"Html 杂记","text":"1. 文字 &lt;!-- 颜色 --&gt;&lt;p style=&quot;color:black;&quot;&gt;文字&lt;/p&gt;&lt;!-- 大小 --&gt;&lt;p style=&quot;font-size:100px;&quot;&gt;文字&lt;/p&gt;&lt;!-- 加粗 400: normal, 700:bold--&gt;&lt;p style=&quot;font-weight:700;&quot;&gt;文字&lt;/p&gt;&lt;!-- 行间距 --&gt;&lt;p style=&quot;line-height:20px;&quot;&gt;文字&lt;/p&gt;&lt;!-- 换行 --&gt;&lt;br&gt;&lt;!-- 加粗 --&gt;&lt;strong&gt;&lt;/strong&gt;&lt;b&gt;&lt;/b&gt;&lt;!-- 傾斜 --&gt;&lt;i&gt;&lt;/i&gt;&lt;!-- 下划线 --&gt;&lt;u&gt;&lt;/u&gt;&lt;!-- 右上角 --&gt;&lt;sup&gt;&lt;/sup&gt;&lt;!-- 右下角 --&gt;&lt;sub&gt;&lt;/sub&gt;&lt;!-- 穿越横线 --&gt;&lt;s&gt;&lt;/s&gt;&lt;strike&gt;&lt;/strike&gt;&lt;!-- 强制不换行 --&gt;&lt;nobr&gt;&lt;/nobr&gt; 1.1 标签横向排列 &lt;style&gt;##nav li{ float:right; list-style: none; margin:10px; /*左右间隔*/ padding&quot;0; /*上下*/ }&lt;/style&gt;&lt;ul id=&quot;nav-top&quot;;&gt; &lt;li&gt;1&lt;/li&gt; &lt;li&gt;2&lt;/li&gt;&lt;/ul&gt; 2.图片 在img标签里面只设置宽，不设置高，图片就会等比例缩放。 &lt;!-- 等比例缩放 --&gt;&lt;img src=&quot;/i/mouse.jpg&quot; height=&quot;200&quot;&gt;&lt;!-- 拉伸 --&gt;&lt;img style=&quot;width:100%; height:100%;&quot; src=&quot;2.jpg&quot;&gt;&lt;!-- 旋转 --&gt;&lt;img style=&quot;transform: rotate(90deg);&quot; src=&quot;2.jpg&quot;&gt; 复杂模块 2.1 图片点击放大 HTML 点击悬屏放大, 再点击退出。鼠标悬停有提示 &lt;div class=&quot;col-lg-4 col-md-6 col-xs-12 mix development print&quot;&gt; &lt;div class=&quot;portfolio-item&quot;&gt; &lt;div class=&quot;shot-item&quot;&gt; &lt;img src=&quot;Linkercare/Clients/总览/crop3.png&quot; alt=&quot;&quot; /&gt; &lt;div class=&quot;single-content&quot;&gt; &lt;div class=&quot;fancy-table&quot;&gt; &lt;div class=&quot;table-cell&quot;&gt; &lt;div class=&quot;zoom-icon&quot;&gt; &lt;a class=&quot;lightbox&quot; href=&quot;Linkercare/Clients/总览/crop3.png&quot;&gt;&lt;i class=&quot;lni-zoom-in item-icon&quot;&gt;&lt;/i&gt;&lt;/a&gt; &lt;/div&gt; &lt;a href=&quot;#&quot;&gt;View Project&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; JS 点击原地放大，并挤压其他图片/文字空间造成重排，再次点击恢复原来打小。鼠标悬停无提示 &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot; /&gt; &lt;script type=&quot;text/javascript&quot; src='jquery-1.8.0.js'&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;img id=&quot;img1&quot; src=&quot;11.jpg&quot; style=&quot;width:100px;height:150px&quot; alt=&quot;&quot; /&gt; &lt;/body&gt; &lt;script type=&quot;text/javascript&quot;&gt; $(function(){ $(&quot;#img1&quot;).click(function(){ var width = $(this).width(); if(width==100) { $(this).width(200); $(this).height(300); } else { $(this).width(100); $(this).height(150); } }); }); &lt;/script&gt;&lt;/html&gt; 2.2 图片圆角 &lt;img style=&quot;border-radius:1000px;&quot; src=&quot;Linkercare/Clients/总览/crop3.png&quot; alt=&quot;&quot; /&gt; 2.3 图片边框 &lt;img style=&quot;border:solid;&quot;&gt; 3.超链接 &lt;!-- 页面内超链接 --&gt;&lt;a href=&quot;#tips&quot;&gt;Text&lt;/a&gt;&lt;h1 id=&quot;h1anchor&quot;&gt;标题一&lt;/h1&gt;&lt;!--在新的标签打开本链接--&gt;&lt;a href='test.html' target=&quot;_blank&quot; &gt;链接文字&lt;/a&gt; 4.插入别的页面 &lt;iframe name=&quot;myiframe&quot; id=&quot;myrame&quot; src=&quot;test.html&quot; width=&quot;1100&quot; height=&quot;600&quot;&gt;&lt;/iframe&gt;&lt;!-- 额外参数 --&gt;&lt;iframe frameborder=&quot;0&quot; align=&quot;left&quot; width=&quot;200&quot; height=&quot;200&quot; scrolling=&quot;no&quot;&gt; 5.Table &lt;table&gt; &lt;tr&gt;&lt;th&gt;title1&lt;/th&gt;&lt;th&gt;title2&lt;/th&gt;&lt;tr&gt; &lt;tr&gt;&lt;td&gt;&lt;img src=test1.jpg border=0&gt;&lt;/td&gt;&lt;td&gt;&lt;img src=test2.jpg border=0&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;!-- table可以并列很多东西 --&gt;&lt;!--加背景色--&gt;&lt;table bgcolor=#rrggbb&gt;&lt;/table&gt;&lt;tr height='100px'&gt;&lt;/tr&gt;/*边框:http://blog.sina.com.cn/s/blog_6721f25c0101e0l8.html */&lt;table lign=&quot;center&quot; frame=below rules=rows border=&quot;1&quot; cellpadding=&quot;2&quot; cellspacing=&quot;0&quot;&gt; 6 菜单 6.1 下拉菜单 a. JS &lt;!--来源:https://zhidao.baidu.com/question/1110427647137965899.html --&gt;&lt;html&gt; &lt;head&gt; &lt;style&gt;*{margin:0;padding:0;} ul,li { list-style-type:none; padding:0; margin:0; } #nav li a { display:block; width:40px; text-align:center; text-decoration:none; color:#ffffff; background-color:#3ee27d; } #nav li { position:relative; margin-bottom:2px;float:left;margin-right:0px; } #nav li ul { position:absolute; left:10px; top:30px; display:none;width:100px; } #nav li:hover ul { display:block; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;ul id=&quot;nav&quot;&gt; &lt;li&gt; &lt;a href=&quot;#&quot;&gt;首页&lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;#&quot;&gt;关于我们&lt;/a&gt; &lt;ul&gt; &lt;li&gt;我们的故事&lt;/li&gt; &lt;li&gt;我们的团队&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;#&quot;&gt;我们的服务&lt;/a&gt; &lt;ul&gt; &lt;li&gt;网页设计&lt;/li&gt; &lt;li&gt;页面制作&lt;/li&gt; &lt;li&gt;程序开发&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;#&quot;&gt;联系我们&lt;/a&gt; &lt;ul&gt; &lt;li&gt;团队主力&lt;/li&gt; &lt;li&gt;团队成员&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt;&lt;/body&gt;&lt;/html&gt; 效果： b. HTML &lt;!--来源:https://www.php.cn/div-tutorial-412558.html--&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;style&gt;.dropbtn { background-color: black; color: white; padding: #px; font-size: #px; border: none;}.dropdown { position: relative; display: inline-block;}.dropdown-content { display: none; position: absolute; background-color: lightgrey; min-width: #px; z-index: 1;}.dropdown-content a { color: black; padding: #px #px; text-decoration: none; display: block;}.dropdown-content a:hover {background-color: white;}.dropdown:hover .dropdown-content {display: block;}.dropdown:hover .dropbtn {background-color: grey;}&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;div class=&quot;dropdown&quot;&gt;&lt;button class=&quot;dropbtn&quot;&gt;Name&lt;/button&gt;&lt;div class=&quot;dropdown-content&quot;&gt;&lt;a href=&quot;http://www.php.cn/&quot;&gt;Name&lt;/a&gt;&lt;a href=&quot;http://www.php.cn/&quot;&gt;Name&lt;/a&gt;&lt;a href=&quot;http://www.php.cn/&quot;&gt;Name&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 效果： 7.杂记 7.1 align &lt;img align=&quot;left&quot; src=&quot;/i/mouse.jpg&quot; height=&quot;200&quot;&gt; 值 描述 left 左对齐内容。 right 右对齐内容。 center 居中对齐内容。 justify 对行进行伸展，这样每行都可以有相等的长度（就像在报纸和杂志中）。 7.2 Span &lt;div style=&quot;position: relative; width: 170px; height: 89px;&quot;&gt;&lt;img src=&quot;loading.gif&quot; width=&quot;170&quot; height=&quot;89&quot; alt=&quot;&quot;&gt;&lt;span style=&quot;position: absolute; top: 0; left: 0;&quot;&gt;添加文字...添加文字...添加文字...&lt;/span&gt;&lt;/div&gt; 7.3 Coding Bar source:https://www.bootcdn.cn/highlight.js/ &lt;link href=&quot;https://cdn.bootcss.com/highlight.js/9.15.10/styles/a11y-dark.min.css&quot; rel=&quot;stylesheet&quot;&gt; &lt;script async src=&quot;https://cdn.bootcss.com/highlight.js/9.15.10/highlight.min.js&quot;&gt;&lt;/script&gt; &lt;script &gt;hljs.initHighlightingOnLoad();&lt;/script&gt; &lt;code class=&quot;lang-javascript&quot;&gt;for(ii in 1:ncol(a)){a[,ii][which(a[,ii]&gt;0)] &lt;- log(a[,ii][which(a[,ii]&gt;0)],10)/log(max(a[,ii]),10)a[,ii][which(a[,ii]&lt;0)] &lt;- log(a[,ii][which(a[,ii]&lt;0)](-1),10)(-1)/log(mean(a[,ii]) *(-1))}&lt;/code&gt; 效果: 7.32 Terminal .Terminal{ max-width: 900px; background-color: black; color: #ffffff; padding-left: 10px; font-size: large; font-size: 20px; font-family: monospace; border-radius: 5px 5px 0px 0px;}.code{ max-width: 900px; background-color: rgb(65, 65, 65); color: rgb(0, 205, 0); padding-left: 20px; font-family: monospace; font-size: 18px; border-radius: 0px 0px 10px 10px;} &lt;div class=&quot;Terminal&quot;&gt; &lt;img src=&quot;../Home/img/Terminal.png&quot; height=&quot;30px&quot;&gt; Terminal &lt;img src=&quot;../Home/img/Terminal2.png&quot; height=&quot;30px&quot; align='right' img src=&quot;../Home/img/Terminal2.png&quot; height=&quot;30px&quot; align='right' style=&quot;padding-right:5px;&quot;&gt;&lt;/div&gt;&lt;pre class='code'&gt;&lt;code class=&quot;lang-javascript&quot;&gt;### Generated by deepin-installerdeb [by-hash=force] http://ftp.sjtu.edu.cn/deepin panda main contrib non-free##deb-src http://ftp.sjtu.edu.cn/deepin panda main contrib non-free&lt;/code&gt;&lt;/pre&gt; 效果： 图片元素: 7.4 鼠标悬停显示文字 &lt;a href=&quot;javascript;&quot; title=&quot;悬停的文字&quot;&gt;将鼠标移到这个标签上，就会显示&quot;悬停的文字&quot;&lt;/a&gt; 7.5 每秒刷新一次 &lt;head&gt; &lt;meta http-equiv=&quot;refresh&quot; content=&quot;1&quot;&gt;&lt;/head&gt; 方便排版的时候预览界面 7.6 实时预览 VS 插件： Live Server[1] 亲测有效 7.7 统计访问量 不蒜子：http://busuanzi.ibruce.info/ &lt;script async src=&quot;//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js&quot;&gt;&lt;/script&gt;&lt;span id=&quot;busuanzi_container_site_pv&quot;&gt;本站总访问量&lt;span id=&quot;busuanzi_value_site_pv&quot;&gt;&lt;/span&gt;次&lt;/span&gt; 7.8 免除loft影响, 重开一行 div style=&quot;clear:both;&quot;&gt;&lt;/div&gt; 隐藏内容 &lt;details&gt; &lt;summary&gt;&lt;span style=&quot;font-size:20px&quot;&gt; 请点击我!!&lt;/span&gt; &lt;/summary&gt; 我就在这里!!!&lt;/details&gt; 请点击我!! 我就在这里!!! TianXinCoord; 2018; CSDN; VSCode设置网页代码实时预览.link ↩︎","link":"/2020/01/22/Blog/Html/"},{"title":"Some Online Tools","text":"Documentation PDF images extraction: Cleverpdf Chemistry Draw Chemical Structures[1] MolView (PS: Strong recommended. You can even embed the result to an web page) Chem-space ChemSpider MolView ScihutTool :Free Online Tools to Draw Chemical Structures ↩︎","link":"/2020/08/25/Blog/Online_tools/"},{"title":"Latex grammar highlight Plugin for Atom","text":"Editor Prerequisation sudo apt install -y texlive texlive-font-utils texlive-pstricks-doc texlive-base texlive-formats-extra texlive-lang-german texlive-metapost texlive-publishers texlive-bibtex-extra texlive-latex-base texlive-metapost-doc texlive-publishers-doc texlive-binaries texlive-latex-base-doc texlive-science texlive-extra-utils texlive-latex-extra texlive-science-doc texlive-fonts-extra texlive-latex-extra-doc texlive-pictures texlive-xetex texlive-fonts-extra-doc texlive-latex-recommended texlive-pictures-doc texlive-fonts-recommended texlive-humanities texlive-lang-english texlive-latex-recommended-doc texlive-fonts-recommended-doc texlive-humanities-doc texlive-luatex texlive-pstricks perl-tksudo apt install latexmk atom 3 latex packages for atom: language-latex（latex高亮） latex pdf-view（可视化显示） reference: Violet-Guo © Violet-Guo 2017 按Ctrl+Alt+B預覽 © Violet-Guo 2017 more editors https://www.zhihu.com/question/19954023 Lyx TexStudio Sublime Text Emacs Online Platform: Overleaf I found most of my friends are using Overleaf to edit latex online. So, I tired and use it, too. It is good. All codes and methods below are all test under the Overleaf platform. Main structure of the Latex here is the structure of the latex projects: . ├── figures │ └── example_figure.pdf ├── ldr-article.cls ├── main.bib ├── main.pdf ├── main.tex ├── README.md └── Rmarkdown.Rmd This directory is an example from the overleaf (ldr-template). The figures is a directory for storing the figures. The ldr-article.cls is for storing all configures which like cs for html. the main.bib is for storing the citations the main.tex is the place for your main contented. \\documentclass{ldr-article}\\addbibresource{main.bib}\\title{Titiel is here }\\author{Karobben 1\\\\\\\\Karobben 2}\\begin{document} \\maketitle \\begin{abstract} There are no abstracts. Lol \\end{abstract} \\keywords{latex; write a papre}\\section{Introduction}This is an exmaple for showing the basic structure of a latex\\section{Result}\\subsection{Result 1}\\subsection{Result 2}\\end{document} Citation In latex, there is at least two ways to cite: cite and parencite. The different between two of them are parencite could automatically add parent symbol, “()”, for you. Contents in main.bib file: @article{Ctrax, title={High-throughput ethomics in large groups of Drosophila}, author={Branson, Kristin and Robie, Alice A and Bender, John and Perona, Pietro and Dickinson, Michael H}, journal={Nature methods}, volume={6}, number={6}, pages={451--457}, year={2009}, publisher={Nature Publishing Group US New York} } @article{CADABRA, title={Automated monitoring and analysis of social behavior in Drosophila}, author={Dankert, Heiko and Wang, Liming and Hoopfer, Eric D and Anderson, David J and Perona, Pietro}, journal={Nature methods}, volume={6}, number={4}, pages={297--303}, year={2009}, publisher={Nature Publishing Group US New York} } Latex Rendered in PDF Citation test:\\\\- Parencite: \\parencite{Ctrax} \\\\- Parencite multiple: \\parencite{Ctrax, CADABRA} \\\\- Cite: \\cite{Ctrax}\\\\- Cite multiple: \\cite{Ctrax, CADABRA}\\\\ Citation test: - Parencite: (Branson et al.)- Parencite multiple: (Branson et al.; Dankert et al.)- Cite: Branson et al.- Cite multiple: Branson et al.; Dankert et al. Different styles for citation: Find the line \\RequirePackage[style= in the file of ldr-article.cls Style Approximate Citation Format alphabetic [Bra+09] authortitle Branson et al., “High-throughput ethomics in large groups of Drosophila” authoryear Branson et al. 2009 authoryear-icomp Branson et al. 2009 authoryear-comp Branson et al. 2009 numeric [1] numeric-comp [1] reading Branson, Kristin, et al. 2009 verbose Branson, Kristin, et al. “High-throughput ethomics in large groups of Drosophila.” Nature Methods 6.6 (2009): 451-457 chem-acs (1) phys [1] nejm 1. nature 1. science 1. ieee [1] Other tricks Commenting: % this is a invisible comment Dealing with special characters: In LaTeX, some characters are reserved for special commands. If you need to use these characters as they are, you need to escape them using a backslash (\\). The special characters are: # $ % ^ &amp; _ { } ~ \\. For example, if you want to write 5%, you need to write it as 5\\% in LaTeX. Inserting images: The graphicx package provides commands to work with images. You can use the \\includegraphics command to insert an image. \\usepackage{graphicx}\\begin{document}\\includegraphics{filename}\\end{document} Creating tables: The tabular environment can be used to create tables \\begin{tabular}{|c|c|}\\hlineHeader 1 &amp; Header 2 \\\\\\hlineRow 1, Col 1 &amp; Row 1, Col 2 \\\\Row 2, Col 1 &amp; Row 2, Col 2 \\\\\\hline\\end{tabular} Dealing with large documents: For large documents like a thesis or a book, you can use \\input{filename} or \\include{filename} to add contents from another file. This can help keep your project organized. Math mode: LaTeX is widely used for its superior handling of mathematical equations. You can insert an inline mathematical equation like this: $E=mc^2$, or a standalone one like this: \\begin{equation}E=mc^2\\end{equation} Hyperlinks: With the hyperref package, you can add hyperlinks to your document. \\usepackage{hyperref}...\\href{https://www.example.com}{Link text} Referencing: With LaTeX, you can easily cross-reference figures, tables, sections, etc. For example, when you label a figure using \\label{fig:my_label} you can reference it with \\ref{fig:my_label} and it will automatically update the figure number. Remember, the power of LaTeX comes from the various packages available. When you want to do something specific, there is probably a package that can help you achieve it. Check the documentation of the packages to make full use of their features. pre { background-color:#38393d; color: #5fd381; }","link":"/2020/08/25/Blog/Latex/"},{"title":"Python OpenCV: Blurt Detect","text":"Python OpenCV: Blurt Detect I settled a Raspberry pi for taking pictures for months to recording the pictures of my Eco-Tack. It is fun to see the changing of the plants in the tank after combined the pictures. But the problem is their are few blurt images in those hundreds of pictures. So, I wonder it is really cool that detect the blurt pictures by using python. So, I found two posts from internet and try to find the suitable one for me. Two reference posts: 技术挖掘者; 2019 Dontla; 2019 So, there have 574 photos in total and I have no idea which one is blurt images. 技术挖掘者 Blurt Clear Dontla Blurt Clear Compare By comparing the result of those to codes, I found that they used the exact same way: cv2.Laplacian to calculate… I should really check the raw codes before executing them. First Second The simplified codes should be: import cv2imagePath = &quot;img.png&quot;image = cv2.imread(imagePath)## 将图片转换为灰度图片gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)## 计算灰度图片的方差fm = cv2.Laplacian(gray, cv2.CV_64F).var()print(fm) 很不实用 = = 真的单独一个算法来这么检测, 太水了. Plus So, there are another good post about the blurt-detection by using python Opencv. It applied ‘Brenner’, ‘Laplacian’, ‘SMD’, ‘SMD2’, etc to calculate. If you are interested in it, go to check FUNNY AI.","link":"/2020/10/25/Blog/OpenCV_BlurtDetect/"},{"title":"Nothing Worth for Looking","text":"Nothing Worth for Looking © 千里马校园网 date: 2020/6/22 Today, I just finished the subject-1 of my license. There’s been a lot of episodes before I finish it. But whatever, the result is good, I passed the exam. But what made me writing is nothing about the license, it’s something connected to my academic career, and it’ll definitely affect me in the future. I was writing a paper with my ex-teacher who is a very kind and tolerant person and focusing on Aquatics. If it is accepted, it’ll be my first paper in my academic career. As you can see, how significant it is for me. We agreed on most parts of the paper except one, which I devoted lots of time and energy to and felt very satisfied with it. As a result, I lost myself and believe that I must be right about it and this part would be the shiniest section of the whole paper. So, instead of deleting them, I asked one more time for perfecting this section and hoped that maybe she would concede my idea after I polished it. So, I started to google and read more papers to find evidence to strengthen my hypothesis. After about a half-hour, I looked back at my data and just realized that I dug it too deep to find the way home. It reminded me of common scenes in WuXia World that someone who gained the secret scroll which records the best KunFu in the world. But because it was the best, it was the hardest, too. It takes time to accept and digest them before they can really muster it. But they were desperate to muster it in a short time. So, they can not learn it well and result in hurting themselves or even becoming mad. As for me, I just believed that I was pretty close to doing something like that, too. Bioinformatics is a very powerful skill that I’d like to learn. It’s not hard to follow the pipeline, but it’s hard to make your own pipe to match your data. Though the connection of genes was revealed well according to cited papers, the expression changes and limited morphology data indicate that the relationships in this experiment were way complicated than I believed. So, I quickly re-adjusted myself and conceded my mistake. Luckily, she was so patient with me rather than directly against and denying me. Because if she did that and it definitely evokes my reverse. Then, I’ll dig the hole far deeper than this time and stack myself in it. I’m lucky at this time. But I may not have the same fortunes every time. So, I need to keep wise and clear to avoid this. Hoping it’ll never happen again.","link":"/2020/06/22/Blog/Post_1/"},{"title":"Python|OpenCV| Images to Video","text":"This is a script for connect a serious of images to a video by using python openCV. Before starting: You can find some fundamental codes of Opencv at: My Blog BASHpython3 img2video.py -i *.png -o output.avi -f 24 -t N img2video.py: img2video.py#!/usr/bin/env python3## -*- coding: utf-8 -*-## @Time : 2020/08/03## @Author : Karobben## @Site : China## @File : img2video.py## @Software: Atomimport argparseparser = argparse.ArgumentParser()parser.add_argument('-i', '-I', '--input', nargs='+', help='Input Video file') #输入文件parser.add_argument('-o', '-U', '--output', default = &quot;out_test.avi&quot;, help='Output Video file, default as &quot;out_test.avi&quot;') #输出文件parser.add_argument('-f','-F','--fps', default = 24, type = int, help='Speed up by ratio, &quot;default = 24&quot;') #帧率parser.add_argument('-t', '-T', '--title', default =&quot;N&quot;, help= ''' Add a title;\\n Y/N; default = &quot;N&quot; ''') #输入文件#获取参数args = parser.parse_args()File = args.inputOUTPUT = args.outputfps = args.fpsTitle = args.titleimport cv2, osdef FD_judge(path): result = &quot;&quot; if len(path) &gt; 1: result = &quot;Files&quot; elif os.path.isdir(path[0]): result = &quot;Directory&quot; elif os.path.isfile(path[0]): result = &quot;File&quot; else: result = &quot;path is incorrect&quot; return resultTyp_in = FD_judge(File)if Typ_in == &quot;Directory&quot;: List = os.popen('ls '+File).read().split('\\n')[:-1] img = cv2.imread(File +&quot;/&quot;+List[0])else: List = File img = cv2.imread(List[0])size = (len(img[0]),len(img))fourcc = cv2.VideoWriter_fourcc('M','J','P','G')videowriter = cv2.VideoWriter(OUTPUT,fourcc,fps,size)for i in List: if Typ_in == &quot;Directory&quot;: i = File +&quot;/&quot;+i # Reading img img = cv2.imread(i) # Adding title if Title == &quot;Y&quot;: cv2.putText(img, i.split(&quot;/&quot;)[-1] ,(200, 100), cv2.FONT_HERSHEY_COMPLEX, 2.0, (100, 200, 200), 5) videowriter.write(img)videowriter.release() BiliBili：史上最不正經的生物狗","link":"/2020/10/25/Blog/Py_img2video/"},{"title":"Python|OpenCV| Video Speedup","text":"Python| OpenCV: Video Speed up Before starting: You can find some fundamental codes of Opencv at: My Blog You can find the latest release at: GitHub: Karobben ##!/usr/bin/env python3## -*- coding: utf-8 -*-## @Time : 2020/08/03## @Author : Karobben## @Site : China## @File : VideoSlice.py## @Software: Atomimport argparseparser = argparse.ArgumentParser()parser.add_argument('-i','-I','--input', help='Input Video file') #输入文件parser.add_argument('-o','-U','--output', default = &quot;out_test.avi&quot;, help='Output Video file, default as &quot;out_test.avi&quot;') #输出文件parser.add_argument('-r','-R','--ratio', default = 2, type = int, help='Speed up by ratio, &quot;default = 2&quot;') #加速比率parser.add_argument('-f','-F','--fps', default = 0, type = int, help='Speed up by ratio, &quot;default = 2&quot;') #帧率parser.add_argument('-inf', nargs='?',default=True)##获取参数args = parser.parse_args()INPUT = args.inputOUTPUT = args.outputRatio = args.ratiofps_o = args.fpsinf = args.infimport cv2##INPUT = 'bug.avi'cap = cv2.VideoCapture(INPUT)fps_c = cap.get(cv2.CAP_PROP_FPS)Video_h = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)Video_w = cap.get(cv2.CAP_PROP_FRAME_WIDTH)print(&quot;Current fps:&quot;,fps_c)##OUTPUT = &quot;out_test.avi&quot;if fps_o == 0: fps_o = fps_cdef Video_speed(cap, OUTPUT): Out_size = (int(Video_w),int(Video_h)) fourcc = cv2.VideoWriter_fourcc('M','J','P','G') videowriter = cv2.VideoWriter(OUTPUT,fourcc,fps_o,Out_size) i = 0 ret = True while ret == True: i +=1 ret,frame=cap.read() if i % Ratio == 0: videowriter.write(frame) videowriter.release()if inf == True: Video_speed(cap, OUTPUT) BiliBili：史上最不正經的生物狗","link":"/2020/10/25/Blog/Py_openCV_speed/"},{"title":"Kivy in Action 1: Problem in Urlrequest","text":"Kivy in Action: A Sample Crawler My coworker asked me for help checking the database (A web server) very frequently since without a USB-key, there is no way to log in to the database, and most of the time, she is not in the company. But luckily, I find there is almost no obstacle on the way you crawling it by using python except the cookie is updated every day. So, I decided to write an android app for her so she can check the results on her own. And I just need to send her the cookie if it is updated. It’ll really save my day! Borrow the Codes I’m kind of a new bee in kivy. So, instead of writing on my own, I decided to copy the may frame from the book “Creating Apps in Kivy: Mobile with Python”. It is an awesome book. It’ll introduce kivy to you by teaching you how to build a weather app. It is really helpful for the new bee like me. For the first few chapters, everybody can understand it very quickly and easily as if you know execute print(hello world) in python. Then, it’ll imply lots of class which I can’t understand back that time I first read it. And due to the update of python and some typographical errors, you need to know how to correct it. The main code is in Light Weather App. You can customize the codes of function search_location(self) and found_location(self, request, data) to access what you like. I insert my codes and everything works fine on the computer. But some strange things happened after I run it on my cell phone. The result pops up, it means the codes works fine. But soon, it crushed with no signals. buildozer.spec [app]# (str) Title of your applicationtitle = Ruibio# (str) Package namepackage.name = Ruibio# (str) Package domain (needed for android/ios packaging)package.domain = org.test# (str) Source code where the main.py livesource.dir = .# (list) Source files to include (let empty to include all the files)source.include_exts =# (list) List of inclusions using pattern matching#source.include_patterns = assets/*,images/*.png# (list) Source files to exclude (let empty to not exclude anything)#source.exclude_exts = spec# (list) List of directory to exclude (let empty to not exclude anything)#source.exclude_dirs = tests, bin# (list) List of exclusions using pattern matching#source.exclude_patterns = license,images/*/*.jpg# (str) Application versioning (method 1)version = 0.1# (str) Application versioning (method 2)# version.regex = __version__ = ['&quot;](.*)['&quot;]# version.filename = %(source.dir)s/main.py# (list) Application requirements# comma separated e.g. requirements = sqlite3,kivyrequirements = python3,kivy# (str) Custom source folders for requirements# Sets custom source for any requirements with recipes# requirements.source.kivy = ../../kivy# (list) Garden requirements#garden_requirements =# (str) Presplash of the application#presplash.filename = %(source.dir)s/data/presplash.png# (str) Icon of the application#icon.filename = %(source.dir)s/data/icon.png# (str) Supported orientation (one of landscape, sensorLandscape, portrait or all)orientation = all# (list) List of service to declare#services = NAME:ENTRYPOINT_TO_PY,NAME2:ENTRYPOINT2_TO_PY## OSX Specific### author = © Copyright Info# change the major version of python used by the apposx.python_version = 3# Kivy version to useosx.kivy_version = 1.9.1## Android specific## (bool) Indicate if the application should be fullscreen or notfullscreen = 0# (string) Presplash background color (for new android toolchain)# Supported formats are: #RRGGBB #AARRGGBB or one of the following names:# red, blue, green, black, white, gray, cyan, magenta, yellow, lightgray,# darkgray, grey, lightgrey, darkgrey, aqua, fuchsia, lime, maroon, navy,# olive, purple, silver, teal.#android.presplash_color = #FFFFFF# (list) Permissionsandroid.permissions = INTERNET# (int) Target Android API, should be as high as possible.#android.api = 27# (int) Minimum API your APK will support.#android.minapi = 21# (int) Android SDK version to use#android.sdk = 20# (str) Android NDK version to use#android.ndk = 17c# (int) Android NDK API to use. This is the minimum API your app will support, it should usually match android.minapi.#android.ndk_api = 21# (bool) Use --private data storage (True) or --dir public storage (False)#android.private_storage = True# (str) Android NDK directory (if empty, it will be automatically downloaded.)#android.ndk_path =# (str) Android SDK directory (if empty, it will be automatically downloaded.)#android.sdk_path =# (str) ANT directory (if empty, it will be automatically downloaded.)#android.ant_path =# (bool) If True, then skip trying to update the Android sdk# This can be useful to avoid excess Internet downloads or save time# when an update is due and you just want to test/build your package# android.skip_update = False# (bool) If True, then automatically accept SDK license# agreements. This is intended for automation only. If set to False,# the default, you will be shown the license when first running# buildozer.# android.accept_sdk_license = False# (str) Android entry point, default is ok for Kivy-based app#android.entrypoint = org.renpy.android.PythonActivity# (str) Android app theme, default is ok for Kivy-based app# android.apptheme = &quot;@android:style/Theme.NoTitleBar&quot;# (list) Pattern to whitelist for the whole project#android.whitelist =# (str) Path to a custom whitelist file#android.whitelist_src =# (str) Path to a custom blacklist file#android.blacklist_src =# (list) List of Java .jar files to add to the libs so that pyjnius can access# their classes. Don't add jars that you do not need, since extra jars can slow# down the build process. Allows wildcards matching, for example:# OUYA-ODK/libs/*.jar#android.add_jars = foo.jar,bar.jar,path/to/more/*.jar# (list) List of Java files to add to the android project (can be java or a# directory containing the files)#android.add_src =# (list) Android AAR archives to add (currently works only with sdl2_gradle# bootstrap)#android.add_aars =# (list) Gradle dependencies to add (currently works only with sdl2_gradle# bootstrap)#android.gradle_dependencies =# (list) add java compile options# this can for example be necessary when importing certain java libraries using the 'android.gradle_dependencies' option# see https://developer.android.com/studio/write/java8-support for further information# android.add_compile_options = &quot;sourceCompatibility = 1.8&quot;, &quot;targetCompatibility = 1.8&quot;# (list) Gradle repositories to add {can be necessary for some android.gradle_dependencies}# please enclose in double quotes# e.g. android.gradle_repositories = &quot;maven { url 'https://kotlin.bintray.com/ktor' }&quot;#android.add_gradle_repositories =# (list) packaging options to add# see https://google.github.io/android-gradle-dsl/current/com.android.build.gradle.internal.dsl.PackagingOptions.html# can be necessary to solve conflicts in gradle_dependencies# please enclose in double quotes# e.g. android.add_packaging_options = &quot;exclude 'META-INF/common.kotlin_module'&quot;, &quot;exclude 'META-INF/*.kotlin_module'&quot;#android.add_gradle_repositories =# (list) Java classes to add as activities to the manifest.#android.add_activities = com.example.ExampleActivity# (str) OUYA Console category. Should be one of GAME or APP# If you leave this blank, OUYA support will not be enabled#android.ouya.category = GAME# (str) Filename of OUYA Console icon. It must be a 732x412 png image.#android.ouya.icon.filename = %(source.dir)s/data/ouya_icon.png# (str) XML file to include as an intent filters in &lt;activity&gt; tag#android.manifest.intent_filters =# (str) launchMode to set for the main activity#android.manifest.launch_mode = standard# (list) Android additional libraries to copy into libs/armeabi#android.add_libs_armeabi = libs/android/*.so#android.add_libs_armeabi_v7a = libs/android-v7/*.so#android.add_libs_arm64_v8a = libs/android-v8/*.so#android.add_libs_x86 = libs/android-x86/*.so#android.add_libs_mips = libs/android-mips/*.so# (bool) Indicate whether the screen should stay on# Don't forget to add the WAKE_LOCK permission if you set this to True#android.wakelock = False# (list) Android application meta-data to set (key=value format)#android.meta_data =# (list) Android library project to add (will be added in the# project.properties automatically.)#android.library_references =# (list) Android shared libraries which will be added to AndroidManifest.xml using &lt;uses-library&gt; tag#android.uses_library =# (str) Android logcat filters to use#android.logcat_filters = *:S python:D# (bool) Copy library instead of making a libpymodules.so#android.copy_libs = 1# (str) The Android arch to build for, choices: armeabi-v7a, arm64-v8a, x86, x86_64android.arch = armeabi-v7a## Python for android (p4a) specific## (str) python-for-android fork to use, defaults to upstream (kivy)#p4a.fork = kivy# (str) python-for-android branch to use, defaults to master#p4a.branch = master# (str) python-for-android git clone directory (if empty, it will be automatically cloned from github)#p4a.source_dir =# (str) The directory in which python-for-android should look for your own build recipes (if any)#p4a.local_recipes =# (str) Filename to the hook for p4a#p4a.hook =# (str) Bootstrap to use for android builds# p4a.bootstrap = sdl2# (int) port number to specify an explicit --port= p4a argument (eg for bootstrap flask)#p4a.port =## iOS specific## (str) Path to a custom kivy-ios folder#ios.kivy_ios_dir = ../kivy-ios# Alternately, specify the URL and branch of a git checkout:ios.kivy_ios_url = https://github.com/kivy/kivy-iosios.kivy_ios_branch = master# Another platform dependency: ios-deploy# Uncomment to use a custom checkout#ios.ios_deploy_dir = ../ios_deploy# Or specify URL and branchios.ios_deploy_url = https://github.com/phonegap/ios-deployios.ios_deploy_branch = 1.7.0# (str) Name of the certificate to use for signing the debug version# Get a list of available identities: buildozer ios list_identities#ios.codesign.debug = &quot;iPhone Developer: &lt;lastname&gt; &lt;firstname&gt; (&lt;hexstring&gt;)&quot;# (str) Name of the certificate to use for signing the release version#ios.codesign.release = %(ios.codesign.debug)s[buildozer]# (int) Log level (0 = error only, 1 = info, 2 = debug (with command output))log_level = 2# (int) Display warning if buildozer is run as root (0 = False, 1 = True)warn_on_root = 1# (str) Path to build artifact storage, absolute or relative to spec file# build_dir = ./.buildozer# (str) Path to build output (i.e. .apk, .ipa) storage# bin_dir = ./bin# -----------------------------------------------------------------------------# List as sections## You can define all the &quot;list&quot; as [section:key].# Each line will be considered as a option to the list.# Let's take [app] / source.exclude_patterns.# Instead of doing:##[app]#source.exclude_patterns = license,data/audio/*.wav,data/images/original/*## This can be translated into:##[app:source.exclude_patterns]#license#data/audio/*.wav#data/images/original/*## -----------------------------------------------------------------------------# Profiles## You can extend section / key with a profile# For example, you want to deploy a demo version of your application without# HD content. You could first change the title to add &quot;(demo)&quot; in the name# and extend the excluded directories to remove the HD content.##[app@demo]#title = My Application (demo)##[app:source.exclude_patterns@demo]#images/hd/*## Then, invoke the command line with the &quot;demo&quot; profile:##buildozer --profile demo android debug I changed the properties in main.kv I tried to alter few things to check the codes and find the error that may arise from the Urlrequests. I opened the quests in StackOverflow to asking for help. No responding Stockoverflow Adding verify=False in Urlrequest or my phone can’t get results in some request events. Finally, I found the resolution from Preeti who had met the same problem as mine and solved by assign requirement= python3==3.7.5, hostpython3==3.7.5in buildozer.spec file","link":"/2020/10/25/Blog/Kivy_note1/"},{"title":"Python 缩小图片轮廓","text":"Python 缩小图片轮廓 原图轮廓太粗，希望细一些- -但是不会PS GIMP。所以想用Python解决。思路： 保留四周都有有效颜色的点 import numpy as npimport cv2def Reduice(img): Result=[] for i in range(1,H-1): for ii in range(1,W-1): pix = [list(img[i-1][ii]), # LEFT list(img[i+1][ii]), # RIGHT list(img[i][ii-1]), # UP list(img[i][ii+1]), # DOWN list(img[i-1][ii-1]), # LU list(img[i+1][ii-1]), # RU list(img[i-1][ii+1]), # LD list(img[i+1][ii+1]), # RD ] if pix ==[[0,0,0,], [0,0,0,], [0,0,0,], [0,0,0,], [0,0,0,], [0,0,0,], [0,0,0,], [0,0,0,]]: Result +=[[i,ii]] return Resultimg = cv2.imread('111.png')H = len(img)W = len(img[0])##赋值到另一个图片：for i in range(5): Result = Reduice(img) img2 = np.array(img) img2[img2!=254]=254 for i in Result: img2[i[0],i[1]]=img[i[0],i[1]] img =np.array(img2)cv2.imwrite('5.png',img)## 接下来，减一次，输出一张图Num = 5for i in range(5): Num +=1 Result = Reduice(img) img2 = np.array(img) img2[img2!=254]=254 for i in Result: img2[i[0],i[1]]=img[i[0],i[1]] img =np.array(img2) cv2.imwrite(str(Num)+'.png',img)def View(img): while(True): #img = cv2.imread('111.png') cv2.imshow('image',img) if cv2.waitKey(1) &amp; 0xFF == ord('q'): cv2.destroyAllWindows() break","link":"/2020/06/26/Blog/Python-resizeOutline/"},{"title":"How to Using Python to Acquire Websites&#39; Responding Time","text":"How to Using Python to Acquire Websites’ Responding Time 1. Acquiring Responding Time reference:子黍 import requestsr = requests.get(&quot;http://www.cnblogs.com/yoyoketang/&quot;)print(r.elapsed.total_seconds()) 2. Multiprocessing import multiprocessing as mpimport time, reimport requestsList = [&quot;www.baidu.com&quot;, &quot;https://tongji.baidu.com/web/10000138058/overview/index?siteId=14350939&quot;,&quot;https://karobben.github.io/&quot;,&quot;https://space.bilibili.com/393056819&quot;,&quot;https://github.com/Karobben&quot;,&quot;https://www.yuque.com/dashboard/books&quot;,&quot;haishdiashdiahsdiuhsaiudha&quot;]def RespTime(url): # Page is exist or not try: r = requests.get(url, timeout=20) print(&quot;(&quot;+url+&quot;)(Update:&quot;+time.strftime(&quot;%D&quot;)+ &quot; &quot;+ str(r.elapsed.total_seconds())+&quot;s)&quot;) except: print(url+&quot;\\tFailed&quot;)def multicore(List, Pool=10): pool = mp.Pool(processes=Pool) for i in List: multi_res = [pool.apply_async(RespTime,(i,))] pool.close() pool.join() 3. Extract urls from Markdonw File 1. Extract and Calculates Responding Time Using this Script to test the links in Markdonw file reference: 张土豆 import multiprocessing as mpimport time, reimport requestsInput = &quot;/media/ken/Data/Github/Yuque/Bioinfor/test2.md&quot;F = open(Input,'r')File = F.read()pattern = re.compile(r'\\(http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\\)') # 匹配模式List = pattern.findall(File)def RespTime(url,return_dict): # Page is exist or not url = url.replace('(','').replace(&quot;)&quot;,&quot;&quot;) try: r = requests.get(url, timeout=20) Result = url+&quot;\\t&quot;+str(r.elapsed.total_seconds()) except: Result = url+&quot;\\tFailed&quot; return_dict[Result] = Resultif __name__ == '__main__': manager = mp.Manager() return_dict = manager.dict() jobs = [] for i in List: p = mp.Process(target=RespTime, args=(i,return_dict)) jobs.append(p) p.start() for proc in jobs: proc.join()for i in return_dict.values(): print(i) It backs to: http://www.kazusa.or.jp/codon/ 0.721183http://wwwmgs.bionet.nsc.ru/mgs/gnw/trrd/ 1.616894http://www.ncbi.nlm.nih.gov/dbSTS/ 1.460668... 2. Update the Markdonw File 1. Format your markdown file url as: [Title](https://www.baidu.com) (Oct; 0.888888s) You can format your file with codes below: import reInput = &quot;/media/ken/Data/Github/Yuque/Bioinfor/test2.md&quot;F = open(Input,'r')File = F.read()pattern = re.compile(r'\\(http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\\)') # 匹配模式List = pattern.findall(File)for i in List: i2 = i.replace(&quot;)&quot;,'').replace(&quot;(&quot;,'') File = re.sub(i, i2+&quot;) (test&quot;, File)F = open(Input,'w')F.write(File)F.close() As a result, your url will look like: Title(test) 2. Replace Basic rule of substitude import reurl = 'https://113.215.20.136:9011/113.215.6.77/c3pr90ntcya0/youku/6981496DC9913B8321BFE4A4E73/0300010E0C51F10D86F80703BAF2B1ADC67C80-E0F6-4FF8-B570-7DC5603F9F40.flv'pattern = re.compile(r'(?&lt;![\\.\\d])(?:\\d{1,3}\\.){3}\\d{1,3}(?![\\.\\d])')print pattern.findall(url)out = re.sub(pattern, '127.0.0.1', url)print out Cite: 那年花开月正圆 Replace import multiprocessing as mpimport time, reimport requestsInput = &quot;/media/ken/Data/Github/Yuque/Bioinfor/test2.md&quot;F = open(Input,'r')File = F.read()pattern = re.compile(r'\\(http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\\) \\((?:[a-zA-Z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F])| )+'+&quot;\\)&quot;) # 匹配模式List = pattern.findall(File)def RespTime(url,return_dict): # Page is exist or not url = url.split(')')[0].replace(&quot;(&quot;,&quot;&quot;) try: try: r = requests.get(url, timeout=20) rtime = str(r.elapsed.total_seconds())+&quot;s)&quot; except: rtime = &quot;OutOfTime)&quot; Result = &quot;(&quot;+url+&quot;) (Update:&quot;+time.strftime(&quot;%D&quot;)+ &quot;; &quot;+ rtime except: Result = &quot;(&quot;+url+&quot;) (Update:&quot;+time.strftime(&quot;%D&quot;)+ &quot;; Failed)&quot; return_dict[Result] = Resultif __name__ == '__main__': manager = mp.Manager() return_dict = manager.dict() jobs = [] for i in List: p = mp.Process(target=RespTime, args=(i,return_dict)) jobs.append(p) p.start() for proc in jobs: proc.join()DB=&quot;\\n&quot;.join(return_dict.values())for i in List: Str = i.split(&quot;)&quot;)[0].replace(&quot;(&quot;,'') #pattern = re.compile(Str+r&quot;\\)[ ]\\((?:[a-zA-Z]|[0-9]|[:/|\\.]|;)+[ ][0-9]|[a-zA-Z]|\\.?+&quot;) pattern = re.compile(Str+&quot;\\) \\(.+&quot;) i2 = &quot;(&quot;+pattern.findall(DB)[0] print(i,i2,sep='\\n') File = File[:File.find(i)] + i2+ File[File.find(i)+len(i):]F = open(Input,'w')F.write(File)F.close() 4. Final Script import argparseparser = argparse.ArgumentParser()parser.add_argument('-i','-I','--input') #输入文件parser.add_argument('-o','-U','--output') #输入文件##获取参数args = parser.parse_args()INPUT = args.inputOUTPUT = args.outputimport multiprocessing as mpimport time, reimport requestsF = open(INPUT,'r')File = F.read()pattern = re.compile(r'\\(http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\\) \\((?:[a-zA-Z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F])| )+'+&quot;\\)&quot;) # 匹配模式List = pattern.findall(File)def RespTime(url,return_dict): # Page is exist or not url = url.split(')')[0].replace(&quot;(&quot;,&quot;&quot;) try: try: r = requests.get(url, timeout=20) rtime = str(r.elapsed.total_seconds())+&quot;s)&quot; except: rtime = &quot;OutOfTime)&quot; Result = &quot;(&quot;+url+&quot;) (Update:&quot;+time.strftime(&quot;%D&quot;)+ &quot;; &quot;+ rtime except: Result = &quot;(&quot;+url+&quot;) (Update:&quot;+time.strftime(&quot;%D&quot;)+ &quot;; Failed)&quot; return_dict[Result] = Resultif __name__ == '__main__': manager = mp.Manager() return_dict = manager.dict() jobs = [] for i in List: p = mp.Process(target=RespTime, args=(i,return_dict)) jobs.append(p) p.start() for proc in jobs: proc.join()DB=&quot;\\n&quot;.join(return_dict.values())for i in List: Str = i.split(&quot;)&quot;)[0].replace(&quot;(&quot;,'') #pattern = re.compile(Str+r&quot;\\)[ ]\\((?:[a-zA-Z]|[0-9]|[:/|\\.]|;)+[ ][0-9]|[a-zA-Z]|\\.?+&quot;) pattern = re.compile(Str+&quot;\\) \\(.+&quot;) i2 = &quot;(&quot;+pattern.findall(DB)[0] print(i,i2,sep='\\n') File = File[:File.find(i)] + i2+ File[File.find(i)+len(i):]F = open(OUTPUT,'w')F.write(File)F.close()","link":"/2020/10/25/Blog/Py_url_Rtime/"},{"title":"Python 用 urwid 快速搭建 terminal TUI 交互应用","text":"Python 用 urwid 快速搭建 terminal TUI 交互应用 更多资料：https://www.yuque.com/liuwenkan/python/urwid本文主要用到了urwid 库， 更多关于TUI库介绍请看：https://www.yuque.com/liuwenkan/python/nff2r2 Hollow world import urwiddef exit_on_q(key): if key in ('q', 'Q'): raise urwid.ExitMainLoop()palette = [ ('banner', 'black', 'light gray'), ('streak', 'black', 'dark red'), ('bg', 'black', 'dark blue'),]txt = urwid.Text(('banner', u&quot; Hello World &quot;), align='center')map1 = urwid.AttrMap(txt, 'streak')fill = urwid.Filler(map1)map2 = urwid.AttrMap(fill, 'bg')loop = urwid.MainLoop(map2, palette, unhandled_input=exit_on_q)loop.run() 加上 按钮 Text，Button 等， 在Pile中排序， 然后添加入 Filler， 再丢进loop中 代码地址 ## button functiondef on_exit_clicked(button): raise urwid.ExitMainLoop()## button Namebutton = urwid.Button(u'Exit')## align button and Textfill = urwid.Pile([map1, button])## Connect the signalurwid.connect_signal(button, 'click', on_exit_clicked) 完全代码： import urwiddef exit_on_q(key): if key in ('q', 'Q'): raise urwid.ExitMainLoop()palette = [ ('banner', 'black', 'light gray'), ('streak', 'black', 'dark red'), ('bg', 'black', 'dark blue'),]button = urwid.Button(u'Exit')def on_exit_clicked(button): raise urwid.ExitMainLoop()txt = urwid.Text(('banner', u&quot; Hello World &quot;), align='center')map1 = urwid.AttrMap(txt, 'streak')fill = urwid.Pile([map1, button])fill = urwid.Filler(fill)urwid.connect_signal(button, 'click', on_exit_clicked)loop = urwid.MainLoop(map2, palette, unhandled_input=exit_on_q)loop.run() 其实我挺讨厌这个背景色的 2333 成功加入 退出 干脆添加一个菜单吧～ 菜单代码地址","link":"/2020/06/26/Blog/Python-urwid-Quick/"},{"title":"Python 爬虫 -- 新闻爬取","text":"Python 爬虫 – 新闻爬取 1. 科技快讯 网址:http://www.citreport.com/ 以科技快报为目标 1. 首先, 获取整个页面信息 from bs4 import BeautifulSoupfrom urllib.request import urlopenimport reimport requests## Starting resuqesthtml = urlopen(&quot;http://www.citreport.com/&quot;).read()soup = BeautifulSoup(html, features='lxml') 2. 查看网页源码 ctrl+shit+c 查看网页源码 3. 复制框内的信息, 匹配一下: Paper = soup.find('div',{'class':&quot;right-item news-flash-box&quot;})## 检查一下print(Paper.get_text()) 就这么简单2333 4. 获取快讯文字链接 ## 检查一下print(soup.find('div',{'class':&quot;right-item news-flash-box&quot;}).get_text())##获得快讯文字的链接Links = Paper.find_all(&quot;a&quot;, {&quot;href&quot;: re.compile('http://..*?\\.html')})for link in Links: print(link['href']) # pic locationg 成功获得快讯文字的链接 5. 以第一篇为模板进行文章抓取 url = Links[1]['href']html = urlopen(url).read()soup = BeautifulSoup(html, features='lxml') 6. 继续查看码源, 获取标题和文字格式 发现,标题的标签为: &lt;br /&gt;&lt;h1 class=&quot;ph&quot; 文章主题标签为: &lt;br /&gt;&lt;div class=&quot;d&quot;&gt; 则,代码如下 P_title = soup.find('div',{&quot;class&quot;:&quot;h hm cl&quot;}).get_text()P_body = soup.find('td',{&quot;id&quot;:&quot;article_content&quot;}).get_text() 这就成功啦 7. 整合一下,并且, 循环抓取本小模块的所有paper from bs4 import BeautifulSoupfrom urllib.request import urlopenimport reimport requests## Starting resuqesthtml = urlopen(&quot;http://www.citreport.com/&quot;).read()soup = BeautifulSoup(html, features='lxml')Paper = soup.find('div',{'class':&quot;right-item news-flash-box&quot;})Links = Paper.find_all(&quot;a&quot;, {&quot;href&quot;: re.compile('http://..*?\\.html')})Paper = Paper.get_text()for link in Links: url = link['href'] html = urlopen(url).read() soup = BeautifulSoup(html, features='lxml') P_title = soup.find('div',{&quot;class&quot;:&quot;h hm cl&quot;}).get_text() P_body = soup.find('td',{&quot;id&quot;:&quot;article_content&quot;}).get_text() Paper += P_title + P_bodyprint(Paper) 2 NPR News Head Line from bs4 import BeautifulSoupimport requestsfrom urllib.request import urlopenimport timeurl= &quot;https://www.npr.org/&quot;html = urlopen(url).read().decode('utf-8')soup = BeautifulSoup(html, 'lxml')story_today = soup.find_all('div',{&quot;class&quot;:&quot;story-wrap&quot;})HeadLine =&quot;&quot;for i in story_today: HeadLine += i.get_text() 3. 爬取B站空间主页信息 参考: https://zhuanlan.zhihu.com/p/34716924 import astfrom urllib.request import urlopenimport timeID = &quot;86328254&quot;url = &quot;http://api.bilibili.com/archive_stat/stat?aid=&quot; + IDhtml = urlopen(url).read().decode('utf-8')d = ast.literal_eval(html)Cont = d['data']View = &quot;观看量: &quot; + str(Cont['view'])Like = &quot;点赞: &quot; + str(Cont['like'])Reply = &quot;回复: &quot; + str(Cont['reply'])Coin = &quot;硬币: &quot; + str(Cont['coin'])Result = &quot;\\n&quot;.join([View, Like, Reply, Coin])print(Result)","link":"/2020/12/13/Blog/Python-crawl_news/"},{"title":"Python- IP 地址转地址信息","text":"Python- IP 地址转地址信息 最近看看服務器的/var/log/secure文件發現, 每天居然都收到了好幾千的攻擊 . 抱着好奇的心態, 我想統計一下攻擊都來自哪裏. 因此寫一個跑一趟hon腳本, 畫個地圖. 1. 網站 “https://cn.bing.com/search?mkt=zh-cn&amp;h_IpInput=ctxtb&amp;q=59.173.18.251&amp;submit=查询” 網站查詢方便, 不僅告訴你歸屬地, 還可以告訴你運營商. import sysfrom bs4 import BeautifulSoupfrom urllib.request import urlopen## Starting resuqestdef IP_get(IP): url = &quot;https://ipchaxun.com/&quot;+ IP +&quot;/&quot; Cookies = { &quot;Accept&quot;: &quot;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3&quot;, &quot;Accept-Encoding&quot;: &quot;gzip, deflate, br&quot;, &quot;Accept-Language&quot;: &quot;en-CN,en;q=0.9,zh-CN;q=0.8,zh;q=0.7,en-US;q=0.6&quot;, &quot;Connection&quot;: &quot;keep-alive&quot;, &quot;Cookie&quot;: &quot;PHPSESSID=t9dsgluabl4hs1vnneog2fi91d; Hm_lvt_22d5503e9164951ac850495fe15447a7=1588438128; Hm_lpvt_22d5503e9164951ac850495fe15447a7=1588438769&quot;, &quot;Host&quot;: &quot;ipchaxun.com&quot;, &quot;Referer&quot;: url, &quot;Upgrade-Insecure-Requests&quot;: &quot;1&quot;, &quot;User-Agent&quot;: &quot;Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/11.0 Mobile/15A372 Safari/604.1&quot; } res = requests.get(url, headers=Cookies, timeout=30) # 设置页面编码格式 res.encoding = &quot;utf-8&quot; soup = BeautifulSoup(res.text, &quot;html.parser&quot;) Location = soup.find_all(&quot;label&quot;)[-2].get_text().split(&quot;：&quot;)[-1].replace(&quot;\\n&quot;,&quot;&quot;) Suplyer = soup.find_all(&quot;label&quot;)[-1].get_text().split(&quot;：&quot;)[-1].replace(&quot;\\n&quot;,&quot;&quot;) return IP, Location, SuplyerIPlist = open(&quot;TB_IP&quot;,'r').read().split(&quot;\\n&quot;)[:-1]Result = []for i in IPlist: A,B,C = IP_get(i) print(&quot;\\t&quot;.join([A,B,C])) Result += [&quot;\\t&quot;.join([A,B,C])]F = open(&quot;IP_location&quot;,&quot;w&quot;)F.write(&quot;\\n&quot;.join(Result))F.close()","link":"/2020/10/25/Blog/Python_IP_Loc/"},{"title":"用Python下载高中教材","text":"如何用python爬蟲獲取高中教材 目標網頁: http://www.100.com/article/309299.html(已失效) 點擊網頁， 可知， 目標圖片的結構爲: &lt;p style=&quot;text-align:center&quot;&gt; &lt;img id=&quot;99770&quot; src=&quot;http://edu_img.bs2.100.com/b31c5369425c1c5203b2437.jpg&quot; alt=&quot;bb09f673355c1c4ff92c54c.jpg&quot; /&gt;&lt;/p&gt; from bs4 import BeautifulSoupfrom urllib.request import urlopenimport requests## Function for downloadingdef page_download(image_name,r): try: with open('./img/%s' % image_name, 'wb') as f: for chunk in r.iter_content(chunk_size=128): f.write(chunk) except: print(&quot;missing&quot;)## Starting resuqestulr = &quot;http://www.100.com/article/309299.html?&amp;display=w&amp;fd=wap&quot;html = urlopen(ulr).read().decode('utf-8')soup = BeautifulSoup(html, features='lxml')Book_list = soup.findAll('p',{&quot;style&quot;:&quot;text-align:center&quot;})Num = 0for link in Book_list: try: Num += 1 url = link.find('img')['src'] r = requests.get(url, stream=True) image_name = str(Num)+'.jpg' page_download(image_name,r) print('Saved %s' % image_name) except: print(&quot;Missing&quot;) 壓縮成單個pdf sudo pip3.7 install -i https://pypi.tuna.tsinghua.edu.cn/simple img2pdfimg2pdf $(ls | sort -n) -o ../Biology1.pdf 完成～ 注: 有的網頁， 可能不一樣。 比如生物必修二就在匹配的時候， 多了一個分號， 因此， 要改成：Book_list = soup.findAll('p',{&quot;style&quot;:&quot;text-align:center;&quot;}) enjoy~","link":"/2020/07/17/Blog/Python_cw_book/"},{"title":"Analyzing DNA&#x2F;Protein Band with Opencv, Python","text":"Analyzing DNA/Protein Band with Opencv, Python Before starting: You can find some fundamental codes of Opencv at: My Blog You can also find the image img1.tif at My GitHub Loading img import numpy as npimport cv2img = cv2.imread('img/img1.tif',0)while(True): cv2.imshow('image',img) if cv2.waitKey(1) &amp; 0xFF == ord('q'): cv2.destroyAllWindows() break Selecting the Bands def Draw_rect(img, X,Y,width=100,height=50): # This function is for plot an rectangle by giving perimeters ptLeftTop = (X, Y) ptRightBottom = (X+width, Y+height) point_color = (0, 0, 255) # BGR thickness = 2 lineType = 8 img = cv2.rectangle(img, ptLeftTop, ptRightBottom, point_color, thickness, lineType) return imgdef Rect_listP(img,List,W,H): # This function is for plot a group of equality rectangles by giving perimeters for i in List: img = Draw_rect(img,i[0],i[1],W,H) return imgdef List_M(X1, X2, Y, Num): Result = [] Inter = int((X2-X1)/Num) for i in range(Num): Result += [[X1+i*Inter,Y]] return Resultdef Band_list(List,W,H): # Create The list for the Bands Result = [] for i in List: Result += [[i[0],i[1],W,H]] return Result Targeting the Bands import numpy as npimport cv2img = cv2.imread('img/img1.tif',0)X1, X2, Y, Num, W, H = (275,1985,280,10, 170, 70)img = Rect_listP(img,List_M(X1, X2, Y, Num),W,H)while(True): cv2.imshow('image',img) if cv2.waitKey(1) &amp; 0xFF == ord('q'): cv2.destroyAllWindows() break Result: Calculating the Grey-Grades Bands = Band_list( List_M(X1, X2, Y, Num),W,H)for i in Bands:img = cv2.imread('img/img1.tif',0)X1, X2, Y, Num = (275,1985,280,10)##img = Rect_listP(img,List_M(X1, X2, Y, Num),170,70)Grey = []N_tmp = 0for i in Bands: N_tmp += 1 img2 = img[i[1]:i[1]+H,i[0]:i[0]+W] # Saving the sliced bands cv2.imwrite(&quot;bands_&quot;+str(N_tmp)+'.png',img2) Grey += [img2.sum()]print(Grey) Result: [2317178, 2927580, 2033594, 2125166, 2420660, 2427925, 2370562, 2135051, 1559149, 1549062] library(ggplot2)TB = c(2317178, 2927580, 2033594, 2125166, 2420660, 2427925, 2370562, 2135051, 1559149, 1549062)TB = abs(TB[2] - TB)A = data.frame(TB)A$ID = factor(row.names(A),levels = c(1:10))ggplot(A,aes(ID,TB)) + geom_bar(stat = 'identity') BiliBili：史上最不正經的生物狗","link":"/2020/12/13/Blog/Python_WBA/"},{"title":"Python 下载html 为PDF, 再转成PNG","text":"Python 下载html 为PDF, 再转成PNG html ot PDF: https://www.jb51.net/article/160638.htmPDF to PNG: https://cloud.tencent.com/developer/article/1481641 ##!/usr/bin/env python3import pdfkit, sysimport sys, fitzimport osimport datetimePATH = sys.path[0]print(PATH)pdfkit.from_url('https://www.nature.com/subjects/biological-sciences', PATH+'/out.pdf')def pyMuPDF2_fitz(pdfPath, imagePath): pdfDoc = fitz.open(pdfPath) # open document for pg in range(pdfDoc.pageCount): # iterate through the pages page = pdfDoc[pg] rotate = int(0) # 每个尺寸的缩放系数为1.3，这将为我们生成分辨率提高2.6的图像 # 此处若是不做设置，默认图片大小为：792X612, dpi=96 zoom_x = 1.33333333 #(1.33333333--&gt;1056x816) (2--&gt;1584x1224) zoom_y = 1.33333333 mat = fitz.Matrix(zoom_x, zoom_y).preRotate(rotate) # 缩放系数1.3在每个维度 .preRotate(rotate)是执行一个旋转 rect = page.rect # 页面大小 mp = rect.tl + (rect.bl - (0,1224/zoom_x)) # 矩形区域 56=75/1.3333 clip = fitz.Rect(mp, rect.br) # 想要截取的区域 pix = page.getPixmap(matrix=mat, alpha=False, clip=clip) # 将页面转换为图像 if not os.path.exists(imagePath): os.makedirs(imagePath) pix.writePNG(imagePath+'/'+'psReport_%s.png' % pg)# store image as a PNGif __name__ == &quot;__main__&quot;: pdfPath = PATH+'/out.pdf' imagePath = PATH+'/../Nature' #pyMuPDF_fitz(pdfPath, imagePath)#只是转换图片 pyMuPDF2_fitz(pdfPath, imagePath)#指定想要的区域转换成图片","link":"/2020/07/17/Blog/Python_down_ht2pdf2png/"},{"title":"用R语言来指导实验","text":"我居然用R语言来指导实验点样顺序和位置 96孔板大家都熟悉吧, 如果样孔都一样量, 用排枪, 刷刷刷的, 就结束了, 超级方便. 可是就怕, 不同孔, 不同样本, 还不同的量. 这就, 非常恼火了. 加的慢不说, 还容易搞错, 加到, 怀疑人生 事情是这样子的。 入职了一家测序公司, 在测序之前, BDT反应要根据客户模板的个人情况点样. 可是, 客户多, 且杂, 所以我就要 不同客户模板 引物浓度不一样 有的单个样本重复使用, 用不同引物测 有很多通用引物, 前后都用 更具不同引物, 加不同浓度对应的水 一开始, 我想象着, 一个高级的, AR交互软件, 告诉你哪个孔加哪个样, 加多少, 然后判断是否已完成. 算了, 还是想想把… 那, 普通交互软件, 开始加水, 点一软件, 同浓度水的样孔, 高亮显示? 可是我不会呀, 用QT? TK? 好像可以, 可是没有项目经验呀… 最后, 好吧, 用R语言画图吧. 96孔板是吧, 热图正好. (理想很丰满, 显示很骨感 = =) 公司的系统还是不错的, 点样可以直接导出excel表格. 因此, 直接用library(readxl) 读取excel. 画图, 就用pheatmap, 简单方便. 中文字体库, 用 library(showtext) 格式由于涉密, 就不展示出来了. 看看处理结果把: 让我们来看图吧 第一步, 加水: 像这样, 根据对应高亮孔, 加2ul水, 就好 第二步, 引物: 最开始就用觉得引物太麻烦, 想这个样子, 前面用了, 后面还要用. 对照打印的表格来看, 就太麻烦了. 现在, 在加 B9 的时候, 就可以很明显的发现, C 也需要也需要加, 并且, D 也需要. 这就减少了, 重复找一个通用引物的麻烦 第三步, 模板: 有时候, 模板前后都得加, 比如第一个在 A 行, 第二次加就跳到 E 行, 有这个图, 就会方便很多 总结: 优点: 清楚明了, 防止前后重复找一个东西. 还是蛮有意思的. 有了这个小脚本, 我的加样时间, 大大缩短了. 缺点: 一次生成图片太多… 样本乱的时候, 可以生成上百张图片. 每次手动翻下一张图片, 还是不方便的.","link":"/2020/09/03/Blog/R_Plate_tricks/"},{"title":"用python寫一個B站彈幕聊天機器人腳本","text":"用python寫一個B站彈幕聊天機器人腳本 1 回覆B站彈幕基本框架: (當時bing出來抄人家的, 能用- -但是忘記表明出處了, 實在是抱歉- -) ##!/usr/bin/env python3.7import requests, sys #网络请求##Cookies = &quot;LIVE_BUVID=AUTO3715382739921424; buvid3=71AC02C7-EF25-46A5-9A2F-DB1CB10744F71607infoc; rpdid=oopmqlpqkmdoskqimpwww; stardustvideo=1; CURRENT_FNVAL=16; dssid=8aabde0ff0f7f1621; dsess=BAh7CkkiD3Nlc3Npb25faWQGOgZFVEkiFWRlMGZmMGY3ZjE2MjE3MWMGOwBG%0ASSIJY3NyZgY7AEZJIiUxYTM3YTg4MTY2NzZhNWZkNjYyODAyOWQwODk1NTlh%0AMgY7AEZJIg10cmFja2luZwY7AEZ7B0kiFEhUVFBfVVNFUl9BR0VOVAY7AFRJ%0AIi1lZjFkZjRjZTdiMWE2Y2JkZmQyZjRkMzA2OGYyMGI0NzhjYjU1OGEzBjsA%0ARkkiGUhUVFBfQUNDRVBUX0xBTkdVQUdFBjsAVEkiLWRkMDY1ZWQyNjNjNjdk%0ANzk5Zjk0M2FiNmMzOWI1NWM1ZTAwOGNiYjUGOwBGSSIKY3RpbWUGOwBGbCsH%0Aj3a9W0kiCGNpcAY7AEYiEjY4LjEwNy4xMjQuNTM%3D%0A--b5b62086b230a085ae65aee9304d7f14ca8a07ad; fts=1539143396; CURRENT_QUALITY=64; _uuid=547F11BE-9B64-40CC-37DE-6B95B010429C05405infoc; INTVER=1; sid=9onpe38s; DedeUserID=393056819; DedeUserID__ckMd5=43771d91224c7285; SESSDATA=d1486084%2C1576633926%2Ca277c9b1; bili_jct=b29db4670b4f9967fb2921a0fc878950; UM_distinctid=16e7c3622401e-01fbe0ab154c45-76256753-1fa400-16e7c362241181; laboratory=1-1&quot;def B_send(MSG): Cookies = &quot;LIVE_BUVID=AUTO5015807896693605; _uuid=58C69C39-C741-47C7-0E98-A379326816DE70318infoc; buvid3=3B00857F-A757-4982-9792-4B46DEC0BB12155821infoc; sid=bejf3qns; LIVE_ROOM_ADMIN_UP_TIP=1; CURRENT_FNVAL=16; rpdid=|(k|k)k|))Y)0J'ul)|~mYmk|; im_notify_type_393056819=0; _ga=GA1.2.517604625.1581950019; dy_spec_agreed=1; GIFT_BLOCK_COOKIE=GIFT_BLOCK_COOKIE; INTVER=1; stardustpgcv=0606; DedeUserID=393056819; DedeUserID__ckMd5=43771d91224c7285; SESSDATA=bb15b3a2%2C1598937340%2C37fab*31; bili_jct=e8377d560fe3434ffd36531d323df842; CURRENT_QUALITY=80; bp_t_offset_393056819=365856292215780322; _dfcaptcha=08c1c131463a58b5c74c50f3d9eaed6d; Hm_lvt_8a6e55dbd2870f0f5bc9194cddf32a02=1583825216,1583853309,1583925148,1584087368; Hm_lpvt_8a6e55dbd2870f0f5bc9194cddf32a02=1584087368; PVID=15&quot; cookie = {'Cookie': Cookies} data = { 'color':'16777215', 'fontsize':'25', 'mode':'1', 'msg':MSG, 'rnd':'1584087359', 'roomid':'21154895', 'bubble':'0', 'aid':'56737027', 'csrf_token':'e8377d560fe3434ffd36531d323df842', 'csrf':'e8377d560fe3434ffd36531d323df842' } requests.post('https://api.live.bilibili.com/msg/send', cookies=cookie, data=data)##senddanmu.sendDM(data) #&lt;Response [200]&gt; 200是状态码 表示pass 獲取cookies 方法見視屏:…[還沒上傳] 2 獲取彈幕的方法: 用github的項目吧, xfgryujk/blivedm這是我已知的, 最好的彈幕獲取項目 git clone https://github.com/xfgryujk/blivedm.git 3 聊天模塊 用: https://blog.csdn.net/qq_29129381/article/details/82865617這個是最簡單的抄來的代碼~, 感謝青云客智能聊天机器人的奉獻~ class airoot(object): #This function is original from:https://blog.csdn.net/qq_29129381/article/details/82865617 def __init__(self): self.url = r'http://api.qingyunke.com/api.php?%s' self.data = { 'key':'free', 'appid':0, 'msg':'' } def getword(self, word=''): self.data['msg'] = word if self.data['msg'] == '': self.data['msg'] = '你不说话, 我来撩你吧' self.params = urllib.parse.urlencode(self.data) self.url = self.url % self.params self.page = urllib.request.urlopen(self.url,timeout=15).read() self.res = json.loads(self.page) self.res['content'] = self.res['content'].replace('{br}',' ') return self.res 4 在blivedm裏面, 加入聊天機器人的代碼 修改sample.py 把client ID改成要回覆彈幕的ID async def _on_receive_danmaku(self, danmaku: blivedm.DanmakuMessage): print(f'{danmaku.uname}：{danmaku.msg}') 這兩行是彈幕, 直接用後面的{danmaku.msg}就好,這裏, 我們改成 async def _on_receive_danmaku(self, danmaku: blivedm.DanmakuMessage): print(f'{danmaku.uname}：{danmaku.msg}') if f'{danmaku.uname}' != &quot;史上最不正經的生物狗&quot;:#這裏是我的名字, 不把自己排除, 會自己套娃, 無限自嗨的= = B_send(airoot().getword(str(f'{danmaku.msg}'))['content']) 彈幕分割 因爲普通人員, 一個彈幕只能發20個字節, 字數多了, 會自動忽略, 所以需要分割分佈發送 def B_Slice(MSG): for i in range((len(MSG)//20)+1): B_send(MSG[i*20:(i+1)*20]) 把分割套進去 async def _on_receive_danmaku(self, danmaku: blivedm.DanmakuMessage): print(f'{danmaku.uname}：{danmaku.msg}') if f'{danmaku.uname}' != &quot;史上最不正經的生物狗&quot;: B_Slice(airoot().getword(str(f'{danmaku.msg}'))['content']) 鏈接超時 發現經常連接超時, 然後卡在了那裏. 我設置了一個timeout=15, 在前面, 已更新後面老地方, 加一個try async def _on_receive_danmaku(self, danmaku: blivedm.DanmakuMessage): print(f'{danmaku.uname}：{danmaku.msg}') if f'{danmaku.uname}' != &quot;史上最不正經的生物狗&quot;: try: MSG = airoot().getword(str(f'{danmaku.msg}'))['content'] except: MSG = &quot;鏈接超時了 = =(自動回覆)&quot; B_Slice(MSG) 发送太快而被吞 加一个1s延迟,发送弹幕过多的时候 def B_Slice(MSG): for i in range((len(MSG)//20)+1): B_send(MSG[i*20:(i+1)*20]) time.sleep(1) 娛樂而已, 應該不會載更新了, /摔板凳 Sample.py ## -*- coding: utf-8 -*-import asyncio,requests, sys, timeimport urllib.requestimport urllib.parseimport jsonimport blivedmclass MyBLiveClient(blivedm.BLiveClient): # 演示如何自定义handler _COMMAND_HANDLERS = blivedm.BLiveClient._COMMAND_HANDLERS.copy() async def __on_vip_enter(self, command): print(command) _COMMAND_HANDLERS['WELCOME'] = __on_vip_enter # 老爷入场 async def _on_receive_popularity(self, popularity: int): #print(f'当前人气值：{popularity}') AAAAAAAA = 1 async def _on_receive_danmaku(self, danmaku: blivedm.DanmakuMessage): print(f'{danmaku.uname}：{danmaku.msg}') if f'{danmaku.uname}' != &quot;史上最不正經的生物狗&quot;: try: MSG = airoot().getword(str(f'{danmaku.msg}'))['content'] except: MSG = &quot;鏈接超時了 = =(自動回覆)&quot; B_Slice(MSG) async def _on_receive_gift(self, gift: blivedm.GiftMessage): print(f'{gift.uname} 赠送{gift.gift_name}x{gift.num} （{gift.coin_type}币x{gift.total_coin}）') async def _on_buy_guard(self, message: blivedm.GuardBuyMessage): print(f'{message.username} 购买{message.gift_name}') async def _on_super_chat(self, message: blivedm.SuperChatMessage): print(f'醒目留言 ¥{message.price} {message.uname}：{message.message}')class airoot(object): #This function is original from:https://blog.csdn.net/qq_29129381/article/details/82865617 def __init__(self): self.url = r'http://api.qingyunke.com/api.php?%s' self.data = { 'key':'free', 'appid':0, 'msg':'' } def getword(self, word=''): self.data['msg'] = word if self.data['msg'] == '': self.data['msg'] = '你不说话, 我来撩你吧' self.params = urllib.parse.urlencode(self.data) self.url = self.url % self.params self.page = urllib.request.urlopen(self.url,timeout=15).read() self.res = json.loads(self.page) self.res['content'] = self.res['content'].replace('{br}',' ') return self.resdef B_send(MSG): Cookies = &quot;&quot;#自己的 cookie = {'Cookie': Cookies} data = { 'color':'16777215', 'fontsize':'25', 'mode':'1', 'msg':MSG, 'rnd':'1584087359', 'roomid':'21154895', 'bubble':'0', 'aid':'56737027', 'csrf_token':'e8377d560fe3434ffd36531d323df842', 'csrf':'e8377d560fe3434ffd36531d323df842' } requests.post('https://api.live.bilibili.com/msg/send', cookies=cookie, data=data)##senddanmu.sendDM(data) #&lt;Response [200]&gt; 200是状态码 表示passdef B_Slice(MSG): for i in range((len(MSG)//20)+1): B_send(MSG[i*20:(i+1)*20]) time.sleep(1)async def main(): # 参数1是直播间ID # 如果SSL验证失败就把ssl设为False client = MyBLiveClient(21154895, ssl=True) future = client.start() try: # 5秒后停止，测试用 # await asyncio.sleep(5) # future = client.stop() # 或者 # future.cancel() await future finally: await client.close()if __name__ == '__main__': asyncio.get_event_loop().run_until_complete(main()) 用戶自主開啓關閉機器人 有時候機器人實在是太煩了, 簡直煩到想取關這裏, 我們可以添加一個屏蔽名單, 並用簡單的命令判斷,讓發彈幕的人, 自主選擇, 打開或者關閉機器人回答爲了長久有效, 我們最好是, 把這個名單存入本地文件. 這裏, 取名IgnoreList,我直接把他放進同樣的路徑, 方便讀取. def IgnoreList(USER,MSG): Ignore_List = open(sys.path[0]+&quot;/IgnoreList&quot;,'r').read().split(&quot;\\n&quot;)[:-1] # 設定屏蔽規則 if str(MSG) == &quot;菲菲辛苦啦~&quot;: B_Slice(&quot;好的,菲菲先行告退了,愛你呦,木木噠~&quot;) Ignore_List += [USER] elif str(MSG) == &quot;菲菲快回來~&quot;: try: Ignore_List.remove(USER) except: B_Slice(&quot;你一直都在菲菲心里哟~&quot;) Update = &quot;\\n&quot;.join(Ignore_List)+&quot;\\n&quot; F = open(sys.path[0]+&quot;/IgnoreList&quot;,'w') F.write(Update) F.close() return Ignore_List 防沉迷程序 爲了防止惡意刷屏,或者過於小盆友沉迷而耽誤學習, 因此在學習/工作時間內, 限制每分鐘內響應次數. 若超過, 則忽視多少分鐘時間設定在早上9點,到晚上9點之間 Bubling_List = {}Bubling_ban = {}def ToBubling_detect(User,Bubling_List,Bubling_ban,Times,TimeOut): Times -=1 if User != '史上最不正經的生物狗' and User not in Bubling_ban.keys(): if User not in Bubling_List.keys(): Bubling_List.update({User:{'Time': time.time(), 'Num': 1}}) else: Time_endur = time.time() - Bubling_List[User]['Time'] if Time_endur &lt; 60 and Bubling_List[User]['Num'] &gt; Times: Bubling_ban.update({User:time.time()}) B_Slice(User+&quot; 因調戲菲菲過於頻繁,而被選擇性忽略5min, 略略略~&quot;) Bubling_List[User]['Num'] = 0 Bubling_List[User]['Time'] = time.time() elif Time_endur &lt; 60 and Bubling_List[User]['Num'] &lt;= Times: Bubling_List[User]['Num'] +=1 else: Bubling_List[User]['Num'] =1 Bubling_List[User]['Time'] = time.time() try: if time.time() - Bubling_ban[User] &gt; TimeOut*60: Bubling_ban.pop(User) except Exception as e: Bubling_ban = Bubling_ban return Bubling_List, Bubling_ban 到此, 全程序爲: (自己加cookies) ## -*- coding: utf-8 -*-import asyncio,requests, sys, timeimport urllib.requestimport urllib.parseimport jsonimport blivedmclass MyBLiveClient(blivedm.BLiveClient): # 演示如何自定义handler _COMMAND_HANDLERS = blivedm.BLiveClient._COMMAND_HANDLERS.copy() async def __on_vip_enter(self, command): print(command) _COMMAND_HANDLERS['WELCOME'] = __on_vip_enter # 老爷入场 async def _on_receive_popularity(self, popularity: int): #print(f'当前人气值：{popularity}') AAAAAAAA = 1 async def _on_receive_danmaku(self, danmaku: blivedm.DanmakuMessage): global Bubling_List, Bubling_ban print(f'{danmaku.uname}：{danmaku.msg}') # Bubuling test Bubling_List, Bubling_ban = ToBubling_detect(f'{danmaku.uname}',Bubling_List,Bubling_ban,10,5) # IgnoreList Ignore_List = IgnoreList(f'{danmaku.uname}',f'{danmaku.msg}') Ignore_List += list(Bubling_ban.keys()) #print(Ignore_List) #print(Bubling_List) if f'{danmaku.uname}' not in Ignore_List: try: MSG = airoot().getword(str(f'{danmaku.msg}'))['content'] except: MSG = &quot;鏈接超時了 = =(自動回覆)&quot; B_Slice(MSG) async def _on_receive_gift(self, gift: blivedm.GiftMessage): print(f'{gift.uname} 赠送{gift.gift_name}x{gift.num} （{gift.coin_type}币x{gift.total_coin}）') B_Slice(str(f'谢谢{gift.uname} 赠送的{gift.gift_name}')) async def _on_buy_guard(self, message: blivedm.GuardBuyMessage): print(f'{message.username} 购买{message.gift_name}') async def _on_super_chat(self, message: blivedm.SuperChatMessage): print(f'醒目留言 ¥{message.price} {message.uname}：{message.message}')class airoot(object): #This function is original from:https://blog.csdn.net/qq_29129381/article/details/82865617 def __init__(self): self.url = r'http://api.qingyunke.com/api.php?%s' self.data = { 'key':'free', 'appid':0, 'msg':'' } def getword(self, word=''): self.data['msg'] = word if self.data['msg'] == '': self.data['msg'] = '你不说话, 我来撩你吧' self.params = urllib.parse.urlencode(self.data) self.url = self.url % self.params self.page = urllib.request.urlopen(self.url,timeout=20).read() self.res = json.loads(self.page) self.res['content'] = self.res['content'].replace('{br}',' ') return self.resdef IgnoreList(USER,MSG): Ignore_List = open(sys.path[0]+&quot;/IgnoreList&quot;,'r').read().split(&quot;\\n&quot;)[:-1] # 設定屏蔽規則 if str(MSG) == &quot;菲菲辛苦啦~&quot;: B_Slice(&quot;好的,菲菲先行告退了,愛你呦,木木噠~&quot;) Ignore_List += [USER] elif str(MSG) == &quot;菲菲快回來~&quot;: try: Ignore_List.remove(USER) except: B_Slice(&quot;你一直都在菲菲心里哟~&quot;) Update = &quot;\\n&quot;.join(Ignore_List)+&quot;\\n&quot; F = open(sys.path[0]+&quot;/IgnoreList&quot;,'w') F.write(Update) F.close() return Ignore_Listdef B_send(MSG): Cookies = &quot;&quot; cookie = {'Cookie': Cookies} data = { 'color':'16777215', 'fontsize':'25', 'mode':'1', 'msg':MSG, 'rnd':'1584087359', 'roomid': str(ROOM_ID), 'bubble':'0', 'aid':'56737027', 'csrf_token':'e8377d560fe3434ffd36531d323df842', 'csrf':'e8377d560fe3434ffd36531d323df842' } requests.post('https://api.live.bilibili.com/msg/send', cookies=cookie, data=data)##senddanmu.sendDM(data) #&lt;Response [200]&gt; 200是状态码 表示passBubling_List = {}Bubling_ban = {}def ToBubling_detect(User,Bubling_List,Bubling_ban,Times,TimeOut): Times -=1 if User != '史上最不正經的生物狗' and User not in Bubling_ban.keys(): if User not in Bubling_List.keys(): Bubling_List.update({User:{'Time': time.time(), 'Num': 1}}) else: Time_endur = time.time() - Bubling_List[User]['Time'] if Time_endur &lt; 60 and Bubling_List[User]['Num'] &gt; Times: Bubling_ban.update({User:time.time()}) B_Slice(User+&quot; 因調戲菲菲過於頻繁,而被選擇性忽略5min, 略略略~&quot;) Bubling_List[User]['Num'] = 0 Bubling_List[User]['Time'] = time.time() elif Time_endur &lt; 60 and Bubling_List[User]['Num'] &lt;= Times: Bubling_List[User]['Num'] +=1 else: Bubling_List[User]['Num'] =1 Bubling_List[User]['Time'] = time.time() try: if time.time() - Bubling_ban[User] &gt; TimeOut*60: Bubling_ban.pop(User) except Exception as e: Bubling_ban = Bubling_ban return Bubling_List, Bubling_banROOM_ID = 21154895def B_Slice(MSG): for i in range((len(MSG)//20)+1): B_send(MSG[i*20:(i+1)*20]) time.sleep(1)async def main(): # 参数1是直播间ID # 如果SSL验证失败就把ssl设为False client = MyBLiveClient(ROOM_ID, ssl=True) future = client.start() try: # 5秒后停止，测试用 # await asyncio.sleep(5) # future = client.stop() # 或者 # future.cancel() await future finally: await client.close()if __name__ == '__main__': asyncio.get_event_loop().run_until_complete(main())","link":"/2020/10/25/Blog/Python_Bilibot/"},{"title":"XGboost With R","text":"XGboost With R Documentation: Tutorial Brief Introduction: Xgboost (eXtreme Gradient Boosting) linear model ; tree learning algorithm. it supports various objective functions, including regression, classification and ranking. Install install.packages(&quot;drat&quot;)install.packages(&quot;xgboost&quot;) Quick Start Test Data Just as all Machine algorithms, we need the training data set and testing data set. In real world, caret can help to split the training and testing data set. library(&quot;drat&quot;)library(&quot;xgboost&quot;)data(agaricus.train, package='xgboost')data(agaricus.test, package='xgboost')train &lt;- agaricus.traintest &lt;- agaricus.test ## Have a quick Lookstr(train) List of 2 $ data :Formal class 'dgCMatrix' [package \"Matrix\"] with 6 slots .. ..@ i : int [1:143286] 2 6 8 11 18 20 21 24 28 32 ... .. ..@ p : int [1:127] 0 369 372 3306 5845 6489 6513 8380 8384 10991 ... .. ..@ Dim : int [1:2] 6513 126 .. ..@ Dimnames:List of 2 .. .. ..$ : NULL .. .. ..$ : chr [1:126] \"cap-shape=bell\" \"cap-shape=conical\" \"cap-shape=convex\" \"cap-shape=flat\" ... .. ..@ x : num [1:143286] 1 1 1 1 1 1 1 1 1 1 ... .. ..@ factors : list() $ label: num [1:6513] 1 0 0 1 0 0 0 1 0 0 ... Here in our data set train, label is the outcome of what we’d like to predict. class(train$data) [1] \"dgCMatrix\" attr(,\"package\") [1] \"Matrix\" As seen below, the data are stored in a dgCMatrix which is a sparse matrix and label vector is a numeric vector ({0,1}): Quick Model bstSparse &lt;- xgboost(data = train$data, label = train$label, max.depth = 2, eta = 1, nthread = 2, nrounds = 2, objective = &quot;binary:logistic&quot;) [1] train-error:0.046522 [2] train-error:0.022263 objective = “binary:logistic”: we will train a binary classification model ; max.depth = 2: the trees won’t be deep, because our case is very simple ; nthread = 2: the number of cpu threads we are going to use; nrounds = 2: there will be two passes on the data, the second one will enhance the model by further reducing the difference between ground truth and prediction. Preparing Your Data Set We can preparing our data by turn matrix or attr matrix to xgb.Dmatrix dtrain &lt;- xgb.DMatrix(data = train$data, label = train$label)bstDMatrix &lt;- xgboost(data = dtrain, max.depth = 2, eta = 1, nthread = 2, nrounds = 2, objective = &quot;binary:logistic&quot;) Predict Now, Let’s so the utmost goal, Perform the prediction pred &lt;- predict(bstDMatrix, test$data)## Check The resultprint(data.frame(Pre=round(head(pred,10),4),Rel=head(test$label,10))) Pre Rel 1 0.2858 0 2 0.9239 1 3 0.2858 0 4 0.2858 0 5 0.0517 0 6 0.9239 0 7 0.9239 1 8 0.2858 0 9 0.9239 1 10 0.0107 0 As we can see, most of results are acceptable (except row 6th). Save your model ## save the trained modelxgb.DMatrix.save(dtrain, &quot;dtrain.buffer&quot;)## to load it in, simply call xgb.DMatrixdtrain2 &lt;- xgb.DMatrix(&quot;dtrain.buffer&quot;) feature importance xgb.importance(colnames(agaricus.train$data), model = bstDMatrix) Feature Gain Cover Frequency 1: odor=none 0.67615469 0.4978746 0.4 2: stalk-root=club 0.17135376 0.1920543 0.2 3: stalk-root=rooted 0.12317237 0.1638750 0.2 4: spore-print-color=green 0.02931918 0.1461960 0.2 pre { background-color:#38393d; color: #5fd381; }","link":"/2020/09/20/Blog/R_XGboost/"},{"title":"用Python 写一个日程表","text":"用Python 写一个日程表 依赖: urwid; 1 基本框架 main.py import urwiddef exit_on_q(key): if key in ('q', 'Q'): raise urwid.ExitMainLoop()palette = [ ('banner', 'black', 'light gray'), ('streak', 'black', 'dark red'), ('bg', 'black', 'dark blue'),]txt = urwid.Text(('banner', u&quot; Hello World &quot;), align='center')map1 = urwid.AttrMap(txt, 'streak')fill = urwid.Filler(map1)map2 = urwid.AttrMap(fill, 'bg')loop = urwid.MainLoop(map2, palette, unhandled_input=exit_on_q)loop.run() ToDolist 文本文件, 用tab分隔 语文 10 0数学 10 0英语 10 0 2 读取内容从ToDolist 加入下文的第一行, 并在上文的12行, 改成下文第二行 TODO = open(sys.path[0]+&quot;/ToDolist&quot;,'r').read()txt = urwid.Text(('banner', TODO), align='center') 当然, 这不是想要效果, 2333. 最好的是用numpy或者pandas来读成表格, matrix 的数据结构, 但是我不想为这么点点东西来费这么大的力气, 所以我就全用list了. def Read_ToDolsit(): TODO = open(sys.path[0]+&quot;/ToDolist&quot;,'r').read().split('\\n')[:-1] Result = [] for i in TODO: Result += [i.split()] return Result 这样, 之前的 open, 就直接改成 TODO = Read_ToDolsit() 输出的TODO变成了: [['语文', '10', '0'], ['数学', '10', '0'], ['英语', '10', '0']] 3 放入列表 写一个循环读取, 并放入columns, columns 叠入Pile def TODO_col(TODO): Column_list = [] for Sub in TODO: Sub_list = [] for i in Sub: Sub_list += [urwid.Text(i)] Column_list += [urwid.Columns(Sub_list)] A = urwid.Pile(Column_list) return A 这样的话, 自动读取结果就是: 增加修改按钮: 如何做到按钮对应每一列的操作, 我想的解决方案是,按钮直接操作ToDolist, 然后刷新整个页面. 反正都是小文本, 整个过程都是毫秒级的. 4 添加计数按钮 想了好久= = 么有好方法= =只好预写一堆的button signal 放在 另一个页面, 然后丢在list里面 调用= = 唉, 虽然蠢, 但是有效就好. 不管怎么样- - 反正, 我算是成功了- - 唉… 虽然代码很丑 这个时候的代码: (非常丑= =) ##!/usr/bin/env python3import urwid, sys, buttons## exit the programdef exit_on_q(key): if key in ('q', 'Q'): raise urwid.ExitMainLoop()'''bottons'''def bottons_1P(button): List = Read_ToDolsit() List[0][2] = str(int(List[0][2])+1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview() # loop.set_alarm_in(1,Setupview)def bottons_1M(button): List = Read_ToDolsit() List[0][2] = str(int(List[0][2])-1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_2P(button): List = Read_ToDolsit() List[1][2] = str(int(List[1][2])+1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_2M(button): List = Read_ToDolsit() List[1][2] = str(int(List[1][2])-1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_3P(button): List = Read_ToDolsit() List[2][2] = str(int(List[2][2])+1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_3M(button): List = Read_ToDolsit() List[2][2] = str(int(List[2][2])-1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_4P(button): List = Read_ToDolsit() List[3][2] = str(int(List[3][2])+1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_4M(button): List = Read_ToDolsit() List[3][2] = str(int(List[3][2])-1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_5P(button): List = Read_ToDolsit() List[4][2] = str(int(List[4][2])+1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_5M(button): List = Read_ToDolsit() List[4][2] = str(int(List[4][2])-1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_6P(button): List = Read_ToDolsit() List[5][2] = str(int(List[5][2])+1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_6M(button): List = Read_ToDolsit() List[5][2] = str(int(List[5][2])-1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_7P(button): List = Read_ToDolsit() List[6][2] = str(int(List[6][2])+1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_7M(button): List = Read_ToDolsit() List[6][2] = str(int(List[6][2])-1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_8P(button): List = Read_ToDolsit() List[7][2] = str(int(List[7][2])+1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_8M(button): List = Read_ToDolsit() List[7][2] = str(int(List[7][2])-1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_9P(button): List = Read_ToDolsit() List[8][2] = str(int(List[8][2])+1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_9M(button): List = Read_ToDolsit() List[8][2] = str(int(List[8][2])-1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()Botton_listP = [bottons_1P,bottons_2P,bottons_3P]Botton_listM = [bottons_1M,bottons_2M,bottons_3M]def bottons_resbond(a): TODO = Read_ToDolsit() fill = urwid.Filler(urwid.Pile([TODO_col(TODO),Fresh])) loop.widget = fill'''Botton is done'''def List2str(List): Result2 = &quot;&quot; for i in List: Result2 += '\\t'.join(i) + '\\n' return Result2## reading Task from ToDoListdef Read_ToDolsit(): TODO = open(sys.path[0]+&quot;/ToDolist&quot;,'r').read().split('\\n')[:-1] Result = [] for i in TODO: Result += [i.split()] return Result##bottons_resbond = bottons_resbond(&quot;P_line1&quot;)##A = urwid.Columns([urwid.Text(TODO[0][0]),urwid.Text(TODO[0][1]),urwid.Text(TODO[0][2])])##A = urwid.Pile([A,A])def TODO_col(TODO): Num = 0 Column_list = [] for Sub in TODO: Num += 1 Sub_list = [] for i in Sub: Sub_list += [urwid.Text(i)] # bottons: locals()[&quot;P_line&quot;+str(Num)]= urwid.Button(u'+') locals()[&quot;M_line&quot;+str(Num)]= urwid.Button(u'-') # resbond: urwid.connect_signal(locals()[&quot;P_line&quot;+str(Num)], 'click', Botton_listP[Num-1]) urwid.connect_signal(locals()[&quot;M_line&quot;+str(Num)], 'click', Botton_listM[Num-1]) # Sub_list += [locals()[&quot;P_line&quot;+str(Num)],locals()[&quot;M_line&quot;+str(Num)]] Column_list += [urwid.Columns(Sub_list)] A = urwid.Pile(Column_list) return Apalette = [ ('banner', 'black', 'light gray'), ('streak', 'black', 'dark red'), ('bg', 'black', 'dark blue'),]def Setupview(): TODO = Read_ToDolsit() #Fresh = urwid.Button('fresh') fill = urwid.Filler(TODO_col(TODO)) return fillTODO = Read_ToDolsit()fill = urwid.Filler(TODO_col(TODO))#Setupview()loop = urwid.MainLoop(fill, palette, unhandled_input=exit_on_q)loop.run() 5 将数字改成长条 我们把按钮左移, 然后加一个10个单位的进度条, 底色为红色 def Bar_line(Sub,Bar_Max=20): if int(Sub[2])&lt;= int(Sub[1]): Bar_G = int(int(Sub[2])*Bar_Max/int(Sub[1])) Bar_R = Bar_Max - Bar_G Bar_B = 0 elif int(Sub[2]) &gt; int(Sub[1]): Bar_G = Bar_Max-1 Bar_R = 1 Bar_B = int((int(Sub[2])-int(Sub[1]))*Bar_Max/int(Sub[1])) #print(int((int(Sub[2])-int(Sub[1]))*Bar_Max/int(Sub[1]))) Sub_bar = [('fixed',40,urwid.Text([('Green_BG', &quot; &quot;* Bar_G),('Red_BG', &quot; &quot;*Bar_R),('Blue_BG', &quot; &quot;*Bar_B)]))] return Sub_bar 到此, 最简单的日程表, 就已经做好啦! 完全代码: ##!/usr/bin/env python3import urwid, sys, buttons## exit the programdef exit_on_q(key): if key in ('q', 'Q'): raise urwid.ExitMainLoop()'''bottons'''def bottons_1P(button): List = Read_ToDolsit() List[0][2] = str(int(List[0][2])+1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview() # loop.set_alarm_in(1,Setupview)def bottons_1M(button): List = Read_ToDolsit() List[0][2] = str(int(List[0][2])-1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_2P(button): List = Read_ToDolsit() List[1][2] = str(int(List[1][2])+1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_2M(button): List = Read_ToDolsit() List[1][2] = str(int(List[1][2])-1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_3P(button): List = Read_ToDolsit() List[2][2] = str(int(List[2][2])+1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_3M(button): List = Read_ToDolsit() List[2][2] = str(int(List[2][2])-1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_4P(button): List = Read_ToDolsit() List[3][2] = str(int(List[3][2])+1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_4M(button): List = Read_ToDolsit() List[3][2] = str(int(List[3][2])-1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_5P(button): List = Read_ToDolsit() List[4][2] = str(int(List[4][2])+1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_5M(button): List = Read_ToDolsit() List[4][2] = str(int(List[4][2])-1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_6P(button): List = Read_ToDolsit() List[5][2] = str(int(List[5][2])+1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_6M(button): List = Read_ToDolsit() List[5][2] = str(int(List[5][2])-1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_7P(button): List = Read_ToDolsit() List[6][2] = str(int(List[6][2])+1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_7M(button): List = Read_ToDolsit() List[6][2] = str(int(List[6][2])-1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_8P(button): List = Read_ToDolsit() List[7][2] = str(int(List[7][2])+1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_8M(button): List = Read_ToDolsit() List[7][2] = str(int(List[7][2])-1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_9P(button): List = Read_ToDolsit() List[8][2] = str(int(List[8][2])+1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()def bottons_9M(button): List = Read_ToDolsit() List[8][2] = str(int(List[8][2])-1) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview()Botton_listP = [bottons_1P,bottons_2P,bottons_3P,bottons_4P,bottons_5P,bottons_6P,bottons_7P,bottons_8P,bottons_9P]Botton_listM = [bottons_1M,bottons_2M,bottons_3M,bottons_4M,bottons_5M,bottons_6M,bottons_7M,bottons_8M,bottons_9M]'''Botton is done'''def List2str(List): Result2 = &quot;&quot; for i in List: Result2 += '\\t'.join(i) + '\\n' return Result2## reading Task from ToDoListdef Read_ToDolsit(): TODO = open(sys.path[0]+&quot;/ToDolist&quot;,'r').read().split('\\n')[:-1] Result = [] for i in TODO: Result += [i.split()] return Resultdef Bar_line(Sub,Bar_Max=20): if int(Sub[2])&lt;= int(Sub[1]): Bar_G = int(int(Sub[2])*Bar_Max/int(Sub[1])) Bar_R = Bar_Max - Bar_G Bar_B = 0 elif int(Sub[2]) &gt; int(Sub[1]): Bar_G = Bar_Max-1 Bar_R = 1 Bar_B = int((int(Sub[2])-int(Sub[1]))*Bar_Max/int(Sub[1])) #print(int((int(Sub[2])-int(Sub[1]))*Bar_Max/int(Sub[1]))) Sub_bar = [('fixed',40,urwid.Text([('Green_BG', &quot; &quot;* Bar_G),('Red_BG', &quot; &quot;*Bar_R),('Blue_BG', &quot; &quot;*Bar_B)]))] return Sub_bardef TODO_col(TODO): Num = 0 Column_list = [] for Sub in TODO: Num += 1 Sub_list = [] for i in Sub: Sub_list += [urwid.Text(i)] # bottons: locals()[&quot;P_line&quot;+str(Num)]= urwid.Button(u'+') locals()[&quot;M_line&quot;+str(Num)]= urwid.Button(u'-') # resbond: urwid.connect_signal(locals()[&quot;P_line&quot;+str(Num)], 'click', Botton_listP[Num-1]) urwid.connect_signal(locals()[&quot;M_line&quot;+str(Num)], 'click', Botton_listM[Num-1]) # Sub_list = [('fixed',5,locals()[&quot;P_line&quot;+str(Num)]),('fixed',5,locals()[&quot;M_line&quot;+str(Num)])] + Sub_list # Bar determination: Sub_bar = Bar_line(Sub) Column_list += [urwid.Columns(Sub_list + Sub_bar)] A = urwid.Pile(Column_list) return Adef Setupview(): TODO = Read_ToDolsit() #Fresh = urwid.Button('fresh') fill = urwid.Filler(TODO_col(TODO)) return fillpalette = [ ('banner', 'black', 'light gray'), ('Red_BG', 'dark red', 'dark red'), ('Green_BG', 'dark green', 'dark green'), ('Blue_BG', 'dark blue', 'dark blue'), ('streak', 'black', 'dark red'), ('bg', 'black', 'dark blue'),]fill = Setupview()loop = urwid.MainLoop(fill, palette, unhandled_input=exit_on_q)loop.run() 6 加一個title＆ Clean 按鈕 def BigTxt(TXT): txt = urwid.BigText( ('banner',TXT), urwid.font.HalfBlock5x4Font()) view = urwid.Padding(txt, 'center', width='clip') view = urwid.AttrMap(view, 'Blue_BG') return view#urwid.Columns([view])def Button_C(): def Clean(botton): List = Read_ToDolsit() for i in List: i[2] = str(0) Str_list = List2str(List) F = open(sys.path[0]+&quot;/ToDolist&quot;,'w') F.write(Str_list) F.close() # refresh loop.widget = Setupview() Button_clean = urwid.Button(u&quot;Clear&quot;) urwid.connect_signal(Button_clean, 'click', Clean) return Button_clean Setview改一下: def Setupview(): Header = BigTxt(&quot;What's Next???&quot;) TODO = Read_ToDolsit() ToDOcol_list = TODO_col(TODO) Button_clean = Button_C() ToDoWidget = urwid.Pile([Header] + ToDOcol_list+[Button_clean]) fill = urwid.Filler(ToDoWidget) return fill","link":"/2020/12/13/Blog/Python_todolist/"},{"title":"用Python接收邮件和附件","text":"用Python接收邮件和附件 接收邮件的服务又好几种， 这里主要用到pop3 协议， 关于开通和，请看百度经验，获取授权码，点击这里基础脚本：https://www.yuque.com/liuwenkan/pwh0c8/qqmail_r 加入删除和查看上一封功能： 添加了一些小functions ## 从List中寻找匹配def grep(Str,List): for i in List: if Str in str(i): break return i## 汉字解码def Decode(STR): head = &quot;=?gb2312?b?&quot; tail = &quot;?=&quot; if head in STR: H = STR.find(head) + len(head) T = STR.find(tail) Result = base64.b64decode(STR[H:T]).decode(&quot;GBK&quot;) STR = STR[:H- len(head)] + Result + STR[T+ len(tail):] return STR## 读取邮件def M_read(index): resp, lines, octets = server.retr(index) try: Date= str(grep(&quot;b'Date:&quot;,lines)).replace(&quot;b'&quot;,'') msg_content = b'\\r\\n'.join(lines).decode('utf-8') msg = Parser().parsestr(msg_content) print_info(msg) print('\\n\\n'+Date) except: Date= str(grep(&quot;b'Date:&quot;,lines)).replace(&quot;b'&quot;,'') From= Decode(str(grep(&quot;b'From:&quot;,lines)).replace(&quot;b'&quot;,'')) To= Decode(str(grep(&quot;b'To:&quot;,lines)).replace(&quot;b'&quot;,'')) Subject= Decode(str(grep(&quot;b'Subject:&quot;,lines)).replace(&quot;b'&quot;,'')) print(&quot;&quot;,From,To,&quot;\\n&quot;,Subject,'\\n\\n',&quot;this mail are purely composed by img or html&quot;,sep='\\n') print('\\n\\n'+Date)## 按键对应事件def Action(Press): global index global Num_mail if Press == &quot;q&quot;: server.quit() if Press == &quot;7&quot;: server.dele(index) index -=1 Num_mail -=1 elif Press == &quot;8&quot;: index -=1 elif Press == &quot;5&quot;: index +=1 if index &lt; 0: index =0 elif index &gt; Num_mail: index -= 1 if index == 0: print(&quot;No more new e-mails&quot;) else: M_read(index) 主逻辑 def M_read(index): resp, lines, octets = server.retr(index) try: Date= str(grep(“b’Date:”,lines)).replace(“b’”,‘’) msg_content = b’\\r\\n’.join(lines).decode(‘utf-8’) msg = Parser().parsestr(msg_content) print_info(msg) print(‘\\n\\n’+Date) except: Date= str(grep(“b’Date:”,lines)).replace(“b’”,‘’) From= Decode(str(grep(“b’From:”,lines)).replace(“b’”,‘’)) To= Decode(str(grep(“b’To:”,lines)).replace(“b’”,‘’)) Subject= Decode(str(grep(“b’Subject:”,lines)).replace(“b’”,‘’)) print(“”,From,To,“\\n”,Subject,‘\\n\\n’,“this mail are purely composed by img or html”,sep=‘\\n’) print(‘\\n\\n’+Date) while True: Press = input() os.system('clear') if Press == &quot;q&quot;: break if Num_mail == 0: print(&quot;No New E-mails&quot;) else: Action(Press) print(&quot;index=&quot;,index,&quot;; all=&quot;,Num_mail) 案件说明：8：上一封5：下一封7：删除此封q：退出注： 只有正常退出，才能够同时删除邮箱中的邮件。删除后在垃圾箱中，不会永久删除。 下载附件 function： Source def get_email_content(byte_lines, savepath): str_lines = [] for x in byte_lines: str_lines.append(x.decode()) # 拼接邮件内容 msg_content = '\\n'.join(str_lines) # 把邮件内容解析为Message对象 message = Parser().parsestr(msg_content) attachments = [] for part in message.walk(): filename = part.get_filename() #附件名字 if filename: print(filename) filename = decode_str(filename) data = part.get_payload(decode=True) abs_filename = os.path.join(savepath, filename) attach = open(abs_filename, 'wb') attachments.append(filename) attach.write(data) attach.close() return attachments 添加入action，按9下载： elif Press == &quot;9&quot;: attach = get_email_content(M_read(index), '.') 加个获取附件名称， 发现中文乱码问题， 加个decode def get_attach_name(byte_lines): str_lines = [] for x in byte_lines: str_lines.append(x.decode()) # 拼接邮件内容 msg_content = '\\n'.join(str_lines) # 把邮件内容解析为Message对象 message = Parser().parsestr(msg_content) attachments = [] for part in message.walk(): filename = part.get_filename() #附件名字 if filename: if &quot;=?UTF-8?&quot; in filename: filename = base64.b64decode(filename[9:-2]).decode(&quot;utf8&quot;) attachments.append(filename) return attachmentsdef M_read(index): resp, lines, octets = server.retr(index) try: Attachment = get_attach_name(lines) Date= str(grep(&quot;b'Date:&quot;,lines)).replace(&quot;b'&quot;,'') msg_content = b'\\r\\n'.join(lines).decode('utf-8') msg = Parser().parsestr(msg_content) print_info(msg) print('\\n\\n'+Date) print(&quot;Attachment:&quot;,Attachment)## try: except: Date= str(grep(&quot;b'Date:&quot;,lines)).replace(&quot;b'&quot;,'') From= Decode(str(grep(&quot;b'From:&quot;,lines)).replace(&quot;b'&quot;,'')) To= Decode(str(grep(&quot;b'To:&quot;,lines)).replace(&quot;b'&quot;,'')) Subject= Decode(str(grep(&quot;b'Subject:&quot;,lines)).replace(&quot;b'&quot;,'')) print(&quot;&quot;,From,To,&quot;\\n&quot;,Subject,'\\n\\n',&quot;this mail are purely composed by img or html&quot;,sep='\\n') print('\\n\\n'+Date) return lines 完整版： ##!/usr/bin/env python3.7import poplibimport os, sys, base64from email.parser import Parserfrom email.header import decode_headerfrom email.utils import parseaddrdef decode_str(s): value, charset = decode_header(s)[0] if charset: value = value.decode(charset) return valuedef print_info(msg, indent=0): if indent == 0: for header in ['From', 'To', 'Subject']: value = msg.get(header, '') if value: if header=='Subject': value = decode_str(value) else: hdr, addr = parseaddr(value) name = decode_str(hdr) value = u'%s &lt;%s&gt;' % (name, addr) print('%s%s: %s' % (' ' * indent, header, value)) if (msg.is_multipart()): parts = msg.get_payload()[:-1] for n, part in enumerate(parts): print('%spart %s' % (' ' * indent, n)) print('%s--------------------' % (' ' * indent)) print_info(part, indent + 1) else: content_type = msg.get_content_type() if content_type=='text/plain' or content_type=='text/html': content = msg.get_payload(decode=True) charset = guess_charset(msg) if charset: content = content.decode(charset) print('%sText: %s' % (' ' * indent, content + '...')) else: print('%sAttachment: %s' % (' ' * indent, content_type))def guess_charset(msg): charset = msg.get_charset() if charset is None: content_type = msg.get('Content-Type', '').lower() pos = content_type.find('charset=') if pos &gt;= 0: charset = content_type[pos + 8:].strip() return charsetdef grep(Str,List): for i in List: if Str in str(i): break return idef get_attach_name(byte_lines): str_lines = [] for x in byte_lines: str_lines.append(x.decode()) # 拼接邮件内容 msg_content = '\\n'.join(str_lines) # 把邮件内容解析为Message对象 message = Parser().parsestr(msg_content) attachments = [] for part in message.walk(): filename = part.get_filename() #附件名字 if filename: if &quot;=?UTF-8?&quot; in filename: filename = base64.b64decode(filename[9:-2]).decode(&quot;utf8&quot;) attachments.append(filename) return attachmentsdef M_read(index): resp, lines, octets = server.retr(index) try: Attachment = get_attach_name(lines) Date= str(grep(&quot;b'Date:&quot;,lines)).replace(&quot;b'&quot;,'') msg_content = b'\\r\\n'.join(lines).decode('utf-8') msg = Parser().parsestr(msg_content) print_info(msg) print('\\n\\n'+Date) print(&quot;Attachment:&quot;,Attachment)## try: except: Date= str(grep(&quot;b'Date:&quot;,lines)).replace(&quot;b'&quot;,'') From= Decode(str(grep(&quot;b'From:&quot;,lines)).replace(&quot;b'&quot;,'')) To= Decode(str(grep(&quot;b'To:&quot;,lines)).replace(&quot;b'&quot;,'')) Subject= Decode(str(grep(&quot;b'Subject:&quot;,lines)).replace(&quot;b'&quot;,'')) print(&quot;&quot;,From,To,&quot;\\n&quot;,Subject,'\\n\\n',&quot;this mail are purely composed by img or html&quot;,sep='\\n') print('\\n\\n'+Date) return linesdef Action(Press): attach =&quot;&quot; global index global Num_mail if Press == &quot;q&quot;: server.quit() elif Press == &quot;7&quot;: server.dele(index) index -=1 Num_mail -=1 elif Press == &quot;9&quot;: attach = get_email_content(M_read(index), '.') elif Press == &quot;8&quot;: index -=1 elif Press == &quot;5&quot;: index +=1 if index &lt; 0: index =0 elif index &gt; Num_mail: index -= 1 if index == 0: print(&quot;No more new e-mails&quot;) else: M_read(index) return attachdef Decode(STR): head = &quot;=?gb2312?b?&quot; tail = &quot;?=&quot; if head in STR: H = STR.find(head) + len(head) T = STR.find(tail) Result = base64.b64decode(STR[H:T]).decode(&quot;GBK&quot;) STR = STR[:H- len(head)] + Result + STR[T+ len(tail):] return STRdef get_email_content(byte_lines, savepath): str_lines = [] for x in byte_lines: str_lines.append(x.decode()) # 拼接邮件内容 msg_content = '\\n'.join(str_lines) # 把邮件内容解析为Message对象 message = Parser().parsestr(msg_content) attachments = [] for part in message.walk(): filename = part.get_filename() if filename: print(filename) filename = decode_str(filename) data = part.get_payload(decode=True) abs_filename = os.path.join(savepath, filename) attach = open(abs_filename, 'wb') attachments.append(filename) attach.write(data) attach.close() return attachments## 输入邮件地址, 口令和POP3服务器地址:email = '591465908@qq.com'password = ''pop3_server = 'pop.qq.com'port = 995## 连接到POP3服务器:server = poplib.POP3_SSL(pop3_server, port)server.user(email)server.pass_(password)## stat()返回邮件数量和占用空间:print('Messages: %s. Size: %s' % server.stat())## list()返回所有邮件的编号:resp, mails, octets = server.list()## 可以查看返回的列表类似[b'1 82923', b'2 2184', ...]Num_mail = len(mails)## 获取最新一封邮件, 注意索引号从1开始:index = len(mails)##M_read(index)while True: Press = input() os.system('clear') if Press == &quot;q&quot;: break if Num_mail == 0: print(&quot;No New E-mails&quot;) else: Action(Press) print(&quot;index=&quot;,index,&quot;; all=&quot;,Num_mail)## lines存储了邮件的原始文本的每一行,## 可以根据邮件索引号直接从服务器删除邮件:## server.dele(index)## 关闭连接:server.quit() 效果： 删除邮件后保存并刷新 经过几次测试，我发现， 被删除的index并不会重拍，而是就空载那里了， 再次返回查看邮件的时候， 就会出现错误。 因此，最保险的方法，自然是保存和刷新了。同理，如果不保存，只刷新，那么就可以“撤销” 以删除的邮件。 开始想Action那里加上一个，退出，再重连就好～ 但是server套在函数里面刷新的时候会报错， = =这样就麻烦了， 所以直接都在mainloop了- -反正 - -以后应该不会debug什么的了。 if Press == &quot;s&quot;: print(&quot;ReFreshing...&quot;) server.quit() server, resp, mails, octets, Num_mail = Refresh() 删除以后保存 完整代码 ##!/usr/bin/env python3.7import poplibimport os, sys, base64from email.parser import Parserfrom email.header import decode_headerfrom email.utils import parseaddrimport signaldef decode_str(s): value, charset = decode_header(s)[0] if charset: value = value.decode(charset) return valuedef print_info(msg, indent=0): if indent == 0: for header in ['From', 'To', 'Subject']: value = msg.get(header, '') if value: if header=='Subject': value = decode_str(value) else: hdr, addr = parseaddr(value) name = decode_str(hdr) value = u'%s &lt;%s&gt;' % (name, addr) print('%s%s: %s' % (' ' * indent, header, value)) if (msg.is_multipart()): parts = msg.get_payload()[:-1] for n, part in enumerate(parts): print('%spart %s' % (' ' * indent, n)) print('%s--------------------' % (' ' * indent)) print_info(part, indent + 1) else: content_type = msg.get_content_type() if content_type=='text/plain' or content_type=='text/html': content = msg.get_payload(decode=True) charset = guess_charset(msg) if charset: content = content.decode(charset) print('%sText: %s' % (' ' * indent, content + '...')) else: print('%sAttachment: %s' % (' ' * indent, content_type))def guess_charset(msg): charset = msg.get_charset() if charset is None: content_type = msg.get('Content-Type', '').lower() pos = content_type.find('charset=') if pos &gt;= 0: charset = content_type[pos + 8:].strip() return charsetdef grep(Str,List): for i in List: if Str in str(i): break return idef get_attach_name(byte_lines): str_lines = [] for x in byte_lines: str_lines.append(x.decode()) # 拼接邮件内容 msg_content = '\\n'.join(str_lines) # 把邮件内容解析为Message对象 message = Parser().parsestr(msg_content) attachments = [] for part in message.walk(): filename = part.get_filename() #附件名字 if filename: if &quot;=?UTF-8?&quot; in filename: filename = base64.b64decode(filename[9:-2]).decode(&quot;utf8&quot;) attachments.append(filename) return attachmentsdef M_read(index): resp, lines, octets = server.retr(index) try: Attachment = get_attach_name(lines) Date= str(grep(&quot;b'Date:&quot;,lines)).replace(&quot;b'&quot;,'') msg_content = b'\\r\\n'.join(lines).decode('utf-8') msg = Parser().parsestr(msg_content) print_info(msg) print('\\n\\n'+Date) print(&quot;Attachment:&quot;,Attachment)## try: except: Date= str(grep(&quot;b'Date:&quot;,lines)).replace(&quot;b'&quot;,'') From= Decode(str(grep(&quot;b'From:&quot;,lines)).replace(&quot;b'&quot;,'')) To= Decode(str(grep(&quot;b'To:&quot;,lines)).replace(&quot;b'&quot;,'')) Subject= Decode(str(grep(&quot;b'Subject:&quot;,lines)).replace(&quot;b'&quot;,'')) print(&quot;&quot;,From,To,&quot;\\n&quot;,Subject,'\\n\\n',&quot;this mail are purely composed by img or html&quot;,sep='\\n') print('\\n\\n'+Date) return linesdef Action(Press,server): attach =&quot;&quot; global index global Num_mail if Press == &quot;q&quot;: server.quit() elif Press == &quot;7&quot;: server.dele(index) index -=1 Num_mail -=1 elif Press == &quot;9&quot;: attach = get_email_content(M_read(index), '.') elif Press == &quot;8&quot;: index -=1 elif Press == &quot;5&quot;: index +=1 if index &lt; 0: index =0 elif index &gt; Num_mail: index -= 1 if index == 0: print(&quot;No more new e-mails&quot;) else: M_read(index) return attachdef Decode(STR): head = &quot;=?gb2312?b?&quot; tail = &quot;?=&quot; if head in STR: H = STR.find(head) + len(head) T = STR.find(tail) Result = base64.b64decode(STR[H:T]).decode(&quot;GBK&quot;) STR = STR[:H- len(head)] + Result + STR[T+ len(tail):] return STRdef get_email_content(byte_lines, savepath): str_lines = [] for x in byte_lines: str_lines.append(x.decode()) # 拼接邮件内容 msg_content = '\\n'.join(str_lines) # 把邮件内容解析为Message对象 message = Parser().parsestr(msg_content) attachments = [] for part in message.walk(): filename = part.get_filename() if filename: print(filename) filename = decode_str(filename) data = part.get_payload(decode=True) abs_filename = os.path.join(savepath, filename) attach = open(abs_filename, 'wb') attachments.append(filename) attach.write(data) attach.close() return attachmentsdef Refresh(): server = poplib.POP3_SSL(pop3_server, port) server.user(email) server.pass_(password) resp, mails, octets = server.list() # 可以查看返回的列表类似[b'1 82923', b'2 2184', ...] Num_mail = len(mails) # 获取最新一封邮件, 注意索引号从1开始: index = len(mails) return server, resp, mails, octets, Num_maildef INPUT_delay(): class InputTimeoutError(Exception): pass def interrupted(signum, frame): raise InputTimeoutError signal.signal(signal.SIGALRM, interrupted) signal.alarm(60) try: BB = input() signal.alarm(0) # 读到输入的话重置信号 except InputTimeoutError: BB = 'Fresh' return BB## 输入邮件地址, 口令和POP3服务器地址:email = '591465908@qq.com'password = ''pop3_server = 'pop.qq.com'port = 995## 连接到POP3服务器:server = poplib.POP3_SSL(pop3_server, port)server.user(email)server.pass_(password)## stat()返回邮件数量和占用空间:print('Messages: %s. Size: %s' % server.stat())## list()返回所有邮件的编号:resp, mails, octets = server.list()## 可以查看返回的列表类似[b'1 82923', b'2 2184', ...]Num_mail = len(mails)## 获取最新一封邮件, 注意索引号从1开始:index = len(mails)##M_read(index)while True: Press = INPUT_delay() if Press == &quot;q&quot;: break if Press == &quot;Fresh&quot; or Press == &quot;f&quot;: print(&quot;ReFreshing...&quot;) server, resp, mails, octets, Num_mail = Refresh() if Press == &quot;s&quot;: print(&quot;Save &amp; ReFreshing...&quot;) server.quit() server, resp, mails, octets, Num_mail = Refresh() if Num_mail == 0: os.system('clear') print(&quot;No New E-mails&quot;) else: os.system('clear') Action(Press,server) print(&quot;index=&quot;,index,&quot;; all=&quot;,Num_mail)## lines存储了邮件的原始文本的每一行,## 可以根据邮件索引号直接从服务器删除邮件:## server.dele(index)## 关闭连接:server.quit() Gitub 链接： https://github.com/Karobben/Karobben-Work-Station/blob/master/QQmail_recive.py","link":"/2020/10/25/Blog/Python_email/"},{"title":"How to build index in one line codes","text":"How to build index in one line codes ls | awk '{print &quot;[&quot;$1&quot;](&quot;$i&quot;)&quot;}'| sed 's/\\.md]/]/;s/\\.md)/\\.html)/;/yuque.yml/d;/(summary.html)/d' &gt; Blog_index.md","link":"/2020/07/28/Blog/build_index/"},{"title":"Machine Learning in Action: ab1 file","text":"Machine Learning in Action: ab1 raw data At present, I’m working for a DNA sequencing company. The experiment is not hard for me. But the head-breaking part is analyzing the results for a freshman: there are so many! Traditionally, we can use Sequencing Analyzing to view the signal of electrophics. But there are 96 wells for each plate, and we have several plates in each day. It is hard to imagine checking the graphics one by one especially we have work to do. For solving this problem, I tried R and python both. But ggplot2 is just fucking slow for massive data (As we know, for each plate, there are 96 wells. Each well has 4 signal tunnels, and each tunnel contains about 17,000 check-point. As a result, there are about 6.5 million points to plot). It takes about 2 mins for R to collect all matrix, plot, and save it. But python works much fluently. Let’s see an example of the plot. Familiar with Your Data As we can see the result below, we have few types of pattern judged by the naked eyes: A01: Triangle. (The signal is decreasing but is still readable) A02: Flat. (Which doesn’t have signal at all) A08: Laying-Trapezoid. (The perfect result we’d love to) F01~F07: Acute Triangle. (Which means the signal is decreasing and the result is unreadable) C02: Stick. (Short sequence or Signal-Break due to some reasons.) Though, it is easy to acquire a model from ML by putting all those check-point into a matrix and training them. But I decided to reduce the burden of my computer. By first, I’d like to try something like linear regression. Linear Regression First, Let’s take a quick look of the smooth line Now, let’s try the linear regression. Main codes can be found at my blog Let’s take the well H12 as an example By using geom_smooth from ggplot2, we can achieve these graphics easily. By calculating the regression function by lm with the exponent from 1 to 13, we can get the result as below An example of regression function: $$ f(x)= -5.33506521414874 e^{-56} * x^{13}+2.33068989275763 e^{-50} * x^{12} $$ $$ -4.44202743547308 e^{-45} * x^{11}+4.8269078976017 e^{-40} * x^{10} $$ $$ -3.27011035492282 e^{-35} * x^9+1.40852725678933 e^{-30} * x^8 $$ $$ -3.68400537011035 e^{-26} * x^7+4.64218496851634 e^{-22} * x^6 $$ $$ +2.12911181720032 e^{-18} * x^5-1.64587230405762 e^{-13} * x^4 $$ $$ +2.2678114895877 e^{-09} * x^3-1.27776012720345 e^{-05} * x^2 $$ $$ +0.0270106008326289 * x^1 -8.24054735022609 $$ As we can see, the last diagram is almost about the same as the result of geom_smooth! Another awesome thing is it takes only a second to get the result!! As we can see, the function of linear-regression is enough to tell us about that this well is failed or succeed and we can use the numbers from it to train our model! Let’s check all the regression plot It looks well, but it takes long time to make. Click to see hidden codes library(sangerseqR)library(reshape2)mylr = function(x,y){ x_mean = mean(x) y_mean = mean(y) xy_mean = mean(x*y) xx_mean = mean(x*x) yy_mean = mean(y*y) m = (x_mean*y_mean - xy_mean)/(x_mean^2 - xx_mean) b = y_mean - m*x_mean f = m*x+b# 线性回归方程 sst = sum((y-y_mean)^2) sse = sum((y-f)^2) ssr = sum((f-y_mean)^2) result = c(m,b,sst,sse,ssr) names(result) = c('m','b','sst','sse','ssr') result['ssr']/result['sst']}F_equation &lt;- function(X,Formula){ eval(parse(text = Formula))}LMEE &lt;- function(TB,Times){ colnames(TB)=c(&quot;X&quot;,&quot;Y&quot;) Group_X = &quot;X&quot; for(i in c(2:Times)){ X_i = paste(&quot;I(X^&quot;,i,&quot;)&quot;,sep=&quot;&quot;) Group_X = paste(Group_X,X_i,sep=&quot; + &quot;) } str_lm = paste(&quot;lm(Y ~&quot;,Group_X, ', data=TB)', sep=' ') model = eval(parse(text = str_lm)) Formula = model$coefficients[1] for(i in c(Times:1)){ X_tmp = paste(model$coefficients[i+1], &quot; * X^&quot;, i, sep=&quot;&quot;) Formula = paste(Formula,X_tmp,sep=&quot;+&quot;) } R2 = mylr(TB$Y,F_equation(TB$X,Formula)) result = c() result$R2 = R2[[1]] result$model = model result$Formula=Formula return(result)}MEES &lt;- function(TB, Times){ colnames(TB)=c(&quot;X&quot;,&quot;Y&quot;) for(i in c(1:Times)){ Result = c() if(i == 1){ model &lt;- lm(formula = Y ~ X, data = TB) Formula = paste(model$coefficients[1],&quot; + &quot;, model$coefficients[2],&quot; * X&quot;, sep=&quot;&quot;) R2 = mylr(TB$Y,F_equation(TB$X,Formula)) Result_TB = data.frame(Exp=i,R2=R2, F = Formula) } else{ Result_LMEE = LMEE(TB,i) Result_tmp = data.frame(Exp= i, R2= Result_LMEE$R2, F = Result_LMEE$Formula) Result_TB = rbind(Result_TB, Result_tmp) } } return(Result_TB)}MEES_plot &lt;- function(TB,Result_TB,header=&quot;test&quot;){ MAIN = as.character(TB$tube[1]) colnames(TB)=c(&quot;X&quot;,&quot;Y&quot;) Result_TB = na.omit(Result_TB) Exp = nrow(Result_TB) Result_TB = Result_TB[order(Result_TB$R2, decreasing = T)[1],] X = unique(as.integer(TB$X/100))*100 plot(X, F_equation(X,as.character(Result_TB$F)),type='p', main = paste(MAIN, Exp), xlab = &quot;&quot;, ylab = &quot;&quot; )}TB_get &lt;- function(ab1){ A &lt;- read.abif(ab1) A_raw = A@data$DATA.1 T_raw = A@data$DATA.2 C_raw = A@data$DATA.3 G_raw = A@data$DATA.4 tmp &lt;- melt(t(data.frame(A_raw,T_raw,C_raw, G_raw))) return(list(tmp, A@data$TUBE.1))}png('../test.png',w=1920*1.3,h=1080*1.3)par(mfrow=c(8,12))for(i in dir()){ print(i) TB_tmp = TB_get(i)[[1]] TUBE = TB_get(i)[[2]] TB = data.frame(X=c(1:nrow(TB_tmp)),Y=TB_tmp$value, tube=TUBE) MEES_plot(TB,MEES(TB,20))}dev.off() Logarithmic Regression $$ f(x) = log(x)+B $$ Click to see hidden codes library(sangerseqR)library(reshape2)mylr = function(x,y){ x_mean = mean(x) y_mean = mean(y) xy_mean = mean(x*y) xx_mean = mean(x*x) yy_mean = mean(y*y) m = (x_mean*y_mean - xy_mean)/(x_mean^2 - xx_mean) b = y_mean - m*x_mean f = m*x+b# 线性回归方程 sst = sum((y-y_mean)^2) sse = sum((y-f)^2) ssr = sum((f-y_mean)^2) result = c(m,b,sst,sse,ssr) names(result) = c('m','b','sst','sse','ssr') result['ssr']/result['sst']}TB_get &lt;- function(ab1){ A &lt;- read.abif(ab1) A_raw = A@data$DATA.1 T_raw = A@data$DATA.2 C_raw = A@data$DATA.3 G_raw = A@data$DATA.4 tmp &lt;- melt(t(data.frame(A_raw,T_raw,C_raw, G_raw))) return(list(tmp, A@data$TUBE.1))}Result = c()for(i in dir()){ A &lt;- TB_get(i) Y = A[[1]]$value[-c(1:12000)] TB &lt;- data.frame(X=c(1: length(Y)), Y = Y) Model &lt;- lm(formula = Y ~ log(X), data = TB) Cur &lt;- Model$coefficients[[2]] R2 &lt;- mylr(TB$Y, Model$coefficients[[1]] + Model$coefficients[[2]]*log(TB$X)) #print(paste(Cur, R2)) Result &lt;- c(Result, Cur,R2)}Result &lt;- data.frame(matrix(Result, ncol = 2 , byrow = T))Di = rep(0,96)Di[Result$X1&lt; -10] = 1Di[Result$X2 &lt; 0.1] = 0pheatmap::pheatmap(matrix(Di, ncol = 12, byrow = T), cluster_rows = F, cluster_cols = F)#png('../test2.png',w=1920*1.3,h=1080*1.3)par(mfrow=c(8,12))Result &lt;-c()for(i in dir()){ print(i) A &lt;- read.abif(i) A_raw = A@data$DATA.1 T_raw = A@data$DATA.2 C_raw = A@data$DATA.3 G_raw = A@data$DATA.4 tmp &lt;- melt(t(data.frame(A_raw,T_raw,C_raw, G_raw))) Num =100 Y = apply(matrix(tmp$value, ncol=4*Num, byrow = T),1,max) X = c(1:length(apply(matrix(tmp$value, ncol=4*Num, byrow = T),1,max))) TB = data.frame(X=X,Y=Y) Model &lt;- lm(formula = Y ~ log(X), data = TB) Cur &lt;- Model$coefficients[[2]] R2 &lt;- mylr(TB$Y, Model$coefficients[[1]] + Model$coefficients[[2]]*log(TB$X)) #print(paste(Cur, R2)) Result &lt;- c(Result, Cur,R2) plot(X,Y)}dev.off()Result &lt;- data.frame(matrix(Result, ncol = 2 , byrow = T))Di = rep(1,96)Di[Result$X1&gt; -10] = 0Di[Result$X2 &lt; 0.1] = 0pheatmap::pheatmap(matrix(Di, ncol = 12, byrow = T), cluster_rows = F, cluster_cols = F) Though, judging the result by Regression model is an appropriate way, but this algorithm seems preferring the raw data list. I was tried to use 0 and 1 to replace the result of failed and success and running: xgboost(data = dtrain, max.depth = 2, eta = 1, nthread = 2, nrounds = 2, objective = &quot;binary:logistic&quot;) It works. Not perfect, but acceptable. Because I was trying to find a way to call bases from the raw abi file and failed, I using the Sequencing Analyzing software to made a post processing to get the sequence and quality grades of the bases. Once we have the quality matrix, we can have a better way to grade the result. My choice is calculating the mean value of the base-quality from 80 to 120 for several reasons: 120 base is enough to value a successful task. first 80 bases have low quality and usually was tossed. I’d like to collect the result though it’s a derogation-signal. I choose R to achieve this because package sangerseqR can turn the quality grades to integer from bin16 format. And I don’t know how to achieve this in Python. Read_abiDirector &lt;- function(abi_director){ # Reading List abi_list = dir(abi_director) # Initialize Result TB &lt;- data.frame() # Start flower for(abi_file in abi_list){ Plate = strsplit(abi_director,'/')[[1]][3] Well = strsplit(abi_file,'[.]')[[1]][1] abi_file = paste(abi_director,abi_file,sep=&quot;/&quot;) abi &lt;- read.abif(abi_file) tmp &lt;- data.frame(mean(abi@data$PCON.1[80:120]), Plate = Plate, Well = Well) tmp[[1]] &lt;- tmp[[1]]/61*100 print(tmp) colnames(tmp) &lt;- &quot;Mean&quot; TB &lt;- rbind(TB,tmp) } TB[[1]][is.na(TB[[1]])] = 0 return(TB)} Once We had the label file, we can extract the matrix one by one and turn them to xgb.matrix to train our model. here, I removed the objective = &quot;binary:logistic&quot; parameter, and increased the depths and rounds to 5. xgboost(data = dtrain, max.depth = 2, eta = 1, nthread = 2, nrounds = 2) I combined 16 plates which means it has 1536 samples to compact the training data set. Though, 5 rounds is not enough (fails ratio &gt; 4%), I don’t want the model be over fitted. Since the training data is better than before, I get the best performance for ever.","link":"/2020/09/13/Blog/R_abi_re/"},{"title":"Urwid B站 up主信息实时显示的TUI应用 updating...","text":"Urwid B站 up主信息实时显示的TUI应用 updating… import urwid, time, sys, ast, requests, jsonfrom urllib.request import urlopenclass BiliSpider: def __init__(self): self.online_api = &quot;https://api.bilibili.com/x/web-interface/online&quot; # 在线人数 self.video_api = &quot;https://api.bilibili.com/x/web-interface/archive/stat?&amp;aid=%s&quot; # 视频信息 self.newlist_api = &quot;https://api.bilibili.com/x/web-interface/newlist?&amp;rid=%s&amp;pn=%s&amp;ps=%s&quot; # 最新视频信息 self.region_api = &quot;https://api.bilibili.com/x/web-interface/dynamic/region?&amp;rid=%s&amp;pn=%s&amp;ps=%s&quot; # 最新动态信息 self.member_api = &quot;http://space.bilibili.com/ajax/member/GetInfo&quot; # 用户信息 self.stat_api = &quot;https://api.bilibili.com/x/relation/stat?vmid=%s&quot; # 用户关注数和粉丝总数 self.upstat_api = &quot;https://api.bilibili.com/x/space/upstat?mid=%s&quot; # 用户总播放量和总阅读量 self.follower_api = &quot;https://api.bilibili.com/x/relation/followings?vmid=%s&amp;pn=%s&amp;ps=%s&quot; # 用户关注信息 self.fans_api = &quot;https://api.bilibili.com/x/relation/followers?vmid=%s&amp;pn=%s&amp;ps=%s&quot; # 用户粉丝信息 # def get_api(api_url): headers = { &quot;Accept&quot;: &quot;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8&quot;, &quot;Accept-Encoding&quot;: &quot;gzip, deflate, br&quot;, &quot;Accept-Language&quot;: &quot;zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2&quot;, &quot;Host&quot;: &quot;api.bilibili.com&quot;, &quot;Referer&quot;: &quot;https://www.bilibili.com/&quot;, &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36&quot;, } res = requests.get(api_url, headers=headers) res_dict = res.json() return res_dict # def get_online(self): &quot;&quot;&quot; 获取在线信息 all_count: 最新投稿 web_online: 在线人数 :return: &quot;&quot;&quot; online_dic = BiliSpider.get_api(self.online_api) return online_dic # def get_video_info(self, aid): &quot;&quot;&quot; 获取视频信息 :param aid: 视频id :return: &quot;&quot;&quot; res = BiliSpider.get_api(self.video_api %aid) # print(res) return res # def get_newlist_info(self, rid, pn, ps): &quot;&quot;&quot; 获取最新视频信息 :param rid: 二级标题的id (详见tid_info.txt) :param pn: 页数 :param ps: 每页条目数 1-50 :return: &quot;&quot;&quot; res = BiliSpider.get_api(self.newlist_api %(rid, pn, ps)) return res # def get_region_info(self, rid, pn, ps): &quot;&quot;&quot; 获取最新视频信息 :param rid: 二级标题的id (详见tid_info.txt) :param pn: 页数 :param ps: 每页条目数 1-50 :return: &quot;&quot;&quot; res = BiliSpider.get_api(self.region_api %(rid, pn, ps)) return res # def get_member_info(self, mid): &quot;&quot;&quot; 获取用户信息 :param mid:用户id :return: &quot;&quot;&quot; post_data = { &quot;crsf&quot;: &quot;&quot;, &quot;mid&quot;: mid, } header = { &quot;Host&quot;: &quot;space.bilibili.com&quot;, &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:63.0) Gecko/20100101 Firefox/63.0&quot;, &quot;Accept&quot;: &quot;application/json, text/plain, */*&quot;, &quot;Accept-Encoding&quot;: &quot;gzip, deflate, br&quot;, &quot;Accept-Language&quot;: &quot;zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2&quot;, &quot;Referer&quot;: &quot;https://www.bilibili.com/&quot;, } res = requests.post(self.member_api, data=post_data, headers=header) member_dic = json.dumps(res.json(), ensure_ascii=False) return member_dic # def get_stat_info(self, vmid): &quot;&quot;&quot; 获取某用户的关注数和粉丝总数 :param vmid: 用户id :return: &quot;&quot;&quot; res = BiliSpider.get_api(self.stat_api % vmid) return res # def get_upstat_info(self, mid): &quot;&quot;&quot; 获取某用户的总播放量和总阅读量 :param mid: 用户id :return: &quot;&quot;&quot; res = BiliSpider.get_api(self.upstat_api % mid) return res # def get_follower_info(self, vmid, pn, ps): &quot;&quot;&quot; 获取某用户关注者信息 :param vmid:用户id :param pn: 页数 最多5页 :param ps: 每页条目数 1-50 :return: &quot;&quot;&quot; res = BiliSpider.get_api(self.follower_api %(vmid, pn, ps)) return res # def get_fans_info(self, vmid, pn, ps): &quot;&quot;&quot; 获取某用户粉丝信息 :param vmid:用户id :param pn: 页数 最多5页 :param ps: 每页条目数 1-50 :return: &quot;&quot;&quot; res = BiliSpider.get_api(self.fans_api %(vmid, pn, ps)) return resbili = BiliSpider()def Bili_v(Title,ID): ID = str(ID) url = &quot;http://api.bilibili.com/archive_stat/stat?aid=&quot; + ID html = urlopen(url).read().decode('utf-8') d = ast.literal_eval(html) Cont = d['data'] View = str(Cont['view']) Like = str(Cont['like']) Reply = str(Cont['reply']) Coin = str(Cont['coin']) Result = &quot;\\n&quot;.join([Title,View, Like, Reply, Coin]) return Resultdef exit_on_q(key): if key in ('q', 'Q'): raise urwid.ExitMainLoop()palette = [ ('banner', 'black', 'light gray'), ('streak', 'black', 'dark red'), ('bg', 'black', 'dark blue'),]A = 'Test'class Refresh: def keypress(self, key): if key in ('q', 'Q'): raise urwid.ExitMainLoop() def setup_view(self): #Self infor mid = 393056819 AA = bili.get_member_info(mid) 粉丝 = urwid.Text(str(bili.get_stat_info(mid)['data']['follower'])) #Veido Infor Title = urwid.Text(&quot;\\n&quot;.join([&quot;&quot;,&quot;观看量:&quot;,&quot;点赞:&quot;,&quot;回复:&quot;,&quot;硬币:&quot; ])) Bv1 = urwid.Text(Bili_v(&quot;Python色差&quot;,86328254)) Bv2 = urwid.Text(Bili_v(&quot;汪汪洗澡&quot;,89026731)) Bv3 = urwid.Text(Bili_v(&quot;大生态缸&quot;,61040198)) Bv4 = urwid.Text(Bili_v(&quot;OneNote记&quot;,44637823)) Bv5 = urwid.Text(Bili_v(&quot;OneNote2&quot;,45117221)) self.Vedio_inf = urwid.Columns([Title,Bv1,Bv2,Bv3,Bv4,Bv5]) Fan = urwid.AttrWrap( 粉丝,'header') self.Vedio_inf = urwid.AttrWrap(self.Vedio_inf, 'body') self.view = urwid.Padding(self.Vedio_inf, 'left') #self.view = urwid.ListBox(urwid.SimpleListWalker([self.Vedio_inf,urwid.Divider(),self.Vedio_inf])) self.view = urwid.AttrMap(self.view, 'body') self.view = urwid.Filler(self.Vedio_inf, 'middle') #self.view = urwid.Frame(header=粉丝, body=self.Vedio_inf) def main(self): self.setup_view() loop = urwid.MainLoop( self.view, palette=[('body', 'dark cyan', '')], unhandled_input=self.keypress) loop.set_alarm_in(1, self.refresh) loop.run() def refresh(self, loop=None, data=None): self.setup_view() loop.widget = self.view loop.set_alarm_in(5, self.refresh)if __name__ == '__main__': refresh = Refresh() sys.exit(refresh.main()) = = 实时刷新有了 = =不过排版一加东西就错误= = 下次再来","link":"/2020/06/26/Blog/Urwid-Biliboard/"},{"title":"Android garbage clean by termux","text":"An example of Time: In termux, the files for time is stord at storage/shared/Android/data/com.tencent.tim/ du -sh storage/shared/Android/data/com.tencent.tim/* 1.7G storage/shared/Android/data/com.tencent.tim/Tencent 73K storage/shared/Android/data/com.tencent.tim/cache 70M storage/shared/Android/data/com.tencent.tim/files 92K storage/shared/Android/data/com.tencent.tim/photo 94K storage/shared/Android/data/com.tencent.tim/qq 86M storage/shared/Android/data/com.tencent.tim/qzone By checking the directory Tim, we can see that most garbage is chatting pictures. du -sh storage/shared/Android/data/com.tencent.tim/Tencent/Tim/* 733K storage/shared/Android/data/com.tencent.tim/Tencent/Tim/591465908 9.0M storage/shared/Android/data/com.tencent.tim/Tencent/Tim/DoutuRes 7.0K storage/shared/Android/data/com.tencent.tim/Tencent/Tim/NoRename#H6s8amH6x 861M storage/shared/Android/data/com.tencent.tim/Tencent/Tim/chatpic 424K storage/shared/Android/data/com.tencent.tim/Tencent/Tim/diskcache 308K storage/shared/Android/data/com.tencent.tim/Tencent/Tim/doodle_template 523K storage/shared/Android/data/com.tencent.tim/Tencent/Tim/dov_doodle_template 276K storage/shared/Android/data/com.tencent.tim/Tencent/Tim/dov_ptv_template_dov 2.0M storage/shared/Android/data/com.tencent.tim/Tencent/Tim/emoji 7.5K storage/shared/Android/data/com.tencent.tim/Tencent/Tim/funcall 3.5K storage/shared/Android/data/com.tencent.tim/Tencent/Tim/head 4.6M storage/shared/Android/data/com.tencent.tim/Tencent/Tim/newpoke 5.6M storage/shared/Android/data/com.tencent.tim/Tencent/Tim/pddata 24M storage/shared/Android/data/com.tencent.tim/Tencent/Tim/photo 3.8M storage/shared/Android/data/com.tencent.tim/Tencent/Tim/portrait 140K storage/shared/Android/data/com.tencent.tim/Tencent/Tim/ppt 114K storage/shared/Android/data/com.tencent.tim/Tencent/Tim/qav 9.2M storage/shared/Android/data/com.tencent.tim/Tencent/Tim/qbosssplahAD 327K storage/shared/Android/data/com.tencent.tim/Tencent/Tim/rbt 142M storage/shared/Android/data/com.tencent.tim/Tencent/Tim/shortvideo 470K storage/shared/Android/data/com.tencent.tim/Tencent/Tim/system_background 2.8M storage/shared/Android/data/com.tencent.tim/Tencent/Tim/tencent 4.0K storage/shared/Android/data/com.tencent.tim/Tencent/Tim/thumb ~ $ du -sh storage/shared/Android/data/com.tencent.tim/Tencent/Tim/ 1.1G storage/shared/Android/data/com.tencent.tim/Tencent/Tim/ ~ $ ls storage/shared/Android/data/com.tencent.tim/Tencent/Tim/chatpic Garbage file lists # 我也不知道有什么用，反正我删了Noidea=$(echo &quot;storage/shared/tencentstorage/shared/MideaHome/storage/shared/Huawei/Themes/themecache/&quot;)for i in $Noidea:do rm -rf $idone######### Tim######### 可删## 没啥影响， 就是聊天记录和图片都需要重新加载。 往上滑就能重新加载回来。 但是删掉可以空出好几个GTim=$(echo &quot;storage/shared/Android/data/com.tencent.tim/Tencent/Timstorage/shared/Android/data/com.tencent.tim/Tencent/MobileQQstorage/shared/Android/data/com.tencent.tim/Tencent/Tim_Imagesstorage/shared/Android/data/com.tencent.tim/Tencent/QQ_businessstorage/shared/Android/data/com.tencent.tim/Tencent/ministorage/shared/Android/data/com.tencent.tim/Tencent/qzonebackupstorage/shared/Android/data/com.tencent.tim/Tencent/Qzonestorage/shared/Android/data/com.tencent.tim/Tencent/Qzonestorage/shared/Android/data/com.tencent.tim/qzone&quot;)## Tim_Images: 自己编辑过的图## 不知道是啥， 我先删为敬了: QQ_business, mini, qzonebackup, Qzone# 可选# rm -r storage/shared/Android/data/com.tencent.tim/Tencent/TIMfile_recv# rm -r storage/shared/Android/data/com.tencent.tim/Tencent/QQ_Favoritefor i in $Tim;do rm -rf $i;done## 自己收藏的图片# rm -r storage/shared/Android/data/com.tencent.tim/Tencent/TIM_Favorite# rm -r storage/shared/Android/data/com.tencent.tim/Tencent/QQ_Collection# rm -r storage/shared/Android/data/com.tencent.tim/Tencent/QQ_Favorite# 先不删# 不知道是啥， 所以先不删， 反正占地不大# rm -r storage/shared/Android/data/com.tencent.tim/Tencent/TMAssistantSDK####### QQ####### QQ 我还没看。 估计和tim是一个样子的 过段时间再来更新Phone_QQ=$(echo &quot;storage/shared/Android/data/com.tencent.mobileqq/qzonestorage/shared/Android/data/com.tencent.mobileqq/Tencent/MobileQQ&quot;)for i in $Phone_QQ; do rm -r $idone######## 微信#######mm=$(echo &quot;storage/shared/Android/data/com.tencent.mm/MicroMsg/6eae3a15b247f7e822ed8dbc12c884e5storage/shared/Android/data/com.tencent.mm/MicroMsg/CheckResUpdatestorage/shared/Android/data/com.tencent.mm/MicroMsg/SQLTracestorage/shared/Android/data/com.tencent.mm/MicroMsg/ThumbVideoCachestorage/shared/Android/data/com.tencent.mm/MicroMsg/WebNetFilestorage/shared/Android/data/com.tencent.mm/MicroMsg/b2b233ad21176b0661427b78a381faf3storage/shared/Android/data/com.tencent.mm/MicroMsg/cardstorage/shared/Android/data/com.tencent.mm/MicroMsg/crashstorage/shared/Android/data/com.tencent.mm/MicroMsg/facedirstorage/shared/Android/data/com.tencent.mm/MicroMsg/hilivestorage/shared/Android/data/com.tencent.mm/MicroMsg/mapsdkstorage/shared/Android/data/com.tencent.mm/MicroMsg/recoverystorage/shared/Android/data/com.tencent.mm/MicroMsg/switchAccountBgstorage/shared/Android/data/com.tencent.mm/MicroMsg/vusericonstorage/shared/Android/data/com.tencent.mm/MicroMsg/wagamefilesstorage/shared/Android/data/com.tencent.mm/MicroMsg/walletstorage/shared/Android/data/com.tencent.mm/MicroMsg/wallet_imagesstorage/shared/Android/data/com.tencent.mm/MicroMsg/wxafilesstorage/shared/Android/data/com.tencent.mm/MicroMsg/wxanewfilesstorage/shared/Android/data/com.tencent.mm/MicroMsg/xlogstorage/shared/Android/data/com.tencent.mm/cache/&quot;)for i in $mm; do rm -r $i;done# 已知删除项：# 语音# 保留项# 图片， 聊天记录， 转帐记录# 可选mm_config=$(echo &quot;storage/shared/Android/data/com.tencent.mm/MicroMsg/Download #下载的文件&quot;)######### 淘宝########rm -rf storage/shared/Android/data/com.taobao.taobao/cache/######### 华为垃圾########storage/shared/Android/data/com.huawei.meetime/files/######### 优酷########rm -rf storage/shared/Android/data/com.youku.phone/files/#################### 一些垃圾图片的位置##################rm -rf storage/shared/com*#???rm -rf storage/shared/Android/obb","link":"/2021/06/10/Blog/android-garbageclean/"},{"title":"Compose keys in Linux","text":"Show all keys Show all able compose keys with command. cat &quot;/usr/share/X11/locale/$(grep --max-count=1 &quot;${LANG%.*}.UTF-8\\$&quot; /usr/share/X11/locale/locale.dir | cut --delimiter=/ --fields 1)/Compose&quot; ⫰ Math keys Result o o ° o A Å &gt; = ≥ &lt; = ≤ x x × &gt; &gt; » &lt; &lt; «» Direction keys Result &lt; - ← | ^ ↑ | v ↓ Others keys Result o c © o r ® = Y ¥ = E € Meme keys Result &lt; 3 ♥ Customize Compouse key In default profile, the Greek alphabet is like &lt;dead_greek&gt; &lt;a&gt;. But normally, we do not have this thing in our keyboard. As a result, I changed it to g+g+a This is how I change all &lt;dead_greek&gt; sudo cp /usr/share/X11/locale/en_US.UTF-8/Compose /usr/share/X11/locale/en_US.UTF-8/Compose_bksudo sed -i 's/&lt;dead_greek&gt;/&lt;Multi_key&gt; &lt;g&gt; &lt;g&gt;/' /usr/share/X11/locale/en_US.UTF-8/Composesudo reboot``` ## Costumize Compose Key```bashsudo vim /usr/share/X11/locale/en_US.UTF-8/Compose &lt;Multi_key&gt; &lt;bar&gt; &lt;asciicircum&gt; : &quot;↑&quot;&lt;Multi_key&gt; &lt;asciicircum&gt; &lt;bar&gt; : &quot;↑&quot;&lt;Multi_key&gt; &lt;bar&gt; &lt;v&gt; : &quot;↓&quot;&lt;Multi_key&gt; &lt;bar&gt; &lt;V&gt; : &quot;↓&quot;&lt;Multi_key&gt; &lt;v&gt; &lt;bar&gt; : &quot;↓&quot;&lt;Multi_key&gt; &lt;V&gt; &lt;bar&gt; : &quot;↓&quot;&lt;Multi_key&gt; &lt;asciitilde&gt; &lt;equal&gt; : &quot;≈&quot; Reboot/Relogo to reload","link":"/2021/10/02/Blog/compouse-keys/"},{"title":"Just write a post for recording my depression...","text":"2021/03/13 This is the first time I am recording my anxiety and depression. Give a brief statement about my situation: I just quit my job and staying with my parents. I am waiting for Autumn fall to come back to campus. I am writing a paper for my previous mentor for publishing. I am trying to update my blogs every day. I am learning python and kivy every day. I also plan to learn some statistics and bioinformatics. I still didn’t finish my reading task. I want to do some biochemistry knowledge review. I also want to learn more complicated vocabulary and native idioms. I also want to play switch games. I worry that I can’t pass the driver’s license check the day after postnatal. I am worried about I can’t get the visa two months from now. I am worried that I can’t pass my classes one year from now. I am worried about I can’t graduate from campus three years from now. And also, I am pushing my progress very slow, as slow as a snail. That’s why I am falling into deep anxiety and depression. It has given me so much pressure and worried about so many things. Also, I have no peers around, no much of face to face communication. Though, I have lots of friends living in the same city as me. But I don’t want to call them, bather them. And I also lack exercise… coffee addiction, low appetite, small eater, sedentary life-style, trouble with fall into sleep, can’t get up earlier. All those things make me feel like I am a loser. I think I need a plan to tightly stick with it. I also need to set times to take a break since I never know how to stop once I start typing. I’ll start with going to sleep and waking up on time first. Let me just do it.","link":"/2021/03/13/Blog/depression-record/"},{"title":"用Python快速批量压缩图片","text":"用Python快速批量压缩图片 ## Structure ### 1 Arguments import argparseparser = argparse.ArgumentParser()parser.add_argument('-i','-I','--input') #输入文件parser.add_argument('-o','-O','--output',default = &quot;OUT&quot;) #输出文件parser.add_argument('-r','-R','--ratio', type = int,default = 2) #resize ratioparser.add_argument('-w','-W','--width',default = &quot;NA&quot;) #resize by widthparser.add_argument('-t','-T','--height',default = &quot;NA&quot;) #resize by Height##获取参数args = parser.parse_args()INPUT = args.inputOUTPUT = args.outputR_img = args.ratioW_img = args.widthH_img = args.height 2 File/Director Judgement import osdef FD_judge(path): result = &quot;&quot; if &quot;*&quot; in path: result = &quot;Files&quot; elif os.path.isdir(path): result = &quot;Directory&quot; elif os.path.isfile(path): result = &quot;File&quot; else: result = &quot;path is incorrect&quot; return resultprint(FD_judge(INPUT))Typ_in = FD_judge(INPUT) 3 Resize Determine import PIL.Image as Imagedef Calc_WH(w,h,W_img,H_img,R_img): if W_img != &quot;NA&quot; and H_img == &quot;NA&quot;: #Resize by Width print('Resize by Width') R = w/ int(W_img) w=int(w/R) h=int(h/R) elif H_img != &quot;NA&quot; and W_img == &quot;NA&quot;: #Resize by Height print(&quot;Resize by Height&quot;) R = h/ int(H_img) w=int(w/R) h=int(h/R) elif H_img != &quot;NA&quot; and W_img != &quot;NA&quot;: #Resize by Width and Height print('Resize by Width and Height') w=int(W_img) h=int(H_img) else: print(&quot;Resize by ratio, R=&quot;+str(R_img)) w=int(w/R_img) h=int(h/R_img) return w,h 4 Resize function def Resize(path,W_img,H_img,R_img): Img=Image.open(path) w,h=Img.size w,h=Calc_WH(w,h,W_img,H_img,R_img) Img_out=Img.resize((w,h),Image.ANTIALIAS) return Img_out 5 logic if Typ_in==&quot;File&quot; and OUTPUT == &quot;OUT&quot;: OUTPUT = &quot;Re_&quot; + INPUTelif Typ_in==&quot;File&quot; and OUTPUT != &quot;OUT&quot;: OUTPUT = OUTPUTelse: if not os.path.exists(OUTPUT): os.makedirs(OUTPUT) OUTPUT = OUTPUT +&quot;/&quot; test result: Whole Scripts:link Result Single file Reading img infor With package “imagemagick”. If you doesn’t have this lib, for debian, please execute:**sudo apt install ****imagemagick Running with default argument ../test.py -i 1.png##Outfile: Re_1.pngidentify 1.png Re_1.png## 1.png PNG 2666x1827 2666x1827+0+0 8-bit sRGB 295921B 0.000u 0:00.010## Re_1.png PNG 1333x913 1333x913+0+0 8-bit sRGB 203679B 0.000u 0:00.000../test.py -i 1.png -o my.png##Outfile: my.pngidentify 1.png my.png##1.png PNG 2666x1827 2666x1827+0+0 8-bit sRGB 295921B 0.000u 0:00.000##my.png PNG 1333x913 1333x913+0+0 8-bit sRGB 203679B 0.000u 0:00.000 Resize by width ../test.py -i 1.png -w 300identify 1.png Re_1.png##1.png PNG 2666x1827 2666x1827+0+0 8-bit sRGB 295921B 0.000u 0:00.000##Re_1.png PNG 300x205 300x205+0+0 8-bit sRGB 27338B 0.000u 0:00.000 Resize by Height ../test.py -i 1.png -t 300identify 1.png Re_1.png##1.png PNG 2666x1827 2666x1827+0+0 8-bit sRGB 295921B 0.000u 0:00.000##Re_1.png PNG 437x300 437x300+0+0 8-bit sRGB 44276B 0.000u 0:00.000 Resize by Ratio ../test.py -i 1.png -r 10identify 1.png Re_1.png##1.png PNG 2666x1827 2666x1827+0+0 8-bit sRGB 295921B 0.000u 0:00.000##Re_1.png PNG 266x182 266x182+0+0 8-bit sRGB 23398B 0.000u 0:00.000 Resize by Height and Width ../test.py -i 1.png -t 200 -w 10##1.png PNG 2666x1827 2666x1827+0+0 8-bit sRGB 295921B 0.000u 0:00.000##Re_1.png PNG 10x200 10x200+0+0 8-bit sRGB 2186B 0.000u 0:00.000 Resize Multiple files Resize multiple file ../test.py -i &quot;*.png&quot; All result will be printed to “OUT” director. ../test.py -i OUT -o test -w 100 reading all pictures from OUT directory, and all result where out put to test file update Print information 2020/2/9 Adding arguments parser.add_argument('-inf','-INF','--infor',default = &quot;None&quot;) #resize by HeightINFORM = args.infor Def functions： def Resize_loop(): if Typ_in == &quot;File&quot;: Result = Resize(INPUT,W_img,H_img,R_img) Result.save(OUTPUT, quality=Quality) elif Typ_in == &quot;Files&quot;: List = os.popen(&quot;ls &quot;+INPUT).read().split('\\n')[:-1] for i in List: Result = Resize(i,W_img,H_img,R_img) Result.save(OUTPUT + i.split('/')[-1], quality=Quality) elif Typ_in == &quot;Directory&quot;: List = os.popen(&quot;ls &quot;+INPUT+&quot;/*&quot;).read().split('\\n')[:-1] for i in List: Result = Resize(i,W_img,H_img,R_img) Result.save(OUTPUT+i.split('/')[-1], quality=Quality)def IMG_inf(INPUT): Space = size_format(getsize(INPUT)) Img = Image.open(INPUT) Name = Img.filename Format = Img.format_description Mode = Img.mode try: Bit = &quot;bit:&quot; + str(Img.bits) except: Bit = &quot;bit:NA&quot; try: Dpi = &quot;dpi:&quot; + 'x'.join([str(x) for x in Img.info['dpi']]) except: Dpi = &quot;dpi: NA&quot; Size = &quot;size:&quot; + 'x'.join([str(x) for x in Img.size]) Result = Name +&quot;\\t&quot;+&quot; &quot;.join([Space, Size, Dpi, Format,Mode,Bit]) return Result Logic: if INFORM == &quot;None&quot;: # Resize Typ_in = FD_judge(INPUT) print(Typ_in) OUTPUT = OUT_fig(INPUT,OUTPUT) Resize_loop()else: # img information Typ_in = FD_judge(INPUT) if Typ_in == &quot;File&quot;: print(IMG_inf(INPUT)) elif Typ_in == &quot;Files&quot;: #List = os.popen(&quot;ls &quot;+INPUT).read().split('\\n')[:-1] List = os.popen(&quot;ls &quot;+INPUT).read().split('\\n\\n')[0].split('\\n')[:-1] for i in List: print(IMG_inf(i)) elif Typ_in == &quot;Directory&quot;: List = os.popen(&quot;ls &quot;+INPUT+&quot;/*&quot;).read().split('\\n\\n')[0].split('\\n')[:-1] for i in List: print(IMG_inf(i)) Usage: Imresize.py -i &quot;*&quot; -inf 1 output: Details: Name Size Width&amp;height DPI format mode Bit bash.jpg 16.8KB size:800x450 dpi: NA JPEG (ISO 10918) RGB bit:8 st=>start: Python read op1=>operation: Target(s) c1=>condition: Print inf c2=>condition: File/Directory c3=>condition: Single File op2=>operation: File op3=>operation: Files op4=>operation: Risze op5=>operation: 添加代码 op5=>operation: 初始化评论 e=>end: 完成!! Enjoy！ st->op1 op1->c1 c1(yes,right)->c2 c1(no)->e c2(yes,right)->c3 c3(yes)->op2 c3(no)->op3 op2(left)->op4 op3->op4 c2(no)->op4 op4(left)->e{\"theme\":\"simple\",\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"flowchart-0-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"flowchart-0-options\").value)); var diagram = flowchart.parse(code); diagram.drawSVG(\"flowchart-0\", options);","link":"/2020/10/25/Blog/Python_imgResize/"},{"title":"刪除低map的reads","text":"刪除低map的reads 1. 讀取counts文件並篩選 1.1 頻率分佈統計 ## Trintiy 腳本獲取的counts文件A &lt;- read.csv(&quot;/media/ken/Data/Yan/RNA-seq/report/4.exprs//All_isoform.COUNT.matrix.anno.xls&quot;,sep='\\t')head(A) X.ID1 ID2 Liver_CK Intest_CK Muscle_CK Liver_30 Intest_30 Muscle_30 Liver_75 Intest_75 Muscle_751 TRINITY_DN100000_c1_g1 TRINITY_DN100000_c1_g1_i1 212 331 89 128 401 223 310 407 1302 TRINITY_DN100001_c0_g1 TRINITY_DN100001_c0_g1_i1 35 1244 1 14 609 261 12 1085 03 TRINITY_DN100002_c0_g1 TRINITY_DN100002_c0_g1_i1 27 4 2 38 7 3 19 16 74 TRINITY_DN100002_c1_g1 TRINITY_DN100002_c1_g1_i1 23 2 34 4 6 18 8 5 515 TRINITY_DN100002_c2_g2 TRINITY_DN100002_c2_g2_i1 0 1 0 0 0 0 1 1 06 TRINITY_DN100002_c2_g3 TRINITY_DN100002_c2_g3_i1 0 0 40 0 0 62 0 1 84 row.names(A)=A[[2]]A$Sum = rowSums(A[-c(1:2)]) 1.2 繪圖 library(ggplot2)library(reshape2)ggplot(A[c(&quot;ID2&quot;,&quot;Sum&quot;)])+ geom_density(aes(x=Sum)) + xlim(c(0,25)) + theme_linedraw() 如圖所示， 大部分的hit總和小於等於3。應爲有9個樣本， 所以我們把閾值設置在10，則： A_sub = A[which(A$Sum&gt;10),]paste(round((nrow(A_sub)/nrow(A))*100,2),&quot;%&quot;,sep=&quot;&quot;) 可知， 剩餘&quot;52.86%&quot;的reads被保存了 輸出ID： write.table(A_sub[[2]],&quot;filt.list&quot;,row.names = F,quote=F,col.names=F)","link":"/2020/08/04/Blog/fasta_counts_ex/"},{"title":"Find Dead Links in Your Blog&#x2F;Website","text":"Find Dead Links in Your Blog/Website Links may die from time to time. For example, some posts might be deleted, some old servers may be shout-done, some links dead because the host transplanted to another platform. These dead links may damage your website’s rankings and usability. So, it is important to check and delete them periodically. Dead Link Checker This is one of the most friendly and powerful tools for dead link check! You can check a single page or Whole Website at a time. You can check the first 2000 links on our website. But for more services, you must subscribe to achieve advanced applications. Chick the single page Chick the website Deleted the Deadlinks ## delete page0 which generated by hexo theme-icarussed -i '/page\\/0\\//d' linsk.csv## Deleted blogs from csdnsed -i '/https:\\/\\/blog.csdn.net\\//d' linsk.csvsed -i '/cnblogs.com/d' linsk.csv## Deleted blogs from 云栖社区sed -i '/yq.aliyun.com/d' linsk.csv## Some links work for mesed -i '/edrawsoft.cn/d' linsk.csvsed -i '/cj.weather.com.cn/d' linsk.csv## Deleted the line which have the linklinks=https://karobben.github.io/2020/07/28/Bioinfor/BioDB/ii=$(echo $links|sed 's=/=\\\\/=g')sed -i &quot;/$ii/d&quot; example.md 站长工具 This tool can only check a single page. Local Dead Link Check Python Deadlinks GitHub: butuzov ## Insatllpip install deadlinks## rundeadlinks gobyexample.com -n 10 -e -d play.golang.org -d github.com © butuzov I am currently running this version: Name: deadlinks Version: 0.3.2 Summary: Health checks for your documentation links. Home-page: https://github.com/butuzov/deadlinks Author: Oleg Butuzov Author-email: butuzov@made.ua License: Apache License 2.0 Location: ~/.local/lib/python3.7/site-packages Requires: reppy, six, click, requests, urllib3 Required-by: But it is easy to cease when we have too many deadlinks. So, I’d like to add a timeout argument. But I failed. By checking the command, we know taht the main function is __main__.py cat $(which deadlinks) ## -*- coding: utf-8 -*- import re import sys from deadlinks.__main__ import main if __name__ == '__main__': sys.argv[0] = re.sub(r'(-script\\.pyw|\\.exe)?$', '', sys.argv[0]) sys.exit(main()) So, let’s check the (part of codes) __main__.py: from .settings import Settingsdef main(ctx: click.Context, url: str, **opts: Options) -&gt; None: &quot;&quot;&quot; Check links in your (web) documentation for accessibility. &quot;&quot;&quot; try: settings = Settings(url, **opts) crawler = Crawler(settings) driver = exporters[str(opts['export'])] # Instantion of the exported before starting crawling will alow us to # have progress report, while we crawling website. exporter = driver(crawler, **opts) It looks like it is checking the web with the function crawler and arguments are stored at **opts which handled by Settings Write your tools For my example, all my html are in the directory of public. So, my strategist is: find all &lt;a&gt; tags (grep) remove redundant part (awk) sorting all href (sort|uniq) filter reliable links ## comendcat $(find public/ -name &quot;*.html&quot;)| \\ tr &quot;&lt;&quot; &quot;\\n&quot;|grep -E &quot;^a|^img&quot;| \\ tr ' ' '\\n'|grep -E &quot;href|src&quot;| \\ awk -F&quot;&gt;&quot; '{print $1}'|awk -F&quot;=&quot; '{print $2}'| \\ awk -F&quot;#&quot; '{print $1}' |sed 's/&quot;//g'| \\ sort|uniq| \\ grep -v ^\\&quot;\\#|grep -v ^/ |\\ grep -vE &quot;https://karobben.github.io/|javascri&quot; |\\ grep -E &quot;^http|^ftp&quot; |sed 's/^/[1](/;s/$/)/' &gt; link_list.md Then, run another script import multiprocessing as mpimport time, reimport requests## Read links from md and stored them in ListInput = &quot;link_list.md&quot;F = open(Input,'r')File = F.read()pattern = re.compile(r'\\(http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\\)') # 匹配模式List = pattern.findall(File)## Clean the listList_clean = []for i in List: List_clean += [i.replace('(','').replace(&quot;)&quot;,&quot;&quot;)]List =List_clean## Define a function for test the urldef RespTime(url,return_dict): # Page is exist or not try: r = requests.get(url, timeout=20) Result = url+&quot;\\t&quot;+str(r.elapsed.total_seconds()) except: Result = url+&quot;\\tFailed&quot; print(Result) return_dict[Result] = Result## run all linksif __name__ == '__main__': manager = mp.Manager() return_dict = manager.dict() jobs = [] for i in List: p = mp.Process(target=RespTime, args=(i,return_dict)) jobs.append(p) p.start() for proc in jobs: proc.join()##F_list = ['www.youtube.com', 'github.com']## store the live linksLink_ok = []for i in return_dict.values(): if 'Failed' not in i: Link_ok += [i.split('\\t')[0]] print(i)## remove the alive links and run it againlen(List)for i in Link_ok: List.remove(i)for i in List: print(&quot;[1](&quot;,i,&quot;)&quot;,sep='')","link":"/2021/02/28/Blog/dead_link/"},{"title":"Nutrition Data Sheet Visualization","text":"Complicate Nutrition Data Sheet Visualization Example Data A &lt;- read.table(&quot;Digestive_Enzymes.csv&quot;,sep=',',header=T) In this matrix, we have unique colname and rowname. There are ± and abc followed with the numbers. Data Matrix online: Github Gastric_Pepsin Gastric_Amylase Gastric_Lipase Intestinal_PepsinG1 17.23±0.03f 0.68±0.00 18.08±0.12f 1.54±0.01dG2 18.48±0.02e 0.71±0.00 19.11±0.11e 1.62±0.01cG3 20.67±0.04d 0.77±0.00 20.0±0.14ad 1.68±0.01bcG4 22.32±0.10c 0.80±0.00 20.71±0.21ab 1.76±0.02abG5 24.21±0.04ab 0.84±0.00 21.18±0.25a 1.78±0.01abG6 17.38±0.02de 0.70±0.00 17.63±0.15f 1.57±0.02cd Data Clean NutriSplit &lt;- function(A){ A1 &lt;- c() A2 &lt;- c() # Split the Avr and Disparity for(i in A){ tmp1 = sapply(strsplit(as.character(i),'±'),&quot;[&quot;,1) tmp2 = sapply(strsplit(as.character(i),'±'),&quot;[&quot;,2) A1 &lt;- c(A1,tmp1) A2 &lt;- c(A2,tmp2) } A1 &lt;- as.numeric(A1) # split the Dist and Significant A2_1 &lt;- gsub(&quot;[^0-9.]&quot;, &quot;&quot;, A2) A2_2 &lt;- gsub(&quot;[^a-z]&quot;, &quot;&quot;, A2) # Matrix A1 &lt;- matrix(A1,nrow = nrow(A)) A2_1 &lt;- matrix(as.numeric(A2_1),nrow = nrow(A)) A2_2 &lt;- matrix(A2_2,nrow = nrow(A)) colnames(A1) = colnames(A2_1) = colnames(A2_2) = colnames(A) rownames(A1) = rownames(A2_1) = rownames(A2_2) = rownames(A) A1 &lt;- data.frame(A1) A2_1 &lt;- data.frame(A2_1) A2_2 &lt;- data.frame(A2_2) Result = c() Result$Avr &lt;- A1 Result$Dit &lt;- A2_1 Result$Sig &lt;- A2_2 return(Result)} Plot library(ggplot2)library(reshape2)library(ggrepel)TB &lt;- NutriSplit(t(A))ggplot(melt(as.matrix(TB$Avr)),aes(x=Var2,y=value)) + geom_line(aes(group=Var1)) + geom_errorbar(aes(ymin=value-melt(as.matrix(TB$Dit))$value, ymax=value+melt(as.matrix(TB$Dit))$value), width=0.2)+ geom_text_repel(aes(x=Var2,y=value,label= melt(as.matrix(TB$Sig))$value, color= 'blue' ))+ theme_light() + facet_wrap(~Var1, scales = 'free')+ geom_point(aes(color=melt(as.matrix(TB$Sig))$value))+ theme(axis.text.x=element_text(angle=45, hjust=1))","link":"/2020/07/28/Blog/ggplot_NRPlot/"},{"title":"ggplot畫斷層圖","text":"ggplot畫斷層圖 library(ggplot2)library(patchwork)data(cars)cars[1,2] =100000p &lt;- ggplot(cars,aes(x=speed,y=dist)) + geom_bar(stat='identity') 通過patchwork， 拼接得到想要的圖 p1 &lt;- p + coord_cartesian(ylim = c(0,400))p2 &lt;- p + coord_cartesian(ylim = c(99998,100020))+ theme(axis.text.x = element_blank(), axis.title = element_blank(), axis.ticks.x = element_blank())layout &lt;- 'A\\nB\\nB\\nB'p2/p1 + plot_layout(design = layout) 原圖 拼接圖 函數封裝 SplitBar &lt;- function(p, Y1,Y2,Y3, Y0=0,R=c(1,1)){ Lay = c(rep(&quot;A&quot;,R[1]),rep(&quot;B&quot;,R[2])) layout=&quot;&quot; for( i in Lay){ layout=paste(layout,i,sep=&quot;\\n&quot;) } p1 &lt;- p + coord_cartesian(ylim = c(Y2,Y3))+ theme(axis.text.x = element_blank(), axis.title = element_blank(), axis.ticks.x = element_blank(), legend.position = 'none', panel.grid = element_blank(), panel.border = element_blank(), axis.line.y = element_line(colour = &quot;black&quot;)) p2 &lt;- p + coord_cartesian(ylim = c(Y0,Y1))+ theme(title = element_blank(), plot.title = element_blank(), panel.grid = element_blank(), panel.border = element_blank(), axis.line = element_line(colour = &quot;black&quot;)) p1/p2 + plot_layout(design = layout)}SplitBar(p,450,99998,100011,0,c(1,10)) p &lt;- ggplot(cars,aes(x=speed,y=dist)) + geom_bar(,fill=cars$speed,stat='identity') + theme_light()+ ggtitle('哈哈哈哈') + theme( plot.title = element_text(hjust = 0.5))SplitBar(p,450,99998,100021,0,c(1,5)) 原圖 拼接圖 Keep updating in package: remotes::install_github(&quot;karobben/ggkaboom&quot;)library(ggkaboom)data(cars)cars[1,2] =100000p &lt;- ggplot(cars,aes(x=speed,y=dist, fill=as.factor(speed))) + geom_bar(stat='identity')Kaboom_break(p, c(0, 15, 30, 400, 10000, 120000), R=c(1,4, 2))Kaboom_break(p, c(0, 15, 30, 400, 10000, 120000), R=c(1, 4, 2), panel.grid.scale = 'len', panel.grid.num = 6) No panel.grid parameters With panel.grid parameters","link":"/2020/06/11/Blog/ggplot_split/"},{"title":"Hexo theme: Butterfly","text":"12 Butterfly npm install hexo-renderer-pug hexo-renderer-stylusnpm i hexo-theme-butterflyvim - theme: landscape+ theme: butterfly Change the Pohoto from main page Reference: © Moqiqiuzi index_img: htts://......png","link":"/2022/09/05/Blog/hexo-butterfly/"},{"title":"KEGG result visualization by ggplot","text":"KEGG result visualization by ggplot 用ggplot画KEGG结果 Data Before running the codes, I’d like to have a brief introduces about my data. As you can see codes below, List has all files I need. Take Intest_30_vs_Intest_75 as an example: #KEGGid KEGGdescription KEGGclass KEGGsubclass Oddsratio p-value q-value Gene_numbers 04610 Complement and coagulation cascades Organismal Systems Immune system 11.7158541941 6.30141083687e-10 1.18731846295e-07 14 04977 Vitamin digestion and absorption Organismal Systems Digestive system 11.1739766082 0.000269773611998 0.0254155139724 5 04974 Protein digestion and absorption Organismal Systems Digestive system 3.73319892473 0.000445170135803 0.0279598085294 11 Quick Start library(ggplot2)library(reshape2)library(patchwork)List = c('Intest_30_vs_Intest_75','Intest_CK_vs_Intest_30','Intest_CK_vs_Intest_75','Liver_30_vs_Liver_75','Liver_CK_vs_Liver_30','Liver_CK_vs_Liver_75','Muscle_30_vs_Muscle_75','Muscle_CK_vs_Muscle_30','Muscle_CK_vs_Muscle_75')TB = data.frame()for(i in List){ A &lt;- read.table(paste(&quot;../&quot;,i,&quot;/kegg_annotation/Diff_exprs.KEGG_enrich.lst.network&quot;, sep = &quot;&quot;), sep = '\\t') A$Group=i print(dim(A)) TB = rbind(TB,A)}TB$SubG = &quot;Intest&quot;TB$SubG[grep( &quot;Muscle&quot;, TB$Group)] = &quot;Muscle&quot;TB$SubG[grep( &quot;Liver&quot;, TB$Group)] = &quot;Liver&quot;## KEGG Dotsp1&lt;- ggplot(TB)+ geom_point(aes(x=Group,y=V2,size=V8,color=V6)) + theme(axis.text.x = element_text(angle = 45,hjust = 1)) + facet_grid(~SubG, scales = 'free')p2 &lt;- ggplot(TB)+ geom_point(aes(x=Group,y=V2,size=V8,color=V6)) + theme(axis.text.x = element_text(angle = 45,hjust = 1), strip.text.y = element_text(size=12, face=&quot;bold&quot;, angle = 0), strip.background.y = element_blank()) + facet_grid(V3~SubG, scales = 'free', space = 'free')p3 &lt;- ggplot(TB)+ geom_point(aes(x=Group,y=V2,size=V8,color=V6)) + theme(axis.text.x = element_text(angle = 45,hjust = 1), strip.text.y = element_text(size=12, face=&quot;bold&quot;, angle = 0), strip.background.y = element_blank()) + facet_grid(V4~SubG, scales = 'free', space = 'free')## KEGG subclass_barp4 &lt;- ggplot(TB)+ geom_bar(aes(x=V3,fill=Group), ,position = 'dodge') + theme(axis.text.x = element_text(angle = 45,hjust = 1))+ facet_wrap(~SubG, scales = 'free')LL &lt;- 'AAAAB'p2+p4 +plot_layout(design = LL) More complicate plot Functions TreePlot and LS_judg could be found at: Blog/Yueque clust_TB &lt;- reshape(TB[c(&quot;V4&quot;,&quot;V8&quot;,&quot;Group&quot;)],timevar='Group', idvar=c('V4'),direction='wide')row.names(clust_TB)=clust_TB[[1]]clust_TB= clust_TB[-1]clust_TB[is.na(clust_TB)] = 0hc &lt;- hclust(dist(clust_TB))dendr &lt;- dendro_data(hc, type=&quot;rectangle&quot;) # convert for ggplotdendr$labels$cluster &lt;- TB$V3[match(dendr$labels$label,TB$V4)]## plot the dendrogram; note use of color=cluster in geom_text(...)p_tree &lt;- ggplot() + geom_segment(data=segment(dendr), aes(x=x, y=y, xend=xend, yend=yend)) + geom_text(data=label(dendr), aes(x, y, label=label, hjust=0, color=cluster), size=3) + coord_flip() + #scale_y_reverse(expand=c(0.2, 0)) + theme(axis.line.y=element_blank(), axis.ticks.y=element_blank(), axis.text.y=element_blank(), axis.title.y=element_blank(), panel.background=element_rect(fill=&quot;white&quot;), panel.grid=element_blank())TB$V4 = factor(TB$V4,levels(dendr$labels$label))TB = TB[order(TB$V4),]TB$V2 = factor(TB$V2,levels=(unique(TB$V2)))TB_mbar = data.frame(table(unique(TB[c(&quot;V2&quot;,&quot;V4&quot;)])$V4))TB_mbar$hei = TB_mbar$Freq[1]/2for(i in c(2:nrow(TB_mbar))){ TB_mbar$hei[i] =sum(TB_mbar$Freq[1:i-1])+ (TB_mbar$Freq[i]/2)}Width_tree = TB_mbar$heiden_2 &lt;- TreePlot(dendr, Width_tree)Result = c()C_list=c('#178c60','#B4292C')TB_mbar = data.frame(table(TB$V4))Num = 0for(i in TB_mbar$Freq){ Result = c(Result,rep(C_list[Num%%2+1],i)) Num = Num +1}p_dot &lt;- ggplot(TB)+ geom_point(aes(x=Group,y=V2,size=V8,color=V6)) + labs(y=&quot;Pathway&quot;)+ theme(axis.text.x = element_text(angle = 45,hjust = 1), axis.text = element_text(size=10), strip.text.y = element_text(size=12, face=&quot;bold&quot;, angle = 0), strip.background.y = element_blank(), legend.position='left', panel.background = element_blank(), panel.grid.major= element_line(linetype=2,color='grey'), panel.grid.minor= element_blank())+ geom_tile(aes(x=10,y=V2), fill= Result)+ scale_color_gradient(low = &quot;salmon&quot;,high = &quot;steelblue&quot;)p_tree &lt;- ggplot() + geom_segment(data=segment(den_2), aes(x=x, y=y, xend=xend, yend=yend)) + geom_text(data=label(dendr), aes(Width_tree, y, label=levels(dendr$labels$label), hjust=1, color=cluster),size=4) + coord_flip() + #scale_y_reverse(expand=c(0.2, 0)) + labs(y='Distance')+ theme(axis.line.y=element_blank(), axis.ticks.y=element_blank(), axis.text.y=element_blank(), axis.title.y=element_blank(), panel.background=element_blank(), panel.grid=element_blank()) + expand_limits(y=c(-80,10),x=c(0,68))ggdraw() + draw_plot(p_dot,0,0.007,0.4)+ draw_plot(p_tree,0.4,0.068,0.6,0.98)ggsave('KEGG_tree.png',wi=20.4,hei=11) More Get a KEGG results first codes from: ClusterProfiler library(clusterProfiler)data(geneList, package=&quot;DOSE&quot;)gene &lt;- names(geneList)[abs(geneList) &gt; 2]kk &lt;- enrichKEGG(gene = gene, organism = 'hsa', pvalueCutoff = 0.05)head(kk) $Cos\\alpha = \\frac{tA}{tC}$ $Sin\\alpha = \\frac{\\sqrt{tC^2 - tA^2}}{tC}$ $mC = \\frac{mB_1}{Sin\\alpha}$ $mtC = mC * \\frac{mB_1 - mB_2}{mB_2}$ $S = mtC/tC$ $S = \\frac{mC * \\frac{mB_1 - mB_2}{mB_2}}{tC}$ $S = \\frac{\\frac{mB_1}{Sin\\alpha} * \\frac{mB_1 - mB_2}{mB_2}}{tC}$ $S = \\frac{\\frac{mB_1}{\\frac{\\sqrt{tC^2 - tA^2}}{tC}} * \\frac{mB_1 - mB_2}{mB_2}}{tC}$ $S = \\frac{\\frac{mB_1}{\\frac{\\sqrt{tC^2 - tA^2}}{tC}} * \\frac{mB_1 - mB_2}{mB_2}}{tC}$ $S = \\frac{\\frac{mB_1^2 - mB_1 * mB_2 }{\\frac{mB_2\\sqrt{tC^2 - tA^2}}{tC}}}{tC}$ $S = \\frac{mB_1^2 - mB_1 * mB_2 }{\\frac{mB_2\\sqrt{tC^2 - tA2}}{tC2}}$ $S = \\frac{mB_1^2 - mB_1 * mB_2 }{tC^2 * mB_2\\sqrt{tC^2 - tA^2}}$","link":"/2020/08/04/Blog/ggplot_KEGG/"},{"title":"Hexo: Sitemap| Generate and Submit your Hexo-Sitemaps to Google and Bing","text":"“Hexo: Sitemap” The Sitemaps protocol allows a webmaster to inform search engines about URLs on a website that are available for crawling. A Sitemap is an XML file that lists the URLs for a site. It allows webmasters to include additional information about each URL: when it was last updated, how often it changes, and how important it is in relation to other URLs of the site. This allows search engines to crawl the site more efficiently and to find URLs that may be isolated from the rest of the site’s content. The Sitemaps protocol is a URL inclusion protocol and complements robots.txt, a URL exclusion protocol.[1] install plugins[2] # for googlenpm install hexo-generator-sitemap --save# for baidunpm install hexo-generator-baidu-sitemap --save Config # URL## If your site is put in a subdirectory,set url as 'http://yoursite.com/child' and root as '/child/'url: ${your domain}root: /permalink: :year/:month/:day/:title/permalink_defaults:pretty_urls: trailing_index: true # Set to false to remove trailing 'index.html' from permalinks trailing_html: true # Set to false to remove trailing '.html' from permalinks Submit to BBG[3] I am currently using GitPage. So, submitting it to Baidu is kind of useless… Before Submitting it to Google/Bing, we need to verify the ownership of the domain. The easiest way to verify this is by adding it to your Google Analytics. Once you’re down with google, you can synchronize it to Bing with Google. wikipedia: Sitemaps ↩︎ 沧沧凉凉, 2020: Hexo进阶-生成站点地图（Sitemap） ↩︎ FLUNGGG, 2019: hexo搭建博客系列(六)百度，必应，谷歌收录 ↩︎","link":"/2021/03/22/Blog/hexo-sitemap/"},{"title":"用 ggplot 畫 hclust 的結果","text":"用 ggplot 畫 hclust 的結果 drawing hclust result with ggplot data(mtcars)Tree &lt;- hclust(dist(mtcars))plot(Tree) library(ggplot2)library(ggdendro)hc &lt;- hclust(dist(mtcars)) # heirarchal clusteringdendr &lt;- dendro_data(hc, type=&quot;rectangle&quot;) # convert for ggplotclust &lt;- cutree(hc,k=5) # find 2 clustersclust.df &lt;- data.frame(label=names(clust), cluster=factor(clust))## dendr[[&quot;labels&quot;]] has the labels, merge with clust.df based on label columndendr[[&quot;labels&quot;]] &lt;- merge(dendr[[&quot;labels&quot;]],clust.df, by=&quot;label&quot;)## plot the dendrogram; note use of color=cluster in geom_text(...)ggplot() + geom_segment(data=segment(dendr), aes(x=x, y=y, xend=xend, yend=yend)) + geom_text(data=label(dendr), aes(x, y, label=label, hjust=0, color=cluster), size=3) + coord_flip() + scale_y_reverse(expand=c(0.2, 0)) + theme(axis.line.y=element_blank(), axis.ticks.y=element_blank(), axis.text.y=element_blank(), axis.title.y=element_blank(), panel.background=element_rect(fill=&quot;white&quot;), panel.grid=element_blank()) 美美噠！ 自定義間距： library(ggplot2)library(ggdendro)hc &lt;- hclust(dist(head(mtcars)))dendr &lt;- dendro_data(hc, type=&quot;rectangle&quot;) # convert for ggplotclust &lt;- cutree(hc,k=2) # find 2 clustersclust.df &lt;- data.frame(label=names(clust), cluster=factor(clust))## dendr[[&quot;labels&quot;]] has the labels, merge with clust.df based on label columndendr[[&quot;labels&quot;]] &lt;- merge(dendr[[&quot;labels&quot;]],clust.df, by=&quot;label&quot;)## plot the dendrogram; note use of color=cluster in geom_text(...)ggplot() + geom_segment(data=segment(dendr), aes(x=x, y=y, xend=xend, yend=yend)) + geom_text(data=label(dendr), aes(x, y, label=label, hjust=0, color=cluster), size=3) + coord_flip() + scale_y_reverse(expand=c(0.2, 0)) + theme(axis.line.y=element_blank(), axis.ticks.y=element_blank(), axis.text.y=element_blank(), axis.title.y=element_blank(), panel.background=element_rect(fill=&quot;white&quot;), panel.grid=element_blank()) 觀察數據可知， 樹圖數據在dendr$segment裏面， 名字在dendr$label裏面。先給定一個listWidth_tree = c(1,2,5,10,11,20) hc &lt;- hclust(dist(head(mtcars)))dendr &lt;- dendro_data(hc, type=&quot;rectangle&quot;) # convert for ggplotclust &lt;- cutree(hc,k=2) # find 2 clustersclust.df &lt;- data.frame(label=names(clust), cluster=factor(clust))## dendr[[&quot;labels&quot;]] has the labels, merge with clust.df based on label columndendr[[&quot;labels&quot;]] &lt;- merge(dendr[[&quot;labels&quot;]],clust.df, by=&quot;label&quot;)## plot the dendrogram; note use of color=cluster in geom_text(...)ggplot() + geom_segment(data=segment(dendr), aes(x=x, y=y, xend=xend, yend=yend)) + geom_text(data=label(dendr), aes(x, y, label=label, hjust=0, color=cluster), size=3) + scale_y_reverse(expand=c(0.2, 0)) + theme(axis.line.y=element_blank(), axis.ticks.y=element_blank(), axis.text.y=element_blank(), axis.title.y=element_blank(), panel.background=element_rect(fill=&quot;white&quot;), panel.grid=element_blank())Width_tree = c(1,2,5,10,11,20)dendr$labels$x = Width_tree[dendr$labels$x]dendr$segments = dendr$segments[order(dendr$segments$x),]## 做個listList = c()for(i in c(1:length(Width_tree))){ List = c(List, which(dendr$segments$x==i))} 打包一個函數，方便重複畫圖 PLOT &lt;- function(dendr){ ggplot() + geom_segment(data=segment(dendr), aes(x=x, y=y, xend=xend, yend=yend)) + geom_text(data=label(dendr), aes(x, y, label=label, hjust=0, color=cluster), size=3) + scale_y_reverse(expand=c(0.2, 0)) + theme(axis.line.y=element_blank(), axis.ticks.y=element_blank(), axis.text.y=element_blank(), axis.title.y=element_blank(), panel.background=element_rect(fill=&quot;white&quot;), panel.grid=element_blank())}PLOT2 &lt;- function(dendr){ ggplot() + geom_segment(data=segment(dendr), aes(x=x, y=y, xend=xend, yend=yend)) + geom_text(data=label(dendr), aes(x, y, label=label, hjust=0, color=cluster), size=3) + coord_flip() + scale_y_reverse(expand=c(0.2, 0)) + theme(axis.line.y=element_blank(), axis.ticks.y=element_blank(), axis.text.y=element_blank(), axis.title.y=element_blank(), panel.background=element_rect(fill=&quot;white&quot;), panel.grid=element_blank())} 調整豎線 for( i in c(1:6)){Dif_tmp = Width_tree[i]- dendr$segments$x[List[i]]dendr$segments$x[List[i]:nrow(dendr$segments)] = dendr$segments$x[List[i]:nrow(dendr$segments)]+Dif_tmpdendr$segments$xend[List[i]:nrow(dendr$segments)] = dendr$segments$xend[List[i]:nrow(dendr$segments)]+Dif_tmp}PLOT(dendr) 鏈接橫線 ##刪除橫線dendr$segments = dendr$segments[dendr$segments$x == dendr$segments$xend,]Y_list = dendr$segments$y[duplicated(dendr$segments$y)]for(i in Y_list){ tmp = (dendr$segments$x[dendr$segments$y == i])dendr$segments = rbind(dendr$segments, data.frame(x=tmp[1],y=i,xend=tmp[2],yend=i))}PLOT(dendr) 能用。。。但是好像會有bug。。唉= = 修正 LS_judg&lt;- function(TB){ if (TB['x'] == TB['xend']){ R = 'v' }else{ R = 'h' } return(R)}##修正竖线Seg = dendr$segmentsfor( i in c(nrow(dendr$segments):1)){ if(LS_judg(dendr$segments[i,]) == 'h'){ tmpy = dendr$segments[i,]$y tmpTB = Seg[Seg$yend== tmpy,] for( ii in c(1:nrow(tmpTB))){ if(LS_judg(tmpTB[ii,]) == 'v'){ Num = rownames(tmpTB[1,]) dendr$segments[match(Num, row.names(dendr$segments)),][c(1,3)] = sum(Seg[i,c('x','xend')])/2 } } }}## 重画横线：dendr$segments = dendr$segments[dendr$segments$x == dendr$segments$xend,]Y_list = dendr$segments$y[duplicated(dendr$segments$y)]for(i in Y_list){ tmp = (dendr$segments$x[dendr$segments$y == i])dendr$segments = rbind(dendr$segments, data.frame(x=tmp[1],y=i,xend=tmp[2],yend=i))}PLOT(dendr) 整合一下： Width_tree = c(1,2,5,10,11,20)LS_judg&lt;- function(TB){ if (TB['x'] == TB['xend']){ R = 'v' }else{ R = 'h' } return(R)}TreePlot &lt;- function(dendr, Width_tree){ dendr$labels$x = Width_tree[dendr$labels$x] dendr$segments = dendr$segments[order(dendr$segments$x),] # 做個list List = c() for(i in c(1:length(Width_tree))){ List = c(List, which(dendr$segments$x==i)) } # 調整豎線 for( i in c(1:length(dendr$labels$label))){ Dif_tmp = Width_tree[i]- dendr$segments$x[List[i]] dendr$segments$x[List[i]:nrow(dendr$segments)] = dendr$segments$x[List[i]:nrow(dendr$segments)]+Dif_tmp dendr$segments$xend[List[i]:nrow(dendr$segments)] = dendr$segments$xend[List[i]:nrow(dendr$segments)]+Dif_tmp } # 刪除添加新的橫線 dendr$segments = dendr$segments[dendr$segments$x == dendr$segments$xend,] Y_list = dendr$segments$y[duplicated(dendr$segments$y)] for(i in Y_list){ tmp = (dendr$segments$x[dendr$segments$y == i]) dendr$segments = rbind(dendr$segments, data.frame(x=tmp[1],y=i,xend=tmp[2],yend=i)) } Seg = dendr$segments for( i in c(nrow(dendr$segments):1)){ if(LS_judg(dendr$segments[i,]) == 'h'){ tmpy = dendr$segments[i,]$y tmpTB = Seg[Seg$yend== tmpy,] for( ii in c(1:nrow(tmpTB))){ if(LS_judg(tmpTB[ii,]) == 'v'){ Num = rownames(tmpTB[1,]) dendr$segments[match(Num, row.names(dendr$segments)),][c(1,3)] = sum(Seg[i,c('x','xend')])/2 } } } } # 重画横线： dendr$segments = dendr$segments[dendr$segments$x == dendr$segments$xend,] Y_list = dendr$segments$y[duplicated(dendr$segments$y)] for(i in Y_list){ tmp = (dendr$segments$x[dendr$segments$y == i]) dendr$segments = rbind(dendr$segments, data.frame(x=tmp[1],y=i,xend=tmp[2],yend=i)) } return(dendr)} 再來試一下： 正常情況: library(ggplot2)library(ggdendro)hc &lt;- hclust(dist(mtcars)) # heirarchal clusteringdendr &lt;- dendro_data(hc, type=&quot;rectangle&quot;) # convert for ggplotclust &lt;- cutree(hc,k=5) # find 2 clustersclust.df &lt;- data.frame(label=names(clust), cluster=factor(clust))## dendr[[&quot;labels&quot;]] has the labels, merge with clust.df based on label columndendr[[&quot;labels&quot;]] &lt;- merge(dendr[[&quot;labels&quot;]],clust.df, by=&quot;label&quot;)## plot the dendrogram; note use of color=cluster in geom_text(...)PLOT2(dendr) 轉化後： Width_tree =c(2, 5, 6, 10, 12, 13, 16, 20, 23, 24, 29, 37, 41, 42, 45, 47, 51, 53, 54, 57, 60, 61, 63, 67, 70, 173, 175, 276, 280, 281, 287, 593)AA &lt;- TreePlot(dendr,Width_tree)PLOT2(AA) 原圖 後圖 终于- - 终于终于， 修正好了， 最终版本 else: factoextra+dendextend","link":"/2020/08/04/Blog/ggplot_hclust/"},{"title":"Hexo: Visitor traffic map|Revolvermaps, clustrmaps, maploco| Static Blog","text":"A real-time visitor statistic map widget or visitor traffic map widget is a script that could show the visitor records on the maps. It is fun to see that you remain a trace on the site or notice that someone is visiting this site with you at the same time. For the owner, it could greatly gain a sense of achievement by watching this map and promoting their motivation to update. For static web-pages/blogs, there are few but awesome free-services we can use to decorate our pages. Please visit JNingWei[1] to see more! clustrmaps Where to git the widget: links Customize It is highly customizable and beautiful. But it runs a little bit slower than I expected. Effects: &lt;script type=&quot;text/javascript&quot; id=&quot;clustrmaps&quot; src=&quot;//clustrmaps.com/map_v2.js?d=-i1RAbH-h9aHEmWoLwPcQ5wyiILjE5GhqB9gLn_MTlQ&amp;cl=ffffff&amp;w=a&quot;&gt;&lt;/script&gt; 2D map: 3D Globe: maploco This is the easiest one to create. But it seems you can’t customize it Revolvermaps Customize Revolvermaps is one of the most popular visitor traffic maps among them since I saw them so frequently. It can not only show 2D maps but also a 3D globe is supportable. One thing that bothered me a lot was that I failed to customize it when I inserted it below my profile widget. I thought it was the fault of the revolvermaps. But I find that it works fine when it is present in the post. That means the JS in the profile widget doesn’t work appropriately. By comparing the source of the JS between profile and widget: There are slight differences between them Source in Profile: //rf.revolvermaps.com/w/7/a/a2.php?i=5obi4wthjqz&amp;amp;m=0c&amp;amp;c=f03b11&amp;amp;cr1=ffffff&amp;amp;sx=0&amp;amp;cw=ffffff&amp;amp;cb=3472cd Source in Posrt: //rf.revolvermaps.com/w/7/a/a2.php?i=5obi4wthjqz&amp;m=0c&amp;c=f03b11&amp;cr1=ffffff&amp;sx=0&amp;cw=ffffff&amp;cb=3472cd The raw source is //rf.revolvermaps.com/0/0/7.js?i=5obi4wthjqz&amp;amp;m=0c&amp;amp;c=f03b11&amp;amp;cr1=ffffff&amp;amp;sx=0&amp;amp;cw=ffffff&amp;amp;cb=3472cd So, I altered it as //rf.revolvermaps.com/0/0/7.js?i=5obi4wthjqz&amp;m=0c&amp;c=f03b11&amp;cr1=ffffff&amp;sx=0&amp;cw=ffffff&amp;cb=3472cd And them, boon!! It works fine, now! Enjoy~ JNingWei, 2017: 利用 visitor map (访客地图) 统计网站访客) ↩︎","link":"/2021/03/22/Blog/hexo-worldmap/"},{"title":"HTML Infinite Scroll","text":"HTML Infinite Scroll Github: janpaepke an example you can find at examples/advanced/infinite_scrolling.html. By deleting codes line by line, we can figure out that three lines below are essential for achieving this function. &lt;link rel=&quot;stylesheet&quot; href=&quot;../../assets/css/examples.css&quot; type=&quot;text/css&quot;&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;../../assets/js/lib/jquery.min.js&quot;&gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;../../scrollmagic/uncompressed/ScrollMagic.js&quot;&gt;&lt;/script&gt;","link":"/2020/06/26/Blog/html_infscroll/"},{"title":"khal, a fancy calendar app in your terminal","text":"khal calendar The store begins I find I had a very terrible memory and forget the schedules again and again. I really need a calendar to stick on the wall and remind me again and again. I considered some online services like outlook calendar or google calendar but they are not fancy. I think it could be cool that I can show it in the terminal, for one thing, is that I can make the background dark to save the bower. On the other hand, I can use the old tablet or android phone to display the calendar for a whole day in the “termux”. It could also be my small server for running some programs. According to some posts, it can also sync your online calendars like google calendar or outlook calendar. I tried to use vdirsyncer to synchronize the Google calendar but failed. I applied the Client ID but it tell me that I had uri_redirect_mistake. Annoying. But anyway, I still like to use it in local, synchronize them through the local network with some stupid bash scrip. So, I’ll introduce the basic use of the khal to build your local calendar. Cheers! vdirsyncer sudo apt install vdirsyncermkdir /home/ken/.config/vdirsyncertouch /home/ken/.config/vdirsyncer/configvdirsyncer discover personal_sync khal sudo apt install khal# Creat a configure filekhal configure How the initiated configure file looks like: [calendars] [[private]] path = /home/ken/.local/share/khal/calendars/private type = calendar [locale] timeformat = %H:%M dateformat = %Y-%m-%d longdateformat = %Y-%m-%d datetimeformat = %Y-%m-%d %H:%M longdatetimeformat = %Y-%m-%d %H:%M Detailed configuration paremeters could be find at: Documentation More information: Documentation Maybe check this: https://opensource.com/article/20/1/open-source-calendar https://vdirsyncer.pimutils.org/en/stable/config.html#google https://arwebhosting.com/blog/set-up-and-sync-your-calendar-with-khal-and-vdirsyncer/ http://manpages.ubuntu.com/manpages/bionic/man1/vdirsyncer.1.html Bugs in Termux File \"/data/data/com.termux/files/usr/lib/python3.9/site-packages/atomicwrites/__init__.py\", line 59, in _move_atomic os.link(src, dst) AttributeError: module 'os' has no attribute 'link' vim /data/data/com.termux/files/usr/lib/python3.9/site-packages/atomicwrites/__init__.py def link(src, dest): shutil.copyfile(src, dest)def unlink(src): os.remove(src)os.link = linkos.unlink = unlink","link":"/2022/05/02/Blog/khal/"},{"title":"pdf to txt| txt to pdf","text":"如何用python提取pdf的文本內容 pdf2txt.py; extract the txt from pdf files. github: pdfminer reference: Mr_Vague PDF to text 1.Install git clone https://github.com/pdfminer/pdfminer.six.gitpython3 setup.py install or you can use pip sudo pip3.7 install -i https://pypi.tuna.tsinghua.edu.cn/simple pdfminer.six 2. Run pdf2txt.py Papers/vilhelmsson2004.pdf| tail backs to: ken@ken-PC:~/Desktop$ pdf2txt.py Papers/vilhelmsson2004.pdf| tail -n 20Fotsis T &amp; Mann M (1996) Femtomole sequencing of proteinsfrom polyacrylamide gels by nano-electrospray mass spec-trometry. Nature 379, 466– 469.Wilson RP &amp; Cowey CB (1985) Amino acid composition ofwhole-body tissue of rainbow trout and Atlantic salmon. Aqua-culture 48, 373– 376.Wing SS, Haas AL &amp; Goldberg AL (1995) Increase in ubiquitin –protein conjugates concomitant with the increase in proteolysisin rat skeletal muscle during starvation and atrophy denerva-tion. Biochem J 307, 639–645.Yamamoto T, Shima T, Furuita H &amp; Suzuki N (2002) Inﬂuence offeeding diets with and without ﬁsh meal by hand and by self-feeders on feed intake, growth and nutrient utilization of juven-ile rainbow trout (Oncorhynchus mykiss). Aquaculture 214,289– 305.... Compare to raw file: © vilhelmsson 2004 PDF to html output as html file: pdf2txt.py -o test.html Papers/vilhelmsson2004.pdf Text to PDF Profile: mkumarchaudhary06 Install sudo pip3.7 install -i https://pypi.tuna.tsinghua.edu.cn/simple fpdf Quick Start from fpdf import FPDFpdf = FPDF() # save FPDF() class into a variable pdfpdf.add_page() # Add a pagepdf.set_font(&quot;Arial&quot;, size = 15) # set style and size of font that you want in the pdfpdf.cell(200, 10, txt = &quot;GeeksforGeeks&quot;, ln = 1, align = 'C') # create a cellpdf.cell(200, 10, txt = &quot;A Computer Science portal for geeks.&quot;, ln = 2, align = 'C') # add another cellpdf.output(&quot;GFG.pdf&quot;) # save the pdf with name .pdf Output: It works, but you need to slicing the sentences before running this codes or the contents will run out of the page. By solving this problem, there is a script in github: baruchel . It’s not perfect but it works. git clone https://github.com/baruchel/txt2pdf.gittxt2pdf -s 12 -o document.pdf document.txt","link":"/2020/10/25/Blog/pdf2txt/"},{"title":"Python: getting location through IP address","text":"Python: getting location through IP address Target Website: https://my.ip.cn/ import requestsimport timeurl = &quot;https://my.ip.cn/api/index?ip=&amp;type=0&quot;headers = { &quot;:authority&quot;: &quot;my.ip.cn&quot;, &quot;:method&quot;: &quot;GET&quot;, &quot;:path&quot;: &quot;/api/index?ip=&amp;type=0&quot;, &quot;:scheme&quot;: &quot;https&quot;, &quot;accept&quot;: &quot;application/json, text/javascript, */*; q=0.01&quot;, &quot;accept-encoding&quot;: &quot;gzip, deflate, br&quot;, &quot;accept-language&quot;: &quot;en-CN,en;q=0.9,zh-CN;q=0.8,zh;q=0.7,en-US;q=0.6,zh-TW;q=0.5,ja;q=0.4&quot;, &quot;cookie&quot;:&quot;__cfduid=dfd9a8ad770a7d54ed934a6adb02390651607854807; INIT_IP_INFO=%E4%B8%AD%E5%9B%BD++%E9%BB%91%E9%BE%99%E6%B1%9F%E7%9C%81+%E5%93%88%E5%B0%94%E6%BB%A8%E5%B8%82+%E8%81%94%E9%80%9A&quot;, &quot;referer&quot;: &quot;https://my.ip.cn/&quot;, &quot;user-agent&quot;: &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36&quot;, &quot;x-requested-with&quot;: &quot;XMLHttpRequest&quot;}Result = requests.get(url).json()## IPprint(Result['ip'])## Addressprint(Result['address'])City = Result['address'].split(&quot; &quot;)[-2]","link":"/2020/12/13/Blog/python_loc_get/"},{"title":"eChart is fun","text":"eChart is fun Official examples: Apache ECharts 请移步博客阅读, 不然只能是一堆乱码… Install eChart git clone https://github.com/apache/echarts.git Than, you can using it as the instructions written by Quest_sec 2020 Running it in hexo npm install hexo-tag-echarts3 --save Standard Code model: {% echarts 400 '85%' %}{% endecharts %} and then, insert codes below {% echarts 400 '85%' %}{ tooltip : { trigger: 'axis', axisPointer : { // 坐标轴指示器，坐标轴触发有效 type : 'shadow' // 默认为直线，可选为：'line' | 'shadow' } }, legend: { data:['利润', '支出', '收入'] }, grid: { left: '3%', right: '4%', bottom: '3%', containLabel: true }, xAxis : [ { type : 'value' } ], yAxis : [ { type : 'category', axisTick : {show: false}, data : ['周一','周二','周三','周四','周五','周六','周日'] } ], series : [ { name:'利润', type:'bar', itemStyle : { normal: { label: {show: true, position: 'inside'} } }, data:[200, 170, 240, 244, 200, 220, 210] }, { name:'收入', type:'bar', stack: '总量', itemStyle: { normal: { label : {show: true} } }, data:[320, 302, 341, 374, 390, 450, 420] }, { name:'支出', type:'bar', stack: '总量', itemStyle: {normal: { label : {show: true, position: 'left'} }}, data:[-120, -132, -101, -134, -190, -230, -210] } ]};{% endecharts %} This is how it looks like from the codes above: // 基于准备好的dom，初始化echarts实例 var myChart = echarts.init(document.getElementById('echarts6209')); // 指定图表的配置项和数据 var option = { tooltip: { trigger: 'axis', axisPointer: { // 坐标轴指示器，坐标轴触发有效 type: 'shadow' // 默认为直线，可选为：'line' | 'shadow' } }, legend: { data: ['利润', '支出', '收入'] }, grid: { left: '3%', right: '4%', bottom: '3%', containLabel: true }, xAxis: [ { type: 'value' } ], yAxis: [ { type: 'category', axisTick: { show: false }, data: ['周一', '周二', '周三', '周四', '周五', '周六', '周日'] } ], series: [ { name: '利润', type: 'bar', label: { show: true, position: 'inside' }, emphasis: { focus: 'series' }, data: [200, 170, 240, 244, 200, 220, 210] }, { name: '收入', type: 'bar', stack: '总量', label: { show: true }, emphasis: { focus: 'series' }, data: [320, 302, 341, 374, 390, 450, 420] }, { name: '支出', type: 'bar', stack: '总量', label: { show: true, position: 'left' }, emphasis: { focus: 'series' }, data: [-120, -132, -101, -134, -190, -230, -210] } ] }; // 使用刚指定的配置项和数据显示图表。 myChart.setOption(option); Line chart {% echarts 400 '85%' %}option = { xAxis: { type: 'category', name: 'Time', nameLocation: &quot;middle&quot;, nameTextStyle: {fontSize: &quot;2rem&quot;}, data: [1,2,3,4,5,6,7,] }, yAxis: { type: 'value', name: &quot;Velacity&quot;, nameLocation: &quot;middle&quot;, nameTextStyle: {fontSize: &quot;2rem&quot;, padding: [0, 0, 20, 0] , }, }, series: [{ data: [150, 230, 270, 285, 290, 295, 297], type: 'line' }]};{% endecharts %} // 基于准备好的dom，初始化echarts实例 var myChart = echarts.init(document.getElementById('echarts7091')); // 指定图表的配置项和数据 var option = option = { xAxis: { type: 'category', name: 'Time', nameLocation: \"middle\", nameTextStyle: {fontSize: \"2rem\"}, data: [1,2,3,4,5,6,7,] }, yAxis: { type: 'value', name: \"Velacity\", nameLocation: \"middle\", nameTextStyle: {fontSize: \"2rem\", padding: [0, 0, 20, 0] , }, }, series: [{ data: [150, 230, 270, 285, 290, 295, 297], type: 'line' }] }; // 使用刚指定的配置项和数据显示图表。 myChart.setOption(option); Details for Echart The name of axis info: In hexo widget, the you can give a int value to the fontSize. 2rem is not supported. xAxis: { type: 'category', name: 'Time', nameLocation: &quot;middle&quot;, nameTextStyle: {fontSize: &quot;2rem&quot;}, // 基于准备好的dom，初始化echarts实例 var myChart = echarts.init(document.getElementById('echarts8568')); // 指定图表的配置项和数据 var option = option = { xAxis: { type: 'category', name: 'Time', nameLocation: \"middle\", nameTextStyle: {fontSize: 30, padding: [10, 0, 0, 0]}, data: [1,2] }, yAxis: { }, series: [{ data: [0, 20], type: 'line' }] }; // 使用刚指定的配置项和数据显示图表。 myChart.setOption(option); Multiple Lines with legend {% echarts 400 '85%' %}option = { xAxis: { type: 'category', name: 'Time', nameLocation: &quot;middle&quot;, nameTextStyle: {fontSize: 30, padding: [10, 0, 0, 0] , }, data: [0,1,2,3,4,5,6,7,] }, yAxis: { type: 'value', name: &quot;Velacity&quot;, nameLocation: &quot;middle&quot;, nameTextStyle: {fontSize: 30, padding: [0, 0, 10, 0] , }, }, legend: { data: ['Measured Velocity', &quot;Expected Velocity&quot;] }, series: [{ name: 'Measured Velocity', data: [0, 150, 230, 270, 285, 290, 295, 297], type: 'line' }, { name: &quot;Expected Velocity&quot;, data: [, 150, 230, 310], type: 'line' }]};{% endecharts %} // 基于准备好的dom，初始化echarts实例 var myChart = echarts.init(document.getElementById('echarts7863')); // 指定图表的配置项和数据 var option = option = { xAxis: { type: 'category', name: 'Time', nameLocation: \"middle\", nameTextStyle: {fontSize: 30, padding: [10, 0, 0, 0] , }, data: [0,1,2,3,4,5,6,7,] }, yAxis: { type: 'value', name: \"Velacity\", nameLocation: \"middle\", nameTextStyle: {fontSize: 30, padding: [0, 0, 10, 0] , }, }, legend: { data: ['Measured Velocity', \"Expected Velocity\"] }, series: [{ name: 'Measured Velocity', data: [0, 150, 230, 270, 285, 290, 295, 297], type: 'line' }, { name: \"Expected Velocity\", data: [, 150, 230, 310], type: 'line' }] }; // 使用刚指定的配置项和数据显示图表。 myChart.setOption(option); lineStyle { type: \"line\", smooth: false, lineStyle: {type: \"dotted\",} } info: In hexo chart, you can’t assign lineStyle directly. But we can include it in intemStyle lineStyle in hexo: itemStyle:{ normal:{ lineStyle:{ width:2, type:'dotted' //'dotted'虚线 'solid'实线 } } }, Bugs can’t assign variables before plot Barchart can’t show labels in serious exp for labels: label: { show: true, rotate: 90, align: 'left', verticalAlign: 'middle', position: 'insideBottom', formatter: '{c} | {a}', distance: 15},","link":"/2021/02/01/Blog/echart/"},{"title":"用biopython抽取特定長度的序列","text":"用biopython抽取特定長度的序列 1. fasta 讀取和長度統計 1.1 統計 from Bio import SeqIOSeq = '/media/ken/Data/Yan/RNA-seq/report/2.assembly/out.fa'Seq = SeqIO.parse(Seq, &quot;fasta&quot;)Len_Seq = []for seq_record in Seq: Num = len(str(seq_record.seq)) Len_Seq += [Num] 1.2 統計圖 import matplotlib.pyplot as pltplt.ion()plt.show()plt.figure(figsize=(7, 4))plt.hist(Len_Seq, label=['1st', '2nd'], bins=900)plt.grid(True)plt.legend(loc=0)plt.xlim(xmax=1000,xmin=0)plt.xlabel('value')plt.ylabel('frequency')plt.title('Histogram') ummm, 決定篩掉30000bp一下的reads from Bio import SeqIOSeq = '/media/ken/Data/Yan/RNA-seq/report/2.assembly/out.fa'Seq = SeqIO.parse(Seq, &quot;fasta&quot;)Num = 4000Result = []for seq_record in Seq: if len(str(seq_record.seq)) &gt; Num: Result +=[&quot;&gt;&quot;+seq_record.id] Result +=[str(seq_record.seq)]Fasta = &quot;\\n&quot;.join(Result)F = open(&quot;out.fa&quot;,'w')F.write(Fasta)F.close()","link":"/2020/12/13/Blog/python_seqlen/"},{"title":"Garden Aquarium","text":"My Garden Aquarium I am always want to have a tank which have a small but independent environment so that I needn’t to clean it. Date: 2019/10/30~2020/04/04 Date: 2020/03/18 Moving to my desk Date Events 2019/10/30 the begin of the story[1] 2019/11/04 the coming of the red shrimp[2] 2019/12/05 snail eggs[3] 2020/02/08 hell hydra[4] 2020/03/18 moving to a new place![5] 2020/03/20 See the planaria again[6] 2020/04/05 string algae[7] 2019/10/30: the begin of the story ↩︎ 2019/11/04: the coming of the red shrimp ↩︎ 2019/12/05: snail eggs ↩︎ 2020/02/08: hell hydro ↩︎ 2020/03/18: moving to a new place! ↩︎ 2020/03/20: See the planaria again ↩︎ 2020/04/05: string algae ↩︎","link":"/2020/08/13/Blog/tank1/"},{"title":"如何向百度提交自己的博客网站","text":"如何向百度提交自己的博客网站 2020/2/9 最新地址: https://ziyuan.baidu.com/linksubmit/url 进入链接， 非常慢， 等他转开就好了 输入链接， 直接选提交就好了 链接提交的官方解释： 链接提交工具是网站主动向百度搜索推送数据的工具，本工具可缩短爬虫发现网站链接时间，网站时效性内容建议使用链接提交工具，实时向搜索推送数据。本工具可加快爬虫抓取速度，无法解决网站内容是否收录问题 百度搜索资源平台为站长提供链接提交通道，您可以提交想被百度收录的链接，百度搜索引擎会按照标准处理，但不保证一定能够收录您提交的链接。 除了提交，这个网站还能给网站和服务器做简单或者深度安全检测， 可以随便玩玩。 主要参考：百度经验","link":"/2020/06/26/Blog/submit_baidu/"},{"title":"鱼缸除藻生物工具","text":"鱼缸除藻生物工具 螺 黑金刚 © 帅不过我haha 缺点: 难看[1] 黑金刚翻泥，刚种下的前景草飘起来了 喜欢产卵，多数是产在水草叶背面 趴在缸壁上发呆，半天懒得动一下 苹果螺[2] 食性：绿斑藻、褐藻、饲料、细小水草（慕斯） 爆缸警告 马来螺[2:1] 推荐度：★★☆☆☆（除藻能力弱） 食性：绿斑藻、褐藻、饲料 斑马螺[2:2] 推荐度：★★★☆☆（除藻能力一般） 食性：绿斑藻、褐藻、饲料 汽水螺 鱼类 青苔鼠[1:1] 它不但拔草 抢鱼粮跟吸病鱼 不容易捕捞 小猴飞狐； 黑线飞狐[2:3] 食性：褐藻、绿斑藻、丝藻、饲料 成鱼大小：10-15CM (过大) 小精灵，学名筛耳鲶[2:4] 成鱼大小：4-6CM 食性：褐藻、绿斑藻、蜗牛卵、饲料 习性：性格温和胆小，可与灯鱼一起混养 水质不好会暴毙 黄金大胡子[2:5] 成鱼大小：10-12CM 食性：褐藻、绿斑藻、烫熟青瓜、烫熟菠菜 习性：性格温和胆小，大了会翻底泥 龙须灯鱼[2:6] 成鱼大小：6-7CM 食性：缸面油膜、饲料 习性：性格温和，生活在上层 巧克力娃娃鱼[2:7] 成鱼大小：3-4CM 食性：缸内淡水螺、虾、鱼苗、饲料 习性：肉食性鱼、主要吃杂螺，会攻击鱼虾 超级凶！！超级凶！！！ 鼠鱼（一类），甲鲶亚科[2:8] 成鱼大小：5-6CM 食性：褐藻、绿斑藻、饲料 习性：会翻底泥，前景草杀手 虾 黑壳虾[2:9] 除藻满星 成虾大小：2-3CM 食性：几乎所有藻类、菌膜 大河藻虾[2:10] 除藻满星 成虾大小：4-5CM 食性：几乎所有藻类、菌膜 极火，琉璃虾[2:11] 除藻能力：一般。。。但是漂亮呀！ 成虾大小：2-3CM 食性：几乎所有藻类、菌膜 个人经验： 筛耳鲶黑壳虾苹果螺青鳉 萌宠随想录; 鱼缸里除藻强力的工具螺，都这么多坏毛病吗; 企鹅号; 2020-04-15. 链接 ↩︎ ↩︎ 案锦水草； 如何选择草缸的工具鱼、虾、螺； 知乎; 2018-05-28; 链接 ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ ↩︎","link":"/2020/08/12/Blog/tank_notes/"},{"title":"Evaluating the quality of classification","text":"Situation I have a large, sparse dataset that I’ve analyzed using a neural network model borrowed from previous research. After classifying the data using this model, I applied dimensionality reduction, resulting in well-defined groups. To assess the quality of this classification, I’m considering evaluating the sparsity of classes in the reduced dimension space. One method I’m contemplating is examining the standard deviation in relation to the mean/median value for each group. Are there other effective methods to evaluate the classification based on the distribution in the reduced space? How to start Evaluating the quality of classification, especially in the context of redundancy and sparsity, can be a nuanced task. It sounds like you’re interested in understanding how well-separated or distinct the groups are after applying redundancy techniques on the classification results. Here’s a structured approach to evaluate your classification results based on redundancy distribution: Descriptive Statistics: Mean/Median: Understand the central tendency of each group. Standard Deviation (SD): Check the spread or variability within each group. A lower SD indicates that the data points are closer to the mean, suggesting tighter clusters or classes. Skewness: Understand the symmetry of your distribution. Positive skewness indicates a long tail on the right, while negative skewness indicates a long tail on the left. skewness(X) Visualization: Heatmaps: These can help you visualize the density and sparsity of your classes in the redundancy map. Histograms/Box-plots: To visually inspect the distribution of each group. Quantifying Sparsity: Sparsity Ratio: It’s the ratio of the number of zero (or near-zero, depending on the threshold you set) elements to the total number of elements. A higher sparsity ratio indicates that the classes are more distinct in the redundancy map. Gini Coefficient: Used in economics to measure inequality, it can also measure the inequality of the distribution of classes in a redundancy map. A Gini coefficient of 0 indicates perfect equality, while a Gini coefficient of 1 indicates maximum inequality. Comparative Metrics: Silhouette Score: Measures how close each sample in one cluster is to the samples in the neighboring clusters. Values range from -1 to 1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters. Davies-Bouldin Index: The lower the value, the better the clustering result. It evaluates intra-cluster similarity and inter-cluster differences. Stability Analysis: If possible, perform the same classification and redundancy process on different subsets of your data. If the results are consistent across different subsets, it adds to the validity of your analysis. Ground Truth Comparison: If there’s a “ground truth” or some external benchmark dataset that you can compare with, it can provide a clear evaluation of how well your classification aligns with known standards. Entropy: For each group or cluster, you can compute its entropy to gauge the randomness or unpredictability of its classification assignments. Lower entropy indicates that a cluster is predominantly made up of one class, whereas higher entropy indicates a mix of classes. Lastly, remember that no single metric can fully capture the quality and nuances of your classification, especially in the context of redundancy and sparsity. Use a combination of metrics and visualizations to get a comprehensive view of the quality and then base your conclusions on the collective evidence. Consider also cross-referencing your results with domain experts or literature in the field to ensure that your evaluations and conclusions align with the underlying phenomena you’re studying. Skewness run PCA We use the wine data as the example data. The classes information is in wine.class ## install ggbioplot## remotes::install_github(&quot;vqv/ggbiplot&quot;)## install.packages('plyr')library(plyr)library(ggbiplot)library(ggplot2)data(wine)wine.pca &lt;- prcomp(wine, scale. = TRUE)## bioplotggbiplot(wine.pca, obs.scale = 1, var.scale = 1, groups = wine.class, ellipse = TRUE, circle = TRUE) + scale_color_discrete(name = '') + theme_light()+ theme(axis.title = element_text(size=10)) Check the Skewness library(e1071) # for function skewnessscore &lt;- wine.pcawine_types &lt;- unique(wine.class)skew_TB &lt;- data.frame()for(type in wine_types){ subset_scores &lt;- scores[wine.class == type, ] skewness_PC1 &lt;- skewness(subset_scores[, 1]) skewness_PC2 &lt;- skewness(subset_scores[, 2]) skew_TB &lt;- rbind(skew_TB, data.frame(sk1 = skewness_PC1, sk2 = skewness_PC2, Type = type))}# visualizationggplot(skew_TB, aes(sk1, sk2, color = Type)) + geom_point() + theme_bw() + coord_polar(theta = 'x') By polarizing the x-axis, the points closer to the center exhibit reduced skewness in both PC components, resulting in decreased sparsity. Sparsity Ratio and Gini Coefficient Sparsity Ratio: To compute the sparsity ratio for the PCA scores, you’d typically set a threshold (e.g., a value close to 0) below which a score is considered as ‘sparse’ or ‘zero’. The sparsity ratio is then calculated as the number of scores below this threshold divided by the total number of scores. Gini Coefficient: This measures inequality among values. For the PCA scores, a Gini Coefficient close to 1 indicates high inequality (i.e., few scores dominate), whereas a value close to 0 indicates more equality among scores. # following the code abovecompute_sparsity_ratio &lt;- function(data, threshold = 0.1){ return(sum(abs(data) &lt; threshold) / length(data))}SG_TB = data.frame()for(type in wine_types){ subset_scores_PC1 &lt;- scores[wine.class == type, 1] subset_scores_PC2 &lt;- scores[wine.class == type, 2] # Sparsity ratio for PC1 and PC2 sparsity_PC1 &lt;- compute_sparsity_ratio(subset_scores_PC1) sparsity_PC2 &lt;- compute_sparsity_ratio(subset_scores_PC2) # Gini coefficient for PC1 and PC2 gini_PC1 &lt;- ineq::Gini(subset_scores_PC1) gini_PC2 &lt;- ineq::Gini(subset_scores_PC2) SG_TB &lt;- rbind(SG_TB, data.frame(Type = type, index1 = c(sparsity_PC1, gini_PC1), index2 = c(sparsity_PC2, gini_PC2), index = c('Sparsity', &quot;gigi&quot;)))} pre { background-color:#38393d; color: #5fd381; }","link":"/2023/10/06/Blog/spacial-disEvl/"},{"title":"Tools&#x2F;Softwares collection, technology changes your life","text":"Software Name Platform Discription Xmind Windows/ Mac / Linux Edraw Windows/ Mac / Linux/ Android Flameshot Linux/ Mac The best, open source, cross platform Screen Shot App. Adobe PDF Reader (Linux) Installation scripts show below Other PDF reader Linux Biology Name Platform Discription Alignment software List Linux = = To many tools = = Phylogeny Programs List Linux or more More than 40 different kinds for sorftawres Chemistry Name Platform Discription Chemdoodle 2D Win/Mac/Linux (15$/Mon) One of the most powerful chemical structures drawer Chemdoodle 3D Win/Mac/Linux (15$/Mon) One of the most powerful chemical structures drawer Online Tools Free Copyright Pictures: shutterstock Adobe Stock Software Adobe PDF Reader Reference: Lubos Rendek; 2020 wget -O ~/adobe.deb ftp://ftp.adobe.com/pub/adobe/reader/unix/9.x/9.5.5/enu/AdbeRdr9.5.5-1_i386linux_enu.deb## add i386 requirment for dpkgsudo dpkg --add-architecture i386sudo apt updatesudo apt install libxml2:i386 libcanberra-gtk-module:i386 gtk2-engines-murrine:i386 libatk-adaptor:i386sudo dpkg -i ~/adobe.deb Other PDF Reader Reference: Swapnil Tirthakar; 2017 Evince is recommended sudo apt-get install evince More : ## okularsudo apt-get install okular## zathurasudo apt-get install zathura## GNU GVsudo apt-get install gv## MuPDFsudo apt-get install mupdf## ePDF Viewer## Foxit Reader ### Download the Foixt firstcd /tmpgzip –d FoxitReader_version_Setup.run.tar.gztar –xvf FoxitReader_version_Setup.run.tar./FoxitReader_version_Setup.run## Atrilsudo apt-get install atril## Xpdfsudo apt-get install xpdf Pictures Flameshot: The best, open source screen shot App cross platform. (Github) © Flameshot Videos tools For linux: Video Editor: Kdenlive Video mate information: mediainfo sudo apt install mediainfomediainfo test.mp4 General Complete name : 20210613_Desat1-V330035-Hnf4-HA-29C_8d_OR_5d_.MP4 Format : MPEG-4 Format profile : Base Media Codec ID : isom (isom/iso2/avc1/mp41) File size : 131 MiB Duration : 18 min 10 s Overall bit rate : 1 004 kb/s Writing application : Lavf58.29.100 Video ID : 1 Format : AVC Format/Info : Advanced Video Codec Format profile : High@L4 Format settings : CABAC / 4 Ref Frames Format settings, CABAC : Yes Format settings, Reference frames : 4 frames Codec ID : avc1 Codec ID/Info : Advanced Video Coding Duration : 18 min 10 s Bit rate : 1 000 kb/s Width : 1 920 pixels Height : 1 080 pixels Display aspect ratio : 16:9 Frame rate mode : Constant Frame rate : 30.000 FPS Color space : YUV Chroma subsampling : 4:2:0 Bit depth : 8 bits Scan type : Progressive Bits/(Pixel*Frame) : 0.016 Stream size : 130 MiB (100%) Writing library : x264 core 155 r2917 0a84d98 Encoding settings : cabac=1 / ref=3 / deblock=1:0:0 / analyse=0x3:0x113 / me=hex / subme=7 / psy=1 / psy_rd=1.00:0.00 / mixed_ref=1 / me_range=16 / chroma_me=1 / trellis=1 / 8x8dct=1 / cqm=0 / deadzone=21,11 / fast_pskip=1 / chroma_qp_offset=-2 / threads=12 / lookahead_threads=2 / sliced_threads=0 / nr=0 / decimate=1 / interlaced=0 / bluray_compat=0 / constrained_intra=0 / bframes=3 / b_pyramid=2 / b_adapt=1 / b_bias=0 / direct=1 / weightb=1 / open_gop=0 / weightp=2 / keyint=250 / keyint_min=25 / scenecut=40 / intra_refresh=0 / rc_lookahead=40 / rc=abr / mbtree=1 / bitrate=1000 / ratetol=1.0 / qcomp=0.60 / qpmin=0 / qpmax=69 / qpstep=4 / ip_ratio=1.40 / aq=1:1.00 Codec configuration box : avcC Biology Biologic Models Science Photo Library","link":"/2021/10/16/Blog/tools/"},{"title":"Hexo theme: icarus| Highly personalize it","text":"Hexo Theme: Icarus GitHub: Ruipeng Zhang Document: PPOffice Blog Current Version: 4.0.0 Install sudo apt upgrade nodehexo init /media/ken/Data/Github/hexo-icaruscd /media/ken/Data/Github/hexo-icarussudo npm install -g hexo-clinpm installnpm install hexo-theme-icarushexo config theme icarushexo server Error Message (node:19025) ExperimentalWarning: The fs.promises API is experimental INFO ======================================= ██╗ ██████╗ █████╗ ██████╗ ██╗ ██╗███████╗ ██║██╔════╝██╔══██╗██╔══██╗██║ ██║██╔════╝ ██║██║ ███████║██████╔╝██║ ██║███████╗ ██║██║ ██╔══██║██╔══██╗██║ ██║╚════██║ ██║╚██████╗██║ ██║██║ ██║╚██████╔╝███████║ ╚═╝ ╚═════╝╚═╝ ╚═╝╚═╝ ╚═╝ ╚═════╝ ╚══════╝ ============================================= INFO === Checking package dependencies === ERROR Package bulma-stylus is not installed. ERROR Package hexo-renderer-inferno is not installed. ERROR Please install the missing dependencies your Hexo site root directory: ERROR npm install --save bulma-stylus@0.8.0 hexo-renderer-inferno@^0.1.3 ERROR or: ERROR yarn add bulma-stylus@0.8.0 hexo-renderer-inferno@^0.1.3 how to solve npm install bulma-stylusnpm install hexo-renderer-infernohexo config theme icarushexo server Error Message ERROR Package bulma-stylus's version (0.9.1) does not satisfy the required version (0.8.0). how to solve npm install bulma-stylus@0.8.0hexo config theme icarushexo server Stylize After you run hexo new Notes, a file nameds as Notes.md would be created in source/_posts. The head a few lines would be exactly as you stored in ./scaffolds/post.md. As a result, you just need to change the words in that file to create your own model for all new posts. For example, I’ll add some new features and a style feature for text block by change this file. post.md---title:ytitle:date: {{ date }}toc: truedescription:url: {{ title }}excerpt:tags:category:cover:thumbnail:covercopy: '© Karobben'priority: 10000---&lt;style&gt;pre { background-color:#38393d; color: #5fd381;}&lt;/style&gt; icarus: To Do List Before we started, there are a few other excellent posts I’d like to share with: iMaeGoo 2020: 活用 Bulma 美化 Icarus 文章 Anyway, let’s follow the document first: Document: PPOffice Blog RSS Image for post at Home page and Recent Block Index Read more button in post card Comment Personal file and images Share Baidu Statistics Anchor sidebars Math Function Math Function fontSize admonition CC block Footnote Lived 2D Flow Chart &amp; Mermaid Graph Busuanzi statistic Visitors for each posts Copyright announcement for Cover image Co-exist with waque Change the size of the Logo Stick the togs (headers) ==high light/mark== limit height of &lt;pre&gt; and &lt;code&gt; Abbreviation Change Sitemap Visitor-traffics map Widget Graphviz strike style pre tag style for output Change the tags style in the post page Change the article-meta line Weather widget Fold a part of the tags Fold a part of the archives Code highlight Optional: Change the “latest posts” to “Recommended Post” _config.icarus.yml RSS a, p, RSS span Terminal# install the RSS pluginnpm install hexo-generator-feed# Generate RSS XML filehexo g It indicates you made it if you can see the code below: ... INFO Generated: 2020/06/10/R/WGCNA/index.html INFO Generated: atom.xml INFO Generated: 2019/08/13/R/edgeR/index.html INFO Generated: content.json INFO 690 files generated in 21 s Then, adding the path into _config.icarus.yml _config.icarus.ymlsocial_links: RSS: icon: fas fa-rss url: 'atom.xml' Thumbnail &amp; Cover[1] thumbnail is the image show in recent cover is the image show in main page post.md---cover: '/img/123.png'thumbnail: '/img/123.png'--- Index post.mdtoc: true--- Read More Button post.md---title: '123'excerpt: &quot;This post is for recording...&quot;--- Comment[2] comment: type: utterances repo: Your-GitHub-Username/Your-Public-Repo-Name issue_term: pathname # Required if issue_number is not set issue_number: 100 # Required if issue_term is not set. Every post can be mapped to a separate, manually-created GitHub issue. label: some-issue-label # Optional theme: github-light # Optional crossorigin: anonymous log, favicon, and avatar log is the img line with the action bar _config.icarus.ymllogo: # image of your logohead: favicon: # image for web tag logo avatar: # image for profile Share the easiest way: _config.icarus.ymlshare: type: sharejs baidu_analytics[3] _config.icarus.ymlplugins: baidu_analytics: tracking_id: 3f06f2b************ Anchor Sidebar _config.icarus.ymlsidebar: left: sticky: true right: sticky: true Math Function _config.icarus.ymlmathjax: true Math Function Font Size The default size of the math function is the same size as the article which makes the functions are hard to distinguish from the main page. The easiest method to alter their font-size is adding something if themes/icarus/include/style/article.styl: PS: .mjx-chtml works on $$ (double) quoted functions only. .mjx-math works on both $$ and $ quoted function. article.stylarticle &amp;.article .content word-wrap: break-word font-size: $article-font-size+ span+ .mjx-chtml+ overflow: auto+ max-width: 100%+ font-size: 1.5 em+ z-index: 999+ .mjx-math+ font-size: 1.1 em+ font-weight: 700+ color: SteelBlue+ background-color:white; Default Style Changed Style Admonition reference: lxl80/hexo-admonition install the plugin: npm install hexo-admonition --save add the codes at the end of themes/icarus/include/style/article.styl: article.styl.admonition { margin: 1.5625em 0; padding: .6rem; overflow: hidden; font-size: 1rem; page-break-inside: avoid; border-left: .3rem solid #42b983; border-radius: .3rem; box-shadow: 0 0.1rem 0.4rem rgba(0,0,0,.05), 0 0 0.05rem rgba(0,0,0,.1); background-color: #fafafa; } p.admonition-title { position: relative; margin: -.6rem -.6rem .8em -.6rem !important; padding: .4rem .6rem .4rem 2.5rem; font-weight: 700; background-color:rgba(66, 185, 131, .1); } .admonition-title::before { position: absolute; top: .9rem; left: 1rem; width: 12px; height: 12px; background-color: #42b983; border-radius: 50%; content: ' '; } .info&gt;.admonition-title, .todo&gt;.admonition-title { background-color: rgba(0,184,212,.1); } .warning&gt;.admonition-title, .attention&gt;.admonition-title, .caution&gt;.admonition-title { background-color: rgba(255,145,0,.1); } .failure&gt;.admonition-title, .missing&gt;.admonition-title, .fail&gt;.admonition-title, .error&gt;.admonition-title { background-color: rgba(255,82,82,.1); } .admonition.info, .admonition.todo { border-color: #00b8d4; } .admonition.warning, .admonition.attention, .admonition.caution { border-color: #ff9100; } .admonition.failure, .admonition.missing, .admonition.fail, .admonition.error { border-color: #ff5252; } .info&gt;.admonition-title::before, .todo&gt;.admonition-title::before { background-color: #00b8d4; border-radius: 50%; } .warning&gt;.admonition-title::before, .attention&gt;.admonition-title::before, .caution&gt;.admonition-title::before { background-color: #ff9100; border-radius: 50%; } .failure&gt;.admonition-title::before,.missing&gt;.admonition-title::before,.fail&gt;.admonition-title::before,.error&gt;.admonition-title::before{ background-color: #ff5252;; border-radius: 50%; } .admonition&gt;:last-child { margin-bottom: 0 !important; } Use: hexo cleanhexo s -g post.md!!! note Hexo-admonition 插件使用示例 这是基于 hexo-admonition 插件渲染的一条提示信息。类型为 note，并设置了自定义标题。 提示内容开头留 4 个空格，可以有多行，最后用空行结束此标记。!!! warning 这是一条采用默认标题的警告信息。 &lt;pre&gt; Warning messages &lt;/pre&gt;!!! failure &quot;嵌套链接及引用块&quot; 欢迎访问我的博客链接：[悟尘纪](https://www.lixl.cn) &gt;这里嵌套一行引用信息。!!! infor &quot;嵌套链接及引用块&quot; ```bash echo hello world ``\\` Hexo-admonition 插件使用示例 这是基于 hexo-admonition 插件渲染的一条提示信息。类型为 note，并设置了自定义标题。 提示内容开头留 4 个空格，可以有多行，最后用空行结束此标记。 warning这是一条采用默认标题的警告信息。 Warning messages 嵌套链接及引用块 欢迎访问我的博客链接：悟尘纪 这里嵌套一行引用信息。 r 嵌套链接及引用块 echo hello world CC block You can’t alter the infor from _config.icarus.yml because everything is recorded in _congig.yml… _congig.ymltitle: Karobbensubtitle: ''description: ''keywords: Biology, Data Science, Bioinformaticsauthor: Karobbenlanguage: entimezone: ''url: 'https://karobben.github.io/' edit the footer You may can’t find the hexo-theme-icarus in your theme directory. So, for editing the role module, we can editing them in node_modules/hexo-theme-icarus FlowChart &amp; Mermaid FlowChart and Mermaid: link For icarus, hexo document didn’t give the resolution for jsx file. So, I insert the &lt;script src=&quot;https://unpkg.com/mermaid@8.8.4/dist/mermaid.min.js&quot;&gt;&lt;/script&gt; directly in themes/icarus/layout/common/scripts.jsx scripts.jsxreturn &lt;Fragment&gt; &lt;script src={cdn('jquery', '3.3.1', 'dist/jquery.min.js')}&gt;&lt;/script&gt; &lt;script src={cdn('moment', '2.22.2', 'min/moment-with-locales.min.js')}&gt;&lt;/script&gt; {clipboard &amp;&amp; &lt;script src={cdn('clipboard', '2.0.4', 'dist/clipboard.min.js')} defer&gt;&lt;/script&gt;} &lt;script dangerouslySetInnerHTML={{ __html: `moment.locale(&quot;${language}&quot;);` }}&gt;&lt;/script&gt; &lt;script dangerouslySetInnerHTML={{ __html: embeddedConfig }}&gt;&lt;/script&gt; &lt;script src={url_for('/js/column.js')}&gt;&lt;/script&gt; &lt;Plugins site={site} config={config} page={page} helper={helper} head={false} /&gt; &lt;script src={url_for('/js/main.js')} defer&gt;&lt;/script&gt; // mermaid script &lt;script src=&quot;https://unpkg.com/mermaid@8.8.4/dist/mermaid.min.js&quot;&gt; &lt;/script&gt; // mermaid script ends&lt;/Fragment&gt;;} It’s not the best resolution, but it works. And a problem is it can’t show the whole word if the word is long. Busuanzi You can try to enable the busuanzi plugin in _congig.icarus.yml. But I have no idea why that it doesn’t work all the time. But it still doen’t work at first. Thanks for BoyInTheSun[4]. It seams like it conflicted to lived2d plugin. By solving this problem, the best solution is download the script to local and alter the script. Before you do this, make sure you have called the busuanzi: false in _congig.icarus.yml or it won’t work. Insert latest script inner the &lt;div class=&quot;level-start&quot;&gt; tags at /themes/icarus/layout/common/footer.ejs file The latest script you can find at BUSUANZI /themes/icarus/layout/common/footer.jsx&lt;script async src=&quot;//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js&quot;&gt;&lt;/script&gt; &lt;span id=&quot;busuanzi_container_site_pv&quot;&gt;本站总访问量&lt;span id=&quot;busuanzi_value_site_pv&quot;&gt;&lt;/span&gt;次&lt;/span&gt; Go check the raw codes. if it shows that &lt;span id=&quot;busuanzi_container_site_uv&quot; style=&quot;display: none;&quot;&gt; and nothing show at all, it means some plugin conflicted to it. You can fix this by following another post. Visitors for each post[5] This script is based on the Busaunzi script below After you insert the codes below appropriately, we can add the codes below inner &lt;div class=&quot;level-left&quot;&gt; in /themes/icarus/layout/common/article.jsx /themes/icarus/layout/common/article.jsx{/* counts of this passage*/}&lt;i class=&quot;far fa-eye&quot;&gt;&lt;/i&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span id=&quot;busuanzi_container_page_pv&quot; style=&quot;display: inline;&quot;&gt; &lt;span id=&quot;busuanzi_value_page_pv&quot;&gt;0&lt;/span&gt;&amp;nbsp;&lt;/span&gt;{/* counts of this passage Done*/} Copyright announcement for Cover image[6] Result: add a covercopy tag in the md header ***.mdtitle: &quot;Hexo theme: icarus&quot;date: &quot;2021/02/11&quot;toc: truecovercopy: '© ppoffice' Then, insert the codes below in card-image tag in themes/icarus/layout/common/article.jsx file as it’s show. &lt;span style=&quot;position: absolute; bottom: 0; right: 0; padding-right:3px; padding-left:4px; background-color: rgba(255, 255, 255, 0.6)&quot; class=&quot;ccopy&quot; dangerouslySetInnerHTML={{ __html: index &amp;&amp; page.covercopy ? page.covercopy : page.covercopy }}&gt;&lt;/span&gt; My example: article.jsx{cover ? &lt;div class=&quot;card-image&quot;&gt; {index ? &lt;a href={url_for(page.link || page.path)} class=&quot;image is-7by3&quot;&gt; &lt;img class=&quot;fill&quot; src={cover} alt={page.title || cover} /&gt; &lt;/a&gt; : &lt;span class=&quot;image is-7by3&quot;&gt; &lt;img class=&quot;fill&quot; src={cover} alt={page.title || cover} /&gt; &lt;/span&gt;} &lt;span style=&quot;position: absolute; bottom: 0; right: 0; padding-right:3px; padding-left:4px; background-color: rgba(255, 255, 255, 0.6)&quot; class=&quot;ccopy&quot; dangerouslySetInnerHTML={{ __html: index &amp;&amp; page.covercopy ? page.covercopy : page.covercopy }}&gt;&lt;/span&gt;&lt;/div&gt; : null} 和瓦雀共存 瓦雀需要summary.md做index界面, 需要(可選) layout.md 做統一落款, 用 yuque.yml 做配置文件 如果直接使用, 則會出現如下圖片情況: 這些文件都會被渲染且置頂(因爲沒有時間). 非常難受. 查閱後可知, hexo 自帶的 skip_render 可以完美解決此方案. 因此, 只需要在_config.yml 中, 添加通配字符, 即可解決次問題. _config.ymlskip_render: - _posts/**/**.yml - _posts/**/layout.md - _posts/**/summary.md - _posts/**/index.md 之後, 記得 清除緩存, 再查看效果 hexo cleanhexo s --watch 用 python 腳本輔助更新語雀筆記: 腳本鏈接 Change the Size of the Logo The size of the default logo was too small to fit the cell phone page. So, I tried to alter the height from the raw code. But nothing happened. By retrieving the element one by one, you’ll finally find that it sited an argument of max-height: 1.75rem for this class. The quick solution is to set a new value for max-height in themes/icarus/include/style/navbar.styl.(PS: I set it equals 3.8rem) Bsides, I also commented the padding and margin to make the header tight. themes/icarus/include/style/navbar.styl.navbar-item display: flex align-items: center /*padding: $navbar-item-padding-v $navbar-item-padding-h*/ /*margin: $navbar-item-margin-v $navbar-item-margin-h*/ © KarobbenBefore © KarobbenAfter © KarobbenThe Final And this how I find everything. By checking the raw codes, we can know the logo was: &lt;a class=&quot;navbar-item navbar-logo&quot; href=&quot;/&quot;&gt; &lt;img src=&quot;/Karobben_logo_horizontal_800.png&quot; alt=&quot;Karobben&quot; height=&quot;28&quot;&gt;&lt;/a&gt; The class is navbar-logo. So, by searching this class, we can located it in grep -s &quot;navbar-logo&quot; $(find themes/icarus)| awk -F&quot;:&quot; '{print $1}' themes/icarus/include/style/navbar.styl themes/icarus/layout/common/navbar.jsx By checking the themes/icarus/layout/common/navbar.jsx, there are nothing we can do. &lt;a class=&quot;navbar-item navbar-logo&quot; href={siteUrl}&gt; {navbarLogo}&lt;/a&gt; By checking the themes/icarus/include/style/navbar.styl, we now know, .navbar-logo img max-height: $logo-height Let’s continue to retrive the logo-height grep -s &quot;logo-height&quot; $(find themes/icarus)| awk -F&quot;:&quot; '{print $1}' themes/icarus/include/style/base.styl themes/icarus/include/style/footer.styl themes/icarus/include/style/navbar.styl Finally, you’ll find this in themes/icarus/include/style/base.styl: $logo-height ?= 1.75rem Stick the togs (headers/CATALOGUE) In version V4.0, the scripts in themes/icarus/layout/widget are all gone except profile.jsx. I have no idea why. But by reading the issue #740, I thought maybe I can try to bring it back to the widget. When I firstly copy toc.jsx from hexo-component-inferno, it runs incorrectly: ERROR { err: Error: Cannot find module '../../util/cache' Require stack: - /media/ken/Data/Github/hexo-icarus/themes/icarus/layout/widget/toc.jsx - /media/ken/Data/Github/hexo-icarus/node_modules/hexo-renderer-inferno/lib/compile.js - /media/ken/Data/Github/hexo-icarus/node_modules/hexo-renderer-inferno/index.js at Function.Module._resolveFilename (node:internal/modules/cjs/loader:923:15) Obviously, we lack a model named cache.js So, I checked the repository again and found the util/cache.js at here Instead of making another directory, I placed the cache.js to themes/icarus/scripts/cache.js and change the path in themes/icarus/layout/widget/toc.jsx Here’s how I achieved it: copy the cache.js from GitHub to themes/icarus/scripts/cache.js copy the toc.jsx from GitHub to themes/icarus/layout/widget/toc.jsx Replace the codes: toc.jsx- const { cacheComponent } = require('../../until/cache');+ const { cacheComponent } = require('../../scripts/cache'); Adding the is-sticky in to the class[7]: toc.jsx- &lt;div class=&quot;card widget&quot; id=&quot;toc&quot; data-type=&quot;toc&quot;&gt;+ &lt;div class=&quot;card widget is-sticky&quot; id=&quot;toc&quot; data-type=&quot;toc&quot;&gt; BASHhexo cleanhexo g Change the “latest posts” to “Recommended Post” One of the sidebars is showing the latest posts. But, yeah, it is unnecessary since everything shows on the home page already. But it’ll be a good place to place your most recommended or valuable posts. By doing that, we need to make a few changes. For old version[8]: Find \\icarus\\layout\\widget\\recent_posts.ejs: Change the code 1 to code 2 ejs recent_posts.ejs- &lt;% site.posts.sort('date', -1).limit(5).each(post =&gt; { %&gt;+ &lt;% site.posts.sort('priority', -1).limit(5).each(post =&gt; { %&gt; Change the name of the block: Change the name in language is fine en.yml- recents: 'Recents'+ recents: 'Recommend' Adding the priority at the head of the posts. post.md---title: &quot;Hexo theme: icarus&quot;date: &quot;2021/02/11&quot;toc: true+ priority: 1--- For Version 4.0 As is the situation in above, we need to cp the files, first. copy the article_media.jsx from GitHub to layout/common/article_media.jsx copy the recent_posts.jsx GitHub to themes/icarus/layout/widget/recent_posts.jsx Alter the require path: recent_posts.jsx- const { cacheComponent } = require('../../until/cache');+ const { cacheComponent } = require('../../scripts/cache'); Alter the codes similar like the old version: recent_posts.jsx- .sort('date', -1)+ .sort('priority') Adding priority as same as above: post.md---title: &quot;Hexo theme: icarus&quot;date: &quot;2021/02/11&quot;toc: true+ priority: 1--- Attention: It might not work if you didn’t add priority to most of the posts and this takes me a few hours to found it out… You can use sed to add the priority to all posts: sed -i '/^thumbnail:/a\\priority: 10000' $(find source/_posts/ -name &quot;*.md&quot;) Make sure that the ^thumbnail: is unique to each post. hexo cleanhexo g Keep _post directory free with suspicious files Highlight/Mark In markdown, we can using the == to mark words or sentences. But the the default mark would be rendering to yellow: Highlight And my target is change it to Highlight Open include/style/article.styl: article.stylh5 font-size: 1em+ mark+ background-color: salmon+ padding: .2em+ border-radius: .4em BASHhexo cleanhexo g max height for &lt;pre&gt; and &lt;code&gt; The passage would be looked untidy if the code block or the &lt;pre&gt; block is too long. So, assign the max-height is a good choise. Since code was embedded in pre, we just need to change pre. Open include/style/article.styl: article.stylpre font-size: .85em+ max-height: 30em BASHhexo cleanhexo g Abbreviation style Though abbreviation is convenient in markdown, it is hard to achive in cellphone since there are no suspend events for touch screen. Adding an click event could make it friendly to cellphone users. Open include/style/article.styl: article.stylabbr position: relative; color: seagreenabbr:active::before content: attr(title); white-space: nowrap; round: 90; position: absolute; top: 100%; background-color: #000000; color: #fff; border-radius: 5px; opacity:0.8; padding-left: 10px; padding-right: 10px; z-index: 999 Abbreviation grammar in markdown: post.md*[HB]: hemoglobinHB HB BASHhexo cleanhexo g Visitor-traffics map Pick a Visitor traffics map server you like: link Personally, I’d like to adding it at the end of the profile: so, the code would be inserted into layout/widget/profile.jsx around line-77. profile.jsx &lt;/div&gt; : null} {socialLinks ? this.renderSocialLinks(socialLinks) : null} &lt;/div&gt;++ &lt;div class= &quot;card&quot;&gt;+ &lt;script type=&quot;text/javascript&quot; src=&quot;//rf.revolvermaps.com/0/0/7.js?i=${your ID}&amp;m=0c&amp;c=f03b11&amp;cr1=ffffff&amp;sx=0&amp;cw=ffffff&amp;cb=3472cd&quot; async=&quot;async&quot;&gt;&lt;/script&gt;+ &lt;/div&gt;+ &lt;/div&gt;; }} Widget Graphviz GitHub document Install npm install --save hexo-graphviz# npm install https://github.com/dwatow/hexo-filter-viz.git Adding the script Added this to layout/common/footer.jsx before &lt;/footer&gt;; footer.jsx {/*graphviz script start*/} &lt;script src='https://cdnjs.cloudflare.com/ajax/libs/viz.js/1.7.1/viz.js'&gt;&lt;/script&gt; {/*graphviz script end*/}&lt;/footer&gt;; (Optional) set the max-width If the width of Graphviz is long, it may exceed out of the border. include/style/article.styl article.styl&amp;.article .article-meta, .article-tags color: $text-light .article-meta overflow-x: auto margin-bottom: .5rem .article-more @extend .button.is-light .content word-wrap: break-word font-size: $article-font-size+ svg+ max-width : 100%; include the code below in graphviz digraph F { rankdir = LR; edge [style=solid]; node [style=filled, font=Courier]; subgraph M { rank = same; Start [label = \"Lamp doesn't work\", shape = box, fillcolor = \"#FF0000\" ]; End [label = \"Repair lamp\" , shape = box, color = coral]; Con1 [label = \"Lamp plugged in?\", shape = diamond, color = green, size = 3]; Con2 [label = \"Bulb burned out?\", shape = diamond, color = green, size = 3]; } subgraph C { rank = same; RB [label = \"Replace bulb\", shape = box, color = deepskyblue1]; AP [label = \"Plug in lamp\", shape = box, color = deepskyblue1]; } Start -> Con1; Con1 -> AP [label = \"No\"]; Con1 -> Con2 [label = \"Yes\"]; Con2 -> RB [label = \"Yes\"]; Con2 -> End [label = \"No\"]; AP -> End RB -> End } Strike Style Open include/style/article.styl: article.stylh5 font-size: 1em+ s+ color: #00CD66 BASHhexo cleanhexo g Giscus Origin blog: Yury Zhauniarovich Create public repository in your github (like ‘Giscus’) Pre style Add the codes below in each of md file &lt;style&gt;pre { background-color:#38393d; color: #5fd381;}&lt;/style&gt;&lt;pre&gt;Pre block presentationJust love this style&lt;/pre&gt; Pre block presentation Just love this style pre { background-color:#38393d; color: #5fd381; } digraph F { rankdir = LR; edge [style=solid]; node [style=filled, font=Courier]; subgraph M { rank = same; Start [label = \"Lamp doesn't work\", shape = box, fillcolor = \"#FF0000\" ]; End [label = \"Repair lamp\" , shape = box, color = coral]; Con1 [label = \"Lamp plugged in?\", shape = diamond, color = green, size = 3]; Con2 [label = \"Bulb burned out?\", shape = diamond, color = green, size = 3]; } subgraph C { rank = same; RB [label = \"Replace bulb\", shape = box, color = deepskyblue1]; AP [label = \"Plug in lamp\", shape = box, color = deepskyblue1]; } Start -> Con1; Con1 -> AP [label = \"No\"]; Con1 -> Con2 [label = \"Yes\"]; Con2 -> RB [label = \"Yes\"]; Con2 -> End [label = \"No\"]; AP -> End RB -> End } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) }); weixin_30300225, 2019: 安装配置hexo icarus主题配置 ↩︎ PPOffice, 2017: Icarus User Guide - Comment Plugins ↩︎ PPOffice, 2016: Icarus用户指南 - 网站分析插件 ↩︎ BoyInTheSun, 2020: 解决live2d看板娘和busuanzi不蒜子计数冲突 ↩︎ 摆柿阔落, 2019: Hexo | 两个你可能会用到的icarus主题配置 ↩︎ 开着拖拉机的梦想家, 2016: HTML让文字在图片上显示 ↩︎ Andy Cen, 2020: Hexo-Icarus主题配置建议 ↩︎ somebody, 2019: hexo主题Icarus浅度修改教程 ↩︎","link":"/2021/02/11/Blog/hexo_icarus/"},{"title":"Hexo: Busuanzi doesn&#39;t work","text":"Hexo: Busuanzi doesn’t work Github Issue Sometimes, the busuanzi works, but sometimes it doesn’t work. By checking the code, we can find that the script runs well but it was hidden for some reason. &lt;span id=&quot;busuanzi_container_site_uv&quot; style=&quot;display: none;&quot;&gt; BoyInTheSun gived a solution in his blog It works fine. So, I recorded it specifically for theme-icarus. Create a js file For me, I created the script here: themes/icarus/source/js/busuanzi.pure.js Copy the script Then, copy the code from his blog busuanzi.pure.jsvar bszCaller,bszTag;!function(){var c,d,e,a=!1,b=[];ready=function(c){return a||&quot;interactive&quot;===document.readyState||&quot;complete&quot;===document.readyState?c.call(document):b.push(function(){return c.call(this)}),this},d=function(){for(var a=0,c=b.length;c&gt;a;a++)b[a].apply(document);b=[]},e=function(){a||(a=!0,d.call(window),document.removeEventListener?document.removeEventListener(&quot;DOMContentLoaded&quot;,e,!1):document.attachEvent&amp;&amp;(document.detachEvent(&quot;onreadystatechange&quot;,e),window==window.top&amp;&amp;(clearInterval(c),c=null)))},document.addEventListener?document.addEventListener(&quot;DOMContentLoaded&quot;,e,!1):document.attachEvent&amp;&amp;(document.attachEvent(&quot;onreadystatechange&quot;,function(){/loaded|complete/.test(document.readyState)&amp;&amp;e()}),window==window.top&amp;&amp;(c=setInterval(function(){try{a||document.documentElement.doScroll(&quot;left&quot;)}catch(b){return}e()},5)))}(),bszCaller={fetch:function(a,b){var c=&quot;BusuanziCallback_&quot;+Math.floor(1099511627776*Math.random());window[c]=this.evalCall(b),a=a.replace(&quot;=BusuanziCallback&quot;,&quot;=&quot;+c),scriptTag=document.createElement(&quot;SCRIPT&quot;),scriptTag.type=&quot;text/javascript&quot;,scriptTag.defer=!0,scriptTag.src=a,document.getElementsByTagName(&quot;HEAD&quot;)[0].appendChild(scriptTag)},evalCall:function(a){return function(b){ready(function(){try{a(b),scriptTag.parentElement.removeChild(scriptTag)}catch(c){bszTag.hides()}})}}},bszCaller.fetch(&quot;//busuanzi.ibruce.info/busuanzi?jsonpCallback=BusuanziCallback&quot;,function(a){bszTag.texts(a),bszTag.shows()}),bszTag={bszs:[&quot;site_pv&quot;,&quot;page_pv&quot;,&quot;site_uv&quot;],texts:function(a){this.bszs.map(function(b){var c=document.getElementById(&quot;busuanzi_value_&quot;+b);c&amp;&amp;(c.innerHTML=a[b])})},hides:function(){this.bszs.map(function(a){var b=document.getElementById(&quot;busuanzi_container_&quot;+a);b&amp;&amp;(b.style.display=&quot;&quot;)})},shows:function(){this.bszs.map(function(a){var b=document.getElementById(&quot;busuanzi_container_&quot;+a);b&amp;&amp;(b.style.display=&quot;inline&quot;)})}}; Finally, apply it in your theme Before doing so, please make sure that you have disabled the busuanzi plugin in your _congig.icarus.yml. And then, insert the scripts appropriately. For me, I inserted my codes by following another post. Now, find your code and replace the source from: &lt;script async src=&quot;//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js&quot;&gt;&lt;/script&gt; to: &lt;script async src=&quot;/js/busuanzi.pure.js&quot;&gt;&lt;/script&gt; Now, everything is done! Enjoy~","link":"/2021/02/20/Blog/hexo_lived2d_busuanzi/"},{"title":"为什么我要使用瓦雀| markdown 语法大全","text":"为什么我要使用瓦雀 爲什麼使用瓦雀 瓦雀是官方又推薦的一個，三方開源程序。方便本地管理，編輯，下載，上傳markdown語法的文件具體可以看官方文檔 哪些人適合使用瓦雀 想要在本地直接備份，想類似git一樣管理自己的筆記 希望在本地用markdown語法編輯記錄 希望用自己喜歡的編輯器的人 希望自由插入html語法(部分)的人 希望可以方便存入其他庫備份的人(比如, 百度雲, github) 喜歡用代碼畫流程圖的人 不適合人羣 不熟悉markdown語法的人 不會用代碼畫流程圖/腦圖 討厭命令行的人 Markdown 語法雖然輕量, 但是足夠強大. 不過, 語雀, GIthub等, 並不是就能完美支持markdown和html的所有語法. 因此, 還請跟具自己的實際情況來選擇個人所需. 使用方式 詳情點擊 安裝 sudo npm i -g waque 登錄 waque login 這個時候彈出一張網頁, 掃碼登錄授權就好 初始化配置 創建一個文件夾(倉庫), 進入後,初始化 waque init 選擇一個 Repository 使用 然後就可以通過waque export下載本倉庫所有的文本通過waque export ***.md 便可以上傳同步筆記了! 注意: 直接編輯文檔並上傳, 會出現: ✖ error 更新 安卓手机 Turmux 搭建博客[is3vdm] { status: 400, message: '抱歉，语雀不允许通过 API 修改 Lake 格式文档，请到语雀进行操作。' } 只需要去網頁上, 把該文檔刪除, 然後就可以上傳了. 已知問題 大部分和簡書顯示類似: 择势勤 2019[1] 在语雀無法使用(hexo 可以): 腦圖;流程圖等語法 &lt;details&gt;或region 摺疊標籤 html 的 height 屬性 &lt;font-size=&quot;100px&quot;&gt; style font-size 無效 &lt;font&gt;&lt;/font&gt; font 屬性標籤 &lt;i&gt; &lt;p style=&quot;...&quot;&gt; 代碼摺疊 可 文字 註釋[\\\\]:# &lt;div style='display: none'&gt; &lt;img&gt; 標籤 &lt;div align=right&gt; 排版標籤 这是*倾斜*的文字 这是倾斜的文字 这是**加粗**的文字 这是加粗的文字 这是 ***斜体加粗*** 的文字 这是 斜体加粗 的文字 这是文字^右上角^ 这是文字右上角 这是文字~右下角~ 这是文字右下角 这是==高亮==文字 这是高亮文字 (hexo 失效) 这是加~~删除线~~的文字 这是加删除线的文字 ![图片alt](图片地址 ''图片title'') &lt;s&gt;&lt;sub&gt;&lt;sup&gt;&lt;u&gt;&lt;b&gt; flow mermaid 字体 &lt;font face=&quot;黑体&quot;&gt;我是黑体字&lt;/font&gt;&lt;br&gt;&lt;font face=&quot;微软雅黑&quot;&gt;我是微软雅黑&lt;/font&gt;&lt;br&gt;&lt;font face=&quot;STCAIYUN&quot;&gt;我是华文彩云&lt;/font&gt;&lt;br&gt;&lt;font color=red&gt;我是红色&lt;/font&gt;&lt;br&gt;&lt;font color=#008000&gt;我是绿色&lt;/font&gt;&lt;br&gt;&lt;font color=Blue&gt;我是蓝色&lt;/font&gt;&lt;br&gt;&lt;font size=5&gt;我是尺寸&lt;/font&gt;&lt;br&gt;&lt;font face=&quot;黑体&quot; color=green size=5&gt;我是黑体，绿色，尺寸为5&lt;/font&gt; 我是黑体字我是微软雅黑我是华文彩云我是红色我是绿色我是蓝色我是尺寸我是黑体，绿色，尺寸为5 缩写 convert to HTML*[HTML]: HyperText Markup Language# Same as&lt;a title=&quot;HyperText Markup Language&quot;&gt;HTML&lt;/a&gt; convert to HTML (hold you mouse on the HTML) HTML 待办事项 (hexo 失效) - [ ] item item - [x] item2 item2 公式 (hexo 失效) hexo 解决办法： 链接 $$\\Gamma(z) = \\int_0^\\infty t ^ {z-1} e ^ {-t}dt$$ $$ \\Gamma(z) = \\int_0^ \\infty t^ {z-1}e ^{-t}dt $$ 公式对齐：参考： 芳草碧连天lc 2016 $$ \\begin{equation} \\begin{aligned} \\theta ^{},\\theta ^{'}&amp;= \\argmin\\limits_{\\theta,\\theta{'}}\\frac{1}{n}\\sum_{n}{i=1}L\\left (\\textbf{x}{(i)},\\textbf{x}{‘(i)} \\right )\\ &amp;=\\argmin\\limits_{\\theta,\\theta{'}}\\frac{1}{n}\\sum_{n}{i=1}L\\left (\\textbf{x}^{(i)},g_{\\theta ^{’}}\\left ( f_{\\theta }\\left ( \\textbf{x}^{i}\\right )\\right )\\right ) \\end{aligned} \\end{equation} $$ 表格 |表头1|表头2|表头3|表头4|5||--|---------|:--|--:|:--:||普通|加宽|靠左对齐|靠右对齐|居中||普普通通|(无效))|我从左边开始|我向右看齐|我在中间| 表头1 表头2 表头3 表头4 5 普通 加宽 靠左对齐 靠右对齐 居中 普普通通 宽 我从左边开始 我向右看齐 我在中间 Tricks for 加宽无效: |表头1|表头2||--|--||1|2&lt;font alpha=white&gt;aaaaaaaaaaaaaaaaaaaaaaaaaaa&lt;/font&gt;| 表头1 表头2 1 2aaaaaaaaaaaaaaaaaaaaaaaaaaa 更多: 复杂表格 aladdin_sun 2018 Flow Chart ##flow codes for belowst=&gt;start: Start|past:&gt;http://www.google.com[blank]e=&gt;end: End:&gt;http://www.google.comop1=&gt;operation: My Operation|pastop2=&gt;operation: Stuff|currentsub1=&gt;subroutine: 这啥啊|invalidcond=&gt;condition: Yes or No?|approved:&gt;http://www.google.comc2=&gt;condition: Good idea|rejectedio=&gt;inputoutput: catch something...|requestst-&gt;op1(right)-&gt;condcond(yes, right)-&gt;c2cond(no)-&gt;sub1(left)-&gt;op1c2(yes)-&gt;io-&gt;ec2(no)-&gt;op2(right)-&gt;op1 Mermaid Graph ##mermaid codes for belowgraph LR; Portal--&gt;|发布/更新配置|Apollo配置中心; Apollo配置中心--&gt;|实时推送|App; App--&gt;|实时查询|Apollo配置中心; Citation: cicero 2018 graph LR; Portal-->|发布/更新配置|Apollo配置中心; Apollo配置中心-->|实时推送|App; App-->|实时查询|Apollo配置中心; 更多mermaid例子：道隐无名 2015 七适散人 2018 Foot Note You can create footnotes like this[^footnote].[^footnote]: Here is the *text* of the **footnote**. You can create footnotes like this[2]. 其他 希腊字母/角标等特殊符号 因为markdown可以使用公式插件， 这些都可以用 latex 语法解决。 不过也有latex， 甚至是markdown自带的语法解决不了的情况。比如说， icarus 的目录就没法使用各种语法来给 希腊字母， 角标等。最简单的解决办法是， 复制现成的。 但是这个方法可能对于 plain text editor 不太友好。这里我们就可以引入 实体/html 的编码来解决。网站: 各种编码大全 实体编码表 案例: A = &amp;beta; + &amp;psi;&amp;sup2; A = β + ψ² 可以发现， 实体编码就是在 &amp;和; 之间添加一些简单的语法规则。 比如 希腊字母的读音， sup+数字组成上标数字的情况。 虽然远没latex那么强大， 但是在一些小场景却更高效。 经测试， hexo和语雀均支持～ html 编码全，但是几乎完全不可读。 实体编码易读信高，但是东西少所以也就希腊字母等这些字母会比较实用。 其他的还是用latex吧 应用场景: latex 渲染太慢不想用。 graphviz 中的markdown 语法， latex 语法 无效 标题等其他 markdown语法无效的地方 建议： 大部分还是直接去网页里， 复制黏贴来的快一些 st=>start: Start|past:>http://www.google.com[blank] e=>end: End:>http://www.google.com op1=>operation: My Operation|past op2=>operation: Stuff|current sub1=>subroutine: 这啥啊|invalid cond=>condition: Yes or No?|approved:>http://www.google.com c2=>condition: Good idea|rejected io=>inputoutput: catch something...|request st->op1(right)->cond cond(yes, right)->c2 cond(no)->sub1(left)->op1 c2(yes)->io->e c2(no)->op2(right)->op1{\"theme\":\"simple\",\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"flowchart-0-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"flowchart-0-options\").value)); var diagram = flowchart.parse(code); diagram.drawSVG(\"flowchart-0\", options); 择势勤; Markdown语法大全(超级版); 简书; 2019.05.02 16:37:47. ↩︎ Here is the text of the footnote. ↩︎","link":"/2020/06/26/Blog/waque/"},{"title":"语雀AIP 配置和简单使用","text":"语雀AIP 配置和简单使用 1. 设置 TOKEN号 进入个人设置 , Terminal 内 输入 curl -H &quot;X-Auth-Token: 你的token &quot; https://www.yuque.com/api/v2/hello import requestsurl = &quot;https://www.yuque.com/api/v2/repos/646554/docs/&quot;header = {&quot;X-Auth-Token&quot;:&quot;&quot;}## Read the list of the reposResult = requests.get(url, headers = header).json()## post a passage in this reposrequests.post(url, headers = header).json() 返回: {&quot;data&quot;:{&quot;message&quot;:&quot;Hello Karroben&quot;}} 2. 获取用户信息: https://www.yuque.com/yuque/developer/user 官方例子: GET /users/:login## 或GET /users/:id 说明: GET = curl -H &quot;X-Auth-Token: 你的token &quot; https://www.yuque.com/api/v2 这一串 使用方法: 把https://www.yuque.com/api/v2/hello 的 hello 去掉加上users/, 再加上你的ID curl -H &quot;X-Auth-Token: 你的token &quot; https://www.yuque.com/api/v2/users/liuwenkan 返回: {&quot;data&quot;: {&quot;id&quot;:691897, &quot;type&quot;:&quot;User&quot;, &quot;space_id&quot;:0, &quot;account_id&quot;:494138, &quot;login&quot;:&quot;liuwenkan&quot;, &quot;name&quot;:&quot;Karroben&quot;, &quot;avatar_url&quot;:&quot;https://cdn.nlark.com/yuque/0/2019/jpeg/anonymous/1576914522864-5dabd37e-9a90-4ee4-96b4-a1973dbcede4.jpeg&quot;, &quot;books_count&quot;:8, &quot;public_books_count&quot;:8, &quot;followers_count&quot;:1, &quot;following_count&quot;:2, &quot;public&quot;:1, &quot;description&quot;:&quot;R 语言作图索引:https://karobben.github.io/R/R-index.html&quot;, &quot;created_at&quot;:&quot;2019-12-21T07:49:03.000Z&quot;,&quot;updated_at&quot;:&quot;2020-02-14T02:57:36.000Z&quot;, &quot;_serializer&quot;:&quot;v2.user_detail&quot; }} 3. 获取repository信息 https://www.yuque.com/yuque/developer/repo ## for UserGET /users/:login/repos## for GroupGET /groups/:login/repos## 或GET /users/:id/reposGET /groups/:id/repos 一样, Get = 前面一大串 例子: curl -H &quot;X-Auth-Token: 你的token &quot; https://www.yuque.com/api/v2/repos/liuwenkan/python 返回太多, 不在这里赘述 Post a passage Example for post a Non-title passage curl -v -X POST test.md -H &quot;${Your Token}&quot; https://www.yuque.com/api/v2/repos/646554/docs/","link":"/2020/06/26/Blog/yuque_API/"},{"title":"Weight Tracking","text":"Tracking // 基于准备好的dom，初始化echarts实例 var myChart = echarts.init(document.getElementById('echarts6723')); // 指定图表的配置项和数据 var option = option = { title: { text: 'Weight Tracking' }, tooltip: { trigger: 'axis' }, legend: { data: ['Ken', 'YR'] }, grid: { left: '3%', right: '4%', bottom: '3%', containLabel: true }, xAxis: { type: 'time', boundaryGap: false }, yAxis: { type: 'value', min: 51, }, series: [ { name: 'Ken', type: 'line', smooth: 'true', data: [[\"2021-09-04\", 56.4], [\"2021-09-21\", 55.8], [\"2021-09-22\", 54.6], [\"2021-09-23\", 55.3], [\"2021-09-24\", 54.6], [\"2021-09-25\", 54.6], [\"2021-09-26\", 55.0], [\"2021-09-27\", 54.7], [\"2021-09-28\", 54.0], [\"2021-09-29\", 54.0], [\"2021-09-30\", 54.4], [\"2021-10-01\", 54.1], [\"2021-10-02\", 54.4], [\"2021-10-03\", 54.4], [\"2021-10-04\", 54.4], [\"2021-10-05\", 54.2], [\"2021-10-06\", 54.4], [\"2021-10-07\", 54.7], [\"2021-10-07\", 54.8], [\"2021-10-09\", 54.5], [\"2021-10-10\", 54.2], [\"2021-10-11\", 54.4], [\"2021-10-12\", 54.4], [\"2021-10-13\", 54.4], [\"2021-10-14\", 54.4], [\"2021-10-15\", 54.4], [\"2021-10-16\", 54.6], [\"2021-10-17\", 55.0], [\"2021-10-18\", 54.6], [\"2021-10-19\", 54.3], [\"2021-10-20\", 54.6], [\"2021-10-21\", 54.7], [\"2021-10-22\", 54.5], [\"2021-10-23\", 54.6], [\"2021-10-24\", 55.0], [\"2021-10-25\", 54.3], [\"2021-10-26\", 54.3], [\"2021-10-27\", 54.0], [\"2021-10-28\", 54.0], [\"2021-10-29\", 54.1], [\"2021-10-30\", 54.3], [\"2021-10-31\", 54.5], [\"2021-11-01\", 54.4], [\"2021-11-02\", 54.5], [\"2021-11-03\", 54.6], [\"2021-11-04\", 53.9], [\"2021-11-05\", 54.2], [\"2021-11-06\", 54.3], [\"2021-11-07\", 54.4], [\"2021-11-08\", 54.9], [\"2021-11-09\", 54.7], [\"2021-11-10\", 54.5], [\"2021-11-11\", 54.4], [\"2021-11-12\", 54.4], [\"2021-11-13\", 54.2], [\"2021-11-14\", 54.1], [\"2021-11-15\", 53.9], [\"2021-11-15\", 55.6], [\"2021-11-16\", 54.5], [\"2021-11-17\", 54.3], [\"2021-11-18\", 54.5], [\"2021-11-19\", 54.4], [\"2021-11-20\", 54.6], [\"2021-11-21\", 54.4], [\"2021-11-22\", 55.0], [\"2021-11-23\", 55.0], [\"2021-11-24\", 54.6], [\"2021-11-25\", 54.3], [\"2021-11-26\", 53.7], [\"2021-11-27\", 54.3], [\"2021-11-28\", 54.5], [\"2021-11-29\", 54.6], [\"2021-12-02\", 55.3], [\"2021-12-05\", 54.3], [\"2021-12-06\", 54.4], [\"2021-12-07\", 54.6], [\"2021-12-08\", 54.2], [\"2021-12-13\", 54.4], [\"2021-12-16\", 54.4], [\"2021-12-18\", 54.7], [\"2021-12-19\", 54.7], [\"2021-12-23\", 54.2], ], markArea: { itemStyle: { color: 'rgba(255, 173, 177, 0.4)' }, data: [ [ { name: 'Latest Week', xAxis: '2021-10-25' }, { xAxis: '2021-10-31' } ], ] } }, { name: 'YR', type: 'line', smooth: 'true', data: [[\"2021-09-04\", 58.9], [\"2021-09-21\", 55.4], [\"2021-09-22\", 55.1], [\"2021-09-23\", 55.3], [\"2021-09-24\", 55.4], [\"2021-09-25\", 55.6], [\"2021-09-26\", 55.3], [\"2021-09-28\", 55.0], [\"2021-09-29\", 54.7], [\"2021-09-30\", 54.5], [\"2021-10-02\", 54.4], [\"2021-10-01\", 54.4], [\"2021-10-03\", 54.2], [\"2021-10-04\", 54.3], [\"2021-10-06\", 54.6], [\"2021-10-07\", 54.9], [\"2021-10-08\", 54.7], [\"2021-10-09\", 54.6], [\"2021-10-10\", 54.2], [\"2021-10-11\", 54.4], [\"2021-10-12\", 54.2], [\"2021-10-13\", 54.4], [\"2021-10-14\", 54.4], [\"2021-10-15\", 53.8], [\"2021-10-16\", 53.8], [\"2021-10-17\", 54.0], [\"2021-10-18\", 53.8], [\"2021-10-19\", 53.8], [\"2021-10-20\", 54.0], [\"2021-10-21\", 54.0], [\"2021-10-22\", 54.1], [\"2021-10-23\", 53.8], [\"2021-10-24\", 53.5], [\"2021-10-25\", 53.1], [\"2021-10-26\", 53.0], [\"2021-10-27\", 52.9], [\"2021-10-28\", 52.8], [\"2021-10-29\", 53.1], [\"2021-10-30\", 52.9], [\"2021-10-31\", 53.0], [\"2021-11-01\", 53.0], [\"2021-11-02\", 52.7], [\"2021-11-03\", 52.7], [\"2021-11-04\", 53.4], [\"2021-11-05\", 53.3], [\"2021-11-06\", 53.5], [\"2021-11-07\", 53.2], [\"2021-11-08\", 53.4], [\"2021-11-09\", 53.4], [\"2021-11-10\", 53.5], [\"2021-11-11\", 53.3], [\"2021-11-12\", 53.3], [\"2021-11-13\", 53.1], [\"2021-11-14\", 53.0], [\"2021-11-15\", 53.0], [\"2021-11-16\", 53.5], [\"2021-11-17\", 53.3], [\"2021-11-18\", 53.5], [\"2021-11-19\", 53.3], [\"2021-11-20\", 52.9], [\"2021-11-21\", 52.8], [\"2021-11-22\", 53.7], [\"2021-11-23\", 53.2], [\"2021-11-24\", 53.0], [\"2021-11-25\", 53.1], [\"2021-11-26\", 52.8], [\"2021-11-27\", 52.7], [\"2021-11-28\", 52.6], [\"2021-11-29\", 52.6], [\"2021-11-30\", 51.2], [\"2021-12-01\", 51.6], [\"2021-12-02\", 51.8], [\"2021-12-02\", 51.8], [\"2021-12-04\", 51.9], [\"2021-12-05\", 52.0], [\"2021-12-06\", 52.0], [\"2021-12-07\", 51.8], [\"2021-12-08\", 51.9], [\"2021-12-09\", 51.8], [\"2021-12-10\", 51.9], [\"2021-12-11\", 51.8], [\"2021-12-12\", 51.8], [\"2021-12-13\", 51.7], [\"2021-12-16\", 51.7], [\"2021-12-17\", 51.7], [\"2021-12-18\", 51.7], [\"2021-12-19\", 51.9], [\"2021-12-20\", 51.9], [\"2021-12-22\", 51.6], [\"2021-12-23\", 51.6], [\"2021-12-24\", 51.4], [\"2021-12-25\", 51.3], [\"2021-12-26\", 51.5], [\"2021-12-27\", 51.8], ] } ] }; // 使用刚指定的配置项和数据显示图表。 myChart.setOption(option); // 基于准备好的dom，初始化echarts实例 var myChart = echarts.init(document.getElementById('echarts7249')); // 指定图表的配置项和数据 var option = option = { title: { text: 'Step Line' }, tooltip: { trigger: 'axis' }, legend: { data: ['Step Start', 'Step Middle', 'Step End'] }, grid: { left: '3%', right: '4%', bottom: '3%', containLabel: true }, toolbox: { feature: { saveAsImage: {} } }, xAxis: { type: 'time', boundaryGap: false }, yAxis: [ {type: 'value'}, { name: 'Rainfall(mm)', nameLocation: 'start', max: 5, type: 'value', inverse: true } ], series: [ { name: 'Step Start', type: 'line', step: 'start', data: [[\"2019-12-01\", 1], [\"2019-12-01\", 14], [\"2019-12-05\", 83], [\"2019-12-05\", 84], [\"2019-12-05\", 100], [\"2019-12-10\", 262], [\"2019-12-10\", 263], [\"2019-12-16\", 281], [\"2019-12-22\", 637], [\"2019-12-22\", 643], [\"2019-12-24\", 724], [\"2019-12-24\", 725], [\"2020-01-14\", 829], [\"2020-02-02\", 2097], [\"2020-02-03\", 2177], [\"2020-04-06\", 2572], [\"2020-04-08\", 3024], [\"2020-04-09\", 3043], [\"2020-04-09\", 3198], [\"2021-08-21\", 4164], [\"2021-10-10\", 5475], [\"2021-10-20\", 6766], [\"2021-10-23\", 6885], [\"2021-10-25\", 6918], [\"2021-10-25\", 6933], ] }, ] }; // 使用刚指定的配置项和数据显示图表。 myChart.setOption(option); // 基于准备好的dom，初始化echarts实例 var myChart = echarts.init(document.getElementById('echarts1094')); // 指定图表的配置项和数据 var option = option = { tooltip: { trigger: 'axis', axisPointer: { // Use axis to trigger tooltip type: 'shadow' // 'shadow' as default; can also be 'line' or 'shadow' } }, legend: {}, grid: { left: '3%', right: '4%', bottom: '3%', containLabel: true }, xAxis: { type: 'value' }, yAxis: { type: 'category', data: ['2021_12_31_new_bg', '2021_12_31_3D_New_label', '2021_12_30_train_new', '2021_12_30_train_bymodle', '2021_12_31_3D_nL', '2022_01_01_3D_D40', '2022_01_01_3D_D40_NewL', \"2022_01_02_3D\"] }, series: [ { name: '5', type: 'bar', stack: 'total', label: { show: true }, emphasis: { focus: 'series' }, data: [0, 0, 0, 1, 0, 1, 0, 0] }, { name: '6', type: 'bar', stack: 'total', label: { show: true }, emphasis: { focus: 'series' }, data: [0, 0, 0, 17, 0, 6, 0, 5] }, { name: '7', type: 'bar', stack: 'total', label: { show: true }, emphasis: { focus: 'series' }, data: [0, 0, 0, 82, 0, 19, 0, 22] }, { name: '8', type: 'bar', stack: 'total', label: { show: true }, emphasis: { focus: 'series' }, data: [1, 0, 0, 293, 2, 106, 0, 86] }, { name: '9', type: 'bar', stack: 'total', label: { show: true }, emphasis: { focus: 'series' }, data: [6, 17, 6, 530, 22, 309, 3, 216] }, { name: '10', type: 'bar', stack: 'total', label: { show: true }, emphasis: { focus: 'series' }, data: [50, 89, 35, 614, 69, 542, 51, 460] }, { name: '11', type: 'bar', stack: 'total', label: { show: true }, emphasis: { focus: 'series' }, data: [224, 312, 173, 500, 206, 642, 159, 796] }, { name: '12', type: 'bar', stack: 'total', label: { show: true }, emphasis: { focus: 'series' }, data: [901, 925, 799, 311, 903, 456, 765, 656] }, { name: '13', type: 'bar', stack: 'total', label: { show: true }, emphasis: { focus: 'series' }, data: [1261, 1093, 1408, 114, 1218, 224, 1289, 208] }, { name: '14', type: 'bar', stack: 'total', label: { show: true }, emphasis: { focus: 'series' }, data: [21, 28, 43, 2, 41, 135, 172, 15] }, { name: '15', type: 'bar', stack: 'total', label: { show: true }, emphasis: { focus: 'series' }, data: [0, 0, 6, 0, 15, 21, 25] }, { name: '16', type: 'bar', stack: 'total', label: { show: true }, emphasis: { focus: 'series' }, data: [0, 0, 0, 0, 0, 3] }, ] }; // 使用刚指定的配置项和数据显示图表。 myChart.setOption(option); Google Chart test: google.charts.load('current', {'packages':['corechart']}); google.charts.setOnLoadCallback(drawChart); function drawChart() { var data = google.visualization.arrayToDataTable([ ['Year', 'Sales', 'Expenses'], ['2004', 1000, 400], ['2005', 1170, 460], ['2006', 660, 1120], ['2007', 1030, 540] ]); var options = { title: 'Company Performance', curveType: 'function', legend: { position: 'bottom' } }; var chart = new google.visualization.LineChart(document.getElementById('curve_chart')); chart.draw(data, options); }","link":"/2021/09/21/Blog/weight-t/"},{"title":"Atom","text":"Atom System： Deepin 15.11Atom : 1.41.0Electron: 4.2.7Chrome : 69.0.3497.128Node : 10.11.0 安装插件 ctrl + ， 打开设置 1 预览Markdonw ctrl + shift + m 效果还是感人的～！！ 2 预览html 下载并安装 git clone https://github.com/harmsk/atom-html-preview.gitcd atom-html-preview/apm install Ctrl + Shift + H（我没成功） 3 自动补全文件路径 git://www.github.com/atom-community/autocomplete-paths.gitcd autocomplete-paths##apm installnpm install## 直接使用 apm install 可能會缺少插件導致， 安裝成功卻無法使用，## 而 npm Install 會有報錯 npm install 報錯： npm WARN worker-loader@0.8.1 requires a peer of webpack@&gt;=0.9 &lt;2 || ^2.1.0-beta || ^2.2.0 but none is installed. You must install peer dependencies yourself.audited 53 packages in 1.756sfound 3 vulnerabilities (2 moderate, 1 high) run `npm audit fix` to fix them, or `npm audit` for details 解決： npm install npm WARN worker-loader@0.8.1 requires a peer of webpack@&gt;=0.9 &lt;2 || ^2.1.0-beta || ^2.2.0 but none is installed. You must install peer dependencies yourself.audited 53 packages in 1.756sfound 3 vulnerabilities (2 moderate, 1 high) run `npm audit fix` to fix them, or `npm audit` for details 说实话 - -我安装了- -但是没看出什么效果来- - 其他 插件網頁下載： https://atom.io/packages 更多博客： Location：https://www.cnblogs.com/GarfieldEr007/p/5594700.html 更多插件: language-r (R 语言语法高亮) minimap (VS 一样小图预览) atom-beautify (高亮美化) emmet (emmet是HTML,CSS快速编写的神器,具体的使用可以参看emmet官网。) autocomplete-* 系列 (自动补全) pigments (显示颜色) https://blog.csdn.net/qq_32340877/article/details/79095610 script (run different kinds of scripts in atom) high CPU Usage Reference: 1. Fantashit","link":"/2020/06/26/Linux/Atom/"},{"title":"Deepin 15.11 Bug 汇集","text":"Deepin 15.11 Bug 汇集 任务栏消失 解决办法: 山野莽夫, 2019: https://www.shanyemangfu.com/deepin-dock.html (链接已失效) 进入任务管理器, 关闭 dock. livefun, 2020 删除配置文件并重启 rm -rf ~/.config/dconf; reboot widon1104, 2020 手动启动: dde-dock &amp; 录屏bug deepin screen recorder: 窗口冻结在原处","link":"/2020/06/26/Linux/Deepin15_Bugs/"},{"title":"如何在Deepin上安装稳定的OBS","text":"如何在Deepin上安装稳定的OBS 系统： Deepin 15.11apt， Deepin 商店， 以及 OBS 官方教程都试过了， 折腾了好久， 安装都很简单，也能打开。但是一开始录屏或这推流， 软件就开始闪退， 非常头疼，最后终于找到了这个帖子记录一下，做个备份 ## 安装 flatpak 软件管理器apt install flatpakapt install gnome-software-plugin-flatpakflatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo## 这里官方建议安装完flatpak以后重启一下系统。不过我好像没有重启，也没有关系的样子## 安装 OBSflatpak install flathub com.obsproject.Studio## 运行 OBSflatpak run com.obsproject.Studio 安装以后，在主菜单也可以找到了，也可以在开始菜单里面，点击运行","link":"/2020/06/26/Linux/Deepin_OBS/"},{"title":"如何在Deepin上安装gtop","text":"如何在Deepin上安装gtop 参考：https://github.com/aksakalli/gtop npm Install apt-get -y install git curlnpm install gtop --registry https://registry.npm.taobao.orggtop'''You can sort the process table by pressingp: Process Idc: CPU usagem: Memory usage'''","link":"/2020/06/23/Linux/Deepin_gtop/"},{"title":"Conky: Si-Fi Theme","text":"Conky Another post for Conky: Conky CODE: Karobben, GitHub video: 史上最不正經的生物狗, BiliBili Assign variables conkyrc############################ - Graphics settings - ###########################draw_shades nodefault_color cccccccolor0 whitecolor1 1E90FFcolor2 whitecolor3 0084C8 CPU Model conkyrc## |--CPU1## Assign the path of the image## -p position${image /home/ken/Desktop/BlueVision/Blue_conky/Resorse/CPU_INTERFACE.png -p 0,0 }${image /home/ken/Desktop/BlueVision/Blue_conky/Resorse/CPU_INFO_PANEL.png -p 225,0 }${image /home/ken/Desktop/BlueVision/Blue_conky/Resorse/CPU_TEMPERATURE_GRAPH.png -p 241,60 }## CPU tag${voffset 1}${voffset -48}${goto 8}${cpugraph cpu1 50,216 1E90FF 0084C8}${color}## CPU usage${voffset -56}${goto 250} ${font HOOGE 05_53:style=Bold:size=9}${color0 white}CPU 1${goto 250} ${font Digital Readout Thick Upright:style=Bold:size=16}${color0}${cpu cpu1} ${font HOOGE 05_53:style=Bold:size=9}%## CPU Tem${voffset 2}${goto 248} ${font HOOGE 05_53:style=Bold:size=10}${color salmon}TEMP ${color white}${execi 30 sensors | grep 'Core 0' | awk '{print $3}' | sed 's/+//'| sed 's/.0.*//' }°C## CPU bar${voffset 2}${goto 8}${cpubar cpu1 7,216} RAM conkyrc##RAM Tag,Usage${voffset -129} ${color0}${font ConkyColors:size=15}g${font}${color white}${goto 32}${voffset -6} ${font HOOGE 05_53:style=Bold:size=9}RAM:${goto 78}${color firebrick}$memperc%${color0} ${goto 120}F: ${color firebrick}${memeasyfree} ${goto 200}${color0}U: ${color firebrick}${mem}${color} # |--SWAP${goto 10}${color0}${font ConkyColors:size=15}z${font}${voffset -6}${goto 32}${font HOOGE 05_53:style=Bold:size=9}SWAP:${goto 78}${color firebrick}${swapperc}%${color0} ${goto 120}F: ${color firebrick}$swapmax ${goto 200}${color0}U: ${color firebrick}$swap${color}${font}##RAM bar${voffset -55}${goto 406}${color white}${membar 10,97}${voffset 1}${goto 406}${color white}${swapbar 10,97} InforBoard It’ll be rolling-present lines in File1.txt file. conkyrc## |--infor board1${voffset 130}${execpi 5 cat /home/ken/Desktop/BlueVision/Blue_conky/File1.txt | fold -w 83 | sed 's/\\[ \\]/\\[ \\]/' | sed 's/\\[X\\]/\\[ X \\]/' | sed 's/\\] /\\] ${color white}/' | sed 's/$/${color }/' | sed 's/^/${voffset 4}${goto 55}${color CCFFCC}${font Liberation Sans:style=Bold:size=11}/'| head -n $(echo $(date &quot;+%M&quot;)+9|bc)| tail -n 9}${execpi 5 cat /home/ken/Desktop/BlueVision/Blue_conky/File1.txt | fold -w 83 | sed 's/\\[ \\]/\\[ \\]/' | sed 's/\\[X\\]/\\[ X \\]/' | sed 's/\\] /\\] ${color white}/' | sed 's/$/${color }/' | sed 's/^/${voffset 4}${goto 55}${color 99CCFF}${font Liberation Sans:style=Bold:size=11}/'| head -n $(echo $(date &quot;+%M&quot;)+19|bc)| tail -n 10}${image /home/ken/Desktop/BlueVision/Blue_conky/Resorse/GRID.png -p 0,580 -s 692x500 }${image /home/ken/Desktop/BlueVision/Blue_conky/Resorse/GRID.png # -p 700,700 -s 485x380 } GPU Module conkyrc## |--GPU${voffset -1148}${image /home/ken/Desktop/BlueVision/Blue_conky/Resorse/GPU.png -p 710,0 }${goto 725}${font HOOGE 05_53:style=Bold:size=9}${color black}Ver: ${goto 785}${exec nvidia-settings -q [gpu:0]/NvidiaDriverVersion -t}${goto 725}${font HOOGE 05_53:style=Bold:size=9}${color black}Tm: ${goto 785}${color 993333}${nvidia temp}°C${color}${goto 725}${font HOOGE 05_53:style=Bold:size=9}${color black}G.freq: ${goto 785}${nvidia gpufreq}${goto 725}${font HOOGE 05_53:style=Bold:size=9}${color black}M.freq: ${goto 785}${nvidia memfreq}${voffset -60}${goto 820}${color 008800}${font ConkyColorsLogos:size=40}n${font}${color} Time &amp; Processes conkyrc## |-- Time &amp; Processes${voffset 10}${font Digital Readout Thick Upright:size=40}${goto 750}${color2}${time %k}${voffset -9}:${voffset 9}${time %M}${color2}${voffset -14}${font Digital Readout Thick Upright:size=24}${goto 855}${color2}${time %d}${font Digital Readout Thick Upright:size=12}${voffset 14}${goto 855}${color2}${time %m}${goto 869}${color2}${time %y}${font}${voffset -97}${goto 1250}${voffset -10}Processes: ${color2}${goto 1330} CPU${goto 1370 }RAM${goto 1420 }PID${goto 1470 }USER${color}${voffset -1}${goto 1250}${color2}${top name 1}${color}${font Liberation Sans:style=Bold:size=8}${color1} ${goto 1330}${top cpu 1}${goto 1370 }${top mem 1}${goto 1420 }${top pid 1}${goto 1470 }${top user 1}${color}${font}${voffset -1}${goto 1250}${color2}${top name 2}${color}${font Liberation Sans:style=Bold:size=8}${color1} ${goto 1330}${top cpu 2}${goto 1370 }${top mem 2}${goto 1420 }${top pid 2}${goto 1470 }${top user 2}${color}${font}${voffset -1}${goto 1250}${color2}${top name 3}${color}${font Liberation Sans:style=Bold:size=8}${color1} ${goto 1330}${top cpu 3}${goto 1370 }${top mem 3}${goto 1420 }${top pid 3}${goto 1470 }${top user 3}${color}${font}${voffset -1}${goto 1250}${color2}${top name 4}${color}${font Liberation Sans:style=Bold:size=8}${color1} ${goto 1330}${top cpu 4}${goto 1370 }${top mem 4}${goto 1420 }${top pid 4}${goto 1470 }${top user 4}${color}${font}${voffset -1}${goto 1250}${color2}${top name 5}${color}${font Liberation Sans:style=Bold:size=8}${color1} ${goto 1330}${top cpu 5}${goto 1370 }${top mem 5}${goto 1420 }${top pid 5}${goto 1470 }${top user 5}${color}${font}${voffset -1}${goto 1250}${color2}${top name 6}${color}${font Liberation Sans:style=Bold:size=8}${color1} ${goto 1330}${top cpu 6}${goto 1370 }${top mem 6}${goto 1420 }${top pid 6}${goto 1470 }${top user 6}${color}${font}${voffset -1}${goto 1250}${color2}${top name 7}${color}${font Liberation Sans:style=Bold:size=8}${color1} ${goto 1330}${top cpu 7}${goto 1370 }${top mem 7}${goto 1420 }${top pid 7}${goto 1470 }${top user 7}${color}${font}${image /home/ken/Desktop/BlueVision/Blue_conky/Resorse/ZONES.png -p 960,0 } CPU and GPU information | Test in Deepin 15.1 conkyrc## |--C＆G infor${voffset -145}${goto 1541}${color white}${font Liberation Sans:style=Bold:size=7}${exec lscpu| grep &quot;Model name:&quot;| awk -F&quot; &quot; '{print $2}'|sed &quot;s/ E3/\\nE3/&quot;|head -n 1}${goto 1540}${color white}${exec lscpu| grep &quot;Model name:&quot;| awk -F&quot; &quot; '{print $2}'|sed &quot;s/ E3/\\nE3/&quot;|tail -n 1}${voffset -31}${goto 1790}${color white}${exec lspci | grep -i vga| awk -F&quot;HD &quot; '{print $2}'}${goto 1791}${color white}${exec lspci | grep --colour=never -i nvidia| awk -F&quot;M &quot; '{print $2}'| awk -F&quot;(&quot; '{print $1}'}${image /home/ken/Desktop/BlueVision/Blue_conky/Resorse/OVERALL_INTERFACE.png -p 1530,0 } Battery conkyrc## |--BATTERY${voffset 845}${goto 1201}${if_existing /sys/class/power_supply/BAT0}${color0}${font ConkyColors:size=15}6${font}${color} ${voffset -6}Battery: ${font Liberation Sans:style=Bold:size=8}${color1}${battery_percent BAT0}%${color}${font}${voffset -14}${goto 1320}${color 99CCFF}${battery_bar 12,594} Network conkyrc## |--NetWork${voffset 32}${goto 1201}${color #0077ff}${upspeedgraph wlp4s0 48,605 104E8B 0077ff}${voffset 3 }${goto 1201}${color #0077ff}${downspeedgraph wlp4s0 48,605 104E8B 0077ff}${voffset -119 }${goto 1818}${color0}${font HOOGE 05_53:style=Bold:size=9}Up:${goto 1818}$color${font HOOGE 05_53:style=Bold:size=9}${upspeed wlp4s0}${voffset 32 }${goto 1818}${color0}${font HOOGE 05_53:style=Bold:size=9}Down:$color${goto 1818}${font HOOGE 05_53:style=Bold:size=9}${downspeed wlp4s0}${image /home/ken/Desktop/BlueVision/Blue_conky/Resorse/NETWORK_INFO.png -p 1195,885 }${image /home/ken/Desktop/BlueVision/Blue_conky/Resorse/NETWORK2.png -p 1195,955 }${image /home/ken/Desktop/BlueVision/Blue_conky/Resorse/NETWORK2.png -p 1195,1020 }","link":"/2021/02/28/Linux/Conky_si_fi/"},{"title":"Disck Manage","text":"Disck Manage Gparted 磁盘扩容 之前安装这个deepin系统是做测试用的,所以就随便给了点空间. 后来发现挺好用的, 就一直用了. 但是现在, 50G的内存, 非常吃紧了. 想要扩容. Windows 下, 只能删除磁盘, 不能扩容, 因此, Gparted 就是对小白来说, 最友善的软件了. 1. 右键点击 选择 Resize1. 拖动滑块, 或者填写数字1. 点击Resize1. 回到主界面后, 选择Apply1. 回到文件夹, 检查确认一下~ 完成啦! 关键词: deepin 磁盘压缩, 磁盘扩容, 图形化操作","link":"/2020/06/26/Linux/Disck-Manage/"},{"title":"如何在deepin上安装scrcpy","text":"如何在deepin上安装scrcpy source: https://www.linuxuprising.com/2019/03/control-android-devices-from-your.html scrcpy 作为一个良心开源投屏加控制软件，真是太强大了。 不需要手机安装额外垃圾东西，比自带的手机投屏到电脑功能要稳定很多， 不容易崩溃(某win)。稳定好， 高清画面也不容易掉帧，真是太舒服了。 本来这个软件非常友好啊, 但是却应为deepin 系统的关系, apt源没有, snap在上国又很鸡肋,完全不能用, 只能自己编译。编译就编译吧， 偏偏又有很多的坑要填 = = 我是被虐的不要不要的反正。对于小白来说， configure + make， 还是很友好的， 报错清晰，debug简单。 但是第一次接触mason 和nijia 来说- -有点噩梦了。最开始想着直接下最新的1.12.1， 然后直接编译， 一堆错误。 后面终于通过googel 到了一个全能贴， 发现需要安装服务。按照要求，安装服务器后，又出现了，ninjia 报错说没有找到1.11.1 的服务器。。？？？ 好吧，去下好了1.11.1的， 总算是没有报错了， 输入scrcpy 也成功了， 没有报错。并且和成功运行的画面一样， 手机收到了确认。 但是- - 就是半天不显示画面。。。 没反应了。瞎折腾了几下， 抱着实时心态， 既然报错说1.11.1， 可能是版本对不上 == ？ 索性干脆安装1.11.1的包， 删掉重来。 终于- -唉， 成功了 - - 撒花！！！下面是详细教程： 1. 各种依赖： sudo apt install adb ffmpeg libsdl2-2.0.0 make gcc pkg-config meson ninja-build \\ libavcodec-dev libavformat-dev libavutil-dev libsdl2-dev 2. 下载 **地址：https://github.com/Genymobile/scrcpy/releases/tag/v1.11 现在圈内两个， 代码：第一个加尾坠“.jar”第二个解压 wget -c https://github.com/Genymobile/scrcpy/releases/download/v1.11/scrcpy-server-v1.11wget -c https://github.com/Genymobile/scrcpy/archive/v1.11.tar.gzmv scrcpy-server-v1.11 scrcpy-server-v1.11.jartar -zxvf v1.11.tar.gz 3. 安装 安装服务 sudo install scrcpy-server-v1.11.jar /usr/local/bin/scrcpy-server.jar 编译 cd scrcpy-1.11meson build --buildtype release --strip -Db_lto=true -Dprebuilt_server=../scrcpy-server-v1.11.jarcd buildninjasudo ninja install 这一步可能出现错误： ninja: error: '/home/ken/Soft/scrcpy-server-v1.11.jar', needed by 'server/scrcpy-server', missing and no known rule to make it 因为没有找到server 的路径， 因此只需要把那前面下载的文件， 拷贝或者移动到这个路径就好了， 然后重新ninjia 最后 插入数据线， 打开USB调试模式，输入scrcpy后手机勾选确认 adb tcpip 5555scrcpy terminal可能会出现如下代码： INFO: scrcpy 1.11 [100%] /data/local/tmp/scrcpy-server bind: Address already in use ERROR: Could not listen on port 27183 端口被占用或无法使用， 我们换一个端口：输入 scrcpy -p 1234 scrcpy -p 1234INFO: scrcpy 1.11 &lt;https://github.com/Genymobile/scrcpy&gt;[100%] /data/local/tmp/scrcpy-serverINFO: Initial texture: 1080x2336INFO: Device clipboard copied[server] WARN: Could not inject char u+5509[server] WARN: Could not inject char u+ff0c[server] WARN: Could not inject char u+5509 等待一下就好啦！ 安装成功的环境： Ubuntu 18 Deepin 15.1 Manjaro 21.0.4 Ornara Enjoy~","link":"/2020/06/26/Linux/Deepin_scrcpy/"},{"title":"Conky - the best plug for desktop","text":"Conky - the best plug for desktop reference:aikunzhe sudo apt-get install conkyconky sudo apt-get install hddtemp curl lm-sensors conky-allsudo chmod u+s /usr/sbin/hddtempsudo sensors-detectsudo reboot cp /etc/conky/conky.conf /home/$USER/.conkyrc You can editing /home/$USER/.conkyrc to personize it. conky.config gap_x # initial placegap_y # initial place Theme from github git clone https://github.com/aikunzhe/conky_colors.gitcd conky_colorsmakesudo make install## testconky-colors --theme=custom --default-color=black --color0=cyan --color1=green --color2=orange --color3=red --ubuntu --cpu=2--updates --proc=3--clock=default --calendar --nvidia --hd=default --hdtemp1=sda --photo --photord --network --unit=C --side=right --bbcweather=1586--weather=CHXX0100 --rhythmbox=cdconky -c /home/$USER/.conkycolors/conkyrc 效果: 具體配置:from: aikunzhe 快捷键 Ctrl Alt T 打开一个终端运行以下命令查看帮助，代码:conky-colors --help部份conky-colors命令参数选项介绍：--lang 语言，5.1.2 版没有cn 中文选项，只能用默认的en 英语。--theme 面板主题， brave|carbonite|dust|human|noble|tribute|wine|wise| ambiance|radiance|elementary| cyan|blue|orange|red|green|purple|black|white| custom--side 面板在桌面的位置 left 左， right 右（默认）--ubuntu 显示LOGO，有9个LOGO可选，还可以在配置文件里自定义更多的LOGO--Fedora，--openSUSE，--debian，--arch，--gentoo，--pardus，--xfce，--gnome--cpu 显示CPU信息，双核CPU用2，四核用4，单核用1--cputemp 显示CPU温度--swap 显示swap缓存分区的信息--updates 显示系统需要升级的软件包信息--proc 显示资源占用情况排在前列的进程，3 显示3个进程（最多为10）--clock 显示时钟和日期，有7种形式可选default，classic，slim，modern，lucky，digital，off--calendar 显示月历--nvidia 显示Nidia显卡信息，抱歉没有ATI 的选项--hd 显示硬盘信息，有4中形式可选default，meerkat，mix，simple--hdtemp1 显示第一个硬盘的温度，第2个sata硬盘为 --hdtemp2=sdb--photord 随机显示幻灯片相册，默认使用的是系统桌面背景图片文件夹，可以在脚本 ~/.conkycolors/bin/conkyPhotoRandom 中把 source=&quot;/usr/share/backgrounds/&quot; 修改为自定义的图片目录--photo 仅固定显示一张图片，放在 /usr/share/backgrounds/ 内--network 显示网络信息，可以指定使用 --eth 网卡设备，--wlan 无线设备，--ppp 拨号设备 （默认都是0）--battery 显示电池信息--unit 温度单位 C 摄氏 或 F 华氏--rhythmbox 在多媒体栏显示Ubuntu自带的rhythmbox播放器的曲目信息。有7中形式可选：default，cd，case，glassy，vinyl，oldvinyl，simple还支持其他播放器：--covergloobus，--banshee，--exaile--pidgin 可显示pidgin在线的聊天好友按自己需要实现的功能选择相应参数，然后运行conky-colors生成.conkycolors目录和相关文件，你至少需要运行一次这个命令！否则没有.conkycolors这个目录，或者缺少某些程序文件。例如：代码:conky-colors --theme=custom --default-color=black --color0=cyan --color1=green --color2=orange --color3=red --ubuntu --cpu=2--updates --proc=3--clock=default --calendar --nvidia --hd=default --hdtemp1=sda --photo --photord --network --unit=C --side=right --bbcweather=1586--weather=CHXX0100 --rhythmbox=cd然后生成conkyrc配置文件，存放在 /home/用户名/.conkycolors 目录下,如果没有.conkycolors这个目录，可以自己创建。提示：在Linux中，凡是名称以点号开头的文件或文件夹，默认都是隐藏不见的。在窗口中，按下 Ctrl H 键即可显示隐藏文件。在终端下，可以用 ls -a 命令查看隐藏文件。 ./conky-colors &lt;options&gt; options: -------------- LANGUAGES -------------- --lang=&lt;language&gt; - Set default language Languages: bg|de|el|en*|et|fr|it|pl|pt|ru|es|uk -------------- THEMES -------------- --theme=&lt;theme&gt; - Set default theme color Themes: brave|carbonite|dust|human*|noble|tribute|wine|wise| ambiance|radiance|elementary| cyan|blue|orange|red|green|purple|black|white| custom Work only with --theme=custom --default-color=&lt;value&gt; --color0=&lt;value&gt; --color1=&lt;value&gt; --color2=&lt;value&gt; --color3=&lt;value&gt; --dark - Set Dark Brightness -------------- DEFAULT MODE -------------- --&lt;logo&gt; - Replace computer icon for distro Logo Logos: ubuntu|fedora|opensuse|debian|arch|gentoo|pardus|xfce|gnome --cpu=&lt;number&gt; - Set number of cpu cores --cputemp - Enable CPU temperature --swap - Enable SWAP --battery - Enable battery --battery-value=&lt;number&gt; - Change battery device number &lt;/proc/acpi/battery&gt; --updates - Show updates for Debian/Ubuntu --proc=&lt;number&gt; - Enable processes [Max = 10] --clock=&lt;default|modern|digital|off&gt; --nodata - disable Data --calendar - Enable calendar --calendarm - Enable calendar with monday as first day --calendarzim - Enable calendar with Zim support --nvidia - Enable nvidia gpu --task - Enable Task [type &quot;ct help&quot; in terminal for info] --hd=&lt;default|meerkat|mix|simple&gt; - Enable HD --hdtemp1=&lt;device&gt; - Enable HD temperature [Ex: --hdtemp1=sda] --hdtemp2=&lt;device&gt; - Enable HD temperature [Ex: --hdtemp2=sdb] --hdtemp3=&lt;device&gt; - Enable HD temperature [Ex: --hdtemp3=sdc] --hdtemp4=&lt;device&gt; - Enable HD temperature [Ex: --hdtemp4=sdd] --photo - Enable Photo --photord - Enable Photo in random mode --mpd - Enable MPD --banshee=&lt;default|cd|case|glassy|vinyl|oldvinyl|simple&gt; --clementine=&lt;default|cd|case|glassy|vinyl|oldvinyl|simple&gt; --rhythmbox=&lt;default|cd|case|glassy|vinyl|oldvinyl|simple&gt; --covergloobus - Enable CoverGloobus --gmail - Enable gmail notify --user=&lt;username&gt; - Type your username --passwd=&lt;password&gt; - Type your password --network - Enable network --eth=&lt;number&gt; - Change ethernet device [Default=0] --wlan=&lt;number&gt; - Change wireless device [Default=0] --ppp=&lt;number&gt; - Change 3g modem device [Default=0] --unit=&lt;C|F&gt;- Force output temperature either in Celius or Fahrenheit --weather=&lt;AreaID&gt; - Enable weather[Ex: --weather=BRXX0043] --bbcweather=&lt;AreaID&gt; - Enable weather[Ex: --bbcweather=3849] --side=&lt;left|right*&gt; - Set the side of conky in your screem -------------- CAIRO/RING MODE -------------- --cairo - Enable cairo-conky mode. --ring - Enable ring-conky mode. --cpu=&lt;number&gt; - Set number of cpu cores --swap - Enable SWAP [cairo-mode only] --clock=&lt;cairo|bigcairo&gt; - Enable/disable clock [cairo-mode only] --banshee=&lt;cairo|cairo-case|cairo-cd|cairo-glassy|lua&gt; [cairo-mode only] --clementine=&lt;cairo|cairo-case|cairo-cd|cairo-glassy|lua&gt; [cairo-mode only] --rhythmbox=&lt;cairo|cairo-case|cairo-cd|cairo-glassy|lua&gt; [cairo-mode only] --banshee=&lt;ring|ring-case|ring-cd|ring-glassy&gt; [ring-mode only] --clementine=&lt;ring|ring-case|ring-cd|ring-glassy&gt; [ring-mode only] --rhythmbox=&lt;ring|ring-case|ring-cd|ring-glassy&gt; [ring-mode only] --network - Enable network --unit=&lt;C|F&gt;- Force output temperature either in Celius or Fahrenheit -------------- BOARD/SLIM MODE -------------- --board - Enable board-conky mode. --slim - Enable slim-conky mode. --w=&lt;width&gt; - Set your screen width --h=&lt;height&gt; - Set your screen height --nobg - Remove background --posfix=&lt;number&gt; - fix ring position --weather=&lt;AreaID&gt; - Enable weather[Ex: --weather=BRXX0043] --unit=&lt;C|F&gt;- Force output temperature either in Celius or Fahrenheit -------------- SLS MODE -------------- --sls - Enable SLS-conky mode. --nobg - Remove background --weather=&lt;AreaID&gt; - Enable weather[Ex: --weather=BRXX0043] --user=&lt;username&gt; - Type your gmail username --passwd=&lt;password&gt; - Type your gmail password -------------- EXTRA OPTIONS -------------- --datadir=/path/to/datadir - it overrides default datadir --createlocalcopy - it copies the content of system datadir to /home/ken/.conkycolors --nofilecheck - disables checking the presence of files --default_datadir - prints the order of default datadirs in which files are searched by default. --finddir=FILE - this option makes this program find and print out a directory where FILE is located. --argb-value=0-255 - Set the value of own_window_argb_value, the default is 200 --install=local(*), system, or custom - install generated configuration files to a chosen datadir. --systemdir - displays the system directory for conkycolors. --localdir - displays the local directory for conkycolors.(*)default values task 文件在 /home/$USER/.conkycolors/tasks conky-colors --theme=blue --default-color=black --color0=cyan --color1=green \\--color2=orange --color3=red \\ # basic thmeme--debian --updates \\ # system $ update information--cpu=8 --cputemp \\ # cpu and cmp tmp--nvidia \\ # gpu infor--swap \\ # Ram--battery \\ # Battery inf--proc=10 \\ #task--clock=digital --calendarm \\ # Date--task \\ # personal task, stort at /home/$USER/.conkycolors/tasks--hd=default --hdtemp1=sda --hdtemp2=sda2 \\ #hard drive Tm--banshee=simple --clementine=default --rhythmbox=default \\ #Media player##--network \\ # fail to show on my computer## --board/--slim \\ # fail to show on my computer## --weather=BRXX0043\\ # fail to request the Tm conky-colors --theme=blue --default-color=black --color0=cyan --color1=green \\--color2=orange --color3=red \\--debian --updates \\--cpu=8 --cputemp \\--nvidia \\--swap \\--battery \\--proc=10 \\--clock=digital --calendarm \\--task \\--hd=default --hdtemp1=sda --hdtemp2=sda2 \\--banshee=simple --clementine=default --rhythmbox=default 开机启动 reference:Micr067创建启动文件并加入以下配置locate autostart 查找系统启动文件目录我的栗子: sudo vim /etc/xdg/autostart/conky.desktop 输入一下文本 [Desktop Entry]Name=conkyType=ApplicationExec=/usr/bin/conky 保存(:wq!)并退出 reboot conky主题网站 reference:潘哒matehttps://www.deviantart.com/customization/skins/linuxutil/applications/conky/newest/ tutorial:https://www.cnblogs.com/MineLSG/p/10413608.html","link":"/2020/06/23/Linux/Conky/"},{"title":"Download Softwares","text":"apt apt, short for Advanced Package Tool, is a package management system commonly used in Debian-based Linux distributions like Ubuntu. It simplifies the process of installing, updating, and managing software packages on a system. Usually, we could do apt insatll or sudo apt install. In this case, commands would link into /usr/bin or /usr/local/bin which requires root permission. You could also use it to down load the deb file and download in local. Take a common software tree as an example: apt download treedpkg -x tree_2.1.1-2ubuntu3_amd64.deb tree After that, you just need to export the bin from tree into the environment. wget wget -c ulr 支持断点续传 aria2c website: https://aria2.github.io/install: sudo apt-get install aria2 aria2 is a lightweight multi-protocol &amp; multi-source command-line download utility. It supports HTTP/HTTPS, FTP, SFTP, BitTorrent and Metalink. aria2 can be manipulated via built-in JSON-RPC and XML-RPC interfaces. Examples ##Usage Examples##Command-line scares you off? No, aria2 is really easy to use!!##Download from WEB:aria2c http://example.org/mylinux.iso##Download from 2 sources:aria2c http://a/f.iso ftp://b/f.iso##Download using 2 connections per host:aria2c -x2 http://a/f.iso##BitTorrent:aria2c http://example.org/mylinux.torrent##BitTorrent Magnet URI:aria2c 'magnet:?xt=urn:btih:248D0A1CD08284299DE78D5C1ED359BB46717D8C'##Metalink:aria2c http://example.org/mylinux.metalink##Download URIs found in text file:aria2c -i uris.txt curl reference: https://curl.haxx.se/docs/manpage.html curl is a tool to transfer data from or to a server, using one of the supported protocols (DICT, FILE, FTP, FTPS, GOPHER, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, POP3, POP3S, RTMP, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET and TFTP). The command is designed to work without user interaction. curl ftps://files.are.secure.com/secrets.txt more tutorial: https://curl.haxx.se/docs/manual.html","link":"/2020/06/23/Linux/Download-Software/"},{"title":"GIMP","text":"GIMP Line Straight line 鼠标左键 选择起始位置 按住shift， 锁定 松开鼠标左键， 不松shift 移动到终点，点击鼠标左键 Rectangle Rectangle select tools (select a region) Edit -&gt; Stroke selection -&gt; Stroke hot key: R (select rectangle tools and select a region) Alt+E(open edit menu board) S Enter","link":"/2020/06/23/Linux/GIMP/"},{"title":"Start With Raspberry pi","text":"Start With Raspberry pi apt Mirror reference: https://mirrors.tuna.tsinghua.edu.cn/help/raspbian/ ## 编辑 `/etc/apt/sources.list` 文件，删除原文件所有内容，用以下内容取代：deb http://mirrors.tuna.tsinghua.edu.cn/raspbian/raspbian/ buster main non-free contribdeb-src http://mirrors.tuna.tsinghua.edu.cn/raspbian/raspbian/ buster main non-free contrib## 编辑 `/etc/apt/sources.list.d/raspi.list` 文件，删除原文件所有内容，用以下内容取代：deb http://mirrors.tuna.tsinghua.edu.cn/raspberrypi/ buster main ui Virtual Keyboard reference:https://www.cnblogs.com/little-kwy/p/9478961.html sudo apt-get install matchbox-keyboardsudo apt-get install libmatchbox1 -y sudo nano /usr/bin/toggle-matchbox-keyboard.sh ##!/bin/bash##This script toggle the virtual keyboardPID=`pidof matchbox-keyboard`if [ ! -e $PID ]; then killall matchbox-keyboardelse matchbox-keyboard&amp;fi sudo nano /usr/share/applications/toggle-matchbox-keyboard.desktop [Desktop Entry]Name=Toggle Matchbox KeyboardComment=Toggle Matchbox KeyboardExec=toggle-matchbox-keyboard.shType=ApplicationIcon=matchbox-keyboard.pngCategories=Panel;Utility;MBX-MB-INPUT-MECHANSIM=True It’s failed and I don’t know why. But there is a keyboard for rasberrypi, so… Screen Shot sudo apt-get install scrotscrot test.png## screen shot forscrot -s 0 0 100 100## Screen shot after 10sscrot -d 10 Screen Record sudo apt-get install vokoscreenvokoscreen USB Camera reference: https://blog.csdn.net/yjp19871013/article/details/80147803 Take a Photo sudo apt-get install fswebcamfswebcam /dev/video0 ~/image.jpg #/dev/vedio0 is the vedio raspistill -o ugi.jpg -w 2560 -h 1440 -v # -vf Stream image sudo apt-get install luvcviewluvcview -s 400x400 I got an error code after a lunached the command. The image poped out and crashed after about 1s. luvcview: ../../src/xcb_io.c:165: dequeue_pending_request: Assertion `!xcb_xlib_unknown_req_in_deq' failed. But I find that once you launched your camera, you need to keep the camera moving for a while and so, it can run smoothly. 自动免密码登录 ##https://blog.csdn.net/zexzex_/article/details/78490054sudo raspi-config选择Boot OptionsDesktop / CLTconsole Autologin Text console int3 或者 Desktop Autologin Desktop GUI 桌面环境finishreboot 开机任务 参考: yuanfujie 進入隱藏文件夾， 然後創建一個文件夾和文件， 做開機啓動腳本 cd ~/.configcd /home/pi/.configmkdir autostartcd autostart## 創建自啓腳本sudo nano myapp.desktop 在nano後黏貼代碼如下。重點在Exec=XXX; 比如，我的需要執行的腳本路徑爲/home/pi/Blive [Desktop Entry]Type=ApplicationExec=/home/pi/BliveIcon=ICON_PATH 親測有效 Enjoy～","link":"/2020/06/26/Linux/Start-With-Rasberry-pi/"},{"title":"Package Managers For linux","text":"Package Managers For linux apt snap website: https://snapcraft.io/store systemctl restart snapdsudo snap install ** 获得下载链接: curl -H 'Snap-Device-Series: 16' http://api.snapcraft.io/v2/snaps/info/anbox ulr 在结果中(页面查找download可以迅速定位):“download”:{“deltas”:[],“sha3-384”:“76f4f975d6e465f7362f176a9c4ab49067224157d0d611d243596b82cd24c78f51c3d2a29f382882967bb5ae5fbf1858”,“size”:81797120,“url”:“https://api.snapcraft.io/api/v1/snaps/download/M7yvgnqOvyQj64bolfpawIAEwHv7dQ5G_202.snap”} {&quot;channel-map&quot;:[{&quot;channel&quot;:{&quot;architecture&quot;:&quot;amd64&quot;,&quot;name&quot;:&quot;stable&quot;,&quot;released-at&quot;:&quot;2020-01-01T22:39:50.563736+00:00&quot;,&quot;risk&quot;:&quot;stable&quot;,&quot;track&quot;:&quot;latest&quot;},&quot;created-at&quot;:&quot;2020-01-01T22:38:31.952619+00:00&quot;,&quot;download&quot;:{&quot;deltas&quot;:[],&quot;sha3-384&quot;:&quot;f385d44ecfdfa9268a2be6b2fd98f29ac5d38d80d374e92cdc45ba07eac16c6fe9e178dbf675f579d0256cf52a483cb7&quot;,&quot;size&quot;:81793024,&quot;url&quot;:&quot;https://api.snapcraft.io/api/v1/snaps/download/M7yvgnqOvyQj64bolfpawIAEwHv7dQ5G_204.snap&quot;},&quot;revision&quot;:204,&quot;type&quot;:&quot;app&quot;,&quot;version&quot;:&quot;v1.12&quot;},{&quot;channel&quot;:{&quot;architecture&quot;:&quot;i386&quot;,&quot;name&quot;:&quot;stable&quot;,&quot;released-at&quot;:&quot;2020-01-01T22:42:08.624199+00:00&quot;,&quot;risk&quot;:&quot;stable&quot;,&quot;track&quot;:&quot;latest&quot;},&quot;created-at&quot;:&quot;2020-01-01T22:41:21.457669+00:00&quot;,&quot;download&quot;:{&quot;deltas&quot;:[],&quot;sha3-384&quot;:&quot;201b9a486e02fa8b06b7a1b1fad002757cc64b3982ba1fff5e5b11a82802fba31a0389d0aa5affba986d2400df273d31&quot;,&quot;size&quot;:82841600,&quot;url&quot;:&quot;https://api.snapcraft.io/api/v1/snaps/download/M7yvgnqOvyQj64bolfpawIAEwHv7dQ5G_205.snap&quot;},&quot;revision&quot;:205,&quot;type&quot;:&quot;app&quot;,&quot;version&quot;:&quot;v1.12&quot;},{&quot;channel&quot;:{&quot;architecture&quot;:&quot;amd64&quot;,&quot;name&quot;:&quot;beta&quot;,&quot;released-at&quot;:&quot;2020-01-18T07:04:58.924188+00:00&quot;,&quot;risk&quot;:&quot;beta&quot;,&quot;track&quot;:&quot;latest&quot;},&quot;created-at&quot;:&quot;2020-01-18T07:03:58.524875+00:00&quot;,&quot;download&quot;:{&quot;deltas&quot;:[],&quot;sha3-384&quot;:&quot;f608e1c8bc2fee937a1dead15ece1be4cc79fbb06804e3f405410a69933b1282967ce138454b92c6c6f15fd135b78e3c&quot;,&quot;size&quot;:85434368,&quot;url&quot;:&quot;https://api.snapcraft.io/api/v1/snaps/download/M7yvgnqOvyQj64bolfpawIAEwHv7dQ5G_208.snap&quot;},&quot;revision&quot;:208,&quot;type&quot;:&quot;app&quot;,&quot;version&quot;:&quot;v1.12.1-1-g31bd950&quot;},{&quot;channel&quot;:{&quot;architecture&quot;:&quot;armhf&quot;,&quot;name&quot;:&quot;beta&quot;,&quot;released-at&quot;:&quot;2020-01-18T08:02:17.160034+00:00&quot;,&quot;risk&quot;:&quot;beta&quot;,&quot;track&quot;:&quot;latest&quot;},&quot;created-at&quot;:&quot;2020-01-18T08:01:25.981004+00:00&quot;,&quot;download&quot;:{&quot;deltas&quot;:[],&quot;sha3-384&quot;:&quot;f44ce790760d736855c078b5679737cc6bf013ee91d28860fc9fb5cade2e0bf57ae4c81d987b2081e7874a7027c97f5a&quot;,&quot;size&quot;:73723904,&quot;url&quot;:&quot;https://api.snapcraft.io/api/v1/snaps/download/M7yvgnqOvyQj64bolfpawIAEwHv7dQ5G_210.snap&quot;},&quot;revision&quot;:210,&quot;type&quot;:&quot;app&quot;,&quot;version&quot;:&quot;v1.12.1-1-g31bd950&quot;},{&quot;channel&quot;:{&quot;architecture&quot;:&quot;i386&quot;,&quot;name&quot;:&quot;beta&quot;,&quot;released-at&quot;:&quot;2020-01-18T07:05:48.607438+00:00&quot;,&quot;risk&quot;:&quot;beta&quot;,&quot;track&quot;:&quot;latest&quot;},&quot;created-at&quot;:&quot;2020-01-18T07:04:34.542649+00:00&quot;,&quot;download&quot;:{&quot;deltas&quot;:[],&quot;sha3-384&quot;:&quot;8a330eb9981ef9957556515cda2ee8b8f4ae2a458d93488d62182fe5a4a60d0fb888e3d18ea420fe0dbf0e4ec39381f2&quot;,&quot;size&quot;:86736896,&quot;url&quot;:&quot;https://api.snapcraft.io/api/v1/snaps/download/M7yvgnqOvyQj64bolfpawIAEwHv7dQ5G_209.snap&quot;},&quot;revision&quot;:209,&quot;type&quot;:&quot;app&quot;,&quot;version&quot;:&quot;v1.12.1-1-g31bd950&quot;},{&quot;channel&quot;:{&quot;architecture&quot;:&quot;amd64&quot;,&quot;name&quot;:&quot;edge&quot;,&quot;released-at&quot;:&quot;2019-12-10T00:14:49.361567+00:00&quot;,&quot;risk&quot;:&quot;edge&quot;,&quot;track&quot;:&quot;latest&quot;},&quot;created-at&quot;:&quot;2019-12-10T00:12:26.588992+00:00&quot;,&quot;download&quot;:{&quot;deltas&quot;:[],&quot;sha3-384&quot;:&quot;76f4f975d6e465f7362f176a9c4ab49067224157d0d611d243596b82cd24c78f51c3d2a29f382882967bb5ae5fbf1858&quot;,&quot;size&quot;:81797120,&quot;url&quot;:&quot;https://api.snapcraft.io/api/v1/snaps/download/M7yvgnqOvyQj64bolfpawIAEwHv7dQ5G_202.snap&quot;},&quot;revision&quot;:202,&quot;type&quot;:&quot;app&quot;,&quot;version&quot;:&quot;v1.12-1-g71df317&quot;}],&quot;default-track&quot;:null,&quot;name&quot;:&quot;scrcpy&quot;,&quot;snap&quot;:{&quot;license&quot;:&quot;Apache-2.0&quot;,&quot;name&quot;:&quot;scrcpy&quot;,&quot;prices&quot;:{},&quot;publisher&quot;:{&quot;display-name&quot;:&quot;sisco311&quot;,&quot;id&quot;:&quot;jQgc0rEVirS9Mk0Ud0UWWPFSwlGF3yVu&quot;,&quot;username&quot;:&quot;sisco311&quot;,&quot;validation&quot;:&quot;unproven&quot;},&quot;snap-id&quot;:&quot;M7yvgnqOvyQj64bolfpawIAEwHv7dQ5G&quot;,&quot;store-url&quot;:&quot;https://snapcraft.io/scrcpy&quot;,&quot;summary&quot;:&quot;Display and control your Android device&quot;,&quot;title&quot;:&quot;scrcpy&quot;},&quot;snap-id&quot;:&quot;M7yvgnqOvyQj64bolfpawIAEwHv7dQ5G&quot;} npm We’re npm, Inc., the company behind Node package manager, the npm Registry, and npm CLI. We offer those to the community for free, but our day job is building and selling useful tools for developers like you. –npm Reference:https://blog.csdn.net/chenjh213/article/details/45692987 Install npm install &lt;registry-name&gt;## With mirror sitenpm install &lt;registry-name&gt; --registry https://registry.npm.taobao.org'''Other Mirrowshttps://registry.npmjs.orghttps://r.cnpmjs.orghttps://registry.npm.taobao.org''' Mirrors 2.永久设置: npm config set registry https://registry.npmjs.org npm config list #查看更新后的config设置 apm Atom pakcages manager mirror apm config set registry http://registry.npm.taobao.org reference: 提辖鲁 install apm install atom-latex flatpak What is flatpak? Flatpak is a next-generation technology for building and distributing desktop applications on Linux. Flatpak is developed by an independent community, made up of contributors, volunteers and supporting organizations. It is a true upstream open source project, dedicated to providing technology and services that can be used by all, with no vendor lock-in. We have strong links to other Free Software projects, including the Freedesktop project. –Flatpck Install flatpak apt install flatpakapt install gnome-software-plugin-flatpakflatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo To complete setup, restart your system. Now all you have to do is install some apps! Install and run apps from flatpak ## isntall OBSflatpak install flathub com.obsproject.Studio## run OBSflatpak run com.obsproject.Studio","link":"/2020/06/26/Linux/Shop-store/"},{"title":"To Start With Linux","text":"To Start With Linux 1 Add a user useradd ken # add a user 'ken'passwd ken # add a password for urser 'ken' 2 Add users to sudo group vim /etc/sudoers # use root acount or run with sudo Find the line “root ALL=(ALL) ALL” and add a line: ken ALL=(ALL) ALL save and quite 3 Adding Script to boot list sudo vim /etc/rc.local ##!/bin/bash## rc.local config file created by use##The script you want to run while bootingexit 0 sudo chmod +x /etc/rc.local Something Else System infor # print distrohead -n 1 /etc/issue# Name of the computerhostname Hardware infor # CPU inforcat /proc/cpuinfo# Ram inforgrep MemTotal /proc/meminfo# Ram inforfree -h Java adopt open jdk Control your sound alsamixer Mute and unmute sounds Source: Eric Carvalho 2011 amixer set Master mute amixer set Master unmute Paste ДМИТРИЙ МАЛИКОВ, 2013 paste &lt;(echo &quot;$VAR1&quot;) &lt;(echo &quot;$VAR2&quot;) --delimiters ''","link":"/2020/06/26/Linux/To-Start-With-Linux/"},{"title":"Linux Commands","text":"Linux Commands Public and private key Create a public and private key pair. Upload your public key on your remote Unix and Linux servers. Use ssh to login to your remote servers without using a password. Add your key at the end of ~/.ssh/authorized_keys file # generate the key for your local computerssh-keygen -t rsa# upload your public keyscp ~/.ssh/id_rsa.pub username@192.168.1.100:~# Now, login your remote server and add the public key at the end of authorizecat ~/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys# Now you shell be logging without any problems. location of bash script Source: Hiks Gerganov # paht of the script fileecho &quot;${BASH_SOURCE}&quot;# path of script's directoryecho &quot;$(dirname -- &quot;$(readlink -f &quot;${BASH_SOURCE}&quot;)&quot;)&quot; sort &amp; uniq ##数字大小排序sort -n test.txt | while read num ;do echo $num ; sum=`expr $sum + $num 2&gt; /dev/null`;echo $sum &gt; /tmp/sum.tmp ;done ; echo -n &quot;sum is :&quot; ;cat /tmp/sum.tmpsort -n C.txt &gt;T.txt## 二、去掉所有重复的数据行cat data1.txt | sort | uniq head and tail tail实例3：从第5行开始显示文件命令：tail -n +5 log2014.log echo echo AAAecho -e &quot;\\033[41;36m something here \\033[0m&quot;echo -e &quot;\\033[40;37m red \\033[0m&quot;echo -e &quot;\\033[41;37m blue \\033[0m&quot;echo -e &quot;\\033[42;37m green \\033[0m&quot;echo -e &quot;\\033[43;37m 黄底白字 \\033[0m&quot;echo -e &quot;\\033[44;37m 蓝底白字 \\033[0m&quot;echo -e &quot;\\033[45;37m 紫底白字 \\033[0m&quot;echo -e &quot;\\033[46;37m 天蓝底白字 \\033[0m&quot;echo -e &quot;\\033[47;30m 白底黑字 \\033[0m&quot; find # find empty files and delete themfind . -type f -empty -print -delete mail ##1.如何写一般的邮件：mail test@126.com Cc 编辑抄送对象，Subject:邮件主题,输入回车，邮件正文后，按Ctrl-D结束##2.快速发送方式：echo &quot;邮件正文&quot; | mail -s 邮件主题 591465908@qq.com##3.以文件内容作为邮件正文来发送： mail -s test test@126.com &lt; test.txt##4.发送带附件的邮件：uuencode 附件名称 附件显示名称 | mail -s 邮件主题 发送地址##例如： uuencode test.txt test.txt | mail -s Test test@126.com Release Cached RAM echo 1 &gt; /proc/sys/vm/drop_caches record screen as gif byzanz-record -d 40 -x 0 -y 0 -w 400 -h 320 byzanz-demo.gif其中： -d 40 为录制的时长为 40 秒 -x 0 录制区域的横坐标 -y 0 录制区域的纵坐标，记住：屏幕右上角为原点（0,0） -w 400 录制区域的宽度 -h 320 录制区域的高度byzanz-demo.gif 保存的文件名####snap shoutxwd -silent -root | convert xwd:- -crop 800x600+0+76 test.png for fun bannerfiglettoilet case ##Casecase $Random in1)/media/ken/Data/Python-Voice/speak.sh &quot;WARNNING!&quot;;;2)/media/ken/Data/Python-Voice/speak.sh &quot;PLEASE_HELP_ME!&quot;;;3)/media/ken/Data/Python-Voice/speak.sh &quot;WARNNING!&quot;/media/ken/Data/Python-Voice/speak.sh &quot;I_DONT_WANT_TO_GO&quot;esacpstree -up##参数选择：##-A ：各程序树之间以 ASCII 字元來連接；##-p ：同时列出每个 process 的 PID；##-u ：同时列出每个 process 的所屬账户名称。 Time ##https://www.cnblogs.com/janezhao/p/9732157.htmltime1=$(date)echo $time1time2=$(date &quot;+%Y%m%d%H%M%S&quot;)echo $time2##20180930155515 Font reference: 某某某的账号 ##查看所有字体：fc-list##查看中文字体fc-list :lang=zh stat 海王 2011 stat public/ File: public/ Size: 4096 Blocks: 8 IO Block: 4096 directory Device: 802h/2050d Inode: 348256 Links: 1 Access: (0777/drwxrwxrwx) Uid: ( 1000/ ken) Gid: ( 1000/ ken) Access: 2020-07-29 23:57:44.005512600 +0800 Modify: 2020-07-29 23:57:43.560542100 +0800 Change: 2020-07-29 23:57:43.560542100 +0800 Birth: - SCP ## Download files from serverscp -P 8022 root@192.168.3.6:~/test.md .## Upload files to serverscp -P 8022 test.md root@192.168.3.6:~/ Similar to SCP, this commands could help you to skip files already exist: rsync -avz --ignore-existing test2/* username@IP:path# synchronize all files in test2 into the remote directory test````## 查看硬件&lt;a name=&quot;IPgOq&quot;&gt;&lt;/a&gt;### CPU```bashlscpu### 网卡lspci | grep -i 'eth' GPU inf lspci| grep -i vga # Check the GPU at prsent Disable Keys/Mouse We could use the xinput list to check all the input devices and disable it with xinput disable $id xinput list ⎡ Virtual core pointer id=2 [master pointer (3)] ⎜ ↳ Virtual core XTEST pointer id=4 [slave pointer (2)] ⎜ ↳ LXDDZ JLab Epic Keys id=12 [slave pointer (2)] ⎜ ↳ LXDDZ JLab Epic Keys Consumer Control id=14 [slave pointer (2)] ⎜ ↳ RH USB Gaming Mouse id=18 [slave pointer (2)] ⎜ ↳ RH USB Gaming Mouse Consumer Control id=20 [slave pointer (2)] ⎜ ↳ TSTP MTouch id=9 [slave pointer (2)] ⎜ ↳ TSTP MTouch id=10 [slave pointer (2)] ⎣ Virtual core keyboard id=3 [master keyboard (2)] # disable the touch screenxinput disable 9 xinput disable 10 ∼ TSTP MTouch id=9 [floating slave] ∼ TSTP MTouch id=10 [floating slave] Mount remate file system ssh-keygen -t rsasudo apt install sshfssudo mkdir /mnt/cypresssudo sshfs -o allow_other,IdentityFile=~/.ssh/id_rsa wliu15@cypress.tulane.edu:/lustre/project/wdeng7/wliu15/ /mnt/cypress/","link":"/2020/06/26/Linux/System/"},{"title":"Arch linux in Android (aarch64)&#x2F;No root (proot)","text":"Arch linux in Android phon Test host: Samsung Galaxy ultra S23 How to install: Tmoe Tmoe link: majianwei_private After start with VNC install a packages: sudo pacman -S cmatrix remove the package: sudo pacman -R cmatrix get the information of the package: pacman -Qi cmatrix Name : cmatrix Version : 2.0-2 Description : A curses-based scrolling 'Matrix'-like screen Architecture : aarch64 URL : https://www.asty.org/cmatrix/ Licenses : GPL3 Groups : None Provides : None Depends On : ncurses Optional Deps : kbd: cmatrix-tty custom font [installed] xterm: cmatrix-tty custom font Required By : None Optional For : None Conflicts With : None Replaces : None Installed Size : 94.74 KiB Packager : Arch Linux ARM Build System Build Date : Mon 29 Jun 2020 02:47:20 PM CDT Install Date : Thu 15 Jun 2023 12:26:30 PM CDT Install Reason : Explicitly installed Install Script : No Validated By : Signature setup yay sudo pacman -S --needed base-devel gitgit clone https://aur.archlinux.org/yay-git.gitcd yay-git/makepkg -si ==> Making package: yay-git 12.0.5.r0.g9641d2a-1 (Thu 15 Jun 2023 12:34:49 PM CDT) ==> Checking runtime dependencies... ==> Checking buildtime dependencies... ==> Installing missing dependencies... resolving dependencies... looking for conflicting packages... Packages (1) go-2:1.20.4-1 Total Download Size: 35.71 MiB Total Installed Size: 192.95 MiB :: Proceed with installation? [Y/n] Just type y and enter some software you may like firefox: pacman -S firefox pre { background-color:#38393d; color: #5fd381; }","link":"/2023/06/15/Linux/archarm/"},{"title":"Linux Bluetooth Trouble Shoot","text":"Linux Blue tooth Trouble Shoot Reference: system 76 Except Nvidia driver, bluetooth driver could be an annoying one, too. Link above list lost of possible ways to deal with the bluetooth. Im my situation, I am using Pop 20.04 focal which kernel is x86_64 Linux 5.16.19-76051619-generic. Very interesting thing is I can connect my Cellphone with bluetooth but not head buds. After tried a few codes from the blog of system 76, my problem was solved by reset the bluetooth devices profile. sudo rm -r /var/lib/bluetooth/","link":"/2022/05/27/Linux/bluetooth/"},{"title":"awk 语言基础","text":"awk 语言基础 pre { background-color:#38393d; color: #5fd381; } awk -F\\; '{print $1}' filename # print the first columnawk -F\\; '{print $(NF)}' filename # print the last column awk '/^the/' filename # the every line starting with the 'the'awk '/the$/' filename # the every line ending with the 'the'awk '/[0-9]/' filename # the every line contain numbersawk '/[a-z]/' filename # the every line contain the lower capital lettersawk '/hel+0/' filename # helllllo helloawk '/abc|123/' filename # return for 'abc' or '123'. | --&gt; orFS = Input field separator valueOFS = Output field separator valueNF = Number of fields on the current lineNR = Number of records in the current fileRS = Record separator valueORS = Output record separatorFILENAME = Current file name being processed and probably a few moreawk '{print NR}' filename # would print the line number for every line processed## = grep -cawk 'END{print NR}' filename # Counts the lines in a file. similar to 'wc -l' pipline on awk awk 'BEGIN{print &quot;the start&quot;};{print}; END{print &quot;the end&quot;}' filename Simple Logic awk '{if(NR~/^2#/)print}' filename # would print line 2 from filenameawk '{if(NR~2)print}' filename # would print any line numbers contain 2 from filename### 2, 12, 22, 32...awk '{if(NR!~2)print}' filename # negated matchawk '{if(NR==2)print}' filenameawk '{if(NR!=2)print}' filename OFS awk '{OFS=&quot;\\t&quot;;print $6}' filenameorawk -F&quot;\\t&quot; '{print $6}' filenameawk -F&quot;\\t&quot; 'NR==1,NR==10{print $6}' filename #print the cloum 6 from line 1 to line 10;awk -F&quot;\\t&quot; '{print length($5)}' filename # length() function to count the Delete columns awk '$1=&quot;&quot;;{print;OFS=\\t}' FILENAME Conditions awk '$3&gt;10' FILENAME Deleted the line after calculation The grammar gawk is much the same like awk but more flexible To delete some lines which doesn’t contain Baeldung awk '!/Baeldung/' myfile.txt &gt; tmpfile &amp;&amp; mv tmpfile myfile.txt To delete lines which the second column is larger than 0.5: gawk -i inplace '$2&gt;=0.5' file_name Turn one columns into few different rows RavinderSingh13, 2016 From: 10000|[12080000000] 10002|[13075200000] 10003|[13939200000] 10004|[1347200000,133600000,1152000000,106400000,12800000,117200000,145180000,1451000000,148400000,14240000] 10005|[16000000] To: PARTY|PART_DT 10000|12080000000 10002|13075200000 10003|13939200000 10004|1347200000 10004|133600000 10004|1152000000 10004|106400000 10004|12800000 10004|117200000 10004|145180000 10004|1451000000 10004|148400000 10004|14240000 10005|16000000 awk -F&quot;|&quot; 'BEGIN{print &quot;PARTY|PART_DT&quot;} {gsub(/\\[|\\]/,X,$NF);num=split($NF, array,&quot;,&quot;);for(i=1;i&lt;=num;i++){print $1 OFS array[i]}}' OFS=&quot;|&quot; Input_file Merge one column into three columns to reduce the row number kumaran_5555, 2011 From AAA BBB CCC DDD EEE FFF GGG HHH III To AAA DDD GGG BBB EEE HHH CCC FFF III awk -v col=3 '{if(NR%col){printf &quot;%s &quot;,$0 }else {printf &quot;%s\\n&quot;,$0}} ' test.txt RudiC, 2019 From A value1 A value2 A value3 B value1 B value2 B value3 C value1 C value2 C value3 To A value1 value2 value3 B value1 value2 value3 C value1 value2 value3 awk 'LAST != $1 {printf &quot;%s%s&quot;, DL, $0; LAST = $1; DL = RS; next}; {printf &quot;\\t%s&quot;, $2} END {printf RS}' file Match to print print the rows when the first column contains ‘,’ From: 123,1 123,1 123 1123,1 12,12 12314 1231 123123 To: 123,1 123,1 12,12 12314 awk -F &quot;\\t&quot; '$1 ~ /,/ {print}' file_name Calculation Sum of a column Cite:Ajo, 2015 awk -F',' '{sum+=$57;} END{print sum;}' file.txt Mean of a column Cite: orges, 2010 awk '{ total += $3 } END { print total/NR }' file.name Print a column by match CHROM X A B 1 1 1 1 1 2 2 2 Let’s say, I want first two columns and the column which names is “B”: CHROM X B 1 1 1 1 2 2 awk -v tmp=$(grep -i CHROM test.txt| tr '\\t' '\\n'| grep -wn B | awk -F: '{print $1}') '{OFS=&quot;\\t&quot;; print $1,$2,$tmp}' test.txt","link":"/2020/06/23/Linux/awk/"},{"title":"Termux","text":"Version: Switch to your favorite mirror termux-change-repo Select all (or whatever you want) Select a mirror exp: mirror by Tsinghua University SSH pkg install openssh # 安装sshpasswd # 设置登录密码ifconfig # 获取ip (手机电脑链接同一路由器/局域网)whoami # 获取用户名sshd # 开启 ssh 服务 Now, you can login your termux through ssh: u0_a450@192.168.0.100 -p8022 Cell Phon Storage Access ##建立storagetermux-setup-storage #(手机需要授予权限) After executed the code, you can see the directory storage which can connect to your cell phone directories. Install VNC desktop environment Document pkg install x11-repopkg install tigervnc# setup servervncserver -localhost# kill desktopvncserver -kill :1 xfce4 desktop pkg install xfce4export DISPLAY=&quot;:1&quot;xfce4-session &amp;apt install aterm twm PS: Though it seems have a ‘perfect’ desktop environment, it can’t show the result of the plot from R and python . errors E: Failed to fetch https://10.via0.com/ipns/k51qzi5uqu5dg9vawh923wejqffxiu9bhqlze5f508msk0h7ylpac27fdgaskx/pool/main/libs/libsm/libsm_1.2.3-17_aarch64.deb 521 Origin Down [IP: 172.67.212.200 443] E: Failed to fetch https://10.via0.com/ipns/k51qzi5uqu5dg9vawh923wejqffxiu9bhqlze5f508msk0h7ylpac27fdgaskx/pool/main/libx/libxext/libxext_1.3.4-11_aarch64.deb 521 Origin Down [IP: 172.67.212.200 443] E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing? Connection is unstable, try it few more times. apt install tigervnc Some other packages apt install vim vim-gtk vim-python wget pythonenv wget http://python.org/ftp/python/3.7.6/Python-3.7.6.tar.xztar xf Python-3.7.6.tar.xzcd Python-3.7.6./configure --enable-optimizationsmake altinstallrm -rf ../Python*xz kivyenv pip install -i https://pypi.tuna.tsinghua.edu.cn/simple kivy pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pillow hello world example: Kivy hello world R Conor I. Anderson pkg install curl gnupgmkdir -p &quot;$PREFIX/etc/apt/sources.list.d/&quot;echo &quot;deb https://its-pointless.github.io/files/24 termux extras&quot; &gt; &quot;$PREFIX/etc/apt/sources.list.d/pointless.list&quot;curl &quot;https://its-pointless.github.io/pointless.gpg&quot; | apt-key addpkg install r-base Install linux The troditional way (which I faild = =) 想做个好人 2020 faildapt install opensslpkg install wget prootwget https://raw.githubusercontent.com/Neo-Oli/termux-ubuntu/master/ubuntu.shbash ubuntu.sh Tmoe-linux 青菜芋子 2020 Tmoe-repository You just need run one of them three. I failed for execute the first and succesed on the second. #bash -c &quot;$(curl -L git.io/linux.sh)&quot;bash -c &quot;$(curl -L l.tmoe.me)&quot;#bash -c &quot;$(curl -L https://gitee.com/mo2/linux/raw/2/2)&quot; Arch in Tmoe # add a user 'ken'useradd ken# add a password for urser 'ken'passwd ken # use root acount or run with sudovim /etc/sudoers# siwtch to user kensu ken Find the line “root ALL=(ALL) ALL” and add a line: ken ALL=(ALL) ALL save and quite pacman -S r tk# tk for matplotlibpip install radian matplotlib docutils pygments pygame Matplotlib doesn’t show graph import matplotlibmatplotlib.use('TkAgg') kivy Don’t install kivy while pip!!! pacman -S python sdl2_image sdl2_mixer sdl2_ttf python-setuptools sdl2pacman -S python-pygame python-kivy openCV pip install opencv-python Some other Softwarw sudo pacman -Sy yay python-condachmod +777 /usr/bin/condaconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/channel conda config -- removeconda create --name Biosource activate# (base) [user@localhost Desktop]$conda activate Bio# (Bio) [user@localhost Desktop]$sudo pacman -Sy zlib requests idna chardet urllib3 six Error Unable to establish SSL connection. apt install openssl Install R in Jupyter Notebook pip3 install notebook install.packages(&quot;remotes&quot;)remotes::install_github('IRkernel/IRkernel')# Connect to Jupyter NotebookIRkernel::installspec()# 或者是在系统下安装IRkernel::installspec(user = FALSE) Enable Jupyter notebook remote (local) computer Lup Peng 2017 jupyter notebook --generate-configvim ./.jupyter/jupyter_notebook_config.py #------------------------------------------------------------------------------ # NotebookApp(JupyterApp) configuration #------------------------------------------------------------------------------ ... ## The IP address the notebook server will listen on. #c.NotebookApp.ip = 'localhost'+ c.NotebookApp.ip = '0.0.0.0' jupyter notebook password blast+ apt install blast2 Trinity-try dependency apt install cd autoconfapt install cd automake # download the trinity. I used the mirror which is more stable in Chinawget -c https://github.com.cnpmjs.org/trinityrnaseq/trinityrnaseq/releases/download/v2.12.0/trinityrnaseq-v2.12.0.FULL.tar.gztar -zxvf trinityrnaseq-v2.12.0.FULL.tar.gzcd trinityrnaseq-v2.12.0make problem Err:1 https://termux.org/packages stable/main aarch64 m4 aarch64 1.4.18-3 OpenSSL SSL_connect: SSL_ERROR_SYSCALL in connection to termux.org:443 Err:2 https://termux.org/packages stable/main aarch64 autoconf all 2.71 OpenSSL SSL_connect: SSL_ERROR_SYSCALL in connection to termux.org:443 Unable to correct missing packages. E: Failed to fetch https://termux.org/packages/pool/main/m/m4/m4_1.4.18-3_aarch64.deb OpenSSL SSL_connect: SSL_ERROR_SYSCALL in connection to termux.org:443 E: Failed to fetch https://termux.org/packages/pool/main/a/autoconf/autoconf_2.71_all.deb OpenSSL SSL_connect: SSL_ERROR_SYSCALL in connection to termux.org:443 E: Aborting install. Reason: failed to connect the github Set a proxy / VPN During make cannot find required auxiliary files: config.guess config.sub apt install automakevim /data/data/com.termux/files/home/Biosoft/trinityrnaseq-v2.11.0/trinity-plugins/bamsifter/build_htslib.sh set -e -vcd htslibautomake -amkdir -p buildautoheaderautoconf./configure --prefix=`pwd`/build/makemake install error: /bin/sh checking host system type... Invalid configuration `unknown-Linux': machine `unknown' not recognized configure: error: /bin/sh ./config.sub unknown-Linux failed sed -i 's=CONFIG_SHELL-/bin/sh=CONFIG_SHELL-/data/data/com.termux/files/usr/bin/sh=' /data/data/com.termux/files/home/Biosoft/trinityrnaseq-v2.11.0/trinity-plugins/bamsifter/htslib/configure | grep &quot;/bin/sh&quot; Github issue curl -O http://ftp.gnu.org/gnu/autoconf/autoconf-2.69.tar.gztar zxvf autoconf-2.70.tar.gzcd autoconf-2.70./configure &amp;&amp; make# add to pathsource ~/.bashrcexport PATH=$PATH:/data/data/com.termux/files/home/Softwarw/autoconf-2.70/bin#:wq! exitsource ~/.bashrc module Autom4te::ChannelDefs Can't locate Autom4te/ChannelDefs.pm in @INC (you may need to install the Autom4te::ChannelDefs module) (@INC contains: /usr/local/share/autoconf /data/data/com.termux/files/usr/lib/perl5/site_perl/5.30.0/aarch64-android /data/data/com.termux/files/usr/lib/perl5/site_perl/5.30.0 /data/data/com.termux/files/usr/lib/perl5/5.30.0/aarch64-android /data/data/com.termux/files/usr/lib/perl5/5.30.0 .) at /data/data/com.termux/files/home/Softwarw/autoconf-2.69/bin/autoheader line 41. Problem: lack of perl modules By perldoc perllocal We can find the module was in /data/data/com.termux/files/usr/lib/perl5/site_perl/5.30.0 directory Wed May 12 15:19:24 2021: \"Module\" Test::Warnings * \"installed into: /data/data/com.termux/files/usr/lib/perl5/site_perl/5.30.0\" * \"LINKTYPE: dynamic\" * \"VERSION: 0.030\" * \"EXE_FILES: \" Wed May 12 15:19:26 2021: \"Module\" File::Slurper So, we can make the soft link ln -s /data/data/com.termux/files/home/Softwarw/autoconf-2.70/lib/Autom4te /data/data/com.termux/files/usr/lib/perl5/site_perl/5.30.0/Autom4te /usr/local/bin/ cd bamsifter && make make[2]: Entering directory '/data/data/com.termux/files/home/Biosoft/trinityrnaseq-v2.12.0/trinity-plugins/bamsifter' ./build_htslib.sh cd htslib mkdir -p build autoheader sh: 1: /usr/local/bin/autom4te: not found autoheader: '/usr/local/bin/autom4te' failed with exit status: 127 make[2]: *** [Makefile:10: htslib/version.h] Error 127 /data/data/com.termux/files/home/Biosoft/trinityrnaseq-v2.12.0/trinity-plugins/bamsifter/build_htslib.sh Problem: in ‘./trinity-plugins/bamsifter/htslib/Makefile’ file, it assigned the prefix = /usr/local - prefix = /usr/local+ prefix = /data/data/com.termux/files/usr/exec_prefix = $(prefix)bindir = $(exec_prefix)/bin...- $ENV{'SHELL'} = '/bin/sh' if ($^O eq 'dos');- $ENV{'SHELL'} = '/data/data/com.termux/files/usr/bin/sh' if ($^O eq 'dos'); /data/data/com.termux/files/home/Softwarw/autoconf-2.70/bin/autoheader This error actually comes form autoheader file: my $autom4te = $ENV{'AUTOM4TE'} || '/usr/local/bin/autom4te'; We need to change it into: my $autom4te = $ENV{'AUTOM4TE'} || '/data/data/com.termux/files/home/Softwarw/autoconf-2.70/bin/autom4te' sed -i 's=/usr/local/bin/autom4te=/data/data/com.termux/files/home/Softwarw/autoconf-2.70/bin/autom4te=' /data/data/com.termux/files/home/Softwarw/autoconf-2.70/bin/autoheader|grep &quot;{'AUTOM4TE'}&quot; cd htslib mkdir -p build autoheader autom4te: cannot open < /usr/local/share/autoconf/autom4te.cfg: No such file or directory autoheader: '/data/data/com.termux/files/home/Softwarw/autoconf-2.69/bin/autom4te' failed with e /data/data/com.termux/files/home/Softwarw/autoconf-2.69/bin/autom4te - my $pkgdatadir = $ENV{'autom4te_perllibdir'} || '/usr/local/share/autoconf';+ my $pkgdatadir = $ENV{'autom4te_perllibdir'} || '/data/data/com.termux/files/home/Softwarw/autoconf-2.69/lib/'; cd htslib mkdir -p build autoheader autom4te: m4sugar/m4sugar.m4: no such file or directory /data/data/com.termux/files/home/Softwarw/autoconf-2.69/bin/autom4te - my $pkgdatadir = $ENV{'AC_MACRODIR'} || '/usr/local/share/autoconf';+ my $pkgdatadir = $ENV{'AC_MACRODIR'} || '/data/data/com.termux/files/home/Softwarw/autoconf-2.69/bin/'; autoheader autom4te: cannot open < /data/data/com.termux/files/home/Softwarw/autoconf-2.69/bin/autom4te.cfg: Not a directory autoheader: '/data/data/com.termux/files/home/Softwarw/autoconf-2.69/bin/autom4te' failed with exit status: 1 mak /data/data/com.termux/files/home/Softwarw/autoconf-2.69/bin/autom4te - load_configuration ($ENV{'AUTOM4TE_CFG'} || &quot;$pkgdatadir/autom4te.cfg&quot;);+ load_configuration ($ENV{'AUTOM4TE_CFG'} || &quot;/data/data/com.termux/files/home/Softwarw/autoconf-2.69/lib/autom4te.cfg&quot;); autom4te.cfg autoheader autom4te: error: cannot open /usr/local/share/autoconf/autom4te.cfg: No such file or directory sed -i 's=/usr/local/share/autoconf=/data/data/com.termux/files/home/Softwarw/autoconf-2.70/lib=' /data/data/com.termux/files/home/Softwarw/autoconf-2.70/bin/autom4te |grep &quot;/data/data/com.&quot; ‘s=/usr/local/share/autoconf=/data/data/com.termux/files/home/Softwarw/autoconf-2.69/lib=’ I finally installed 2.71 perl doesn’t support multithreads ./Configure -des -Dprefix=/data/data/com.termux/files/usr/local/perl -Dusethreads -Uinstalluserbinperl R apt install r-base miniconda # download minicondawget -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/Miniconda3-py39_4.9.2-Linux-x86_64.sh # blast+apt install blast2 bowtie bowtie2 Hexo Reference: 便当的梅开四度 # update first or you'll got errorpkg upgrade &amp;&amp; pkg update# hexo is based on the nodejspkg install nodejs","link":"/2021/05/19/Linux/Termux/"},{"title":"How to copy files in linux faster than cp","text":"How to copy files in linux faster than cp Tar pipe install the pv: sudo apt install pv tar cf - . | (cd /dst; tar xvf -)[1] time tar cf - Mutation/Raw_VCF | (cd /media/Side/ken/; tar xvf -) tar cf - Mutation/Raw_VCF 2.04s user 21.44s system 18% cpu 2:06.94 total ( cd /dst; tar xvf -; ) 1.33s user 32.93s system 26% cpu 2:06.94 total It only takes 2 minutes compared 12 minutes by cp. Another commands such as pv can help you too, to monitor the progress of a copy between two directories, for example: tar cf - . | pv | (cd /dst; tar xf -) gcp Only works for git repository. gcp -rv ~/Music/* /data/music/ [1:1] pre { background-color:#38393d; color: #5fd381; } Cesar Capillas, 2017: How to copy files in linux faster and safer than cp ↩︎ ↩︎","link":"/2022/09/14/Linux/cp/"},{"title":"ImageMagick: convert","text":"Documentation: imagemagick.org The convert command in Linux is a part of the ImageMagick suite, a powerful toolset for image manipulation. This command allows you to convert between different image formats, resize images, change image quality, and perform a wide variety of other image transformations. Here are a few basic examples of what you can do with the convert command: Converting an Image Format: To convert a JPEG image to a PNG, you would use: convert image.jpg image.png Resizing an Image: To resize an image to a specific width and height (e.g., 100x100 pixels), you can use: # based on the pixel of x*y convert original.jpg -resize 100x100 resized.jpg# based on the ratio convert original.jpg -resize 30% reduced.jpg# based on the ratio of x*yconvert original.jpg -resize 50%x30% reduced.jpg Changing Image Quality: To change the quality of a JPEG image, useful for reducing file size, use: convert original.jpg -quality 85 compressed.jpg Combining Multiple Images: To combine multiple images into one, for instance, side by side: convert image1.jpg image2.jpg +append combined.jpg Converting a PDF to an Image: To convert a PDF file to a series of images, you can use: convert document.pdf document.png Creating an Animated GIF: To create an animated GIF from a series of images: convert -delay 20 -loop 0 frame1.png frame2.png frame3.png animated.gif These examples are just the tip of the iceberg in terms of what ImageMagick’s convert command can do. It’s a very powerful tool with a wide array of options and capabilities. For more detailed information, you can check the manual page (man convert) or the official ImageMagick documentation. Other Functions You May Want to Know Certainly! Here are examples demonstrating various capabilities of ImageMagick: Image Composition: Overlay one image on top of another (watermark): convert background.jpg watermark.png -gravity center -composite output.jpg Color Manipulation: Convert an image to grayscale: convert original.jpg -colorspace Gray grayscale.jpg Cropping: Crop an image to a 100x100 pixel square starting at (50,50): convert original.jpg -crop 100x100+50+50 cropped.jpg Rotating and Flipping: Rotate an image by 90 degrees: convert original.jpg -rotate 90 rotated.jpg Blurring and Sharpening: Apply a Gaussian blur: convert original.jpg -blur 0x8 blurred.jpg Drawing: Draw a red rectangle: convert original.jpg -fill none -stroke red -draw &quot;rectangle 10,10 50,50&quot; output.jpg Format Conversion: Convert an image to a different format (e.g., PNG to GIF): convert image.png image.gif Handling Transparency: Make the white background of an image transparent: convert original.jpg -transparent white output.png Image Annotation: Add text to an image: convert original.jpg -pointsize 24 -fill black -annotate +50+50 'Sample Text' output.jpg Special Effects: Add a shadow to an image: convert original.jpg \\( +clone -background black -shadow 60x5+10+10 \\) +swap -background none -layers merge +repage shadow.jpg Image Optimization: Optimize an image for the web (reduce file size): convert original.jpg -strip -interlace Plane -gaussian-blur 0.05 -quality 85% optimized.jpg Batch Processing: Resize all PNG images in a directory (example in a bash loop): for img in *.png; do convert &quot;$img&quot; -resize 50% &quot;resized_$img&quot;; done Image Analysis: Get image information (format, dimensions, etc.): identify -verbose image.jpg Creating Thumbnails: Generate a thumbnail: convert original.jpg -thumbnail 100x100 thumbnail.jpg Morphing and Transforming: Morph between two images: convert image1.jpg image2.jpg -morph 10 morph_output.jpg These commands showcase the versatility of ImageMagick. Remember to adjust the file names and parameters according to your specific needs. The ImageMagick documentation provides more detailed information and examples for these and other features. pre { background-color:#38393d; color: #5fd381; }","link":"/2023/12/25/Linux/convert/"},{"title":"ffmpeg","text":"Mp4 ffmpeg -re -i &quot;1.mp4&quot; -vcodec copy -acodec aac -b:a 192k -f flv &quot;你的rtmp地址/你的直播码&quot; Camera sudo raspivid -o - -t 0 -w 1280 -h 720 -fps 24 -b 1000000 | ffmpeg -f h264 -i - -vcodec copy -acodec aac -b:a 192k \\ \\\\\\-f flv &quot;你的rtmp地址/你的直播码&quot; Add an audio sudo raspivid -o - -t 0 -w 1280 -h 720 -fps 24 -b 1000000 | ffmpeg -re -stream_loop -1 -i &quot;/home/pi/scrpt/Blive/StarBucks_BGN.mp3&quot; \\ -f h264 -i - -vcodec copy -r 30 -acodec aac -b:a 100k -preset ultrafast \\ -tune zerolatency -f flv &quot;rtmp://&quot; Camera＆ Mircrophone ## https://blog.csdn.net/word_joke/article/details/96978138ffmpeg -f dshow -i video=&quot;USB2.0 PC CAMERA&quot; -f dshow -i audio=&quot;麦克风 (2- USB2.0 MIC)&quot; -vcodec libx264 -preset:v ultrafast -tune:v zerolatency -f flv rtmp://127.0.0.1:1935/live/123## https://blog.csdn.net/HuiShouDeZaiLai/article/details/97373878ffmpeg -f alsa -thread_queue_size 1024 -i &quot;$MIC_DEV_NAME&quot; \\ -f video4linux2 -r 10 -s 640x480 -i &quot;$CAMERA_DEV_NAME&quot; \\ -vcodec h264 -ac 1 -b:a 128k -ar 44100 -acodec aac \\ -strict -2 -tune zerolatency -preset medium -b:v 1500k -f pcm \\ -f flv rtmp://XXX:1935/live/livestream 拉流 ##https://blog.csdn.net/hdg745979749/article/details/103000160ffmpeg -i rtmp://58.200.131.2:1935/livetv/hunantv -c copy dump.flv## 地址为 湖南卫视## 可直接下载保存为flv 视频 American SCCTV: rtmp://media3.scctv.net/live/scctv_800 Video Editer ffmpeg -i test.MP4 \\ -r 30 -b 1000k -s &quot;1920*1080&quot; \\ -an output.mp4 -i: Input Video -r: Frame -b: bit rate for video -s: size for each frame -an: mute video Crop the Video This example, we could crop the Video, Zoom in, and finally fit it in an new size of the video ffmpeg -i test.avi -vf &quot;crop=300:300:814:396,scale=1080:1080,scale=-1:1080,pad=1920:1080:(1920-iw)/2:0:black&quot; -acodec aac -vcodec h264 out.mp4 -i: Input video -vf: filter graph, Different kinds of filter you can do with your video. crop: crop peremeter: width:height❌y. The x and y means the left up point you started to crop the video. All units are work as pixels. scale: rescale the image. Here is from 300 to 1080. pad: Not very clear. It seams like adding an black pad on the backgorund. We can use this feature to turn vertical-laied video into horizontal-laied video and filld with black in empty. ffmpeg -i VideoBefore.mp4 -i MainVideo.mp4 -i VideoAfter.mp4 -i Audio.mp3 -filter_complex [1:v]scale=-2:480,setsar=sar=1[Scaled];[0:v][Scaled][2:v]concat=n=3:v=1:a=0[Merged] -map [Merged] -map 3:a OUTPUT.mp4MOVE1=/mnt/8A26661926660713/Vlog/PubData/Courtship/hyper/movie1/movie1.mp4MOVE2=/mnt/8A26661926660713/Vlog/PubData/Courtship/hyper/movie2/movie2.mp4MOVE3=/mnt/8A26661926660713/Vlog/PubData/Courtship/hyper/movie3/movie3.mp4MOVE4=/mnt/8A26661926660713/Vlog/PubData/Courtship/hyper/movie4/movie4.mp4ffmpeg -i $MOVE1 -i $MOVE2 -i $MOVE3 -i $MOVE4 -filter_complex &quot;[1:v]scale=-2:480,setsar=sar=1[Scaled];[0:v][Scaled][2:v]concat=n=3:v=1:a=0[Merged]&quot; -map &quot;[Merged]&quot; -map 3:a OUTPUT.mp4ffmpeg -i $MOVE1 -i $MOVE2 -i $MOVE3 -i $MOVE4 \\-f lavfi -t 0.1 -i anullsrc \\-filter_complex \\ &quot;[0:v]trim=0:138,setpts=PTS-STARTPTS[v0]; \\ [0:a]atrim=0:138,asetpts=PTS-STARTPTS[a0]; \\ [v0]scale='gte(iw/ih\\,600/480)*600+lt(iw/ih\\,600/480)*((480*iw)/ih):lte(iw/ih\\,600/480)*480+gt(iw/ih\\,600/480)*((600*ih)/iw)',pad='600:480:(600-gte(iw/ih\\,600/480)*600-lt(iw/ih\\,600/480)*((480*iw)/ih))/2:(480-lte(iw/ih\\,600/480)*480-gt(iw/ih\\,600/480)*((600*ih)/iw))/2:black'[x];[1:v]scale=600:480[y];[x][y]overlay=0:0[z];[2:v]scale=600:480,setsar=1:1[x0];[3:v]scale=600:480,setsar=1:1[x1];[x0][4:a][z][a0][x1][4:a]concat=n=3:v=1:a=1[v][a]&quot; -map &quot;[v]&quot; -map &quot;[a]&quot; -c:v libx264 -shortest out.mp4ffmpeg -y -i $MOVE1 -i $MOVE2 -filter_complex &quot;[0]scale=90:90;[1]scale=90:90;[0:0][1:0]concat=n=2:v=1:a=0&quot; output.mp4ffmpeg -y -i $MOVE1 -i $MOVE2 -filter_complex &quot;[0]scale=720:576:force_original_aspect_ratio=decrease,pad=720:576:(ow-iw)/2:(oh-ih)/2,setsar=1[v0];[1]scale=720:576:force_original_aspect_ratio=decrease,pad=720:576:(ow-iw)/2:(oh-ih)/2,setsar=1[v1];[v0][0:a:0][v1][1:a:0]concat=n=2:v=1:a=1[v][a]&quot; -map &quot;[v]&quot; -map &quot;[a]&quot; out.mp4","link":"/2020/06/23/Linux/ffmpeg/"},{"title":"github","text":"github Github 本地上更新库 ## Initialize your directorygit init## 关联git remote add IO https://github.com/Karobben/Karobben.github.io##添加git add .##注释git commit -m &quot;注释&quot;git pull --rebase IO mastergit push -u IO master Avoid password everytime Click me when uploading file is to big git config http.postBuffer 524288000 ignore files Cite: Git-scm the name of the file: .gitignore should keep in the home directory rather than the .git directory $ cat .gitignore# exclude everything except directory foo/bar/*!/foo/foo/*!/foo/bar An optional prefix “!” which negates the pattern; any matching file excluded by a previous pattern will become included again. It is not possible to re-include a file if a parent directory of that file is excluded. An asterisk “*” matches anything except a slash. A trailing “/&quot; matches everything inside. For example, &quot;abc/” matches all files inside directory “abc”, relative to the location of the .gitignore file, with infinite depth. A slash followed by two consecutive asterisks then a slash matches zero or more directories. For example, “a/**/b” matches “a/b”, “a/x/b”, “a/x/y/b” and so on. Delete large files © Daniel Andrei Mincă; 2015 $ git rm --cached giant_file# Stage our giant file for removal, but leave it on diskgit commit --amend -CHEAD# Amend the previous commit with your change# Simply making a new commit won't work, as you need# to remove the file from the unpushed history as wellgit push# Push our rewritten, smaller commit Another way to solve the same problem © Clark McCauley; 2022 git filter-branch --index-filter 'git rm -r --cached --ignore-unmatch &lt;file/dir&gt;' HEAD Git push with ssh Documentation: Github Follow the instructions from Github to generate a ssh public key first. Be sure about add the email for config the user Exp: ssh-keygen -t ed25519 -C &quot;your_email@example.com&quot;ssh-add ~/.ssh/id_ed25519cat ~/.ssh/id_ed25519 After that, copy the key into github. You may still find that Username is needed for push. According 2240, we need to change the type or remote link. Test Your Connection Once you down, you could test the ssh connections with ssh -T git@github.com. If it works fine, you’ll get the greating form GitHub: Hi Karobben! You've successfully authenticated, but GitHub does not provide shell access. If you are running on another environment, you’ll get a warning. But it would be fine, just input yes would solve all problems. Warning: the ECDSA host key for 'github.com' differs from the key for the IP address '140.82.114.3' Offending key for IP in /home/ken/.ssh/known_hosts:9 Matching host key in /home/ken/.ssh/known_hosts:69 Are you sure you want to continue connecting (yes/no)? Ready Your Local Repository Enter your github repository page and select the ssh link to configure the local repository as follow and the problem shell be solved. git remote set-url origin git@github.com:username/repo.git Re-base the Local by Deleting all Local Change git stashgit pull Reference: Cameron McKenzie The git stash command, which saves uncommitted changes and reset your workspace. The git reset command, which only touches tracked files. The git clean command, that deletes every untracked file. Errors fatal: in unpopulated submodule ‘.deploy_git’ fatal: in unpopulated submodule '.deploy_git' FATAL { err: { Error: Spawn failed at ChildProcess.task.on.code (/mnt/8A26661926660713/Github/Notes_BK/node_modules/hexo-util/lib/spawn.js:51:21) at ChildProcess.emit (events.js:198:13) at Process.ChildProcess._handle.onexit (internal/child_process.js:248:12) code: 128 } } 'Something\\'s wrong. Maybe you can find the solution here: %s' '\\u001b[4mhttps://hexo.io/docs/troubleshooting.html\\u001b[24m' According to ChatGPT (this is a super genius! I can’t find this result anywhere!) The error message you provided is related to Hexo, a static site generator. It seems that there was an issue with a submodule named ‘.deploy_git’ in the Git repository you were working with. This error occurs when there’s a problem with the Git submodule in your Hexo project, and it’s not able to be cloned. To resolve this issue, try the following steps: # Remove the problematic submodule:git rm --cached .deploy_git# Commit the changes:git commit -m &quot;Removed problematic submodule&quot;# Re-add the submodule:# Replace &lt;repo&gt; with the URL of the Git repository for the submodule.git submodule add -b master &lt;repo&gt; .deploy_git# Initialize the submodule:git submodule init# Update the submodule:git submodule update These steps should resolve the issue with the Git submodule and allow you to continue using Hexo to generate your static site. If the issue persists, you may need to refer to the Hexo troubleshooting guide (https://hexo.io/docs/troubleshooting.html) for further assistance. pre { background-color:#38393d; color: #5fd381; } Submodule In github, you could add entire another repository here with submodule: git submodule add git@github.com:Karobben/20240501_PacBio_lib_assmb_screening.git How to remove the submodule? To remove a submodule from a Git repository, you’ll need to follow a series of steps to cleanly remove all traces of the submodule from your repository. Here’s how to do it: 1. Deinitialize the Submodule First, you need to deinitialize the submodule to remove its configuration. Run the following command: git submodule deinit -f path/to/submodule Replace path/to/submodule with the actual path to the submodule. 2. Remove the Submodule from the .gitmodules File The .gitmodules file in the root of your repository contains the configuration for all submodules. You need to remove the corresponding entry of the submodule you want to delete. Open the .gitmodules file in a text editor and remove the section corresponding to the submodule. It will look something like this: [submodule &quot;path/to/submodule&quot;] path = path/to/submodule url = https://github.com/user/repo.git Save and close the file after removing the relevant section. 3. Remove the Submodule Directory from the Working Tree After removing the entry from .gitmodules, you can remove the submodule directory from your working tree: rm -rf path/to/submodule 4. Remove the Submodule from the Git Index Finally, you need to remove the submodule from the Git index (staging area). Run the following command: git rm -f path/to/submodule This command will remove the submodule from your repository’s index, which means it will be removed in the next commit. 5. Commit the Changes Now that you’ve removed the submodule, commit the changes: git commit -m &quot;Remove submodule path/to/submodule&quot; 6. Remove the Submodule Directory from the Git Directory As an optional cleanup step, you can remove the submodule’s entry in the .git/config file and the submodule directory inside the .git folder. The commands below accomplish this: rm -rf .git/modules/path/to/submodule This sequence of commands will completely remove the submodule from your repository. If you push these changes to a remote repository, the submodule will also be removed from there. Branches Delete branch: git push origin --delete &lt;remote-branch-name&gt;","link":"/2020/06/23/Linux/github/"},{"title":"grep 搜索","text":"grep 搜索 grep##Usage: grep [OPTION]... PATTERN [FILE]...##Try 'grep --help' for more information. ** 1. 快速上手 ## 创建测试文件echo -e &quot;ab\\na\\nb\\nc\\nd\\ne\\nf\\ng\\nA\\nB\\nC&quot; &gt; test.txt## 搜索存在'a'的内容grep a test.txt 2. 常用 $gr ## &quot;.&quot;模糊匹配grep a. test.txt ## 显示所在行grep -n a test.txt ## 输出匹配次数(多少行)grep -c a test.txt ## 忽略大小写grep -i a test.txt ##多项匹配: &quot;|&quot; 分隔开多选必配项。注意，如果我没记错的话，最多可同时匹配1000项grep -E 'a|b' test.txt ##打印匹配项的上下一行或多行grep -nA 1 A test.txt # 等同于 grep -n -A 1 A test.txt， -n 用于显示行数grep -nB 1 A test.txt # 显示匹配的上一行grep -nA 1 -B 1 A test.txt # 同时显示匹配的上下两行 3. 快速应用： 抓取fasta序列：测试文件：test.fa.txt首先，把fasta文件规整成一行ID，一行序列格式。 ##通过一系列骚操作，把多行序列转换成单行cat test.fa.txt | tr '\\n' '#'| sed 's/#&gt;/\\n&gt;/g'|sed 's/#/\\n/;s/#//g' &gt; test.fa 3.1，获取所有的fasta ID grep &quot;&gt;&quot; test.fa 3.2，获取杠内ID grep &quot;&gt;&quot; test.fa| awk -F\\| '{print $2}' 3.3，通过grep 多项匹配，获取前两个ID及其序列 grep -EA 1 $(grep &quot;&gt;&quot; test.fa| awk -F\\| '{print $2}'|head -n 2| tr '\\n' '|'|sed 's/^/&quot;|/;s/$/&quot;/') test.fa##orgrep -EA 1 $(grep &quot;&gt;&quot; test.fa|\\awk -F\\| '{print $2}'|\\head -n 2|\\tr '\\n' '|'|\\sed 's/^/&quot;|/;s/$/&quot;/') test.fa'''其中，$(grep &quot;&gt;&quot; test.fa| awk -F\\| '{print $2}'|head -n 2| tr '\\n' '|'|sed 's/^/&quot;|/;s/$/&quot;/') 的结果为的结果为：&quot;|Q6GZX4|Q6GZX3|&quot;因此可以直接被 grep -E 参数识别''' 4. 其他详细请看： 参数解释：https://www.runoob.com/linux/linux-comm-grep.html复杂正则匹配：https://www.cnblogs.com/keithtt/p/6820540.html Multi-words/strings grep Shell can only 1000 args and if you exceeded it, you would end as error. For doing large number or words/strings match, we need to input words/strings in a file and grep it later. But the consuming time is raising largely after 1000. Number or words time 1000 0m1.954s 2000 0m4.825s 5000 0m26.232s Though, you can match thousands of words in a time, but you don’t have too or it doesn’t deserve it. In this time, a loop would much faster than single threads grep.","link":"/2020/06/26/Linux/grep/"},{"title":"How to set a static IP address for Linux","text":"How to set a static ip for Pop os Find Gateway and the DNS for your network Setting → Network → Check the details of your network. Here, Default Route is the Gateway, DNS is the DNS Find the Netmask for your network by ifconfig ifconfig eno1: flags=4163 mtu 1500 inet 192.168.3.1 netmask 255.255.255.0 broadcast 192.168.3.255 . . . fill them in IPv4 setting Fill the address you want and rest of other infor you jut get from above. || pre { background-color:#38393d; color: #5fd381; }","link":"/2023/01/31/Linux/linux-static-ip/"},{"title":"Blive with RasperryPi","text":"Blive with RasperryPi Reference: Bilibili: 五维谐振子 Qick Start sudo apt upgradesudo apt updatesudo apt install ffmpegsudo raspivid -o - -t 0 -w 1280 -h 720 -fps 24 -b 1000000 | ffmpeg -f h264 -i - -vcodec copy -acodec aac -b:a 192k -f flv &quot;你的rtmp地址/你的直播码&quot; 降低延迟: CSDN: 北雨南萍 sudo raspivid -o - -t 0 -w 1280 -h 720 -fps 24 -b 1000000 | ffmpeg -f h264 -i - -vcodec copy -r 30 -acodec aac -b:a 100k -preset ultrafast -tune zerolatency -f flv &quot;你的rtmp地址/你的直播码&quot; raspivid 树莓派实验室: Spoony &quot;raspivid&quot; Camera App (commit 06bc6daa0213 Tainted)Display camera output to display, and optionally saves an H264 capture at requested bitrateusage: raspivid [options]Image parameter commands-b, --bitrate : Set bitrate. Use bits per second (e.g. 10MBits/s would be -b 10000000)-t, --timeout : Time (in ms) to capture for. If not specified, set to 5s. Zero to disable-d, --demo : Run a demo mode (cycle through range of camera options, no capture)-fps, --framerate : Specify the frames per second to record-e, --penc : Display preview image *after* encoding (shows compression artifacts)-g, --intra : Specify the intra refresh period (key frame rate/GoP size). Zero to produce an initial I-frame and then just P-frames.-pf, --profile : Specify H264 profile to use for encoding-td, --timed : Cycle between capture and pause. -cycle on,off where on is record time and off is pause time in ms-s, --signal : Cycle between capture and pause on Signal-k, --keypress : Cycle between capture and pause on ENTER-i, --initial : Initial state. Use 'record' or 'pause'. Default 'record'-qp, --qp : Quantisation parameter. Use approximately 10-40. Default 0 (off)-ih, --inline : Insert inline headers (SPS, PPS) to stream-sg, --segment : Segment output file in to multiple files at specified interval &lt;ms&gt;-wr, --wrap : In segment mode, wrap any numbered filename back to 1 when reach number-sn, --start : In segment mode, start with specified segment number-sp, --split : In wait mode, create new output file for each start event-c, --circular : Run encoded data through circular buffer until triggered then save-x, --vectors : Output filename &lt;filename&gt; for inline motion vectors-if, --irefresh : Set intra refresh type-fl, --flush : Flush buffers in order to decrease latency-pts, --save-pts : Save Timestamps to file for mkvmerge-cd, --codec : Specify the codec to use - H264 (default) or MJPEG-lev, --level : Specify H264 level to use for encoding-r, --raw : Output filename &lt;filename&gt; for raw video-rf, --raw-format : Specify output format for raw video. Default is yuv-l, --listen : Listen on a TCP socket-stm, --spstimings : Add in h.264 sps timings-sl, --slices : Horizontal slices per frame. Default 1 (off)H264 Profile options :baseline,main,highH264 Level options :4,4.1,4.2H264 Intra refresh options :cyclic,adaptive,both,cyclicrowsRaw output format options :yuv,rgb,grayRaspivid allows output to a remote IPv4 host e.g. -o tcp://192.168.1.2:1234or -o udp://192.168.1.2:1234To listen on a TCP port (IPv4) and wait for an incoming connection use the -l optione.g. raspivid -l -o tcp://0.0.0.0:3333 -&gt; bind to all network interfaces,raspivid -l -o tcp://192.168.1.1:3333 -&gt; bind to a certain local IPv4 portCommon Settings commands-?, --help : This help information-w, --width : Set image width &lt;size&gt;-h, --height : Set image height &lt;size&gt;-o, --output : Output filename &lt;filename&gt; (to write to stdout, use '-o -'). If not specified, no file is saved-v, --verbose : Output verbose information during run-cs, --camselect : Select camera &lt;number&gt;. Default 0-md, --mode : Force sensor mode. 0=auto. See docs for other modes available-gps, --gpsdexif : Apply real-time GPS information to output (e.g. EXIF in JPG, annotation in video (requires libgps.so.23)Preview parameter commands-p, --preview : Preview window settings &lt;'x,y,w,h'&gt;-f, --fullscreen : Fullscreen preview mode-op, --opacity : Preview window opacity (0-255)-n, --nopreview : Do not display a preview window-dn, --dispnum : Display on which to display the preview window (dispmanx/tvservice numbering)Image parameter commands-sh, --sharpness : Set image sharpness (-100 to 100)-co, --contrast : Set image contrast (-100 to 100)-br, --brightness : Set image brightness (0 to 100)-sa, --saturation : Set image saturation (-100 to 100)-ISO, --ISO : Set capture ISO-vs, --vstab : Turn on video stabilisation-ev, --ev : Set EV compensation - steps of 1/6 stop-ex, --exposure : Set exposure mode (see Notes)-fli, --flicker : Set flicker avoid mode (see Notes)-awb, --awb : Set AWB mode (see Notes)-ifx, --imxfx : Set image effect (see Notes)-cfx, --colfx : Set colour effect (U:V)-mm, --metering : Set metering mode (see Notes)-rot, --rotation : Set image rotation (0-359)-hf, --hflip : Set horizontal flip-vf, --vflip : Set vertical flip-roi, --roi : Set region of interest (x,y,w,d as normalised coordinates [0.0-1.0])-ss, --shutter : Set shutter speed in microseconds-awbg, --awbgains : Set AWB gains - AWB mode must be off-drc, --drc : Set DRC Level (see Notes)-st, --stats : Force recomputation of statistics on stills capture pass-a, --annotate : Enable/Set annotate flags or text-3d, --stereo : Select stereoscopic mode-dec, --decimate : Half width/height of stereo image-3dswap, --3dswap : Swap camera order for stereoscopic-ae, --annotateex : Set extra annotation parameters (text size, text colour(hex YUV), bg colour(hex YUV), justify, x, y)-ag, --analoggain : Set the analog gain (floating point)-dg, --digitalgain : Set the digital gain (floating point)-set, --settings : Retrieve camera settings and write to stdout python + openCVC + ffmpeg more: CSDN: mind_programmonkey 基本框架 import cv2 as cvimport subprocess as sprtmpUrl = &quot;你的rtmp地址/你的直播码&quot;camera_path = &quot;/dev/video0&quot;cap = cv.VideoCapture(camera_path)## Get video informationfps = 30 #int(cap.get(cv.CAP_PROP_FPS))width = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))## ffmpeg commandcommand = ['ffmpeg', '-y', '-f', 'rawvideo', '-vcodec','rawvideo', '-pix_fmt', 'bgr24', '-s', &quot;{}x{}&quot;.format(width, height), '-r', str(fps), '-i', '-', '-c:v', 'libx264', '-pix_fmt', 'yuv420p', '-preset', 'ultrafast', '-f', 'flv', rtmpUrl]## 管道配置p = sp.Popen(command, stdin=sp.PIPE)## read webcamerawhile(cap.isOpened()): ret, frame = cap.read() if not ret: print(&quot;Opening camera is failed&quot;) break # process frame # your code # process frame # write to pipe p.stdin.write(frame.tostring())","link":"/2020/06/23/Linux/Blive-with-RasperryPi/"},{"title":"fancy tools in linux","text":"Fancy Tools for Linux User pre { background-color:#38393d; color: #5fd381; } Office IDE System Media Bioinformatic Office Documents, Sheets, Powerpoints WPS for Linux ONLYOFFICE snap shot for Gmonitor Document format convert Pandoc # HTML fragment:pandoc MANUAL.txt -o example1.html# Standalone HTML file:pandoc -s MANUAL.txt -o example2.html# HTML with table of contents, CSS, and custom footer:pandoc -s --toc -c pandoc.css -A footer.html MANUAL.txt -o example3.html# LaTeX:pandoc -s MANUAL.txt -o example4.tex IDE Vim © Real Python Atom © Seth Kenlon VScode snap shot for Gmonitor System Processes Monitor CPU and RAM top htop gtop gotop (favorite) GPU nvtop (favorite) gmonitor snap shot for Gmonitor Media Audio Play music in terminal sudo apt-get install soxsudo apt-get install sox libsox-fmt-allplay test.mp3 © Enock Seth Nyamador Video Print mate information of a Video mediainfo test.mp4 General Complete name : test.mp4 Format : MPEG-4 Format profile : Base Media Codec ID : isom (isom/iso2/avc1/mp41) File size : 131 MiB Duration : 18 min 10 s Overall bit rate : 1 004 kb/s Writing application : Lavf58.29.100 Video ID : 1 Format : AVC Format/Info : Advanced Video Codec Format profile : High@L4 Format settings : CABAC / 4 Ref Frames Format settings, CABAC : Yes Format settings, Reference frames : 4 frames Codec ID : avc1 Codec ID/Info : Advanced Video Coding Duration : 18 min 10 s Bit rate : 1 000 kb/s Width : 1 920 pixels Height : 1 080 pixels Display aspect ratio : 16:9 Frame rate mode : Constant Frame rate : 30.000 FPS Color space : YUV Chroma subsampling : 4:2:0 Bit depth : 8 bits Scan type : Progressive Bits/(Pixel*Frame) : 0.016 Stream size : 130 MiB (100%) Writing library : x264 core 155 r2917 0a84d98 Encoding settings : cabac=1 / ref=3 / deblock=1:0:0 / analyse=0x3:0x113 / me=hex / subme=7 / psy=1 / psy_rd=1.00:0.00 / mixed_ref=1 / me_range=16 / chroma_me=1 / trellis=1 / 8x8dct=1 / cqm=0 / deadzone=21,11 / fast_pskip=1 / chroma_qp_offset=-2 / threads=12 / lookahead_threads=2 / sliced_threads=0 / nr=0 / decimate=1 / interlaced=0 / bluray_compat=0 / constrained_intra=0 / bframes=3 / b_pyramid=2 / b_adapt=1 / b_bias=0 / direct=1 / weightb=1 / open_gop=0 / weightp=2 / keyint=250 / keyint_min=25 / scenecut=40 / intra_refresh=0 / rc_lookahead=40 / rc=abr / mbtree=1 / bitrate=1000 / ratetol=1.0 / qcomp=0.60 / qpmin=0 / qpmax=69 / qpstep=4 / ip_ratio=1.40 / aq=1:1.00 Codec configuration box : avcC ffmpeg: Crop; stream etc. Link ffmpeg accelerate with NVIDA GPU The most awesome thing is ffmpeg support GPU accelerating which could make video cropping much faster than traditional way. Kdenlive libmovit-devlibmovit8","link":"/2022/06/22/Linux/linux-tools/"},{"title":"Quick Guide of Mysql for Newbies","text":"Quick Guide of Mysql for Newbies Video tutorial Text Tutorial Dataabse type Relation Database Non-relational Database - Store specific types of project like customer, products.- Store as tables - No tables or relationships- Don’t understand SQL INSTALL For Ubuntu:雪梦科技 2020; 云栖社区, Mac: WebCoder 2016, 简书; Windows: BruceLong 2020; 博客园 Quick Start mysql -- print store locationshow variables like '%datadir%';-- print database in stoarageSHOW DATABASES;-- Create a new databaseCREATE DATABASE `sql_invoicing`;-- Access the databaseUSE `sql_invoicing`;-- Create a tableCREATE TABLE runoob_tbl( runoob_id INT NOT NULL AUTO_INCREMENT, runoob_title VARCHAR(100) NOT NULL, runoob_author VARCHAR(40) NOT NULL, submission_date DATE, PRIMARY KEY ( runoob_id ) )ENGINE=InnoDB DEFAULT CHARSET=utf8;-- show tablesSHOW TABLES-- Check the indexdesc runoob_tbl/*INT: datatype = integer;DATE: datatype = date;NOT NULL: value auto-fill;AUTO_INCREMENT: fill-logic;VARCHAR(10): ??? I don't know*/-- Insert value to tableINSERT INTO runoob_tbl (runoob_title, runoob_author, submission_date) VALUES (&quot;学习 PHP&quot;, &quot;菜鸟教程&quot;, NOW());-- Insert multi-lines value to tableINSERT INTO runoob_tbl (runoob_title, runoob_author, submission_date) VALUES (&quot;学习 myspl&quot;, &quot;karobben&quot;, NOW()), ('learn python', 'Karobben', NOW());-- Print the whole tableSELECT * from runoob_tbl;-- Print the `runoob_title` column(field)SELECT `runoob_title` from runoob_tbl;-- Print the filtered result by WHENSELECT * from runoob_tbl WHERE runoob_author='karobben'; #Capitals letters tolerantSELECT * from runoob_tbl WHERE BINARY runoob_author='Karobben'; #Capital letter matters-- Print the filtered result by LIKESELECT * from runoob_tbl WHERE runoob_author LIKE '%rob%';-- Change the value of tables by updateUPDATE runoob_tbl SET runoob_title='sleep' WHERE runoob_id=3;-- Change a part of string in column(field)UPDATE runoob_tbl SET runoob_author=REPLACE(runoob_author, 'ka', 'Ka')-- Change the value of table by deleteDELETE FROM runoob_tbl WHERE runoob_id=1;-- delete the taleDROP TABLE `runoob_tbl`;-- delete the databaseDROP DATABASE `sql_invoicing` Set Environment Change the store directory: 虫文儿~ 2019; 博客园 Show the directory of the DATABASE show variables like '%datadir%'; Show all databases SHOW DATABASES; Create &amp; Drop Database ps: ‘;’ is needed for separate commands in sql language. CREATE DATABASE IF NOT EXISTS `sql_invoicing`;USE `sql_invoicing`;SET NAMES utf8;SET character_set_client= utf8mb4;SHOW DATABASES; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sql_invoicing | | sys | +--------------------+ drop database `sql_invoicing`; #deleting sql_invoicing Table CREATE TABLE IF NOT EXISTS `runoob_tbl`( `runoob_id` INT UNSIGNED AUTO_INCREMENT, `runoob_title` VARCHAR(100) NOT NULL, `runoob_author` VARCHAR(40) NOT NULL, `submission_date` DATE, PRIMARY KEY ( `runoob_id` ))ENGINE=InnoDB DEFAULT CHARSET=utf8;SHOW TABLES;desc runoob_tbl; +-------------------------+ | Tables_in_sql_invoicing | +-------------------------+ | runoob_tbl | +-------------------------+ 1 row in set (0.00 sec) +-----------------+--------------+------+-----+---------+----------------+ | Field | Type | Null | Key | Default | Extra | +-----------------+--------------+------+-----+---------+----------------+ | runoob_id | int(11) | NO | PRI | NULL | auto_increment | | runoob_title | varchar(100) | NO | | NULL | | | runoob_author | varchar(40) | NO | | NULL | | | submission_date | date | YES | | NULL | | +-----------------+--------------+------+-----+---------+----------------+ 4 rows in set (0.00 sec) DROP TABLE runoob_tbl; Datatypes Details: runoob.com INSERT Insert a Row -- Insert value to tableINSERT INTO runoob_tbl (runoob_title, runoob_author, submission_date) VALUES (&quot;学习 PHP&quot;, &quot;菜鸟教程&quot;, NOW());-- Insert multi-lines value to tableINSERT INTO runoob_tbl (runoob_title, runoob_author, submission_date) VALUES (&quot;学习 myspl&quot;, &quot;karobben&quot;, NOW()), ('learn python', 'Karobben', NOW()); ALTER (insert a column) ALTER TABLE runoob_tblADD COLUMN Citation VARCHAR(15) AFTER runoob_author; Select the column WHERE SELECT * from runoob_tbl WHERE runoob_author='karobben'; +-----------+--------------+---------------+-----------------+ | runoob_id | runoob_title | runoob_author | submission_date | +-----------+--------------+---------------+-----------------+ | 2 | 学习 myspl | Karobben | 2021-01-31 | | 3 | sleep | Karobben | 2021-01-31 | | 4 | learn python | Karobben | 2021-01-31 | +-----------+--------------+---------------+-----------------+ 3 rows in set (0.00 sec) LIKE -- match the column which end with a| grep a$'%a' -- match the column which start with a| grep ^a'a%' -- match the column which contain a| grep a'%a%' -- match pattern: grep ^.a.$'_a_' -- match pattern: grep ^.a$'_a'-- match pattern: grep ^a$'a_'SELECT * from runoob_tbl WHERE runoob_title LIKE '% %'; +-----------+--------------+---------------+-----------------+ | runoob_id | runoob_title | runoob_author | submission_date | +-----------+--------------+---------------+-----------------+ | 2 | 学习 myspl | Karobben | 2021-01-31 | | 4 | learn python | Karobben | 2021-01-31 | +-----------+--------------+---------------+-----------------+ 2 rows in set (0.00 sec) UPDATE &amp; DELETE UPDATE runoob_tbl SET runoob_title='学习 C++' WHERE runoob_id=3;DELETE FROM runoob_tbl WHERE runoob_id=3; UNION So, union could combine the unique values from different selected columns to a new table sql SELECT runoob_title FROM runoob_tbl UNION SELECT runoob_author FROM runoob_tbl; +--------------+ | runoob_title | +--------------+ | 学习 myspl | | sleep | | learn python | | Karobben | +--------------+ it can also be used to merge tables: Example ORDER SELECT * from runoob_tbl;SELECT * from runoob_tbl ORDER BY runoob_title ASC; +-----------+--------------+---------------+-----------------+ | runoob_id | runoob_title | runoob_author | submission_date | +-----------+--------------+---------------+-----------------+ | 2 | 学习 myspl | Karobben | 2021-01-31 | | 3 | sleep | Karobben | 2021-01-31 | | 4 | learn python | Karobben | 2021-01-31 | +-----------+--------------+---------------+-----------------+ +-----------+--------------+---------------+-----------------+ | runoob_id | runoob_title | runoob_author | submission_date | +-----------+--------------+---------------+-----------------+ | 4 | learn python | Karobben | 2021-01-31 | | 3 | sleep | Karobben | 2021-01-31 | | 2 | 学习 myspl | Karobben | 2021-01-31 | +-----------+--------------+---------------+-----------------+ INPUT and Output Input -- insert and replaceLOAD DATA INFILE '/var/lib/mysql-files/test.csv' REPLACEINTO TABLE regulation_netFIELDS TERMINATED BY ','OPTIONALLY ENCLOSED BY '&quot;'LINES TERMINATED BY '\\n';IGNORE 1 ROWS; output ## output sql as txt filemysqldump -h other-host.com -P port -u root -p database_name &gt; dump.txt -- output as csvSELECT * FROM regulation_net;SELECT * INTO OUTFILE '/var/lib/mysql-files/test.csv'FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '&quot;'LINES TERMINATED BY '\\n'FROM regulation_net;","link":"/2021/01/31/Linux/mysql/"},{"title":"Using Vim as Python and R IDE","text":"Using Vim as IDE Vim is a classic text editor known for efficiency, while NeoVim is its modernized fork with improvements like better plugin support. LunarVim, built on NeoVim, offers a pre-configured setup, making it easier for users to get a powerful, feature-rich environment without the hassle of individual configurations. Ideal for those new to Vim/NeoVim or seeking a ready-to-use development setup, LunarVim combines ease of setup with customizability. It’s particularly appealing for its integrated toolset, active community support, and a balance between functionality and performance, making it a great choice for a streamlined coding experience. Plug: Nvim-R Video Tutorial: Rohit Farmer Instruction following the video: rohitfarmer Final work: © Karobben Installation Please install the latest NeoVim by following the Neovim document and LunarVim Document # install neovim# sudo apt install neovim# install vim-plugcurl -fLo ~/.local/share/nvim/site/autoload/plug.vim --create-dirs \\ https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim# for storing the config filemkdir ~/.config/nvimtouch ~/.config/nvim/init.vim# for storing plug# because all plug would be installed by here, you could just delete the directories here to delete plugs.mkdir ~/.vim/plugged# open and edit the config filevim ~/.config/nvim/init.vim Save the lines below in the ~/.config/nvim/init.vim file to install the pluges. \" Specify a directory for plugins \" - Avoid using standard Vim directory names like 'plugin' call plug#begin('~/.vim/plugged') \" List of plugins. \" Make sure you use single quotes \" Shorthand notation Plug 'jalvesaq/Nvim-R', { 'branch' : 'stable' } Plug 'ncm2/ncm2' Plug 'roxma/nvim-yarp' Plug 'gaalcaras/ncm-R' Plug 'preservim/nerdtree' Plug 'Raimondi/delimitMate' Plug 'patstockwell/vim-monokai-tasty' Plug 'itchyny/lightline.vim' \" Initialize plugin system call plug#end() How to instsall the plunges After stored the change, you need to open it again by using nvim ~/.config/nvim/init.vim. And then, under the command model (which is triggered by :), input PlugInstall (PlugUpdate if you want to update them). After you see the picture below which means you installed it successfully: By following the instruction from rohitfarmer’s post, we could add more things at the end of the init.vim file: folding behavior \" Set foldbehavior set tabstop=2 &quot; Number of spaces that a in the file counts for set shiftwidth=2 &quot; Number of spaces to use for each step of (auto)indent set softtabstop=2 &quot; Number of spaces that a counts for while performing editing operations set expandtab &quot; Use spaces instead of tabs set foldmethod=indent set foldlevelstart=2 &quot; Start folding at an indent level greater than 2 For quick unfold all codes: :set nofoldenable \" Set a Local Leader \" With a map leader it's possible to do extra key combinations \" like w saves the current file let mapleader = \",\" let g:mapleader = \",\" \" Plugin Related Settings \" NCM2 autocmd BufEnter * call ncm2#enable_for_buffer() \" To enable ncm2 for all buffers. set completeopt=noinsert,menuone,noselect \" :help Ncm2PopupOpen for more \" information. \" NERD Tree map nn :NERDTreeToggle \" Toggle NERD tree. \" Monokai-tasty let g:vim_monokai_tasty_italic = 1 \" Allow italics. colorscheme vim-monokai-tasty \" Enable monokai theme. \" LightLine.vim set laststatus=2 \" To tell Vim we want to see the statusline. let g:lightline = { \\ 'colorscheme':'monokai_tasty', \\ } \" General NVIM/VIM Settings \" Mouse Integration set mouse=i \" Enable mouse support in insert mode. \" Tabs & Navigation map nt :tabnew \" To create a new tab. map to :tabonly \" To close all other tabs (show only the current tab). map tc :tabclose \" To close the current tab. map tm :tabmove \" To move the current tab to next position. map tn :tabn \" To swtich to next tab. map tp :tabp \" To switch to previous tab. \" Line Numbers & Indentation set backspace=indent,eol,start \" To make backscape work in all conditions. set ma \" To set mark a at current cursor location. set number \" To switch the line numbers on. set expandtab \" To enter spaces when tab is pressed. set smarttab \" To use smart tabs. set autoindent \" To copy indentation from current line \" when starting a new line. set si \" To switch on smart indentation. \" Search set ignorecase \" To ignore case when searching. set smartcase \" When searching try to be smart about cases. set hlsearch \" To highlight search results. set incsearch \" To make search act like search in modern browsers. set magic \" For regular expressions turn magic on. \" Brackets set showmatch \" To show matching brackets when text indicator \" is over them. set mat=2 \" How many tenths of a second to blink \" when matching brackets. \" Errors set noerrorbells \" No annoying sound on errors. \" Color & Fonts syntax enable \" Enable syntax highlighting. set encoding=utf8 \" Set utf8 as standard encoding and \" en_US as the standard language. \" Enable 256 colors palette in Gnome Terminal. if $COLORTERM == 'gnome-terminal' set t_Co=256 endif try colorscheme desert catch endtry \" Files & Backup set nobackup \" Turn off backup. set nowb \" Don't backup before overwriting a file. set noswapfile \" Don't create a swap file. set ffs=unix,dos,mac \" Use Unix as the standard file type. \" Return to last edit position when opening files au BufReadPost * if line(\"'\\\"\") > 1 && line(\"'\\\"\")","link":"/2024/01/03/Linux/nvimr/"},{"title":"sed 匹配编辑","text":"sed 匹配编辑 Sed substitute ## substitute the first 't' to 'T'sed 's/t/T/' file## substitute all 't' to 'T'sed 's/t/T/g' file## substitute 'all little letters' to 'T'sed 's/[a-z]/T/g' file## similarly, you can substitute 'all numbers' to 'T'sed 's/[0-9]/T/g' File Deleted matched line sed '/pattern/d' filenamesed '1d' filename # deleted the first line onlysed '2d' filename # deleted the second line only Adding a line ## adding a line before the matched linesed -i '/allow chengyongxu.com/i\\allow chengyongxu.cn' file## adding a line after the matched linesed -i '/allow chengyongxu.com/a\\allow chengyongxu.cn' file Match pattern Pattern Meanings Example Result ^ The begin of each line sed '/^A/d' file Delete all lines which begin with ‘A’ $ The end of each line sed 's/$/+/' file Add a ‘+’ at the end of all lines [ ] match all single elements in it sed 's/[abcd]/T/g' file Replace all ‘a’, ‘b’, ‘c’, and ‘d’ to ‘T’ Sed sed 's/^t/000/g' filename #the t on beginning of the lines replaced by ***sed 's/t$/000/g' filename #000 as a substitute for the t on the end of the linessed 's/[0-9]/*/' filename # * as a subustitute for every number with *sed 's/[a-z][A-Z]/--/' filename # looking for a pattern that a lower capital followed a capital## TaT --&gt; T--sed 's/[a-zA-Z]/--/g' filename # -- as a substitute for all letters on the filenameorsed 's/[a-Z]/--/g' filenamesed 's/[0-z]/--/g' filenamesed 's/[0-9]/-&amp;-/g' filename # exp: 833 new -- &gt; -8--3--3- newsed 's/[0-9][0-9]/-&amp;-/g' filename # exp: 833 new -- &gt; -833- newsed 's/\\w/_/g' filename # or letters except symples.(including chinese)sed 's/\\b/==/g' filename # add a &quot;==&quot; on the begin and the end of all words## ==4811== ==that== [==ðæt==; ==ðət==]sed 's/[^0-9]/*/g' filename # ^ means negated matchsed 's/A/B/g;s/C/D/f' FILENAME################################ deleted the match line ###############################sed '/\\bnew\\b/d' filename #boundary (new),( new),(new ),( new ),( new, )sed '/^$/d' # remove the line which beginning with end (blank line)sed '5,$ d' filenameequosed '4 q' filenameequo head -n 4 filename Others remove ^M Before TGCTGATCGATCGTAGCTAGCTAGCG^M CATGTCTGATCAGTGCTAGCTGATCG^M sed -i 's/\\r//' file After TGCTGATCGATCGTAGCTAGCTAGCG CATGTCTGATCAGTGCTAGCTGATCG pre { background-color:#38393d; color: #5fd381; }","link":"/2020/06/26/Linux/sed/"},{"title":"To start with manjaro","text":"Manjaro May 13 R hexo Chinese input QQ &amp; wechat kivy buildozer May 15 Graphic Manager OBS bug May 17 SSR Biology Environment(#Biology-environment) Others zoom Slack [Atom] update pacman -Syyu Graphic Manager I strongly recommend Settle GPU driver first if you are using dual GPU and one of them is Nvidia. Because one of my systems can’t be open again after following a set of processes for installing an Nvidia driver. As it said by Linus Torvalds: F**K YOU, NVIDIA! After you switched to the Nvidia driver, your OBS could work fluently. This post from linuxconfig could help you install driver appropriately. The trick is you need to switch into an old kernel (exp: 5.4.116). I even failed to install it on kernel 5.4.106_rt54-1. sudo mhwd -a pci nonfree 0300sudo reboot ██████████████████ ████████ ken@manjaro ██████████████████ ████████ OS: Manjaro 21.0.4 Ornara ██████████████████ ████████ Kernel: x86_64 Linux 5.4.116-1-MANJARO ██████████████████ ████████ Uptime: 2h 55m ████████ ████████ Packages: 1390 ████████ ████████ ████████ Shell: zsh 5.8 ████████ ████████ ████████ Resolution: 1920x1080 ████████ ████████ ████████ DE: GNOME 3.38.5 ████████ ████████ ████████ WM: Mutter ████████ ████████ ████████ WM Theme: Matcha-dark-sea ████████ ████████ ████████ GTK Theme: Matcha-sea [GTK2/3] ████████ ████████ ████████ Icon Theme: Papirus-Dark-Maia ████████ ████████ ████████ Font: Noto Sans 11 ████████ ████████ ████████ Disk: 868G / 1.8T (48%) CPU: Intel Xeon E3-1535M v6 @ 8x 4.2GHz [82.0°C] GPU: Quadro M2200 RAM: 5644MiB / 64042MiB Terminal failed to open after update Try this: Yochanan sudo sed -i '/en_US.UTF-8/s/^#//g' /etc/locale.gensudo sed -i '/fr_FR.UTF-8/s/^#//g' /etc/locale.gensudo locale-gen R sudo pacman -S yaourtsudo pacman -S r# an R execute terminal environmentpip install -i https://pypi.tuna.tsinghua.edu.cn/simple radian some common libraries of R:Karobben hexo # Switch the mirror into TaoBaonpm --registry https://registry.npm.taobao.org install expresssudo npm install hexo-cli -g Chinese input Neutionwei 2020 # installssudo pacman -S fcitxsudo pacman -S fcitx-imsudo pacman -S fcitx-configtoolsudo pacman -S fcitx-googlepinyinsudo pacman -S fcitx-sunpinyin# configsudo vim ~/.xprofile export GTK_IM_MODULE=fcitx export QT_IM_MODULE=fcitx export XMODIFIERS=\"@im=fcitx\" reboot needed reboot undo-check Only Show Current Language selection and you can find the Google Pinyin you just installed fcix5 I failed to setup Chinese input, so I try 5 DotIN13 2020 pacman -Rs $(pacman -Qsq fcitx) #卸载fcitx4pacman -S fcitx5-chinese-addons fcitx5 fcitx5-gtk fcitx5-qt #安装community源的fcitx5#你也可以选择用下面的命令安装archlinuxcn源的fcitx5sudo pacman -S fcitx5-chinese-addons-git fcitx5-git fcitx5-gtk-git fcitx5-qt5-git# configmkdir ~/.config/fcitx5/vim ~/.config/fcitx5/profile # Activateexport GTK_IM_MODULE=fcitxexport QT_IM_MODULE=fcitxexport XMODIFIERS=&quot;@im=fcitx&quot;# reboot your computer to activate it.reboot run fcitx5 &amp; Error You're currently running Fcitx with GUI, but fcitx5-config-qt couldn't be found. Now it will open config directory. reference: sudo pacman -S fcitx5-config-qt themes downloads the themes from github hosxy pacman -S fcitx5-material-color Japanese Impute sudo pacman -S fcitx5-mozc Wechat JontyShaw 2020 sudo pacman -S yaysudo pacman -S base-develyay -S deepin-wine-wechat#yay -S deepin-wine-qq # I failed to install QQ QQ link 1 link 2 sudo pacman -S yayyay -S adobe-source-han-sans-cn-fontsyay -S xdotoolyay -S com.qq.im.deepin other packages nmp npm i -g waque apps from Add/Remove Software atom: sudo pacman -Sy atom obs: sudo pacman -Sy obs wps: yay -S wps-office Scrcyp prerequisite: sudo pacman -S meson ninja Who to install Scrcyp Kivy john100 2021 cd /usr/localsudo wget http://python.org/ftp/python/3.7.6/Python-3.7.6.tar.xzsudo tar xf Python-3.7.6.tar.xzcd Python-3.7.6sudo ./configure --enable-optimizationssudo make altinstallsudo rm -rf ../Python*xz python3.7 -m pip install -i https://pypi.tuna.tsinghua.edu.cn/simple --user --upgrade pip wheel setuptools virtualenvcd ~python3.7 -m virtualenv kivyvensource kivyven/bin/activatepip install -i https://pypi.tuna.tsinghua.edu.cn/simple kivy pip install -i https://pypi.tuna.tsinghua.edu.cn/simple cythonpip install -i https://pypi.tuna.tsinghua.edu.cn/simple buildozerpip install -i https://pypi.tuna.tsinghua.edu.cn/simple https://github.com/kivymd/KivyMD/archive/master.zip buildozer test cd ~# install adbsudo pamac install android-tools, dpkg# install javasudo pacman -S jre8-openjdk-headless jre8-openjdk jdk8-openjdk openjdk8-doc openjdk8-src# Make invironment for some python librarysudo pacman -S cmakesource kivyven/bin/activate# enter the working directory thenbuildozer android debug deploy run RAN: /run/media/karobben/Data/Kivy_env/Kivy2Py3.8.1MD0.104.2.dev0/.buildozer/android/platform/build-armeabi-v7a/build/other_builds/hostpython3/desktop/hostpython3/native-build/python3 setup.py build_ext -v STDOUT: Could not find platform independent libraries Consider setting $PYTHONHOME to [:] Python path configuration: . . . Python runtime state: core initialized ModuleNotFoundError: No module named 'encodings' rm -r /run/media/karobben/Data/Kivy_env/Kivy2Py3.8.1MD0.104.2.dev0/.buildozer/android/platform/build-armeabi-v7a/build/other_builds/hostpython3 STDOUT: Traceback (most recent call last): File \"setup.py\", line 20, in from setuptools import Extension, setup ModuleNotFoundError: No module named 'setuptools' rm -r /run/media/karobben/Data/Kivy_env/Kivy2Py3.8.1MD0.104.2.dev0/.buildozer CMake Error at cmake/android/OpenCVDetectAndroidSDK.cmake:176 (message): Android SDK Tools: OpenCV requires Android SDK Tools revision 14 or newer. Use BUILD_ANDROID_PROJECTS=OFF to prepare Android project files without building them Call Stack (most recent call first): CMakeLists.txt:780 (include) git issue issue Debug info for oepncv The problem of building fail for opencv is the SDK tool was changes. But we could settle our own sdk too by setting android.sdk_path= in buildozer file. [DEBUG]: -> running gradlew assembleDebug [DEBUG]: [DEBUG]: > Task :compileDebugJavaWithJavac [DEBUG]: Note: Some input files use or override a deprecated API. [DEBUG]: Note: Recompile with -Xlint:deprecation for details. [DEBUG]: Note: Some input files use unchecked or unsafe operations. [DEBUG]: Note: Recompile with -Xlint:unchecked for details. [DEBUG]: [DEBUG]: > Task :transformNativeLibsWithStripDebugSymbolForDebug [DEBUG]: /home/karobben/.buildozer/android/platform/android-ndk-r19c/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/bin/arm-linux-androideabi-strip:/run/media/karobben/Data/Kivy2.0MD0.104.2.dP3.7.5/.buildozer/android/platform/build-armeabi-v7a/dists/opencvtest__armeabi-v7a/build/intermediates/transforms/mergeJniLibs/debug/0/lib/armeabi-v7a/gdb.setup: File format not recognized [DEBUG]: [DEBUG]: Unable to strip library '1' due to error /home/karobben/.buildozer/android/platform/android-ndk-r19c/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/bin/arm-linux-androideabi-strip returned from '/run/media/karobben/Data/Kivy2.0MD0.104.2.dP3.7.5/.buildozer/android/platform/build-armeabi-v7a/dists/opencvtest__armeabi-v7a/build/intermediates/transforms/mergeJniLibs/debug/0/lib/armeabi-v7a/gdb.setup', packaging it as is. [DEBUG]: [DEBUG]: Deprecated Gradle features were used in this build, making it incompatible with Gradle 7.0. [DEBUG]: Use '--warning-mode all' to show the individual deprecation warnings. [DEBUG]: See https://docs.gradle.org/6.4.1/userguide/command_line_interface.html#sec:command_line_warnings [DEBUG]: [DEBUG]: BUILD SUCCESSFUL in 5s [DEBUG]: 27 actionable tasks: 27 executed [INFO]: running cp /run/media/karobben/Data/Kivy2.0MD0.104.2.dP3.7.5/.buildozer/android/platform/build-armeabi-v7a/dists/opencvtest__armeabi-v7a/build/outputs/apk/debug/opencvtest__armeabi-v7a-debug.apk opencvtest__armeabi-v7a-debug-0.1-.apk WARNING: Received a --sdk argument, but this argument is deprecated and does nothing. No setup.py/pyproject.toml used, copying full private data into .apk. Applying Java source code patches... Applying patch: src/patches/SDLActivity.java.patch franslott #mv tools old-tools# mv lib/external/com/android/tools lib/external/com/android/old-tools# 1. Download [cmdlines-tools from google](https://developer.android.com/studio#cmdline-tools)# 2. prepare the sdk by yourself# export the path you'd like to place itexport PREFIX=/run/media/karobben/Data/Kivy2.0MD0.104.2.dP3.7.5mkdir $PREFIX/.buildozer/android/platform/android-sdkcd $PREFIX/.buildozer/android/platform/android-sdk/cp ~/Downloads/commandlinetools-linux-7302050_latest.zip .unzip commandlinetools-linux-7302050_latest.zip# mv tools old-toolscd cmdline-tools/binsudo ./sdkmanager --sdk_root=$PREFIX/.buildozer/android/platform/android-sdk/ --install &quot;tools&quot;sudo ./sdkmanager --sdk_root=$PREFIX/.buildozer/android/platform/android-sdk/ --install &quot;build-tools;29.0.0-rc3&quot;sudo ./sdkmanager --sdk_root=$PREFIX/.buildozer/android/platform/android-sdk/ --install &quot;platforms;android-27&quot;sudo ./sdkmanager --sdk_root=$PREFIX/.buildozer/android/platform/android-sdk/ --install &quot;platform-tools&quot;sudo ./sdkmanager --sdk_root=$PREFIX/.buildozer/android/platform/android-sdk/ --install &quot;patcher;v4&quot;sudo ./sdkmanager --sdk_root=$PREFIX/.buildozer/android/platform/android-sdk/ --install &quot;emulator&quot;sudo ./sdkmanager --sdk_root=$PREFIX/android-sdk/ --install &quot;tools&quot;sudo ./sdkmanager --sdk_root=$PREFIX/android-sdk/ --install &quot;build-tools;29.0.0-rc3&quot;sudo ./sdkmanager --sdk_root=$PREFIX/android-sdk/ --install &quot;platforms;android-27&quot;sudo ./sdkmanager --sdk_root=$PREFIX/android-sdk/ --install &quot;platform-tools&quot;sudo ./sdkmanager --sdk_root=$PREFIX/android-sdk/ --install &quot;patcher;v4&quot;sudo ./sdkmanager --sdk_root=$PREFIX/android-sdk/ --install &quot;emulator&quot; adding the path into buildozer.spc: buildozer.spcandroid.sdk_path = /run/media/ken/Data/Kivy2.0MD0.104.2.dP3.7.5/android-sdk/ # delete ANT, NDK againbuildozer android cleanbuildozer distcleanbuildozer -v android debug# or buildozer android debug deploy run SSR Awk.BLOG 2021 Download Qv2ray and (AppImage) SSR plugin chmod +x *.AppInage mv SSR plugin to /home/$USER/.config/qv2ray/plugins/ Click AppImage, Click group, add your links. Biology environment bioconda ## miniconda# download minicondawget -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/Miniconda3-py39_4.9.2-Linux-x86_64.sh# export your Miniconda/bin to path# Douban mirrorconda config --add channels https://pypi.douban.com/anaconda/cloud/conda-forge/conda config --add channels https://pypi.douban.com/anaconda/cloud/msys2/conda config --add channels https://pypi.douban.com/anaconda/cloud/bioconda/conda config --add channels https://pypi.douban.com/anaconda/cloud/menpo/conda config --add channels https://pypi.douban.com/anaconda/cloud/pytorch/ qinhua mirro #Anaconda Python 免费仓库conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/menpo/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/# for legacy win-64conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/peterjc123/conda config --set show_channel_urls yes beida mirror conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/pkgs/main/conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/cloud/conda-forge/conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/cloud/msys2/conda config --add channels https://mirrors.bfsu.edu.cn/miniconda/cloud/bioconda/conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/cloud/menpo/conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/cloud/pytorch/conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/cloud/peterjc123/conda config --set show_channel_urls yes Zoom Source: Zoom for linux sudo pacman -U zoom_x86_64.pkg.tar.xz Slack Slack is a chatting channel which for sharing your ideas proficiently.sla sudo pacman -S slack-desktop","link":"/2021/05/13/Linux/manjaro/"},{"title":"Pop OS","text":"Pop os Atom R python latex Apps from stores update sudo apt updatesudo apt upgradesudo apt dist-upgradesudo apt autoremovesudo apt autocleansudo fwupdmgr get-devicessudo fwupdmgr get-updatessudo fwupdmgr updatesudo apt install flatpakflatpak updatesudo reboot nowsudo apt install curl vim install aps from store shop: atom; obs wechat Reference: Kumar, 2020 Use web app throuhg Rambox sudo snap install ramboxpro sudo snap install electronic-wechat Wine based wechat: 白菜林; 2022 App source from: Ukylin wget -O weixin.deb &quot;http://archive.ubuntukylin.com/software/pool/partner/weixin_2.1.1_amd64.deb&quot;sudo dpkg -i weixin.deb hexo Reference: hexo.io sudo apt install nodejssudo apt upgrade nodesudo apt install npmsudo npm install -g hexo-cli waque npm i -g waque Install Atom plugs Atom is died More: Karobben 2020 markdown-preview-enhanced language-r (R 语言语法高亮) minimap (VS 一样小图预览) atom-beautify (高亮美化) emmet (emmet是HTML,CSS快速编写的神器,具体的使用可以参看emmet官网。) autocomplete-* 系列 (自动补全) pigments (显示颜色) apm install markdown-preview-enhancedapm install language-r minimap pigments atom-beautify R sudo apt install r-base-core python Python3 was pre-installed sudo apt install python3-pip Go lang sudo apt install golang-go others Scrcpy the best app for cast your cell on linux Karobben, 2020 sudo apt install mesonsudo apt install adb ffmpeg libsdl2-2.0-0 make gcc pkg-config meson ninja-build \\ libavcodec-dev libavformat-dev libavutil-dev libsdl2-dev libusb-1.0-0-devwget -c https://github.com/Genymobile/scrcpy/releases/download/v1.11/scrcpy-server-v1.11wget -c https://github.com/Genymobile/scrcpy/archive/v1.11.tar.gzmv scrcpy-server-v1.11 scrcpy-server-v1.11.jartar -zxvf v1.11.tar.gzsudo install scrcpy-server-v1.11.jar /usr/local/bin/scrcpy-server.jarcd scrcpy-1.11meson build --buildtype release --strip -Db_lto=true -Dprebuilt_server=../scrcpy-server-v1.11.jarcd buildninjasudo ninja installscrcpy Gotop Github: cjbassi/gotop Release wget https://github.com/cjbassi/gotop/releases/download/3.0.0/gotop_3.0.0_linux_amd64.debsudo dpkg -i gotop_3.0.0_linux_amd64.debrm gotop_3.0.0_linux_amd64.deb snap install gotop-cjbassisnap connect gotop-cjbassi:hardware-observesnap connect gotop-cjbassi:mount-observesnap connect gotop-cjbassi:system-observegotop-cjbassi else ## Set a hostnamehostnamectl set-hostname karobben## install screenfetchsudo apt install screenfetchsudo apt install lolcat## SSH keyseval &quot;$(ssh-agent -s)&quot;ssh-add ~/.ssh/id_ed25519## Fish - A Friendly Interactive Shell (doesn't work for me)sudo apt install -y fish util-linux-userchsh -s /usr/bin/fishmkdir -p /home/$USER/.local/binset -Ua fish_user_paths /home/$USER/.local/bin# Snap## Enable snap supportsudo apt install snapd# nautilus-admin## Right-click context menu in nautilus for adminsudo apt install -y nautilus-admin#Virtual machines: Quickemu and other stuff# git clone https://github.com/wmutschl/quickemu ~/quickemu#sudo apt install snapd bsdgames wget#sudo snap install qemu-virgil#sudo snap connect qemu-virgil:kvm#sudo snap connect qemu-virgil:raw-usb#sudo snap connect qemu-virgil:removable-media#sudo snap connect qemu-virgil:audio-record#sudo ln -s ~/quickemu/quickemu /home/$USER/.local/bin/quickemu## Open-sshsudo apt install openssh-server# gitsudo apt install -y git git-lfsgit-lfs installflatpak install -y gitkraken# latexsudo apt install -y texlive texlive-font-utils texlive-pstricks-doc texlive-base texlive-formats-extra texlive-lang-german texlive-metapost texlive-publishers texlive-bibtex-extra texlive-latex-base texlive-metapost-doc texlive-publishers-doc texlive-binaries texlive-latex-base-doc texlive-science texlive-extra-utils texlive-latex-extra texlive-science-doc texlive-fonts-extra texlive-latex-extra-doc texlive-pictures texlive-xetex texlive-fonts-extra-doc texlive-latex-recommended texlive-pictures-doc texlive-fonts-recommended texlive-humanities texlive-lang-english texlive-latex-recommended-doc texlive-fonts-recommended-doc texlive-humanities-doc texlive-luatex texlive-pstricks perl-tk## zoomflatpak install -y zoom## Flameshortsudo apt install flameshotflameshot gui##Multimedia Codecs#Install and compile multimedia codecs:sudo apt install -y libavcodec-extra libdvd-pkg; sudo dpkg-reconfigure libdvd-pkg#OBSsudo apt install -y obs-studio# xmindsnap install xmind# cowsaysnap install cowsaysudo apt install imagemagick-6.q16 # convert functionsudo apt install ffmpegsudo apt install kdenlive## gtt-clisudo apt install python3-gtts## playsudo apt install soxsudo apt install mplayer# PDF readersudo apt-get install okular fingerprint authority sudo pam-auth-update python OpenCV pip3 install --upgrade setuptoolspip3 install numpy Matplotlibpip3 install opencv-python Chinese input download the deb: link reference: @kuang-da , github woq 2021 Lei Mao (This post shell be solve your question) sudo apt install fcitxsudo apt install fcitx5-chinese-addons fcitx5curl -sL 'https://keyserver.ubuntu.com/pks/lookup?&amp;op=get&amp;search=0x73BC8FBCF5DE40C6ADFCFFFA9C949F2093F565FF' | sudo apt-key addsudo apt-add-repository 'deb http://archive.ubuntukylin.com/ukui focal main'sudo apt upgrade imput themes/skin for fcitx Source: @BrandonCardoso; 2021-github https://github.com/BrandonCardoso/fcitx-dracula 拼音词库 Reference: CodeAlex; 2019 sudo apt install fcitx-toolsmkdir /home/$USER/.config/fcitx/pinyin/git clone https://github.com/AlessandroChen/fcitx-pinyin-lexicon.gitcd fcitx-pinyin-lexicon Apps from stores atom Xmind 8 TigerVNC Viewer software for biologist sudo apt install clustalw bowtie bowtie2 muscle rsem t-coffee pymol ncbi-entrez-direct samtoolssudo apt install ncbi-blast+ # some system is blast2 auto mount D Quetza, 2019 sudo echo &quot;/dev/sda2 /media/$USER/Data/ ntfs defaults,nls=utf-8,umask=007,gid=46 0 0&quot; &gt;&gt; /etc/fstab Themes Reference:Abhishek Prakash, 2021, It’s FOSS Select a theme from Website install ocs-url from here After download, an example code for installation could be: sudo dpkg -i ocs-url_3.1.0-0ubuntu1_amd64.deb Then, open Tweaks → Apearance → Applications → Theme you download ${theme.zip} is the theme zip file you download mkdir ~/.themessudo apt install gnome-shell-extensionscd ~/.themesmv ~/Download/${theme.zip} .unzip ${theme.zip} Other themes for Gnome: gnome-look.org Exp: Win11 style Gnome-tweaks sudo apt install gnome-tweaks sudo apt install gnome-tweak-toolsudo apt install gnome-shell-extensionssudo apt install $(apt search gnome-shell-extension | grep ^gnome | cut -d / -f1)gnome-tweaks apps for configuring Ubuntu, removes GNOME Shell Extensions support by releasing version 40. You need to launch extensions idependently Karim Buzdar,2020 After start the Extesion, choose User themes → Settings → select it video wall paper komorebi Zsh A similar zsh environment from Manjaro. zsh theme: source Fonts for powerlevel10k Download fonts: MesloLGS NF; from Github # Install zshsudo apt install zshchsh -s /bin/zsh# Install oh-my-zshsh -c &quot;$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&quot;# Zsh Theme: powerlevel10kgit clone https://github.com/romkatv/powerlevel10k.git $ZSH_CUSTOM/themes/powerlevel10k# Install the font for powerlevel10kapt-get install fonts-powerline# add lines below to ~/.zshrc#ZSH_THEME=&quot;powerlevel10k/powerlevel10k&quot;#POWERLEVEL9K_MODE=&quot;awesome-patched&quot;# Set the themesource ~/.zshrc# configure the theme again if you wanna a changep10k configure# pluginsgit clone https://github.com/zsh-users/zsh-autosuggestions.git $ZSH_CUSTOM/plugins/zsh-autosuggestionsgit clone https://github.com/zsh-users/zsh-syntax-highlighting.git $ZSH_CUSTOM/plugins/zsh-syntax-highlighting# add lines below to ~/.zshrc#plugins=(zsh-autosuggestions zsh-syntax-highlighting git)source ~/.zshrc You should change ~/.zshrc as below listed. - ZSH_THEME=&quot;...&quot;+ ZSH_THEME=&quot;powerlevel10k/powerlevel10k&quot;- plugins=(git)+ plugins=(git+ zsh-autosuggestions+ zsh-syntax-highlighting) zsh didn’t load automatically: skepticNeophyte We need to reload oh-my-zsh.sh and config again source $ZSH/oh-my-zsh.sh command Autosuggestion: Thansk for Kumar Abhirup’s post, I finally get my favorate zsh environment. zsh plunges: Varun Kumar Manik: How to Install Zsh/ zsh-autosuggestions/ oh-my-zsh in Linux Kivy I Strongly recommend that build the kivy in an virtualenv. You can use either conda or python virtualenv python virtualenv python3.7 -m pip install -i https://pypi.tuna.tsinghua.edu.cn/simple --user --upgrade pip wheel setuptools virtualenvcd ~python3.7 -m virtualenv kivyvensource kivyven/bin/activatepip install -i https://pypi.tuna.tsinghua.edu.cn/simple kivy pip install -i https://pypi.tuna.tsinghua.edu.cn/simple cythonpip install -i https://pypi.tuna.tsinghua.edu.cn/simple buildozerpip install -i https://pypi.tuna.tsinghua.edu.cn/simple https://github.com/kivymd/KivyMD/archive/master.zip Conda conda create -n kivy python==3.8.10pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple kivy pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple cythonpip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple buildozerpip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple https://github.com/kivymd/KivyMD/archive/master.zip","link":"/2022/01/31/Linux/popos/"},{"title":"Slurm Workload Manager","text":"Introduction Slurm is an open source, fault-tolerant, and highly scalable cluster management and job scheduling system for large and small Linux clusters. Slurm requires no kernel modifications for its operation and is relatively self-contained. As a cluster workload manager, Slurm has three key functions. First, it allocates exclusive and/or non-exclusive access to resources (compute nodes) to users for some duration of time so they can perform work. Second, it provides a framework for starting, executing, and monitoring work (normally a parallel job) on the set of allocated nodes. Finally, it arbitrates contention for resources by managing a queue of pending work. Optional plugins can be used for accounting, advanced reservation, gang scheduling (time sharing for parallel jobs), backfill scheduling, topology optimized resource selection, resource limits by user or bank account, and sophisticated multifactor job prioritization algorithms. From: slurm Sbatch sbatch run.sh Chcek jobs squeue -u {username} kill jobs scancel -u {username} Check the log sacct --format=jobid,elapsed,ncpus,ntasks,state|headsacct JobID Elapsed NCPUS NTasks State ------------ ---------- ---------- -------- ---------- 2218153 00:00:01 1 FAILED 2218153.bat+ 00:00:01 1 1 FAILED 2218154 00:00:00 1 FAILED 2218154.bat+ 00:00:00 1 1 FAILED 2218155 00:00:01 1 FAILED 2218155.bat+ 00:00:01 1 1 FAILED 2218501 00:14:52 1 COMPLETED 2218501.bat+ 00:14:52 1 1 COMPLETED 2218502 00:47:16 1 RUNNING 2218503 00:15:19 1 COMPLETED 2218503.bat+ 00:15:19 1 1 COMPLETED Tricks Hold the job submit when the waiting list is too long Sometimes, we need to upload a large number of jobs using a for loop. However, there is a limit to the number of jobs that can be submitted by each user. In such cases, we prefer to hold off on job submission and wait until some of the previously submitted jobs are completed. To achieve this, the easiest way is to use a while loop before submitting the jobs. for i in {1..3000}; do while [ $(squeue -u user| wc -l) -gt 900 ] ;do echo $(squeue -u user| wc -l) too many jobs; sleep 10; done sbatch job.shdone In this while loop, we utilize the command squeue -u user | wc -l to determine the number of jobs in the user’s list. When it exceeds 900, we enter a while loop that will pause the submission process until some jobs have completed. This is a bash script that will submit a batch job (job.sh) 3000 times. However, it will check if there are already 900 or more jobs running under the user account “user” using the squeue command. If there are, it will wait for 10 seconds and check again. This loop will continue until there are fewer than 900 jobs running, at which point it will submit the next batch job using the sbatch command. Here is a breakdown of the code: for i in {1..3000}; do starts a loop that will run 3000 times. This is just a counter and is not used in the loop. while [ $(squeue -u user| wc -l) -gt 900 ] ;do starts a while loop that will continue as long as there are 900 or more jobs running under the user account “user”. echo $(squeue -u user| wc -l) too many jobs; prints a message to the console indicating how many jobs are currently running. sleep 10; pauses the script for 10 seconds before checking again. sbatch job.sh submits the batch job job.sh to the queue for processing. pre { background-color:#38393d; color: #5fd381; }","link":"/2022/09/22/Linux/slurm/"},{"title":"terminal 不走代理加速","text":"terminal 不走代理加速 系统: deepin 15.11 明明都开了全局模式, 但是terminal 下载还是很慢解决方法: export http_proxy=&quot;http://127.0.0.1:12333&quot;export https_proxy=&quot;http://127.0.0.1:12333&quot; 然后就好啦~ 参考:https://blog.csdn.net/weixin_43377336/article/details/87249688","link":"/2020/06/26/Linux/terminal-speed/"},{"title":"Compress and Decompress","text":"tar ##reference:https://man.linuxde.net/tar Compress: tar -zcvf File.tar.gz File Decompress: tar - zxvf File.tar.gz Format Decompress compress .tar xvf cvf .tar.gz zxvf zcvf .tar.bz2 jxvf jcvf .tar.bz jxvf .tar.Z .tar.Z .tar.Z Tar with ssh to substitute scp This pipe could help you upload large files much faster than scp. It is a very good way to substitute scp. I tried to backup 1.4 T files from a moveable hard drive with scp and it takes a half hour for 24 KB files. It spends most of the time reading files. When I switched this pipeline, a few decade gigabytes was uploaded within a few minutes. It is crazy fast!!! Cite: roaima; 2015 tar czf - cap_* | ssh user@host tar xvzfC - dirtar cf - cap_* | gzip | ssh user@host 'cd dir &amp;&amp; gzip -d | tar xvf -' cp files with tar tar czf - cap_* | ssh user@host tar xvzfC - dirtar cf - cap_* | gzip | ssh ken@0.0.0.0 'cd dir &amp;&amp; gzip -d | tar xvf -' Samll size fiels: cp -r Github /media/Side/ken/Github cp -r Github /media/Side/ken/Github 0.00s user 0.23s system 27% cpu 0.835 total time tar cf -Github | gzip | ssh ken@0.0.0.0 'cd /media/Side/ken &amp;&amp; gzip -d | tar xvf -' tar cf - Githu* 0.06s user 0.32s system 2% cpu 13.564 total gzip 10.70s user 0.04s system 79% cpu 13.566 total ssh ken@0.0.0.0 'cd /media/Side/ken && gzip -d | tar xvf -' 0.59s user 0.26s system 6% cpu 13.567 total For the Github directory, cp only takes less than 1 s, but take 13.5s for tar-pipe. So, if you have lots of small files, cp still are your first choose. Large file test check the size of the file: du -sh Mutation/Raw_VCF 23G Mutation/Raw_VCF time cp -r Mutation/Raw_VCF /media/Side/ken/ cp -r Mutation/Raw_VCF /media/Side/ken/ 0.53s user 59.35s system 7% cpu 12:31.78 total time tar cf - Mutation/Raw_VCF | gzip | ssh ken@0.0.0.0 'cd /media/Side/ken &amp;&amp; gzip -d | tar xvf -' tar cf - Mutation/Raw_VCF 3.21s user 27.98s system 4% cpu 10:36.64 total gzip 532.32s user 2.73s system 84% cpu 10:36.65 total ssh ken@0.0.0.0 'cd /media/Side/ken && gzip -d | tar xvf -' 18.95s user 7.16s system 4% cpu 10:36.65 total So, in this result, cp takes like 12 minutes, but our tar-pipe takes 10.5 minutes A better way Though the pipeline works, but the ssh part is wasting large of resource. The best way for this situation is: tar cf - Mutation/Raw_VCF | (cd /media/Side/ken/; tar xvf -) And it only takes roughly 2 minutes. gzip Compress: gzip -cr 220725_KEGG &gt; KEGG.gz Decompress: gzip -d KEGG.gz Tar with multiple threads Resource: Artem S. Tashkinov, 2020 # compress tar -c -I 'xz -9 -T0' -f archive.tar.xz [list of files and folders]# decompresstar -x -I xz -f archive.tar.xz tar: tar stands for “tape archive” and is a command-line utility used to create, extract, or manipulate tarball archives, which are collections of files and directories bundled together into a single file. -c: This flag tells tar to create a new archive. -I 'xz -9 -T0': The -I option allows you to specify a compression program to use. In this case, 'xz -9 -T0' is being used. xz: This is the program used for compression. xz is a lossless data compression tool that is highly efficient. -9: This option tells xz to use the maximum compression level (9). This will result in the smallest possible archive size, though it may take more time to compress. -T0: This option tells xz to use all available CPU threads to perform the compression. 0 dynamically chooses the number of threads based on the number of available CPU cores. This makes the compression faster on multi-core systems. -f archive.tar.xz: The -f option allows you to specify the name of the archive file you’re creating. In this case, the archive is named archive.tar.xz. archive.tar.xz: This is the name of the output file. The .tar.xz extension indicates that it’s a tarball compressed with xz. [list of files and folders]: This is a placeholder for the actual files and directories you want to include in the archive. You would replace this with a list of the files and directories you wish to compress into the archive. pre { background-color:#38393d; color: #5fd381; }","link":"/2020/06/26/Linux/tar/"},{"title":"tmux2","text":"Genearl Commands for Tmux tmux is a very powerful interact-able bash interpreter. Once you familiarized with the hot keys, it would be an inextricable programs of you. Copy and Past: ^b [ (ctrl+b [) : move the mouse;^blanck: start to selecte; (hold this at less for a second) ^w: copy Now, the selected words are in your copy list. You can using the favorite way to copy it in terminal, or Word, Atom, etc.A typical way to past in tmux is:^b ]. Or you can:^B [;Using mouse the select a target;^w; It works on turmx, but not on my laptop since when ever I typing ^+blank, the stupid Sugou Input will pop out and interrupt the processor… Panes: Each window could split into small panes which is the key feature for tmux. Moves Keys Split pane horizontal ctrl-b + &quot; Split pane Vertical ctrl-b + % Resize the the Panes ctrl-b + ctrl-→ Show pane ID ctrl-b + q Show the window and pane ID ctrl-b + w move the Panes into right ctrl-b + { Tips: Panes resize: After you executed ctrl-b, you can hold ctrl and press the up, down, left, or right as many as you can until it fits you the best. Window Related Moves Keys Create a new Window ctrl-b+ ‘c’ Switch to the next window ctrl-b + n","link":"/2020/06/26/Linux/tmux/"},{"title":"Ubuntu linux in Android (aarch64)&#x2F;No root (proot)","text":"Ubuntu linux in Android (aarch64)/No root (proot) apt updateapt upgrade conda Ivon’s Blog R R: apt install r-base radian: pip install radian install.packages('ggplot2') Python apt install python3.10-venv apt install jupyter-notebook python -m venv base source ~/env-name/bin/activate ipython: pip install ipython tk: sudo apt-get install python3-tk matplotlib: pip install matplotlib pandas: pip install pandas Something I installed vim: apt install vim Permission denied (src/ip_resolver.cpp:542) sudo chown -R ken:root ~/.local/share/jupyter UserWarning: Unexpected error discovering local network interfaces: [Errno 13] Permission denied Permission denied (src/ip_resolver.cpp:542) pre { background-color:#38393d; color: #5fd381; }","link":"/2023/06/15/Linux/ubuntuarm/"},{"title":"Secure Shell (SSH)","text":"SSH SSH, short for Secure Shell, is a network protocol used to securely access and manage a computer over an unsecured network. It provides a secure channel over an unencrypted network, like the internet, allowing users to log into another computer, execute commands remotely, and move files. SSH uses strong encryption to protect the data being transmitted, ensuring confidentiality and integrity of the data against eavesdropping and interception. It’s commonly used by system administrators and IT professionals for managing systems and applications remotely. How to Use It Using SSH typically involves two primary components: an SSH client and an SSH server. The server runs on the machine you want to connect to, while the client runs on the machine you’re connecting from. Here’s a basic guide on how to use SSH: Setting Up an SSH Server Install SSH Server: On the remote machine (the one you want to access), you need to install an SSH server. For Linux systems, this is often done using the openssh-server package. sudo apt updatesudo apt install openssh-server This example is for Debian-based systems (like Ubuntu). The commands might vary for other systems. Start and Enable SSH Service: Ensure that the SSH service is started and enabled to start on boot. sudo systemctl start sshsudo systemctl enable ssh Configure SSH Server (Optional): You can configure your SSH server by editing the /etc/ssh/sshd_config file. This step is optional and typically only necessary for advanced configurations. Connecting Using an SSH Client Install SSH Client: Most Unix-like systems (Linux, macOS) come with an SSH client pre-installed. For Windows, you can use clients like PuTTY or use the built-in SSH client in Windows 10/11. Establish an SSH Connection: To connect to the SSH server, you need the IP address or hostname of the server and the username on that system. The basic command is: ssh [username]@[host] For example, if your username is user and the server’s IP address is 192.168.1.100, you would use: ssh user@192.168.1.100 Authenticate: When you connect for the first time, you’ll be asked to verify the identity of the server. After accepting, you’ll be prompted for the password of the user account you are logging into on the remote machine. Using SSH: Once connected, you can execute commands on the remote machine as if you were physically present. Transferring Files (Optional): SSH also allows for secure file transfer using SCP or SFTP. To copy a file from your local machine to the remote machine:scp /path/to/local/file user@192.168.1.100:/path/to/remote/directory To copy a file from the remote machine to your local machine:scp user@192.168.1.100:/path/to/remote/file /path/to/local/directory Exiting SSH: To end your SSH session, simply type exit or press Ctrl+D. Configure file vim ~/.ssh/config Host home_pc HostName 192.168.3.1 User john Port 2322 How to login this host: ssh home_pc Security Considerations SSH Keys: For better security, it’s recommended to use SSH keys instead of passwords. SSH keys are a pair of cryptographic keys that can be used to authenticate to an SSH server as an alternative to password-based logins. Firewall Settings: Make sure your firewall settings allow SSH connections (usually on port 22). Regular Updates: Keep the SSH server software up to date for security. SSH is a powerful tool for remote administration, but it’s important to use it securely to protect your systems and data. SSH Key Generating an SSH key is a security practice for authenticating to an SSH server more securely than using just a password. Here’s why you should do it and how to generate an SSH key: Why Use SSH Keys? Enhanced Security: SSH keys are cryptographic keys that are much more secure than passwords. They are almost impossible to decipher using brute force methods. No Need for Passwords: When you use SSH keys, you don’t need to enter your password every time you connect, which reduces the risk of password theft. Automation Friendly: SSH keys are ideal for automated processes. Scripts and applications can authenticate without manual password entry. Access Control: SSH keys can be used to control who can access a server. Only users with the matching private key can access the server configured with the public key. How to Generate an SSH Key On Linux or macOS: Open Terminal: Launch the terminal application. Generate Key Pair: Use the ssh-keygen command to generate a new SSH key pair. ssh-keygen -t rsa -b 4096 This command creates a new SSH key using the RSA algorithm with a key size of 4096 bits, providing a good balance between security and compatibility. You can choose other algorithms like ed25519 which is considered more secure but may not be compatible with older systems. Specify File to Save the Key: By default, ssh-keygen will save the key in the ~/.ssh/id_rsa file. You can specify a different file if you want. Enter a Passphrase (Optional): For additional security, you can enter a passphrase when prompted. This passphrase will be required whenever the private key is used. Adding the SSH Key to Your SSH Server Copy Public Key: After generating your SSH key, you need to add the public key to the ~/.ssh/authorized_keys file on your SSH server. Use ssh-copy-id on Linux/macOS: If you’re using Linux or macOS, you can use ssh-copy-id to copy your public key to the server easily. ssh-copy-id user@server-address Manual Copying: If ssh-copy-id isn’t available or you’re using Windows, you can manually copy the public key text and append it to ~/.ssh/authorized_keys on the server. Remember, never share your private key. The public key is what you distribute or add to servers, while the private key should be securely stored and kept private. Trouble Shooting: Public Key Doesn’t Work If your SSH public key authentication isn’t working, there could be several reasons. Here’s a troubleshooting guide to help you resolve common issues: 1. Check File Permissions On the Server: SSH is particular about file permissions for the ~/.ssh directory and the authorized_keys file. Incorrect permissions can prevent SSH from authenticating using keys. The ~/.ssh directory should have permissions set to 700 (drwx------). The authorized_keys file should have permissions set to 600 (-rw-------). Use the chmod command to set these permissions: chmod 700 ~/.sshchmod 600 ~/.ssh/authorized_keys 2. Ensure Correct Ownership The .ssh directory and the authorized_keys file should be owned by the user, not root or any other user. Use the chown command to set the ownership: chown -R your_username:your_username ~/.ssh You can also make sure that the home directory permissions are restricted to the user. I think it could do the same thing. chmod -R u+rwX,go-rwx /home/your_username 3. Verify the Public Key Format Ensure that the public key in authorized_keys is in the correct format. It should be a single line starting with ssh-rsa or ssh-ed25519, followed by the key, and optionally a comment. 4. Check the SSH Server Configuration The SSH server configuration file (/etc/ssh/sshd_config) on the server might restrict public key authentication. Check the following settings: PubkeyAuthentication yes should be set to allow public key authentication. AuthorizedKeysFile should point to the correct path, typically .ssh/authorized_keys. If PasswordAuthentication is set to no, the server will not fall back to password authentication if key authentication fails. After making changes, restart the SSH service: sudo systemctl restart ssh 5. Check SSH Client Configuration On your client machine, ensure you’re specifying the correct private key. If you’re using a key with a non-default name or location, specify it with the -i option: ssh -i /path/to/private_key user@server 6. Look at Server Logs SSH server logs can provide details on why the key authentication is failing. Check the logs for relevant error messages: On most Linux systems, SSH logs are located in /var/log/auth.log or /var/log/secure. 7. Validate Key Pair Ensure that the public and private keys are a matching pair. If you have regenerated or changed keys, make sure the server has the corresponding public key. 8. Check Passphrase If your private key is protected with a passphrase, ensure you’re entering the correct passphrase when prompted. 9. Network Issues Confirm there are no network issues preventing SSH access. Firewall settings on either the client or server side can block SSH connections. 10. Client-Side Debugging Use SSH with the -vvv option for verbose output, which can give more insights: ssh -vvv -i /path/to/private_key user@server This will provide detailed debug information about each step of the SSH connection process, potentially highlighting where the issue lies. pre { background-color:#38393d; color: #5fd381; }","link":"/2023/12/20/Linux/ssh/"},{"title":"Disk Mount and Manage in Linux","text":"Mount the disk if the name of your drive you want to mount is /dev/sda2. And you want to mount it as /media/Side, the quickest way is: sudo mkdir /media/Sidesudo mount /dev/sda2 /media/Side Check the drive list and find it df -h could view all hard drive storage information fdisk -l could print more detailed partition drives sudo fdisk -l As you can see the basic information belowe. This Disk as 3.7 TiB in total but was splited into four partitions Disk /dev/sda: 3.7 TiB, 4000787030016 bytes, 7814037168 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 4096 bytes I/O size (minimum/optimal): 4096 bytes / 4096 bytes Disklabel type: gpt Disk identifier: 01EA470B-E7C7-4AB8-BCE5-88319B2E0C64 Device Start End Sectors Size Type /dev/sda1 2048 264191 262144 128M Microsoft reserved /dev/sda2 264192 3894284119 3894019928 1.8T Microsoft basic data /dev/sda3 3894284288 3895334911 1050624 513M EFI System /dev/sda4 3895334912 7814035455 3918700544 1.8T Linux filesystem we can also use sudo parted -l to print partitions, only (phoenixnap, 2020): Model: ATA ST4000DM004-2CV1 (scsi) Disk /dev/sda: 4001GB Sector size (logical/physical): 512B/4096B Partition Table: gpt Disk Flags: Number Start End Size File system Name Flags 1 1049kB 135MB 134MB Microsoft reserved partition msftres 2 135MB 1994GB 1994GB ntfs Basic data partition msftdata 3 1994GB 1994GB 538MB fat32 EFI System Partition boot, esp 4 1994GB 4001GB 2006GB ext4 And you can see that half of it, 1.8 TiB was given Linux system and another half was given Windows System. Windows ntf disk in Linux mkdir: cannot create directory 'ken': Read-only file system sudo ntfsfix /dev/sda2 Mounting volume... OK Processing of $MFT and $MFTMirr completed successfully. Checking the alternate boot sector... OK NTFS volume version is 3.1. NTFS partition /dev/sda2 was processed successfully. You may need to reboot and re-mount to work Mount online Web sever The “sshfs” command in Linux is used to mount a remote file system on a local machine over an SSH connection. It allows users to securely access and manipulate files on a remote machine as if they were on the local machine. The command syntax typically involves specifying the remote host and directory to mount, as well as the local directory to mount it to. © ChatGPT sudo apt-get install sshfssudo mkdir /mnt/Ken_lapsudo chmod 777 /mnt/Ken_lapsshfs Karroben@192.168.1.110:/mnt/8A26661926660713/ /mnt/Ken_lap pre { background-color:#38393d; color: #5fd381; }","link":"/2022/09/14/Linux/mount/"},{"title":"VS code","text":"VS code I am a loyal Atom user. But Atom has died and I have to move on. Hotkeys Keyboard shortcuts for Linux Fold all: ctrl+k ctrl+0 Release all: ctrl+k ctrl+j wrap text: Alt+z Plugins List ctrl+shift+x to open and search plugins. Markdown Preview Enhance R Code Spell Checker pre { background-color:#38393d; color: #5fd381; }","link":"/2023/01/13/Linux/vscode/"},{"title":"If &amp; whle &amp; case","text":"If &amp; whle &amp; case if [ 1 -eq 1 ] #expressionthen #Statement(s) to be executed if expression is true echo Yesfi © Bash Test Operators -eq is equal to -ne is not equal to -gt is greater than -ge is greater than or equal to -lt is less than -le is less than or equal to &lt; is less than &lt;= is less than or equal to &gt; is greater tha &gt;= is greater than or equal to = is equal to == The == comparison operator behaves differently within a double-brackets test != is not equal to &lt; is less than, in ASCII alphabetical order &gt; is greater than, in ASCII alphabetical order. -z string is null -n string is not null. -e file exists -a is deprecated and its use is discouraged. -f file is a regular file (not a directory or device file) -d file is a directory -h file is a symbolic link -L file is a symbolic link -b file is a block device -c file is a character device -p file is a pipe -S file is a socket -s file is not zero size -t file (descriptor) is associated with a terminal device; -r file has read permission (for the user running the test) -w file has write permission (for the user running the test) -x file has execute permission (for the user running the test) -g set-group-id (sgid) flag set on file or directory -u set-user-id (suid) flag set on file -k sticky bit set -O you are owner of file -G group-id of file same as yours -N file modified since it was last read -nt file f1 is newer than f2 if [ &quot;$f1&quot; -nt &quot;$f2&quot; ] -ot file f1 is older than f2 if [ &quot;$f1&quot; -ot &quot;$f2&quot; ] -ef files f1 and f2 are hard links to the same file if [ &quot;$f1&quot; -ef &quot;$f2&quot; ] ! “not” – reverses the sense of the tests above (returns true if condition absent). pairwise-compare with if loop © Ole Tange; 2018 for i in *.txt ; do for j in *.txt ; do if [ &quot;$i&quot; '&lt;' &quot;$j&quot; ] ; then echo &quot;Pairs $i and $j&quot; fi donedone 字符串判断 ##https://blog.csdn.net/Primeprime/article/details/79625306strA=&quot;long string&quot;strB=&quot;string&quot;result=$(echo $strA | grep &quot;${strB}&quot;)if [[ &quot;$result&quot; != &quot;&quot; ]]then echo &quot;包含&quot;else echo &quot;不包含&quot;fi while while [ expression ]do Statement(s) to be executed if expression is truedone try reference:筱光 { # try command1 #save your output} || { # except # save log for exception}","link":"/2020/06/26/Linux/while-if-case/"},{"title":"Text Animation in Python","text":"Animation-Text class Signal: # &lt;1&gt; go = Truedef spin(msg, signal): # &lt;2&gt; write, flush = sys.stdout.write, sys.stdout.flush for char in itertools.cycle('|/-\\\\'): # &lt;3&gt; status = char + ' ' + msg write(status) flush() time.sleep(.1) write('\\x08' * len(status)) # &lt;4&gt; if not signal.go: break write(' ' * len(status) + '\\x08' * len(status)) # &lt;6&gt;def slow_function(): # &lt;7&gt; # pretend waiting a long time for I/O time.sleep(3) # &lt;8&gt; return 42def supervisor(): # &lt;9&gt; signal = Signal() spinner = threading.Thread(target=spin, args=('thinking!', signal)) print('spinner object:', spinner) # &lt;10&gt; spinner.start() # &lt;11&gt; result = slow_function() # &lt;12&gt; signal.go = False # &lt;13&gt; spinner.join() # &lt;14&gt; return resultdef main(): result = supervisor() # &lt;15&gt; print('Answer:', result)if __name__ == '__main__': main() PaddleGAN python -m pip install munch scikit-imagepython -m pip install paddlepaddle-gpu==2.2.2 import paddle#paddle.set_device('cpu')paddle.set_device('gpu')from ppgan.apps import DeOldifyPredictordeoldify = DeOldifyPredictor()pred = deoldify.run_image(&quot;/mnt/8A26661926660713/Deng/Cell_segmentation/lgl4wd5d1_c2.tif&quot;)pred.save('deoldify_result.jpg') $$\\frac{r_C×C +rG×G}{(1-r_{CG})(C+G)}=r_T$$ $C=53012;\\ r_C=38.27%$ $G=19742.5;\\ r_G=13%$ $TM=73304;\\ r_{T}=36.7%$ $r_{CG}=10.725%$ $(G+C)*(1-r_{CG})=64951.58$ $\\frac{38.27%×53012 + 13%19742.5}{(1-10.725%)(53012+19742.5)}≈38.811%$","link":"/2020/06/22/Python/Animation-Text/"},{"title":"Basmap","text":"Basmap 0. Install 教程推薦: 官方文檔 moxigandashu 2017 往下看我的(系統:Deepin 15.11) 1. Dependency: python pip install: Matplotlib NumPy GeobricksProj4ToEPSG pyproj pyshp geos sudo apt install libgeos-3.6.2 sudo apt install libgeos-dev Install from the source Release：WeatherGod 百度網盤: 2tue mkdir Basemapcd Basmapwget -c https://github.com/matplotlib/basemap/archive/v1.1.0.tar.gz## ummmmm... 126m， 我下載的時候... 有點大， 優點慢， 自己想辦法把## 給個百度雲鏈接把，我。 100kb，總比50kb的瀏覽器速度要好把tar -zxvf basemap-1.1.0.tar.gzcd basemap-1.1.0cd geos-3.3.3export GEOS_DIR=$(pwd)./configure --prefix=$GEOS_DIRmake; make install 報錯 ../../../include/geos/geom/Coordinate.inl:39:10: error: 'ISNAN' was not declared in this scope return (ISNAN(x) &amp;&amp; ISNAN(y) &amp;&amp; ISNAN(z)); 解決： VeRo 找到platform.h把24行的/* #undef HAVE_ISNAN */替換成： #define HAVE_ISNAN 1 (&quot;#&quot;號不能丟) 我直接用sed替換了: sed -i 's=/\\* #undef HAVE_ISNAN \\*/=#define HAVE_ISNAN 1=' ./include/geos/platform.h make 要蠻久， 慢慢等把 sudo make install 以後， 退到上一級目錄 python setup.py install 又報錯： src/_geoslib.c:5552:21: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_type’; did you mean ‘curexc_type’? sudo pip3.7 install cpython 更具jonathanunderwood在github帖子中的解釋， 是應爲python3.7不適配的原因。我直接用python2.7安裝成功了。 不過，後面在導入包的時候，又有function問題- -我放棄了 嘿嘿嘿 還是用leaft把","link":"/2020/01/22/Python/BaseMap/"},{"title":"Python 3D Plot","text":"Plot a ball import numpy as npimport matplotlib.pyplot as pltfrom mpl_toolkits.mplot3d import Axes3D# Generate random points on the surface of a unit spherenp.random.seed(123)n_points = 500theta = np.random.uniform(0, 2 * np.pi, size=n_points)phi = np.random.uniform(0, np.pi, size=n_points)x = np.sin(phi) * np.cos(theta)y = np.sin(phi) * np.sin(theta)z = np.cos(phi)# Plot the points on a 3D scatter plotfig = plt.figure()ax = fig.add_subplot(111, projection='3d')ax.scatter(x, y, z, s=50)# Connect the dots to the center of the ballcenter = np.array([0, 0, 0])for i in range(n_points): point = np.array([x[i], y[i], z[i]]) ax.plot([center[0], point[0]], [center[1], point[1]], [center[2], point[2]], 'k--', alpha=0.3)# Set axis limits and labelsax.set_xlim([-1, 1])ax.set_ylim([-1, 1])ax.set_zlim([-1, 1])ax.set_xlabel('X')ax.set_ylabel('Y')ax.set_zlabel('Z')plt.show() In this code, we first generate random points on the surface of a unit sphere using the numpy.random.uniform function. Then we plot these points on a 3D scatter plot using matplotlib. Finally, we connect each point to the center of the sphere using a black dotted line with ax.plot. The center of the sphere is defined as [0, 0, 0]. Add a plate to slice the dots how to plot a surface import numpy as npimport matplotlib.pyplot as pltfrom mpl_toolkits.mplot3d import Axes3Dfig = plt.figure()ax = fig.add_subplot(111, projection='3d')# Generate some data for the plotx, y = np.meshgrid(np.arange(-5, 5, 0.5), np.arange(-5, 5, 0.5))z = np.zeros(x.shape)# Create the plane surfaceax.plot_surface(x, y, z, alpha=0.5, color='blue')# Plot some 3D pointsxs = np.random.normal(size=50)ys = np.random.normal(size=50)zs = np.random.normal(size=50)ax.scatter(xs, ys, zs)plt.show() In this code, we first create a figure and a subplot with a 3D projection. Then, we generate some data for the surface plane using numpy.meshgrid(). We set the z values to zero so that the plane is on the xy plane. We then create the plane surface using Axes3D.plot_surface() function. The alpha parameter sets the transparency of the surface and the color parameter sets its color. Finally, we plot some 3D points using the Axes3D.scatter() function. When you run this code, you should see a 3D plot with a transparent blue plane surface and some randomly scattered 3D points. Slice the ball with the surface import numpy as npimport matplotlib.pyplot as pltfrom mpl_toolkits.mplot3d import Axes3D# Generate random points on the surface of a unit spherenp.random.seed(123)n_points = 500theta = np.random.uniform(0, 2 * np.pi, size=n_points)phi = np.random.uniform(0, np.pi, size=n_points)x = np.sin(phi) * np.cos(theta)y = np.sin(phi) * np.sin(theta)z = np.cos(phi)# Plot the points on a 3D scatter plotfig = plt.figure()ax = fig.add_subplot(111, projection='3d')ax.scatter(x, y, z, s=50)# Connect the dots to the center of the ballcenter = np.array([0, 0, 0])for i in range(n_points): point = np.array([x[i], y[i], z[i]]) ax.plot([center[0], point[0]], [center[1], point[1]], [center[2], point[2]], 'k--', alpha=0.3)# Set axis limits and labelsax.set_xlim([-1, 1])ax.set_ylim([-1, 1])ax.set_zlim([-1, 1])ax.set_xlabel('X')ax.set_ylabel('Y')ax.set_zlabel('Z')# Add platex, y = np.meshgrid(np.arange(-1, 1.5, 0.5), np.arange(-1, 1.5, 0.5))z = np.zeros(x.shape)# Create the plane surfaceax.plot_surface(x, y, z + .7, alpha=0.5, color='steelblue')ax.plot_surface(x, y, z +.75, alpha=0.5, color='red')ax.plot_surface(x, y, z + .8, alpha=0.5, color='steelblue')plt.show() pre { background-color:#38393d; color: #5fd381; }","link":"/2023/03/07/Python/3dball/"},{"title":"Sanger Sequencing (abi) Plot (Biopython)","text":"Sanger Sequencing Plot (Biopython + Matplotlib) Quick Start from Bio import SeqIOimport matplotlib.pyplot as pltfrom collections import defaultdict## Abi Fileabi_file = &quot;D10.1.F.YP13033649.D10.S7695.ab1&quot;record = SeqIO.read(abi_file, &quot;abi&quot;)channels = [&quot;DATA1&quot;, &quot;DATA2&quot;, &quot;DATA3&quot;, &quot;DATA4&quot;]trace = defaultdict(list)for c in channels: trace[c] = record.annotations[&quot;abif_raw&quot;][c]plt.plot(trace[&quot;DATA2&quot;], color=&quot;green&quot; ,alpha=0.6, lw=0.2) # Aplt.plot(trace[&quot;DATA4&quot;], color=&quot;blue&quot; ,alpha=0.6, lw=0.2) # Cplt.plot(trace[&quot;DATA1&quot;], color=&quot;black&quot; ,alpha=0.6, lw=0.2) # Gplt.plot(trace[&quot;DATA3&quot;], color=&quot;red&quot; ,alpha=0.6, lw=0.2) # Tplt.title(record.annotations['abif_raw']['TUBE1'])plt.show() Script for Results of 96-wells plate abi_plot.py ##!/usr/bin/env python3import argparseparser = argparse.ArgumentParser()parser.add_argument('-i','-I','--input') #输入文件parser.add_argument('-o','-O','--output', default=&quot;out.png&quot;) #输入文件##获取参数args = parser.parse_args()INPUT = args.inputOUTPUT = args.output##########import osimport matplotlib as mplimport matplotlib.pyplot as pltfrom Bio import SeqIOfrom collections import defaultdictdef raw_plot(INPUT): record = SeqIO.read(INPUT, &quot;abi&quot;) channels = [&quot;DATA1&quot;, &quot;DATA2&quot;, &quot;DATA3&quot;, &quot;DATA4&quot;] trace = defaultdict(list) for c in channels: trace[c] = record.annotations[&quot;abif_raw&quot;][c] plt.plot(trace[&quot;DATA2&quot;], color=&quot;green&quot; ,alpha=0.6, lw=0.2) # A plt.plot(trace[&quot;DATA4&quot;], color=&quot;blue&quot; ,alpha=0.6, lw=0.2) # C plt.plot(trace[&quot;DATA1&quot;], color=&quot;black&quot; ,alpha=0.6, lw=0.2) # G plt.plot(trace[&quot;DATA3&quot;], color=&quot;red&quot; ,alpha=0.6, lw=0.2) # T plt.title(record.annotations['abif_raw']['TUBE1']) #plt.show()Cmd = &quot;ls &quot;+ str(INPUT)LIST = os.popen(Cmd).read().split(&quot;\\n&quot;)[:-1]print(LIST)plt.figure(figsize=(14*3, 8*3))plt.ion()for i in range(96): plt.subplot(8,12,i+1) abi = INPUT+&quot;/&quot;+LIST[i] print(abi) raw_plot(abi)plt.show()plt.savefig(OUTPUT) Usage: abi_plot.py -i 96Well_Result Box plot It is useful when all abi files are plasmid or long sequencing result. Box plot def raw_box_plot(INPUT): record = SeqIO.read(INPUT, &quot;abi&quot;) channels = [&quot;DATA1&quot;, &quot;DATA2&quot;, &quot;DATA3&quot;, &quot;DATA4&quot;] trace = [] for c in channels: trace += record.annotations[&quot;abif_raw&quot;][c][2500:15000] plt.boxplot(trace) # A plt.axis([0,2,0,600]) plt.title(record.annotations['abif_raw']['TUBE1']) plt.show() import osimport matplotlib as mplimport matplotlib.pyplot as pltfrom Bio import SeqIOINPUT = &quot;96Well_Result&quot;Cmd = &quot;ls &quot;+ str(INPUT)LIST = os.popen(Cmd).read().split(&quot;\\n&quot;)[:-1]trace = []for i in range(96): abi = INPUT+&quot;/&quot;+LIST[i] record = SeqIO.read(abi, &quot;abi&quot;) channels = [&quot;DATA1&quot;, &quot;DATA2&quot;, &quot;DATA3&quot;, &quot;DATA4&quot;] for c in channels: trace += record.annotations[&quot;abif_raw&quot;][c][2500:15000]trace2 = []for i in range(18): abi = INPUT+&quot;/&quot;+LIST[i] record = SeqIO.read(abi, &quot;abi&quot;) channels = [&quot;DATA1&quot;, &quot;DATA2&quot;, &quot;DATA3&quot;, &quot;DATA4&quot;] for c in channels: trace2 += record.annotations[&quot;abif_raw&quot;][c][2500:15000]trace3 = []for i in range(18,96): abi = INPUT+&quot;/&quot;+LIST[i] record = SeqIO.read(abi, &quot;abi&quot;) channels = [&quot;DATA1&quot;, &quot;DATA2&quot;, &quot;DATA3&quot;, &quot;DATA4&quot;] for c in channels: trace3 += record.annotations[&quot;abif_raw&quot;][c][2500:15000]plt.boxplot([trace, trace2, trace3])plt.axis([0,4,0,600])","link":"/2020/11/29/Python/Bio_SSP/"},{"title":"Change the Citation Format by Python","text":"import jsondef BibTeX_Dic(X): X = X.replace(&quot;@article&quot;, &quot;&quot;) Cite_id = X[:X.find(&quot;,&quot;)].replace(&quot;{&quot;,&quot;&quot;) X = X.replace(Cite_id+&quot;, &quot;,&quot;&quot;) X = X.replace(&quot;={&quot;,'&quot;:&quot;').replace(&quot;}, &quot;, '&quot;, &quot;')[:-2] X = '{&quot;' + X[1:-1] + '&quot;}' Cite_P = json.loads(X) Cite_P['author'] = Cite_P['author'].split(&quot; and &quot;) Cite_P['pages'] = Cite_P['pages'].split(&quot;--&quot;) return Cite_PX = &quot;@article{sun1960analysis, title={Analysis of joint action of insecticides against house flies}, author={Sun, Yun-Pei and Johnson, EoRo}, journal={Journal of economic entomology}, volume={53}, number={5}, pages={887--892}, year={1960}, publisher={Oxford University Press Oxford, UK} }&quot;Cite_P = BibTeX_Dic(X)Format = &quot;MLA&quot;if Format == &quot;MLA&quot;: Author = &quot;, and &quot;.join([i for i in Cite_P['author']]) Result = [Author + '. &quot;' + Cite_P['title'] +'.&quot; ' + Cite_P['journal'] + &quot; &quot; + Cite_P['volume'] +&quot;.&quot;+ Cite_P['number'] + &quot; (&quot;+ Cite_P['year']+&quot;): &quot;+ Cite_P['pages'][0] +&quot;-&quot;+ Cite_P['pages'][1] ]print(Result[0])Format = &quot;APA&quot;if Format == &quot;APA&quot;: Author = [] for i in Cite_P['author']: # chinese name with &quot;-&quot;: N_fam = i.split(&quot;, &quot;)[0] N_giv = i.split(&quot;, &quot;)[1] if &quot;-&quot; in i: N_giv = &quot; &quot;.join([i[0]+&quot;.&quot; for i in N_giv.split(&quot;-&quot;)]) Author += [N_fam +&quot;, &quot;+N_giv] elif &quot; &quot; not in N_giv: Author += [N_fam +&quot;, &quot;+N_giv[0]+&quot;.&quot;] Result = [&quot;, &amp; &quot;.join(Author) + &quot; (&quot; + Cite_P['year'] + '). &quot;'+ Cite_P['title'] + '.&quot; ' + Cite_P['journal'] + &quot;, &quot;+ Cite_P['volume'] +&quot;(&quot;+ Cite_P['number'] + &quot;), &quot;+ Cite_P['pages'][0] +&quot;-&quot;+ Cite_P['pages'][1] ]print(Result[0])","link":"/2021/01/22/Python/Citation_format/"},{"title":"Encode &amp; decode in Python","text":"Encode&amp;decode gb2312 =?gb2312?b?1cq7p9Lss6O1x8K8u+62rw==?= base64.b64decode(&quot;1cq7p9Lss6O1x8K8u+62rw==&quot;).decode(&quot;GBK&quot;) 结果： ‘帐户异常登录活动’","link":"/2020/01/22/Python/Encode_decode/"},{"title":"Crawler (爬虫)","text":"Crawler (爬虫) 1. Quick Start Crawler img location sites from National Geographic web site &amp; downloading them. from bs4 import BeautifulSoupfrom urllib.request import urlopenimport reimport requests## Starting resuqesthtml = urlopen(&quot;http://www.nationalgeographic.com.cn/animals/&quot;).read().decode('utf-8')soup = BeautifulSoup(html, features='lxml')img_links = soup.find_all(&quot;img&quot;, {&quot;src&quot;: re.compile('http://image..*?\\.jpg')})for link in img_links: print(link['src']) # pic locationg ## With adding this## mkdir img # 创建一个img文件夹for link in img_links: print(link['src']) if link['src'][0:4] == 'http': url = link['src'] r = requests.get(url, stream=True) image_name = url.split('/')[-1] with open('./img/%s' % image_name, 'wb') as f: for chunk in r.iter_content(chunk_size=128): f.write(chunk) print('Saved %s' % image_name) Running result: 实战案例: 科技快讯","link":"/2020/01/22/Python/Crawler/"},{"title":"HTML server | Python","text":"PYTHONpython3 -m http.server 8000 --bind 127.0.0.1","link":"/2020/01/22/Python/HTML-server/"},{"title":"Biopython Introduction for Newbies","text":"Biopython 1. Quick Start from Bio.Seq import reverse_complement, transcribe, back_transcribe, translate## echo a seqmy_string = &quot;GCTGTTATGGGTCGTTGGAAGGGTGGTCGTGCTGCTGGTTAG&quot;##Revers complementreverse_complement(my_string)## { 'CTAACCAGCAGCACGACCACCCTTCCAACGACCCATAACAGC' }##DNA to RNAtranscribe(my_string)##--&gt; { 'GCUGUUAUGGGUCGUUGGAAGGGUGGUCGUGCUGCUGGUUAG' }##RNA to DNAback_transcribe(my_string) --&gt; { 'GCTGTTATGGGTCGTTGGAAGGGTGGTCGTGCTGCTGGTTAG' }##DNA to protinetranslate(my_string) --&gt; { 'AVMGRWKGGRAAG*' } 2. Sequences 2.1 reading FASTA file from Bio import SeqIOSeq1='GSE44995_Reference_assembled_isotig_seq.fna'for seq_record in SeqIO.parse(Seq1, &quot;fasta&quot;): print(seq_record.id) print(repr(seq_record.seq)) print(len(seq_record.seq))## print by fasta formateSeq10=''for seq_record in SeqIO.parse(Seq1, &quot;fasta&quot;): if len(seq_record.seq) &lt; 100: Seq10 += &quot;&gt;&quot;+str(seq_record.id)+&quot;\\n&quot; Seq10 += str(seq_record.seq)+&quot;\\n&quot; print(seq_record.id) print(repr(seq_record.seq)) print(len(seq_record.seq)) 2.2 Seq run as string from Bio.Seq import Seqfrom Bio.Alphabet import IUPACmy_seq = Seq(&quot;GATCG&quot;, IUPAC.unambiguous_dna)for index, letter in enumerate(my_seq): print(&quot;%i %s&quot; % (index, letter))'''print result0 G1 A2 T3 C4 G'''print(my_seq[0]) #/ print(my_seq[-1])Seq(&quot;AAAA&quot;).count(&quot;AA&quot;)len(my_seq)## convert to strmy_seq = str(my_seq) ### 2.3 GC caculate from Bio.Seq import Seqfrom Bio.Alphabet import IUPACfrom Bio.SeqUtils import GCmy_seq = Seq(&quot;GATCGATGGGCCTATATAGGATCGAAAATCGC&quot;, IUPAC.unambiguous_dna)GC(my_seq)##Result##46.875 2.4 Slicing a sequence my_seq[4:12]#####the first, second and third codon positions of this DNA sequence:#####my_seq[0::3] # Seq('GCTGTAGTAAG', IUPACUnambiguousDNA())my_seq[1::3] # Seq('AGGCATGCATC', IUPACUnambiguousDNA())my_seq[2::3] # Seq('TAGCTAAGAC', IUPACUnambiguousDNA()) 2.5 revers string my_seq = my_seq[::-1] 2.6 Changing Font case from Bio.Seq import Seqfrom Bio.Alphabet import generic_dnadna_seq = Seq(&quot;acgtACGT&quot;, generic_dna)dna_seq.upper() --&gt; {Seq('ACGTACGT', DNAAlphabet())}dna_seq.lower() --&gt; {Seq('acgtacgt', DNAAlphabet())} 3 Bio-information 3.1 Revers Complement my_seq.reverse_complement()Seq(&quot;ACGTCGTAGCTAC&quot;).complement() # standard example =&gt; output: Seq('TGCAGCATCGATG')Seq(&quot;ACGTCGTAGCTAC&quot;).reverse_complement() # output =&gt; Seq('GTAGCTACGACGT') 3.2 Translation from Bio.Seq import Seqfrom Bio.Alphabet import IUPACSeq(&quot;UUU&quot;, IUPAC.unambiguous_rna).translate() # for RNASeq(&quot;TTT&quot;, IUPAC.unambiguous_dna).translate() # for DNA 3.3 Translation Tables from Bio.Data import CodonTablestandard_table = CodonTable.unambiguous_dna_by_name['Standard']mito_table = CodonTable.unambiguous_dna_by_name['Vertebrate Mitochondrial']##same as:standard_table = CodonTable.unambiguous_dna_by_id[1]mito_table = CodonTable.unambiguous_dna_by_id[2]mito_table.stop_codons #--&gt; { ['TAA', 'TAG', 'AGA', 'AGG'] }mito_table.start_codons # --&gt; { ['ATT', 'ATC', 'ATA', 'ATG', 'GTG'] }mito_table.forward_table[&quot;ACG&quot;] #--&gt; { 'T' }print(standard_table) | T | C | A | G | --+---------+---------+---------+---------+-- T | TTT F | TCT S | TAT Y | TGT C | T T | TTC F | TCC S | TAC Y | TGC C | C T | TTA L | TCA S | TAA Stop| TGA Stop| A T | TTG L(s)| TCG S | TAG Stop| TGG W | G --+---------+---------+---------+---------+-- C | CTT L | CCT P | CAT H | CGT R | T C | CTC L | CCC P | CAC H | CGC R | C C | CTA L | CCA P | CAA Q | CGA R | A C | CTG L(s)| CCG P | CAG Q | CGG R | G --+---------+---------+---------+---------+-- A | ATT I | ACT T | AAT N | AGT S | T A | ATC I | ACC T | AAC N | AGC S | C A | ATA I | ACA T | AAA K | AGA R | A A | ATG M(s)| ACG T | AAG K | AGG R | G --+---------+---------+---------+---------+-- G | GTT V | GCT A | GAT D | GGT G | T G | GTC V | GCC A | GAC D | GGC G | C G | GTA V | GCA A | GAA E | GGA G | A G | GTG V | GCG A | GAG E | GGG G | G --+---------+---------+---------+---------+-- 4. Alignment 1. Echo a test file ## run in bashecho &quot;&gt;TRINITY_DN106095_c2_g1_i2MSRIMKVFLFLAVMVCISEAQLHAQCLCPRVRSRISSMTDIREVQIYEATIFCDRMEIVVTNDSGLRYCLNPKLKAVQKLLTAMKPKTSTTARPTVHSSSTGSTNTARM&gt;TRINITY_DN92154_c0_g1_i1DIHVRRRTLTRSKTLGRSTNVNKMKLCILLMLGTLLVLVYGMPPISRDYNTHCRCLQVESRIIPPNSLKSIKLVPEGPHCPDMEVIAGLSNGEKVCLNPRSSWVKKLVNFVLEKQQGGALPKNQGQ&quot; &gt; test.fa 2. Align ## run in pythonfrom Bio import pairwise2from Bio.Seq import Seqfrom Bio.pairwise2 import format_alignmentfrom Bio.SubsMat import MatrixInfoseq1 = Seq(&quot;MSRIMKVFLFLAVMVCISEAQLHAQCLCPRVRSRISSMTDIREVQIYEATIFCDRMEIVVTNDSGLRYCLNPKLKAVQKLLTAMKPKTSTTARPTVHSSSTGSTNTARM&quot;)seq2 = Seq(&quot;DIHVRRRTLTRSKTLGRSTNVNKMKLCILLMLGTLLVLVYGMPPISRDYNTHCRCLQVESRIIPPNSLKSIKLVPEGPHCPDMEVIAGLSNGEKVCLNPRSSWVKKLVNFVLEKQQGGALPKNQGQ&quot;)alignments = pairwise2.align.globalxx(seq1, seq2)test_alignments = pairwise2.align.localds(seq1, seq2, MatrixInfo.blosum62, -10, -1)for alignment in alignments: print(format_alignment(*alignment))for alignment in test_alignments: print(format_alignment(*alignment)) SingleLetterAlphabet() alignment with 6 rows and 65 columns MQNTPAERLPAIIEKAKSKHDINVWLLDRQGRDLLEQRVPAKVA...EGP B7RZ31_9GAMM/59-123 AKQRGIAGLEEWLHRLDHSEAIPIFLIDEAGKDLLEREVPADIT...KKP A0A0C3NPG9_9PROT/58-119 ARRHGQEYFQQWLERQPKKVKEQVFAVDQFGRELLGRPLPEDMA...KKP A0A143HL37_9GAMM/57-121 TRRHGPESFRFWLERQPVEARDRIYAIDRSGAEILDRPIPRGMA...NKP A0A0X3UC67_9GAMM/57-121 AINRNTQQLTQDLRAMPNWSLRFVYIVDRNNQDLLKRPLPPGIM...NRK B3PFT7_CELJU/62-126 AVNATEREFTERIRTLPHWARRNVFVLDSQGFEIFDRELPSPVA...NRT K4KEM7_SIMAS/61-125 Quick Alignment from Bio import pairwise2from Bio.pairwise2 import format_alignmentalignments = pairwise2.align.globalxx(&quot;ACCGT&quot;, &quot;ACG&quot;)print(format_alignment(*alignments[0])) ACCGT | || A-CG- Score=3 PDB file Split the chain from PDF file Cite: David Cain import osfrom Bio import PDBclass ChainSplitter: def __init__(self, out_dir=None): &quot;&quot;&quot; Create parsing and writing objects, specify output directory. &quot;&quot;&quot; self.parser = PDB.PDBParser() self.writer = PDB.PDBIO() if out_dir is None: out_dir = os.path.join(os.getcwd(), &quot;chain_PDBs&quot;) self.out_dir = out_dir def make_pdb(self, pdb_path, chain_letters, overwrite=False, struct=None): &quot;&quot;&quot; Create a new PDB file containing only the specified chains. Returns the path to the created file. :param pdb_path: full path to the crystal structure :param chain_letters: iterable of chain characters (case insensitive) :param overwrite: write over the output file if it exists &quot;&quot;&quot; chain_letters = [chain.upper() for chain in chain_letters] # Input/output files (pdb_dir, pdb_fn) = os.path.split(pdb_path) pdb_id = pdb_fn[3:7] out_name = &quot;pdb%s_%s.ent&quot; % (pdb_id, &quot;&quot;.join(chain_letters)) out_path = os.path.join(self.out_dir, out_name) print (&quot;OUT PATH:&quot;,out_path) plural = &quot;s&quot; if (len(chain_letters) &gt; 1) else &quot;&quot; # for printing # Skip PDB generation if the file already exists if (not overwrite) and (os.path.isfile(out_path)): print(&quot;Chain%s %s of '%s' already extracted to '%s'.&quot; % (plural, &quot;, &quot;.join(chain_letters), pdb_id, out_name)) return out_path print(&quot;Extracting chain%s %s from %s...&quot; % (plural, &quot;, &quot;.join(chain_letters), pdb_fn)) # Get structure, write new file with only given chains if struct is None: struct = self.parser.get_structure(pdb_id, pdb_path) self.writer.set_structure(struct) self.writer.save(out_path, select=SelectChains(chain_letters)) return out_pathclass SelectChains(PDB.Select): &quot;&quot;&quot; Only accept the specified chains when saving. &quot;&quot;&quot; def __init__(self, chain_letters): self.chain_letters = chain_letters def accept_chain(self, chain): return (chain.get_id() in self.chain_letters)if __name__ == &quot;__main__&quot;: &quot;&quot;&quot; Parses PDB id's desired chains, and creates new PDB structures. &quot;&quot;&quot; import sys if not len(sys.argv) == 2: print( &quot;Usage: $ python %s 'pdb.txt'&quot; % __file__) sys.exit() pdb_textfn = sys.argv[1] pdbList = PDB.PDBList() splitter = ChainSplitter(&quot;&quot;) # Change me. with open(pdb_textfn) as pdb_textfile: for line in pdb_textfile: pdb_id = line[:4].lower() chain = line[4] pdb_fn = pdbList.retrieve_pdb_file(pdb_id) splitter.make_pdb(pdb_fn, chain) Another example: This one works fine for me from Bio.PDB import Select, PDBIOfrom Bio.PDB.PDBParser import PDBParserimport syspdb_file = sys.argv[1]class ChainSelect(Select): def __init__(self, chain): self.chain = chain def accept_chain(self, chain): if chain.get_id() == self.chain: return 1 else: return 0chains = ['A','B','C']p = PDBParser(PERMISSIVE=1) structure = p.get_structure(pdb_file, pdb_file)for chain in chains: pdb_chain_file = 'pdb_file_chain_{}.pdb'.format(chain) io_w_no_h = PDBIO() io_w_no_h.set_structure(structure) io_w_no_h.save('{}'.format(pdb_chain_file), ChainSelect(chain)) Extract fasta from PDB file import sysfrom Bio import SeqIOPDBFile = sys.argv[1]with open(PDBFile, 'r') as pdb_file: for record in SeqIO.parse(pdb_file, 'pdb-atom'): print('&gt;' + record.id) print(record.seq) pre { background-color:#38393d; color: #5fd381; }","link":"/2020/01/22/Python/Biopython/"},{"title":"What can kivy do","text":"PDF Input Management Touch down, up, move Double/Triple Tap Touch Shape Gesture Joystick events!!! (游戏手柄) Widgets Traversing the Tree Z index • floatlayout • boxlayout • gridlayout • stacklayout • relativelayout • anchorlayout • Nesting Layout Size: pt, mm, cm, inch, dp, and sp Screen Separation: Screen Manager ScreenManager: set classes TransitionBase: transit from one to another Graphics Canvas: drawing board Context (change the results of the vertex) Vertex Android API Plyer; Pyjnius; android module","link":"/2020/12/03/Python/Kivy_document/"},{"title":"Kivy examples: bubble","text":"example from document '''Bubble======Test of the widget Bubble.'''from kivy.app import Appfrom kivy.uix.floatlayout import FloatLayoutfrom kivy.uix.button import Buttonfrom kivy.lang import Builderfrom kivy.uix.bubble import BubbleBuilder.load_string('''&lt;cut_copy_paste&gt; size_hint: (None, None) size: (160, 120) pos_hint: {'center_x': .5, 'y': .6} BubbleButton: text: 'Cut' BubbleButton: text: 'Copy' BubbleButton: text: 'Paste'''')class cut_copy_paste(Bubble): passclass BubbleShowcase(FloatLayout): def __init__(self, **kwargs): super(BubbleShowcase, self).__init__(**kwargs) self.but_bubble = Button(text='Press to show bubble') self.but_bubble.bind(on_release=self.show_bubble) self.add_widget(self.but_bubble) def show_bubble(self, *l): if not hasattr(self, 'bubb'): self.bubb = bubb = cut_copy_paste() self.add_widget(bubb) else: values = ('left_top', 'left_mid', 'left_bottom', 'top_left', 'top_mid', 'top_right', 'right_top', 'right_mid', 'right_bottom', 'bottom_left', 'bottom_mid', 'bottom_right') index = values.index(self.bubb.arrow_pos) self.bubb.arrow_pos = values[(index + 1) % len(values)]class TestBubbleApp(App): def build(self): return BubbleShowcase()if __name__ == '__main__': TestBubbleApp().run() Show bubble when touch the Input box origin source: ikolim, stackoverflow from kivy.app import Appfrom kivy.uix.floatlayout import FloatLayoutfrom kivy.uix.bubble import Bubble, BubbleButtonfrom kivy.uix.label import Labelfrom kivy.properties import ObjectPropertyfrom kivy.lang import BuilderClipboard = Nonefrom kivy.core.clipboard import Clipboardfrom kivy.clock import Clockimport timeclass CustomBubbleButton(BubbleButton): passclass NumericKeyboard(Bubble): layout = ObjectProperty(None) def __init__(self, **kwargs): super(NumericKeyboard, self).__init__(**kwargs) self.create_bubble_button() def create_bubble_button(self): numeric_keypad = [Clipboard.paste()] for x in numeric_keypad: if len(x) == 0: self.layout.add_widget(Label(text=&quot;&quot;)) else: bubb_btn = CustomBubbleButton(text=str(x)) self.layout.add_widget(bubb_btn) #Clock.schedule_once(self.REMOVE, 1) #self.layout.add_widget(bubb_btn)class BubbleShowcase(FloatLayout): text_input = ObjectProperty(None) def REMOVE(self, dt): self.remove_widget(self.bubb) #print('12') def show_bubble(self, *l): # If you annotate this line, the wedge would survive from self.REMOVE by clicking the bubble. if not hasattr(self, 'bubb'): self.bubb = bubb = NumericKeyboard() self.bubb.arrow_pos = &quot;bottom_mid&quot; self.add_widget(self.bubb) # close the bubble after 3s Clock.schedule_once(self.REMOVE, 3) #self.remove_widget(self.bubb)Builder.load_file(&quot;test.kv&quot;)class TestBubbleApp(App): title = &quot;Numeric Key Pad - Using Bubble&quot; def build(self): return BubbleShowcase()if __name__ == '__main__': TestBubbleApp().run() test.kv ##:kivy 1.10.0&lt;CustomBubbleButton&gt;: on_release: app.root.text_input.text += self.text&lt;NumericKeyboard&gt;: layout: layout size_hint: (None, None) size: (160, 120) pos_hint: {'center_x': .5, 'y': .6} GridLayout: id: layout cols: 3&lt;BubbleShowcase&gt;: text_input: text_input canvas: Color: rgba: 0, 1, 1, 1 Rectangle: size: self.width, self.height TextInput: id: text_input pos_hint: {'center_x': .5, 'y': .54} size_hint: (0.2, 0.06) cursor_blink: True font_size: 20 multiline: False on_focus: root.show_bubble() So, by setting the clock, it could automatically vanished.","link":"/2020/12/16/Python/Kivy_bubble/"},{"title":"Kivy examples: smooth line","text":"Document Quick Start By copy the codes from the document, you are supposed being able to show the line on the screen and adjust the alpha, width, etc of the line. ListProperty([(500, 500), [300, 300, 500, 300], [500, 400, 600, 400]]) As you can see above, you can envelope the points by () or [], you can line the points one by one or line them all together if you wish (The examples show down below). ListProperty([(500, 500), [300, 300], [500, 300], [500, 400], [600, 400]])```pythonor```pythonListProperty([500, 500, 300, 300, 500, 300, 500, 400, 600, 400]) The minimal codes you’ve to keep is: from kivy.app import Appfrom kivy.uix.floatlayout import FloatLayoutfrom kivy.lang import BuilderBuilder.load_string('''&lt;LinePlayground&gt;: # assign a list variate as point so it could be easliy handled in later point: [0,0, 200, 100] canvas: Color: rgba: .4, .4, 1, 1 Line: # recall the variate 'point' above points: self.point''')class LinePlayground(FloatLayout): passclass TestLineApp(App): def build(self): return LinePlayground()if __name__ == '__main__': TestLineApp().run() updating the line If you are not satisfied with drawing a line and want to create an animation, than like do some thing cool. updating… from kivy.app import Appfrom kivy.properties import ListPropertyfrom kivy.uix.floatlayout import FloatLayoutfrom kivy.uix.widget import Widgetfrom kivy.lang import Builderfrom kivy.clock import Clockfrom kivy.properties import ObjectProperty## Remove unnecessary codes from this classclass LinePlayground(FloatLayout): passclass Main_app(Widget): # assign a numeric variate i = 0 # connect the class in kv file: line -&gt; line_ground -&gt; LinePlayground line = ObjectProperty(None) def update(self, dt): self.i +=1 # update the point self.line.point = [[0,0,], [self.i,self.i]] print(self.line.point) print(self.line) print(&quot;1&quot;)class TestLineApp(App): def build(self): Main = Main_app() # update the result with 60 fps (1/60) Clock.schedule_interval(Main.update,1/60) return Mainif __name__ == '__main__': TestLineApp().run() testline.kv file: &lt;LinePlayground&gt;: # assign a list variate as point so it could be easliy handled in later point: [0,0, 200, 100] canvas: Color: rgba: .4, .4, 1, 1 Line: # recall the variate 'point' above points: self.point&lt;Main_app&gt;: # assign the id which could be recall later line: line_ground LinePlayground: id: line_ground point: [0,10, 100,200]","link":"/2020/12/13/Python/Kivy_sline/"},{"title":"Learn Kivy from Sant: 1","text":"Introduction of kivy: Youtube Vedio Text Tutorial Installation: Skip python: python=3.7.5 is strongly recommended!! If you wants to know why, go to check This blog So, if you want to write an app for windows, linux, IOS, and Android with only one set of code, then, Kivy is the best choice for you. Hello World first, you’d like to import kivy and from kivy.app import App; Then, you’d like from kivy.uix.label import Label so you can add some text Add kivy.require(&quot;1.10.1&quot;) to assign the version of the kivy. (PS: actually, mine is 1.11.1) Then, we can start to class a class EpicApp(App) import kivyfrom kivy.app import Appfrom kivy.uix.label import Label # so you can add some textkviy.require(&quot;1.10.1&quot;) # Assign the version of the kivy so every body would be on the same pageclass EpicApp(App): ''' After class, we'd like to initializing the App''' def build(self): return Label(text=&quot;Hello world&quot;)if __name__ == &quot;__main__&quot;: EpicApp().run() So, it’ll be your first kivy app! It is not interesting at all, actually. So, Let’s move one for GridLayout GridLayout Now, let’s add from kivy.uix.gridlayout import GridLayout to import the Layout style for organizing sort of things; from kivy.uix.textinput import TextInput to add a TextInput box. Now, Our class are becoming more complicated So, during the initiation in build section, we not return to a simple text Label anymore. Let’s say, to return to a class named ConnectPage. And let’s sorting stuff in ConnectPage by GridLayout import kivyfrom kivy.app import Appfrom kivy.uix.label import Labelfrom kivy.uix.gridlayout import GridLayout # one of many layout structuresfrom kivy.uix.textinput import TextInput # allow for ...text input.kivy.require(&quot;1.10.1&quot;)## An actual app is likely to consist of many different## &quot;pages&quot; or &quot;screens.&quot; Inherit from GridLayoutclass ConnectPage(GridLayout): # runs on initialization def __init__(self, **kwargs): # we want to run __init__ of both ConnectPage AAAAND GridLayout super().__init__(**kwargs) self.cols = 2 # used for our grid # widgets added in order, so mind the order. self.add_widget(Label(text='IP:')) # widget #1, top left self.ip = TextInput(multiline=False) # defining self.ip... self.add_widget(self.ip) # widget #2, top right self.add_widget(Label(text='Port:')) self.port = TextInput(multiline=False) self.add_widget(self.port) self.add_widget(Label(text='Username:')) self.username = TextInput(multiline=False) self.add_widget(self.username)class EpicApp(App): def build(self): return ConnectPage()if __name__ == &quot;__main__&quot;: EpicApp().run() And that is what will we get! Awesome, hum? Lesson3 import socketimport errnofrom threading import ThreadHEADER_LENGTH = 10client_socket = None## Connects to the serverdef connect(ip, port, my_username, error_callback): global client_socket # Create a socket # socket.AF_INET - address family, IPv4, some otehr possible are AF_INET6, AF_BLUETOOTH, AF_UNIX # socket.SOCK_STREAM - TCP, conection-based, socket.SOCK_DGRAM - UDP, connectionless, datagrams, socket.SOCK_RAW - raw IP packets client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM) try: # Connect to a given ip and port client_socket.connect((ip, port)) except Exception as e: # Connection error error_callback('Connection error: {}'.format(str(e))) return False # Prepare username and header and send them # We need to encode username to bytes, then count number of bytes and prepare header of fixed size, that we encode to bytes as well username = my_username.encode('utf-8') username_header = f&quot;{len(username):&lt;{HEADER_LENGTH}}&quot;.encode('utf-8') client_socket.send(username_header + username) return True## Sends a message to the serverdef send(message): # Encode message to bytes, prepare header and convert to bytes, like for username above, then send message = message.encode('utf-8') message_header = f&quot;{len(message):&lt;{HEADER_LENGTH}}&quot;.encode('utf-8') client_socket.send(message_header + message)## Starts listening function in a thread## incoming_message_callback - callback to be called when new message arrives## error_callback - callback to be called on errordef start_listening(incoming_message_callback, error_callback): Thread(target=listen, args=(incoming_message_callback, error_callback), daemon=True).start()## Listens for incomming messagesdef listen(incoming_message_callback, error_callback): while True: try: # Now we want to loop over received messages (there might be more than one) and print them while True: # Receive our &quot;header&quot; containing username length, it's size is defined and constant username_header = client_socket.recv(HEADER_LENGTH) # If we received no data, server gracefully closed a connection, for example using socket.close() or socket.shutdown(socket.SHUT_RDWR) if not len(username_header): error_callback('Connection closed by the server') # Convert header to int value username_length = int(username_header.decode('utf-8').strip()) # Receive and decode username username = client_socket.recv(username_length).decode('utf-8') # Now do the same for message (as we received username, we received whole message, there's no need to check if it has any length) message_header = client_socket.recv(HEADER_LENGTH) message_length = int(message_header.decode('utf-8').strip()) message = client_socket.recv(message_length).decode('utf-8') # Print message incoming_message_callback(username, message) except Exception as e: # Any other exception - something happened, exit error_callback('Reading error: {}'.format(str(e)))","link":"/2020/10/28/Python/Kivy_sent1/"},{"title":"Python Machine Learning","text":"Python Machine Learning Random Foret Built-in Feature Importance Row blog is from: Piotr Płoński, 2020 In this practice, we load dataset boston from sklearn.datasets first. All arugments (features) are stored in X and predected results stored in y which is a numpy array. This is the protocol: load dataset boston from sklearn.datasets. Split the dataset into tow parts: Train set and Test set. Run Models Show results import numpy as npimport pandas as pdfrom sklearn.datasets import load_bostonfrom sklearn.model_selection import train_test_splitfrom sklearn.ensemble import RandomForestRegressorfrom sklearn.inspection import permutation_importanceimport shapfrom matplotlib import pyplot as pltplt.rcParams.update({'figure.figsize': (12.0, 8.0)})plt.rcParams.update({'font.size': 14})boston = load_boston()X = pd.DataFrame(boston.data, columns=boston.feature_names)y = boston.targetX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=12)rf = RandomForestRegressor(n_estimators=100)rf.fit(X_train, y_train)sorted_idx = rf.feature_importances_.argsort()plt.barh(boston.feature_names[sorted_idx], rf.feature_importances_[sorted_idx])plt.xlabel(&quot;Random Forest Feature Importance&quot;)plt.show() © Piotr Płoński; 2020 Permutation Based Feature Importance perm_importance = permutation_importance(rf, X_test, y_test)sorted_idx = perm_importance.importances_mean.argsort()plt.barh(boston.feature_names[sorted_idx], perm_importance.importances_mean[sorted_idx])plt.xlabel(&quot;Permutation Importance&quot;) © Piotr Płoński; 2020 Feature Importance Computed with SHAP Values explainer = shap.TreeExplainer(rf)shap_values = explainer.shap_values(X_test)#shap.summary_plot(shap_values, X_test, plot_type=&quot;bar&quot;)shap.summary_plot(shap_values, X_test) © Piotr Płoński; 2020 xgboost Codes PDF (English) sudo pip3.7 install -i https://pypi.tuna.tsinghua.edu.cn/simple sklearnsudo pip3.7 install -i https://pypi.tuna.tsinghua.edu.cn/simple xgboost from sklearn.datasets import load_irisimport xgboost as xgbfrom xgboost import plot_importancefrom matplotlib import pyplot as pltfrom sklearn.model_selection import train_test_split## read in the iris datairis = load_iris()X = iris.datay = iris.targetX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234565)params = { 'booster': 'gbtree', 'objective': 'multi:softmax', 'num_class': 3, 'gamma': 0.1, 'max_depth': 6, 'lambda': 2, 'subsample': 0.7, 'colsample_bytree': 0.7, 'min_child_weight': 3, 'silent': 1, 'eta': 0.1, 'seed': 1000, 'nthread': 4,}plst = params.items()dtrain = xgb.DMatrix(X_train, y_train)num_rounds = 500model = xgb.train(plst, dtrain, num_rounds)## 对测试集进行预测dtest = xgb.DMatrix(X_test)ans = model.predict(dtest)## 计算准确率cnt1 = 0cnt2 = 0for i in range(len(y_test)): if ans[i] == y_test[i]: cnt1 += 1 else: cnt2 += 1print(&quot;Accuracy: %.2f %% &quot; % (100 * cnt1 / (cnt1 + cnt2)))## 显示重要特征plot_importance(model)plt.show()","link":"/2020/09/12/Python/ML/"},{"title":"Learn Kivy from Sant: 3","text":"Introduction of kivy: Youtube Vedio Text Tutorial As you can see, I skipped lesson 2 which is introducing how to add and join a button. Besides, he showed us how to get the input texts from the TextInput In this video, Sant introduced the module of screenmanager from kivy.uix. Main skeleton of the codes: import kivyfrom kivy.app import Appfrom kivy.uix.label import Labelfrom kivy.uix.gridlayout import GridLayout## to use buttons:from kivy.uix.button import Button## to screenfrom kivy.uix.screenmanager import ScreenManager, Screenkivy.require(&quot;1.10.1&quot;)class EpicApp(App):class ConnectPage(GridLayout):class InfoPage(GridLayout):if __name__ == &quot;__main__&quot;: chat_app = EpicApp() chat_app.run() EpicApp() As you can see, there are three classes. In the first class, EpicApp, is the class which manager different screens. class EpicApp(App): def build(self): # We are going to use screen manager, so we can add multiple screens # and switch between them self.screen_manager = ScreenManager() # Initial, connection screen (we use passed in name to activate screen) # First create a page, then a new screen, add page to screen and screen to screen manager self.connect_page = ConnectPage() screen = Screen(name='Connect') screen.add_widget(self.connect_page) self.screen_manager.add_widget(screen) # Info page # Info page was below self.info_page = InfoPage() screen = Screen(name='Info') screen.add_widget(self.info_page) self.screen_manager.add_widget(screen) return self.screen_manager After assigned the screen_manger, we need to assign the “name” and “widget” on each screen; and then, add them into screen_manager As we can see, it loaded the ConnectPage first, and named it as ‘Connect’ which was used to switch the screen later. Who loaded first would be the Home Page. ConnectPage class ConnectPage(GridLayout): # runs on initialization # Our Main Screen def __init__(self, **kwargs): super().__init__(**kwargs) self.cols = 1 # used for our grid self.add_widget(Label(text='Hello World')) # widget #1, top left #self.add_widget(self.ip) # widget #2, top right # add our button. self.join = Button(text=&quot;Try me&quot;) self.join.bind(on_press=self.join_button) self.add_widget(Label()) # just take up the spot. self.add_widget(self.join) def join_button(self, instance): #print(f&quot;Joining {ip}:{port} as {username}&quot;) # Create info string, update InfoPage with a message and show it info = f&quot;You found me&quot; chat_app.info_page.update_info(info) chat_app.screen_manager.current = 'Info' The layout of this page was clearly explained by Sant. And for practicing, I simplified it and remained a line of text and button only. The button is the key to join another screen. The trick of it is create a brand new screen. InfoPage class InfoPage(GridLayout): def __init__(self, **kwargs): super().__init__(**kwargs) # Just one column self.cols = 1 # And one label with bigger font and centered text self.message = Label(halign=&quot;center&quot;, valign=&quot;middle&quot;, font_size=30) # By default every widget returns it's side as [100, 100], it gets finally resized, # but we have to listen for size change to get a new one # more: https://github.com/kivy/kivy/issues/1044 self.message.bind(width=self.update_text_width) # Add text widget to the layout self.add_widget(self.message) # add our button. # Add an return button self.join = Button(text=&quot;return&quot;) self.join.bind(on_press=self.join_button) self.add_widget(Label()) # just take up the spot. self.add_widget(self.join) def join_button(self, instance): #print(f&quot;Joining {ip}:{port} as {username}&quot;) chat_app.screen_manager.current = 'Connect' # Called with a message, to update message text in widget def update_info(self, message): self.message.text = message # Called on label width update, so we can set text width properly - to 90% of label width def update_text_width(self, *_): self.message.text_size = (self.message.width * 0.9, None) In this page, Sant add a function which could update the texts in the screen. So we can print the texts by running chat_app.info_page.update_info(info) before switch to the screen ‘Info’ And personally, I add a return button to back to the home page. Click to see the full version of the code import kivyfrom kivy.app import Appfrom kivy.uix.label import Labelfrom kivy.uix.gridlayout import GridLayout# to use buttons:from kivy.uix.button import Button# to screenfrom kivy.uix.screenmanager import ScreenManager, Screenkivy.require(&quot;1.10.1&quot;)class EpicApp(App): def build(self): # We are going to use screen manager, so we can add multiple screens # and switch between them self.screen_manager = ScreenManager() # Initial, connection screen (we use passed in name to activate screen) # First create a page, then a new screen, add page to screen and screen to screen manager self.connect_page = ConnectPage() screen = Screen(name='Connect') screen.add_widget(self.connect_page) self.screen_manager.add_widget(screen) # Info page # Info page was below self.info_page = InfoPage() screen = Screen(name='Info') screen.add_widget(self.info_page) self.screen_manager.add_widget(screen) return self.screen_managerclass ConnectPage(GridLayout): # runs on initialization # Our Main Screen def __init__(self, **kwargs): super().__init__(**kwargs) self.cols = 1 # used for our grid self.add_widget(Label(text='Hello World')) # widget #1, top left #self.add_widget(self.ip) # widget #2, top right # add our button. self.join = Button(text=&quot;Try me&quot;) self.join.bind(on_press=self.join_button) self.add_widget(Label()) # just take up the spot. self.add_widget(self.join) def join_button(self, instance): #print(f&quot;Joining {ip}:{port} as {username}&quot;) # Create info string, update InfoPage with a message and show it info = f&quot;You found me&quot; chat_app.info_page.update_info(info) chat_app.screen_manager.current = 'Info'# Simple information/error pageclass InfoPage(GridLayout): def __init__(self, **kwargs): super().__init__(**kwargs) # Just one column self.cols = 1 # And one label with bigger font and centered text self.message = Label(halign=&quot;center&quot;, valign=&quot;middle&quot;, font_size=30) # By default every widget returns it's side as [100, 100], it gets finally resized, # but we have to listen for size change to get a new one # more: https://github.com/kivy/kivy/issues/1044 self.message.bind(width=self.update_text_width) # Add text widget to the layout self.add_widget(self.message) # add our button. # Add an return button self.join = Button(text=&quot;return&quot;) self.join.bind(on_press=self.join_button) self.add_widget(Label()) # just take up the spot. self.add_widget(self.join) def join_button(self, instance): #print(f&quot;Joining {ip}:{port} as {username}&quot;) chat_app.screen_manager.current = 'Connect' # Called with a message, to update message text in widget def update_info(self, message): self.message.text = message # Called on label width update, so we can set text width properly - to 90% of label width def update_text_width(self, *_): self.message.text_size = (self.message.width * 0.9, None)if __name__ == &quot;__main__&quot;: chat_app = EpicApp() chat_app.run()","link":"/2020/11/12/Python/Kivy_sent3/"},{"title":"Opencv &amp; gif","text":"Opencv &amp; gif reference: https://blog.csdn.net/qq_41500251/article/details/82820806 import time, cv2from PIL import Imageimport numpy as npdef GIF(file): List = [] im = Image.open(file) im.seek(1)#skip to the second frame try: while 1: List += [cv2.cvtColor(np.asarray(im.convert()),cv2.COLOR_RGB2BGR)] im.seek(im.tell()+1) except EOFError:#the sequence ends pass Num = 0 while Num &lt; len(List)*2: Num +=1 ID = Num%(len(List)) cv2.imshow(&quot;OpenCV&quot;,List[ID]) print(ID) cv2.waitKey(1) time.sleep(0.1) cv2.destroyAllWindows() for Videos: from cv2 import cv2import imageioimport numpy# Collection of the imgsframes_list = []# Tossed frames per FPS. When FPS = 1, all frame are saved.FPS = 1cap=cv2.VideoCapture(&quot;test_1.mp4&quot;)while (True): ret,frame=cap.read() #img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) img = cv2.resize(frame, (460,360)) frames_list.append(img)frames = []Num =0for img in frames_list: Num +=1 if Num %3 == 0: frames.append(img)gif=imageio.mimsave('test_3.gif',frames,'GIF',duration=1/8)","link":"/2020/09/12/Python/Opencv_gif/"},{"title":"PIL image to np.array","text":"PIL, np.array PIL.Image转换成OpenCV格式 ##reference https://blog.csdn.net/dcrmg/java/article/details/78147219import cv2from PIL import Imageimport numpyimage = Image.open(&quot;plane.jpg&quot;)image.show()img = cv2.cvtColor(numpy.asarray(image),cv2.COLOR_RGB2BGR)cv2.imshow(&quot;OpenCV&quot;,img)cv2.waitKey()","link":"/2020/01/22/Python/PIL_np.array/"},{"title":"Matplotlib","text":"Matplotlib 1. Quick Start 1.1 Quick hit import numpy as npimport matplotlib as mplimport matplotlib.pyplot as pltnp.random.seed(1000)y = np.random.standard_normal(20)x = range(len(y))plt.plot(x, y)plt.show() 1.2 Adding layers ## Showing change of each movements plt.ion()plt.show()np.random.seed(2000)y = np.random.standard_normal((20,2)).cumsum(axis=0)plt.figure(figsize=(7, 4)) # adding a canves figsize=(width, height)plt.plot(y.cumsum(), 'm',lw=1.5) # adding a lineplt.plot(y.cumsum(), 'ro') # adding dotsplt.grid(True) # adding grid on panalsplt.axis('tight') # adding... I don't knowplt.xlabel('index') # adding a title xplt.ylabel('value') # addint a title yplt.title('A Simple Plot') # adding a title 1.3 Facet(subplot) plt.ion()plt.show()## Data setnp.random.seed(2000)y = np.random.standard_normal((20,2)).cumsum(axis=0)plt.figure(figsize=(7,5))plt.subplot(211)'''211:2: 2 plot in a column;1: 1 plot in a row1: the 1sd'''plt.plot(y[:, 0], lw=1.5, label='1st')plt.plot(y[:, 0], 'ro')plt.grid(True)plt.legend(loc=0)plt.axis('tight')plt.ylabel('value')plt.title('A Simple Plot')plt.subplot(212) # the secondplt.plot(y[:, 1], 'g', lw=1.5, label='2nd')plt.plot(y[:, 1], 'ro')plt.grid(True)plt.legend(loc=0)plt.axis('tight')plt.xlabel('index')plt.ylabel('value') 2. Main Plot 2.1 Dot plot plt.plot(y[:, 0], 'ro') 2.2 Scatter plot 2.2.1 plot() y = np.random.standard_normal((1000, 2))plt.figure(figsize=(7, 5))plt.plot(y[:, 0], y[:, 1], 'ro')plt.grid(True)plt.title('Scatter Plot') 2.2.2 scatter() plt.figure(figsize=(7, 5))plt.scatter(y[:, 0], y[:, 1], marker='o')plt.grid(True)plt.xlabel('1st')plt.ylabel('2nd')plt.title('Scatter Plot') 2.2.3 Adding color: c = c c = np.random.randint(0, 10, len(y))plt.figure(figsize=(7, 5))plt.scatter(y[:, 0], y[:, 1], c=c, marker='o')plt.colorbar()plt.grid(True)plt.xlabel('1st')plt.ylabel('2nd')plt.title('Scatter Plot') Edge of the Scatter Points # default plotplt.scatter(x= TB_Sp.Frame, y = TB_Sp.value, color = 'black', alpha = .1)# Adding color to the edgeplt.scatter(x= TB_Sp.Frame, y = TB_Sp.value, color = 'black', alpha = .1, edgecolors = 'steelblue')# remove the edges from each pointplt.scatter(x= TB_Sp.Frame, y = TB_Sp.value, color = 'black', alpha = .1, linewidths= 0 ) Default Edge with Color No Edge 2.3 Line plot y = np.random.standard_normal(20)x = range(len(y))plt.plot(y, lw=1.5, label='1st') 2.4 Bar plot 2.4.1 Bar plot y = np.random.standard_normal(20)x = range(len(y))plt.bar(np.arange(len(y)), y, width=0.5, color='g', label='2nd') 2.4.2 Histogram 1. Align as “dodge” plt.figure(figsize=(7, 4))plt.hist(y, label=['1st', '2nd'], bins=25)plt.grid(True)plt.legend(loc=0)plt.xlabel('value')plt.ylabel('frequency')plt.title('Histogram') 2. Align as ‘stack’ y = np.random.standard_normal((1000, 2))plt.figure(figsize=(7, 4))plt.hist(y, label=['1st', '2nd'], color=['b', 'g'], stacked=True, bins=20)plt.grid(True)plt.legend(loc=0)plt.xlabel('value')plt.ylabel('frequency')plt.title('Histogram') 2.5 Box polt fig, ax = plt.subplots(figsize=(7,4))plt.boxplot(y)plt.grid(True)plt.setp(ax, xticklabels=['1st', '2nd'])plt.xlabel('data set')plt.ylabel('value')plt.title('Boxplot') 2.6 Adding Text/Formula from matplotlib.patches import Polygondef func(x): return 0.5 * np.exp(x) + 1a, b = 0.5, 1.5x = np.linspace(0, 2)y = func(x)fig, ax = plt.subplots(figsize=(7, 5))plt.plot(x, y, 'b', linewidth=2)plt.ylim(ymin=0)Ix = np.linspace(a, b)Iy = func(Ix)verts = [(a, 0)] + list(zip(Ix, Iy)) + [(b, 0)]poly = Polygon(verts, facecolor='0.7', edgecolor='0.5')ax.add_patch(poly)plt.text(0.5 * (a + b), 1, r&quot;$\\int_a^b fx\\mathrm{d}x$&quot;, horizontalalignment='center', fontsize=20)plt.figtext(0.9, 0.075, '$x$')plt.figtext(0.075, 0.9, '$f(x)$')ax.set_xticks((a, b))ax.set_xticklabels(('$a$', '$b$'))ax.set_yticks([func(a), func(b)])ax.set_yticklabels(('$f(a)$', '$f(b)$'))plt.grid(True) Result 3. Plot 3D 3.1 ## Preparing for Data setstrike = np.linspace(50, 150, 24)ttm = np.linspace(0.5, 2.5, 24)strike, ttm = np.meshgrid(strike, ttm)iv = (strike - 100) ** 2 / (100 * strike) / ttmfig, ax = plt.subplots(subplot_kw={&quot;projection&quot;: &quot;3d&quot;})surf = ax.plot_surface(strike, ttm, iv, rstride=2, cstride=2, cmap=plt.cm.coolwarm, linewidth=0.5, antialiased=True)ax.set_xlabel('strike')ax.set_ylabel('time-to-maturity')ax.set_zlabel('implied volatility')fig.colorbar(surf, shrink=0.5, aspect=5) 3.2 From Surface data to Dot fig = plt.figure(figsize=(8, 5))ax = fig.add_subplot(111, projection='3d')ax.view_init(30, 60)ax.scatter(strike, ttm, iv, zdir='z', s=25, c='b', marker='^')ax.set_xlabel('strike')ax.set_ylabel('time-to-maturity')ax.set_zlabel('implied volatility')plt.show() From 3D Dots into Surface Plot Cite: Adobe, 2014 from matplotlib.ticker import MaxNLocatorX = range(10)Y = range(10)Points = []for x in X: for y in Y: Points += [[x*10, y*10, x**y]]Points = np.array(Points)fig, ax = plt.subplots(subplot_kw={&quot;projection&quot;: &quot;3d&quot;}, figsize=(6,6))surf = ax.plot_trisurf(Points[:, 0], Points[:, 1], Points[:,2])ax.xaxis.set_major_locator(MaxNLocator(5))ax.yaxis.set_major_locator(MaxNLocator(6))ax.zaxis.set_major_locator(MaxNLocator(5))plt.show() Raw 3D dots plot Converte the 3D dots plot into surface plot Save ## Assignment the size of the pictureplt.figure(figsize=(12*3, 8*3))## Saveplt.savefig(OUTPUT) plot a circle (ring) Yann, 2012 import matplotlib.pyplot as pltcircle1 = plt.Circle((0, 0), 0.2, color='r')circle2 = plt.Circle((0.5, 0.5), 0.2, color='blue')circle3 = plt.Circle((1, 1), 0.2, color='g', clip_on=False)fig, ax = plt.subplots() # note we must use plt.subplots, not plt.subplot# (or if you have an existing figure)# fig = plt.gcf()# ax = fig.gca()ax.add_patch(circle1)ax.add_patch(circle2)ax.add_patch(circle3)fig.savefig('plotcircles.png') © Yann Others for 3D Delaunay Triangulation to fill the mesh by mayavi calculate the ball like mesh by pyvista arrow from point (0, 0), (2, 2) plt.arrow(0, 0, 2, 2, width = 0.05) 4 points for 2 arrows: plt.arrow(P1[0], P1[1], P2[0]-P1[0], P2[1]-P1[1], width = 1)plt.arrow(P3[0], P3[1], P4[0]-P3[0], P4[1]-P3[1], width = 1) Animation import numpy as npimport matplotlib.pyplot as pltimport matplotlib.animation as animationimport mathy = []for t in range(100): y += [np.sin(2*math.pi * (0 - t/100))]x = np.array([0] * 100)y = np.array(y)fig, ax = plt.subplots()line, = ax.plot(x, y, 'o')def update(num, x, y, line): line.set_data(x[num], y[num]) return line,ani = animation.FuncAnimation(fig, update, len(x), interval=10, fargs=[x, y, line], blit=True)ani.save('animation_drawing.gif', writer='imagemagick', fps=60)plt.plot(np.array(range(100))/10, y, 'o')plt.savefig('wave.png')plt.show() import numpy as np import matplotlib.pyplot as plt import matplotlib.animation as animation import math frame = 100 Y = [] for x in range(10): y = [] for t in range(frame): y += [np.sin(2*math.pi * (x/10 - t/10/10))] Y += [np.array(y)] Y = np.array(Y) X = np.array([[i] * frame for i in range(len(Y))]) fig, ax = plt.subplots() line, = ax.plot([0, 10], [-1, 1], 'o') ax.set_ylim(-1) def update(num, x, y, line): line.set_data(x[:,num], y[:,num]) return line, ani = animation.FuncAnimation(fig, update, frame, interval=100, fargs=[X, Y, line], blit=True ) ani.save('animation_drawing.gif', writer='imagemagick', fps=60) plt.plot(np.array(range(100))/10, y, 'o') plt.savefig('wave.png') plt.show() `","link":"/2020/01/22/Python/Matplotlib/"},{"title":"Plot in the Terminal!!! 在终端里面画画！！","text":"Plot in the Terminal!!! 在终端里面画画！！ https://github.com/kressi/terminalplothttps://github.com/glamp/bashplotlib！！！ https://stackoverflow.com/questions/20295646/python-ascii-plots-in-terminalhttps://stackoverflow.com/questions/37288421/how-to-plot-a-chart-in-the-terminal – https://stackoverflow.com/questions/42507096/highlight-find-data-points-in-plotly-scatter-from-the-browser","link":"/2020/01/22/Python/Plot-in-the-Terminal/"},{"title":"OpenCV examples for beginners| Python","text":"Install pip3 install --upgrade setuptoolspip3 install numpy Matplotlibpip3 install opencv-contrib-python Notice: Don’t ever install other versions opencv, exp: python2-opencv, opencv-python Img Read and Show Load an color image in grayscale import numpy as npimport cv2img = cv2.imread('messi5.jpg',0) img read from Camera cap = cv2.VideoCapture(0)ret, frame = cap.read()cap.release()cap = cv2.VideoCapture(0)while(True): ret, frame = cap.read() cv2.imshow('image',frame) if cv2.waitKey(1) &amp; 0xFF == ord('q'): cv2.destroyAllWindows() break Resolution of the img cap.set(cv2.CAP_PROP_FRAME_WIDTH,1280)cap.set(cv2.CAP_PROP_FRAME_HEIGHT,720) img show and close cv2.imshow('image',img)if cv2.waitKey(0) &amp; 0xFF == ord('q'): cv2.destroyAllWindows() resize cv2.resize(img, (10,10), interpolation = cv2.INTER_AREA) Slice Slice the image based on the center, width, and height import cv2import numpy as np# Load the imageimg = cv2.imread('example.jpg')# Get the center point of the rectangular regioncenter_x, center_y = 100, 100# Get the width and height of the rectangular regionwidth, height = 50, 80def img_slice(center_x, center_y, width, height): # Calculate the coordinates of the top-left and bottom-right corners of the rectangular region x1 = int(center_x - (width / 2)) y1 = int(center_y - (height / 2)) x2 = int(center_x + (width / 2)) y2 = int(center_y + (height / 2)) # Slice the rectangular region from the original image return img[y1:y2, x1:x2] rotate Cite: geeksforgeeks.org, 2023 image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE) img wirte cv2.imwrite('messigray.png',img) img to gif Original Webpage: PHILOS_THU, 2017 执笔论英雄, 2018 import cv2import imageioList = ['./yang1.jpg', './yang2.jpg', './yang3.jpg']frames = []for img in List: img = cv2.imread(img, 1) img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img = cv2.resize(img, (460,360)) frames.append(img)gif=imageio.mimsave('yang.gif',frames,'GIF',duration=0.4) Screen shot import cv2import numpy as npfrom mss import msscords = {'top':40 , 'left': 0 , 'width': 800, 'height': 640 }while(True): with mss() as sct : img = np.array(sct.grab(cords)) #sct.grab(cords/monitor) #cimg = cv2.cvtColor(img , cv2.COLOR_BGRA2GRAY) cv2.imshow('image',img) if cv2.waitKey(1) &amp; 0xFF == ord('q'): cv2.destroyAllWindows() breakcv2.destroyAllWindows() Draw on Img Draw a Rectangle reference: AlanWang4523 2018 With know top-left and bottom-right: ## 绘制一个红色矩形ptLeftTop = (120, 100)ptRightBottom = (200, 150)def Draw_rect(img, ptLeftTop, ptRightBottom, point_color = (0, 0, 255), # BGR thickness = 1, lineType = 8): return cv.rectangle(img, ptLeftTop, ptRightBottom, point_color, thickness, lineType) With know center, width, and height def Draw_rect(img, Ccenter_x, center_y, width, height, point_color = (0, 0, 255), # BGR) thickness = 2, lineType = 8): ptLeftTop = (int(center_x - (width / 2)), int(center_y - (height / 2))) ptRightBottom = (int(center_x + (width / 2)), int(center_y + (height / 2))) # Draw the rectangle on the image return cv.rectangle(img, ptLeftTop, ptRightBottom, point_color, thickness, lineType) Draw a oval / ellipse Source: geeksforgeeks.org center_coordinates = (120, 100)axesLength = (100, 50)angle = 30startAngle = 0endAngle = 360# Blue color in BGRcolor = (255, 0, 0)# Line thickness of -1 pxthickness = -1# Using cv2.ellipse() method# Draw a ellipse with blue line borders of thickness of -1 pximage = cv2.ellipse(image, center_coordinates, axesLength, angle, startAngle, endAngle, color, thickness)# Displaying the imagecv2.imshow(&quot;Ellipse&quot;, image) Draw an arrow Source: geeksforgeeks.org start_point = (225, 0)# End coordinateend_point = (0, 90)# Red color in BGRcolor = (0, 0, 255)# Line thickness of 9 pxthickness = 9# Using cv2.arrowedLine() method# Draw a red arrow line# with thickness of 9 px and tipLength = 0.5image = cv2.arrowedLine(image, start_point, end_point, color, thickness, tipLength = 0.5)# Displaying the imagecv2.imshow(&quot;arrow&quot;, image) Write on the image img = cv2.imread('messi5.jpg',0)cv2.putText(img, &quot;Hello World&quot; ,(200, 100), cv2.FONT_HERSHEY_COMPLEX, 2.0, (100, 200, 200), 5) Other Tricks for image ## Blurimg = cv2.medianBlur(img,5)## Greycv2.cvtColor(img,cv2.COLOR_RGB2GRAY) Video Video read cap=cv2.VideoCapture(&quot;test&quot;)while (True): ret,frame=cap.read() cv2.imshow(&quot;video&quot;,frame) # 在播放每一帧时，使用cv2.waitKey()设置适当的持续时间。如果设置的太低视频就会播放的非常快，如果设置的太高就会播放的很慢。通常情况下25ms就ok if cv2.waitKey(25)&amp;0xFF==ord('q'): cv2.destroyAllWindows() break Reading Video information ## fps of this Videofps_c = cap.get(cv2.CAP_PROP_FPS)frame_total = cap.get(cv2.CAP_PROP_FRAME_COUNT)Video_h = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)Video_w = cap.get(cv2.CAP_PROP_FRAME_WIDTH) play Video and audio ##https://stackoverflow.com/questions/46864915/python-add-audio-to-video-opencvimport cv2import numpy as np##ffpyplayer for playing audiofrom ffpyplayer.player import MediaPlayervideo_path=&quot;../L1/images/Godwin.mp4&quot;def PlayVideo(video_path): video=cv2.VideoCapture(video_path) player = MediaPlayer(video_path) while True: grabbed, frame=video.read() audio_frame, val = player.get_frame() if not grabbed: print(&quot;End of video&quot;) break if cv2.waitKey(28) &amp; 0xFF == ord(&quot;q&quot;): break cv2.imshow(&quot;Video&quot;, frame) if val != 'eof' and audio_frame is not None: #audio img, t = audio_frame video.release() cv2.destroyAllWindows()PlayVideo(video_path) Video write import cv2, osFile = &quot;Up&quot;OUTPUT = &quot;Egg_Day1.avi&quot;List = os.popen('ls '+File).read().split('\\n')[:-1]img = cv2.imread(File +&quot;/&quot;+List[0])fps = 24size = (len(img[0]),len(img))fourcc = cv2.VideoWriter_fourcc('M','J','P','G')videowriter = cv2.VideoWriter(OUTPUT,fourcc,fps,size)for i in List: img = cv2.imread(File +&quot;/&quot;+i) videowriter.write(img)videowriter.release() cv2.VideoWriter_fourcc('M','J','P','G'): It creates a VideoWriter fourcc object in OpenCV, which is used to specify the codec to be used for writing video files. The cv2.VideoWriter_fourcc() function takes four characters as input to create a fourcc code. In this case, the four characters are 'M', 'J', 'P', and 'G', which correspond to the MPEG-1 codec. So the fourcc variable will hold the fourcc code for the MPEG-1 codec, which will be used when writing the video file. Grey iamge to video import cv2import numpy as np# Create a list of grayscale imagesimg_list = [...] # insert your list of images here# Define the video writer objectfourcc = cv2.VideoWriter_fourcc(*'XVID')out = cv2.VideoWriter('output.avi', fourcc, 10.0, (img_list[0].shape[1], img_list[0].shape[0]), False)# Write each image to the videofor img in img_list: # Convert to grayscale if not already if len(img.shape) == 3 and img.shape[2] == 3: img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # Write to video out.write(img)# Release the video writerout.release() In this code, img_list is the list of grayscale images you want to output as a video. The code first defines the VideoWriter object with the desired filename, codec, frame rate, and frame size. Then, it iterates through each image in img_list, converts it to grayscale (if it isn’t already), and writes it to the video using the write method of the VideoWriter object. Finally, it releases the VideoWriter object to close the video file. vedio to gif from cv2 import cv2import imageioimport numpy# Collection of the imgsframes_list = []# Tossed frames per FPS. When FPS = 1, all frame are saved.FPS = 1cap=cv2.VideoCapture(&quot;test_1.mp4&quot;)while (True): ret,frame=cap.read() #img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) img = cv2.resize(frame, (460,360)) frames_list.append(img)frames = []Num =0for img in frames_list: Num +=1 if Num %3 == 0: frames.append(img)gif=imageio.mimsave('test_3.gif',frames,'GIF',duration=1/8) Video capture ##!/usr/bin/env python## -*- coding: utf-8 -*-## @Time : 2019/3/7 11:43## @Author : HaoWANG## @Site :## @File : VideoWrite.py## @Software: PyCharm## 加载包import mathimport sysimport cv2def main(): # 初始化摄像头 keep_processing = True; camera_to_use = 0; # 0 if you have one camera, 1 or &gt; 1 otherwise cap = cv2.VideoCapture(0) # 定义视频捕获类cap windowName = &quot;Live Video Capture and Write&quot; # 窗口名 # opencv中视频录制需要借助VideoWriter对象， 将从VideoCapture 中读入图片，不断地写入到VideoWrite的数据流中。 # 指定视频编解码方式为MJPG codec = cv2.VideoWriter_fourcc(*'MJPG') fps = 25.0 # 指定写入帧率为25 frameSize = (640, 480) # 指定窗口大小 # # 创建 VideoWriter对象 output = cv2.VideoWriter('VideoRecord.avi', codec, fps, frameSize) # 摄像头开启检测 # error detection # if not (((len(sys.argv) == 2) and (cap.open(str(sys.argv[1])))) or (cap.open(camera_to_use))): print(&quot;ERROR：No video file specified or camera connected.&quot;) return -1 # Camera Is Open # create window by name (note flags for resizable or not) cv2.namedWindow(windowName, cv2.WINDOW_NORMAL) print(&quot;按键Q-结束视频录制&quot;) while (cap.isOpened()): # 00 if video file successfully open then read frame from video if (keep_processing): ret, frame = cap.read() # 定义read对象ret和frame帧 # start a timer (to see how long processing and display takes) start_t = cv2.getTickCount() # 不断的从VideoCapture 中读入图片，然后写入到VideoWrite的数据流中。 output.write(frame) cv2.imshow(windowName, frame) # display image # stop the timer and convert to ms. (to see how long processing and display takes) stop_t = ((cv2.getTickCount() - start_t) / cv2.getTickFrequency()) * 1000 # 接收键盘停止指令 # start the event loop - essential # wait 40ms or less depending on processing time taken (i.e. 1000ms / 25 fps = 40 ms) key = cv2.waitKey(max(2, 40 - int(math.ceil(stop_t)))) &amp; 0xFF # It can also be set to detect specific key strokes by recording which key is pressed # e.g. if user presses &quot;q&quot; then exit if (key == ord('q')): print(&quot;Quit Process &quot;) keep_processing = False else: break print(&quot;The display and video write tasks take {} ms&quot;.format(stop_t)) # release the camera and close all windows # 资源释放,在录制结束后，我们要释放资源： # # 释放资源 cap.release() output.release() cv2.destroyAllWindows()## end main()if __name__ == &quot;__main__&quot;: main() Training your personal model '''positive list:Pics in Me director, 55*110Background Pics are in BG file'''for i in $(ls Me/);do echo Me/$i 1 0 0 55 110;done &gt; pos.listfor i in $(ls BG/);do echo BG/$i;done &gt; bg.listrm models/*opencv_createsamples -info pos.list -vec pos.vec -bg bg.list -num 12 -w 20 -h 40opencv_traincascade -data models/ -vec pos.vec -bg bg.list -numPos 12 -numNeg 27 -numStages 2 -featureType HAAR -w 20 -h 40'''s'''import cv2## 探测图片中的人脸detector = cv2.CascadeClassifier(&quot;models/params.xml&quot;) # absolute !!!faces = detector.detectMultiScale(img)for(x,y,w,h) in faces: cv2.rectangle(image,(x,y),(x+w,y+w),(0,255,0),2) Matlibplot ## -*- coding: utf-8 -*-&quot;&quot;&quot;## --------------------------------------------------------## @Author : panjq## @E-mail : pan_jinquan@163.com## @Date : 2020-02-05 11:01:49## --------------------------------------------------------&quot;&quot;&quot;import matplotlib.pyplot as pltimport numpy as npimport cv2def fig2data(fig): &quot;&quot;&quot; fig = plt.figure() image = fig2data(fig) @brief Convert a Matplotlib figure to a 4D numpy array with RGBA channels and return it @param fig a matplotlib figure @return a numpy 3D array of RGBA values &quot;&quot;&quot; import PIL.Image as Image # draw the renderer fig.canvas.draw() # Get the RGBA buffer from the figure w, h = fig.canvas.get_width_height() buf = np.fromstring(fig.canvas.tostring_argb(), dtype=np.uint8) buf.shape = (w, h, 4) # canvas.tostring_argb give pixmap in ARGB mode. Roll the ALPHA channel to have it in RGBA mode buf = np.roll(buf, 3, axis=2) image = Image.frombytes(&quot;RGBA&quot;, (w, h), buf.tostring()) image = np.asarray(image) return imageif __name__ == &quot;__main__&quot;: # Generate a figure with matplotlib&lt;/font&gt; figure = plt.figure() plot = figure.add_subplot(111) # draw a cardinal sine plot x = np.arange(1, 100, 0.1) y = np.sin(x) / x plot.plot(x, y) plt.show() ## image = fig2data(figure) cv2.imshow(&quot;image&quot;, image) cv2.waitKey(0) img1 = Overed_fly.copy()img2 = ID_lay_img.copy()gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)# Initialize SIFT detectorsift = cv2.SIFT_create()# Find keypoints and descriptors for both imageskp1, des1 = sift.detectAndCompute(gray1, None)kp2, des2 = sift.detectAndCompute(gray2, None)# Initialize brute-force matcherbf = cv2.BFMatcher()# Match descriptors from both imagesmatches = bf.knnMatch(des1, des2, k=2)# Apply ratio test to remove false matchesgood_matches = []for m, n in matches: if m.distance &lt; 0.75 * n.distance: good_matches.append(m)# Draw the matched keypointsresult = cv2.drawMatches(img1, kp1, img2, kp2, good_matches, None)cv2.imshow(&quot;video&quot;,result)if cv2.waitKey(0)&amp;0xFF==ord('q'): cv2.destroyAllWindows()","link":"/2020/09/12/Python/OpenCV/"},{"title":"QT","text":"QT from PyQt5.QtWidgets import QApplication, QLabelapp = QApplication([])label = QLabel('Hello World!')label.show()app.exec_() 无边窗, 初始位点设定, 透明 from PyQt5.QtWidgets import QApplication, QLabelfrom PyQt5.QtCore import *app = QApplication([])My_Window = QLabel('Hello World!')My_Window.setWindowFlags(Qt.WA_TranslucentBackground|Qt.WindowStaysOnBottomHint|Qt.SubWindow)My_Window.move(1920, 100)##背景颜色My_Window.setStyleSheet(&quot;QLabel{color:rgb(225,22,173,255);font-size:50px;font-weight:normal;font-family:Arial;}&quot;)My_Window.setWindowOpacity(0.5)My_Window.show()app.exec_() 添加按钮(接上) from PyQt5.QtWidgets import *from PyQt5.QtWidgets import QApplication, QLabelfrom PyQt5.QtCore import *import osdef btnPress1_clicked(): os.system(&quot;google-chrome &amp;&quot;)app = QApplication([])btnPress1=QPushButton('显示文本')btnPress1.setWindowFlags(Qt.FramelessWindowHint|Qt.WA_TranslucentBackground|Qt.WindowStaysOnBottomHint|Qt.SubWindow)btnPress1.clicked.connect(btnPress1_clicked)btnPress1.move(1920, 100)btnPress1.show() 多个元素 from PyQt5.QtWidgets import QApplication, QWidget, QPushButton, QVBoxLayoutfrom PyQt5.QtGui import *from PyQt5.QtCore import *from PyQt5.QtWidgets import *from PyQt5 import QtWidgets, QtGuiapp = QApplication([])window = QWidget()window.setWindowFlags(Qt.FramelessWindowHint|Qt.WindowStaysOnBottomHint|Qt.SubWindow)window.setAutoFillBackground(False)window.setAttribute(Qt.WA_TranslucentBackground, True)window.repaint()layout = QVBoxLayout()btn = QPushButton('Top')## 无边框##btn.setFlat(True)layout.addWidget(btn)layout.addWidget(QPushButton('Bottom'))window.setLayout(layout)window.show()app.exec_()","link":"/2020/01/22/Python/QT/"},{"title":"TUI libs","text":"TUI libs npyscreen Github Repositories: 34 我第一个知道的 TUI Python 库，比较小众，但是又不错的项目，比如ptop，TelegramTUI，PipTUI。上手简单，支持一些比较简单又去的功能， ptop Terlegram TUI ©darxtrix/ptop © vtr0n/TelegramTUI 详细介绍请看另一篇笔记：npyscreen unicurses Github Repositories: 20 项目示范： The-Snake-Game 教程和项目相对较少 urwid Github Repositories: 176 目前我知道的星最高的项目了以前非常喜欢的2k starts的 s-tui 就是这个库开发的， 还有 ＱＱ库高星项目有：s-tui (系统资源监测,2k), pudb(python debug 1.7k),alot(e-mail), gowid … ©amanusk/s-tui ©Nanoseb/ncTelegram source:https://www.oschina.net/p/urwid pygcurse Github Repositories: 11 source：http://inventwithpython.com/pygcurse/ Referen:http://www.voidcn.com/article/p-sjrivwij-bue.html","link":"/2020/06/22/Python/TUI-libs/"},{"title":"PDF","text":"PYPDF2 Read &amp; Write from PyPDF2 import PdfFileReader, PdfFileWriterreadFile = 'read.pdf'writeFile = 'write.pdf'pdfReader = PdfFileReader(open(readFile, 'rb'))pdfWriter.write(open(writeFile, 'wb')) Pick First two Page from PyPDF2 import PdfFileReader, PdfFileWriterimport PyPDF2readFile = 'SA.pdf'writeFile = 'write.pdf'pdfWriter = PyPDF2.PdfFileWriter()pdfReader = PdfFileReader(open(readFile, 'rb'))pdfWriter.write(open(writeFile, 'wb'))for page in range(2): pageObj = pdfReader.getPage(page) pdfWriter.addPage(pageObj)newFile = open(writeFile,'wb')pdfWriter.write(newFile)newFile.close() 2.1 Double the Pages from PyPDF2 import PdfFileReader, PdfFileWriterimport PyPDF2readFile = 'SA.pdf'writeFile = 'write.pdf'pdfWriter = PyPDF2.PdfFileWriter()pdfReader = PdfFileReader(open(readFile, 'rb'))pdfWriter.write(open(writeFile, 'wb'))for page in range(2): pageObj = pdfReader.getPage(page) pdfWriter.addPage(pageObj) pageObj = pdfReader.getPage(page) pdfWriter.addPage(pageObj)newFile = open(writeFile,'wb')pdfWriter.write(newFile)newFile.close() 3. Water Mark cm =1def create_watermark(content): #默认大小为21cm*29.7cm c = canvas.Canvas('mark.pdf', pagesize = (30*cm, 30*cm)) c.translate(10*cm, 10*cm) #移动坐标原点(坐标系左下为(0,0))) #c.setFont('song',22)#设置字体为宋体，大小22号 c.setFillColorRGB(0.5,0.5,0.5)#灰色 c.rotate(45)#旋转45度，坐标系被旋转 c.drawString(-7*cm, 0*cm, content) c.drawString(7*cm, 0*cm, content) c.drawString(0*cm, 7*cm, content) c.drawString(0*cm, -7*cm, content) c.save()#关闭并保存pdf文件 from reportlab.pdfgen import canvascm =1def create_watermark(W, H): #默认大小为21cm*29.7cm c = canvas.Canvas('mark.pdf', pagesize = (W, H)) c.translate(10*cm, 10*cm) #移动坐标原点(坐标系左下为(0,0))) #c.setFont('song',22)#设置字体为宋体，大小22号 #c.setFillColorRGB(0.5,0.5,0.5)#灰色 #c.rotate(45)#旋转45度，坐标系被旋转 #c.drawString(-7*cm, 0*cm, content) #c.drawString(7*cm, 0*cm, content) #c.drawString(0*cm, 7*cm, content) #c.drawString(0*cm, -7*cm, content) #指定描边的颜色 #c.setStrokeColorRGB(0, 1, 0) #指定填充颜色 c.setFillColorRGB(255, 255, 255) #画一个矩形 c.rect(0, 0, W, H/2 -10 , fill=1) c.save()#关闭并保存pdf文件create_watermark(580,820)add_watermark(pdf_file_in, pdf_file_mark, pdf_file_out) ##encoding=utf-8##author: walker##date: 2014-03-18##function:给pdf添加水印from PyPDF2 import PdfFileWriter, PdfFileReaderfrom reportlab.pdfgen import canvas##所有路径为绝对路径def add_watermark(pdf_file_in, pdf_file_mark, pdf_file_out): pdf_output = PdfFileWriter() input_stream = open(pdf_file_in, 'rb') pdf_input = PdfFileReader(pdf_file_in) # PDF文件被加密了 if pdf_input.getIsEncrypted(): print( '该PDF文件被加密了.') # 尝试用空密码解密 try: pdf_input.decrypt('') except Exception or e: print( '尝试用空密码解密失败.') return False else: print( '用空密码解密成功.') # 获取PDF文件的页数 pageNum = pdf_input.getNumPages() #读入水印pdf文件 pdf_watermark = PdfFileReader(open(pdf_file_mark, 'rb')) # 给每一页打水印 for i in range(pageNum): page = pdf_input.getPage(i) page.mergePage(pdf_watermark.getPage(0)) page.compressContentStreams() #压缩内容 pdf_output.addPage(page) return pdf_outputPDF1 = add_watermark(&quot;GRE阅读白皮书.pdf&quot;, pdf_file_mark, pdf_file_out)PDF2 = add_watermark(&quot;GRE阅读白皮书.pdf&quot;, pdf_file_mark2, pdf_file_out)pdf_output = PdfFileWriter()for i in range(PDF2.getNumPages()): page = PDF1.getPage(i) pdf_output.addPage(page) page = PDF2.getPage(i) pdf_output.addPage(page)newFile = open(pdf_file_out,'wb')pdf_output.write(newFile)newFile.close() Add Page number ###!/usr/bin/env python3## -*- coding:utf-8 -*-## 本示例使用两个第三方库来实现为PDF文件添加文字水印## 这两个库是pyPdf和reportlab## 使用的Python版本是Python 3.7## origing from https://www.cnblogs.com/kayb/p/10846341.html## 作者：小磊##链接：https://www.zhihu.com/question/19628465/answer/353504051##来源：知乎##著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。##!/usr/bin/env python3## -*- coding: utf-8 -*-helpDoc = '''Add Page Number to PDF file with PythonPython 给 PDF 添加 页码usage: python addPageNumberToPDF.py [PDF path]require: pip install reportlab pypdf2 Support both Python2/3, But more recommend Python3tips: * output file will save at pdfWithNumbers/[PDF path]_page.pdf * only support A4 size PDF * tested on Python2/Python3@ubuntu * more large size of PDF require more RAM * if segmentation fault, plaese try use Python 3 * if generate PDF document is damaged, plaese try use Python 3Author: Lei Yang (ylxx@live.com)GitHub: https://gist.github.com/DIYer22/b9ede6b5b96109788a47973649645c1f'''print(helpDoc)import reportlabfrom reportlab.lib.units import mmfrom reportlab.pdfgen import canvasfrom PyPDF2 import PdfFileWriter, PdfFileReaderpath = 'test.pdf'def createPagePdf(num, tmp): c = canvas.Canvas(tmp) for i in range(1,num+1): c.drawString((210//2)*mm, (4)*mm, str(i)) c.showPage() c.save() return with open(tmp, 'rb') as f: pdf = PdfFileReader(f) layer = pdf.getPage(0) return layerif __name__ == &quot;__main__&quot;: pass import sys,os if len(sys.argv) == 1: if not os.path.isfile(path): sys.exit(1) else: path = sys.argv[1] base = os.path.basename(path) tmp = &quot;__tmp.pdf&quot; batch = 10 batch = 0 output = PdfFileWriter() with open(path, 'rb') as f: pdf = PdfFileReader(f,strict=False) n = pdf.getNumPages() if batch == 0: batch = -n createPagePdf(n,tmp) if not os.path.isdir('pdfWithNumbers/'): os.mkdir('pdfWithNumbers/') with open(tmp, 'rb') as ftmp: numberPdf = PdfFileReader(ftmp) for p in range(n): if not p%batch and p: newpath = path.replace(base, 'pdfWithNumbers/'+ base[:-4] + '_page_%d'%(p//batch) + path[-4:]) with open(newpath, 'wb') as f: output.write(f) output = PdfFileWriter() print('page: %d of %d'%(p, n)) page = pdf.getPage(p) numberLayer = numberPdf.getPage(p) page.mergePage(numberLayer) output.addPage(page) if output.getNumPages(): newpath = path.replace(base, 'pdfWithNumbers/' + base[:-4] + '_page_%d'%(p//batch + 1) + path[-4:]) with open(newpath, 'wb') as f: output.write(f) os.remove(tmp) Access the size of pages Reference: SUN_SU3 2020 def pdf_size(path, page =0): pdf = PdfFileReader(open(path, 'rb')) page_1 = pdf.getPage(page) if page_1.get('/Rotate', 0) in [90, 270]: return page_1['/MediaBox'][2], page_1['/MediaBox'][3] else: return page_1['/MediaBox'][3], page_1['/MediaBox'][2]height, width = pdf_size(path)print('height: %s, width: %s'%(height, width)) height: 767.06, width: 575.29 This is the size of PDF file made by Sony DPT-1 Crop the pages of PDF For doing this, you need to know the size of your pdf and the width/height ratio. File = &quot;Improving_Reading_Skills.pdf&quot;height, width = pdf_size(File,20) # Function from aboveC_width = round(float(690)/(767.06/575.29),2)with open(File, &quot;rb&quot;) as in_f: input1 = PdfFileReader(in_f) output = PdfFileWriter() # number numPages = input1.getNumPages() print (&quot;document has %s pages.&quot; % numPages) # Start for i in range(10): page = input1.getPage(i) print( page.mediaBox.getUpperRight_x(), page.mediaBox.getUpperRight_y()) # (x, y) from left to right, from botton to top #page.trimBox.lowerLeft = (400, 700) page.cropBox.lowerLeft = (500, 600) page.cropBox.upperRight = (100, 200) output.addPage(page) # End with open(&quot;out.pdf&quot;, &quot;wb&quot;) as out_f: output.write(out_f) When left and right page is different with open(File, &quot;rb&quot;) as in_f: input1 = PdfFileReader(in_f) output = PdfFileWriter() # number numPages = input1.getNumPages() print (&quot;document has %s pages.&quot; % numPages) # Start for i in range(numPages): page = input1.getPage(i) print( page.mediaBox.getUpperRight_x(), page.mediaBox.getUpperRight_y()) # (x, y) from left to right, from botton to top #page.trimBox.lowerLeft = (400, 700) if i%2 == 0: page.cropBox.lowerLeft = (540, 680) page.trimBox.lowerLeft = (540, 680) page.cropBox.upperRight = (60, 40) page.trimBox.upperRight = (60, 40) if i%2 == 1: page.cropBox.lowerLeft = (580, 680) page.trimBox.lowerLeft = (580, 680) page.cropBox.upperRight = (100, 40) page.trimBox.upperRight = (100, 40) output.addPage(page) # End with open(&quot;out.pdf&quot;, &quot;wb&quot;) as out_f: output.write(out_f) Extract images from PDF Reference:Labo; 2016 from PIL import Imagefrom PyPDF2 import PdfReaderdef extract_image(pdf_file_path): reader = PdfReader(pdf_file_path) page = reader.pages[0] x_object = page[&quot;/Resources&quot;][&quot;/XObject&quot;].getObject() for obj in x_object: if x_object[obj][&quot;/Subtype&quot;] == &quot;/Image&quot;: size = (x_object[obj][&quot;/Width&quot;], x_object[obj][&quot;/Height&quot;]) data = x_object[obj].getData() if x_object[obj][&quot;/ColorSpace&quot;] == &quot;/DeviceRGB&quot;: mode = &quot;RGB&quot; else: mode = &quot;P&quot; if x_object[obj][&quot;/Filter&quot;] == &quot;/FlateDecode&quot;: img = Image.frombytes(mode, size, data) img.save(obj[1:] + &quot;.png&quot;) elif x_object[obj][&quot;/Filter&quot;] == &quot;/DCTDecode&quot;: img = open(obj[1:] + &quot;.jpg&quot;, &quot;wb&quot;) img.write(data) img.close() elif x_object[obj][&quot;/Filter&quot;] == &quot;/JPXDecode&quot;: img = open(obj[1:] + &quot;.jp2&quot;, &quot;wb&quot;) img.write(data) img.close() pdfplumber Read import pdfplumberpath = 'MMR.pdf'pdf = pdfplumber.open(path) Reference: SUN_SU3 2020 import pdfplumberpath = 'MMR.pdf'def run(path): with pdfplumber.open(path) as pdf: page_1 = pdf.pages[0] return page_1.height, page_1.widthheight, width = run(path)print('height: %s, width: %s'%(height, width)) height: 841.920, width: 595.200 import cv2import numpy as npfrom PIL import Imagefrom pandas import pdimport seaborn as snsimport matplotlib.pyplot as pltimg = cv2.imread('I0.jpg')# remove usless infordef Get_data(img): # Main string img[img[:,:,2]&lt;250] = 0 img[img[:,:,1]&gt;50] = 0 img[img[:,:,0]&lt;60] = 0 return imgdef Get_box(img): # Main string img[np.abs(img[:,:,2]-135)&gt;=1] = 255 img[np.abs(img[:,:,1]-135)&gt;=1] = 255 img[np.abs(img[:,:,0]-135)&gt;=1] = 255 return imgimg_show = Get_data(img)img_show = cv2.resize(img_show, (2382,1936))while(True): cv2.imshow('image',img_show) if cv2.waitKey(1) &amp; 0xFF == ord('q'): cv2.destroyAllWindows() breakimg_show = cv2.cvtColor(img_show, cv2.COLOR_BGR2RGB)colourImg = Image.fromarray(img_show)colourPixels = colourImg.convert(&quot;RGB&quot;)colourArray = np.array(colourPixels.getdata()).reshape(colourImg.size + (3,))indicesArray = np.moveaxis(np.indices(colourImg.size), 0, 2)allArray = np.dstack((indicesArray, colourArray)).reshape((-1, 5))df = pd.DataFrame(allArray, columns=[&quot;y&quot;, &quot;x&quot;, &quot;red&quot;,&quot;green&quot;,&quot;blue&quot;])df_lines = df[df.red!=0]df_line_1 = df_lines[df_lines.y&gt;=2000]df_line_1 = df_line_1.sort_values(by=['x'])plt.plot(df_line_1.x, df_line_1.y, 'ro')plt.show() ( []) (255,50,51)","link":"/2020/01/22/Python/PDF/"},{"title":"Pandas","text":"Pandas Ignore “Warning” messages Reference: Bot Bark; 2019 import warningswarnings.filterwarnings(&quot;ignore&quot;) Basic import pandas as pd###read fileTB = pd.read_csv(&quot;sentence-G&quot;,sep='\\t', names=None, header=None)TB.columns = ['频率', '', 'V2', '词义', 'V3']##DataFramepd.DataFrame(index=range(40),columns=['a', 'b'])### rsult outputTB.to_csv(&quot;table&quot;,sep='\\t')datadata[0:2] #取前两行数据len(data ) #求出一共多少行data.columns.size #求出一共多少列data.columns #列索引名称data.index #行索引名称data.ix[1] #取第2行数据data.iloc[1] #取第2行数据data.loc['A'] #取第行索引为”A“的一行数据，data['x'] #取列索引为x的一列数据## Most frequent valuedata.mode()## Any True value in this seriesdata['A'].any()## All the values are Truedata['A'].all()data.loc[:,['x','z'] ] #表示选取所有的行以及columns为a,b的列；data.loc[['A','B'],['x','z']] #表示选取'A'和'B'这两行以及columns为x,z的列的并集；data.iloc[1:3,1:3] #数据切片操作，切连续的数据块data.iloc[[0,2],[1,2]] #即可以自由选取行位置，和列位置对应的数据，切零散的数据块data[data&gt;2] #表示选取数据集中大于0的数据data[data.x&gt;5] #表示选取数据集中x这一列大于5的所有的行a1=data.copy()a1[a1['y'].isin(['6','10'])] #表显示满足条件：列y中的值包含'6','8'的所有行。data.to_excel(r'E:\\pypractice\\Yun\\doc\\2.xls',sheet_name='Sheet1') #数据输出至Exceldata[0:2] #取前两行数据### from Dictionary to DataFrameTB = pd.Series(BB)### DataFrame sortTB = TB.sort_values(ascending=False)### NaN drapdata.dropna(thresh=3) # at least 3 data we have Skills reference: 数据分析1480 NA count df=pd.read_csv('titanic_train.csv')def missing_cal(df): &quot;&quot;&quot; df :数据集 return：每个变量的缺失率 &quot;&quot;&quot; missing_series = df.isnull().sum()/df.shape[0] missing_df = pd.DataFrame(missing_series).reset_index() missing_df = missing_df.rename(columns={'index':'col', 0:'missing_pct'}) missing_df = missing_df.sort_values('missing_pct',ascending=False).reset_index(drop=True) return missing_dfmissing_cal(df) Drop/Fill NA ## Drop the columns or rows by NA valuedata.dropna(axis=0)data.dropna(axis=1)# drop na with thresholddata.dropna(thresh=3) # at least 3 data we have## Fill NA value by intdata.fillna(0)## Fill the NA value by linear interpolationdata.interpolate()## Fill te NA value with the value ahead or the nextdata.fillna(method='ffill')data.fillna(method='backfill') idmax df = pd.DataFrame({'Sp':['a','b','c','d','e','f'], 'Mt':['s1', 's1', 's2','s2','s2','s3'], 'Value':[1,2,3,4,5,6], 'Count':[3,2,5,10,10,6]})dfdf.iloc[df.groupby(['Mt']).apply(lambda x: x['Count'].idxmax())]df[&quot;rank&quot;] = df.groupby(&quot;ID&quot;)[&quot;score&quot;].rank(method=&quot;min&quot;, ascending=False).astype(np.int64)df[df[&quot;rank&quot;] == 1][[&quot;ID&quot;, &quot;class&quot;]] Merging DataFrame This is one of the most feature I like in pandas since it could automatically fill the missing value with NA. Plus, when the DataFrame goes huge, pd.concat was way faster than dataframe merge in R. df = pd.DataFrame({'id_part':['a','b','c','d'], 'pred':[0.1,0.2,0.3,0.4], 'pred_class':['women','man','cat','dog'], 'v_id':['d1','d2','d3','d1']})## Rowpd.concat([df,df], axis=1)## Columnpd.concat([df,df])## ordf.append(df) Merge by columns From: geeksforgeeks pandas # import pandas as pdimport pandas as pd# creating dataframes as df1 and df2df1 = pd.DataFrame({'ID': [1, 2, 3, 5, 7, 8], 'Name': ['Sam', 'John', 'Bridge', 'Edge', 'Joe', 'Hope']})df2 = pd.DataFrame({'ID': [1, 2, 4, 5, 6, 8, 9], 'Marks': [67, 92, 75, 83, 69, 56, 81]})df = pd.merge(df1, df2, on=&quot;ID&quot;, how=&quot;left&quot;)print(df)## multiple columnsnew_df = pd.merge(A_df, B_df, how='left', left_on=['A_c1','c2'], right_on = ['B_c1','c2']) Deleting rows by string-match df = pd.DataFrame({'a':[1,2,3,4], 'b':['s1', 'exp_s2', 's3','exps4'], 'c':[5,6,7,8], 'd':[3,2,5,10]})df[df['b'].str.contains('exp')] Sort df = pd.DataFrame([['A',1],['A',3],['A',2],['B',5],['B',9]], columns = ['name','score'])df.sort_values(['name','score'], ascending = [True,False])df.groupby('name').apply(lambda x: x.sort_values('score', ascending=False)).reset_index(drop=True) Select columns by features drinks = pd.read_csv('data/drinks.csv')## 选择所有数值型的列drinks.select_dtypes(include=['number']).head()## 选择所有字符型的列drinks.select_dtypes(include=['object']).head()drinks.select_dtypes(include=['number','object','category','datetime']).head()## 用 exclude 关键字排除指定的数据类型drinks.select_dtypes(exclude=['number']).head() str to integer (data type switch) geeksforgeeks df.astype(int)df = pd.DataFrame({'列1':['1.1','2.2','3.3'], '列2':['4.4','5.5','6.6'], '列3':['7.7','8.8','-']})df.astype({'列1':'float','列2':'float'}).dtypesdf = df.apply(pd.to_numeric, errors='coerce').fillna(0) Reduce the RAM-consume cols = ['beer_servings','continent']small_drinks = pd.read_csv('data/drinks.csv', usecols=cols) dtypes ={'continent':'category'}smaller_drinks = pd.read_csv('data/drinks.csv',usecols=cols, dtype=dtypes) 根据最大的类别筛选 DataFrame movies = pd.read_csv('data/imdb_1000.csv')counts = movies.genre.value_counts()movies[movies.genre.isin(counts.nlargest(3).index)].head() split string to columns df = pd.DataFrame({'姓名':['张 三','李 四','王 五'], '所在地':['北京-东城区','上海-黄浦区','广州-白云区']})dfdf.姓名.str.split(' ', expand=True) str.contain df.['column1'].str.cotain('A') 把 Series 里的列表转换为 DataFrame df = pd.DataFrame({'列1':['a','b','c'],'列2':[[10,20], [20,30], [30,40]]})pd.concat([df,df_new], axis='columns') 用多个函数聚合 orders = pd.read_csv('data/chipotle.tsv', sep='\\t')orders.groupby('order_id').item_price.agg(['sum','count']).head() 分组聚合 import pandas as pddf = pd.DataFrame({'key1':['a', 'a', 'b', 'b', 'a'], 'key2':['one', 'two', 'one', 'two', 'one'], 'data1':np.random.randn(5), 'data2':np.random.randn(5)})dffor name, group in df.groupby('key1'): print(name) print(group)dict(list(df.groupby('key1'))) 通过字典或Series进行分组 people = pd.DataFrame(np.random.randn(5, 5), columns=['a', 'b', 'c', 'd', 'e'], index=['Joe', 'Steve', 'Wes', 'Jim', 'Travis'])mapping = {'a':'red', 'b':'red', 'c':'blue', 'd':'blue', 'e':'red', 'f':'orange'}by_column = people.groupby(mapping, axis=1)by_column.sum() Connect to the matplotlib import numpy as npimport pandas as pdfrom matplotlib import pyplot as pltdates=pd.date_range('20180310',periods=6)df = pd.DataFrame(np.random.randn(6,4), index=dates, columns=['A','B','C','D'])df.plot()plt.show() more for plot() df.hist(column='A', figsize=(4,3))df.boxplot(column='A', figsize=(4,3)) Data Description: Summary and count data.mean() #默认对每一列的数据求平均值；若加上参数a.mean(1)则对每一行求平均值；data.describe() #对每一列数据进行统计，包括计数，均值，std，各个分位数等。 Count the number of elements in a column More detials: Erik Marsja; 2020 data['x'].value_counts() #统计某一列x中各个值出现的次数 Count the number of elelments and convert the result as a DataFrame jezrael; 2017 df2 = df.value_counts().rename_axis().reset_index() Read huge file with pandas check the size of the file: du -sh test.csvwc -l test.csv 1.4G test.csv 17504652 test.csv Check the normal reading time import pandas as pdimport timeT_A = time.time()TB = pd.read_csv('test.csv', sep= ' ')print(time.time() - T_A) 8.875486135482788 It tacks 8.9s for it read a 1.4GB size file # Read the file in chunks of 1000 rowsfor chunk in pd.read_csv('test.csv', chunksize=1000, sep = ' '): # Process each chunk of data print(chunk.shape)","link":"/2020/09/12/Python/Pandas/"},{"title":"Tensorflow-Numbers-k","text":"Tensorflow-Numbers-k 我也不记得这是啥了= = ##!/usr/local/bin/python3.6import numpy as npimport pandas as pdfrom sklearn.model_selection import train_test_splitfrom tensorflow.python import kerasfrom tensorflow.python.keras.models import Sequentialfrom tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropouta=pd.read_csv(&quot;train.csv&quot;)a.drop('label', axis=1)img_rows, img_cols = 28, 28num_classes = 10def data_prep(raw): out_y = keras.utils.to_categorical(raw.label, num_classes) num_images = raw.shape[0] x_as_array = raw.values[:,1:] x_shaped_array = x_as_array.reshape(num_images, img_rows, img_cols, 1) out_x = x_shaped_array / 255 return out_x, out_ytrain_size = 30000train_file = &quot;train.csv&quot;raw_data = pd.read_csv(train_file)x, y = data_prep(raw_data)model = Sequential()model.add(Conv2D(30, kernel_size=(3, 3), strides=2, activation='relu', input_shape=(img_rows, img_cols, 1)))Dropout(0.5)model.add(Conv2D(30, kernel_size=(3, 3), strides=2, activation='relu'))Dropout(0.5)model.add(Flatten())model.add(Dense(128, activation='relu'))model.add(Dense(num_classes, activation='softmax'))model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])model.fit(x, y, batch_size=128, epochs=2, validation_split = 0.2)","link":"/2020/01/22/Python/Tensorflow-Numbers-k/"},{"title":"Tensorflow","text":"Tensorflow ##!/usr/locol/bin/python3.6import tensorflow as tfimport numpy as np## creat datax_data = np.random.rand(100).astype(np.float32)y_data = x_data*0.1 + 0.3#### creat tnsorflow structure startWeights = tf.Variable(tf.random_uniform([1],-1.0,1.0))biases = tf.Variable(tf.zeros([1]))y = Weightess =tf.Session()*x_data + biasesloss = tf.reduce_mean(tf.square(y - y_data))optimizer = tf.train.GradientDescentOptimizer(0.5)train = optimizer.minimize(loss)init = tf.initialize_all_variables()###create tensorflow structure end ###sess =tf.Session()sess.run(init)for step in range(201): sess.run(train) if step % 20 == 0: print(step, sess.run(Weights),sess.run(biases))#### add a laier###def add_layer(inputs, in_size, out_size, activation_function=None): Weights = tf.Variable(tf.random_normal([in_size, out_size])) biases = tf.Variable(tf.zeros([1, out_size]) + 0.1) Wx_plus_b = tf.matmul(inputs, Weights) + biases if activation_function is None: outputs = Wx_plus_b else: outputs = activation_function(Wx_plus_b) return outputs#####################From https://tensorflow.google.cn/get_started/premade_estimators###############","link":"/2020/01/22/Python/Tensorflow/"},{"title":"Transfer_Learning","text":"Transfer_Learning ##!/usr/local/bin/python3.6from tensorflow.python.keras.applications import ResNet50from tensorflow.python.keras.models import Sequentialfrom tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2Dnum_classes = 2resnet_weights_path = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'my_new_model = Sequential()my_new_model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))my_new_model.add(Dense(num_classes, activation='softmax'))my_new_model.layers[0].trainable = Falsemy_new_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])######## Fit Model ###from tensorflow.python.keras.applications.resnet50 import preprocess_inputfrom tensorflow.python.keras.preprocessing.image import ImageDataGeneratorimage_size = 224data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)train_generator = data_generator.flow_from_directory( './train', target_size=(image_size, image_size), batch_size=24, class_mode='categorical')validation_generator = data_generator.flow_from_directory( './val', target_size=(image_size, image_size), class_mode='categorical')my_new_model.fit_generator( train_generator, steps_per_epoch=3, validation_data=validation_generator, validation_steps=1)","link":"/2020/01/22/Python/Transfer_Learning/"},{"title":"VedioSlice.py","text":"VedioSlice.py ##!/usr/bin/env python3## -*- coding: utf-8 -*-## @Time : 2020/4/18## @Author : Karobben## @Site : China## @File : VedioSlice.py## @Software: Atomimport argparseparser = argparse.ArgumentParser()parser.add_argument('-i','-I','--input', help='Input vedio file') #输入文件parser.add_argument('-o','-U','--output', default = &quot;out_test.avi&quot;, help='Output vedio file, default as &quot;out_test.avi&quot;') #输入文件parser.add_argument('-s','-S','--Start', type = int, default = 0, help='Start from X second. default from 0') #输入文件parser.add_argument('-e','-E','--End', type = int, default = 1, help='End at X second, defalt at 1s') #输入文件##获取参数args = parser.parse_args()INPUT = args.inputOUTPUT = args.outputSlice_S = args.StartSlice_E = args.Endimport cv2import numpy as np##INPUT = 'bug.avi'cap = cv2.VideoCapture(INPUT)fps_c = cap.get(cv2.CAP_PROP_FPS)Vedio_h = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)Vedio_w = cap.get(cv2.CAP_PROP_FRAME_WIDTH)print(&quot;Current fps:&quot;,fps_c)Slice_S = Slice_S* fps_cSlice_E = Slice_E* fps_c##OUTPUT = &quot;out_test.avi&quot;fps_o = fps_cOut_size = (int(Vedio_w),int(Vedio_h))fourcc = cv2.VideoWriter_fourcc('M','J','P','G')videowriter = cv2.VideoWriter(OUTPUT,fourcc,fps_o,Out_size)Num = 0while (True): Num += 1 ret,frame=cap.read() if Num &gt;= Slice_S and Num &lt;= Slice_E: videowriter.write(frame) if Num &gt;= Slice_E: breakvideowriter.release() How to use it ## print the vedio from 0s to 1s to out_test.aviVedio_slice.py -i bug.avi## print the vedio from 10s to 20s to sliced.avi fileVedio_slice.py -i bug.avi -s 10 -e 20 -o sliced.avi","link":"/2020/06/23/Python/VedioSlice.py/"},{"title":"Vedio_reverse.py","text":"Vedio_reverse.py ##视频倒放 ##!/usr/bin/env python3## -*- coding: utf-8 -*-## @Time : 2020/4/18## @Author : Karobben## @Site : China## @File : VedioSlice.py## @Software: Atomimport argparseparser = argparse.ArgumentParser()parser.add_argument('-i','-I','--input', help='Input vedio file') #输入文件parser.add_argument('-o','-U','--output', default = &quot;out_test.avi&quot;, help='Output vedio file, default as &quot;out_test.avi&quot;') #输入文件##获取参数args = parser.parse_args()INPUT = args.inputOUTPUT = args.outputimport cv2import numpy as np##INPUT = 'bug.avi'cap = cv2.VideoCapture(INPUT)fps_c = cap.get(cv2.CAP_PROP_FPS)Vedio_h = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)Vedio_w = cap.get(cv2.CAP_PROP_FRAME_WIDTH)print(&quot;Current fps:&quot;,fps_c)##OUTPUT = &quot;out_test.avi&quot;fps_o = fps_cOut_size = (int(Vedio_w),int(Vedio_h))fourcc = cv2.VideoWriter_fourcc('M','J','P','G')videowriter = cv2.VideoWriter(OUTPUT,fourcc,fps_o,Out_size)List= []while True: ret,frame=cap.read() try: frame[0,0,0] != None List += [frame] except: breakfor i in List[::-1]: videowriter.write(i)videowriter.release() Vedio_reverse.py -i caopazi.avi -o test.avi","link":"/2020/06/23/Python/Vedio_reverse.py/"},{"title":"argparse lib in Python | Writing python scripts","text":"argparse (参数库) 1. sys sys.argv[1] 2. argparse 1. Quick Start import argparseparser = argparse.ArgumentParser()parser.add_argument('-i','-I','--input') #输入文件parser.add_argument('-o','-U','--output') #输入文件##获取参数args = parser.parse_args()INPUT = args.inputRANGE = args.output run as python3 test.py -i inputfile -o outpufile 2. Important arguments #####with type and defaultparser.add_argument( '--width', dest='num_hands', type = int, default = 80, help='Max number of hands to detect.') 3. Reading *.png 3.1 nargs=“+” (One/More) import argparseparser = argparse.ArgumentParser()parser.add_argument('-i','-I','--input',nargs='+') #输入文件args = parser.parse_args()INPUT = args.inputprint(INPUT) $ python3.7 test.py -i Ms*['Msg', 'Msg2'] 3.2 nargs=“?” (None/One) import argparseparser = argparse.ArgumentParser()parser.add_argument('-i','-I','--input', default='a', nargs='?') #输入文件args = parser.parse_args()INPUT = args.inputprint(INPUT) $ python3.7 test.pya$ python3.7 test.py -iNone$ python3.7 test.py -i bb","link":"/2020/01/22/Python/argparse/"},{"title":"Python hello world","text":"Integer/Float calculation ################################# caculating ########################Operator Description Example+ Addition operator 100 + 45 = 145- Subtraction operator 500 - 65 = 435* Multiplication operator 25 * 4 = 100/ Float Division Operator 10 / 2 = 5.0// Integer Division Operator 10 / 2 = 5** Exponentiation Operator 5 ** 3 = 125% Remainder Operator 10 % 3 = 1 # 10 / 3 = 3 ... 1 Float formate ##########print##########pi = 3.141592653print('%10.3f' % pi) #字段宽10，精度3## 3.142print(&quot;pi = %.*f&quot; % (3,pi)) #用*从后面的元组中读取字段宽度或精度## pi = 3.142print('%010.3f' % pi) #用0填充空白## 000003.142print('%-10.3f' % pi) #左对齐## 3.142print('%+f' % pi) #显示正负号## +3.141593 List ## duplicats removingA = [1,1,1,2,3,4,3]print(A) Remove duplicates from list list(set(A)) int list to str list [str(x) for x in int_list] or a_list = [&quot;1&quot;, &quot;2&quot;, &quot;3&quot;]##int list to str listlist(map(str, a_list))##str list to int listlist(map(int, a_list)) 逐个相减 c = [b[i] - a[i] for i in range(len(a))] Compare Two list l = [1, 2, 3, 5]l_one = [2, 8, 6, 10]print set(l) &amp; set(l_one) Time import timeprint(time.time())time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, time.localtime()) Date caculating zhengxiangwen 2017 import datetime #导入日期时间模块today = datetime.date.today() #获得今天的日期print today #输出今天日期2016-01-25yesterday = today - datetime.timedelta(days=1) #用今天日期减掉时间差，参数为1天，获得昨天的日期print yesterday2016-01-25tomorrow = today + datetime.timedelta(days=1) #用今天日期加上时间差，参数为1天，获得明天的日期print tomorrow2016-01-25print &quot;昨天:%s， 今天:%s， 明天：%s&quot; % (yesterday, today, tomorrow) # For loop for x in range(0,10): print (x,end = '') Read/Write a file ###read filef = open(&quot;demofile.txt&quot;, &quot;r&quot;)print(f.read())with open(fname) as f: content = f.readlines()### write to filefo = open(&quot;foo.txt&quot;, &quot;w&quot;)fo.write( &quot;www.runoob.com!\\nVery good site!\\n&quot;)fo.close()## wirte at the end of the filewith open('something.txt', 'a') as f: f.write('text to be appended') print A =&quot; &quot;B =u&quot;\\u2581&quot;C =u&quot;\\u2582&quot;D =u&quot;\\u2583&quot;E =u&quot;\\u2584&quot;F =u&quot;\\u2585&quot;G =u&quot;\\u2586&quot;H =u&quot;\\u2587&quot;I =u&quot;\\u2588&quot;for i in A,B,C,D,E,F,G,H,I: print(&quot;\\x1b[3;45;6m%s\\x1b[0m&quot;%(i),end='') path import pathlibpathlib.Path(__file__).parent.absolute()import pathlibpathlib.Path().absolute()import ossys.path[0]## Chage Workind Directorimport osos.chdir(&quot;../&quot;) import ## import from the same directoryimport XXX## import from the directories in the same directoryfrom Directory import xxx## import from .. directoryimport syssys.path.append(&quot;..&quot;)import xxx str to var for i in range(4): name='v'+str(i) locals()['v'+str(i)]=iprint v1,v2,v3 Dictionary Find the max value from a dictionary d = {'a': 10, 'b': 5, 'c': 20}max_value = max(d, key=d.get)print(max_value) c","link":"/2020/01/22/Python/base/"},{"title":"Cython","text":"Cython Tutorial: cython Hello world First, write the code in the file helloworld.pyx print(&quot;Hello World&quot;) Then, write a file setup.py with codes below: from setuptools import setupfrom Cython.Build import cythonizesetup( ext_modules = cythonize(&quot;helloworld.pyx&quot;)) Now, let’s setup the Cython in the terminal/cmd python setup.py build_ext --inplace Compiling helloworld.pyx because it changed. [1/1] Cythonizing helloworld.pyx /home/ken/.local/lib/python3.8/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /home/ken/test/helloworld.pyx tree = Parsing.p_module(s, pxd, full_module_name) running build_ext building 'helloworld' extension gcc -pthread -B /mnt/8A26661926660713/Conda/miniconda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /mnt/8A26661926660713/Conda/miniconda/include -fPIC -O2 -isystem /mnt/8A26661926660713/Conda/miniconda/include -fPIC -I/mnt/8A26661926660713/Conda/miniconda/include/python3.8 -c helloworld.c -o build/temp.linux-x86_64-cpython-38/helloworld.o gcc -pthread -B /mnt/8A26661926660713/Conda/miniconda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/mnt/8A26661926660713/Conda/miniconda/lib -Wl,-rpath-link,/mnt/8A26661926660713/Conda/miniconda/lib -L/mnt/8A26661926660713/Conda/miniconda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/mnt/8A26661926660713/Conda/miniconda/lib -Wl,-rpath-link,/mnt/8A26661926660713/Conda/miniconda/lib -L/mnt/8A26661926660713/Conda/miniconda/lib build/temp.linux-x86_64-cpython-38/helloworld.o -o build/lib.linux-x86_64-cpython-38/helloworld.cpython-38-x86_64-linux-gnu.so copying build/lib.linux-x86_64-cpython-38/helloworld.cpython-38-x86_64-linux-gnu.so -> Finally, import it in any python interpreter: import helloworld Hello World Speed up the for loop First, let’s create a file named example.pyx with the following Cython code: # example.pyxdef sum_elements(double[:] array): cdef int i cdef double result = 0 for i in range(array.shape[0]): result += array[i] return result To compile and use the Cython code, you’ll need a setup.py file. Create a setup.py file with the following content: # setup.pyfrom setuptools import setupfrom Cython.Build import cythonizeimport numpy as npsetup( ext_modules=cythonize(&quot;example.pyx&quot;), include_dirs=[np.get_include()]) Next, compile the example.pyx file: python setup.py build_ext --inplace Now, you can test it in the python import timeimport numpy as npfrom example import sum_elements# define the same function in python to compare the time consumingdef sum_elements_py(array): result = 0 for i in range(array.shape[0]): result += array[i] return(result)array = np.array([1.0, 2.0, 3.0, 4.0, 5.0]*200000, dtype=np.float64)A = time.time()sum_elements(array)print(time.time() - A)A = time.time()sum_elements_py(array)print(time.time() - A)from numba import njit@njitdef sum_elements_numba(array): result = 0.0 for i in range(array.shape[0]): result += array[i] return result 0.001369476318359375 0.11698126792907715 When there are 1M loops, Cython is 85 times faster than python. array = np.array([1.0, 2.0, 3.0, 4.0, 5.0]*20000000, dtype=np.float64)A = time.time()sum_elements_py(array)print(time.time() - A)A = time.time()sum_elements(array)print(time.time() - A)A = time.time()sum_elements_numba(array)print(time.time() - A) 13.218583345413208 0.11868596076965332 0.19266653060913086 When there are 10000M loops, Cython is 85 times faster than python. pre { background-color:#38393d; color: #5fd381; }","link":"/2023/05/17/Python/cython/"},{"title":"Python: Data Calculating Skills","text":"Python: Data Calculating Skills 2D points cloud Distance of two points delftstack # from mathmath.dist()# from scipyfrom scipy.spatial import distancea = (1, 2, 3)b = (4, 5, 6)print(distance.euclidean(a, b)) Longest distance of points in a point cloud The longest distance of points between any two points. Yann, 2015 from numpy import random, nanmax, argmax, unravel_indexfrom scipy.spatial.distance import pdist, squareformA = random.randint(-5,5, (500,2))D = pdist(A)D = squareform(D);N, [I_row, I_col] = nanmax(D), unravel_index( argmax(D), D.shape )# result:# Point 1:A[I_row]# Point 2:A[I_col] Nearest adjacent point import numpy as npimport mathp1 = [1,2]p_list = [[2,1], [1,2], [0,0]]# np.array([math.dist(p1, i) for i in p_list]).argmin() can return the index rather than valuep_list[np.array([math.dist(p1, i) for i in p_list]).argmin()] Distance from points to line © DotPi, 2016 point p3 to line p1-p2 from numpy.linalg import normp1=(x1,y1)p2=(x2,y2)p3=(x3,y3)d = norm(np.cross(p2-p1, p1-p3))/norm(p2-p1) Distance from points to rectangle p1----p2 | p5 | | | p4----p3 from point p5 to rectangle p1,p2,p3,p4 from numpy.linalg import normdef lin_dist(p1, p2, p3): d = norm(np.cross(p2-p1, p1-p3))/norm(p2-p1) return ddef p_rect(p1,p2,p3,p4,p5): d1 = lin_dist(p1,p2,p5) d2 = lin_dist(p1,p4,p5) d3 = lin_dist(p3,p2,p5) d4 = lin_dist(p3,p4,p5) return min([d1,d2,d3,d4])p1=(x1,y1)p2=(x2,y2)p3=(x3,y3)p4=(x4,y4)p5=(x5,y5)p_rect(p1,p2,p3,p4,p5) Points rotation © an0nym0use; 2020 P1 and P2 are points in points. Rotate the P1 to the same level as P2, so as the rest of others. import numpy as npdef rotate(point, origin, degrees): radians = np.deg2rad(degrees) x,y = point offset_x, offset_y = origin adjusted_x = (x - offset_x) adjusted_y = (y - offset_y) cos_rad = np.cos(radians) sin_rad = np.sin(radians) qx = offset_x + cos_rad * adjusted_x + sin_rad * adjusted_y qy = offset_y + -sin_rad * adjusted_x + cos_rad * adjusted_y return qx, qy Angles of two points This codes works perfect to me. © sabbahillel; 2017 import mathmyradians = math.atan2(targetY-gunY, targetX-gunX)mydegrees = math.degrees(myradians)myradians = math.radians(mydegrees)def point2agl(P1, P2): myradians = math.atan2(P1[1]-P2[1], P1[0]-P2[0]) mydegrees = math.degrees(myradians) return mydegrees Angle of three points © Manivannan Murugavel import mathdef getAngle(a, b, c): ang = math.degrees(math.atan2(c[1]-b[1], c[0]-b[0]) - math.atan2(a[1]-b[1], a[0]-b[0])) return return ang - 360 if ang &gt;= 360 else angprint(getAngle((5, 0), (0, 0), (0, 5))) Angle of two vectors © adamsmith.haus import numpy as npimport mathvector_1 = [0, 1]vector_2 = [1, 0]def Vector_angle(vector_1, vector_2): unit_vector_1 = vector_1 / np.linalg.norm(vector_1) unit_vector_2 = vector_2 / np.linalg.norm(vector_2) dot_product = np.dot(unit_vector_1, unit_vector_2) angle = np.arccos(dot_product) mydegrees = math.degrees(angle) return mydegreesang = Vector_angle(vector_1, vector_2)print(ang) SO, we can have angle of 4 points: P1 = np.array([0,1])P2 = np.array([1,1])P3 = np.array([1,2])P4 = np.array([3,1])vector_1 = P2 - P1vector_2 = P3 - P2ang = Vector_angle(vector_1, vector_2)print(ang)# or:def Points4_angle(P1, P2, P3, P4): P1 = np.array(P1) P2 = np.array(P2) P3 = np.array(P3) P4 = np.array(P4) vector_1 = P2 - P1 vector_2 = P4 - P3 unit_vector_1 = vector_1 / np.linalg.norm(vector_1) unit_vector_2 = vector_2 / np.linalg.norm(vector_2) dot_product = np.dot(unit_vector_1, unit_vector_2) angle = np.arccos(dot_product) mydegrees = math.degrees(angle) return mydegrees Find the end point by angele and length import mathimport matplotlib.pyplot as pltAngle = 30Radian = 0.5Origin = (0.5, 0.5)End_x = math.cos(math.radians(Angle)) * RadianEnd_y = math.sin(math.radians(Angle)) * Radianplt.arrow(Origin[0], Origin[0], End_x, End_y, head_width = 0.1, width = 0.03)plt.show() Test import cv2import pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport seaborn as snsNP_result = np.load(&quot;/mnt/8A26661926660713/Deng/Cell_segmentation/CellSegmentation/Results/220214_all_channels/images/lgl.3d.casp.1.lsm2_seg.npy&quot;, allow_pickle=True)A = NP_result.all()['masks']# Create the multiindex we'll need for the seriesindex = pd.MultiIndex.from_product( (*map(range, A.shape[:2]), (['r'])), names=('col','row', None))# Can be chained but separated for use in explanationdf = pd.Series(A.flatten(), index=index)df = df.unstack()df = df.reset_index().reindex(columns=['row', 'col', 'r'])sns.scatterplot(data=df[df.r!=0], x= &quot;row&quot;, y=&quot;col&quot;, hue = &quot;r&quot;)plt.show() Time format Second to format Hour and min studytonight.com seconds = 12601seconds = seconds % (24 * 3600)hour = seconds // 3600seconds %= 3600minutes = seconds // 60seconds %= 60print(&quot;%d:%02d:%02d&quot; % (hour, minutes, seconds)) 3:30:01","link":"/2022/03/07/Python/data_skill/"},{"title":"Brownian Motion","text":"Codes from: Tirthajyoti Sarkar import numpy as npimport matplotlib.pyplot as pltclass Brownian(): &quot;&quot;&quot; A Brownian motion class constructor &quot;&quot;&quot; def __init__(self,x0=0): &quot;&quot;&quot; Init class &quot;&quot;&quot; assert (type(x0)==float or type(x0)==int or x0 is None), &quot;Expect a float or None for the initial value&quot; self.x0 = float(x0) def gen_random_walk(self,n_step=100): &quot;&quot;&quot; Generate motion by random walk Arguments: n_step: Number of steps Returns: A NumPy array with `n_steps` points &quot;&quot;&quot; # Warning about the small number of steps if n_step &lt; 30: print(&quot;WARNING! The number of steps is small. It may not generate a good stochastic process sequence!&quot;) w = np.ones(n_step)*self.x0 for i in range(1,n_step): # Sampling from the Normal distribution with probability 1/2 yi = np.random.choice([1,-1]) # Weiner process w[i] = w[i-1]+(yi/np.sqrt(n_step)) return w def gen_normal(self,n_step=100): &quot;&quot;&quot; Generate motion by drawing from the Normal distribution Arguments: n_step: Number of steps Returns: A NumPy array with `n_steps` points &quot;&quot;&quot; if n_step &lt; 30: print(&quot;WARNING! The number of steps is small. It may not generate a good stochastic process sequence!&quot;) w = np.ones(n_step)*self.x0 for i in range(1,n_step): # Sampling from the Normal distribution yi = np.random.normal() # Weiner process w[i] = w[i-1]+(yi/np.sqrt(n_step)) return w def stock_price( self, s0=100, mu=0.2, sigma=0.68, deltaT=52, dt=0.1 ): &quot;&quot;&quot; Models a stock price S(t) using the Weiner process W(t) as `S(t) = S(0).exp{(mu-(sigma^2/2).t)+sigma.W(t)}` Arguments: s0: Iniital stock price, default 100 mu: 'Drift' of the stock (upwards or downwards), default 1 sigma: 'Volatility' of the stock, default 1 deltaT: The time period for which the future prices are computed, default 52 (as in 52 weeks) dt (optional): The granularity of the time-period, default 0.1 Returns: s: A NumPy array with the simulated stock prices over the time-period deltaT &quot;&quot;&quot; n_step = int(deltaT/dt) time_vector = np.linspace(0,deltaT,num=n_step) # Stock variation stock_var = (mu-(sigma**2/2))*time_vector # Forcefully set the initial value to zero for the stock price simulation self.x0=0 # Weiner process (calls the `gen_normal` method) weiner_process = sigma*self.gen_normal(n_step) # Add two time series, take exponent, and multiply by the initial stock price s = s0*(np.exp(stock_var+weiner_process)) return sb1 = Brownian()b2 = Brownian()x = b1.gen_normal(10000)y = b2.gen_normal(10000)colors = np.linspace(0, 1, len(x))plt.plot(x,y, color = 'grey')plt.scatter(x,y, c=colors, cmap='viridis')xmax,xmin,ymax,ymin = x.max(),x.min(),y.max(),y.min()scale_factor = 1.25xmax,xmin,ymax,ymin = xmax*scale_factor,xmin*scale_factor,ymax*scale_factor,ymin*scale_factorplt.xlim(xmin,xmax)plt.ylim(ymin,ymax)plt.show() Use Opencv to Show the Animation import cv2import numpy as npdef Position_update(Point1): yi1 = np.random.normal()*10 yi2 = np.random.normal()*10 Point1[0] = Point1[0] + int(yi1/np.sqrt(30)) Point1[1] = Point1[1] + int(yi2/np.sqrt(30)) return Point1MAP = np.zeros([1500, 1500, 3], dtype=np.uint8)MAP[MAP==0] = 255Point = {}for i in range(1000): Point.update({i:[750,750]})b1 = Brownian(1)b2 = Brownian(1)fourcc = cv2.VideoWriter_fourcc(*'XVID')out = cv2.VideoWriter('output.avi',fourcc, 20.0, (1080,1080))while (True): MAP = np.zeros([1080, 1080, 3], dtype=np.uint8) MAP[MAP==0] = 255 for i in range(1000): Point[i]=Position_update(Point[i]) cv2.circle(MAP, Point[i], 3, [0,0,0], 2) cv2.imshow(&quot;video&quot;,MAP) out.write(MAP) if cv2.waitKey(25)&amp;0xFF==ord('q'): cv2.destroyAllWindows() break Detection import cv2import numpy as np# Map Edge detection# Direction ReversePoint1 = { &quot;O&quot;:[200,200], &quot;N&quot;:[20,10], &quot;Dit&quot;:[0,0], &quot;Sp&quot;: 1}def Map_bonce(Point, X, Y): if Point['N'][0] &lt;0: Point['N'][0] *= -1 if Point['N'][1] &lt;0: Point['N'][1] *= -1 if Point['N'][0] &gt; X: Point['N'][0] = X - (Point['N'][0]- X) if Point['N'][1] &gt; Y: Point['N'][1] = Y - (Point['N'][1]- Y) return(Point)Point = {}for i in range(10): Point.update({i:{ &quot;O&quot;:np.array([50,50]), &quot;N&quot;:np.array([50,50]), &quot;Dit&quot;:np.array([0,0]), &quot;Sp&quot;: 1 }})while (True): MAP = np.zeros([100, 100, 3], dtype=np.uint8) MAP[MAP==0] = 255 for i in range(10): Point[i][&quot;O&quot;] = np.array(Point[i][&quot;N&quot;]) Point[i][&quot;N&quot;] = Position_update(Point[i][&quot;N&quot;]) Point[i]= Map_bonce(Point[i], len(MAP[0]), len(MAP)) # update old position and direction Point[i][&quot;Dit&quot;]=Point[i][&quot;N&quot;] - Point[i][&quot;O&quot;] cv2.circle(MAP, Point[i][&quot;N&quot;], 3, [0,0,0], 2) print(Point[i]) cv2.imshow(&quot;video&quot;,MAP) if cv2.waitKey(25)&amp;0xFF==ord('q'): cv2.destroyAllWindows() break Collision by the center point import pandas as pd# Overlap detectiondef Map_bonce(Point, X, Y): if Point['N'][0] &lt;0: Point['N'][0] *= -1 if Point['N'][1] &lt;0: Point['N'][1] *= -1 if Point['N'][0] &gt; X: Point['N'][0] = X - (Point['N'][0]- X) if Point['N'][1] &gt; Y: Point['N'][1] = Y - (Point['N'][1]- Y) return(Point)Point = {}N_point = 300for i in range(N_point): Point.update({i:{ &quot;O&quot;:np.array([50,50]), &quot;N&quot;:np.array([50,50]), &quot;Dit&quot;:np.array([0,0]), &quot;Sp&quot;: 1 }})while (True): MAP = np.zeros([500, 500, 3], dtype=np.uint8) MAP[MAP==0] = 255 for i in range(N_point): Point[i][&quot;O&quot;] = np.array(Point[i][&quot;N&quot;]) Point[i][&quot;N&quot;] = Position_update(Point[i][&quot;N&quot;]) # Check map-collision Point[i]= Map_bonce(Point[i], len(MAP[0]), len(MAP)) # Particals Collision # update old position and direction Point[i][&quot;Dit&quot;]=Point[i][&quot;N&quot;] - Point[i][&quot;O&quot;] while True in pd.DataFrame([Point[i]['N'] for i in Point]).duplicated().tolist(): TMP = pd.DataFrame([Point[i]['N'] for i in Point]) TMP2 = TMP[TMP.duplicated()] TMP == TMP2.iloc[0,:] INDEX = [i for i in Point if Point[i]['N'].tolist() == Point[TMP2.index[0]]['N'].tolist()] print(INDEX) for i in range(int(len(INDEX)/2)): INDEX_1 = INDEX[i*2] INDEX_2 = INDEX[i*2+1] Point[INDEX_1]['N'] +=Point[INDEX_2]['Dit'] Point[INDEX_2]['N'] +=Point[INDEX_1]['Dit'] Point[INDEX_1][&quot;O&quot;] = np.array(Point[INDEX_1][&quot;N&quot;]) Point[INDEX_2][&quot;O&quot;] = np.array(Point[INDEX_2][&quot;N&quot;]) if Point[INDEX_1][&quot;O&quot;].tolist() == Point[INDEX_1][&quot;N&quot;].tolist(): Point[i][&quot;N&quot;] = Position_update(Point[i][&quot;N&quot;]) if Point[INDEX_2][&quot;O&quot;].tolist() == Point[INDEX_2][&quot;N&quot;].tolist(): Point[INDEX_2][&quot;N&quot;] = Position_update(Point[INDEX_2][&quot;N&quot;]) Point[INDEX_1][&quot;Dit&quot;]=Point[INDEX_1][&quot;N&quot;] - Point[INDEX_1][&quot;O&quot;] Point[INDEX_2][&quot;Dit&quot;]=Point[INDEX_2][&quot;N&quot;] - Point[INDEX_2][&quot;O&quot;] # Check map-collision Point[INDEX_1]= Map_bonce(Point[INDEX_1], len(MAP[0]), len(MAP)) Point[INDEX_2]= Map_bonce(Point[INDEX_2], len(MAP[0]), len(MAP)) for i in range(N_point): cv2.circle(MAP, Point[i][&quot;N&quot;], 3, [0,0,0], 2) print(Point[i]) cv2.imshow(&quot;video&quot;,MAP) if cv2.waitKey(25)&amp;0xFF==ord('q'): cv2.destroyAllWindows() break Collision based on the mask mask circle # Circle Maskdef Cir_mas(Radian): x = np.arange(0, Radian *2 +1) y = np.arange(0, Radian *2 +1) arr = np.zeros((y.size, x.size)) cx = Radian +1 cy = Radian +1 r = Radian # The two lines below could be merged, but I stored the mask # for code clarity. mask = (x[np.newaxis,:]-cx)**2 + (y[:,np.newaxis]-cy)**2 &lt; r**2 TMP = pd.melt(pd.DataFrame(mask).reset_index(), id_vars='index') MASK = TMP.iloc[:,:2][TMP.value==True].to_numpy()-[Radian+1,Radian+1] return def Map_bonce(Point, X, Y): if Point['N'][0] &lt;0: Point['N'][0] *= -1 if Point['N'][1] &lt;0: Point['N'][1] *= -1 if Point['N'][0] &gt; X: Point['N'][0] = X - (Point['N'][0]- X) if Point['N'][1] &gt; Y: Point['N'][1] = Y - (Point['N'][1]- Y) return(Point)Point = {}N_point = 50for i in range(N_point): X = np.random.choice(range(500)) Y = np.random.choice(range(500)) Point.update({i:{ &quot;O&quot;:np.array([X,Y]), &quot;N&quot;:np.array([X,Y]), &quot;Dit&quot;:np.array([0,0]), &quot;Ms&quot;: Cir_mas(3), &quot;Sp&quot;: 1 }})def Point_TB(Point): TB = pd.DataFrame() for i in Point: tmp = pd.DataFrame(Point[i]['Ms']) + Point[i]['N'] tmp['index'] = i TB = pd.concat([TB, tmp]) return TBwhile (True): MAP = np.zeros([500, 500, 3], dtype=np.uint8) MAP[MAP==0] = 255 for i in range(N_point): Point[i][&quot;O&quot;] = np.array(Point[i][&quot;N&quot;]) Point[i][&quot;N&quot;] = Position_update(Point[i][&quot;N&quot;]) # Check map-collision Point[i]= Map_bonce(Point[i], len(MAP[0]), len(MAP)) # Particals Collision # update old position and direction Point[i][&quot;Dit&quot;]=Point[i][&quot;N&quot;] - Point[i][&quot;O&quot;] while True in Point_TB(Point).iloc[:,:2].duplicated().tolist(): TMP = Point_TB(Point) TMP2 = TMP[TMP.iloc[:,:2].duplicated()] INDEX = TMP[[i== TMP2.iloc[:,:2].to_numpy().tolist()[0] for i in TMP.iloc[:,:2].to_numpy().tolist()]]['index'].to_numpy() print(INDEX) for i in range(int(len(INDEX)/2)): INDEX_1 = INDEX[i*2] INDEX_2 = INDEX[i*2+1] Point[INDEX_1]['N'] +=Point[INDEX_2]['Dit'] Point[INDEX_2]['N'] +=Point[INDEX_1]['Dit'] Point[INDEX_1][&quot;O&quot;] = np.array(Point[INDEX_1][&quot;N&quot;]) Point[INDEX_2][&quot;O&quot;] = np.array(Point[INDEX_2][&quot;N&quot;]) if Point[INDEX_1][&quot;O&quot;].tolist() == Point[INDEX_1][&quot;N&quot;].tolist(): Point[i][&quot;N&quot;] = Position_update(Point[i][&quot;N&quot;]) if Point[INDEX_2][&quot;O&quot;].tolist() == Point[INDEX_2][&quot;N&quot;].tolist(): Point[INDEX_2][&quot;N&quot;] = Position_update(Point[INDEX_2][&quot;N&quot;]) Point[INDEX_1][&quot;Dit&quot;]=Point[INDEX_1][&quot;N&quot;] - Point[INDEX_1][&quot;O&quot;] Point[INDEX_2][&quot;Dit&quot;]=Point[INDEX_2][&quot;N&quot;] - Point[INDEX_2][&quot;O&quot;] # Check map-collision Point[INDEX_1]= Map_bonce(Point[INDEX_1], len(MAP[0]), len(MAP)) Point[INDEX_2]= Map_bonce(Point[INDEX_2], len(MAP[0]), len(MAP)) print(Point) for i in range(N_point): cv2.circle(MAP, Point[i][&quot;N&quot;], 3, [0,0,0], 1) cv2.imshow(&quot;video&quot;,MAP) if cv2.waitKey(25)&amp;0xFF==ord('q'): cv2.destroyAllWindows() break pre { background-color:#38393d; color: #5fd381; }","link":"/2022/11/23/Python/brownian-motion/"},{"title":"Dash-bio, powered by plotly, python","text":"What is dash and how wants dash Dash is the original low-code framework for rapidly building data apps in Python, R, Julia, and F# (experimental). Written on top of Plotly.js and React.js, Dash is ideal for building and deploying data apps with customized user interfaces. It’s particularly suited for anyone who works with data. Through a couple of simple patterns, Dash abstracts away all of the technologies and protocols that are required to build a full-stack web app with interactive data visualization. Dash is simple enough that you can bind a user interface to your code in less than 10 minutes. Dash apps are rendered in the web browser. You can deploy your apps to VMs or Kubernetes clusters and then share them through URLs. Since Dash apps are viewed in the web browser, Dash is inherently cross-platform and mobile ready. There is a lot behind the framework. Plotly develops Dash and also offers a platform for writing and deploying Dash apps in an enterprise environment. If you’re interested, please get in touch. From: dash.plotly.com Examples: Dash Galleries Installation pip install dashpip install jupyter-dashpip install pandaspip install dash_bio dash_authpip install matplotlibpip install openpyxl Hello Word for Dash # Run this app with `python app.py` and# visit http://127.0.0.1:8050/ in your web browser.from dash import Dash, html, dccimport plotly.express as pximport pandas as pdapp = Dash(__name__)# assume you have a &quot;long-form&quot; data frame# see https://plotly.com/python/px-arguments/ for more optionsdf = pd.DataFrame({ &quot;Fruit&quot;: [&quot;Apples&quot;, &quot;Oranges&quot;, &quot;Bananas&quot;, &quot;Apples&quot;, &quot;Oranges&quot;, &quot;Bananas&quot;], &quot;Amount&quot;: [4, 1, 2, 2, 4, 5], &quot;City&quot;: [&quot;SF&quot;, &quot;SF&quot;, &quot;SF&quot;, &quot;Montreal&quot;, &quot;Montreal&quot;, &quot;Montreal&quot;]})fig = px.bar(df, x=&quot;Fruit&quot;, y=&quot;Amount&quot;, color=&quot;City&quot;, barmode=&quot;group&quot;)app.layout = html.Div(children=[ html.H1(children='Hello Dash'), html.Div(children=''' Dash: A web application framework for your data. '''), dcc.Graph( id='example-graph', figure=fig )])if __name__ == '__main__': app.run_server(debug=True) How Dash Works For the example above, main layouts information was stored in app.layout. It is a list. Each part is arranged horizontally from top to bottom. We can add tags for html one by one. For example, the h1 tag, div tag. Customize Hello Dash Codes for Dashboard from dash import Dash, html, dccimport plotly.express as pximport pandas as pdapp = Dash(__name__)# assume you have a &quot;long-form&quot; data frame# see https://plotly.com/python/px-arguments/ for more optionsdf = pd.DataFrame({ &quot;Fruit&quot;: [&quot;Apples&quot;, &quot;Oranges&quot;, &quot;Bananas&quot;, &quot;Apples&quot;, &quot;Oranges&quot;, &quot;Bananas&quot;], &quot;Amount&quot;: [4, 1, 2, 2, 4, 5], &quot;City&quot;: [&quot;SF&quot;, &quot;SF&quot;, &quot;SF&quot;, &quot;Montreal&quot;, &quot;Montreal&quot;, &quot;Montreal&quot;]})colors = { 'background': '#111111', 'text': '#7FDBFF'}markdown_text = '''### Dash and MarkdownOne of the greatist feature from Dash is the markdown rendering. It may can only redenring the basic features but it could be very helpful. unfortunately, it not support html tags in the markdown. **But it accepts code highlight!! Chears!!!**&lt;br&gt;&lt;pre&gt;code test, this is a code block&lt;/pre&gt;\\```bashecho hello world\\```'''fig = px.bar(df, x=&quot;Fruit&quot;, y=&quot;Amount&quot;, color=&quot;City&quot;, barmode=&quot;group&quot;)app.layout = html.Div(children=[ html.H1(children='Hello Dash', style={ 'textAlign': 'center', 'color': colors['text'] }), html.Div(children=''' Dash: A web application framework for your data. ''', style={ 'textAlign': 'center', 'color': colors['text'], }), html.Div(children=[ html.Div(children=[dcc.Graph( id='example-graph', figure=fig, style={&quot;height&quot;: 720})], style={'width':&quot;60%&quot;,'height': &quot;100%&quot;}), html.Div(children=[ dcc.Markdown(children=markdown_text), dcc.Graph(figure=fig, style={'width':&quot;100%&quot;, &quot;height&quot;: &quot;100%&quot;}) ], style={'width':&quot;40%&quot;, &quot;height&quot;: &quot;100%&quot;})] , style={'display': 'flex', &quot;height&quot;: &quot;100%&quot;} )])if __name__ == '__main__': app.run_server(debug=True) Styles Height auto-size by the window 50% of the height of the current window style={'width':&quot;100%&quot;, &quot;height&quot;: &quot;50vh&quot;} Window overflow-show style={'width':&quot;100%&quot;, &quot;max-height&quot;: &quot;50%&quot;, &quot;overflow&quot;: &quot;scroll&quot;}style={'width':&quot;100%&quot;, &quot;max-height&quot;: &quot;50%&quot;, &quot;overflow-x&quot;: &quot;scroll&quot;}style={'width':&quot;100%&quot;, &quot;max-height&quot;: &quot;50%&quot;, &quot;overflow-y&quot;: &quot;scroll&quot;} Call back Codes for Call back example from dash import Dash, dcc, html, Input, Outputapp = Dash(__name__)app.layout = html.Div([ html.H6(&quot;Change the value in the text box to see callbacks in action!&quot;), html.Div([ &quot;Input: &quot;, dcc.Input(id='my-input', value='initial value', type='text') ]), html.Br(), html.Div(id='my-output'),])@app.callback( Output(component_id='my-output', component_property='children'), Input(component_id='my-input', component_property='value'))def update_output_div(input_value): return f'Output: {input_value}'if __name__ == '__main__': app.run_server(debug=True) Example shw: dash.plotly.com Explain Input widgets is from dash.dcc.Input. By giving an id as my-input, it could be called back. After we added it in a thread @app.callback, it can update automatically whenever you made a change. For adding more callback widgets, we can add, Dropdown widgets for instance, and show the result on a new line. We can’t add the Input&amp;Output in the old thread directly. But we can add it in a new thread. Two things for callback functions: A threads is paired with function behind. The parameters in the function following the order of the Input from the @ threads. When you paired a thread and function, the like below: @app.callback( Output(&quot;id1&quot;, 'data') Input(&quot;id2&quot;, 'value') Input(&quot;id3&quot;, 'data'))def update(P1, P2): P3 = P1 + P2 return P3 In this result, it would accepts the data from widget ‘id3’ and ‘id2’. New variable P3 is returned and be assigned into the widget ‘id1’. You can use it to make a sample calculator. Codes for Call back example from dash import Dash, dcc, html, Input, Outputapp = Dash(__name__)app.layout = html.Div([ html.H6(&quot;Change the value in the text box to see callbacks in action!&quot;), html.Div([ &quot;Input: &quot;, dcc.Input(id='my-input', value='initial value', type='text'), dcc.Dropdown(['New York City', 'Montréal', 'San Francisco'], value='Montréal', id='my-input2'), ]), html.Br(), html.Div(id='my-output'), html.Div(id='my-output2'),])def TEST(): print(&quot;123&quot;)@app.callback( Output(component_id='my-output2', component_property='children'), Input(component_id='my-input2', component_property='value'),)@app.callback( Output(component_id='my-output', component_property='children'), Input(component_id='my-input', component_property='value'),)def update_output_div(input_value): return f'Output: {input_value}'if __name__ == '__main__': app.run_server(debug=True) Use local picture The easiest and lightest way to using local picture is cite a picture in Markdown. But before doing that, you should make a directory assets and then, put the picture in it. ![Picture](/assets/1.png) Plots import plotly.express as px# All settingsfig = px.scatter( # Colors for each elements color = ['A', 'B', 'C'],)## map axis textfig.update_layout( xaxis=dict(title='', tickvals= [1, 2, 3, 4, 5], # raw text in axis ticktext = ['a', 'b', 'c', 'd'] # alternative text ))# Other layout informationsfig.update_layout( # stringent size autosize=False, width=500, height=500, xaxis_title= &quot;X Axis&quot;, yaxis_title= &quot;Y Axis&quot;, title_font_color=&quot;salmon&quot;, #more details for title title={ 'y':0.9, 'x':0.5, 'font': {'size': 30}, 'xanchor': 'center', 'yanchor': 'top'})# Bar plotfig = px.bar(long_df, x=&quot;nation&quot;, y=&quot;count&quot;, color=&quot;medal&quot;, title=&quot;Long-Form Input&quot;) Blank Background for plot fig.update_layout( autosize=False, width=300, paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)', title={ 'y':0.9, 'x':0.5, 'font': {'size': 30}, 'xanchor': 'center', 'yanchor': 'top'}) Pileup example This function if for make a igv like graph. The basic example is in this link. There is a few things worth to mention: The reference genome is ‘2bit’ format, which is a binary file format designed for storing a genome consists of multiple chromosomal sequences. To create a 2bi genome, you can follow the instruction from UCSC import pysamimport collectionsimport pandas as pdimport matplotlib.pyplot as pltsamfile = pysam.AlignmentFile(&quot;WD-wts+wts149+wts149_3.s.bam&quot;, &quot;rb&quot;)Depth = []for read in samfile.fetch('X', 3134870, 3172221): Depth += [i[1] for i in read.aligned_pairs]frequency = collections.Counter(Depth)Dep_TB = pd.DataFrame(dict(frequency), index=['Freq']).TDep_TB['Loc'] = Dep_TB.indexDep_TB.Loc = pd.to_numeric(Dep_TB.Loc)plt.plot(Dep_TB.Loc, Dep_TB.Freq) pre { background-color:#38393d; color: #5fd381; }","link":"/2022/10/01/Python/dash-bio1/"},{"title":"Python Dictionary is awesome","text":"Dictionary A dictionary in Python is an unordered collection of key-value pairs. It is a mutable, indexed, and iterable data structure that is commonly used to store and retrieve data. The keys in a dictionary must be unique and immutable (strings, integers, tuples) while the values can be of any data type (strings, integers, lists, sets, other dictionaries, etc.). It could be create by my_dict = {&quot;name&quot;: &quot;John&quot;, &quot;age&quot;: 25, &quot;city&quot;: &quot;New York&quot;} Here is some basic operations for Python dictionary Creating a dictionary my_dict = {&quot;name&quot;: &quot;John&quot;, &quot;age&quot;: 25, &quot;city&quot;: &quot;New York&quot;} Accessing values using keys print(my_dict[&quot;name&quot;]) print(my_dict[&quot;age&quot;]) John 25 Adding a new key-value pair my_dict[&quot;country&quot;] = &quot;USA&quot;print(my_dict) {\"name\": \"John\", \"age\": 25, \"city\": \"New York\", \"country\": \"USA\"} Removing and Updating del my_dict[&quot;city&quot;]my_dict[&quot;age&quot;] = 26 Checking if a key exists in a dictionary if &quot;name&quot; in my_dict: print(&quot;Name is present&quot;)else: print(&quot;Name is not present&quot;)# Iterating through a dictionaryfor key, value in my_dict.items(): print(key, value) Find the max value from a dictionary d = {'a': 10, 'b': 5, 'c': 20}max_value = max(d, key=d.get)print(max_value) c pre { background-color:#38393d; color: #5fd381; }","link":"/2023/03/01/Python/dictionary/"},{"title":"Comprehensive Analysis of Large-Scale FastQC Results using Python","text":"FastqQC FastQC aims to provide a simple way to do some quality control checks on raw sequence data coming from high throughput sequencing pipelines. It provides a modular set of analyses which you can use to give a quick impression of whether your data has any problems of which you should be aware before doing any further analysis. © illumina When dealing with a large number of samples, it’s crucial to conduct quality control (QC) and scrutinize the results to identify any outliers. Filtering out low-quality data can significantly influence subsequent processes. Below is an example illustrating how we use all QC results from FastQC for cluster analysis. Summary information collect import osimport pandas as pdfrom bs4 import BeautifulSoupdef Tab_grep(Sample): html = open(Sample).read() soup = BeautifulSoup(html, features='lxml') Summary = soup.find_all('div',{&quot;class&quot;:&quot;summary&quot;})[0] Reu_l = [Sample] Cla_l = [&quot;Sample&quot;] for line in Summary.find_all(&quot;li&quot;): Cla_l += [line.get_text()] Reu_l += [str(line).split('&quot;')[1]] Result_TB = pd.DataFrame([Reu_l], columns=Cla_l) return Result_TBResult_TB = pd.DataFrame()for Sample in [i for i in os.listdir() if &quot;fastqc.html&quot; in i]: Result_TB = pd.concat([Result_TB, Tab_grep(Sample)])Result_TB.to_csv(&quot;QC.csv&quot;) Plot in R library(ggplot2)library(reshape2)TB &lt;- read.csv(&quot;QC.csv&quot;)[-1]TB_P &lt;- melt(TB, id.vars = &quot;Sample&quot;)ggplot() + geom_tile(data= TB_P, aes(Sample,variable, fill= value)) Save the picutre in one file import osimport pandas as pdfrom bs4 import BeautifulSoupdef Pic_save(Sample, OUT=&quot;/home/wliu15/OUT.md&quot;): html = open(Sample).read() soup = BeautifulSoup(html, features='lxml') F = open(OUT,&quot;a&quot;) F.write(Sample+&quot;\\n&quot;) F.write(str(soup.find('h2',{&quot;id&quot;:&quot;M5&quot;}))) F.write(str(soup.find('img',{&quot;alt&quot; : &quot;Per base sequence content&quot;}))) F.close()for Sample in [i for i in os.listdir() if &quot;fastqc.html&quot; in i]: Pic_save(Sample) Overrepresented Sequences import pandas as pdTB = pd.DataFrame()for Sample in [i for i in os.listdir() if &quot;fastqc.html&quot; in i]: if len(pd.read_html(Sample))!=1: TMP = pd.read_html(Sample)[1] TMP['Sample'] = Sample TB = pd.concat([TB, TMP]) Sequence Count Percentage Possible Source Sample 0 CCGGTAGTTATTAAAGAATTCTTTTCCATGCCCAAATGCGGCACGTACTC 33857 0.178685926 No Hit S41_L002_R2_001_fastqc.html 1 CTTGATTATGTCTGTTTCTGATAACTACATTGAACACTTTAATGCTGTTA 26767 0.141267276 No Hit S41_L002_R2_001_fastqc.html 2 GAAAGTGTCAACGATACACCCATGTGGATAAAGGAACCCATAGCCTTTAA 19126 0.100940633 No Hit S41_L002_R2_001_fastqc.html 0 GTCCTTTCGTACTAAAATATCATAATTTTTTAAAGATAGAAACCAACCTG 24695 0.145008391 No Hit S15_L002_R2_001_fastqc.html 1 CTCGTCTTTTAAATAAATTTTAGCTTTTTGACTAAAAAATAAAATTCTAT 17359 0.101931592 No Hit S15_L002_R2_001_fastqc.html 0 CTCGTCTTTTAAATAAATTTTAGCTTTTTGACTAAAAAATAAAATTCTAT 19353 0.111227104 No Hit S44_L002_R2_001_fastqc.html 1 GTCCTTTCGTACTAAAATATCACAATTTTTTAAAGATAGAAACCAACCTG 18903 0.108640828 No Hit S44_L002_R2_001_fastqc.html","link":"/2022/07/20/Python/fastqc_crawl/"},{"title":"Unsupervised Machine Learning in Python (DBSCAN; UMAP, t-SNE, etc)","text":"DBSCAN video instroctrions: Machine Learning TV: DBSCAN: Part 1; 2019; Youtube Machine Learning TV: DBSCAN: Part 1; 2019; Youtube Machine Learning TV: DBSCAN: Part 2; 2019; Youtube Blog and Papers: Li, X.; Zhang, P.; Zhu, G. DBSCAN Clustering Algorithms for Non-Uniform Density Data and Its Application in Urban Rail Passenger Aggregation Distribution. Energies 2019, 12, 3722. https://doi.org/10.3390/en12193722 Kelvin Salton do Prado: How DBSCAN works and why should we use it?; 2017 The ideas of DBscan © Li, X, et al DBscan is cluster a group of nodes by the spatial distribution density. It divided the nodes to “core point”; “border point”, and “outlier point” By given the pre-assigned diameters (of the sphere) and number of the adjacent nodes, it scan the nodes randomly. The node fit our expectation is core node. The node failed to achieve the expectation but adjacent to the core point(a) is border point. Rest of nodes are outlier points The advantage of DBscan is Outlier points (Noises) is tolerated. (Unlike k-means) It can detect the cluster under a cluster. (Not like spherical-shape cluster) DNscan in python Source codes: sklearn from sklearn.cluster import DBSCANimport numpy as npX = np.array([[1, 2], [2, 2], [2, 3], [8, 7], [8, 8], [25, 80]])clustering = DBSCAN(eps=3, min_samples=2).fit(X)clustering.labels_array([ 0, 0, 0, 1, 1, -1])clustering DBSCAN(eps=3, min_samples=2) More examples: from SKlearn UMAP Insatll: - conda install -c conda-forge umap-learn - pip install umap-learn from umap import UMAPimport plotly.express as pxfeatures = np.array(df)umap_2d = UMAP(n_components=2, init='random', random_state=0)umap_3d = UMAP(n_components=3, init='random', random_state=0)proj_2d = umap_2d.fit_transform(features)proj_3d = umap_3d.fit_transform(features) t-SNE from sklearn.manifold import TSNEimport plotly.express as pxfeatures # pd.DataFram or np arraytsne = TSNE(n_components=2, random_state=0)projections = tsne.fit_transform(features)fig = px.scatter( projections, x=0, y=1, color=Cell_index.Group, #labels={'color': 'species'})fig.update_layout({&quot;plot_bgcolor&quot;: 'rgba(0, 0, 0, 0)'})fig.show() K-Means from sklearn.cluster import KMeansfeatures # pd.DataFram or np arraykmeans = KMeans(n_clusters=15, random_state=0).fit(features)print(kmeans.labels_) Affinity Propagations Youtube Tutorial: Soheil Behnezhad; 2017 source:scikit-learn.org preferencearray-like of shape (n_samples,) or float, default=None Preferences for each point - points with larger values of preferences are more likely to be chosen as exemplars. The number of exemplars, ie of clusters, is influenced by the input preferences value. If the preferences are not passed as arguments, they will be set to the median of the input similarities. import numpy as npimport seaborn as snsfrom sklearn.datasets import make_blobsimport matplotlib.pyplot as pltfrom sklearn.cluster import AffinityPropagationX, y = make_blobs(n_samples=350, centers=4, cluster_std=0.60)afprop = AffinityPropagation(preference=-15)afprop.fit(X)labels = afprop.predict(X)sns.scatterplot(x=X[:,0], y=X[:,1], hue= labels, legend=None, palette=&quot;Paired&quot;)for i in set(labels): TMP = X[labels ==i] plt.text(x=TMP.mean(axis=0)[0], y=TMP.mean(axis=0)[1], s=str(i), size = 15)plt.show() preference=-15 preference=-99 MeanShift import numpy as npimport seaborn as snsfrom sklearn.datasets import make_blobsimport matplotlib.pyplot as pltfrom sklearn.cluster import MeanShiftclustering = MeanShift(bandwidth=.6).fit(X)labels = clustering.labels_sns.scatterplot(x=X[:,0], y=X[:,1], hue= labels, legend=None, palette=&quot;Paired&quot;)for i in set(labels): TMP = X[labels ==i] plt.text(x=TMP.mean(axis=0)[0], y=TMP.mean(axis=0)[1], s=str(i), size = 15)plt.show() bandwidth=.6 bandwidth=1 Spectral Clustering from sklearn.cluster import SpectralClusteringsc = SpectralClustering(n_clusters=4).fit(X)labels = sc.labels_sns.scatterplot(x=X[:,0], y=X[:,1], hue= labels, legend=None, palette=&quot;Paired&quot;)for i in set(labels): TMP = X[labels ==i] plt.text(x=TMP.mean(axis=0)[0], y=TMP.mean(axis=0)[1], s=str(i), size = 15)plt.show() n_clusters=13 n_clusters=4 OPTICS cluster from sklearn.cluster import OPTICSclustering = OPTICS(min_samples=1, min_cluster_size=13).fit(X)label = clustering.labels_sns.scatterplot(x=X[:,0], y=X[:,1], hue= labels, legend=None, palette=&quot;Paired&quot;)for i in set(labels): TMP = X[labels ==i] plt.text(x=TMP.mean(axis=0)[0], y=TMP.mean(axis=0)[1], s=str(i), size = 15)plt.show() Hierarchy Reference: Jörn’s Blog; 2016; SciPy Hierarchical Clustering and Dendrogram Tutorial coradek; 2018; Display cluster labels for a scipy dendrogram from scipy.cluster.hierarchy import dendrogram, linkageimport scipy.stats as statsfrom scipy.cluster.hierarchy import cophenetfrom scipy.spatial.distance import pdistfrom sklearn.datasets import make_blobsX, y = make_blobs(n_samples=350, centers=4, cluster_std=0.60)XX= X[:20]Z = linkage(stats.zscore(XX) , 'ward')c, coph_dists = cophenet(Z, pdist(XX))label = [&quot;label_&quot; + str(i) for i in range(len(XX))]temp = {ii: label[ii] for ii in range(len(label))}def llf(xx): return temp[xx]Z = linkage(stats.zscore(XX) , 'ward')plt.title('Hierarchical Clustering Dendrogram')plt.xlabel('sample index')plt.ylabel('distance')dendrogram( Z, orientation='right', leaf_label_func=llf, leaf_rotation=0., # rotates the x axis labels leaf_font_size=10., # font size for the x axis labels)plt.show()","link":"/2021/11/06/Python/dbscan/"},{"title":"flybase api","text":"Flybase api API documentation from bs4 import BeautifulSoupfrom urllib.request import urlopenID = &quot;FBgn0051624&quot;url = &quot;https://api.flybase.org/api/v1.0/chadoxml/&quot; + IDhtml = urlopen(url)soup = BeautifulSoup(html, features='xml')Orth_all = [i for i in soup.find_all(&quot;feature_relationship&quot;) if i.find('name').get_text() == 'orthologous_to']Orth_Homo = [i for i in Orth_all if i.find('genus').get_text() == 'Homo']Gene_Syambol = [i.find_all('name')[2].get_text().split('\\\\')[1] for i in Orth_Homo]Gene_Ensembl = [[i.find('accession').get_text() for i in ii.find_all(&quot;dbxref_id&quot;) if i.find('name').get_text() == &quot;Ensembl_Homo_sapiens&quot;][0] for ii in Orth_Homo] pre { background-color:#38393d; color: #5fd381; }","link":"/2022/12/05/Python/flybase-api/"},{"title":"python ftp","text":"Reference soruce: jihite, 2015 Quick start from ftplib import FTP # Loading the libftp=FTP() # Assign to ftpftp.connect(&quot;IP&quot;,&quot;port&quot;) # Connected itftp.login(&quot;user&quot;,&quot;password&quot;) # Loginftp.cwd(&quot;xxx/xxx&quot;) # cd commandftp.nlst() # read the items in directory as list","link":"/2020/01/22/Python/ftp/"},{"title":"Image skills for python","text":"Read tiff files skimage import skimage.io as skioimstack1 = skio.imread(&quot;FILENAME.TIF&quot;, plugin=&quot;tifffile&quot;) Gaussian Smoothing scipy from scipy.ndimage import gaussian_filterimport matplotlib.pyplot as pltimport numpy as npa = np.arange(50, step=2).reshape((5,5))b = gaussian_filter(a, sigma=3)fig, axs = plt.subplots(1,2)axs[0].imshow(a)axs[1].imshow(b)plt.show() © scipy Turn image to DataFrame Grey image import pandas as pdimport numpy as np# create a 2D image arrayimage_array = np.array([[10, 20, 30], [40, 50, 60], [70, 80, 90]])# convert to pandas dataframedf = pd.DataFrame(image_array)# print dataframeprint(df) pre { background-color:#38393d; color: #5fd381; }","link":"/2023/03/07/Python/image/"},{"title":"itchat | Log and boot your wechat with python","text":"wechat bot微信机器人 确保你可以正常登录网页版微信 import itchat## 登录itchat.login()itchat.auto_login(enableCmdQR=True)itchat.auto_login(hotReload=True)## 发送消息itchat.send(u'你好', 'filehelper')## 联系人列表F_list = itchat.get_friends(update=True)##找到发信息的IDfor i in F_list: if i['RemarkName'] == 'XXX': #昵称 print(i['UserName'])## friendsfriends = itchat.get_friends(update=True)[0:]## aotu-returnimport itchat##自动回复@itchat.msg_register(itchat.content.TEXT)def text_reply(msg): return &quot;本人已死，有事招魂，没事烧纸 ಠಗಠ&quot;#+msg[&quot;Text&quot;]##登入itchat.auto_login()##保持运行itchat.run()","link":"/2020/01/22/Python/itchat/"},{"title":"python: geomitry calculation","text":"Geomitry is fun pre { background-color:#38393d; color: #5fd381; } Area Polygon Draw a polygon import numpy as npimport seaborn as snsimport matplotlib.pyplot as pltx = [0, 1, 2]y = [0, 1, 0]def PolyArea(x,y): # calculate the area of the polygon return 0.5*np.abs(np.dot(x,np.roll(y,1))-np.dot(y,np.roll(x,1)))def sns_poly(x, y): # function for plot the polygon x = x +x[:1] y = y +y[:1] return [sns.lineplot(x=[x[i], x[i+1]], y=[y[i], y[i+1]]) for i in range(len(x) -1)]sns_poly(x, y)plt.show()PolyArea(x,y) 1.0 As we can see, the area of the polygon is 1 Example 2: More complicated polygon x = [0, 0, 1, 2, 2]y = [0, 2, 1, 2, 0]PolyArea(x,y)sns_poly(x, y)plt.show() 3.0 Aear by shapely library shapely could also calculate the areas of a giving polygon # pip install shapelyfrom shapely.geometry import Polygon# create a polygon by following order:def creat_polygon(x, y): return Polygon([[i,j]for i,j in zip(x,y)])x = [0, 0, 1, 2, 2]y = [0, 2, 1, 2, 0]P = creat_polygon(x, y)print(P.area) Circle Reference: Plot the circle: Yann; 2012 Create a circle with scipy import mathimport matplotlib.pyplot as pltfrom scipy.spatial.distance import euclideandef Cir_arear(Center, P1): r = euclidean(Center, P1) area = math.pi * r * r #circumference = 2 * math.pi * r return area# points for circleCenter = (0, 0)P1 = (1,1)radius = euclidean(Center, P1)# points for intersect lineL1 = [-1.5, -1]L2 = [0.5, 1.5]Line = np.array([L1, L2]) fig, ax = plt.subplots(figsize = (5,5)) # note we must use plt.subplots, not plt.subplotcircle1 = plt.Circle(Center, radius, color='salmon', fill=False)ax.add_patch(circle1)ax.set(xlim=(-2,2), ylim=(-2,2),)sns.lineplot(x=Line[:, 0], y = Line[:, 1])plt.show() from shapely.geometry import LineStringfrom shapely.geometry import Pointdef Inters_CL(Center, P1, L1, L2, Plot=True): Line = np.array([L1, L2]) radius = euclidean(Center, P1) Inter_vertics = [] p = Point(Center).buffer(radius) l = LineString(Line) if p.intersects(l) == True: i = p.intersection(l) for index in range(len(i.boundary)): if i.boundary[index].coords[0] not in Line: Inter_vertics += [i.boundary[index].coords[0]] Inter_vertics = np.array(Inter_vertics) if Plot==True: circle1 = plt.Circle(Center, radius, color='salmon', fill=False) ax.add_patch(circle1) ax.set(xlim=(-2,2), ylim=(-2,2),) sns.lineplot(x=Line[:, 0], y = Line[:, 1]) sns.scatterplot(x= Inter_vertics[:, 0], y = Inter_vertics[:, 1]) return Inter_verticsfig, ax = plt.subplots(figsize = (5,5)) # note we must use plt.subplots, not plt.subplotInters_CL(Center, P1, L1, L2)Inters_CL(Center, P1, [-0.5,-2], [0,0])Inters_CL(Center, P1, [-2, 1.5], [0,-0.5]) intersect Area x = [0, 0, 1, 2, 2]y = [0, 2, 1, 2, 0]P = Polygon([[i,j]for i,j in zip(x,y)])# p is the circle defined aboveLine = np.array([L1, L2])radius = euclidean(Center, P1)Inter_vertics = []p = Point(Center).buffer(radius)# intersection area of a circle and a polygonp.intersection(P).areafig, ax = plt.subplots(figsize = (5,5)) # note we must use plt.subplots, not plt.subplotcircle1 = plt.Circle(Center, radius, color='salmon', fill=False)ax.add_patch(circle1)ax.set(xlim=(-2,2), ylim=(-2,2),)sns_poly(x, y)plt.show()","link":"/2022/02/13/Python/geomitry/"},{"title":"json data in python | read, write, and transfer","text":"import jsondata = [ { 'a' : 1, 'b' : 2, 'c' : 3, 'd' : 4, 'e' : 5 } ]json = json.dumps(data)print jsonjsonData = '{&quot;a&quot;:1,&quot;b&quot;:2,&quot;c&quot;:3,&quot;d&quot;:4,&quot;e&quot;:5}';text = json.loads(jsonData)print textConfig = json.load(open('config.json'))","link":"/2020/12/16/Python/json/"},{"title":"ImageAI","text":"Create an virtual environment for ImageAI python3 -m pip install --upgrade pip wheel setuptools virtualenvpython3 -m virtualenv Python_ev_imagesource Python_ev_image/bin/activate Install pip install tensorflow==2.4.0pip install tensorflow-gpu==2.4.0pip install keras==2.4.3 numpy==1.19.3 pillow==7.0.0 scipy==1.4.1 h5py==2.10.0 matplotlib==3.3.2 opencv-python keras-resnet==0.2.0pip install imageai --upgrade Download Models Download MobileNetV2 Model Download ResNet50 Model Download InceptionV3 Model Download DenseNet121 Model After downloaded, move it to your directory mkdir Python_ev_image/image_Modelsmv *.h5 Python_ev_image/image_Models test from imageai.Classification import ImageClassificationimport osexecution_path = os.getcwd()prediction = ImageClassification()prediction.setModelTypeAsResNet50()prediction.setModelPath(os.path.join(execution_path, &quot;Python_ev_image/image_Models/resnet50_imagenet_tf.2.0.h5&quot;))prediction.loadModel()Pic_test =&quot;/home/ken/Downloads/test_car.jpeg&quot;predictions, probabilities = prediction.classifyImage(Pic_test, result_count=5 )for eachPrediction, eachProbability in zip(predictions, probabilities): print(eachPrediction , &quot; : &quot; , eachProbability) cab : 70.75855731964111 sports_car : 16.99793189764023 forklift : 2.3407679051160812 pickup : 2.0892834290862083 car_wheel : 1.97103600949049 © unsplash.com Test 2, Video detact Download the models: RetinaNet (Size = 145 mb, high performance and accuracy, with longer detection time) YOLOv3 (Size = 237 mb, moderate performance and accuracy, with a moderate detection time) TinyYOLOv3 (Size = 34 mb, optimized for speed and moderate performance, with fast detection time) After download the models, move them to the same directory as above. from imageai.Detection import VideoObjectDetectionimport osexecution_path = os.getcwd()detector = VideoObjectDetection()detector.setModelTypeAsRetinaNet()detector.setModelPath( &quot;./Python_ev_image/image_Models/hololens-ex-60--loss-2.76.h5&quot;)detector.loadModel()Video_test = &quot;Github/FliesDetect/Behavior_movie/promE.mp4&quot;video_path = detector.detectObjectsFromVideo(input_file_path=os.path.join(execution_path, Video_test), output_file_path=os.path.join(execution_path, &quot;traffic_detected&quot;) , frames_per_second=20, log_progress=True)print(video_path) I failed build custom video object detaction FirstCustomVideoObjectDetection.py from imageai.Detection.Custom import CustomVideoObjectDetectionimport osexecution_path = os.getcwd()video_detector = CustomVideoObjectDetection()video_detector.setModelTypeAsYOLOv3()video_detector.setModelPath(&quot;hololens-ex-60--loss-2.76.h5&quot;)video_detector.setJsonPath(&quot;detection_config.json&quot;)video_detector.loadModel()Video_test = &quot;/media/ken/Data/Github/FliesDetect/Behavior_movie/promE.mp4&quot;video_detector.detectObjectsFromVideo(input_file_path=Video_test, output_file_path=os.path.join(execution_path, &quot;holo1-detected3&quot;), frames_per_second=20, minimum_percentage_probability=40, log_progress=True) import cv2import sys(major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')if __name__ == '__main__' : # Set up tracker. # Instead of MIL, you can also use tracker_types = ['BOOSTING', 'MIL','KCF', 'TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE', 'CSRT'] tracker_type = tracker_types[2] if int(minor_ver) &lt; 3: tracker = cv2.Tracker_create(tracker_type) else: if tracker_type == 'BOOSTING': tracker = cv2.TrackerBoosting_create() if tracker_type == 'MIL': tracker = cv2.TrackerMIL_create() if tracker_type == 'KCF': tracker = cv2.TrackerKCF_create() if tracker_type == 'TLD': tracker = cv2.TrackerTLD_create() if tracker_type == 'MEDIANFLOW': tracker = cv2.TrackerMedianFlow_create() if tracker_type == 'GOTURN': tracker = cv2.TrackerGOTURN_create() if tracker_type == 'MOSSE': tracker = cv2.TrackerMOSSE_create() if tracker_type == &quot;CSRT&quot;: tracker = cv2.TrackerCSRT_create() # Read video video = cv2.VideoCapture(&quot;/media/ken/Data/Github/FliesDetect/Behavior_movie/promE.mp4&quot;) # Exit if video not opened. if not video.isOpened(): print(&quot;Could not open video&quot;) sys.exit() # Read first frame. ok, frame = video.read() if not ok: print ('Cannot read video file') sys.exit() # Define an initial bounding box bbox = (287, 23, 86, 320) # Uncomment the line below to select a different bounding box bbox = cv2.selectROI(frame, False) # Initialize tracker with first frame and bounding box ok = tracker.init(frame, bbox) while True: # Read a new frame ok, frame = video.read() if not ok: break # Start timer timer = cv2.getTickCount() # Update tracker'Cannot read video file' ok, bbox = tracker.update(frame) # Calculate Frames per second (FPS) fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer); # Draw bounding box if ok: # Tracking success p1 = (int(bbox[0]), int(bbox[1])) p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3])) cv2.rectangle(frame, p1, p2, (255,0,0), 2, 1) else : # Tracking failure cv2.putText(frame, &quot;Tracking failure detected&quot;, (100,80), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2) # Display tracker type on frame cv2.putText(frame, tracker_type + &quot; Tracker&quot;, (100,20), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (50,170,50),2); # Display FPS on frame cv2.putText(frame, &quot;FPS : &quot; + str(int(fps)), (100,50), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (50,170,50), 2); # Display result cv2.imshow(&quot;Tracking&quot;, frame) # Exit if ESC pressed k = cv2.waitKey(1) &amp; 0xff if k == 27 : break","link":"/2020/01/22/Python/imageai/"},{"title":"Jupyter Notebook","text":"Install pip install notebook Sattel for the online Jupiter server Reference:qcyfred 2018 generate a config fire jupyter notebook --generate-config Modify the config file vim ~/.jupyter/jupyter_notebook_config.py # c.ConnectionFileMixin.ip = ''+c.ConnectionFileMixin.ip = '0.0.0.0'# c.NotebookApp.ip = 'localhost'+c.NotebookApp.ip = '172.18.108.101'# c.NotebookApp.password = ''+c.NotebookApp.allow_password_change = True+c.NotebookApp.password = '12345678' Note book buttons: technologger, 2019 For R Plot size It works both for ggplot and plot functions user41871 options(repr.plot.width=20, repr.plot.height=8)","link":"/2021/10/31/Python/jupyter/"},{"title":"kivy-Buildozer: packed to android apk","text":"Prerequisite: Java Home Download openJDK 8 from here. sudo apt-get install build-essential libsqlite3-dev sqlite3 bzip2 libbz2-dev zlib1g-dev libssl-dev openssl libgdbm-dev libgdbm-compat-dev liblzma-dev libreadline-dev libncursesw5-dev libffi-dev uuid-devsudo apt install -y git zip unzip openjdk-8-jdk python3-pip autoconf libtool pkg-config zlib1g-dev libncurses5-dev libncursesw5-dev libtinfo5 cmake libffi-dev libssl-devsudo apt install cython 1 install Buildozer ## install pythonsudo apt install python3.7## install pipsudo apt install python3-pip##sudo python3.7 -m pip install --user --upgrade Cython==0.29.19 virtualenvsudo python3.7 -m pip install -i https://pypi.tuna.tsinghua.edu.cn/simple buildozersudo apt updatesudo apt install -y git zip unzip openjdk-8-jdk python3-pip autoconf libtool pkg-config zlib1g-dev libncurses5-dev libncursesw5-dev libtinfo5 cmake libffi-dev libssl-devpip3 install --user --upgrade Cython==0.29.19 virtualenv # the --user should be removed if you do this in a venvor you can go and Check: [kivy-buildozer-installer.sh](https://github.com/zaemiel/kivy-buildozer-installer/blob/master/kivy-buildozer-installer.sh)## add the following line at the end of your ~/.bashrc fileexport PATH=$PATH:~/.local/bin/ If you come with error buildozer debug error &quot;[WARNING]&quot; when i run buildozer andriod debug, please install lib below sudo apt-get install build-essential libsqlite3-dev sqlite3 bzip2 libbz2-dev zlib1g-dev libssl-dev openssl libgdbm-dev libgdbm-compat-dev liblzma-dev libreadline-dev libncursesw5-dev libffi-dev uuid-dev 链接安卓手机, 开启USB debug模式;进入 kivy 项目目录测试项目:https://github.com/sevvalbrt/Todolist buildozer initbuildozer android debug deploy run 手机有什么提示, 记得选择 可能会下一些东西. 等一下就好了 更多参考:https://cycleuser.gitbooks.io/kivy-guide-chinese/content/15-Kivy-Pack-Android.html Quick Test Download a Kivy example git clone https://github.com/sevvalbrt/Todolist.gitcd ToDolistbuildozer initbuildozer android debug deploy run As this photo above, it’ll take a while… The problem is you’ll download a bunch of libs and you’ll fail if one of the packages download fail. [‘hostpython3’, ‘libffi’, ‘openssl’, ‘sdl2_image’, ‘sdl2_mixer’, ‘sdl2_ttf’, ‘sqlite3’, ‘python3’, ‘sdl2’, ‘setuptools’, ‘six’, ‘pyjnius’, ‘android’, ‘kivy’] android-ndk-r19c-linux-x86_64.zip ## Buildozer failed to execute the last command ## The error might be hidden in the log above this error ## Please read the full log, and search for it before ## raising an issue with buildozer itself. ## In case of a bug report, please add a full log with log_level = 2 I got an error and it says I need to read the error code in full log file… Exception in thread \"main\" java.lang.NoClassDefFoundError: javax/xml/bind/annotation/XmlSchema reference: lplj717 2019 It seems like I got a wrong version of jave. So, I removed the new version and keep the jdk8. And then, a new error arise: WARNING: Received a --sdk argument, but this argument is deprecated and does nothing. BUILD FAILURE: No main.py(o) found in your app directory. This file must exist to act as the entry point for you app. If your app is started by a file with a different name, rename it to main.py or add a main.py that loads it. So… mv Main.py to main.py and then: Could not find tools.jar. Please check that /home/ken/Soft/jre1.8.0_231 contains a valid JDK installation reference: CUFFS 2017 So, there are some thing wrong with my JAVA environment, I download it from https://adoptopenjdk.net and export them in ~/.bashrc Success When the code shows as below, it means everything is down and you can upload apk file from bin to your Android phone: WARNING: Received a --sdk argument, but this argument is deprecated and does nothing. No setup.py/pyproject.toml used, copying full private data into .apk. Applying Java source code patches... Applying patch: src/patches/SDLActivity.java.patch Warning: failed to apply patch (exit code 1), assuming it is already applied: src/patches/SDLActivity.java.patch ## Android packaging done! ## APK myapp-0.1-armeabi-v7a-debug.apk available in the bin directory ummmm… I fail to open this app in Huawei p30 pro. But I tried another more simple app and it succeed. sudo apt install install python3-dev Erros RAN: /bin/tar xf /media/ken/Data/Kivy_env/Kivy2Py3.8.1MD0.104.2.dev0/.buildozer/android/platform/build-armeabi-v7a/packages/cython/0.29.15.tar.gz STDOUT: STDERR: /bin/tar: This does not look like a tar archive gzip: stdin: unexpected end of file /bin/tar: Child returned status 1 /bin/tar: Error is not recoverable: exiting now cypython file is damaged. Delete .buildozer/android/platform/build-armeabi-v7a/packages/cython to download it again def Seq_clean():F = open(&quot;clusttmp/result.aln-clustal_num.clustal_num&quot;).read()F = F.replace(&quot;\\n\\n\\n&quot;,&quot;\\n\\n&quot;)F = F.split(&quot;\\n\\n&quot;)[1:]Result = &quot;&quot;Num = 0for head in F[0].split(&quot;\\n&quot;): for Seq in F: tmp = Seq.split(&quot;\\n&quot;)[Num].split(&quot;\\t&quot;)[0] if head !=Seq.split(&quot;\\n&quot;)[Num]: tmp = tmp.split(&quot; &quot;)[-1] Result += tmp Result += &quot;\\n&quot; Num +=1print(Result)Mark_list = []for i in Result.split('\\n'): Mark_list += [i.split(&quot; &quot;)[-1]]while &quot;&quot; in Mark_list: Mark_list.remove(&quot;&quot;)Marked_list = []for seq in Mark_list: Marked_list += [MarkDown(seq)]for i, ii in zip(Mark_list, Marked_list): Result= Result.replace(i, ii)return Resultdef MarkDown(Text): Result = &quot;&quot; for i in list(Text): if i == &quot;a&quot; or i == &quot;A&quot;: i = &quot;[color=#fa937f]A[/color]&quot; if i == &quot;t&quot; or i == &quot;T&quot;: i = &quot;[color=#1193ee]T[/color]&quot; if i == &quot;c&quot; or i == &quot;C&quot;: i = &quot;[color=#51d673]C[/color]&quot; if i == &quot;g&quot; or i == &quot;G&quot;: i = &quot;[color=#edcf1d]G[/color]&quot; if i == &quot;-&quot; or i == &quot; &quot;: i = &quot;[color=#ffffff]G[/color]&quot; Result += i return Result","link":"/2021/01/01/Python/kivy-Buildozer/"},{"title":"Kivy for android in action: Toolbox 2: Filechooser","text":"CryptoWatch-Kivy 1.13Kivy 2.0.0Kivy-Garden 0.1.4kivy-garden.wordcloud 1.0.0kivymd 0.104.2.dev0 Quick Review tree ├── bin │ └── KarobbenTB-1.3-armeabi-v7a-debug.apk ├── buildozer.spec ├── favicon.ico ├── font │ ├── FangZhengHeiTiFanTi-1.ttf │ ├── HuaKangXinZhuanTi-1.ttc │ ├── HuaKangXinZhuanTi-1.ttf │ └── JingDianFanJiaoZhuan-1.ttf ├── Layout │ ├── filechooser.kv │ ├── Navigation_Draw.kv │ ├── Navigation_Tabs.kv │ └── Seq.kv ├── lib │ └── bio_seq.py ├── libWidget │ ├── filechooser.py │ └── Seq.py ├── logo.png └── main.py Filechooser My another post about Filechooser: Karobben Document: kivy.org touch libWidget filechooser.py main.py+ from libWidget.filechooser import ConfirmPopupclass MainApp(MDApp):+ ConfirmPopup = ConfirmPopup()+ def change_text(self, Files):+ self.Button_test.text = Files[0]+ print(str(Files))def build(self): screen = Screen()+ screen.change_text = self.change_textdef on_start(self):+ self.Button_test = MDRectangleFlatButton(+ text=&quot;Hello, World&quot;,+ pos_hint={&quot;center_x&quot;: 0.5, &quot;center_y&quot;: 0.5},+ on_release = self.ConfirmPopup.popup_func)+ Tab1.add_widget(self.Button_test) filechooser.pyfrom kivy.app import Appfrom kivy.uix.anchorlayout import AnchorLayoutfrom kivy.uix.boxlayout import BoxLayoutfrom kivy.uix.popup import Popupfrom kivy.lang import Builderclass ConfirmPopup(BoxLayout): def __init__(self, **kwargs): Builder.unload_file(&quot;./Layout/filechooser.kv&quot;) Builder.load_file(&quot;./Layout/filechooser.kv&quot;) self.register_event_type('on_answer') self.register_event_type('on_cancel') super(ConfirmPopup, self).__init__(**kwargs) self.total_images = 0 def on_answer(self, filename, MainPage): self.total_images = filename if len(filename) &gt;0: MainPage.change_text(self.total_images) else: MainPage.change_text(&quot;Please Select a File&quot;) def on_cancel(self, filename, MainPage): pass def popup_func(self, *args): content = ConfirmPopup() content.bind(on_answer = self._on_answer) content.bind(on_cancel = self._on_answer) #content.bind(Cancel = self._on_answer) self.popup = Popup(title=&quot;Select .zip file&quot;, content=content, size_hint=(None, None), size=(500, 500), auto_dismiss=True) self.popup.open() def _on_answer(self, instance, answer, obj): self.popup.dismiss() def dismiss(self): self.popup.dismiss() #: kivy 1.10.0&lt;ConfirmPopup&gt;: BoxLayout: orientation: 'vertical' FileChooserIconView: id: filechooser #filters: ['*.zip'] GridLayout: cols: 2 size_hint: 1,0.2 Button: text: 'OK' on_release: root.dispatch('on_answer', filechooser.selection, app.root) size_hint: 1,0.2 Button: id: cancel text: 'Cancel' on_release: root.dispatch('on_cancel', filechooser.selection, app.root) size_hint: 1,0.2 main.pyfrom kivy.app import Appfrom kivy.uix.floatlayout import FloatLayoutfrom kivy.factory import Factoryfrom kivy.properties import ObjectPropertyfrom kivy.uix.popup import Popupfrom kivy.utils import platformfrom kivy.uix.screenmanager import Screenfrom kivymd.uix.button import MDRectangleFlatButtonfrom kivy.lang import Builderfrom kivymd.app import MDAppimport osfrom kivy.uix.anchorlayout import AnchorLayoutfrom kivy.uix.boxlayout import BoxLayoutfrom kivy.uix.popup import Popupfrom kivy.lang import Builderfrom filechooser import ConfirmPopupclass MainPage(AnchorLayout): ConfirmPopup = ConfirmPopup() def __init__(self, **kwargs): super(MainPage, self).__init__(**kwargs) def change_text(self, Files): self.the_time.text = str(Files) print(str(Files))class Main(App): def build(self): Builder.load_file(&quot;main.kv&quot;) return MainPage()if __name__ == &quot;__main__&quot;: Main().run() Change the style of the Filechooser Background color: @ Nykakin[1] canvas.before: Color: rgb: 1, 1, 1 Rectangle: pos: self.pos size: self.size Else newbie programmerz; 2019; Changing the icon of Kivy FileChooserIconView; StackOverflow Cube_tbh; 2015; How to allow user to choose file as background image in kivy? GitHub Repository: Karobben Toolbox Android Release: Karobben Toolbox digraph{ rankdir = \"LR\" mm1 [label =\"\", height = 0, width = 0, shape = none] mm2 [label =\"\", height = 0, width = 0, shape = none] mm3 [label =\"\", height = 0, width = 0, shape = none] mm4 [label =\"\", height = 0, width = 0, shape = none] mm5 [label =\"\", height = 0, width = 0, shape = none] mm6 [label =\"\", height = 0, width = 0, shape = none] mm7 [label =\"\", height = 0, width = 0, shape = none] Navigation [URL=\"/2021/04/26/Python/kivy-inaction-tb-1/#Navigation\", fontcolor = \"#3273DC\"] Navigation_S [URL=\"/2021/04/26/Python/kivy-inaction-tb-1/#Separate-the-KV-and-PY\", fontcolor = \"#3273DC\"] Tags [URL =\"/2021/04/26/Python/kivy-inaction-tb-1/#Tags\", fontcolor = \"#3273DC\"] FF [label=\"First Function\"; URL =\"/2021/04/26/Python/kivy-inaction-tb-1/#First-Function\", fontcolor = \"#3273DC\"] FileChooser [label=\"File Chooser\"; URL =\"/2021/04/28/Python/kivy-inaction-tb-2/#Filechooser\", fontcolor = \"#3273DC\"] {rank=\"same\"; mm1; mm2; mm3; mm4; mm5; mm6, mm7} node [shape = \"box\"] Navigation_S [label = \"Separate the KV and PY\"] Navigation -> mm2 mm3 -> Navigation_S [dir=back] Tags -> mm4 mm5 -> FF [dir=back] FileChooser -> mm6 mm1 -> mm2 -> mm3 -> mm4 -> mm5 -> mm6 -> mm7 [dir = \"none\"] } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) }); picibucor; 2016; font-color of FileChooser; StackOverflow ↩︎","link":"/2021/04/28/Python/kivy-inaction-tb-2/"},{"title":"Kivy for android in action: Toolbox 1: Navigation","text":"CryptoWatch-Kivy 1.13Kivy 2.0.0Kivy-Garden 0.1.4kivy-garden.wordcloud 1.0.0kivymd 0.104.2.dev0 Navigation Example of Navigation: KivyMD GitHub Documentation: Kivymd Attention: “MDNavigationLayout” was abandoned, using “NavigationLayout” as substitute. Root:- MDNavigationLayout:+ NavigationLayout: ScreenManager: Screen_1: Screen_2: Example 1 from kivy.lang import Builderfrom kivy.uix.boxlayout import BoxLayoutfrom kivymd.app import MDAppKV = '''Screen: NavigationLayout: ScreenManager: Screen: BoxLayout: orientation: 'vertical' MDToolbar: title: &quot;Navigation Drawer&quot; elevation: 10 left_action_items: [['menu', lambda x: nav_drawer.set_state(&quot;open&quot;)]] Widget: MDNavigationDrawer: id: nav_drawer ContentNavigationDrawer:'''class ContentNavigationDrawer(BoxLayout): passclass TestNavigationDrawer(MDApp): def build(self): return Builder.load_string(KV)TestNavigationDrawer().run() Separate the KV and PY mkdir Layouttree . ├── Layout │ └── Navigation_Draw.kv └── main.py 1 directory, 2 files KV file Navigation_Draw.kvScreen: NavigationLayout: ScreenManager: Screen: BoxLayout: orientation: 'vertical' MDToolbar: title: &quot;Navigation Drawer&quot; elevation: 10 left_action_items: [['menu', lambda x: nav_drawer.set_state(&quot;open&quot;)]] Widget: MDNavigationDrawer: id: nav_drawer from kivy.uix.screenmanager import Screenfrom kivymd.uix.button import MDRectangleFlatButtonfrom kivy.lang import Builderfrom kivymd.app import MDAppdef OPEN(file): return open(file).read()class MainApp(MDApp): def F_test(self, *args): print(123) def build(self): screen = Screen() Widget_navi = Builder.load_string(OPEN(&quot;Layout/Navigation_Draw.kv&quot;)) screen.add_widget(Widget_navi) screen.add_widget( MDRectangleFlatButton( text=&quot;Hello, World&quot;, pos_hint={&quot;center_x&quot;: 0.5, &quot;center_y&quot;: 0.5}, on_release = self.F_test )) return screenMainApp().run() Tags Example: GitHub main.pyfrom kivy.uix.screenmanager import Screenfrom kivymd.uix.button import MDRectangleFlatButtonfrom kivy.lang import Builderfrom kivymd.uix.floatlayout import MDFloatLayoutfrom kivymd.uix.tab import MDTabsBasefrom kivymd.app import MDAppdef OPEN(file): return open(file).read()class Tab(MDFloatLayout, MDTabsBase): '''Class implementing content for a tab.'''class MainApp(MDApp): def F_test(self, *args): print(123) def build(self): screen = Screen() # loading Navigation (left) Widget_navi = Builder.load_string(OPEN(&quot;Layout/Navigation_Draw.kv&quot;)) # loading navigation tags Widget_tabs = Builder.load_string(OPEN(&quot;Layout/Navigation_Tabs.kv&quot;)) self.Widget_tabs = Widget_tabs screen.add_widget(Widget_tabs) screen.add_widget(Widget_navi) return screen # Functions for Navigation Tab def on_start(self): Tab1 = Tab(text=&quot;alarm&quot;) Tab1.add_widget( MDRectangleFlatButton( text=&quot;Hello, World&quot;, pos_hint={&quot;center_x&quot;: 0.5, &quot;center_y&quot;: 0.5},)) self.Widget_tabs.ids.tabs.add_widget(Tab1) self.Widget_tabs.ids.tabs.add_widget(Tab(text=&quot;alarm-bell&quot;)) # Functions for Navigation Tab Switch def on_tab_switch( self, instance_tabs, instance_tab, instance_tab_label, tab_text): '''Called when switching tabs. :type instance_tabs: &lt;kivymd.uix.tab.MDTabs object&gt;; :param instance_tab: &lt;__main__.Tab object&gt;; :param instance_tab_label: &lt;kivymd.uix.tab.MDTabsLabel object&gt;; :param tab_text: text or name icon of tab; ''' instance_tab.ids.label.text = tab_textMainApp().run() KV file: Navigation_Tabs.kv MDBoxLayout: orientation: &quot;vertical&quot; MDToolbar: title: &quot;Example Tabs&quot; MDTabs: id: tabs text: &quot;1&quot; on_ref_press: app.on_ref_press(*args)&lt;Tab&gt; MDIconButton: id: icon icon: &quot;&quot; user_font_size: &quot;48sp&quot; pos_hint: {&quot;center_x&quot;: .5, &quot;center_y&quot;: .5} . ├── Layout │ ├── Navigation_Draw.kv │ └── Navigation_Tabs.kv └── main.py 1 directory, 3 files First Function Convert atcg to ATCG touch Layout/Seq.kvtree . ├── Layout │ ├── Navigation_Draw.kv │ ├── Navigation_Tabs.kv │ └── Seq.kv ├── lib │ └── bio_seq.py ├── libWidget │ └── Seq.py └── main.py Seq.kv Seq.kvMDBoxLayout: padding: root.width * .05, root.height * .05,root.width * .05, root.height * .05 MDBoxLayout: id: boxs orientation: &quot;vertical&quot; functions: None#{&quot;aA&quot;:&quot;a&quot;} label_c: 0, 0, 1, 1 MDTextField: id: seq_input hint_text: &quot;Input DNA Hear&quot; pos_hint: {&quot;center_x&quot;: .5} MDIconButton: id: upper icon: &quot;android&quot; user_font_size: &quot;64sp&quot; on_release: boxs.functions#[&quot;aA&quot;] pos_hint: {&quot;center_x&quot;: .5} MDLabel: id: seq_result text: &quot;Result shows Herer&quot; color: boxs.label_c pos_hint: {&quot;center_x&quot;: .5} Seq.py#from kivy.lang import Builderfrom kivy.lang import Builderclass FunctionWidget(): def OPEN(self, file): return open(file).read() def PP(self): #self.print(self.Function_page.ids.seq_input.text) self.Function_page.ids.seq_result.text = self.Function_page.ids.seq_input.text.upper() def main(self): self.Function_page = Builder.load_string(self.OPEN(&quot;Layout/Seq.kv&quot;)) self.Function_page.ids.upper.on_release = self.PP return self.Function_page main.pyfrom kivy.uix.screenmanager import Screenfrom kivymd.uix.button import MDRectangleFlatButtonfrom kivy.lang import Builderfrom kivymd.uix.floatlayout import MDFloatLayoutfrom kivymd.uix.tab import MDTabsBasefrom kivymd.app import MDApp# Function libsdef OPEN(file): return open(file).read()class Tab(MDFloatLayout, MDTabsBase): '''Class implementing content for a tab.'''class MainApp(MDApp): def F_test(self, *args): print(123) def build(self): screen = Screen() # loading Navigation (left) Widget_navi = Builder.load_string(OPEN(&quot;Layout/Navigation_Draw.kv&quot;)) # loading navigation tags Widget_tabs = Builder.load_string(OPEN(&quot;Layout/Navigation_Tabs.kv&quot;)) self.Widget_tabs = Widget_tabs # loading The Function pages # Loading Sequencs function page screen.add_widget(Widget_tabs) screen.add_widget(Widget_navi) return screen # Functions for Navigation Ta def on_start(self): from lib.bio_seq import Bio as FunBioSeq Fun = FunBioSeq() print(Fun.List()) def PP(): print(Function_page.ids.seq_input.text) Function_page.ids.seq_result.text = Function_page.ids.seq_input.text.upper() Fun = FunBioSeq() List = {&quot;Seq&quot;:{'icon':&quot;dna&quot;,'title':&quot;Sequencs Tools&quot;}} Tab1 = Tab(text=&quot;Bio&quot;) Tab1.add_widget( MDRectangleFlatButton( text=&quot;Hello, World&quot;, pos_hint={&quot;center_x&quot;: 0.5, &quot;center_y&quot;: 0.5},)) self.Widget_tabs.ids.tabs.add_widget(Tab1) for i in List.keys(): tmp_tab = Tab(text=List[i]['icon']) #Function = Builder.load_string(OPEN(&quot;Layout/&quot;+i+&quot;.kv&quot;)) from libWidget.Seq import FunctionWidget Fun = FunctionWidget() tmp_tab.add_widget(Fun.main()) self.Widget_tabs.ids.tabs.add_widget(tmp_tab) # Functions for Navigation Tab Switch def on_tab_switch( self, instance_tabs, instance_tab, instance_tab_label, tab_text): '''Called when switching tabs. :type instance_tabs: &lt;kivymd.uix.tab.MDTabs object&gt;; :param instance_tab: &lt;__main__.Tab object&gt;; :param instance_tab_label: &lt;kivymd.uix.tab.MDTabsLabel object&gt;; :param tab_text: text or name icon of tab; ''' instance_tab.ids.label.text = tab_textMainApp().run() GitHub Repository: Karobben Toolbox Android Release: Karobben Toolbox digraph{ rankdir = \"LR\" mm1 [label =\"\", height = 0, width = 0, shape = none] mm2 [label =\"\", height = 0, width = 0, shape = none] mm3 [label =\"\", height = 0, width = 0, shape = none] mm4 [label =\"\", height = 0, width = 0, shape = none] mm5 [label =\"\", height = 0, width = 0, shape = none] mm6 [label =\"\", height = 0, width = 0, shape = none] Navigation [URL=\"#Navigation\", fontcolor = \"#3273DC\"] Navigation_S [URL=\"#Separate-the-KV-and-PY\", fontcolor = \"#3273DC\"] Tags [URL =\"#Tags\", fontcolor = \"#3273DC\"] FF [label=\"First Function\"; URL =\"#First-Function\", fontcolor = \"#3273DC\"] {rank=\"same\"; mm1; mm2; mm3; mm4; mm5; mm6} node [shape = \"box\"] Navigation_S [label = \"Separate the KV and PY\"] Navigation -> mm2 mm3 -> Navigation_S [dir=back] Tags -> mm4 mm5 -> FF [dir=back] mm1 -> mm2 -> mm3 -> mm4 -> mm5 -> mm6 [dir = \"none\"] } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });","link":"/2021/04/26/Python/kivy-inaction-tb-1/"},{"title":"Kivy for android in action: Toolbox 3: Menu","text":"CryptoWatch-Kivy 1.13Kivy 2.0.0Kivy-Garden 0.1.4kivy-garden.wordcloud 1.0.0kivymd 0.104.2.dev0 Quick Review tree ├── bin │ └── KarobbenTB-1.3-armeabi-v7a-debug.apk ├── buildozer.spec ├── favicon.ico ├── font │ ├── FangZhengHeiTiFanTi-1.ttf │ ├── HuaKangXinZhuanTi-1.ttc │ ├── HuaKangXinZhuanTi-1.ttf │ └── JingDianFanJiaoZhuan-1.ttf ├── Layout │ ├── filechooser.kv │ ├── Navigation_Draw.kv │ ├── Navigation_Tabs.kv │ └── Seq.kv ├── lib │ └── bio_seq.py ├── libWidget │ ├── filechooser.py │ ├── menu.py │ └── Seq.py ├── logo.png └── main.py Example Document: HeaTTheatR, GitHub Issues This example is for another KVmd version = = from kivy.lang import Builderfrom kivymd.app import MDAppfrom kivymd.uix.menu import MDDropdownMenuKV = '''Screen: MDRaisedButton: id: button text: &quot;PRESS ME&quot; pos_hint: {&quot;center_x&quot;: .5, &quot;center_y&quot;: .5} on_release: app.menu.open()'''class Test(MDApp): def __init__(self, **kwargs): super().__init__(**kwargs) self.screen = Builder.load_string(KV) menu_items = [{&quot;text&quot;: f&quot;Item {i}&quot;} for i in range(5)] self.menu = MDDropdownMenu( caller=self.screen.ids.button, items=menu_items, width_mult=4, ) self.menu.bind(on_release=self.menu_callback) def menu_callback(self, instance_menu, instance_menu_item): print(instance_menu, instance_menu_item.text) self.screen.ids.button.text = instance_menu_item.text self.menu.dismiss() def build(self): return self.screenTest().run() Example from document This is for version 0.104.2.dev0 Installed by pip install https://github.com/kivymd/KivyMD/archive/master.zip from kivy.lang import Builderfrom kivy.metrics import dpfrom kivy.properties import StringPropertyfrom kivymd.uix.list import OneLineIconListItemfrom kivymd.app import MDAppfrom kivymd.uix.menu import MDDropdownMenuKV = '''&lt;IconListItem&gt; IconLeftWidget: icon: root.iconMDScreen MDTextField: id: field pos_hint: {'center_x': .5, 'center_y': .6} size_hint_x: None width: &quot;200dp&quot; hint_text: &quot;Password&quot; on_focus: if self.focus: app.menu.open()'''class IconListItem(OneLineIconListItem): icon = StringProperty()class Test(MDApp): def __init__(self, **kwargs): super().__init__(**kwargs) self.screen = Builder.load_string(KV) menu_items = [ { &quot;viewclass&quot;: &quot;IconListItem&quot;, &quot;icon&quot;: &quot;git&quot;, &quot;height&quot;: dp(56), &quot;text&quot;: f&quot;Item {i}&quot;, &quot;on_release&quot;: lambda x=f&quot;Item {i}&quot;: self.set_item(x), } for i in range(5)] self.menu = MDDropdownMenu( caller=self.screen.ids.field, items=menu_items, position=&quot;bottom&quot;, width_mult=4, ) def set_item(self, text__item): self.screen.ids.field.text = text__item self.menu.dismiss() def build(self): return self.screenTest().run() Write is as a widget touch libWidget/menu.pytouch Layout/menu.kv menu.py from kivymd.uix.menu import MDDropdownMenufrom kivymd.uix.floatlayout import MDFloatLayout#KV = ''''''Screen: MDRaisedButton: id: button text: &quot;PRESS ME&quot; pos_hint: {&quot;center_x&quot;: .5, &quot;center_y&quot;: .5} on_release: app.menu.open()'''class Menu(MDFloatLayout): #menu = MDDropdownMenu() def __init__(self, **kwargs): #super().__init__(**kwargs) #self.screen = Builder.load_string(KV) menu_items = [{&quot;text&quot;: f&quot;Item {i}&quot;, &quot;viewclass&quot;: &quot;OneLineListItem&quot;, 'font_name': &quot;./font/FangZhengHeiTiJianTi-1&quot;, &quot;on_release&quot;: lambda x=f&quot;Item {i}&quot;: self.menu_callback(x)} for i in range(4)] self.menu = MDDropdownMenu( #caller=self.screen.ids.button, caller= None, items=menu_items, width_mult=4, ) self.menu.bind(on_release=self.menu_callback) print(123) #return self.menu # def menu_callback(self, instance_menu_item): print(&quot;instance_menu&quot;, instance_menu_item) #self.page_callback() self.test =&quot;Change Page&quot; print(self.test) self.menu.dismiss() def page_callback(self): self.test =&quot;Change Page&quot; print(self.test) # let's start def pop(self): self.menu.open() Insert to page: from kivy.uix.screenmanager import Screenfrom kivymd.app import MDAppfrom kivymd.uix.button import MDRectangleFlatButtonfrom menu import Menu as Seq_Menuclass MainApp(MDApp):+ Seq_Menu = Seq_Menu() def build(self): screen = Screen() self.Button = MDRectangleFlatButton( text=&quot;Hello, World&quot;, pos_hint={&quot;center_x&quot;: 0.5, &quot;center_y&quot;: 0.5})+ self.Button.on_release = self.Seq_Menu.pop+ self.Seq_Menu.menu.caller = self.Button+ self.Seq_Menu.menu.bind(on_release = self.menu_callback)++ for i in range(len(self.Seq_Menu.menu.items)):+ self.Seq_Menu.menu.items[i]['text'] = &quot;A&quot; + str(i)+ self.Seq_Menu.menu.items[i]['on_release'] = lambda x=str(i)+&quot;: test&quot;: self.menu_callback(x) screen.add_widget(self.Button) return screen+ def menu_callback(self, Text):+ print(123, Text)+ self.Button.text = &quot;Choosed: &quot;+Text+ self.Seq_Menu.menu.dismiss()MainApp().run() After imported the widget, we should bind the pop and the menu.bind. pop is for popup the widget bubble menu.bind is for showing the MenuItems. You also need to bind the bottom wiht self.Seq_Menu.menu.caller = self.Button if the button is in ‘kv’ file, them, bind its id. GitHub Repository: Karobben Toolbox Android Release: Karobben Toolbox digraph{ rankdir = \"LR\" mm1 [label =\"\", height = 0, width = 0, shape = none] mm2 [label =\"\", height = 0, width = 0, shape = none] mm3 [label =\"\", height = 0, width = 0, shape = none] mm4 [label =\"\", height = 0, width = 0, shape = none] mm5 [label =\"\", height = 0, width = 0, shape = none] mm6 [label =\"\", height = 0, width = 0, shape = none] mm7 [label =\"\", height = 0, width = 0, shape = none] mm8 [label =\"\", height = 0, width = 0, shape = none] mm9 [label =\"\", height = 0, width = 0, shape = none] Navigation [URL=\"/2021/04/26/Python/kivy-inaction-tb-1/#Navigation\", fontcolor = \"#3273DC\"] Navigation_S [URL=\"/2021/04/26/Python/kivy-inaction-tb-1/#Separate-the-KV-and-PY\", fontcolor = \"#3273DC\"] Tags [URL =\"/2021/04/26/Python/kivy-inaction-tb-1/#Tags\", fontcolor = \"#3273DC\"] FF [label=\"First Function\"; URL =\"/2021/04/26/Python/kivy-inaction-tb-1/#First-Function\", fontcolor = \"#3273DC\"] FileChooser [label=\"File Chooser\"; URL =\"/2021/04/28/Python/kivy-inaction-tb-2/#Filechooser\", fontcolor = \"#3273DC\"] Menu [label=\"Menu\"; URL =\"/2021/04/30/Python/kivy-inaction-tb-3/#Write-is-as-a-widget\", fontcolor = \"#3273DC\"] node [shape = \"box\"] Navigation_S [label = \"Separate the KV and PY\"] Navigation -> mm2 mm3 -> Navigation_S [dir=back] Tags -> mm4 mm5 -> FF -> Slider[dir=back] FileChooser -> mm6 mm7 -> Menu [dir=back] Menu -> FF subgraph A{ rank = same mm1 -> mm2 -> mm3 -> mm4 -> mm5 -> mm6 -> mm7 -> mm8 -> mm9 [dir = \"none\"] } } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });","link":"/2021/04/30/Python/kivy-inaction-tb-3/"},{"title":"Kivy for android in action: Toolbox 4: Dynamic Tabs manager","text":"CryptoWatch-Kivy 1.13Kivy 2.0.0Kivy-Garden 0.1.4kivy-garden.wordcloud 1.0.0kivymd 0.104.2.dev0 Quick Review tree . ├── bin │ └── KarobbenTB-1.3-armeabi-v7a-debug.apk ├── buildozer.spec ├── favicon.ico ├── font │ ├── ArtificialBox-WdD4.ttf | ... │ └── JingDianFanJiaoZhuan-1.ttf ├── Layout │ ├── filechooser.kv │ ├── menu.kv │ ├── Navigation_Draw.kv │ ├── Navigation_Tabs.kv │ └── Seq.kv ├── lib │ └── bio_seq.py ├── libWidget │ ├── filechooser.py │ ├── main.py │ ├── menu.py │ └── Seq.py ├── logo.png └── main.py Function for Close Tab Navigation_Tabs.kv Use on_ref_press method Navigation_Tabs.kv MDTabs: id: tabs text: &quot;1&quot;+ on_ref_press: app.on_ref_press(*args) main.pyclass MainApp(MDApp):+ def on_ref_press(+ self,+ instance_tabs,+ instance_tab_label,+ instance_tab,+ instance_tab_bar,+ instance_carousel,+ ):+ '''+ The method will be called when the ``on_ref_press`` event+ occurs when you, for example, use markup text for tabs.+ :param instance_tabs: &lt;kivymd.uix.tab.MDTabs object&gt;+ :param instance_tab_label: &lt;kivymd.uix.tab.MDTabsLabel object&gt;+ :param instance_tab: &lt;__main__.Tab object&gt;+ :param instance_tab_bar: &lt;kivymd.uix.tab.MDTabsBar object&gt;+ :param instance_carousel: &lt;kivymd.uix.tab.MDTabsCarousel object&gt;+ '''++ # Removes a tab by clicking on the close icon on the left.+ for instance_tab in instance_carousel.slides:+ if instance_tab.text == instance_tab_label.text:+ instance_tabs.remove_widget(instance_tab_label)+ break Connect Navigation to Tabs Navigation_Draw.kv Navigation_Draw.kvMDNavigationLayout: ScreenManager: Screen: BoxLayout: orientation: 'vertical' MDToolbar: id: nav_banner icon: &quot;android&quot; title: &quot;Tool Box&quot; elevation: 10 left_action_items: [[&quot;&quot;, lambda x: nav_drawer.set_state(&quot;open&quot;)]] Widget: id: nav_widget MDNavigationDrawer: id: nav_drawer text: &quot;I am here &quot; BoxLayout:+ id: nav_button MDLabel: text: &quot;Add something here&quot; main.py main.pyclass MainApp(MDApp): def build(self):+ self.Widget_navi = Builder.load_string(OPEN(&quot;Layout/Navigation_Draw.kv&quot;))+ self.Widget_tabs = Builder.load_string(OPEN(&quot;Layout/Navigation_Tabs.kv&quot;))+ screen.add_widget(self.Widget_tabs)+ screen.add_widget(self.Widget_navi) def on_start(self): from lib.bio_seq import Bio as FunBioSeq Fun = FunBioSeq() ... List = {&quot;Seq&quot;:{'icon':&quot;Characters&quot;,'title':&quot;Sequencs Tools&quot;}}+ name_tab = &quot;Bio&quot;+ Tab1 = Tab(+ text=f&quot;[ref={name_tab}][color=#fa937f][font=font/heydings-icons-1]{'X'}[/font][/color][/ref] {name_tab}&quot;)+ '''+ Navigation test+ '''+ Button_test = MDRectangleFlatButton(+ text=&quot;篆体&quot;,+ pos_hint={&quot;center_x&quot;: 0.5, &quot;center_y&quot;: 0.5},+ font_name = &quot;./font/JingDianFanJiaoZhuan-1.ttf&quot;,+ on_release = self.run_test)+ self.Widget_navi.ids.nav_button.add_widget(Button_test)+ def run_test(self, *args):+ self.add_tag()+ self.Widget_navi.ids.nav_drawer.set_state(&quot;close&quot;)+ print(iter(list(self.Widget_tabs.ids.tabs.get_tab_list())))#switch_tab(&quot;X 篆书&quot;)+ def add_tag(self, *args):+ name_tab = &quot; 篆书&quot;+ Tag_title = f&quot;[ref={name_tab}][font=font/heydings-icons-1][color=#fa937f]{'X'}[/color][/font][/ref][font=./font/JingDianFanJiaoZhuan-1]{name_tab}[/font]&quot;+ tmp_tab =Tab( text = Tag_title)+ from libWidget.Seq import FunctionWidget+ Fun = FunctionWidget()+ screen_tmp = Screen()+ screen_tmp.name = &quot;Test&quot;+ screen_tmp.add_widget(Fun.main())+ tmp_tab.add_widget(screen_tmp)+ self.Widget_tabs.ids.tabs.add_widget(tmp_tab)+ self.Widget_tabs.ids.tabs.switch_tab(Tag_title) Result: © Karobben digraph{ rankdir = \"LR\" mm1 [label =\"\", height = 0, width = 0, shape = none] mm2 [label =\"\", height = 0, width = 0, shape = none] mm3 [label =\"\", height = 0, width = 0, shape = none] mm4 [label =\"\", height = 0, width = 0, shape = none] mm5 [label =\"\", height = 0, width = 0, shape = none] mm6 [label =\"\", height = 0, width = 0, shape = none] mm7 [label =\"\", height = 0, width = 0, shape = none] mm8 [label =\"\", height = 0, width = 0, shape = none] mm9 [label =\"\", height = 0, width = 0, shape = none] Navigation [URL=\"/2021/04/26/Python/kivy-inaction-tb-1/#Navigation\", fontcolor = \"#3273DC\"] Navigation_S [URL=\"/2021/04/26/Python/kivy-inaction-tb-1/#Separate-the-KV-and-PY\", fontcolor = \"#3273DC\"] Tags [URL =\"/2021/04/26/Python/kivy-inaction-tb-1/#Tags\", fontcolor = \"#3273DC\"] FF [label=\"First Function\"; URL =\"/2021/04/26/Python/kivy-inaction-tb-1/#First-Function\", fontcolor = \"#3273DC\"] FileChooser [label=\"File Chooser\"; URL =\"/2021/04/28/Python/kivy-inaction-tb-2/#Filechooser\", fontcolor = \"#3273DC\"] Menu [label=\"Menu\"; URL =\"/2021/04/30/Python/kivy-inaction-tb-3/#Write-is-as-a-widget\", fontcolor = \"#3273DC\"] node [shape = \"box\"] Navigation_S [label = \"Separate the KV and PY\"] Navigation -> mm2 mm3 -> Navigation_S [dir=back] Tags -> mm4 mm5 -> FF -> Slider[dir=back] FileChooser -> mm6 mm7 -> Menu [dir=back] Menu -> FF subgraph A{ rank = same mm1 -> mm2 -> mm3 -> mm4 -> mm5 -> mm6 -> mm7 -> mm8 -> mm9 [dir = \"none\"] } } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });","link":"/2021/05/07/Python/kivy-inaction-tb-4/"},{"title":"Kivy for android in action: Web Service","text":"CryptoWatch-Kivy 1.13Kivy 2.0.0Kivy-Garden 0.1.4kivy-garden.wordcloud 1.0.0kivymd 0.104.2.dev0 Quick Review tree . ├── 123.fa ├── 123.html ├── Karobben_logo_horizontal_800.png ├── LICENSE ├── Layout │ ├── Blog.kv │ ├── CV_cm.kv │ ├── CV_test.kv │ ├── Data_table.kv │ ├── Font.kv │ ├── Navigation_Draw.kv │ ├── Navigation_Tabs.kv │ ├── Seq.kv │ ├── editor.kv │ ├── filechooser.kv │ └── menu.kv ├── README.md ├── alipay.jpg ├── buildozer.spec ├── config │ ├── Navi.json │ └── home.json ├── custom_camera │ ├── __init__.py │ ├── custom_camera.kv │ └── custom_camera.py ├── demo │ ├── clustal │ └── echart ├── favicon.ico ├── font │ ├── ArtificialBox-WdD4.ttf │ ├── FangZhengHeiTiFanTi-1.ttf │ ├── FangZhengHeiTiJianTi-1.ttf │ ├── FangZhengKaiTiPinYinZiKu-1.ttf │ ├── FangzhenXiaozhuan.ttf │ ├── HuaKangXinZhuanTi-1.ttf │ ├── JingDianFanJiaoZhuan-1.ttf │ ├── heydings-controls-1.ttf │ ├── heydings-icons-1.ttf │ ├── heydings-icons-2.ttf │ └── icon-works-webfont-2.ttf ├── image_processing │ ├── __init__.py │ ├── cascades │ │ └── haarcascade_frontalface_default.xml │ └── image_processing.py ├── libWidget │ ├── Blog.py │ ├── CV_cm.py │ ├── CV_test.py │ ├── Data_table.py │ ├── Font.py │ ├── Seq.py │ ├── editor.py │ ├── filechooser.py │ ├── menu.py │ └── model.txt ├── libs │ ├── bio_seq.py │ ├── clustalo.py │ ├── clustalo.pytxt │ ├── web_open.py │ └── webview.py ├── logo.png ├── main.py └── wepay.png Function for Close Tab Because I was using my blog project to doing the test with this server, so I called it as Blog.py Function run_sever is for starting the http server so you can render CSS and applying js, close_blog could close the server and back to home directory. Blog.pyfrom kivy.lang import Builderfrom kivy.uix.popup import Popupfrom kivy.uix.floatlayout import FloatLayoutfrom kivy.uix.screenmanager import Screenfrom kivy.properties import ObjectPropertyfrom kivy.utils import platformimport osimport webbrowser, timeimport threadingclass FunctionWidget(): def main(self): Builder.unload_file(&quot;Layout/Blog.kv&quot;) self.Function_page = Builder.load_file(&quot;Layout/Blog.kv&quot;) self.Function_page.ids.buton_start.on_release = self.open_blog self.Function_page.ids.buton_close.on_release = self.close_blog return self.Function_page def run_sever(self): import http.server import socketserver PORT = 5500 Handler = http.server.SimpleHTTPRequestHandler with socketserver.TCPServer((&quot;&quot;, PORT), Handler) as self.httpd: print(&quot;serving at port&quot;, PORT) self.httpd.serve_forever() def close_blog(self): PATH = os.path.abspath(__file__).split(&quot;libWidget&quot;)[0].replace(&quot;appc&quot;,&quot;app&quot;) print(PATH) try: self.httpd.shutdown() os.chdir(PATH) except: os.chdir(PATH) def open_blog(self, *args): if platform == &quot;android&quot;: from libs.webview import WebView os.chdir(&quot;Blog&quot;) PATH = os.path.abspath(__file__).split(&quot;libWidget&quot;)[0].replace(&quot;appc&quot;,&quot;app&quot;) URL = 'file://'+PATH+'/demo/clustal/123.html', URL = 'http://127.0.0.1:5500/' print(&quot;URL = &quot;, URL) x = threading.Thread(target=self.run_sever, args=()) x.start() print(&quot;Started, test&quot;) if platform == &quot;android&quot;: self.browser = None self.browser = WebView(URL, enable_javascript = True, enable_downloads = True, enable_zoom = True) else: try: webbrowser.open('http://127.0.0.1:5500/') except: pass Layout Blog.py Blog.kvMDBoxLayout: MDRectangleFlatButton: id: buton_start text: &quot;Start Server&quot; on_release: None pos_hint: {&quot;center_x&quot;: .5, &quot;center_y&quot;: .5} MDRectangleFlatButton: id: buton_close text: &quot;Close Server&quot; on_release: None pos_hint: {&quot;center_x&quot;: .5, &quot;center_y&quot;: .5} Functions for webview This function was written by RobertFlatt and published in RobertFlatt /Android-for-Python . He also contributed lots of other awesome functions and examples of widgets. I copied his webview.py to libs directory. An example of using it: if platform == &quot;android&quot;: from libs.webview import WebView self.browser = None self.browser = WebView(URL, enable_javascript = True, enable_downloads = True, enable_zoom = True) digraph{ rankdir = \"LR\" mm1 [label =\"\", height = 0, width = 0, shape = none] mm2 [label =\"\", height = 0, width = 0, shape = none] mm3 [label =\"\", height = 0, width = 0, shape = none] mm4 [label =\"\", height = 0, width = 0, shape = none] mm5 [label =\"\", height = 0, width = 0, shape = none] mm6 [label =\"\", height = 0, width = 0, shape = none] mm7 [label =\"\", height = 0, width = 0, shape = none] mm8 [label =\"\", height = 0, width = 0, shape = none] mm9 [label =\"\", height = 0, width = 0, shape = none] Navigation [URL=\"/2021/04/26/Python/kivy-inaction-tb-1/#Navigation\", fontcolor = \"#3273DC\"] Navigation_S [URL=\"/2021/04/26/Python/kivy-inaction-tb-1/#Separate-the-KV-and-PY\", fontcolor = \"#3273DC\"] Tags [URL =\"/2021/04/26/Python/kivy-inaction-tb-1/#Tags\", fontcolor = \"#3273DC\"] FF [label=\"Font Switch\"; URL =\"/2021/04/26/Python/kivy-inaction-tb-1/#First-Function\", fontcolor = \"#3273DC\"] FileChooser [label=\"File Chooser\"; URL =\"/2021/04/28/Python/kivy-inaction-tb-2/#Filechooser\", fontcolor = \"#3273DC\"] Menu [label=\"Menu\"; URL =\"/2021/04/30/Python/kivy-inaction-tb-3/#Write-is-as-a-widget\", fontcolor = \"#3273DC\"] Editor [label=\"Editor\"; URL =\"/2021/05/08/Python/kivy-inaction-tb-6/\", fontcolor = \"#3273DC\"] node [shape = \"box\"] Navigation_S [label = \"Separate the KV and PY\"] Navigation -> mm2 mm3 -> Navigation_S [dir=back] Tags -> mm4 mm5 -> FF -> Slider[dir=back] FileChooser -> mm6 mm7 -> Menu [dir=back] Menu -> FF mm8-> Editor [dir = back] subgraph A{ rank = same mm1 -> mm2 -> mm3 -> mm4 -> mm5 -> mm6 -> mm7 -> mm8 -> mm9 [dir = \"none\"] } } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });","link":"/2021/05/10/Python/kivy-inaction-tb-7/"},{"title":"Kivy for android in action: Toolbox 5: Fasta Editor","text":"CryptoWatch-Kivy 1.13Kivy 2.0.0Kivy-Garden 0.1.4kivy-garden.wordcloud 1.0.0kivymd 0.104.2.dev0 Quick Review tree . ├── bin │ └── KarobbenTB-1.3-armeabi-v7a-debug.apk ├── buildozer.spec ├── favicon.ico ├── font │ ├── ArtificialBox-WdD4.ttf | ... │ └── JingDianFanJiaoZhuan-1.ttf ├── Layout │ ├── filechooser.kv │ ├── menu.kv │ ├── Navigation_Draw.kv │ ├── Navigation_Tabs.kv │ └── Seq.kv ├── lib │ └── bio_seq.py ├── libWidget │ ├── filechooser.py │ ├── main.py │ ├── menu.py │ └── Seq.py ├── logo.png └── main.py Function for Close Tab Raw file Added to widget touch libWidget/editor.pytouch libWidget/editor.kv editor.py editor.pyfrom kivy.lang import Builderfrom kivy.uix.popup import Popupfrom kivy.uix.floatlayout import FloatLayoutfrom kivy.uix.screenmanager import Screenfrom kivy.properties import ObjectPropertyfrom kivy.utils import platformimport osclass LoadDialog(FloatLayout): load = ObjectProperty(None) cancel = ObjectProperty(None)class SaveDialog(FloatLayout): save = ObjectProperty(None) text_input = ObjectProperty(None) cancel = ObjectProperty(None)class FunctionWidget(): def main(self): self.popup = Popup(title=&quot;Select .zip file&quot;, content=None, size_hint=(None, None), size=(500, 500), auto_dismiss=True) Builder.unload_file(&quot;Layout/editor.kv&quot;) self.Function_page = Builder.load_file(&quot;Layout/editor.kv&quot;) # select a file self.Function_page.ids.button_load.on_release = self.show_load # save the file self.Function_page.ids.button_save.on_release = self.show_save return self.Function_page def dismiss_popup(self): self._popup.dismiss() def show_load(self): content = LoadDialog(load=self.load, cancel=self.dismiss_popup) PATH = &quot;.&quot; if platform == &quot;android&quot;: from android.permissions import request_permissions, Permission request_permissions([Permission.READ_EXTERNAL_STORAGE, Permission.WRITE_EXTERNAL_STORAGE]) app_folder = os.path.dirname(os.path.abspath(__file__)) PATH = &quot;/storage/emulated/0&quot; #app_folder content.ids.filechooser.path = PATH self._popup = Popup(title=&quot;Load file&quot;, content=content, size_hint=(0.9, 0.9)) self._popup.open() def show_save(self): content = SaveDialog(save=self.save, cancel=self.dismiss_popup) PATH = &quot;.&quot; if platform == &quot;android&quot;: from android.permissions import request_permissions, Permission request_permissions([Permission.READ_EXTERNAL_STORAGE, Permission.WRITE_EXTERNAL_STORAGE]) app_folder = os.path.dirname(os.path.abspath(__file__)) PATH = &quot;/storage/emulated/0&quot; #app_folder content.ids.filechooser.path = PATH self._popup = Popup(title=&quot;Save file&quot;, content=content, size_hint=(0.9, 0.9)) self._popup.open() def load(self, path, filename): with open(os.path.join(path, filename[0])) as stream: try: self.Function_page.ids.text_input.text = stream.read() except: self.Function_page.ids.text_input.text = &quot;Error, can't open this file&quot; self.dismiss_popup() def save(self, path, filename): with open(os.path.join(path, filename), 'w') as stream: stream.write(self.Function_page.ids.text_input.text) self.dismiss_popup() editor.kv editor.kvBoxLayout: orientation: 'vertical' BoxLayout: size_hint_y: None height: 30 Button: id: button_load text: 'Load' Button: id: button_save text: 'Save' BoxLayout: TextInput: id: text_input text: ''&lt;LoadDialog&gt;: BoxLayout: size: root.size pos: root.pos orientation: &quot;vertical&quot; FileChooserListView: id: filechooser path: &quot;.&quot; BoxLayout: size_hint_y: None height: 30 Button: id: test text: &quot;Cancel&quot; on_release: root.cancel() Button: text: &quot;Load&quot; on_release: root.load(filechooser.path, filechooser.selection)&lt;SaveDialog&gt;: text_input: text_input BoxLayout: size: root.size pos: root.pos orientation: &quot;vertical&quot; FileChooserListView: id: filechooser on_selection: text_input.text = self.selection and self.selection[0] or '' TextInput: id: text_input size_hint_y: None height: 30 multiline: False BoxLayout: size_hint_y: None height: 30 Button: text: &quot;Cancel&quot; on_release: root.cancel() Button: text: &quot;Save&quot; on_release: root.save(filechooser.path, text_input.text) digraph{ rankdir = \"LR\" mm1 [label =\"\", height = 0, width = 0, shape = none] mm2 [label =\"\", height = 0, width = 0, shape = none] mm3 [label =\"\", height = 0, width = 0, shape = none] mm4 [label =\"\", height = 0, width = 0, shape = none] mm5 [label =\"\", height = 0, width = 0, shape = none] mm6 [label =\"\", height = 0, width = 0, shape = none] mm7 [label =\"\", height = 0, width = 0, shape = none] mm8 [label =\"\", height = 0, width = 0, shape = none] mm9 [label =\"\", height = 0, width = 0, shape = none] Navigation [URL=\"/2021/04/26/Python/kivy-inaction-tb-1/#Navigation\", fontcolor = \"#3273DC\"] Navigation_S [URL=\"/2021/04/26/Python/kivy-inaction-tb-1/#Separate-the-KV-and-PY\", fontcolor = \"#3273DC\"] Tags [URL =\"/2021/04/26/Python/kivy-inaction-tb-1/#Tags\", fontcolor = \"#3273DC\"] FF [label=\"Font Switch\"; URL =\"/2021/04/26/Python/kivy-inaction-tb-1/#First-Function\", fontcolor = \"#3273DC\"] FileChooser [label=\"File Chooser\"; URL =\"/2021/04/28/Python/kivy-inaction-tb-2/#Filechooser\", fontcolor = \"#3273DC\"] Menu [label=\"Menu\"; URL =\"/2021/04/30/Python/kivy-inaction-tb-3/#Write-is-as-a-widget\", fontcolor = \"#3273DC\"] Editor [label=\"Editor\"; URL =\"/2021/05/08/Python/kivy-inaction-tb-6/\", fontcolor = \"#3273DC\"] node [shape = \"box\"] Navigation_S [label = \"Separate the KV and PY\"] Navigation -> mm2 mm3 -> Navigation_S [dir=back] Tags -> mm4 mm5 -> FF -> Slider[dir=back] FileChooser -> mm6 mm7 -> Menu [dir=back] Menu -> FF mm8-> Editor [dir = back] subgraph A{ rank = same mm1 -> mm2 -> mm3 -> mm4 -> mm5 -> mm6 -> mm7 -> mm8 -> mm9 [dir = \"none\"] } } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });","link":"/2021/05/08/Python/kivy-inaction-tb-5/"},{"title":"Kivy for android in action: pack OpenCV with buildozer","text":"CryptoWatch-Kivy 1.13Kivy 2.0.0Kivy-Garden 0.1.4kivy-garden.wordcloud 1.0.0kivymd 0.104.2.dev0 Build OpenCV for kivy The resolution is from franslott in github issue. It seems the new version of buildozer updated the SDK tools and no longer supports packing the OpenCV with the default setting. So, we should settle the SDK by ourselves. What can we do with OpenCV in Android: loading/writing images writing videos (some formats like avi) facial detection with the camera opened by kivy What we can’t do: loading videos open cameras update images under threading (display) Abilities of OpenCV were limited in android. Hope someone could solve the problems above soon. #mv tools old-tools# mv lib/external/com/android/tools lib/external/com/android/old-tools# 1. Download [cmdlines-tools from google](https://developer.android.com/studio#cmdline-tools)# 2. prepare the sdk by yourself# export the path you'd like to place itexport PREFIX=/run/media/karobben/Data/Kivy2.0MD0.104.2.dP3.7.5mkdir $PREFIX/.buildozer/android/platform/android-sdkcd $PREFIX/.buildozer/android/platform/android-sdk/cp ~/Downloads/commandlinetools-linux-7302050_latest.zip .unzip commandlinetools-linux-7302050_latest.zip# mv tools old-toolscd cmdline-tools/binsudo ./sdkmanager --sdk_root=$PREFIX/.buildozer/android/platform/android-sdk/ --install &quot;tools&quot;sudo ./sdkmanager --sdk_root=$PREFIX/.buildozer/android/platform/android-sdk/ --install &quot;build-tools;29.0.0-rc3&quot;sudo ./sdkmanager --sdk_root=$PREFIX/.buildozer/android/platform/android-sdk/ --install &quot;platforms;android-27&quot;sudo ./sdkmanager --sdk_root=$PREFIX/.buildozer/android/platform/android-sdk/ --install &quot;platform-tools&quot;sudo ./sdkmanager --sdk_root=$PREFIX/.buildozer/android/platform/android-sdk/ --install &quot;patcher;v4&quot;sudo ./sdkmanager --sdk_root=$PREFIX/.buildozer/android/platform/android-sdk/ --install &quot;emulator&quot;sudo ./sdkmanager --sdk_root=$PREFIX/android-sdk/ --install &quot;tools&quot;sudo ./sdkmanager --sdk_root=$PREFIX/android-sdk/ --install &quot;build-tools;29.0.0-rc3&quot;sudo ./sdkmanager --sdk_root=$PREFIX/android-sdk/ --install &quot;platforms;android-27&quot;sudo ./sdkmanager --sdk_root=$PREFIX/android-sdk/ --install &quot;platform-tools&quot;sudo ./sdkmanager --sdk_root=$PREFIX/android-sdk/ --install &quot;patcher;v4&quot;sudo ./sdkmanager --sdk_root=$PREFIX/android-sdk/ --install &quot;emulator&quot; adding the path into buildozer.spc: buildozer.spcandroid.sdk_path = /run/media/ken/Data/Kivy2.0MD0.104.2.dP3.7.5/android-sdk/ # delete ANT, NDK againbuildozer android cleanbuildozer distcleanbuildozer -v android debug# or buildozer android debug deploy run","link":"/2021/05/15/Python/kivy-inaction-tb-8/"},{"title":"Kivy for android in action: Toolbox 6: Tab and Navigation Initiate","text":"CryptoWatch-Kivy 1.13Kivy 2.0.0Kivy-Garden 0.1.4kivy-garden.wordcloud 1.0.0kivymd 0.104.2.dev0 Quick Review tree . ├── bin │ └── KarobbenTB-1.3-armeabi-v7a-debug.apk ├── buildozer.spec ├── favicon.ico ├── font │ ├── ArtificialBox-WdD4.ttf | ... │ └── JingDianFanJiaoZhuan-1.ttf ├── Layout │ ├── filechooser.kv │ ├── menu.kv │ ├── Navigation_Draw.kv │ ├── Navigation_Tabs.kv │ └── Seq.kv ├── lib │ └── bio_seq.py ├── libWidget │ ├── filechooser.py │ ├── main.py │ ├── menu.py │ └── Seq.py ├── logo.png └── main.py Function for Close Tab Raw file Added to widget mkdir configtouch config/home.jsontouch config/Navi.json Navi.json Navi.json{ &quot;Seq&quot;: {&quot;icon&quot;:&quot;篆体&quot;,&quot;title&quot;:&quot;Sequencs Tools&quot;,&quot;font&quot;:&quot;font/HuaKangXinZhuanTi-1&quot;}, &quot;editor&quot;: {&quot;icon&quot;:&quot;Text Editor&quot;,&quot;title&quot;:&quot;editor&quot;, &quot;font&quot;:&quot;font/FangZhengHeiTiFanTi-1&quot;}} main.py+ self.List = json.load(open('config/Navi.json'))+ L = [i for i in self.List.keys()]+ for x in L:+ print(x)+ text = f&quot;[font={self.List[x]['font']}]{self.List[x]['icon']}[/font]&quot;+ X = MDRectangleFlatButton(text =text)+ #X.font = self.List[x]['font']+ X.on_release = lambda Dic = x:self.add_tag(Dic)+ self.Widget_navi.ids.nav_button.add_widget(X) #from libWidget.Seq import FunctionWidget as tmp+ Home_dic = json.load(open('config/home.json'))+ for i in list(Home_dic.keys())[::-1]:+ def HomeTabUpdate(self, Dic):+ if Dic != None:+ List = [icon.text.split(&quot;]&quot;)[0].replace(&quot;[ref=&quot;,&quot;&quot;) for icon in self.Widget_tabs.ids.tabs.get_tab_list()]+[self.List[Dic]['icon']]+ List.remove(&quot;&quot;)+ else:+ List = [icon.text.split(&quot;]&quot;)[0].replace(&quot;[ref=&quot;,&quot;&quot;) for icon in self.Widget_tabs.ids.tabs.get_tab_list()]+ List = list(set(List))+ Result = []+ for icon in List:+ for Key in self.List.keys():+ if self.List[Key]['icon']==icon:+ Result += [Key]+ Home_dic = {x:self.List[x] for x in Result}+ with open(&quot;config/home.json&quot;,'w') as F:+ F.write(json.dumps(Home_dic)) def add_tag(self, Dic): ...+ self.HomeTabUpdate(Dic) def on_ref_press( self, instance_tabs, instance_tab_label, instance_tab, instance_tab_bar, instance_carousel, ):+ self.HomeTabUpdate(Dic=None) Click to show main.py main.pyfrom kivy.uix.screenmanager import Screenfrom kivymd.uix.button import MDRectangleFlatButtonfrom kivy.lang import Builderfrom kivy.uix.floatlayout import FloatLayoutfrom kivymd.uix.tab import MDTabsBasefrom kivy.core.window import WindowBasefrom kivymd.icon_definitions import md_iconsfrom kivymd.app import MDAppfrom libWidget.filechooser import ConfirmPopupimport jsonWindowBase.softinput_mode = &quot;below_target&quot;# Function libsdef OPEN(file): return open(file).read()class Tab(FloatLayout, MDTabsBase): '''Class implementing content for a tab.'''class MainApp(MDApp): ConfirmPopup = ConfirmPopup() #Editor = Editor() PATH = &quot;.&quot; def change_text(self, Files): #self.the_time.text = str(Files) self.Button_test.text = Files[0] print(&quot;main screen&quot;, str(Files)) def build(self): screen = Screen() screen.change_text = self.change_text # loading Navigation (left) self.Widget_navi = Builder.load_string(OPEN(&quot;Layout/Navigation_Draw.kv&quot;)) # loading navigation tags self.Widget_tabs = Builder.load_string(OPEN(&quot;Layout/Navigation_Tabs.kv&quot;)) #self.Widget_tabs.ids.tabs.on_ref_press = self.on_ref_press(*args) # loading The Function pages # Loading Sequencs function page screen.add_widget(self.Widget_tabs) screen.add_widget(self.Widget_navi) return screen # Functions for Navigation Ta def on_start(self): from lib.bio_seq import Bio as FunBioSeq Fun = FunBioSeq() print(Fun.List()) def PP(): print(Function_page.ids.seq_input.text) Function_page.ids.seq_result.text = Function_page.ids.seq_input.text.upper() Fun = FunBioSeq() self.List = json.load(open('config/Navi.json')) ''' Navigation test ''' Num = 0 L = [i for i in self.List.keys()] for x in L: print(x) text = f&quot;[font={self.List[x]['font']}]{self.List[x]['icon']}[/font]&quot; X = MDRectangleFlatButton(text =text) #X.font = self.List[x]['font'] X.on_release = lambda Dic = x:self.add_tag(Dic) self.Widget_navi.ids.nav_button.add_widget(X) ''' locals()[&quot;Btn_&quot;.format(self.List[i]['icon'])] = MDRectangleFlatButton( text=self.List[i]['icon'], font_name = self.List[i]['font'], on_release = lambda x = i:self.add_tag(i)) self.Widget_navi.ids.nav_button.add_widget(locals()[&quot;Btn_&quot;.format(self.List[i]['icon'])]) ''' #from libWidget.Seq import FunctionWidget as tmp Home_dic = json.load(open('config/home.json')) for i in list(Home_dic.keys())[::-1]: tmp_tab = Tab(text=f&quot;[ref={self.List[i]['icon']}][color=#fa937f][font=font/heydings-icons-1]{'X'}[/font][/color][/ref] [font={self.List[i]['font']}]{self.List[i]['icon']}[/font]&quot;) Module = __import__('libWidget.'+i, globals(), locals(), [], 0) Fun = eval(&quot;Module.&quot;+i+&quot;.FunctionWidget()&quot;) screen_tmp = Screen() screen_tmp.name = i screen_tmp.add_widget(Fun.main()) tmp_tab.add_widget(screen_tmp) self.Widget_tabs.ids.tabs.add_widget(tmp_tab) def add_tag(self, Dic): print(Dic) name_tab = self.List[Dic]['icon'] Tag_title = f&quot;[ref={name_tab}][font=font/heydings-icons-1][color=#fa937f]{'X'}[/color][/font][/ref][font=./font/JingDianFanJiaoZhuan-1][font={self.List[Dic]['font']}]{name_tab}[/font]&quot; tmp_tab =Tab( text = Tag_title) Module = __import__('libWidget.'+Dic, globals(), locals(), [], 0) Fun = eval(&quot;Module.&quot;+Dic+&quot;.FunctionWidget()&quot;) screen_tmp = Screen() screen_tmp.name = &quot;Test&quot; screen_tmp.add_widget(Fun.main()) tmp_tab.add_widget(screen_tmp) self.Widget_tabs.ids.tabs.add_widget(tmp_tab) self.Widget_tabs.ids.tabs.switch_tab(Tag_title) self.Widget_navi.ids.nav_drawer.set_state(&quot;close&quot;) # Update Tages in First page self.HomeTabUpdate(Dic) def HomeTabUpdate(self, Dic): if Dic != None: List = [icon.text.split(&quot;]&quot;)[0].replace(&quot;[ref=&quot;,&quot;&quot;) for icon in self.Widget_tabs.ids.tabs.get_tab_list()]+[self.List[Dic]['icon']] List.remove(&quot;&quot;) else: List = [icon.text.split(&quot;]&quot;)[0].replace(&quot;[ref=&quot;,&quot;&quot;) for icon in self.Widget_tabs.ids.tabs.get_tab_list()] List = list(set(List)) Result = [] for icon in List: for Key in self.List.keys(): if self.List[Key]['icon']==icon: Result += [Key] Home_dic = {x:self.List[x] for x in Result} with open(&quot;config/home.json&quot;,'w') as F: F.write(json.dumps(Home_dic)) # Functions for Navigation Tab Switch def on_tab_switch( self, instance_tabs, instance_tab, instance_tab_label, tab_text): '''Called when switching tabs. :type instance_tabs: &lt;kivymd.uix.tab.MDTabs object&gt;; :param instance_tab: &lt;__main__.Tab object&gt;; :param instance_tab_label: &lt;kivymd.uix.tab.MDTabsLabel object&gt;; :param tab_text: text or name icon of tab; ''' instance_tab.ids.label.text = tab_text def on_ref_press( self, instance_tabs, instance_tab_label, instance_tab, instance_tab_bar, instance_carousel, ): ''' The method will be called when the ``on_ref_press`` event occurs when you, for example, use markup text for tabs. :param instance_tabs: &lt;kivymd.uix.tab.MDTabs object&gt; :param instance_tab_label: &lt;kivymd.uix.tab.MDTabsLabel object&gt; :param instance_tab: &lt;__main__.Tab object&gt; :param instance_tab_bar: &lt;kivymd.uix.tab.MDTabsBar object&gt; :param instance_carousel: &lt;kivymd.uix.tab.MDTabsCarousel object&gt; ''' # Removes a tab by clicking on the close icon on the left. for instance_tab in instance_carousel.slides: if instance_tab.text == instance_tab_label.text: instance_tabs.remove_widget(instance_tab_label) break self.HomeTabUpdate(Dic=None)MainApp().run() We can also add a json for initializing the home page so we can reload the tabs we keeped in last time. home.json home.json{ &quot;Font&quot;: {&quot;icon&quot;:&quot;篆体&quot;,&quot;title&quot;:&quot;Fonttoo Tools&quot;,&quot;font&quot;:&quot;font/HuaKangXinZhuanTi-1&quot;}} digraph{ rankdir = \"LR\" mm1 [label =\"\", height = 0, width = 0, shape = none] mm2 [label =\"\", height = 0, width = 0, shape = none] mm3 [label =\"\", height = 0, width = 0, shape = none] mm4 [label =\"\", height = 0, width = 0, shape = none] mm5 [label =\"\", height = 0, width = 0, shape = none] mm6 [label =\"\", height = 0, width = 0, shape = none] mm7 [label =\"\", height = 0, width = 0, shape = none] mm8 [label =\"\", height = 0, width = 0, shape = none] mm9 [label =\"\", height = 0, width = 0, shape = none] Navigation [URL=\"/2021/04/26/Python/kivy-inaction-tb-1/#Navigation\", fontcolor = \"#3273DC\"] Navigation_S [URL=\"/2021/04/26/Python/kivy-inaction-tb-1/#Separate-the-KV-and-PY\", fontcolor = \"#3273DC\"] Tags [URL =\"/2021/04/26/Python/kivy-inaction-tb-1/#Tags\", fontcolor = \"#3273DC\"] FF [label=\"First Function\"; URL =\"/2021/04/26/Python/kivy-inaction-tb-1/#First-Function\", fontcolor = \"#3273DC\"] FileChooser [label=\"File Chooser\"; URL =\"/2021/04/28/Python/kivy-inaction-tb-2/#Filechooser\", fontcolor = \"#3273DC\"] Menu [label=\"Menu\"; URL =\"/2021/04/30/Python/kivy-inaction-tb-3/#Write-is-as-a-widget\", fontcolor = \"#3273DC\"] Editor [label=\"Editor\"; URL =\"/2021/05/08/Python/kivy-inaction-tb-6/\", fontcolor = \"#3273DC\"] node [shape = \"box\"] Navigation_S [label = \"Separate the KV and PY\"] Navigation -> mm2 mm3 -> Navigation_S [dir=back] Tags -> mm4 mm5 -> FF -> Slider[dir=back] FileChooser -> mm6 mm7 -> Menu [dir=back] Menu -> FF mm8-> Editor [dir = back] subgraph A{ rank = same mm1 -> mm2 -> mm3 -> mm4 -> mm5 -> mm6 -> mm7 -> mm8 -> mm9 [dir = \"none\"] } } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });","link":"/2021/05/08/Python/kivy-inaction-tb-6/"},{"title":"Kivy in action: video2audio| Python |mp4 to mo3","text":"Quick Start Copy the main codes for filechooser from another post: Karobben, FileChooser, 2021 Copy the function from post: Karobben, video to audio 2021 touch main.py main.kv","link":"/2021/04/27/Python/kivy-video2audio/"},{"title":"Kivy for android in action:Show opencv result in Kivy desktop","text":"CryptoWatch-Kivy 1.13Kivy 2.0.0Kivy-Garden 0.1.4kivy-garden.wordcloud 1.0.0kivymd 0.104.2.dev0 Quick Review tree . ├── 123.fa ├── 123.html ├── Karobben_logo_horizontal_800.png ├── LICENSE ├── Layout │ ├── Blog.kv │ ├── CV_cm.kv │ ├── CV_test.kv │ ├── Data_table.kv │ ├── Font.kv │ ├── Navigation_Draw.kv │ ├── Navigation_Tabs.kv │ ├── Seq.kv │ ├── editor.kv │ ├── filechooser.kv │ └── menu.kv ├── README.md ├── alipay.jpg ├── buildozer.spec ├── config │ ├── Navi.json │ └── home.json ├── custom_camera │ ├── __init__.py │ ├── custom_camera.kv │ └── custom_camera.py ├── demo │ ├── clustal │ └── echart ├── favicon.ico ├── font │ ├── ArtificialBox-WdD4.ttf │ ├── FangZhengHeiTiFanTi-1.ttf │ ├── FangZhengHeiTiJianTi-1.ttf │ ├── FangZhengKaiTiPinYinZiKu-1.ttf │ ├── FangzhenXiaozhuan.ttf │ ├── HuaKangXinZhuanTi-1.ttf │ ├── JingDianFanJiaoZhuan-1.ttf │ ├── heydings-controls-1.ttf │ ├── heydings-icons-1.ttf │ ├── heydings-icons-2.ttf │ └── icon-works-webfont-2.ttf ├── image_processing │ ├── __init__.py │ ├── cascades │ │ └── haarcascade_frontalface_default.xml │ └── image_processing.py ├── libWidget │ ├── Blog.py │ ├── CV_cm.py │ ├── CV_test.py │ ├── Data_table.py │ ├── Font.py │ ├── Seq.py │ ├── editor.py │ ├── filechooser.py │ ├── menu.py │ └── model.txt ├── libs │ ├── bio_seq.py │ ├── clustalo.py │ ├── clustalo.pytxt │ ├── web_open.py │ └── webview.py ├── logo.png ├── main.py └── wepay.png Function for Close Tab This script originally contributed by okajun35 in GitHub. CV_cm.py CV_test.py# -*- coding: utf-8 -*import numpy as npimport cv2from kivy.uix.boxlayout import BoxLayoutfrom PIL import Imagefrom kivy.lang import Builderfrom kivy.uix.widget import Widgetfrom kivy.graphics.texture import Texturefrom kivy.graphics import Rectangleclass FunctionWidget(): def main(self): Builder.unload_file(&quot;Layout/test.kv&quot;) self.Function_page = Builder.load_file(&quot;Layout/test.kv&quot;) self.Function_page.ids.button_load.on_release= self.run return self.Function_page def run(self, *args): img = cv2.imread('logo.png') img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) # 画像をグレイスケールに変換 #gray_img = cv2.cvtColor(img,1) texture = Texture.create(size=(img.shape[1], img.shape[0]), colorfmt='rgb', bufferfmt='ubyte') # BGRモードで用意,ubyteはデフォルト引数なので指定なくてもよい texture.blit_buffer(img.tostring(),colorfmt='rgb', bufferfmt='ubyte') # ★ここもBGRで指定しないとRGBになって色の表示がおかしくなる texture.flip_vertical() self.Function_page.show_pic = texture Layout CV_cm.kv CV_test.kvBoxLayout: orientation: &quot;vertical&quot; show_pic: None BoxLayout: canvas: Rectangle: texture: root.show_pic pos: self.pos size: self.size #pos_hint: {'center_x': .5, 'center_y': .5} #color: 0, 0, 0, 1 BoxLayout: orientation: &quot;vertical&quot; BoxLayout MDRaisedButton: id: button_load text: 'F' font_size: 30 font_name: './font/heydings-icons-1' width: root.width * 0.5 line_color: 1, 1, 1, 1 It works on PC not in androied. And I don’t know why. digraph{ rankdir = \"LR\" mm1 [label =\"\", height = 0, width = 0, shape = none] mm2 [label =\"\", height = 0, width = 0, shape = none] mm3 [label =\"\", height = 0, width = 0, shape = none] mm4 [label =\"\", height = 0, width = 0, shape = none] mm5 [label =\"\", height = 0, width = 0, shape = none] mm6 [label =\"\", height = 0, width = 0, shape = none] mm7 [label =\"\", height = 0, width = 0, shape = none] mm8 [label =\"\", height = 0, width = 0, shape = none] mm9 [label =\"\", height = 0, width = 0, shape = none] Navigation [URL=\"/2021/04/26/Python/kivy-inaction-tb-1/#Navigation\", fontcolor = \"#3273DC\"] Navigation_S [URL=\"/2021/04/26/Python/kivy-inaction-tb-1/#Separate-the-KV-and-PY\", fontcolor = \"#3273DC\"] Tags [URL =\"/2021/04/26/Python/kivy-inaction-tb-1/#Tags\", fontcolor = \"#3273DC\"] FF [label=\"Font Switch\"; URL =\"/2021/04/26/Python/kivy-inaction-tb-1/#First-Function\", fontcolor = \"#3273DC\"] FileChooser [label=\"File Chooser\"; URL =\"/2021/04/28/Python/kivy-inaction-tb-2/#Filechooser\", fontcolor = \"#3273DC\"] Menu [label=\"Menu\"; URL =\"/2021/04/30/Python/kivy-inaction-tb-3/#Write-is-as-a-widget\", fontcolor = \"#3273DC\"] Editor [label=\"Editor\"; URL =\"/2021/05/08/Python/kivy-inaction-tb-6/\", fontcolor = \"#3273DC\"] node [shape = \"box\"] Navigation_S [label = \"Separate the KV and PY\"] Navigation -> mm2 mm3 -> Navigation_S [dir=back] Tags -> mm4 mm5 -> FF -> Slider[dir=back] FileChooser -> mm6 mm7 -> Menu [dir=back] Menu -> FF mm8-> Editor [dir = back] subgraph A{ rank = same mm1 -> mm2 -> mm3 -> mm4 -> mm5 -> mm6 -> mm7 -> mm8 -> mm9 [dir = \"none\"] } } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });","link":"/2021/05/15/Python/kivy-inaction-tb-9/"},{"title":"Kivy: Screen Communication","text":"Quick view © Karobben This work originated from @一个哲学家[1] Here is the main.py main.pyfrom kivy.app import Appfrom kivy.lang import Builderfrom kivy.uix.screenmanager import ScreenManager, Screenfrom kivy.uix.button import Buttonfrom kivy.uix.widget import Widgetfrom kivy.properties import ObjectPropertyfrom kivy.core.text import LabelBaseclass NewGameScreen(Screen): class Gao(Widget): label = ObjectProperty(None) def btn(self,label): label.text='AFTER PROCESSING'+label.textclass OptionScreen(Screen): passclass TestApp(App): def build(self): sm = ScreenManager() sm.add_widget(NewGameScreen()) sm.add_widget(OptionScreen()) return smif __name__ == '__main__': TestApp().run() here is the test.kv test.kv&lt;NewGameScreen&gt;: name: 'newgame' label:label_id BoxLayout: orientation: 'vertical' TextInput: id:label_id text:'INPUT' on_text: root.manager.get_screen('options').label.text = str(self.text) Button: text: 'SUBMIT' on_press: root.Gao.btn(self,label_id) root.manager.transition.direction = 'left' root.manager.current = 'options' root.manager.current = 'options' if label_id.text == '123' else &quot;newgame&quot; #输入为 123 时才跳转&lt;OptionScreen&gt;: label: label_id name: 'options' orientation: 'vertical' BoxLayout: Button: text: 'BACK' on_press: root.manager.transition.direction = 'right' root.manager.current = 'newgame' Label: id: label_id text: '1' Similar Resolution This script was also communicate the different classes by using manager.get_screen @Nykakin[2] from kivy.app import Appfrom kivy.lang import Builderfrom kivy.uix.screenmanager import ScreenManager, Screenfrom kivy.properties import StringPropertyBuilder.load_string('''&lt;MainScreen&gt;: BoxLayout: orientation: &quot;vertical&quot; Button: text: 'Goto strategy' on_press: root.manager.current = 'strategy' Button: text: 'Set text' on_press: root.SetText()&lt;StrategyScreen&gt;: BoxLayout: orientation: &quot;vertical&quot; Label: text: root.labelText Button: text: 'Back to menu' on_press: root.manager.current = 'main'''')class MainScreen(Screen): def SetText(self): text = 'Total=' + str(17*21) self.manager.get_screen('strategy').labelText = textclass StrategyScreen(Screen): labelText = StringProperty('My label')class TestApp(App): def build(self): # Create the screen manager screenManager = ScreenManager() screenManager.add_widget(MainScreen(name='main')) screenManager.add_widget(StrategyScreen(name='strategy')) return screenManagerif __name__ == '__main__': TestApp().run() Another Example: @Taher Kawantwala[3] main.py main.pyfrom kivy.app import Appfrom kivy.uix.anchorlayout import AnchorLayoutfrom kivy.uix.boxlayout import BoxLayoutfrom kivy.uix.popup import Popupclass ConfirmPopup(BoxLayout): def __init__(self, **kwargs): self.register_event_type('on_answer') super(ConfirmPopup, self).__init__(**kwargs) self.total_images = 0 def on_answer(self, filename, JKMain): self.total_images = 8 print(&quot;JKMain=&quot;, JKMain) JKMain.change_text(self.total_images)class JKMain(AnchorLayout): def __init__(self, **kwargs): super(JKMain, self).__init__(**kwargs) def change_text(self, layers): self.the_time.text = &quot;Total Layers : &quot; + str(layers) print(&quot;Total Layers = &quot; + str(layers)) def popup_func(self): content = ConfirmPopup() content.bind(on_answer=self._on_answer) self.popup = Popup(title=&quot;Select .zip file&quot;, content=content, size_hint=(None, None), size=(500, 500), auto_dismiss=False) self.popup.open() def _on_answer(self, instance, answer, obj): self.popup.dismiss()class Main(App): def build(self): return JKMain()if __name__ == &quot;__main__&quot;: Main().run() main.ky main.kv#: kivy 1.10.0&lt;JKmain&gt;: the_time: _id_lbl_time AnchorLayout: anchor_x: 'left' anchor_y: 'top' BoxLayout: orientation: 'vertical' id: _tool_box size_hint: None,0.75 width: 300 Label: id: _id_lbl_time text: &quot;Total Layers : &quot; AnchorLayout: anchor_x: 'right' anchor_y: 'top' GridLayout: rows:2 BoxLayout: orientation: 'horizontal' Button: on_release: app.root.current = &quot;main&quot; text: &quot;SELECT&quot; size_hint: 1,0.2 background_color: (1.0, 1.0, 0.0, 1.0) on_release: root.popup_func() Button: text: &quot;START&quot; size_hint: 1,0.2 background_color: (1.0, 0.0, 1.0, 1.0) on_release: root.change_text(100) Button: text: &quot;EXIT&quot; size_hint: 1,0.2 background_color: (1.0, 0.0, 1.0, 1.0) on_release: root.exit_app(self)&lt;ConfirmPopup&gt;: BoxLayout: orientation: 'vertical' FileChooserIconView: id: filechooser filters: ['*.zip'] GridLayout: cols: 2 size_hint: 1,0.2 Button: text: 'OK' on_release: root.dispatch('on_answer', filechooser.selection, app.root) size_hint: 1,0.2 Button: text: 'Cancel' on_release: root.dispatch('on_answer', 'Cancel') size_hint: 1,0.2 一个哲学家; 2021; 今日头条; kivy教程：实现屏幕切换、数据传递和函数绑定 ↩︎ Psionman; 2015; How to update label text on second kivy screen; StackOverflow ↩︎ Taher Kawantwala; 2018; Kivy Change Label widget Text from another class; StackOverflow ↩︎","link":"/2021/03/09/Python/kivy-screen-commu/"},{"title":"Kivy 新手入门避坑指南","text":"Kivy 新手入门避坑指南 个人说说使用kivy的原因： 不会java, 不会C， 不会。。。 简而言之， 除了python, 啥也不会。但是又想写点 android 的apk. 所以， kivy成了我唯一的选择了。。。 在此奉劝， 如果只是一开发安卓apk为主要目的， 还是不要用比较好。 虽然kivy的买点在跨平台， 但是实际上， 平台夸起来， 很吃力。 我说说我现在的进展吧： （针对安卓） requests 库基本没问题 Opencv 不完美。 可以配合摄像头做人脸识别等但是无法读取视频。 可以输出视频，但是格式有限制。 imageio 输出gif PIL 基本没什么问题 numpy ok 可开启http服务 可调用android web浏览器（java） 目前来说， 其实已经可以做很多事情了。不过得自己注意，电脑和安卓之间的兼容问题。 开始前的避坑 python 版本 都2021年了， 不会真的还有人在用python2吧？？ 不会吧不会吧不会吧？？？ 请赶紧退坑， 谢谢。 python3 也不能乱用。 之前我用的 3.7.6， 然后打包request之后， 能用， 但是再出结果之后， 就会崩溃闪退。 我也不知道为啥。最后更具stack overflow 的解释， 换上了3.7.5， 就完全没问题了。 真的很奇奇怪怪= = 但是- - 目前我还是用的， 3.7.6。。。为什么？ 俺也不知道。反正：不要用最新的不要用3.9，更加不要用4。 不听的老人言， 吃亏在眼前 kivy和kivymd版本 Kivy和kivymd版本倒是没这么多的肯。 但是，md的坑是真大。 如果用错了版本， 你就会发现， 官方文档好多是“错的”！！更不不能运行。 其实官方文档怎么会有问题呢？ 动动脚趾头嘛？当然不会啦！ 对一下版本号就知道了。 切换版本以后， 就好。所以， 版本可以瞎用， 自己明白就好 另外， kivy和kivymd版本， 自己瞎用无所谓， 但请一定记得， 测试和打包的版本，保持一致。 不然， 到时候肯定会有问题的。 开始不会怎么样= = 东西多了复杂就会发现， 电脑和手机结果， 不一样， 甚至手机直接闪退 = = 打包 buildozer 打包hello world, 还是很方便的， 尤其是环境准备好之后， 再次打包就简单快了。 对于国内来说， 打包大部分失败的原因都是， 网络链接问题， 下载失败。所以， 没事的话， 先多重复几次， 然后盯一下卡在了哪里。 一般是先卡很久， 然后才会报错。 更复杂的东西， 比如打包opencv, 需要自己给sdk, 这个就麻烦了。 不过也只是第一次麻烦， 会了以后， 其实蛮简单的。 有些东西， 是真的没发打包= =（打包了也没法用）可能需要更特殊手段。 这就看大家大显神通了 报错 如果在电脑端运行的报错， 都看不懂的话， 那真的， 求你了， 放弃kivy吧。你大概适合换一个饭碗\\兴趣。python的错误， 都是精确到具体哪一行哪一個函数的说- - adb logcat 安卓报错 adb 报错的话， 一般来说， 也是python的运行问题。 如果这样的话， 只要在日至里搜寻 I python 就好。 对于linux, 可以直接adb logcat| grep &quot;I python&quot;再复杂的话， 就可以看看 I python 前面的编号，然后抓去这一个ID, 就可以获得这个程序所有的 adb log 了。但是这个内容报错- - 就会比较复杂了 = = 反正我是看不懂的。 贴上 stack overflow 也从来没有被回答过- - 我贴的几个= = 好难呀。 路径 安卓文件安装后， 会在/data目录下创建该app的文件夹。你在使用对应app的时候，是有读写权限的。 但是在其他地方， 比如自带的文件管理器， 对该app没有任何读写权限。 所以， 你的把想保存的东西放在别的地方。 用户自己有读写权限的根目录， 一般为/storage/emulated/0。 icon-font 消失 请加入字体 sdl2_ttf==2.0.15 在 requirements那里 kivy 及其打包环境快速配置 首先， 这是我的系统环境： ██████████████████ ████████ ken@manjaro ██████████████████ ████████ OS: Manjaro 21.0.5 Ornara ██████████████████ ████████ Kernel: x86_64 Linux 5.4.118-1-MANJARO ██████████████████ ████████ Uptime: 20h 14m ████████ ████████ Packages: 1599 ████████ ████████ ████████ Shell: zsh 5.8 ████████ ████████ ████████ Resolution: 1920x1080 ████████ ████████ ████████ DE: GNOME 3.38.5 ████████ ████████ ████████ WM: Mutter ████████ ████████ ████████ WM Theme: Matcha-dark-sea ████████ ████████ ████████ GTK Theme: Matcha-sea [GTK2/3] ████████ ████████ ████████ Icon Theme: Papirus-Dark-Maia ████████ ████████ ████████ Font: Noto Sans 11 ████████ ████████ ████████ Disk: 705G / 1.5T (50%) CPU: Intel Xeon E3-1535M v6 @ 8x 4.2GHz [77.0°C] GPU: Quadro M2200 RAM: 4366MiB / 64042MiB 这里， 根据 john100 2021 在 arch 论坛的建议， 直接先安装 python 3.7.6， 然后配置一个虚拟环境 安装 Python cd /usr/localsudo wget http://python.org/ftp/python/3.7.6/Python-3.7.6.tar.xzsudo tar xf Python-3.7.6.tar.xzcd Python-3.7.6sudo ./configure --enable-optimizationssudo make altinstallsudo rm -rf ../Python*xz kivy 和buildozer 这里我用力清华镜像。 但是清华镜像好像不稳定。 有时候， 直接下载还快。 python3.7 -m pip install -i https://pypi.tuna.tsinghua.edu.cn/simple --user --upgrade pip wheel setuptools virtualenvcd ~python3.7 -m virtualenv kivyvensource kivyven/bin/activatepip install -i https://pypi.tuna.tsinghua.edu.cn/simple kivy pip install -i https://pypi.tuna.tsinghua.edu.cn/simple cythonpip install -i https://pypi.tuna.tsinghua.edu.cn/simple buildozerpip install -i https://pypi.tuna.tsinghua.edu.cn/simple https://github.com/kivymd/KivyMD/archive/master.zippip install -i https://pypi.tuna.tsinghua.edu.cn/simple encodings 关于 buildozer, 还有一些小东西要安装的, 比如说， java, android-tools. 不同平台安装不一样。 我的是manjaro cd ~# install adbsudo pamac install android-tools, dpkg# install javasudo pacman -S jre8-openjdk-headless jre8-openjdk jdk8-openjdk openjdk8-doc openjdk8-src# Make invironment for some python librarysudo pacman -S cmakesource kivyven/bin/activate# enter the working directory thenbuildozer android debug deploy run 然后就可以直接打包测试了。找个hello world 的帖子， 然后直接打包网络没啥问题的话， 就直接成功啦！ 有些小问题， 记录在 Karobben Blog了 关于安装 sdk为了打包opencv, 也放哪里了 其他 打包 opencv：我的博客 上手项目练习：简单工具箱 关于报错：如何看kivy的报错 所有的kivy 帖子： Kivy 合集 项目展示 inclem.net 介绍了3款完成度非常高的精美kivyapp（本人没有上手测试）， 分别为 Boardz (滑雪游戏) Kognitivo (益智游戏) Barly (文字游戏) 本人在写一个完程度不高， bug很多的工具箱。 主要基于opencv Karobben GitHub 手把手教程：点击我 另外， 写了个垃圾爬虫程序，百度统计 但是好像不能用了- -百度json格式改了， 我懒得更新","link":"/2021/05/31/Python/kivy-tutorial/"},{"title":"kivy: Write&#x2F;Save Files to Android|Android Path","text":"/storage/emulate/{user}/ For my example, my cell phone was: Huawei P30 pro The absolute path of Download directory is: /storage/emulate/0/Download If you Not sure about your path, try this script to access your path: filechooser. I updated this script, so, it will show the absolute path of the file you choose.","link":"/2021/03/12/Python/kivy-write2android/"},{"title":"Kivy: debug, understand adblog| adb log","text":"tar files for packaging This is where tar.gz filers stored. By storing files where, we needn’t downloads them again next time. .buildozer/android/platform/build-armeabi-v7a/packages/ ├── cython │ └── 0.29.15.tar.gz ├── decorator │ └── 4.2.1.tar.gz ├── ffmpeg │ └── 007e03348dbd8d3de3eb09022d72c734a8608144.zip ├── freetype │ └── freetype-2.10.1.tar.gz ├── hostpython3 │ ├── Python-3.7.5.tgz │ └── Python-3.8.1.tgz ├── jpeg │ └── 2.0.1.tar.gz ├── kivy │ ├── 1.11.1.zip │ └── 2.0.0.zip ├── libbz2 │ └── bzip2-1.0.8.tar.gz File for packaging This is the place of environment for packaged apk. The name of it is from buildozer.spec: package.name = KarobbenTB .buildozer/android/platform/build-armeabi-v7a/build/python-installs/ .buildozer/android/platform/build-armeabi-v7a/build/python-installs/ ├── BaiduStat ├── CSVD ├── filechooser ├── Icons ├── KarobbenTB ├── Kivyv2a └── opencvdemo PS: packaged apk Place 1 /media/ken/Data/Kivy/.buildozer/android/platform/build-armeabi-v7a/dists/{package.name}__armeabi-v7a/build/outputs/apk/debug/{package.name}__armeabi-v7a-debug.apk Exp: /media/ken/Data/Kivy/.buildozer/android/platform/build-armeabi-v7a/dists/filechooser__armeabi-v7a/build/outputs/apk/debug/filechooser__armeabi-v7a-debug.apk Place 2 /media/ken/Data/Kivy/.buildozer/android/platform/python-for-android/ Download packages by yourself according to the error code: INFO]: Downloading cython [INFO]: -> running mkdir -p /media/ken/Data/Kivy_env/Kivy2Py3.8.1MD0.104.2.dev0/.buildozer/android/platform/build-armeabi-v7a/packages/cython [INFO]: -> directory context /media/ken/Data/Kivy_env/Kivy2Py3.8.1MD0.104.2.dev0/.buildozer/android/platform/build-armeabi-v7a/packages/cython [INFO]: -> running basename https://github.com/cython/cython/archive/0.29.15.tar.gz [INFO]: -> running rm -f .mark-0.29.15.tar.gz [INFO]: Downloading cython from https://github.com/cython/cython/archive/0.29.15.tar.gz wget -c https://github.com/cython/cython/archive/0.29.15.tar.gzcp 0.29.15.tar.gz .buildozer/android/platform/build-armeabi-v7a/packages/cython/.mark-0.29.15.tar.gz","link":"/2021/05/01/Python/kivy_buildozer/"},{"title":"Kivy: hello world (Cross-platform GUI) for python","text":"Install sudo add-apt-repository ppa:kivy-team/kivy-dailysudo apt-get updatesudo apt-get install python-kivy sudo python3.7 -m pip install --upgrade pip wheel setuptools bcmsudo python3.7 -m pip install docutils pygments sudo python3.7 -m pip install kivy.deps.gstreamer --extra-index-url https://kivy.org/downloads/packages/simple/ Quick Start Kivy - Open source Python library for rapid development of applications that make use of innovative user interfaces, such as multi-touch apps. ## Creat a Hello.kv file in the path you run your scriptvim hello.kv### this is for Hello.kvBoxLayout: Label: text: &quot;Hello&quot; ##!/usr/bin/python3.6from kivy.app import Appclass HelloApp(App): passif __name__ == '__main__': HelloApp().run() You need to name the kv file as hello.kv. This file is target by the function HelloApp in main.py automatically. Text layout ## hello.kv fileBoxLayout: Label: text: &quot;Hello&quot; Label: text: &quot;Beautiful&quot; Label: text: &quot;World&quot; Button Layout ## hello.kv fileAddLocationForm:&lt;AddLocationForm@BoxLayout&gt;: orientation: &quot;vertical&quot; BoxLayout: TextInput: Button: text: &quot;Search&quot; size_hint_x: 1 size_hint_y: 0.3 Button: text: &quot;Current Location&quot; size_hint_x: 0.5 AddLocationForm:&lt;AddLocationForm@BoxLayout&gt;: orientation: &quot;vertical&quot; BoxLayout: height: &quot;40dp&quot; size_hint_y: None TextInput: size_hint_x: 50 Button: text: &quot;Search&quot; size_hint_x: 25 Button: text: &quot;Current Location&quot; size_hint_x: 25 BoxLayout: Label: text: &quot;Palo Alto, MX\\nPalo Alto, US&quot; Events Responding to Input In this section, We’d like to acquire the input information from the input box.For respond the Input message, two things we need to done: Assign an ID for TextInput line 5: Acquiring Input. line 10: Assign the ID “search_box” to TextInput Box line 15: active function search_location() Assign an function for responding the text line 5: import the function line 11-12: assigning the function to acquire and respond the massage from TextInput Weather.kv: AddLocationForm:&lt;AddLocationForm@BoxLayout&gt;: orientation: &quot;vertical&quot; search_input: search_box # Change one BoxLayout: height: &quot;40dp&quot; size_hint_y: None TextInput: id: search_box # Assign an ID size_hint_x: 50 Button: text: &quot;Search&quot; size_hint_x: 25 on_press: root.search_location() Button: text: &quot;Current Location&quot; size_hint_x: 25 BoxLayout: Label: text: &quot;Palo Alto, MX\\nPalo Alto, US&quot; main.py: ##!/usr/local/bin/python3.7from kivy.app import Appfrom kivy.uix.boxlayout import BoxLayoutfrom kivy.properties import ObjectPropertyclass AddLocationForm(BoxLayout): search_input = ObjectProperty() def search_location(self): print(&quot;The user searched for '{}'&quot;.format(self.search_input.text))####class WeatherApp(App): passif __name__ == '__main__': WeatherApp().run() Image left: GUI Layout; Image right: result was printed in terminal after clicked the button search. In the current version Kivy1.11.1,The function ListView is not is not supported. Use Recycle As instead. Take this as example:from: https://stackoverflow.com/questions/56601384/kivy-unknown-class-listview-error-code main.py Light Weather App from kivy.app import Appfrom kivy.uix.boxlayout import BoxLayoutfrom kivy.uix.recycleview.views import RecycleDataViewBehaviorfrom kivy.uix.label import Labelfrom kivy.properties import BooleanProperty, ObjectPropertyfrom kivy.uix.recycleboxlayout import RecycleBoxLayoutfrom kivy.uix.behaviors import FocusBehaviorfrom kivy.uix.recycleview.layout import LayoutSelectionBehaviorfrom kivy.network.urlrequest import UrlRequestfrom kivy.lang import Builderimport jsonclass SelectableRecycleBoxLayout(FocusBehavior, LayoutSelectionBehavior, RecycleBoxLayout): ''' Adds selection and focus behaviour to the view. '''class SelectableLabel(RecycleDataViewBehavior, Label): ''' Add selection support to the Label ''' index = None selected = BooleanProperty(False) selectable = BooleanProperty(True) def refresh_view_attrs(self, rv, index, data): ''' Catch and handle the view changes ''' self.index = index return super(SelectableLabel, self).refresh_view_attrs( rv, index, data) def on_touch_down(self, touch): ''' Add selection on touch down ''' if super(SelectableLabel, self).on_touch_down(touch): return True if self.collide_point(*touch.pos) and self.selectable: return self.parent.select_with_touch(self.index, touch) def apply_selection(self, rv, index, is_selected): ''' Respond to the selection of items in the view. ''' self.selected = is_selectedclass AddLocationForm(BoxLayout): search_input = ObjectProperty() search_results = ObjectProperty() def search_location(self): search_template = &quot;https://samples.openweathermap.org/data/2.5/find?q={}&amp;appid=b6907d289e10d714a6e88b30761fae22&quot; # search_template = &quot;https://api.openweathermap.org/data/2.5/find?q={}&amp;typle=like&amp;appid=xyz&quot; # Replace 'xyz' with your API Key (APPID) search_url = search_template.format(self.search_input.text) request = UrlRequest(search_url, self.found_location) def found_location(self, request, data): data = json.loads(data.decode()) if not isinstance(data, dict) else data cities = [&quot;{} ({})&quot;.format(d['name'], d['sys']['country']) for d in data['list']] self.search_results.data = [{'text': str(x)} for x in cities] print(f&quot;self.search_results.data={self.search_results.data}&quot;)class WeatherRoot(BoxLayout): passclass TestApp(App): title = &quot;Weather App&quot; def build(self): return Builder.load_file(&quot;main.kv&quot;)if __name__ == '__main__': TestApp().run() mian.kv WeatherRoot:&lt;WeatherRoot&gt;: AddLocationForm:&lt;SelectableLabel&gt;: # Draw a background to indicate selection canvas.before: Color: rgba: (1, 0, 0, 1) if self.selected else (.0, 0.9, .1, .3) Rectangle: pos: self.pos size: self.size Color: rgba: (0, 0.9, .1, .3) Rectangle: pos: self.pos size: self.size&lt;AddLocationForm&gt;: orientation: &quot;vertical&quot; search_input: search_input search_results: search_results_list BoxLayout: height: &quot;40dp&quot; size_hint_y:None TextInput: id: search_input size_hint_x: 50 focus: True multiline: False hint_text: 'Your city name' on_text_validate: root.search_location() Button: text: &quot;Search&quot; size_hint_x: 25 on_press: root.search_location() Button: text: &quot;Current Location&quot; size_hint_x: 25 RecycleView: id: search_results_list viewclass: 'SelectableLabel' SelectableRecycleBoxLayout: default_size: None, dp(26) default_size_hint: 1, None size_hint_y: None height: self.minimum_height orientation: 'vertical' multiselect: True touch_multiselect: True Examples UrlRequest Origin from:coder.work from kivy.app import App##kivy.require(&quot;1.9.1&quot;)from kivy.uix.boxlayout import BoxLayoutfrom kivy.properties import ObjectPropertyfrom kivy.network.urlrequest import UrlRequestclass MyWidget(BoxLayout): def __init__(self,**kwargs): super(MyWidget,self).__init__(**kwargs) search_url = &quot;http://api.openweathermap.org/data/2.5/forecast/daily?APPID=ef4f6b76310abad083b96a45a6f547be&amp;q=new%20york&quot; print search_url self.request = UrlRequest(search_url, self.res) print self.request print &quot;Result: before success&quot;, self.request.result,&quot;\\n&quot; def res(self,*args): print &quot;Result: after success&quot;, self.request.resultclass MyApp(App): def build(self): return MyWidget()if __name__ == '__main__': MyApp().run() Some Awesome Blogs Build a Mobile Application With the Kivy Python Framework Mike Driscoll Nov 04, 2019 Official Gallery","link":"/2020/12/16/Python/kivy_Cross-platform-App/"},{"title":"Kivy: import android Onlu on android","text":"You may see error code below when you try to import android in your PC. Traceback (most recent call last): File \"main.py\", line 5, in from android.permissions import request_permissions, Permission ModuleNotFoundError: No module named 'android' For solving this, you can import platform like below: from kivy.utils import platformif platform == &quot;android&quot;: from android.permissions import request_permissions, Permission request_permissions([Permission.READ_EXTERNAL_STORAGE, Permission.WRITE_EXTERNAL_STORAGE])","link":"/2021/01/01/Python/kivy_platform/"},{"title":"Kivy: Webviewer","text":"Thanks for the help of @-=§复活℃ from QQ group kivy who gave me lots of supports when I want to give it up. Original Document: linuxrootok; 2018; GitHub It failed with error codes: AttributeError : 'Wv' object has no attribute 'f2' Resolution: omdo; 2020; python-for-android/issues/1908 main.py main.pyfrom kivy.app import Appfrom jnius import autoclassfrom kivy.clock import Clockfrom android.runnable import run_on_ui_threadfrom kivy.uix.widget import WidgetWebView = autoclass('android.webkit.WebView')WebViewClient = autoclass('android.webkit.WebViewClient')activity = autoclass('org.kivy.android.PythonActivity').mActivity@run_on_ui_threaddef create_webview(*args): webview = WebView(activity) webview.getSettings().setJavaScriptEnabled(True) wvc = WebViewClient(); webview.setWebViewClient(wvc); activity.setContentView(webview) webview.loadUrl('https://ｗｗｗ.baidu.com')class Wv(Widget): def __init__(self, **kwargs): super().__init__(**kwargs) self.__functionstable__ = {} Clock.schedule_once(create_webview, 0)class ServiceApp(App): def build(self): return Wv()if __name__ == '__main__': ServiceApp().run() buildozer.spec buildozer.spec[app]# (str) Title of your applicationtitle = FileChooser# (str) Package namepackage.name = filechooser# (str) Package domain (needed for android/ios packaging)package.domain = org.sirfanas.filechooser# (str) Source code where the main.py livesource.dir = .# (list) Source files to include (let empty to include all the files)source.include_exts = py,png,jpg,kv,atlas# (list) List of inclusions using pattern matching#source.include_patterns = assets/*,images/*.png# (list) Source files to exclude (let empty to not exclude anything)#source.exclude_exts = spec# (list) List of directory to exclude (let empty to not exclude anything)#source.exclude_dirs = tests, bin# (list) List of exclusions using pattern matching#source.exclude_patterns = license,images/*/*.jpg# (str) Application versioning (method 1)version = 0.5# (str) Application versioning (method 2)# version.regex = __version__ = ['&quot;](.*)['&quot;]# version.filename = %(source.dir)s/main.py# (list) Application requirements# comma separated e.g. requirements = sqlite3,kivyrequirements = kivy, python3==3.7.5, docutils, android# (str) Custom source folders for requirements# Sets custom source for any requirements with recipes# requirements.source.kivy = ../../kivy# (list) Garden requirements# garden_requirements =# (str) Presplash of the application#presplash.filename = %(source.dir)s/data/presplash.png# (str) Icon of the application#icon.filename = %(source.dir)s/data/icon.png# (str) Supported orientation (one of landscape, sensorLandscape, portrait or all)orientation = all# (list) List of service to declare#services = NAME:ENTRYPOINT_TO_PY,NAME2:ENTRYPOINT2_TO_PY## OSX Specific### author = © Copyright Info# change the major version of python used by the apposx.python_version = 3# Kivy version to useosx.kivy_version = 2.0.0## Android specific## (bool) Indicate if the application should be fullscreen or notfullscreen = 0# (string) Presplash background color (for new android toolchain)# Supported formats are: #RRGGBB #AARRGGBB or one of the following names:# red, blue, green, black, white, gray, cyan, magenta, yellow, lightgray,# darkgray, grey, lightgrey, darkgrey, aqua, fuchsia, lime, maroon, navy,# olive, purple, silver, teal.#android.presplash_color = #FFFFFF# (list) Permissionsandroid.permissions = INTERNET,WRITE_EXTERNAL_STORAGE,READ_EXTERNAL_STORAGE# (int) Target Android API, should be as high as possible.android.api = 27# (int) Minimum API your APK will support.android.minapi = 21# (str) Android NDK version to useandroid.ndk = 19b# (int) Android NDK API to use. This is the minimum API your app will support, it should usually match android.minapi.android.ndk_api = 21# (bool) Use --private data storage (True) or --dir public storage (False)#android.private_storage = True# (str) Android NDK directory (if empty, it will be automatically downloaded.)#android.ndk_path =# (str) Android SDK directory (if empty, it will be automatically downloaded.)#android.sdk_path =# (str) ANT directory (if empty, it will be automatically downloaded.)#android.ant_path =# (bool) If True, then skip trying to update the Android sdk# This can be useful to avoid excess Internet downloads or save time# when an update is due and you just want to test/build your packageandroid.skip_update = False# (bool) If True, then automatically accept SDK license# agreements. This is intended for automation only. If set to False,# the default, you will be shown the license when first running# buildozer.android.accept_sdk_license = True# (str) Android entry point, default is ok for Kivy-based app#android.entrypoint = org.renpy.android.PythonActivity# (list) Pattern to whitelist for the whole project#android.whitelist =# (str) Path to a custom whitelist file#android.whitelist_src =# (str) Path to a custom blacklist file#android.blacklist_src =# (list) List of Java .jar files to add to the libs so that pyjnius can access# their classes. Don't add jars that you do not need, since extra jars can slow# down the build process. Allows wildcards matching, for example:# OUYA-ODK/libs/*.jar#android.add_jars = foo.jar,bar.jar,path/to/more/*.jar# (list) List of Java files to add to the android project (can be java or a# directory containing the files)#android.add_src =# (list) Android AAR archives to add (currently works only with sdl2_gradle# bootstrap)#android.add_aars =# (list) Gradle dependencies to add (currently works only with sdl2_gradle# bootstrap)#android.gradle_dependencies =# (list) Java classes to add as activities to the manifest.#android.add_activites = com.example.ExampleActivity# (str) python-for-android branch to use, defaults to master#p4a.branch = master# (str) OUYA Console category. Should be one of GAME or APP# If you leave this blank, OUYA support will not be enabled#android.ouya.category = GAME# (str) Filename of OUYA Console icon. It must be a 732x412 png image.#android.ouya.icon.filename = %(source.dir)s/data/ouya_icon.png# (str) XML file to include as an intent filters in &lt;activity&gt; tag#android.manifest.intent_filters =# (str) launchMode to set for the main activity#android.manifest.launch_mode = standard# (list) Android additional libraries to copy into libs/armeabi#android.add_libs_armeabi = libs/android/*.so#android.add_libs_armeabi_v7a = libs/android-v7/*.so#android.add_libs_x86 = libs/android-x86/*.so#android.add_libs_mips = libs/android-mips/*.so# (bool) Indicate whether the screen should stay on# Don't forget to add the WAKE_LOCK permission if you set this to True#android.wakelock = False# (list) Android application meta-data to set (key=value format)#android.meta_data =# (list) Android library project to add (will be added in the# project.properties automatically.)#android.library_references =# (list) Android shared libraries which will be added to AndroidManifest.xml using &lt;uses-library&gt; tag#android.uses_library =# (str) Android logcat filters to use#android.logcat_filters = *:S python:D# (bool) Copy library instead of making a libpymodules.so#android.copy_libs = 1# (str) The Android arch to build for, choices: armeabi-v7a, arm64-v8a, x86, x86_64android.arch = armeabi-v7a## Python for android (p4a) specific## (str) python-for-android git clone directory (if empty, it will be automatically cloned from github)#p4a.source_dir =# (str) The directory in which python-for-android should look for your own build recipes (if any)#p4a.local_recipes =# (str) Filename to the hook for p4a#p4a.hook =# (str) Bootstrap to use for android builds# p4a.bootstrap = sdl2# (int) port number to specify an explicit --port= p4a argument (eg for bootstrap flask)#p4a.port =## iOS specific## (str) Path to a custom kivy-ios folder#ios.kivy_ios_dir = ../kivy-ios# Alternately, specify the URL and branch of a git checkout:ios.kivy_ios_url = https://github.com/kivy/kivy-iosios.kivy_ios_branch = master# Another platform dependency: ios-deploy# Uncomment to use a custom checkout#ios.ios_deploy_dir = ../ios_deploy# Or specify URL and branchios.ios_deploy_url = https://github.com/phonegap/ios-deployios.ios_deploy_branch = 1.7.0# (str) Name of the certificate to use for signing the debug version# Get a list of available identities: buildozer ios list_identities#ios.codesign.debug = &quot;iPhone Developer: &lt;lastname&gt; &lt;firstname&gt; (&lt;hexstring&gt;)&quot;# (str) Name of the certificate to use for signing the release version#ios.codesign.release = %(ios.codesign.debug)s[buildozer]# (int) Log level (0 = error only, 1 = info, 2 = debug (with command output))log_level = 2# (int) Display warning if buildozer is run as root (0 = False, 1 = True)warn_on_root = 1# (str) Path to build artifact storage, absolute or relative to spec filebuild_dir = /media/ken/Data/Kivy/.buildozer/# (str) Path to build output (i.e. .apk, .ipa) storage# bin_dir = ./bin# -----------------------------------------------------------------------------# List as sections## You can define all the &quot;list&quot; as [section:key].# Each line will be considered as a option to the list.# Let's take [app] / source.exclude_patterns.# Instead of doing:##[app]#source.exclude_patterns = license,data/audio/*.wav,data/images/original/*## This can be translated into:##[app:source.exclude_patterns]#license#data/audio/*.wav#data/images/original/*## -----------------------------------------------------------------------------# Profiles## You can extend section / key with a profile# For example, you want to deploy a demo version of your application without# HD content. You could first change the title to add &quot;(demo)&quot; in the name# and extend the excluded directories to remove the HD content.##[app@demo]#title = My Application (demo)##[app:source.exclude_patterns@demo]#images/hd/*## Then, invoke the command line with the &quot;demo&quot; profile:##buildozer --profile demo android debug","link":"/2021/04/30/Python/kivy_android_webviewer/"},{"title":"Kivy: debug, understand adblog| adb log","text":"Adblog cat A standard adblog catout is adb logcat. But I do not suggest you do this since there is too much unrelated information If you have are familiar with adb, you may add a filter-args like adb logcat *:W. But this is not the case for Kivy because most of the information is in *:I level. As a result, pipeline adblog with grep is the best choice which could solve most of your problem. Here is my advice: # it could cover 99% casesadb logcat| grep -i python# it could help you access a more elegant result which cover the most of errors.adb logcat| grep -w &quot;I python&quot; adb logcat| grep -i python could access all information containing python. grep -w &quot;I python&quot; should more focus on the running log of python-android. Python for Android Ended This piece of information always one line a heading before the code Python for android ended. So, you can find it very easily with: adb logcat| grep -B 1 -w &quot;Python for android ended&quot; ModuleNotFoundError 04-27 23:19:06.229 25804 25854 I python : [INFO ] [Logger ] Record log in /data/user/0/org.sirfanas.filechooser.filechooser/files/app/.kivy/logs/kivy_21-04-27_3.txt 04-27 23:19:06.229 25804 25854 I python : [INFO ] [Kivy ] v1.11.1 04-27 23:19:06.229 25804 25854 I python : [INFO ] [Kivy ] Installed at \"/data/user/0/org.sirfanas.filechooser.filechooser/files/app/_python_bundle/site-packages/kivy/__init__.pyc\" 04-27 23:19:06.229 25804 25854 I python : [INFO ] [Python ] v3.7.5 (default, Apr 21 2021, 11:10:26) 04-27 23:19:06.229 25804 25854 I python : [Clang 8.0.2 (https://android.googlesource.com/toolchain/clang 40173bab62ec7462 04-27 23:19:06.229 25804 25854 I python : [INFO ] [Python ] Interpreter at \"android_python\" 04-27 23:19:06.287 2208 2469 I WindowManager: Removing Window{8e822e1 u0 Splash Screen org.sirfanas.filechooser.filechooser} from AppWindowToken{8ef4121 token=Token{7fb7980 ActivityRecord{8ef4191 u0 org.sirfanas.filechooser.filechooser/org.kivy.android.PythonActivity t13316}}} 04-27 23:19:06.390 2208 4223 I WindowManager: Animation done in AppWindowToken{8ef4121 token=Token{7fb7980 ActivityRecord{8ef4191 u0 org.sirfanas.filechooser.filechooser/org.kivy.android.PythonActivity t13316}}} isHidden:false hiddenRequested:false 04-27 23:19:06.587 25804 25854 I python : [INFO ] [Factory ] 184 symbols loaded 04-27 23:19:06.730 25804 25854 I python : [INFO ] [Image ] Providers: img_tex, img_dds, img_sdl2, img_pil, img_gif (img_ffpyplayer ignored) 04-27 23:19:06.745 25804 25854 I python : [INFO ] [Text ] Provider: sdl2 04-27 23:19:06.761 25804 25854 I python : [INFO ] [Window ] Provider: sdl2 04-27 23:19:06.776 25804 25854 I python : [INFO ] [GL ] Using the \"OpenGL ES 2\" graphics system 04-27 23:19:06.777 25804 25854 I python : [INFO ] [GL ] Backend used 04-27 23:19:06.777 25804 25854 I python : [INFO ] [GL ] OpenGL version 04-27 23:19:06.777 25804 25854 I python : [INFO ] [GL ] OpenGL vendor 04-27 23:19:06.777 25804 25854 I python : [INFO ] [GL ] OpenGL renderer 04-27 23:19:06.777 25804 25854 I python : [INFO ] [GL ] OpenGL parsed version: 3, 2 04-27 23:19:06.777 25804 25854 I python : [INFO ] [GL ] Texture max size 04-27 23:19:06.777 25804 25854 I python : [INFO ] [GL ] Texture max units 04-27 23:19:06.780 2208 4460 I DebugKeepScreenOn: Acquiring screen wakelock due to Window{888d929 u0 org.sirfanas.filechooser.filechooser/org.kivy.android.PythonActivity} 04-27 23:19:06.787 25804 25854 I python : [INFO ] [Window ] auto add sdl2 input provider 04-27 23:19:06.788 25804 25854 I python : [INFO ] [Window ] virtual keyboard not allowed, single mode, not docked 04-27 23:19:06.848 25804 25854 I python : [INFO ] [Video ] Provider: null(['video_ffmpeg', 'video_ffpyplayer'] ignored) 04-27 23:19:06.849 25804 25854 I python : Traceback (most recent call last): 04-27 23:19:06.849 25804 25854 I python : File \"/media/ken/Data/Kivy/.buildozer/android/app/main.py\", line 64, in 04-27 23:19:06.849 25804 25854 I python : File \"/media/ken/Data/Kivy/.buildozer/android/platform/build-armeabi-v7a/build/python-installs/filechooser/kivy/app.py\", line 828, in run 04-27 23:19:06.849 25804 25854 I python : File \"/media/ken/Data/Kivy/.buildozer/android/platform/build-armeabi-v7a/build/python-installs/filechooser/kivy/app.py\", line 599, in load_kv 04-27 23:19:06.849 25804 25854 I python : File \"/media/ken/Data/Kivy/.buildozer/android/platform/build-armeabi-v7a/build/python-installs/filechooser/kivy/lang/builder.py\", line 301, in load_file 04-27 23:19:06.849 25804 25854 I python : File \"/media/ken/Data/Kivy/.buildozer/android/platform/build-armeabi-v7a/build/python-installs/filechooser/kivy/lang/builder.py\", line 405, in load_string 04-27 23:19:06.850 25804 25854 I python : File \"/media/ken/Data/Kivy/.buildozer/android/platform/build-armeabi-v7a/build/python-installs/filechooser/kivy/lang/builder.py\", line 659, in _apply_rule 04-27 23:19:06.850 25804 25854 I python : File \"/media/ken/Data/Kivy/.buildozer/android/platform/build-armeabi-v7a/build/python-installs/filechooser/kivy/lang/builder.py\", line 659, in _apply_rule 04-27 23:19:06.850 25804 25854 I python : File \"/media/ken/Data/Kivy/.buildozer/android/platform/build-armeabi-v7a/build/python-installs/filechooser/kivy/lang/builder.py\", line 616, in _apply_rule 04-27 23:19:06.850 25804 25854 I python : File \"/media/ken/Data/Kivy/.buildozer/android/platform/build-armeabi-v7a/build/python-installs/filechooser/kivy/factory.py\", line 142, in __getattr__ 04-27 23:19:06.850 25804 25854 I python : File \"/media/ken/Data/Kivy/.buildozer/android/platform/build-armeabi-v7a/build/python-installs/filechooser/kivy/uix/rst.py\", line 81, in 04-27 23:19:06.850 25804 25854 I python : ModuleNotFoundError: No module named 'docutils' 04-27 23:19:06.850 25804 25854 I python : Python for android ended. 04-27 23:19:06.943 2208 2664 W InputDispatcher: channel '888d929 org.sirfanas.filechooser.filechooser/org.kivy.android.PythonActivity (server)' ~ Consumer closed input channel or an error occurred. events=0x9 04-27 23:19:06.943 2208 2664 E InputDispatcher: channel '888d929 org.sirfanas.filechooser.filechooser/org.kivy.android.PythonActivity (server)' ~ Channel is unrecoverably broken and will be disposed! What you want to know is this: ModuleNotFoundError: No module named 'docutils' As it’s who below, we can get the info by: AttributeError 04-30 16:22:14.236 6326 6417 I python : [INFO ] [Base ] Start application main loop 04-30 16:22:14.236 6326 6417 I python : [INFO ] [Base ] Leaving application in progress... 04-30 16:22:14.237 6326 6417 I python : Traceback (most recent call last): 04-30 16:22:14.237 6326 6417 I python : File \"/media/ken/Data/Kivy/.buildozer/android/app/main.py\", line 111, in 04-30 16:22:14.237 6326 6417 I python : File \"/media/ken/Data/Kivy/.buildozer/android/platform/build-armeabi-v7a/build/python-installs/filechooser/kivy/app.py\", line 855, in run 04-30 16:22:14.237 6326 6417 I python : File \"/media/ken/Data/Kivy/.buildozer/android/platform/build-armeabi-v7a/build/python-installs/filechooser/kivy/base.py\", line 504, in runTouchApp 04-30 16:22:14.237 6326 6417 I python : File \"/media/ken/Data/Kivy/.buildozer/android/platform/build-armeabi-v7a/build/python-installs/filechooser/kivy/core/window/window_sdl2.py\", line 747, in mainloop 04-30 16:22:14.237 6326 6417 I python : File \"/media/ken/Data/Kivy/.buildozer/android/platform/build-armeabi-v7a/build/python-installs/filechooser/kivy/core/window/window_sdl2.py\", line 479, in _mainloop 04-30 16:22:14.237 6326 6417 I python : File \"/media/ken/Data/Kivy/.buildozer/android/platform/build-armeabi-v7a/build/python-installs/filechooser/kivy/base.py\", line 339, in idle 04-30 16:22:14.238 6326 6417 I python : File \"/media/ken/Data/Kivy/.buildozer/android/platform/build-armeabi-v7a/build/python-installs/filechooser/kivy/clock.py\", line 591, in tick 04-30 16:22:14.238 6326 6417 I python : File \"kivy/_clock.pyx\", line 384, in kivy._clock.CyClockBase._process_events 04-30 16:22:14.238 6326 6417 I python : File \"kivy/_clock.pyx\", line 414, in kivy._clock.CyClockBase._process_events 04-30 16:22:14.238 6326 6417 I python : File \"kivy/_clock.pyx\", line 412, in kivy._clock.CyClockBase._process_events 04-30 16:22:14.238 6326 6417 I python : File \"kivy/_clock.pyx\", line 154, in kivy._clock.ClockEvent.tick 04-30 16:22:14.238 6326 6417 I python : File \"kivy/_clock.pyx\", line 88, in kivy._clock.ClockEvent.get_callback 04-30 16:22:14.239 6326 6417 I python : File \"/media/ken/Data/Kivy/.buildozer/android/platform/build-armeabi-v7a/build/python-installs/filechooser/kivy/weakmethod.py\", line 47, in __call__ 04-30 16:22:14.239 6326 6417 I python : AttributeError: 'WebviewLauncher' object has no attribute 'f2' 04-30 16:22:14.239 6326 6417 I python : Python for android ended. Check the class WebviewLauncher and figure out what is f2 in it. Buildozer Error Non-user install due to --prefix or --target option Created temporary directory: /tmp/pip-target-nnpo4wye Created temporary directory: /tmp/pip-ephem-wheel-cache-hjzhdyqg Created temporary directory: /tmp/pip-req-tracker-nryx6lee Initialized build tracking at /tmp/pip-req-tracker-nryx6lee Created build tracker: /tmp/pip-req-tracker-nryx6lee Entered build tracker: /tmp/pip-req-tracker-nryx6lee Created temporary directory: /tmp/pip-install-xivbs0bw Collecting https://github.com/kivymd/kivymd/archive/master.zip (from -r requirements.txt (line 1)) Created temporary directory: /tmp/pip-req-build-6lx7kxss Created temporary directory: /tmp/pip-unpack-cr7m7azt Looking up \"https://github.com/kivymd/kivymd/archive/master.zip\" in the cache No cache entry available Starting new HTTPS connection (1): github.com:443 Incremented Retry for (url='/kivymd/kivymd/archive/master.zip'): Retry(total=4, connect=None, read=None, redirect=None, status=None) WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='github.com', port=443): Read timed out. (read timeout=15)\")': /kivymd/kivymd/archive/master.zip Starting new HTTPS connection (2): github.com:443 Incremented Retry for (url='/kivymd/kivymd/archive/master.zip'): Retry(total=3, connect=None, read=None, redirect=None, status=None) WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(, 'Connection to github.com timed out. (connect timeout=15)')': /kivymd/kivymd/archive/master.zip Starting new HTTPS connection (3): github.com:443 Incremented Retry for (url='/kivymd/kivymd/archive/master.zip'): Retry(total=2, connect=None, read=None, redirect=None, status=None) WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(, 'Connection to github.com timed out. (connect timeout=15)')': /kivymd/kivymd/archive/master.zip Starting new HTTPS connection (4): github.com:443 Incremented Retry for (url='/kivymd/kivymd/archive/master.zip'): Retry(total=1, connect=None, read=None, redirect=None, status=None) WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /kivymd/kivymd/archive/master.zip Starting new HTTPS connection (5): github.com:443 Incremented Retry for (url='/kivymd/kivymd/archive/master.zip'): Retry(total=0, connect=None, read=None, redirect=None, status=None) WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(, 'Connection to github.com timed out. (connect timeout=15)')': /kivymd/kivymd/archive/master.zip Starting new HTTPS connection (6): github.com:443 ERROR: Could not install packages due to an OSError. Traceback (most recent call last): File \"/media/ken/Data/Kivy_env/Kivy2Py3.8.1MD0.104.2.dev0/.buildozer/android/platform/build-armeabi-v7a/build/venv/lib/python3.8/site-packages/pip/_vendor/urllib3/connection.py\", line 169, in _new_conn conn = connection.create_connection( File \"/media/ken/Data/Kivy_env/Kivy2Py3.8.1MD0.104.2.dev0/.buildozer/android/platform/build-armeabi-v7a/build/venv/lib/python3.8/site-packages/pip/_vendor/urllib3/util/connection.py\", line 96, in create_connection raise err File \"/media/ken/Data/Kivy_env/Kivy2Py3.8.1MD0.104.2.dev0/.buildozer/android/platform/build-armeabi-v7a/build/venv/lib/python3.8/site-packages/pip/_vendor/urllib3/util/connection.py\", line 86, in create_connection sock.connect(sa) socket.timeout: timed out During handling of the above exception, another exception occurred: Key error: Starting new HTTPS connection (5): github.com:443 Reason: Github didn’t response. Resolution: Try builder again or connect your terminal to VPN. Errors requests Found by adb logcat| grep -i python Resolution: buildozer.specrequirements = openssl, requests, Urllib3, chardet, certifi, idna 05-09 19:24:20.139 23571 23629 I python : File \"kivy/_event.pyx\", line 709, in kivy._event.EventDispatcher.dispatch 05-09 19:24:20.140 23571 23629 I python : File \"/media/ken/Data/Kivy_env/Kivy2Py3.8.1MD0.104.2.dev0/.buildozer/android/app/libWidget/Seq.py\", line 25, in align 05-09 19:24:20.141 23571 23629 I python : File \"/media/ken/Data/Kivy_env/Kivy2Py3.8.1MD0.104.2.dev0/.buildozer/android/app/bin/clustalo.py\", line 35, in 05-09 19:24:20.141 23571 23629 I python : ModuleNotFoundError: No module named 'requests' 05-09 19:24:20.141 23571 23629 I python : Python for android ended. def fasta_read(FA):fasta = {}with open(&quot;clusttmp/result.aln-fasta.fasta&quot;) as file_one: for line in file_one: line = line.strip() if not line: continue if line.startswith(&quot;&gt;&quot;): print(line) active_sequence_name = line[1:] if active_sequence_name not in fasta: fasta[active_sequence_name] = [] continue sequence = line fasta[active_sequence_name].append(sequence)print(fasta) return fastafrom collections import defaultdict #this will make your life simplerf = open(&quot;clusttmp/result.aln-fasta.fasta&quot;,'r')list=defaultdict(str)name = ''for line in f: #if your line starts with a &gt; then it is the name of the following sequence if line.startswith('&gt;'): name = line[1:-1] continue #this means skips to the next line #This code is only executed if it is a sequence of bases and not a name. list[name]+=line.strip()d = {}with open(&quot;clusttmp/result.aln-fasta.fasta&quot;) as f: for line in f: if len(line) &gt; 1: if '%Labelinf' in line: key = line.strip() d[key] = &quot;&quot; else: d[key] += line.strip() + &quot;+&quot;d = {key: d[key][:-1] for key in d}print d","link":"/2021/04/30/Python/kivy_adblog/"},{"title":"Kivy tip and tricks","text":"keyboard You can prohibit pop up of the keyboard with codes below. @黑猫 keyboard_mode='managed'","link":"/2021/01/01/Python/kivy_tips/"},{"title":"kivy ScrollView","text":"Official Document However, examples from the official document have shown the basics of this widget. But for newbies, it is easy to write an unworking widget due to a lack of understanding of it. Quick Start from kivy.uix.gridlayout import GridLayoutfrom kivy.uix.button import Buttonfrom kivy.uix.scrollview import ScrollViewfrom kivy.core.window import Windowfrom kivy.app import runTouchApplayout = GridLayout(cols=1, spacing=10, size_hint_y=None)## Make sure the height is such that there is something to scroll.layout.bind(minimum_height=layout.setter('height'))for i in range(100): btn = Button(text=str(i), size_hint_y=None, height=40) layout.add_widget(btn)root = ScrollView(size_hint=(1, None), size=(Window.width, Window.height))root.add_widget(layout)runTouchApp(root) Why Am I failed to scroll my widget The problem is that after you settled everything in your kv file, the sub-widget has the same size as the ScrollView widget by default. So, to have a functional scrolling behavior, you’d like to make sure the sub-widget is larger than the ScrollView widget. Let’s go back to the example from the document: ScrollView: do_scroll_x: False do_scroll_y: True Label: size_hint_y: None height: self.texture_size[1] text_size: self.width, None padding: 10, 10 text: 'really some amazing text\\n' * 100 In this kv file, two lines are important to redefine the height of this sub-widget. size_hint_y: Noneheight: self.texture_size[1] The problem is self.texture_size[1] is for text only. You’d like to replace it with an int, 1000, for example. But of course, there is a better resolution from @amd, 2015 height: self.minimum_height An example could show as: ScrollView: size: 300, 20 do_scroll_x: False do_scroll_y: True BoxLayout: size_hint_y: None height: self.minimum_height padding: 10, 10 MyButton: text: 'hit me 1' MyButton: text: 'hit me 2' MyButton: text: 'hit me 3' MyButton: text: 'hit me 4' MyButton: text: 'hit me 5' MyButton: text: 'hit me 6' Case closed!!!","link":"/2021/02/10/Python/kivy_scrollview/"},{"title":"librosa for sound track| Python","text":"python Cite: 叁公子KCN; 2019 import librosaimport matplotlib.pyplot as pltimport librosa.displayFile = &quot;input.mkv&quot;x , sr = librosa.load(File, sr=8000)plt.figure(figsize=(14, 5))librosa.display.waveplot(x[:10000], sr=sr)plt.show() ffmpeg Cite: dennyyoung # Video splitffmpeg -y -ss 0 -t 3 -i Function.mkv -c:v libx264 -c:a copy 123.mkv# Video mergeffmpeg -y -i filename -i filename2 -vcode copy -acodec copy","link":"/2021/09/18/Python/librosa/"},{"title":"Python: lsm image to tif image","text":"import tifffile, cv2, osList_dir = &quot;lsm/&quot;out_dir = &quot;out/&quot;LSM_list = [i for i in os.listdir(List_dir) if &quot;.lsm&quot; in i]LSM_list[0]for i in LSM_list: A = tifffile.imread(List_dir + i) #fig, ax = plt.subplots(figsize=(10, 10)) for ch_id in range(A.shape[1]): Pic = A[:,ch_id,:,:] tifffile.imsave(out_dir + i+str(ch_id)+&quot;.tif&quot;, Pic)","link":"/2021/09/18/Python/lsm2tif/"},{"title":"Multiprocessing","text":"Multiprocessing Quick Start import multiprocessing as mpfrom time import sleepdef echo(i): '''Working Function for cycle''' sleep(i) print(i)def multicore(Pool=10): pool = mp.Pool(processes=Pool) for i in range(10): # Working function &quot;echo&quot; and the arg 'i' multi_res = [pool.apply_async(echo,(i,))] pool.close() pool.join()if __name__ == '__main__': multicore() With Return Cite: StackoverFlow import multiprocessing as mpdef worker(procnum, return_dict): '''worker function''' print (str(procnum) + ' represent!') return_dict[procnum] = procnumif __name__ == '__main__': manager = mp.Manager() return_dict = manager.dict() jobs = [] for i in range(5): p = mp.Process(target=worker, args=(i,return_dict)) jobs.append(p) p.start() for proc in jobs: proc.join() print (return_dict.values())for i in return_dict.values(): print(i) why pool.join() is taking a long time If pool.join() takes a long time, it typically indicates that there are still ongoing tasks in the pool. The duration is largely determined by the longest task in the pool. Issues such as inter-process communication, waiting for shared resources, and insufficient CPU cores can also cause slowdowns. startmap() Generally, startmap could work faster than map. import multiprocessing as mpdef calculate_overlap(i, Ther): row = TB_NST_FP.iloc[i] TB_TMP = TB_NST[TB_NST.Frame == row['Frame']] over_N = TB_TMP.apply(lambda x: overlap_area(row, x, Ther), axis=1).sum() return (i, over_N)# Assuming you have a list/array of i and Ther valuesi_values = range(len(TB_NST_FP)) # Replace this with your actual i valuesTher_values = [0.5] * len(TB_NST_FP) # Replace this with your actual Ther values# Pair up i_values and Ther_valuesargs = list(zip(i_values, Ther_values))# Create a Pool of subprocesseswith mp.Pool() as p: results = p.starmap(calculate_overlap, args) In this code, it only consume 6.3s. def calculate_overlap(args): i, Ther = args row = TB_NST_FP.iloc[i] TB_TMP = TB_NST[TB_NST.Frame == row['Frame']] over_N = TB_TMP.apply(lambda x: overlap_area(row, x, Ther), axis=1).sum() return (i, over_N)# Create a pool of processesTher = 0.5with Pool(cpu_count()) as p: # Map calculate_overlap function to each index in TB_NST_FP results = p.map(calculate_overlap, [(i, Ther) for i in range(len(TB_NST_FP))])# Filter results to only include indices where over_N &lt; 1FP_lst = [i for i in results if i[1] &lt; 1] In this code, it cost 8.9s Real Time Processes Bar Source: pip install parallelbar from parallelbar import progress_imap, progress_map, progress_imapuif __name__=='__main__': res = progress_map(foo, range(20), process_timeout=1.5, n_cpu=8)","link":"/2020/09/12/Python/multyprocesser/"},{"title":"npyscreen | An python TUI lib for development","text":"npyscreen 开发terminal平台软件Developing terminal platform apps 1 Quick Start ##!/usr/bin/env python3.7## encoding: utf-8import npyscreenclass TestApp(npyscreen.NPSApp): def main(self): # These lines create the form and populate it with widgets. # A fairly complex screen in only 8 or so lines of code - a line for each control. F = npyscreen.Form(name = &quot;Welcome to Npyscreen&quot;,) t = F.add(npyscreen.TitleText, name = &quot;Text:&quot;,) fn = F.add(npyscreen.TitleFilename, name = &quot;Filename:&quot;) fn2 = F.add(npyscreen.TitleFilenameCombo, name=&quot;Filename2:&quot;) dt = F.add(npyscreen.TitleDateCombo, name = &quot;Date:&quot;) s = F.add(npyscreen.TitleSlider, out_of=12, name = &quot;Slider&quot;) ml = F.add(npyscreen.MultiLineEdit, value = &quot;&quot;&quot;try typing here!\\nMutiline text, press ^R to reformat.\\n&quot;&quot;&quot;, max_height=5, rely=9) ms = F.add(npyscreen.TitleSelectOne, max_height=4, value = [1,], name=&quot;Pick One&quot;, values = [&quot;Option1&quot;,&quot;Option2&quot;,&quot;Option3&quot;], scroll_exit=True) ms2= F.add(npyscreen.TitleMultiSelect, max_height =-2, value = [1,], name=&quot;Pick Several&quot;, values = [&quot;Option1&quot;,&quot;Option2&quot;,&quot;Option3&quot;], scroll_exit=True) # This lets the user interact with the Form. F.edit() print(ms.get_selected_objects())if __name__ == &quot;__main__&quot;: App = TestApp() App.run() 效果： Features Input Path segestion Path1: Tab 键激活 Path2: Date Progress bar Selection ptop is npyscreen apps","link":"/2020/09/12/Python/npyscreen/"},{"title":"path find in a network plot","text":"path find in a network plot Here’s an example code for a more complicated network graph using NetworkX and finding a path from one node to another node: import networkx as nximport matplotlib.pyplot as plt# Create a graphG = nx.DiGraph()# Add nodesG.add_nodes_from(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'])# Add edgesG.add_edges_from([('A', 'B'), ('B', 'C'), ('B', 'D'), ('C', 'E'), ('D', 'E'), ('D', 'F'), ('E', 'G'), ('F', 'G'), ('G', 'H')])# Plot the graphpos = nx.spring_layout(G, seed=123)nx.draw_networkx(G, pos, with_labels=True)edge_labels = nx.get_edge_attributes(G, 'weight')nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)plt.show()# Find a path from node 'A' to node 'H'path = nx.shortest_path(G, 'A', 'H')print(path)# highlight the pathedge_colors = ['red' if (u, v) in zip(path, path[1:]) else 'black' for u, v in G.edges()]nx.draw(G, pos, with_labels=True, edge_color=edge_colors)plt.show() ['A', 'B', 'C', 'E', 'G', 'H'] In this code, we create a directed graph G using nx.DiGraph(). We add nodes to the graph using G.add_nodes_from(), and add edges to the graph using G.add_edges_from(). We can assign a weight to each edge using a dictionary, but in this example we don’t do that. We then use the nx.spring_layout() function to generate node positions for the graph. This function positions nodes using the Fruchterman-Reingold force-directed algorithm. In this example, we set the random seed to 123 using the seed parameter of nx.spring_layout(). This ensures that the initial conditions of the spring layout algorithm are the same each time you run the code, and the layout of the graph remains the same. We then use nx.draw_networkx() to draw nodes and edges of the graph with labels. We also use nx.get_edge_attributes() and nx.draw_networkx_edge_labels() to add labels to the edges of the graph. Finally, we use plt.show() to display the plot. After displaying the graph, we use nx.shortest_path() to find the shortest path from node ‘A’ to node ‘H’. The function returns a list of nodes that form the path. We print the path to the console. Note that you can modify the graph and the path-finding algorithms according to your specific needs using the functions available in the NetworkX library. How does nx.shortest_path works The nx.shortest_path() function in NetworkX is used to find the shortest path between two nodes in a graph. It uses the Dijkstra’s algorithm, which is an algorithm for finding the shortest paths between nodes in a graph. The nx.shortest_path() function takes three parameters: G: the graph to search for shortest path in. source: the starting node for the path. target: the ending node for the path. The function returns a list of nodes in the shortest path from the source node to the target node. what is Dijkstra’s algorithm Dijkstra’s algorithm is a graph search algorithm that works by finding the shortest path from a starting node to all other nodes in the graph. The algorithm maintains a set of visited nodes and a set of unvisited nodes, with the distance from the starting node to each unvisited node initialized to infinity. At each step, the algorithm selects the unvisited node with the smallest distance from the starting node and adds it to the visited set. It then updates the distances of all adjacent nodes that are still in the unvisited set, setting their distance to the sum of the distance to the current node and the weight of the edge between them. The algorithm continues until the target node is reached, or until all nodes have been visited. Once the shortest path has been found, nx.shortest_path() returns a list of nodes in the path, in the order that they appear in the path. What is “bellman-ford”? Bellman-Ford is an algorithm for finding the shortest paths between nodes in a weighted graph. The algorithm can handle negative edge weights, whereas Dijkstra’s algorithm, which we discussed in a previous question, cannot. However, Bellman-Ford is slower than Dijkstra’s algorithm and has a higher time complexity of O(V*E), where V is the number of vertices and E is the number of edges in the graph. The Bellman-Ford algorithm works by relaxing all edges in the graph V-1 times, where V is the number of vertices in the graph. During each iteration, the algorithm checks if the distance to a node can be improved by going through another node. If so, it updates the distance to the node. The algorithm repeats this process V-1 times to ensure that all possible paths have been explored. After the V-1 iterations, the algorithm performs one more check to see if there are any negative weight cycles in the graph. If there are, then the algorithm cannot find a shortest path because the distance to the node can be decreased indefinitely by traversing the negative cycle. In this case, the algorithm returns a message indicating that a negative cycle has been detected. import networkx as nx# Create a graphG = nx.DiGraph()# Add nodesG.add_nodes_from(['A', 'B', 'C', 'D', 'E'])# Add edges with weightsG.add_weighted_edges_from([('A', 'B', 3), ('A', 'C', 8), ('B', 'C', -4), ('B', 'D', 1), ('B', 'E', 7), ('C', 'D', 2), ('D', 'B', 2), ('E', 'D', -5)])# Find the shortest paths using Bellman-Ford algorithmdistances, predecessors = nx.bellman_ford(G, 'A')# Print the distancesprint(distances)# Print the predecessorsprint(predecessors) In this example, we create a directed graph with five nodes and eight edges, with some edges having negative weights. We then use nx.bellman_ford() to find the shortest paths from the node ‘A’ to all other nodes in the graph. The function returns two dictionaries: one with the shortest distance from the starting node to each node, and another with the predecessor node in the shortest path for each node. We print these dictionaries to the console. pre { background-color:#38393d; color: #5fd381; }","link":"/2023/02/26/Python/net-path/"},{"title":"General Skills for Numpy","text":"np arry to list import numpy as npList = arry.tolist() Create a list print(np.linspace(0, 100, 51)) [ 0. 2. 4. 6. 8. 10. 12. 14. 16. 18. 20. 22. 24. 26. 28. 30. 32. 34. 36. 38. 40. 42. 44. 46. 48. 50. 52. 54. 56. 58. 60. 62. 64. 66. 68. 70. 72. 74. 76. 78. 80. 82. 84. 86. 88. 90. 92. 94. 96. 98. 100.] # np.arrary sum()np.sum(array1-array2)np.mean() append np.append(np1, np2,axis=0) Reduce Dimension x = np.array([[1, 2],[3, 4]])print(np.ravel(x)) print(np.ravel(x,'F')) Locating (argwhere) arr = np.random.randint(0,10, (3,4)) index = np.argwhere(arr &lt; 5)index2 = np.where(arr &lt; 5)# quick way to find the max and min:arr.argmax()arr.argmin() Axis Axis flip / swap frame2 = frame.swapaxes(0,1)frame.shapeframe2.shape (360, 480, 3) (480, 360, 3) Replace arr[arr &gt; 255] = x ummmm... I am not really like to using numpy because I thing data.frame() in R is much better.","link":"/2020/09/12/Python/numpy/"},{"title":"Kivy: FileChooser on Android","text":"Quick Start Because of lacking the knowledge of android, I made very slow progress on running filechooser on android. But thanks the post in GitHub issue, I finally made it. (original codes from Sirfanas) And this is the codes below which could substitude the photos on the background by choosing the photo in your phone. main.py main.pyfrom kivy.app import Appfrom kivy.uix.widget import Widgetfrom kivy.properties import NumericProperty, ReferenceListProperty, ObjectPropertyfrom kivy.vector import Vectorfrom kivy.clock import Clockfrom random import randintfrom kivy.lang import Builderfrom kivy.uix.image import AsyncImagefrom plyer import filechooserfrom kivy.properties import ListPropertyfrom kivy.uix.button import Buttonclass Main(Widget): selection = ListProperty([]) def choose(self): ''' Call plyer filechooser API to run a filechooser Activity. ''' filechooser.open_file(on_selection=self.handle_selection) def handle_selection(self, selection): ''' Callback function for handling the selection response from Activity. ''' self.selection = selection #print(str(selection)) def on_selection(self, *a, **k): ''' Update TextInput.text after FileChoose.selection is changed via FileChoose.handle_selection. ''' self.b_t.ii = self.selection[0] self.box.ii = self.selection[0]class RunApp(App): def build(self): game = Main() return gameif __name__ == '__main__': RunApp().run() run.kv run.kv&lt;Main@BoxLayout&gt;: box: box_img b_t: b_t orientation: &quot; vertical&quot; BoxLayout: id: box_img ii: '1.png' canvas: Rectangle: source: self.ii pos: root.pos size: root.size BoxLayout: width: root.width Button: size_hint_x:1 pos: self.pos text: 'Switch' on_release: root.choose() Label: size_hint_x:9 id: b_t ii: '123' text: self.ii haling: 0 buildozer.spec buildozer.spec[app]# (str) Title of your applicationtitle = FileChooser# (str) Package namepackage.name = filechooser# (str) Package domain (needed for android/ios packaging)package.domain = org.sirfanas.filechooser# (str) Source code where the main.py livesource.dir = .# (list) Source files to include (let empty to include all the files)source.include_exts = py,png,jpg,kv,atlas# (list) List of inclusions using pattern matching#source.include_patterns = assets/*,images/*.png# (list) Source files to exclude (let empty to not exclude anything)#source.exclude_exts = spec# (list) List of directory to exclude (let empty to not exclude anything)#source.exclude_dirs = tests, bin# (list) List of exclusions using pattern matching#source.exclude_patterns = license,images/*/*.jpg# (str) Application versioning (method 1)version = 0.5# (str) Application versioning (method 2)# version.regex = __version__ = ['&quot;](.*)['&quot;]# version.filename = %(source.dir)s/main.py# (list) Application requirements# comma separated e.g. requirements = sqlite3,kivyrequirements = plyer, android, kivy, kivymd, python3==3.7.5, Pillow# (str) Custom source folders for requirements# Sets custom source for any requirements with recipes# requirements.source.kivy = ../../kivy# (list) Garden requirements# garden_requirements =# (str) Presplash of the application#presplash.filename = %(source.dir)s/data/presplash.png# (str) Icon of the application#icon.filename = %(source.dir)s/data/icon.png# (str) Supported orientation (one of landscape, sensorLandscape, portrait or all)orientation = all# (list) List of service to declare#services = NAME:ENTRYPOINT_TO_PY,NAME2:ENTRYPOINT2_TO_PY## OSX Specific### author = © Copyright Info# change the major version of python used by the apposx.python_version = 3# Kivy version to useosx.kivy_version = 1.9.1## Android specific## (bool) Indicate if the application should be fullscreen or notfullscreen = 0# (string) Presplash background color (for new android toolchain)# Supported formats are: #RRGGBB #AARRGGBB or one of the following names:# red, blue, green, black, white, gray, cyan, magenta, yellow, lightgray,# darkgray, grey, lightgrey, darkgrey, aqua, fuchsia, lime, maroon, navy,# olive, purple, silver, teal.#android.presplash_color = #FFFFFF# (list) Permissionsandroid.permissions = INTERNET,WRITE_EXTERNAL_STORAGE,READ_EXTERNAL_STORAGE# (int) Target Android API, should be as high as possible.android.api = 27# (int) Minimum API your APK will support.android.minapi = 21# (str) Android NDK version to useandroid.ndk = 19b# (int) Android NDK API to use. This is the minimum API your app will support, it should usually match android.minapi.android.ndk_api = 21# (bool) Use --private data storage (True) or --dir public storage (False)#android.private_storage = True# (str) Android NDK directory (if empty, it will be automatically downloaded.)#android.ndk_path =# (str) Android SDK directory (if empty, it will be automatically downloaded.)#android.sdk_path =# (str) ANT directory (if empty, it will be automatically downloaded.)#android.ant_path =# (bool) If True, then skip trying to update the Android sdk# This can be useful to avoid excess Internet downloads or save time# when an update is due and you just want to test/build your packageandroid.skip_update = False# (bool) If True, then automatically accept SDK license# agreements. This is intended for automation only. If set to False,# the default, you will be shown the license when first running# buildozer.android.accept_sdk_license = True# (str) Android entry point, default is ok for Kivy-based app#android.entrypoint = org.renpy.android.PythonActivity# (list) Pattern to whitelist for the whole project#android.whitelist =# (str) Path to a custom whitelist file#android.whitelist_src =# (str) Path to a custom blacklist file#android.blacklist_src =# (list) List of Java .jar files to add to the libs so that pyjnius can access# their classes. Don't add jars that you do not need, since extra jars can slow# down the build process. Allows wildcards matching, for example:# OUYA-ODK/libs/*.jar#android.add_jars = foo.jar,bar.jar,path/to/more/*.jar# (list) List of Java files to add to the android project (can be java or a# directory containing the files)#android.add_src =# (list) Android AAR archives to add (currently works only with sdl2_gradle# bootstrap)#android.add_aars =# (list) Gradle dependencies to add (currently works only with sdl2_gradle# bootstrap)#android.gradle_dependencies =# (list) Java classes to add as activities to the manifest.#android.add_activites = com.example.ExampleActivity# (str) python-for-android branch to use, defaults to master#p4a.branch = master# (str) OUYA Console category. Should be one of GAME or APP# If you leave this blank, OUYA support will not be enabled#android.ouya.category = GAME# (str) Filename of OUYA Console icon. It must be a 732x412 png image.#android.ouya.icon.filename = %(source.dir)s/data/ouya_icon.png# (str) XML file to include as an intent filters in &lt;activity&gt; tag#android.manifest.intent_filters =# (str) launchMode to set for the main activity#android.manifest.launch_mode = standard# (list) Android additional libraries to copy into libs/armeabi#android.add_libs_armeabi = libs/android/*.so#android.add_libs_armeabi_v7a = libs/android-v7/*.so#android.add_libs_x86 = libs/android-x86/*.so#android.add_libs_mips = libs/android-mips/*.so# (bool) Indicate whether the screen should stay on# Don't forget to add the WAKE_LOCK permission if you set this to True#android.wakelock = False# (list) Android application meta-data to set (key=value format)#android.meta_data =# (list) Android library project to add (will be added in the# project.properties automatically.)#android.library_references =# (list) Android shared libraries which will be added to AndroidManifest.xml using &lt;uses-library&gt; tag#android.uses_library =# (str) Android logcat filters to use#android.logcat_filters = *:S python:D# (bool) Copy library instead of making a libpymodules.so#android.copy_libs = 1# (str) The Android arch to build for, choices: armeabi-v7a, arm64-v8a, x86, x86_64android.arch = armeabi-v7a## Python for android (p4a) specific## (str) python-for-android git clone directory (if empty, it will be automatically cloned from github)#p4a.source_dir =# (str) The directory in which python-for-android should look for your own build recipes (if any)#p4a.local_recipes =# (str) Filename to the hook for p4a#p4a.hook =# (str) Bootstrap to use for android builds# p4a.bootstrap = sdl2# (int) port number to specify an explicit --port= p4a argument (eg for bootstrap flask)#p4a.port =## iOS specific## (str) Path to a custom kivy-ios folder#ios.kivy_ios_dir = ../kivy-ios# Alternately, specify the URL and branch of a git checkout:ios.kivy_ios_url = https://github.com/kivy/kivy-iosios.kivy_ios_branch = master# Another platform dependency: ios-deploy# Uncomment to use a custom checkout#ios.ios_deploy_dir = ../ios_deploy# Or specify URL and branchios.ios_deploy_url = https://github.com/phonegap/ios-deployios.ios_deploy_branch = 1.7.0# (str) Name of the certificate to use for signing the debug version# Get a list of available identities: buildozer ios list_identities#ios.codesign.debug = &quot;iPhone Developer: &lt;lastname&gt; &lt;firstname&gt; (&lt;hexstring&gt;)&quot;# (str) Name of the certificate to use for signing the release version#ios.codesign.release = %(ios.codesign.debug)s[buildozer]# (int) Log level (0 = error only, 1 = info, 2 = debug (with command output))log_level = 2# (int) Display warning if buildozer is run as root (0 = False, 1 = True)warn_on_root = 1# (str) Path to build artifact storage, absolute or relative to spec filebuild_dir = ../.buildozer# (str) Path to build output (i.e. .apk, .ipa) storage# bin_dir = ./bin# -----------------------------------------------------------------------------# List as sections## You can define all the &quot;list&quot; as [section:key].# Each line will be considered as a option to the list.# Let's take [app] / source.exclude_patterns.# Instead of doing:##[app]#source.exclude_patterns = license,data/audio/*.wav,data/images/original/*## This can be translated into:##[app:source.exclude_patterns]#license#data/audio/*.wav#data/images/original/*## -----------------------------------------------------------------------------# Profiles## You can extend section / key with a profile# For example, you want to deploy a demo version of your application without# HD content. You could first change the title to add &quot;(demo)&quot; in the name# and extend the excluded directories to remove the HD content.##[app@demo]#title = My Application (demo)##[app:source.exclude_patterns@demo]#images/hd/*## Then, invoke the command line with the &quot;demo&quot; profile:##buildozer --profile demo android debug Choose files or directorys Whit this script, it can print the absolute path of the file/directory you piked at the button. filechooser.open_file works fine. But filechooser.choose_dir works only in my PC, not on Android. No idea why. main.py main.pyfrom kivy.app import Appfrom kivy.uix.widget import Widgetfrom kivy.properties import NumericProperty, ReferenceListProperty, ObjectPropertyfrom kivy.vector import Vectorfrom kivy.clock import Clockfrom random import randintfrom kivy.lang import Builderfrom kivy.uix.image import AsyncImagefrom plyer import filechooserfrom kivy.properties import ListPropertyfrom kivy.uix.button import Buttonclass Main(Widget): selection = ListProperty([]) def choose(self): ''' Call plyer filechooser API to run a filechooser Activity. ''' filechooser.open_file(on_selection=self.handle_selection) def choose_d(self): ''' Call plyer filechooser API to run a filechooser Activity. ''' filechooser.choose_dir(on_selection=self.handle_selection) def handle_selection(self, selection): ''' Callback function for handling the selection response from Activity. ''' self.selection = selection #print(str(selection)) def on_selection(self, *a, **k): ''' Update TextInput.text after FileChoose.selection is changed via FileChoose.handle_selection. ''' self.b_t.ii = self.selection[0]class RunApp(App): def build(self): game = Main() return gameif __name__ == '__main__': RunApp().run() run.kv run.kv&lt;FileChoose&gt;:&lt;Main@BoxLayout&gt;: box: box_img b_t: b_t orientation: &quot; vertical&quot; BoxLayout: id: box_img ii: '1.png' canvas: Rectangle: source: self.ii pos: root.pos size: root.size BoxLayout: width: root.width BoxLayout: orientation: 'vertical' size_hint_x:1 Button: pos: self.pos text: 'Pick file' on_release: root.choose() Button: pos: self.pos text: 'Directory' on_release: root.choose_d() Label: color: 0, 0, 0, 1 size_hint_x:9 id: b_t ii: 'The thing you choosed' text: self.ii haling: 0 For android This example makes you are able to choose a filer/directory in Android phone. main.pyfrom kivy.core.window import Windowfrom kivy.lang import Builderfrom kivymd.app import MDAppfrom kivymd.uix.filemanager import MDFileManagerfrom kivymd.toast import toastfrom kivy.utils import platformKV = '''BoxLayout: orientation: 'vertical' MDToolbar: title: &quot;MDFileManager&quot; left_action_items: [['menu', lambda x: None]] elevation: 10 FloatLayout: MDRoundFlatIconButton: text: &quot;Open manager&quot; icon: &quot;folder&quot; pos_hint: {'center_x': .5, 'center_y': .6} on_release: app.file_manager_open()'''class Example(MDApp): def __init__(self, **kwargs): super().__init__(**kwargs) Window.bind(on_keyboard=self.events) self.manager_open = False self.file_manager = MDFileManager( exit_manager=self.exit_manager, select_path=self.select_path, #preview=True ) def build(self): return Builder.load_string(KV) def file_manager_open(self): PATH =&quot;.&quot; if platform == &quot;android&quot;: from android.permissions import request_permissions, Permission request_permissions([Permission.READ_EXTERNAL_STORAGE, Permission.WRITE_EXTERNAL_STORAGE]) app_folder = os.path.dirname(os.path.abspath(__file__)) PATH = &quot;/storage/emulated/0&quot; #app_folder self.file_manager.show(PATH) # output manager to the screen self.manager_open = True def select_path(self, path): '''It will be called when you click on the file name or the catalog selection button. :type path: str; :param path: path to the selected directory or file; ''' self.exit_manager() toast(path) def exit_manager(self, *args): '''Called when the user reaches the root of the directory tree.''' self.manager_open = False self.file_manager.close() def events(self, instance, keyboard, keycode, text, modifiers): '''Called when buttons are pressed on the mobile device.''' if keyboard in (1001, 27): if self.manager_open: self.file_manager.back() return TrueExample().run() Official Document Kivy Add this to the requirements requirements = kivy, python3==3.7.5, docutils, android main.pyfrom kivy.app import Appfrom kivy.uix.floatlayout import FloatLayoutfrom kivy.factory import Factoryfrom kivy.properties import ObjectPropertyfrom kivy.uix.popup import Popupfrom kivy.utils import platformimport osclass LoadDialog(FloatLayout): load = ObjectProperty(None) cancel = ObjectProperty(None)class SaveDialog(FloatLayout): save = ObjectProperty(None) text_input = ObjectProperty(None) cancel = ObjectProperty(None)class Root(FloatLayout): loadfile = ObjectProperty(None) savefile = ObjectProperty(None) text_input = ObjectProperty(None) def dismiss_popup(self): self._popup.dismiss() def show_load(self): content = LoadDialog(load=self.load, cancel=self.dismiss_popup) PATH = &quot;.&quot; if platform == &quot;android&quot;: from android.permissions import request_permissions, Permission request_permissions([Permission.READ_EXTERNAL_STORAGE, Permission.WRITE_EXTERNAL_STORAGE]) app_folder = os.path.dirname(os.path.abspath(__file__)) PATH = &quot;/storage/emulated/0&quot; #app_folder content.ids.filechooser.path = PATH self._popup = Popup(title=&quot;Load file&quot;, content=content, size_hint=(0.9, 0.9)) self._popup.open() def show_save(self): content = SaveDialog(save=self.save, cancel=self.dismiss_popup) PATH = &quot;.&quot; if platform == &quot;android&quot;: from android.permissions import request_permissions, Permission request_permissions([Permission.READ_EXTERNAL_STORAGE, Permission.WRITE_EXTERNAL_STORAGE]) app_folder = os.path.dirname(os.path.abspath(__file__)) PATH = &quot;/storage/emulated/0&quot; #app_folder content.ids.filechooser.path = PATH self._popup = Popup(title=&quot;Save file&quot;, content=content, size_hint=(0.9, 0.9)) self._popup.open() def load(self, path, filename): with open(os.path.join(path, filename[0])) as stream: self.text_input.text = stream.read() self.dismiss_popup() def save(self, path, filename): with open(os.path.join(path, filename), 'w') as stream: stream.write(self.text_input.text) self.dismiss_popup()class Editor(App): passFactory.register('Root', cls=Root)Factory.register('LoadDialog', cls=LoadDialog)Factory.register('SaveDialog', cls=SaveDialog)if __name__ == '__main__': Editor().run() editor.kv editor.kv#:kivy 1.1.0Root: text_input: text_input BoxLayout: orientation: 'vertical' BoxLayout: size_hint_y: None height: 30 Button: text: 'Load' on_release: root.show_load() Button: text: 'Save' on_release: root.show_save() BoxLayout: TextInput: id: text_input text: '' RstDocument: text: text_input.text show_errors: True&lt;LoadDialog&gt;: BoxLayout: size: root.size pos: root.pos orientation: &quot;vertical&quot; FileChooserListView: id: filechooser path: &quot;.&quot; BoxLayout: size_hint_y: None height: 30 Button: id: test text: &quot;Cancel&quot; on_release: root.cancel() Button: text: &quot;Load&quot; on_release: root.load(filechooser.path, filechooser.selection)&lt;SaveDialog&gt;: text_input: text_input BoxLayout: size: root.size pos: root.pos orientation: &quot;vertical&quot; FileChooserListView: id: filechooser on_selection: text_input.text = self.selection and self.selection[0] or '' TextInput: id: text_input size_hint_y: None height: 30 multiline: False BoxLayout: size_hint_y: None height: 30 Button: text: &quot;Cancel&quot; on_release: root.cancel() Button: text: &quot;Save&quot; on_release: root.save(filechooser.path, text_input.text)","link":"/2021/01/02/Python/kivy_filechooser/"},{"title":"Image align by opencv in Python","text":"Align import cv2import numpy as npimg1 = cv2.imread('/home/ken/Desktop/test/IMG_20210421_143828.jpg')img2 = cv2.imread('/home/ken/Desktop/test/IMG_20210421_143832.jpg')img3 = cv2.imread('/home/ken/Desktop/test/IMG_20210421_143834.jpg')img4 = cv2.imread('/home/ken/Desktop/test.png')img_result = cv2.resize(img1, (900,400))img_1 = cv2.resize(img1, (300,200))img_2 = cv2.resize(img2, (300,200))img_3 = cv2.resize(img3, (300,200))img_4 = cv2.resize(img4, (900,200))img_result[0:200, 0:300] = img_1img_result[0:200, 300:600] = img_2img_result[0:200, 600:900] = img_3img_result[200:400, 0:900] = img_4cv2.imwrite('batch.png',img_result)","link":"/2021/04/21/Python/opencv-img-align/"},{"title":"Python:Opencv Edge Detection","text":"Python:Opencv Edge Detection Reference: LearnOpenCV Morphological Transformations Example Image: © Joe Jimbo import cv2import numpy as np# Read the original imageimg = cv2.imread('test.jpg')# Convert to graycsaleimg_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)# Blur the image for better edge detectionimg_blur = cv2.GaussianBlur(img_gray, (3,3), 0)# Sobel Edge Detectionsobelx = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=1, dy=0, ksize=5) # Sobel Edge Detection on the X axissobely = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=0, dy=1, ksize=5) # Sobel Edge Detection on the Y axissobelxy = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=1, dy=1, ksize=5) # Combined X and Y Sobel Edge Detection# Display Sobel Edge Detection Images'''cv2.imshow('Sobel X', sobelx)cv2.waitKey(0)cv2.imshow('Sobel Y', sobely)cv2.waitKey(0)cv2.imshow('Sobel X Y using Sobel() function', sobelxy)cv2.waitKey(0)'''# Canny Edge Detectionedges = cv2.Canny(image=img_blur, threshold1=70, threshold2=70) # Canny Edge Detection# Display Canny Edge Detection Imagecv2.imshow('Canny Edge Detection', edges)cv2.waitKey(0)cv2.destroyAllWindows() edges = cv2.Canny(image=img_blur, threshold1=70, threshold2=70) # Canny Edge Detectionedges[edges!=0]= 100edges[edges==0]= 255edges[edges==100]= 0#img2 = cv2.dilate(edges,kernel,iterations = 1)cv2.imshow('Canny Edge Detection', edges)cv2.waitKey(0)cv2.destroyAllWindows()kernel = np.ones((2,2),np.uint8)erosion = cv2.erode(edges,kernel,iterations = 1)img = cv2.cvtColor(erosion, cv2.COLOR_GRAY2RGB)#img[np.all(img == (0, 0, 0), axis=-1)] = (128, 114, 250)cv2.imshow('Canny Edge Detection', img)cv2.waitKey(0)cv2.destroyAllWindows()cv2.imwrite(&quot;result2.png&quot;, img)","link":"/2022/06/13/Python/opencv-edge-detect/"},{"title":"OpenCV: Extract Informations From Video | python","text":"Quick View Test Vide Information This video is a MRI video record from @浙江医学僧， Bilibili Code for play import cv2cap=cv2.VideoCapture(&quot;心脏的跳动和声音.mp4&quot;)while (True): ret,frame=cap.read() cv2.imshow(&quot;video&quot;,frame) # 在播放每一帧时，使用cv2.waitKey()设置适当的持续时间。如果设置的太低视频就会播放的非常快，如果设置的太高就会播放的很慢。通常情况下25ms就ok if cv2.waitKey(25)&amp;0xFF==ord('q'): cv2.destroyAllWindows() break Extract a Line selecte an area Point_from = (121, 155) # (x, y)Point_end = (292, 155) # (Width, Height)point_color = (0, 0, 255) # BGRthickness = 1lineType = 8cv2.rectangle(frame, Point_from, Point_end, point_color, thickness, lineType) get the date from the selected area frame2 = frame.swapaxes(0,1)print(frame2[Point_from[-1]][Point_from[0]:Point_end[0]].sum()) Test: collect data from first 200 frames Insert the codes below in the while loop to collecte the data. Num = 0Result = []while Num &lt; 200: Num += 1 ... Selected_tmp = frame[Point_from[-1]][Point_from[0]:Point_end[0]].sum() Result += [Selected_tmp] Data: 38484, 38499, 38910, 38886, 37764, 35799, 34968, 34968, 35565, 36000, 36879, 37044, 37062, 37089, 36930, 37041, 36525, 36384, 36213, 36279, 36186, 37065, 37272, 38034, 38175, 38220, 38532, 38730, 38835, 38412, 37287, 37278, 35487, 34749, 34650, 36159, 36891, 36858, 37074, 36969, 37167, 36981, 36696, 36711, 36255, 36048, 35841, 36591, 36966, 36975, 37110, 37737, 38139, 38772, 38769, 38778, 38736, 38634, 37392, 35487, 34701, 34701, 35154, 36345, 36666, 36996, 37065, 37071, 36867, 36903, 36804, 36435, 36039, 36039, 36117, 36006, 36456, 37101, 37461, 37461, 38088, 38466, 38856, 38679, 38742, 38748, 38718, 37830, 35724, 34905, 34977, 34977, 35949, 36726, 37149, 36945, 36789, 36846, 36663, 36783, 36828, 36216, 36030, 36033, 35877, 36789, 37485, 38148, 38463, 38466, 39003, 38997, 39012, 38862, 37707, 37707, 35367, 34971, 35016, 35556, 36684, 36684, 36873, 37233, 37152, 36840, 36714, 36702, 36567, 36318, 35952, 35778, 36420, 36450, 36939, 37221, 38004, 38556, 39108, 39120, 38979, 39105, 39111, 39066, 36699, 36699, 35199, 34488, 34788, 35859, 36420, 36420, 36954, 36783, 37038, 37119, 36825, 36879, 36762, 36681, 36474, 36099, 36006, 36006, 36357, 36996, 37194, 37461, 38325, 38364, 38661, 38967, 38898, 39066, 38838, 38853, 37446, 35427, 34785, 34881, 36003, 36003, 36915, 36951, 37257, 37098, 36810, 36810, 36855, 36453, 36066, 36093, 35508, 35544, 36042, 36693, 37230, 37776, 38019, 38049 Sitch the frames import cv2import numpy as npcap=cv2.VideoCapture(&quot;心脏的跳动和声音.mp4&quot;)Point_from = (121, 155) # (x, y)Point_end = (292, 155) # (Width, Height)point_color = (0, 0, 255) # BGRthickness = 1lineType = 8ret,frame=cap.read()Selected_frame = frame[Point_from[-1]][Point_from[0]:Point_end[0]]Num = 0Result = []Result_frame = Selected_frameResult_frame = Result_frame.reshape((171,1,3))cap=cv2.VideoCapture(&quot;心脏的跳动和声音.mp4&quot;)#while Num &lt; 200:while True: Num += 1 ret,frame=cap.read() # Selecte an area frame = cv2.rectangle(frame, Point_from, Point_end, point_color, thickness, lineType) frame2 = frame.swapaxes(0,1) Selected_tmp = frame2[Point_from[-1]][Point_from[0]:Point_end[0]].sum() Selected_frame = frame2[Point_from[-1]][Point_from[0]:Point_end[0]] Selected_frame = Selected_frame.reshape((171,1,3)) Result += [Selected_frame] Result_frame = np.append(Result_frame, Selected_frame, axis=1) # Show frame cv2.imshow(&quot;video&quot;,frame) cv2.imshow(&quot;Selected Frames&quot;,Result_frame) if cv2.waitKey(25)&amp;0xFF==ord('q'): cv2.destroyAllWindows() break Regression import numpy as npimport matplotlib.pyplot as pltimport scipy.optimize as optimizepi = np.piy = [] # data from abovefps = 30x = np.array(range(len(y)))/fpsfig, ax = plt.subplots()ax.plot(x, np.log(y), 'b--')plt.ion()plt.show()def target_func(x, a0, a1, a2, a3): return a0 * np.sin(a1 * x + a2) + a3# 拟合sin曲线fs = np.fft.fftfreq(len(x), x[1] - x[0])Y = abs(np.fft.fft(y))freq = abs(fs[np.argmax(Y[1:]) + 1])/2a0 = max(y) - min(y)a1 = 2 * pi * freqa2 = 0a3 = np.mean(y)p0 = [a0, a1, a2, a3]para, _ = optimize.curve_fit(target_func, x, y, p0=p0)print(para)y_fit = [target_func(a, *para) for a in x]ax.plot(x, np.log(y_fit), 'g')ax.plot(x, [i-ii for i,ii in zip(y, y_fit)], 'g')plt.show() scripts from cse.unsw.edu Result: digraph{ A -> B } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });","link":"/2021/05/23/Python/opencv-digital-signal-detect/"},{"title":"Image stitch with OpenCV in Python!","text":"Main I tried very hard to find a script which was able to stitch images. Other scripts were either too old to works on python3 or the functions are out of data. I final find a one in the post made by Adrian Rosebrock, 2018. Thanks Adrian Rosebrock, this script works very well and I’d like to note and share it here. Origin Contributor: Adrian Rosebrock, 2018 Please reading the post from the original sites. It would be a great help. pic_stitch.py #!/usr/bin/env python3'''https://www.pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/'''from imutils import pathsimport numpy as npimport argparseimport imutilsimport cv2# construct the argument parser and parse the argumentsap = argparse.ArgumentParser()ap.add_argument(&quot;-i&quot;, &quot;--input&quot;, type=str, required=True, help=&quot;path to input directory of input to stitch&quot;)ap.add_argument(&quot;-o&quot;, &quot;--output&quot;, type=str, required=True, help=&quot;path to the output image&quot;)ap.add_argument(&quot;-c&quot;, &quot;--crop&quot;, type=int, default=0, help=&quot;whether to crop out largest rectangular region&quot;)ap.add_argument(&quot;-t&quot;, &quot;--type&quot;, type=str, default=&quot;d&quot;, help=&quot;type of the input, 'd' is directory, 'v' is video&quot;)args = vars(ap.parse_args())# grab the paths to the input images and initialize our images listimages = []if args[&quot;type&quot;] == &quot;d&quot;: print(&quot;[INFO] loading images...&quot;) imagePaths = sorted(list(paths.list_images(args[&quot;input&quot;]))) # loop over the image paths, load each one, and add them to our # images to stich list for imagePath in imagePaths: image = cv2.imread(imagePath) images.append(image) # initialize OpenCV's image sticher object and then perform the image # stitching print(&quot;[INFO] stitching images...&quot;)elif args[&quot;type&quot;] ==&quot;v&quot;: cap=cv2.VideoCapture(args[&quot;input&quot;]) Num = 0 while Num &lt; cap.get(cv2.CAP_PROP_FRAME_COUNT): Num += 1 if Num % 1 == 0: ret,frame=cap.read() images.append(frame)stitcher = cv2.createStitcher() if imutils.is_cv3() else cv2.Stitcher_create()(status, stitched) = stitcher.stitch(images)# if the status is '0', then OpenCV successfully performed image# stitchingif status == 0: # check to see if we supposed to crop out the largest rectangular # region from the stitched image if args[&quot;crop&quot;] &gt; 0: # create a 10 pixel border surrounding the stitched image print(&quot;[INFO] cropping...&quot;) stitched = cv2.copyMakeBorder(stitched, 10, 10, 10, 10, cv2.BORDER_CONSTANT, (0, 0, 0)) # convert the stitched image to grayscale and threshold it # such that all pixels greater than zero are set to 255 # (foreground) while all others remain 0 (background) gray = cv2.cvtColor(stitched, cv2.COLOR_BGR2GRAY) thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)[1] # find all external contours in the threshold image then find # the *largest* contour which will be the contour/outline of # the stitched image cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) cnts = imutils.grab_contours(cnts) c = max(cnts, key=cv2.contourArea) # allocate memory for the mask which will contain the # rectangular bounding box of the stitched image region mask = np.zeros(thresh.shape, dtype=&quot;uint8&quot;) (x, y, w, h) = cv2.boundingRect(c) cv2.rectangle(mask, (x, y), (x + w, y + h), 255, -1) # create two copies of the mask: one to serve as our actual # minimum rectangular region and another to serve as a counter # for how many pixels need to be removed to form the minimum # rectangular region minRect = mask.copy() sub = mask.copy() # keep looping until there are no non-zero pixels left in the # subtracted image while cv2.countNonZero(sub) &gt; 0: # erode the minimum rectangular mask and then subtract # the thresholded image from the minimum rectangular mask # so we can count if there are any non-zero pixels left minRect = cv2.erode(minRect, None) sub = cv2.subtract(minRect, thresh) # find contours in the minimum rectangular mask and then # extract the bounding box (x, y)-coordinates cnts = cv2.findContours(minRect.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) cnts = imutils.grab_contours(cnts) c = max(cnts, key=cv2.contourArea) (x, y, w, h) = cv2.boundingRect(c) # use the bounding box coordinates to extract the our final # stitched image stitched = stitched[y:y + h, x:x + w] # write the output stitched image to disk cv2.imwrite(args[&quot;output&quot;], stitched) # display the output stitched image to our screen cv2.imshow(&quot;Stitched&quot;, stitched) cv2.waitKey(0)# otherwise the stitching failed, likely due to not enough keypoints)# being detectedelse: print(&quot;[INFO] image stitching failed ({})&quot;.format(status)) How to use it tree test test ├── IMG_20210421_143828.jpg ├── IMG_20210421_143832.jpg └── IMG_20210421_143834.jpg Pythonpython3 pic_stitch.py -i test -o result.png Result: The Simplified Script @MoonJian 2018 import numpy as npimport cv2from cv2 import Stitcherif __name__ == &quot;__main__&quot;: img1 = cv2.imread('/home/ken/Desktop/test/IMG_20210421_143834.jpg') img2 = cv2.imread('/home/ken/Desktop/IMG_20210421_143832.jpg') #stitcher = cv2.createStitcher(False) stitcher = cv2.Stitcher.create(cv2.Stitcher_PANORAMA)# , 根据不同的OpenCV版本来调用 (_result, pano) = stitcher.stitch((img1, img2)) cv2.imshow('pano',pano) cv2.waitKey(0) Stick A video No work so well import numpy as npimport cv2, sys, timefrom cv2 import Stitcherdef progress_bar(i): print(&quot;\\r&quot;, end=&quot;&quot;) print(&quot;Progress: {}%: &quot;.format(i), &quot;▋&quot; * (int(i) // 2), end=&quot;&quot;) sys.stdout.flush() time.sleep(0.05)cap=cv2.VideoCapture(&quot;stitch.mp4&quot;)fps_c = cap.get(cv2.CAP_PROP_FRAME_COUNT)stitcher = cv2.Stitcher.create(cv2.Stitcher_PANORAMA)# , 根据不同的OpenCV版本来调用Num = 0ret,Result =cap.read()while Num &lt;= fps_c: Num += 1 ret,frame=cap.read() _result = 1 if Num % 1 == 0: (_result, Result_tmp) = stitcher.stitch((Result, frame)) progress_bar(100 * Num/fps_c ) if _result == 0: Result = Result_tmp Ratio = [len(Result[0])/1080*2,len(Result)/1920*2] Ratio.sort() Ratio = Ratio[-1] test = cv2.resize(Result, (int(len(Result[0])/Ratio),int(len(Result)/Ratio)), interpolation = cv2.INTER_AREA) cv2.imshow(&quot;Stitched&quot;, test) if cv2.waitKey(1) &amp; 0xFF == ord('q'): cv2.destroyAllWindows() break","link":"/2021/04/21/Python/opencv-img-stitch/"},{"title":"Opencv, Flip, noise, mask, etc","text":"Image Transfor Sometimes, we’d like to transfer image’s color, temperature, or something for getting more trainning data. There are few way’s could help you argument your photos to generate a considerable training data set. Flip img2 = cv2.flip(img, 0) ## img would flip verticallyimg2 = cv2.flip(img, 1) ## img would flip horizontally Temperature source code: Packt Lighter import cv2import numpy as npx = [0, 128, 255]y = [0, 192, 255]myLUT = _create_LUT_8UC1(x, y)img_curved = cv2.LUT(img_gray, myLUT).astype(np.uint8) Warming filter Strangely enough, those codes doesn’t work = = class WarmingFilter: def __init__(self): self.incr_ch_lut = _create_LUT_8UC1([0, 64, 128, 192, 256], [0, 70, 140, 210, 256]) self.decr_ch_lut = _create_LUT_8UC1([0, 64, 128, 192, 256], [0, 30, 80, 120, 192]) def render(self, img_rgb): c_r, c_g, c_b = cv2.split(img_rgb) c_r = cv2.LUT(c_r, self.incr_ch_lut).astype(np.uint8) c_b = cv2.LUT(c_b, self.decr_ch_lut).astype(np.uint8) img_rgb = cv2.merge((c_r, c_g, c_b)) c_b = cv2.LUT(c_b, decrChLUT).astype(np.uint8) # increase color saturation c_h, c_s, c_v = cv2.split(cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)) c_s = cv2.LUT(c_s, self.incr_ch_lut).astype(np.uint8) return cv2.cvtColor(cv2.merge((c_h, c_s, c_v)), cv2.COLOR_HSV2RGB) Colder Filter class CoolingFilter: def render(self, img_rgb): c_r, c_g, c_b = cv2.split(img_rgb) c_r = cv2.LUT(c_r, self.decr_ch_lut).astype(np.uint8) c_b = cv2.LUT(c_b, self.incr_ch_lut).astype(np.uint8) img_rgb = cv2.merge((c_r, c_g, c_b)) # decrease color saturation c_h, c_s, c_v = cv2.split(cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)) c_s = cv2.LUT(c_s, self.decr_ch_lut).astype(np.uint8) return cv2.cvtColor(cv2.merge((c_h, c_s, c_v)), cv2.COLOR_HSV2RGB) Add a transbarent mask source code: Pyimagesearch from __future__ import print_functionimport numpy as npimport cv2# load the imageimage = cv2.imread(&quot;mexico.jpg&quot;)for alpha in np.arange(0, 1.1, 0.1)[::-1]: # create two copies of the original image -- one for # the overlay and one for the final output image overlay = image.copy() output = image.copy() # draw a red rectangle surrounding Adrian in the image # along with the text &quot;PyImageSearch&quot; at the top-left # corner cv2.rectangle(overlay, (420, 205), (595, 385), (0, 0, 255), -1) cv2.putText(overlay, &quot;PyImageSearch: alpha={}&quot;.format(alpha), (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3) # apply the overlay cv2.addWeighted(overlay, alpha, output, 1 - alpha, 0, output) # show the output image print(&quot;alpha={}, beta={}&quot;.format(alpha, 1 - alpha)) cv2.imshow(&quot;Output&quot;, output) cv2.waitKey(0) Add noises Source: Shubham Pachori, from stackoverflow import numpy as npimport osimport cv2def noisy(noise_typ,image): if noise_typ == &quot;gauss&quot;: row,col,ch= image.shape mean = 0 var = 0.1 sigma = var**0.5 gauss = np.random.normal(mean,sigma,(row,col,ch)) gauss = gauss.reshape(row,col,ch) noisy = image + gauss return noisy elif noise_typ == &quot;s&amp;p&quot;: row,col,ch = image.shape s_vs_p = 0.5 amount = 0.004 out = np.copy(image) # Salt mode num_salt = np.ceil(amount * image.size * s_vs_p) coords = [np.random.randint(0, i - 1, int(num_salt)) for i in image.shape] out[coords] = 1 # Pepper mode num_pepper = np.ceil(amount* image.size * (1. - s_vs_p)) coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in image.shape] out[coords] = 0 return out elif noise_typ == &quot;poisson&quot;: vals = len(np.unique(image)) vals = 2 ** np.ceil(np.log2(vals)) noisy = np.random.poisson(image * vals) / float(vals) return noisy elif noise_typ ==&quot;speckle&quot;: row,col,ch = image.shape gauss = np.random.randn(row,col,ch) gauss = gauss.reshape(row,col,ch) noisy = image + image * gauss return noisy Source: ppk28, from stackoverflow import numpy as npimport randomimport cv2def sp_noise(image,prob): ''' Add salt and pepper noise to image prob: Probability of the noise ''' output = np.zeros(image.shape,np.uint8) thres = 1 - prob for i in range(image.shape[0]): for j in range(image.shape[1]): rdn = random.random() if rdn &lt; prob: output[i][j] = 0 elif rdn &gt; thres: output[i][j] = 255 else: output[i][j] = image[i][j] return outputimage = cv2.imread('image.jpg',0) # Only for grayscale imagenoise_img = sp_noise(image,0.05)cv2.imwrite('sp_noise.jpg', noise_img) Filter from PIL Sorce: www.tutorialspoint.com from PIL import Image, ImageFilterim = Image.open('123.png')im1 = im.filter(ImageFilter.BLUR)im1.show()","link":"/2021/11/13/Python/opencv-img-trans/"},{"title":"Compare the similar of two images","text":"Picture similarities a Image from: © Chun-Guang Shan; 2019 Why this example: Youtube: 736778E78A9F9447776A74287756D7 Twitter: Elisabeth Bik import cv2img1 = cv2.imread('1.png')img2 = cv2.imread('2.png')gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)# Initialize SIFT detectorsift = cv2.SIFT_create()# Find keypoints and descriptors for both imageskp1, des1 = sift.detectAndCompute(gray1, None)kp2, des2 = sift.detectAndCompute(gray2, None)# Initialize brute-force matcherbf = cv2.BFMatcher()# Match descriptors from both imagesmatches = bf.knnMatch(des1, des2, k=2)# Apply ratio test to remove false matchesgood_matches = []for m, n in matches: if m.distance &lt; 0.75 * n.distance: good_matches.append(m)# Draw the matched keypointsresult = cv2.drawMatches(img1, kp1, img2, kp2, good_matches, None)cv2.imshow(&quot;video&quot;,result)if cv2.waitKey(0)&amp;0xFF==ord('q'): cv2.destroyAllWindows() From this results, we can find that event though the elements of the images are complicated and the color is transferred, this algorithm could still do an awesome job. Here we are using the RootSIFT rather then standard SIFT which requires cv2.xfeatures2d module. What’s the difference between them? SIFT (Scale-Invariant Feature Transform) is an algorithm used to detect and describe local features in images. It was developed by David Lowe in 1999 and is widely used in computer vision applications, such as image matching, object recognition, and stitching. The key advantages of SIFT are its scale and rotation invariance, as well as its robustness to changes in illumination and viewpoint. RootSIFT is an extension of SIFT proposed by Arandjelović and Zisserman in 2012. The main idea behind RootSIFT is to improve the performance of the original SIFT descriptor by applying a simple element-wise square root normalization to the descriptor values. This normalization helps to better differentiate between descriptors and improves matching performance, especially in scenarios where the distribution of descriptor distances is heavily skewed. The best scenarios for each method: Standard SIFT: General-purpose feature detection and description Applications where scale and rotation invariance are required Object recognition, image stitching, and 3D reconstruction RootSIFT: Improved performance in scenarios with skewed descriptor distance distributions Better differentiation between descriptors for more accurate matching Applications where a more discriminative descriptor is needed In summary, RootSIFT is an improvement over standard SIFT in terms of descriptor matching performance. It is especially useful in scenarios where the distribution of descriptor distances is heavily skewed, and a more discriminative descriptor is required. However, for general-purpose feature detection and description, the standard SIFT algorithm is still widely applicable. © ChatGPT4 Similarity by machine learning model import numpy as npfrom keras.preprocessing import imagefrom keras.applications.vgg16 import VGG16, preprocess_inputfrom sklearn.metrics.pairwise import cosine_similaritydef load_and_preprocess_image(image_path): img = image.load_img(image_path, target_size=(224, 224)) img_array = image.img_to_array(img) img_array = np.expand_dims(img_array, axis=0) return preprocess_input(img_array)def extract_features(img_array, model): return model.predict(img_array)def calculate_similarity(feature_vector1, feature_vector2): return cosine_similarity(feature_vector1, feature_vector2)# Load the pre-trained VGG16 modelmodel = VGG16(weights='imagenet', include_top=False, pooling='avg')# Load and preprocess the imagesimage1_path = '1.png'image2_path = '2.png'image1 = load_and_preprocess_image(image1_path)image2 = load_and_preprocess_image(image2_path)# Extract high-level features from both imagesfeature_vector1 = extract_features(image1, model)feature_vector2 = extract_features(image2, model)# Calculate the cosine similarity between the feature vectorssimilarity_score = calculate_similarity(feature_vector1, feature_vector2)print('Similarity score:', similarity_score[0][0]) Similarity score: 0.9361447 How it work? It compare the similarities of the images is by using a pre-trained deep learning model VGG16 to extract high-level features from both images and then calculate the cosine similarity between these features. Here’s an example of how you can do this using Keras with TensorFlow backend: What is VGG16 (From ChatGPT4) VGG16 is a deep convolutional neural network architecture proposed by the Visual Geometry Group (VGG) at the University of Oxford. It was introduced by Karen Simonyan and Andrew Zisserman in their 2014 paper, “Very Deep Convolutional Networks for Large-Scale Image Recognition” VGG16 contains 16 weight layers, including 13 convolutional layers and 3 fully connected layers. It was trained on the ImageNet dataset, which contains over 14 million images belonging to 1,000 different classes. The primary purpose of VGG16 is for image classification, where it has achieved top performance in the ImageNet Large Scale Visual Recognition Challenge (ILSVRC). However, its learned features can also be used for various other tasks, such as object detection, segmentation, and image similarity comparison, as demonstrated in the previous code example. Merits of using VGG16 for image similarity comparison: Pre-trained models: VGG16 is pre-trained on a large dataset (ImageNet), so it has already learned high-level features that can be useful for a wide range of tasks, including image similarity comparison. Transfer learning: Since VGG16 has already learned high-level features, you can use it as a feature extractor for your images without having to train the model from scratch. Robustness: VGG16 can extract features that are robust to variations in scale, rotation, and translation, making it suitable for comparing images with different sizes and orientations. Disadvantages of using VGG16 for image similarity comparison: Computational complexity: VGG16 has a large number of parameters, which can make it computationally expensive to use, especially on devices with limited computational resources. This can be a concern if you need to process a large number of images or require real-time processing. Model size: The model size of VGG16 is relatively large (around 528 MB), which can be a concern if you have limited storage or need to deploy the model on edge devices. Newer models available: Since the introduction of VGG16, several more advanced architectures have been proposed, such as ResNet, Inception, and EfficientNet, which can achieve better performance with less computational complexity and smaller model sizes. In summary, while VGG16 can be used effectively for image similarity comparison, its computational complexity and model size might be a concern for certain applications or devices. In such cases, you may consider using more recent and efficient architectures like ResNet or EfficientNet for feature extraction. import cv2import numpy as npdef align_images(image1, image2): h1, w1, _ = image1.shape h2, w2, _ = image2.shape aligned_image = np.zeros((max(h1, h2), w1 + w2, 3), dtype=np.uint8) aligned_image[:h1, :w1] = image1 aligned_image[:h2, w1:] = image2 return aligned_imagedef draw_matching_lines(image1, image2, num_matches=50): akaze = cv2.AKAZE_create() keypoints1, descriptors1 = akaze.detectAndCompute(image1, None) keypoints2, descriptors2 = akaze.detectAndCompute(image2, None) bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True) matches = bf.match(descriptors1, descriptors2) matches = sorted(matches, key=lambda x: x.distance)[:num_matches] aligned_image = align_images(image1, image2) for m in matches: pt1 = tuple(np.round(keypoints1[m.queryIdx].pt).astype(int)) pt2 = tuple(np.round(keypoints2[m.trainIdx].pt).astype(int)) pt2 = (pt2[0] + image1.shape[1], pt2[1]) cv2.line(aligned_image, pt1, pt2, (0, 255, 0), 1) return aligned_image# Load the imagesimage1_path = '1.png'image2_path = '2.png'image1 = cv2.imread(image1_path)image2 = cv2.imread(image2_path)# Draw lines between matching keypointsaligned_image = draw_matching_lines(image1, image2, num_matches=50)# Show the aligned images with matching linescv2.imshow('Aligned Images with Similar Regions', aligned_image)cv2.waitKey(0)cv2.destroyAllWindows() = = I am not quirt accept this results pre { background-color:#38393d; color: #5fd381; } import cv2import os import itertoolsImg_lst = os.listdir('Test')pairs = list(itertools.combinations(Img_lst, 2))for i in pairs: img1 = cv2.imread('Test/' + i[0]) img2 = cv2.imread('Test/' + i[1]) gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY) gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY) # Initialize SIFT detector sift = cv2.SIFT_create() # Find keypoints and descriptors for both images kp1, des1 = sift.detectAndCompute(gray1, None) kp2, des2 = sift.detectAndCompute(gray2, None) # Initialize brute-force matcher bf = cv2.BFMatcher() # Match descriptors from both images matches = bf.knnMatch(des1, des2, k=2) # Apply ratio test to remove false matches good_matches = [] for m, n in matches: if m.distance &lt; 0.75 * n.distance: good_matches.append(m) # Draw the matched keypoints result = cv2.drawMatches(img1, kp1, img2, kp2, good_matches, None) cv2.imwrite(&quot;Result/&quot; + i[0] + '_' + i[1], result)","link":"/2023/05/12/Python/opencv-similarity/"},{"title":"Remove the same or similar frame in a video|Python opencv","text":"Basic Grammars of OpenCV: Karobben Blog So, the situation is, after you recorded a video, there are lots of nonsense frames when you are doing something else, drinking water for instance. By calculating the difference between each frame with the previous frame, we can get a list of numbers and tossing the frame with low value by looking into this list. import library Pythonimport cv2import matplotlib.pyplot as plt Reading Video With the Code below, you can load and show the video on window “video” PythonVideo = &quot;test2.mp4&quot;cap=cv2.VideoCapture(Video)while (True): ret,frame=cap.read() cv2.imshow(&quot;video&quot;,frame) # 在播放每一帧时，使用cv2.waitKey()设置适当的持续时间。如果设置的太低视频就会播放的非常快，如果设置的太高就会播放的很慢。通常情况下25ms就ok if cv2.waitKey(1)&amp;0xFF==ord('q'): cv2.destroyAllWindows() break Calculate the different of each frame Calculate the difference of the images def Diff_img(img0, img): ''' This function is designed for calculating the difference between two images. The images are convert it to an grey image and be resized to reduce the unnecessary calculating. ''' # Grey and resize img0 = cv2.cvtColor(img0, cv2.COLOR_RGB2GRAY) img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) img0 = cv2.resize(img0, (320,200), interpolation = cv2.INTER_AREA) img = cv2.resize(img, (320,200), interpolation = cv2.INTER_AREA) # Calculate Result = (abs(img - img0)).sum() return Result PythonVideo = &quot;test2.mp4&quot;cap=cv2.VideoCapture(Video)ret,frame0 = cap.read()Result = []Num = 0while (True): ret,frame=cap.read() #cv2.imshow(&quot;video&quot;,frame) if Num &gt; 0: Result += [Diff_img(frame0, frame)] frame0 = frame Num += 1 if cv2.waitKey(25)&amp;0xFF==ord('q'): cv2.destroyAllWindows() break Write result Video = &quot;test.mp4&quot;cap=cv2.VideoCapture(Video)ret,frame0 = cap.read()fps_c = cap.get(cv2.CAP_PROP_FPS)Video_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))Video_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))fps = fps_csize = (Video_w,Video_h)fourcc = cv2.VideoWriter_fourcc('M','J','P','G')videowriter = cv2.VideoWriter(&quot;output.avi&quot;,fourcc,fps,size)Result = []Num = 0while (True): ret,frame=cap.read() #cv2.imshow(&quot;video&quot;,frame) if Num &gt; 0: Diff = Diff_img(frame0, frame) Result += [Diff] frame0 = frame if Diff &gt; 10000: videowriter.write(frame0) Num += 1 print(round(Num /237450 * 100, 3))videowriter.release() The compare of the video before (left) and after (right) processing. digraph F { rankdir = UD; readV [label = \"Reading Video\"] readV -> B } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });","link":"/2021/04/10/Python/opencv-v-sm/"},{"title":"Opencv add a Progress Bar for video| Python","text":"Opencv Progress Bar Prepare your video, gif, png Sample progress bar We can use a rectangle to be the progress bar import cv2 as cv2# Vdieo sourceVideo = &quot;/run/media/ken/Data/Vlog/Tank_rasbbery/test.avi&quot;cap=cv2.VideoCapture(Video)Video_w = cap.get(cv2.CAP_PROP_FRAME_WIDTH)frame_total = cap.get(cv2.CAP_PROP_FRAME_COUNT)Num = 0print(frame_total, Num)while Num &lt;= frame_total-1: # caculate the current frame # The width of the progress bar = (current frame /Total frame) * Width of the frame Width = int((( Num/frame_total)*420)) Num +=1 print(Num, frame_total, width) # features for rectangle ptLeftTop = (0, 0) ptRightBottom = (Width, 20) point_color = (0, 0, 255) # BGR thickness = 20 lineType = 8 # frame ret,frame=cap.read() frame = cv2.resize(frame, (420,360), interpolation = cv2.INTER_AREA) frame = cv2.rectangle(frame, ptLeftTop, ptRightBottom, point_color, thickness, lineType) cv2.imshow(&quot;video&quot;,frame) # 在播放每一帧时，使用cv2.waitKey()设置适当的持续时间。如果设置的太低视频就会播放的非常快，如果设置的太高就会播放的很慢。通常情况下25ms就ok if cv2.waitKey(25)&amp;0xFF==ord('q'): cv2.destroyAllWindows() breakprint(&quot;Mission Down&quot;) loading a picture and moving with progress bar First, loading the picture Picture = &quot;/home/ken/Pictures/pokeball.png&quot;img = cv2.imread(Picture,1)img = cv2.resize(img, (10,10), interpolation = cv2.INTER_AREA) Then, picture clean: Details about threads and mask: 假小牙 2017 Origing by: 万能的小黑Alex 2020 Transparent Background def CV_mask(img1, img2, rows1, rows2, cols1, cols2): # 把logo放在左上角，所以我们只关心这一块区域 roi = img1[rows1:rows2, cols1:cols2] # 创建掩膜 img2gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY) print(img2gray[0]) ret, mask = cv2.threshold(img2gray, 56, 255, cv2.THRESH_BINARY) mask_inv = cv2.bitwise_not(mask) # 保留除logo外的背景 img1_bg = cv2.bitwise_and(roi, roi, mask=mask_inv) dst = cv2.add(img1_bg, img2) # 进行融合 img1[rows1:rows2, cols1:cols2] = dst # 融合后放在原图上 return img1 or Origing by: 红薯爱帅 2017 Clear Background def img_deal(img_target, img_logo, row1, row2, col1, col2): # 1，对logo进行缩放，按照20%进行 # cv2.imshow(&quot;img_logo&quot;, img_logo) # 2，对logo做清洗，白色区域是255，其他区域置为黑色0 img_logo_gray = cv2.cvtColor(img_logo, cv2.COLOR_BGR2GRAY) print(img_logo_gray[0]) ret, img_logo_mask = cv2.threshold(img_logo_gray, 46, 255, cv2.THRESH_BINARY) # 二值化函数 img_logo_mask1 = cv2.bitwise_not(img_logo_mask) # cv2.imshow(&quot;img_logo_gray&quot;, img_logo_gray) # cv2.imshow(&quot;img_logo_mask&quot;, img_logo_mask) # 3，提取目标图片的ROI img_roi = img_target[col1:col2, row1:row2].copy() #cv2.imshow(&quot;img_roi&quot;, img_roi) # 4，ROI和Logo图像融合 img_res0 = cv2.bitwise_and(img_roi, img_roi, mask=img_logo_mask) img_res1 = cv2.bitwise_and(img_logo, img_logo, mask=img_logo_mask1) img_res2 = cv2.add(img_res0, img_res1) # img_res2 = img_res0 + img_res1 img_target[col1:col2, row1:row2] = img_res2[:, :] return img_target Finally, adding picture to frames import cv2 as cv2import numpy as np# Vdieo sourceVideo = &quot;/run/media/ken/Data/Vlog/Tank_rasbbery/test.avi&quot;Picture = &quot;/home/ken/Pictures/16048269.png&quot;# OUTPUT size of the videoWidth_out = int(1920*.9)Height_out = int(1080*.9)PB_h_r = 1- 0.5# Resize imagePB_img_wr = .025img = cv2.imread(Picture,1)#img = cv2.resize(img, (200, 300), interpolation = cv2.INTER_AREA)# progress barpoint_color = (0, 0, 255) # BGRlineType = 8thickness_r = 0.005cap=cv2.VideoCapture(Video)# configPB_H = int(Height_out*PB_h_r)Video_w = cap.get(cv2.CAP_PROP_FRAME_WIDTH)frame_total = cap.get(cv2.CAP_PROP_FRAME_COUNT)Num = 0## img_position in framePB_img_hr = (img.shape[0]/ img.shape[1] )* PB_img_wrPB_img_w = int(PB_img_wr * Height_out)PB_img_h = int(PB_img_hr * Height_out)if PB_img_h%2 == 1: PB_img_h += 1frame_img_h1 = PB_H -int(PB_img_h/2)frame_img_h2 = PB_H +int(PB_img_h/2)img = cv2.resize(img, (PB_img_w,PB_img_h), interpolation = cv2.INTER_AREA)## Thickness of Progress barthickness = int(thickness_r * Height_out)def img_deal(img_target, img_logo, row1, row2, col1, col2): # 1，对logo进行缩放，按照20%进行 # cv2.imshow(&quot;img_logo&quot;, img_logo) # 2，对logo做清洗，白色区域是255，其他区域置为黑色0 img_logo_gray = cv2.cvtColor(img_logo, cv2.COLOR_BGR2GRAY) print(img_logo_gray[0]) ret, img_logo_mask = cv2.threshold(img_logo_gray, 46, 255, cv2.THRESH_BINARY) # 二值化函数 img_logo_mask1 = cv2.bitwise_not(img_logo_mask) # cv2.imshow(&quot;img_logo_gray&quot;, img_logo_gray) # cv2.imshow(&quot;img_logo_mask&quot;, img_logo_mask) # 3，提取目标图片的ROI img_roi = img_target[col1:col2, row1:row2].copy() #cv2.imshow(&quot;img_roi&quot;, img_roi) # 4，ROI和Logo图像融合 img_res0 = cv2.bitwise_and(img_roi, img_roi, mask=img_logo_mask) img_res1 = cv2.bitwise_and(img_logo, img_logo, mask=img_logo_mask1) img_res2 = cv2.add(img_res0, img_res1) # img_res2 = img_res0 + img_res1 img_target[col1:col2, row1:row2] = img_res2[:, :] return img_targetdef CV_mask(img1, img2, rows1, rows2, cols1, cols2): # 把logo放在左上角，所以我们只关心这一块区域 roi = img1[rows1:rows2, cols1:cols2] # 创建掩膜 img2gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY) print(img2gray[0]) ret, mask = cv2.threshold(img2gray, 46, 255, cv2.THRESH_BINARY_INV) mask_inv = cv2.bitwise_not(mask) # 保留除logo外的背景 img1_bg = cv2.bitwise_and(roi, roi, mask=mask_inv) dst = cv2.add(img1_bg, img2) # 进行融合 img1[rows1:rows2, cols1:cols2] = dst # 融合后放在原图上 return img1while Num &lt;= frame_total-1: # caculate the current frame # The width of the progress bar = (current frame /Total frame) * Width of the frame Width = int((( Num/frame_total)*Width_out)) Num +=1 # features for rectangle ptLeftTop = (0, PB_H) print(Num, frame_total, Width, PB_H, print(img[0][0])) ptRightBottom = (Width, PB_H) # frame ret,frame=cap.read() frame = cv2.resize(frame, (Width_out,Height_out), interpolation = cv2.INTER_AREA) frame = cv2.rectangle(frame, ptLeftTop, ptRightBottom, point_color, thickness, lineType) # Adding png for progress bar Width_png = int((( Num/frame_total)*(Width_out-PB_img_w))) # 保留除logo外的背景 #frame = CV_mask(frame, img, frame_img_h1, frame_img_h2, 0+Width_png, PB_img_w+Width_png) #frame = img_deal(frame, img, 0+Width_png, PB_img_w+Width_png, frame_img_h1, frame_img_h2) #frame[frame_img_h1:frame_img_h2 ,0+Width_png:PB_img_w+Width_png] = img # frame show cv2.imshow(&quot;video&quot;,frame) # 在播放每一帧时，使用cv2.waitKey()设置适当的持续时间。如果设置的太低视频就会播放的非常快，如果设置的太高就会播放的很慢。通常情况下25ms就ok if cv2.waitKey(25)&amp;0xFF==ord('q'): cv2.destroyAllWindows() breakprint(&quot;Mission Down&quot;) Gif progress Loading gif import time, cv2from PIL import Imageimport numpy as npfile = &quot;/home/ken/Pictures/pikachu_run.gif&quot;List = []im = Image.open(file)im.seek(1)#skip to the second frametry: while 1: List += [cv2.cvtColor(np.asarray(im.convert()),cv2.COLOR_RGB2BGR)] im.seek(im.tell()+1)except EOFError:#the sequence ends passNum = 0while Num &lt; len(List)*2: Num +=1 ID = Num%(len(List)) cv2.imshow(&quot;OpenCV&quot;,List[ID]) print(ID) cv2.waitKey(1) time.sleep(0.1)cv2.destroyAllWindows() All codes import cv2 as cv2import numpy as npfrom PIL import Image# Vdieo sourceVideo = &quot;/run/media/ken/Data/Vlog/Tank_rasbbery/test.avi&quot;Picture = &quot;/home/ken/Pictures/test.gif&quot;# OUTPUT size of the videoWidth_out = int(1920*.9)Height_out = int(1080*.9)PB_h_r = 1- 0.05# Resize imagePB_img_wr = .1img = cv2.imread(Picture,1)#img = cv2.resize(img, (200, 300), interpolation = cv2.INTER_AREA)# progress barpoint_color = (0, 0, 255) # BGRlineType = 8thickness_r = 0.005cap=cv2.VideoCapture(Video)# configPB_H = int(Height_out*PB_h_r)Video_w = cap.get(cv2.CAP_PROP_FRAME_WIDTH)frame_total = cap.get(cv2.CAP_PROP_FRAME_COUNT)Num = 0## img_position in frame#PB_img_hr = (img.shape[0]/ img.shape[1] )* PB_img_wr#PB_img_w = int(PB_img_wr * Height_out)#PB_img_h = int(PB_img_hr * Height_out)#if PB_img_h%2 == 1:# PB_img_h += 1#frame_img_h1 = PB_H -int(PB_img_h/2)#frame_img_h2 = PB_H +int(PB_img_h/2)#img = cv2.resize(img, (PB_img_w,PB_img_h), interpolation = cv2.INTER_AREA)## Thickness of Progress barthickness = int(thickness_r * Height_out)def img_deal(img_target, img_logo, row1, row2, col1, col2, THRE): # 1，对logo进行缩放，按照20%进行 # cv2.imshow(&quot;img_logo&quot;, img_logo) # 2，对logo做清洗，白色区域是255，其他区域置为黑色0 img_logo_gray = cv2.cvtColor(img_logo, cv2.COLOR_BGR2GRAY) print(img_logo_gray[0]) ret, img_logo_mask = cv2.threshold(img_logo_gray, THRE, 255, cv2.THRESH_BINARY) # 二值化函数 img_logo_mask1 = cv2.bitwise_not(img_logo_mask) # cv2.imshow(&quot;img_logo_gray&quot;, img_logo_gray) # cv2.imshow(&quot;img_logo_mask&quot;, img_logo_mask) # 3，提取目标图片的ROI img_roi = img_target[col1:col2, row1:row2].copy() #cv2.imshow(&quot;img_roi&quot;, img_roi) # 4，ROI和Logo图像融合 img_res0 = cv2.bitwise_and(img_roi, img_roi, mask=img_logo_mask) img_res1 = cv2.bitwise_and(img_logo, img_logo, mask=img_logo_mask1) img_res2 = cv2.add(img_res0, img_res1) # img_res2 = img_res0 + img_res1 img_target[col1:col2, row1:row2] = img_res2[:, :] return img_target# reading GIF fileList = []im = Image.open(Picture)im.seek(1)#skip to the second frametry: while 1: img = cv2.cvtColor(np.asarray(im.convert()),cv2.COLOR_RGB2BGR) PB_img_hr = (img.shape[0]/ img.shape[1] )* PB_img_wr PB_img_w = int(PB_img_wr * Height_out) PB_img_h = int(PB_img_hr * Height_out) if PB_img_h%2 == 1: PB_img_h += 1 frame_img_h1 = PB_H -int(PB_img_h/2) frame_img_h2 = PB_H +int(PB_img_h/2) List += [cv2.resize(img, (PB_img_w,PB_img_h), interpolation = cv2.INTER_AREA)] im.seek(im.tell()+1)except EOFError:#the sequence ends passdef CV_mask(img1, img2, rows1, rows2, cols1, cols2, THRE): # 把logo放在左上角，所以我们只关心这一块区域 roi = img1[rows1:rows2, cols1:cols2] # 创建掩膜 img2gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY) print(img2gray[0]) ret, mask = cv2.threshold(img2gray, THRE, 255, cv2.THRESH_BINARY_INV) mask_inv = cv2.bitwise_not(mask) # 保留除logo外的背景 img1_bg = cv2.bitwise_and(roi, roi, mask=mask_inv) dst = cv2.add(img1_bg, img2) # 进行融合 img1[rows1:rows2, cols1:cols2] = dst # 融合后放在原图上 return img1while Num &lt;= frame_total-1: # caculate the current frame # The width of the progress bar = (current frame /Total frame) * Width of the frame Width = int((( Num/frame_total)*(Width_out-PB_img_w))) + int(PB_img_w*.5) Num +=1 # features for rectangle ptLeftTop = (0, PB_H) img = List[int(Num%len(List))] img = cv2.flip(img,1 ) print(Num, frame_total, Width, PB_H, print(img[0][0])) ptRightBottom = (Width, PB_H) # frame ret,frame=cap.read() frame = cv2.resize(frame, (Width_out,Height_out), interpolation = cv2.INTER_AREA) frame = cv2.rectangle(frame, ptLeftTop, ptRightBottom, point_color, thickness, lineType) # Adding png for progress bar Width_png = int((( Num/frame_total)*(Width_out-PB_img_w))) # 保留除logo外的背景 #frame = #CV_mask(frame, img, frame_img_h1, frame_img_h2, 0+Width_png, PB_img_w+Width_png, 207) frame = img_deal(frame, img, 0+Width_png, PB_img_w+Width_png, frame_img_h1, frame_img_h2, 207) #frame[frame_img_h1:frame_img_h2 ,0+Width_png:PB_img_w+Width_png] = img # frame show cv2.imshow(&quot;video&quot;,frame) # 在播放每一帧时，使用cv2.waitKey()设置适当的持续时间。如果设置的太低视频就会播放的非常快，如果设置的太高就会播放的很慢。通常情况下25ms就ok if cv2.waitKey(25)&amp;0xFF==ord('q'): cv2.destroyAllWindows() breakprint(&quot;Mission Down&quot;)","link":"/2021/06/01/Python/opencv-progressbar/"},{"title":"Combine two videos in to the same frame|Python opencv","text":"Basic Grammars of OpenCV: Karobben Blog ## import library Pythonimport cv2import matplotlib.pyplot as plt Reading Video With the Code below, you can load and show the video on window “video”. Python# video readVideo1 = &quot;test2.mp4&quot;Video2 = &quot;output.avi&quot;# acquiring the fps and the size of the Video onefps_c1 = cap1.get(cv2.CAP_PROP_FPS)Video_h1 = cap1.get(cv2.CAP_PROP_FRAME_HEIGHT)Video_w1 = cap1.get(cv2.CAP_PROP_FRAME_WIDTH)while (True): ret,frame=cap.read() cv2.imshow(&quot;video&quot;,frame) if cv2.waitKey(1)&amp;0xFF==ord('q'): cv2.destroyAllWindows() break Combine Two Frames def Fram_connect(fram1, frame2, h = Video_h, w = Video_w): frame2 = cv2.resize(frame2, (int(Video_w), int(Video_h)), interpolation = cv2.INTER_AREA) BG = cv2.resize(frame1, (int(Video_w * 2), int(Video_h)), interpolation = cv2.INTER_AREA) BG[0:int(Video_h),0:int(Video_w)] = frame1 BG[0:int(Video_h),int(Video_w):int(Video_w*2)] = frame2 return (BG) Write the result fps = fps_csize = (1920, 1080)fourcc = cv2.VideoWriter_fourcc('M','J','P','G')videowriter = cv2.VideoWriter(OUTPUT + &quot;.avi&quot;,fourcc,fps,size)while (True): ret,frame1=cap1.read() ret,frame2=cap2.read() img = Fram_connect(frame1, frame2, Video_w, Video_h, Video_w2, Video_h2) img = cv2.resize(img, size, interpolation = cv2.INTER_AREA) videowriter.write(img)videowriter.write(frame) Result import argparseparser = argparse.ArgumentParser()parser.add_argument('-i','-I','--input',nargs='+', help='Input vedio file') #输入文件parser.add_argument('-o','-U','--output', default = &quot;combine_result.avi&quot;, help='Output vedio file, default as &quot;combine_result.avi&quot;') #输入文件parser.add_argument('-f','-F','--FPS', type = int, help='Start from X second. default is the same as the first video') #输入文件parser.add_argument('-w','-W','--window', nargs='?', help='1920x1080 default is the combined size of two vedio') #输入文件#获取参数args = parser.parse_args()File = args.inputOUTPUT = args.outputWindow = args.windowfps = args.FPSimport cv2# function for combined two frames.def Fram_connect(fram1, frame2, Video_w, Video_h, Video_w2, Video_h2): frame2 = cv2.resize(frame2, (int(Video_w2), int(Video_h)), interpolation = cv2.INTER_AREA) BG = cv2.resize(frame1, (int(Video_w + Video_w2), int(Video_h)), interpolation = cv2.INTER_AREA) BG[0:int(Video_h),0:int(Video_w)] = frame1 BG[0:int(Video_h),int(Video_w):int(Video_w+ Video_w2)] = frame2 return (BG)Video1 = File[0]Video2 = File[1]cap1=cv2.VideoCapture(Video1)cap2=cv2.VideoCapture(Video2)# The video 1 set the video 1 as the default size and fpsfps_c = cap1.get(cv2.CAP_PROP_FPS)Video_h = cap1.get(cv2.CAP_PROP_FRAME_HEIGHT)Video_w = cap1.get(cv2.CAP_PROP_FRAME_WIDTH)fps_c2 = cap2.get(cv2.CAP_PROP_FPS)Video_h2 = cap2.get(cv2.CAP_PROP_FRAME_HEIGHT)Video_w2 = cap2.get(cv2.CAP_PROP_FRAME_WIDTH)# args for the video outputfps = fps_cif Window == None: size = (int(Video_w+Video_w2), int(Video_h))else: size = (int(Window.split(&quot;x&quot;)[0]), int(Window.split(&quot;x&quot;)[1]))fourcc = cv2.VideoWriter_fourcc('M','J','P','G')videowriter = cv2.VideoWriter(OUTPUT + &quot;.avi&quot;,fourcc,fps,size)while (True): ret,frame1=cap1.read() ret,frame2=cap2.read() img = Fram_connect(frame1, frame2, Video_w, Video_h, Video_w2, Video_h2) img = cv2.resize(img, size, interpolation = cv2.INTER_AREA) videowriter.write(img) if cv2.waitKey(1) &amp; 0xFF == ord('q'): cv2.destroyAllWindows() breakvideowriter.write(frame) Two videos are combined to into a frame aligned by left-right digraph F { rankdir = UD; readV [label = \"Reading Video\"] acc [label = \"Access the frame and size\"] resize [label = \"Resize the video 2\"] readV -> acc -> resize } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });","link":"/2021/04/10/Python/opencv-v-paste/"},{"title":"Pytessaract: OCR Tool in Python","text":"Pytessaract: ORC Tool in Python Prepare: Tesseract Tesseract install manual In Linux sudo apt install tesseract-ocrsudo apt install libtesseract-dev# usage:tesseract 123.pmg 123.txt Pytessaract Reference: © Sandun Amarathunga pip install Pytessaract import cv2import pytesseractimg = cv2.imread(“images/002.png”) # read an imagetext = pytesseract.image_to_string(img) # extract textprint(text) Other languages support Github When you don’t have the language model: tesseract -l chi_sim test.png test.txt Error opening data file /usr/share/tesseract-ocr/4.00/tessdata/chi_sim.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language 'chi_sim' Tesseract couldn't load any languages! Could not initialize tesseract. cd /usr/share/tesseract-ocr/4.00/mv tessdata tessdata_bcgit clone https://github.com/tesseract-ocr/tessdata.git","link":"/2022/08/02/Python/orc/"},{"title":"pip","text":"pip ## 清华pip install -i https://pypi.tuna.tsinghua.edu.cn/simple## 豆瓣pip install -i http://pypi.douban.com/simple/ --upgrade numpy pip install -t /usr/local/lib/python2.7/site-packages/ xlrd sudo pip3.7 install -i https://pypi.tuna.tsinghua.edu.cn/simple list pip list Package Version -------------------- -----------absl-py 0.9.0 aiohttp 3.6.2 allow 0.0.3 alot 0.9 appdirs 1.4.3 show pip show opencv-python'''Name: opencv-pythonVersion: 4.1.2.30Summary: Wrapper package for OpenCV python bindings.Home-page: https://github.com/skvark/opencv-pythonAuthor: NoneAuthor-email: NoneLicense: MITLocation: /usr/local/lib/python3.7/site-packagesRequires: numpyRequired-by:'''","link":"/2020/01/22/Python/pip/"},{"title":"popmail-Python 登录邮箱","text":"popmail-Python 登录邮箱 登录 以ＱＱ邮箱为例 import poplib## 输入邮件地址, 口令和POP3服务器地址:email = '591465908@qq.com'password = input('Password: ') #这里是授权码，必须去申请pop3_server = 'pop.qq.com'## 连接到POP3服务器:server = poplib.POP3(pop3_server)## 可以打开或关闭调试信息:server.set_debuglevel(1)## 可选:打印POP3服务器的欢迎文字:print(server.getwelcome().decode('utf-8'))## 身份认证:server.user(email)server.pass_(password) 授权码申请：https://service.mail.qq.com/cgi-bin/help?subtype=1&amp;&amp;id=28&amp;&amp;no=1001256 server.set_debuglevel(1)## debug 信息， 会打印出账号和密码， 不建议使用server.apop( server.noop( server.stat(server.capa( server.pass_( server.stls(server.close( server.port server.timestampserver.dele( server.quit( server.top(server.encoding server.retr( server.uidl(server.file server.rpop( server.user(server.getwelcome( server.rset( server.utf8(server.host server.set_debuglevel( server.welcomeserver.list( server.sock","link":"/2020/01/22/Python/popmail/"},{"title":"Python: Find the outline (edge) of the 2D points","text":"Python: Find the outline (edge) of the 2D points This passage is for showing how to find the boundary of a group of the point. One major problem of boundary searching is the groove. I rigid groove threshold may cut the points into two or more groups. For the flexibility of the script, the perimeter alpha was set for determining the threshold of the boundary. The larger alpha value, the more tolerance for the grooves. from scipy.spatial import Delaunayimport numpy as nppoints = np.array([[262, 451], [262, 452], [263, 450], [263, 451], [263, 452], [263, 453], [264, 449], [264, 450], [264, 451], [264, 452], [264, 453], [264, 454], [265, 449], [265, 450], [265, 451], [265, 452], [265, 453], [265, 454], [265, 455], [265, 456], [265, 457], [265, 458], [266, 449], [266, 450], [266, 451], [266, 452], [266, 453], [266, 454], [266, 455], [266, 456], [266, 457], [266, 458], [266, 459], [267, 449], [267, 450], [267, 451], [267, 452], [267, 453], [267, 454], [267, 455], [267, 456], [267, 457], [267, 458], [267, 459], [267, 460], [268, 450], [268, 451], [268, 452], [268, 453], [268, 454], [268, 455], [268, 456], [268, 457], [268, 458], [268, 459], [268, 460], [269, 450], [269, 451], [269, 452], [269, 453], [269, 454], [269, 455], [269, 456], [269, 457], [269, 458], [270, 450], [270, 451], [270, 452], [270, 453], [270, 454], [270, 455], [270, 456], [270, 457], [270, 458], [270, 459], [271, 451], [271, 452], [271, 453], [271, 454], [271, 455], [271, 456], [271, 457], [271, 458], [272, 451], [272, 452], [272, 453], [272, 454], [272, 455], [272, 456], [272, 457], [273, 451], [273, 452], [273, 453], [273, 454], [273, 455], [273, 456], [274, 452], [274, 453], [274, 454], [274, 455]]) Functions: Iddo Hanniel; 2018 def alpha_shape(points, alpha, only_outer=True): &quot;&quot;&quot; Compute the alpha shape (concave hull) of a set of points. :param points: np.array of shape (n,2) points. :param alpha: alpha value. :param only_outer: boolean value to specify if we keep only the outer border or also inner edges. :return: set of (i,j) pairs representing edges of the alpha-shape. (i,j) are the indices in the points array. &quot;&quot;&quot; assert points.shape[0] &gt; 3, &quot;Need at least four points&quot; def add_edge(edges, i, j): &quot;&quot;&quot; Add an edge between the i-th and j-th points, if not in the list already &quot;&quot;&quot; if (i, j) in edges or (j, i) in edges: # already added assert (j, i) in edges, &quot;Can't go twice over same directed edge right?&quot; if only_outer: # if both neighboring triangles are in shape, it's not a boundary edge edges.remove((j, i)) return edges.add((i, j)) tri = Delaunay(points) edges = set() # Loop over triangles: # ia, ib, ic = indices of corner points of the triangle for ia, ib, ic in tri.vertices: pa = points[ia] pb = points[ib] pc = points[ic] # Computing radius of triangle circumcircle # www.mathalino.com/reviewer/derivation-of-formulas/derivation-of-formula-for-radius-of-circumcircle a = np.sqrt((pa[0] - pb[0]) ** 2 + (pa[1] - pb[1]) ** 2) b = np.sqrt((pb[0] - pc[0]) ** 2 + (pb[1] - pc[1]) ** 2) c = np.sqrt((pc[0] - pa[0]) ** 2 + (pc[1] - pa[1]) ** 2) s = (a + b + c) / 2.0 area = np.sqrt(s * (s - a) * (s - b) * (s - c)) circum_r = a * b * c / (4.0 * area) if circum_r &lt; alpha: add_edge(edges, ia, ib) add_edge(edges, ib, ic) add_edge(edges, ic, ia) return edges Usage: import matplotlib.pyplot as plt# Plotting the outputfig, ax = plt.subplots(figsize=(18,4))edges = alpha_shape(points, alpha=1, only_outer=True)plt.subplot(1, 3, 1)plt.plot(points[:, 0], points[:, 1], '.')for i, j in edges: plt.plot(points[[i, j], 0], points[[i, j], 1])plt.text(270.5,459, &quot;alpha=1&quot;, size=18)edges = alpha_shape(points, alpha=2, only_outer=True)plt.subplot(1, 3, 2)plt.plot(points[:, 0], points[:, 1], '.')for i, j in edges: plt.plot(points[[i, j], 0], points[[i, j], 1])plt.text(270.5,459, &quot;alpha=2&quot;, size=18)edges = alpha_shape(points, alpha=10, only_outer=True)plt.subplot(1, 3, 3)plt.plot(points[:, 0], points[:, 1], '.')for i, j in edges: plt.plot(points[[i, j], 0], points[[i, j], 1])plt.text(270.5,459, &quot;alpha=10&quot;, size=18)plt.show()","link":"/2022/03/07/Python/point_outline/"},{"title":"Python GAM to fit","text":"Python GAM to fit Source: pygam import numpy as npimport matplotlib.pyplot as pltfrom pygam import LinearGAM, s, tefrom pygam.datasets import mcycle# X = np.array([ [i] for i in Cell_fit.Class_size.to_list()])# y = np.array(Cell_fit.Size.to_list())X, y = mcycle(return_X_y=True)gam = LinearGAM(n_splines=25).gridsearch(X, y)XX = gam.generate_X_grid(term=0, n=500)plt.plot(XX, gam.predict(XX), 'r--')plt.plot(XX, gam.prediction_intervals(XX, width=.95), color='b', ls='--')plt.scatter(X, y, facecolor='gray', edgecolors='none')plt.title('95% prediction interval'); © pyGAM Regression by numpy Source: W3 school x = X.flatten()y = y.to_list()mymodel = np.poly1d(np.polyfit(x, y, 3))myline = np.linspace(2, 95, 100)plt.scatter(x, y)plt.plot(myline, mymodel(myline))plt.show() Other X, y = mcycle(return_X_y=True)gam = LogisticGAM(f(0) + s(1) + s(2)).gridsearch(X, y)fig, axs = plt.subplots(1, 3)titles = ['student', 'balance', 'income']for i, ax in enumerate(axs): XX = gam.generate_X_grid(term=i) pdep, confi = gam.partial_dependence(term=i, width=.95) ax.plot(XX[:, i], pdep) ax.plot(XX[:, i], confi, c='r', ls='--') ax.set_title(titles[i]);","link":"/2022/03/31/Python/py-gam/"},{"title":"Progress Bar in Python","text":"tqdm The tqdm package in Python provides a fast, extensible progress bar for loops and other iterable objects. It was used in pip intall. Here’s a simple example: from tqdm import tqdmimport time# Create a list of numbersnumbers = range(100)# Wrap your iterable with tqdm()for i in tqdm(numbers): # Simulate some work time.sleep(0.01) rich from rich.progress import trackimport time# Create a list of numbersnumbers = range(100)# Wrap your iterable with track()for i in track(numbers, description=&quot;Processing...&quot;): # Simulate some work time.sleep(0.01) track() works similarly to tqdm’s wrapper. It takes an iterable and a description for the task, and returns an iterator that produces the same values as the original, but also updates a progress bar in the console as it iterates over the items. The description parameter allows you to set a text description for the task that is displayed next to the progress bar. Like tqdm, rich offers a variety of options to customize the appearance and behavior of the progress bar. You can find more details in the rich documentation. progressbar cite: sanjaydokula import timeimport progressbar widgets = [' [', progressbar.Timer(format= 'elapsed time: %(elapsed)s'), '] ', progressbar.Bar('*'),' (', progressbar.ETA(), ') ', ] bar = progressbar.ProgressBar(max_value=200, widgets=widgets).start() for i in range(200): time.sleep(0.1) bar.update(i) light-progress cite: @itkr from time import sleepfrom light_progress.commandline import ProgressBarn = 42progress_bar = ProgressBar(n)progress_bar.start()for item in range(n): sleep(0.01) progress_bar.forward()progress_bar.finish() from time import sleepfrom light_progress.commandline import ProgressBarn = 42progress_bar = ProgressBar(n)progress_bar.start()for item in range(n): sleep(0.01) progress_bar.forward()progress_bar.finish()import timeimport progressbar widgets = [' [', progressbar.Timer(format= 'elapsed time: %(elapsed)s'), '] ', progressbar.Bar('*'),' (', progressbar.ETA(), ') ', ] bar = progressbar.ProgressBar(max_value=20, widgets=widgets).start() for i in range(20): time.sleep(0.1) bar.update(i)from rich.progress import trackimport time# Create a list of numbersnumbers = range(100)# Wrap your iterable with track()for i in track(numbers, description=&quot;Processing...&quot;): # Simulate some work time.sleep(0.01)from tqdm import tqdmimport time# Create a list of numbersnumbers = range(100)# Wrap your iterable with tqdm()for i in tqdm(numbers): # Simulate some work time.sleep(0.01) pre { background-color:#38393d; color: #5fd381; }","link":"/2023/07/10/Python/progressbar/"},{"title":"pynput --Moniter your keybaord","text":"pynput --Moniter your keybaord 1. Mouse 1.1 Mouse Controller from pynput.mouse import Button, Controllermouse = Controller()## Read pointer positionprint('The current pointer position is {0}'.format( mouse.position))## Set pointer positionmouse.position = (10, 20)print('Now we have moved it to {0}'.format(mouse.position))## Move pointer relative to current positionmouse.move(5, -5)## Press and releasemouse.press(Button.left)mouse.release(Button.left)while True: mouse.press(Button.left)## Double click; this is different from pressing and releasing## twice on Mac OSXmouse.click(Button.left, 2)## Scroll two steps downmouse.scroll(0, 2) 1.2 Mouse Monitor ##监控鼠标事件from pynput import mousedef on_move(x, y ): print('Pointer moved to {o}'.format( (x,y)))def on_click(x, y , button, pressed): print('{0} at {1}'.format('Pressed' if pressed else 'Released', (x, y))) if not pressed: return Falsedef on_scroll(x, y ,dx, dy): print('scrolled {0} at {1}'.format( 'down' if dy &lt; 0 else 'up', (x, y)))while True: with mouse.Listener( no_move = on_move,on_click = on_click,on_scroll = on_scroll) as listener: listener.join() 2. Keybaord 2.1 Keyboard Controller ##键盘输入用法from pynput.keyboard import Key, Controllerkeyboard = Controller()##Press and release spacekeyboard.press(Key.space)keyboard.release(Key.space)keyboard.press(Key.left)keyboard.release(Key.left)##Type a lower case A ;this will work even if no key on the physical keyboard is labelled 'A'keyboard.press('a')keyboard.release('a')##Type two upper case Askeyboard.press('A')keyboard.release('A')## orwith keyboard .pressed(Key.shift): keyboard.press('a') keyboard.release('a')##type 'hello world ' using the shortcut type methodkeyboard.type('hello world') 2.2 Keyboard Monitor ##键盘监听from pynput import keyboarddef on_press(key): try: print('alphanumeric key {0} pressed'.format(key.char)) except AttributeError: print('special key {0} pressed'.format(key))def on_release(key): print('{0} released'.format(key)) if key == keyboard.Key.esc: return Falsewhile True: with keyboard.Listener( on_press = on_press, on_release = on_release) as listener: listener.join()","link":"/2020/01/22/Python/pynput/"},{"title":"Python Challenge for Beginner | rosalind","text":"Notation: Those Challenges come from Rosalind Introduction Function: def run(a, b): Result = a + b print(&quot;hello function&quot;) return Result Function test: C = run(1 , 5)print(C) hello function 6 Let the fun begin! Calculate Link Given: Two positive integers a and b, each less than 1000. Return: The integer corresponding to the square of the hypotenuse of the right triangle whose legs have lengths a and b. in: 3 5 out: 34 def run(a, b): Result = (a+b)**2 - 2ab print(Result)run(3, 4) String splice Link Given: A string s of length at most 200 letters and four integers a, b, c and d. Return: The slice of this string from indices a through b and c through d (with space in between), inclusively. In other words, we should include elements s[b] and s[d] in our slice. in: HumptyDumptysatonawallHumptyDumptyhadagreatfallAlltheKingshorsesandalltheKingsmenCouldntputHumptyDumptyinhisplaceagain. 22 27 97 102 out: Humpty Dumpty def run(Str, a, b, c, d): Result = Str[a:b+1] + &quot; &quot; Str[c:d+1] print(Result)Str = &quot;HumptyDumptysatonawallHumptyDumptyhadagreatfallAlltheKingshorsesandalltheKingsmenCouldntputHumptyDumptyinhisplaceagain.&quot;a = 22; b = 27; c = 97; d = 102run(Str, a, b, c, d) loop Link Given: Two positive integers a and b (a&lt;b&lt;10000). Return: The sum of all odd integers from a through b, inclusively. in: 100 200 out: 7500 def run(a, b): List = [a, b] List.sort() Result = 0 for i in range(List[0], List[1]+1): if i % 2 == 1: Result += i print(Result)run(100, 200) Reading and writing Link Given: A file containing at most 1000 lines. Return: A file containing all the even-numbered lines from the original file. Assume 1-based numbering of lines. def run(INPUT, OUTPUT): In = open(INPUT, 'r').readlines() Num = 0 Result = &quot;&quot; for i in In: if Num % 2 == 1: Result += i Num += 1 print(Result) F = open(OUTPUT, 'w') F.write(Result) F.close() Words count Link Given: A string s of length at most 10000 letters. Return: The number of occurrences of each word in s, where words are separated by spaces. Words are case-sensitive, and the lines in the output can be in any order. In: We tried list and we tried dicts also we tried Zen Out: and 1 We 1 tried 3 dicts 1 list 1 we 2 also 1 Zen 1 def run(Str): List = Str.split(&quot; &quot;) Index = list(set(List)) Result = &quot;&quot; for i in Index: if i != &quot;&quot;: Result += i +&quot; &quot; + str(List.count(i)) +&quot;\\n&quot; print(Result)","link":"/2021/03/29/Python/python-begin1/"},{"title":"Pyhtnon: 2D Dengsity Plot","text":"Pyhtnon: 2D Density Plot Easiest way in seaborn In seaborn, you can plot the 2D density plot with minimal codes. But it talks for a while to calculate the distribution and fit them into plots. More details for seaborn: Click here import seaborn as snsgeyser = sns.load_dataset(&quot;geyser&quot;)sns.kdeplot(data=geyser, x=&quot;waiting&quot;, y=&quot;duration&quot;, hue=&quot;kind&quot;) © Seaborn Pictures from: © Seaborn fill=True levels=5, thresh=.2 fill=True, thresh=0, levels=100, cmap=&quot;mako&quot; Tutorial from Another amazing tutorial I found is from Madalina Ciortan, 2019. The quickist way The quickist way to show the density distribution of all dots would be using matplotlib directly. from matplotlib.colors import LogNormfrom matplotlib import pyplot as plth =plt.hist2d(geyser.duration, geyser.waiting, bins= 30, norm=LogNorm(), cmap=&quot;coolwarm&quot;)plt.colorbar(h[3])plt.show() More fancy way It would be take some time for fitting the gaussian kernel. But it still way fast than using Seaborn directly. x = geyser.duration.to_numpy()y = geyser.waiting.to_numpy()deltaX = (max(x) - min(x))/10deltaY = (max(y) - min(y))/10xmin = min(x) - deltaXxmax = max(x) + deltaXymin = min(y) - deltaYymax = max(y) + deltaYprint(xmin, xmax, ymin, ymax)# Create meshgridxx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]positions = np.vstack([xx.ravel(), yy.ravel()])values = np.vstack([x, y])kernel = st.gaussian_kde(values)f = np.reshape(kernel(positions).T, xx.shape)fig = plt.figure(figsize=(8,8))ax = fig.gca()ax.set_xlim(xmin, xmax)ax.set_ylim(ymin, ymax)cfset = ax.contourf(xx, yy, f, cmap='coolwarm')#ax.imshow(np.rot90(f), cmap='coolwarm', extent=[xmin, xmax, ymin, ymax])cset = ax.contour(xx, yy, f, colors='k')ax.clabel(cset, inline=1, fontsize=10)ax.set_xlabel('X')ax.set_ylabel('Y')plt.title('2D Gaussian Kernel density estimation') from mpl_toolkits.mplot3d import Axes3Dfig = plt.figure(figsize=(13, 7))ax = plt.axes(projection='3d')surf = ax.plot_surface(xx, yy, f, rstride=1, cstride=1, cmap='coolwarm', edgecolor='none')ax.set_xlabel('x')ax.set_ylabel('y')ax.set_zlabel('PDF')ax.set_title('Surface plot of Gaussian 2D KDE')fig.colorbar(surf, shrink=0.5, aspect=5) # add color bar indicating the PDFax.view_init(60, 35) Something else There is another exmple from stackoverflow by Flabetvibes, 2015. It works fine with the example data. But I just don’t know how to adjust the arguments for fit my data. import numpy as npimport matplotlib.pyplot as plimport scipy.stats as stdata = np.random.multivariate_normal((0, 0), [[0.8, 0.05], [0.05, 0.7]], 100)x = data[:, 0]y = data[:, 1]xmin, xmax = -3, 3ymin, ymax = -3, 3# Peform the kernel density estimatexx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]positions = np.vstack([xx.ravel(), yy.ravel()])values = np.vstack([x, y])kernel = st.gaussian_kde(values)f = np.reshape(kernel(positions).T, xx.shape)fig = pl.figure()ax = fig.gca()ax.set_xlim(xmin, xmax)ax.set_ylim(ymin, ymax)# Contourf plotcfset = ax.contourf(xx, yy, f, cmap='Blues')## Or kernel density estimate plot instead of the contourf plot#ax.imshow(np.rot90(f), cmap='Blues', extent=[xmin, xmax, ymin, ymax])# Contour plotcset = ax.contour(xx, yy, f, colors='k')# Label plotax.clabel(cset, inline=1, fontsize=10)ax.set_xlabel('Y1')ax.set_ylabel('Y0')pl.show() © Flabetvibes","link":"/2022/06/17/Python/python-2D-density-plot/"},{"title":"A quick guide for seaborn plot in python","text":"Searborn import seaborn as sns Countplot source: seaborn.pydata.org import seaborn as snssns.set_theme(style=&quot;darkgrid&quot;)titanic = sns.load_dataset(&quot;titanic&quot;)ax = sns.countplot(x=&quot;class&quot;, data=titanic) Title fig, ax = plt.subplots()ax.set(title='Points vs. Assists')# orax.set_title(&quot;Title&quot;,fontsize=50) © Zach; 2021 Axis Axis text rotation fig, ax = plt.subplots()ax.set_xticklabels(ax.get_xticklabels(),rotation = 30) © delftstack; 2021 Labels Reference: armatita; 2016 fig, ax = plt.subplots()ax.set_xlabel(&quot;X Label&quot;,fontsize=30) © armatita; 2016 Limits fig, ax = plt.subplots()ax.set_xlim(0, 1)ax.set_ylim(0, 1) Ledgend remove # works on parts of plotsns.scatterplot(y = s_y, x = s_x, hue = cat, legend = False)# using function from matplotlibplt.legend([],[], frameon=False)","link":"/2021/11/06/Python/seaborn/"},{"title":"Python: Cell masks result analysis","text":"Image mask to data frame pre { background-color:#38393d; color: #5fd381; } In this blog, I’ll show some tricks I used in cell marks processing. The data could be any kind of image or file. I am using CellPose to detect cells and get the mask. With this result, we can do quantification and size calculations. By comparing the raw image, we can also get the gray intensity or so. But of course, we are not just want to do the basic counts like that. We’d like to do more. In this post, I’ll show how to plot the cell based on the mask result, label the ID of each cell, calculate the Voronoi spacial, and finally determine the adjacent cells. More related techniques would be updated if I had some new ideas and tasks. RGB image This code could turn your image to an pandas data frame. x and y would be list to the first two columns and color values would following. IMG = cv.imread()A = IMG# Create the multiindex we'll need for the seriesindex = pd.MultiIndex.from_product( (*map(range, A.shape[:2]), ('r', 'g', 'b')), names=('col','row', None))# Can be chained but separated for use in explanationdf = pd.Series(A.flatten(), index=index)df = df.unstack()df = df.reset_index().reindex(columns=['row', 'col', 'r', 'g'. 'b'])sns.scatterplot(data=df[df.r!=0], x= &quot;row&quot;, y=&quot;col&quot;, hue = &quot;r&quot;)plt.show() grey/mask fill For CellPose, we can save the result as npy. Both raw image and mask results are saved in it. After read the npy file, we still need to convert them into DataFrame for further calculation. import cv2import pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport seaborn as snsNP_result = np.load(&quot;lgl.3d.casp.1.lsm2_seg.npy&quot;, allow_pickle=True)A = NP_result.all()['masks']# Create the multiindex we'll need for the seriesindex = pd.MultiIndex.from_product( (*map(range, A.shape[:2]), (['r'])), names=('col','row', None))# Can be chained but separated for use in explanationdf = pd.Series(A.flatten(), index=index)df = df.unstack()df = df.reset_index().reindex(columns=['row', 'col', 'r'])sns.scatterplot(data=df[df.r!=0], x= &quot;row&quot;, y=&quot;col&quot;, hue = &quot;r&quot;)plt.show() Example data For save the time and have more detailed presentation, I only selected 30 cells to run the test which achieved very good results. I also applied this pipeline into the whole data and also in some other samples which also has thousands of cell and achieved very promising results. df = df[df.r != 0]df = df[df.r.isin(range(10,40))]fig, ax = plt.subplots(figsize = ((df.row.max() - df.row.min())/28, (df.col.max() - df.col.min())/28))sns.scatterplot(data=df, x= &quot;row&quot;, y=&quot;col&quot;, hue = &quot;r&quot;, linewidth = 0, palette= &quot;Paired&quot;, legend = None )fig.savefig(&quot;123.png&quot;)plt.show() Show labels of each cell # calculate the position for each labelLabel_TB = pd.DataFrame()for ID in df.r.unique(): TMP = df[df.r==ID] TMP_TB = pd.DataFrame(TMP.mean()).T Label_TB = pd.concat([Label_TB, pd.DataFrame(TMP.mean()).T]) Now, we can add the text into the cells fig, ax = plt.subplots(figsize = ((df.row.max() - df.row.min())/28, (df.col.max() - df.col.min())/28))sns.scatterplot(data=df, x= &quot;row&quot;, y=&quot;col&quot;, hue = &quot;r&quot;, linewidth = 0, palette= &quot;Paired&quot;, legend = None )for index in range(len(Label_TB)): plt.text(x= Label_TB.row.iloc[index], y=Label_TB.col.iloc[index], s= str(int(Label_TB.r.iloc[index])), horizontalalignment='center', verticalalignment='center',)#fig.savefig(&quot;123.png&quot;)plt.show() Delaunay triangulation to find adjacent cells scipy.spatial.Delaunay from scipy.spatial import DelaunayLabel_TBpoints = Label_TB[['row', 'col']].to_numpy()tri = Delaunay(points)fig, ax = plt.subplots(figsize = ((df.row.max() - df.row.min())/28, (df.col.max() - df.col.min())/28))sns.scatterplot(data=df, x= &quot;row&quot;, y=&quot;col&quot;, hue = &quot;r&quot;, linewidth = 0, palette= &quot;Paired&quot;, legend = None )plt.triplot(points[:,0], points[:,1], tri.simplices,color=&quot;white&quot;)plt.plot(points[:,0], points[:,1], '.', color=&quot;black&quot;)plt.show() from collections import defaultdictimport itertoolsneiList=defaultdict(set)for p in tri.vertices: for i,j in itertools.combinations(p,2): neiList[i].add(j) neiList[j].add(i)neiList array([[593.98529412, 253.70588235], [516.17708333, 257.85416667], [543.86111111, 254.44444444], [494.31137725, 259.5508982 ], ... Voronoi Spacial Basic codes and results from scipy.spatial import Voronoi, voronoi_plot_2dvor = Voronoi(points)voronoi_plot_2d(vor)plt.show() Hijack the Voronoi results Points of the vertices: vor.vertices List of point index for single region: vor.regions Index of the each region: vor.point_region vor.vertices array([[ 4.40328347e+02, 3.18467250e+02], [ 4.42571096e+02, 2.99374609e+02], [ 6.25590093e+02, 2.70367860e+02], [ 6.75342190e+02, 2.17296792e+02], [ 6.57120671e+02, 3.34527573e+02], ... vor.regions [[1, -1, 0], [5, 3, 4], [8, 2, 5, 3, -1, 7], [10, 4, 5, 2, 9], [-1, 3, 4, 10], ... vor.point_region array([14, 17, 25, 28, 6, 2, 12, 10, 16, 21, 22, 24, 20, 19, 13, 9, 1, 27, 26, 23, 0, 18, 29, 7, 3, 5, 15, 8, 4, 30]) For example, for the cell 24, which is 14 in index, we can have: All Vertices: Index = 14[Vertic for Vertic in vor.ridge_vertices if Vertic[0] in vor.regions[vor.point_region[Index]] and Vertic[1] in vor.regions[vor.point_region[Index]]] [[18, 19], [15, 18], [24, 25], [6, 25], [6, 19], [15, 24]] Index = 0fig, ax = plt.subplots(figsize = ((df.row.max() - df.row.min())/28, (df.col.max() - df.col.min())/28))sns.scatterplot(data=df, x= &quot;row&quot;, y=&quot;col&quot;, hue = &quot;r&quot;, linewidth = 0, palette= &quot;Paired&quot;, legend = None )for index in range(len(Label_TB)): plt.text(x= Label_TB.row.iloc[index], y=Label_TB.col.iloc[index], s= str(int(Label_TB.r.iloc[index])), horizontalalignment='center', verticalalignment='center',)for Re in vor.regions[vor.point_region[Index]]: [sns.lineplot(x=vor.vertices[line][:,0], y = vor.vertices[line][:,1]) for line in vor.ridge_vertices if -1 not in line and Re in line]sns.lineplot([1,1],[1,1]).set(xlim=(df.row.min(),df.row.max()), ylim=(df.col.min(),df.col.max()))plt.show() More precisely, we can have the vertices for a single polygon: sns.scatterplot(data=df[df.r==24], x= &quot;row&quot;, y=&quot;col&quot;, hue = &quot;r&quot;, linewidth = 0, palette= &quot;Paired&quot;, legend = None )plt.text(x= Label_TB.row.iloc[Index], y=Label_TB.col.iloc[Index], s= str(int(Label_TB.r.iloc[Index])), horizontalalignment='center', verticalalignment='center',)for line in [Vertic for Vertic in vor.ridge_vertices if Vertic[0] in vor.regions[vor.point_region[Index]] and Vertic[1] in vor.regions[vor.point_region[Index]]]: sns.lineplot(x=vor.vertices[line][:,0], y = vor.vertices[line][:,1])plt.show() Resolution for cont adjacent cells calculate the points for the boundary Add the boundary points to the group and calculate the Voronoi Spacial Calculate adjacent points by Delaunay Correct Adjacent points by shared boundary Boundary points Codes define the function def alpha_shape(points, alpha, only_outer=True): &quot;&quot;&quot; Compute the alpha shape (concave hull) of a set of points. :param points: np.array of shape (n,2) points. :param alpha: alpha value. :param only_outer: boolean value to specify if we keep only the outer border or also inner edges. :return: set of (i,j) pairs representing edges of the alpha-shape. (i,j) are the indices in the points array. &quot;&quot;&quot; assert points.shape[0] &gt; 3, &quot;Need at least four points&quot; def add_edge(edges, i, j): &quot;&quot;&quot; Add an edge between the i-th and j-th points, if not in the list already &quot;&quot;&quot; if (i, j) in edges or (j, i) in edges: # already added assert (j, i) in edges, &quot;Can't go twice over same directed edge right?&quot; if only_outer: # if both neighboring triangles are in shape, it's not a boundary edge edges.remove((j, i)) return edges.add((i, j)) tri = Delaunay(points) edges = set() # Loop over triangles: # ia, ib, ic = indices of corner points of the triangle for ia, ib, ic in tri.vertices: pa = points[ia] pb = points[ib] pc = points[ic] # Computing radius of triangle circumcircle # www.mathalino.com/reviewer/derivation-of-formulas/derivation-of-formula-for-radius-of-circumcircle a = np.sqrt((pa[0] - pb[0]) ** 2 + (pa[1] - pb[1]) ** 2) b = np.sqrt((pb[0] - pc[0]) ** 2 + (pb[1] - pc[1]) ** 2) c = np.sqrt((pc[0] - pa[0]) ** 2 + (pc[1] - pa[1]) ** 2) s = (a + b + c) / 2.0 area = np.sqrt(s * (s - a) * (s - b) * (s - c)) circum_r = a * b * c / (4.0 * area) if circum_r &lt; alpha: add_edge(edges, ia, ib) add_edge(edges, ib, ic) add_edge(edges, ic, ia) return edges Calculate the index of edge-points Points = df[['row', 'col']].to_numpy()edges = alpha_shape(Points, alpha=500, only_outer=True)fig, ax = plt.subplots(figsize = ((df.row.max() - df.row.min())/28, (df.col.max() - df.col.min())/28))sns.scatterplot(data=df, x= &quot;row&quot;, y=&quot;col&quot;, hue = &quot;r&quot;, linewidth = 0, palette= &quot;Paired&quot;, legend = None ).invert_yaxis()for i, j in edges: plt.plot(Points[[i, j], 0], Points[[i, j], 1], color=&quot;white&quot;)plt.show() Calculate Voronoi space with edge-points # Collect edge-pointsEdges = np.array([[i[0], i[1]]for i in edges]).ravel()Edges = np.unique(Edges)Edge_points = np.array([Points[i] for i in Edges])points = Label_TB[['row', 'col']].to_numpy()Vo_Point = (np.concatenate([points, Edge_points]))vor = Voronoi(Vo_Point)voronoi_plot_2d(vor) fig, ax = plt.subplots(figsize = ((df.row.max() - df.row.min())/28, (df.col.max() - df.col.min())/28))sns.scatterplot(data=df, x= &quot;row&quot;, y=&quot;col&quot;, hue = &quot;r&quot;, linewidth = 0, palette= &quot;Paired&quot;, legend = None )for index in range(len(Label_TB)): plt.text(x= Label_TB.row.iloc[index], y=Label_TB.col.iloc[index], s= str(int(Label_TB.r.iloc[index])), horizontalalignment='center', verticalalignment='center',)#plt.imshow(NP_result.all()['img'])[sns.lineplot(x=vor.vertices[line][:,0], y = vor.vertices[line][:,1]) for line in vor.ridge_vertices if -1 not in line]sns.lineplot([1,1],[1,1]).set(xlim=(df.row.min(),df.row.max()), ylim=(df.col.min(),df.col.max()))plt.show() Delaunay to determine near points from scipy.spatial import Delaunayfrom collections import defaultdictimport itertoolstri = Delaunay(points)neiList=defaultdict(set)for p in tri.vertices: for i,j in itertools.combinations(p,2): neiList[i].add(j) neiList[j].add(i) fig, ax = plt.subplots(figsize = ((df.row.max() - df.row.min())/28, (df.col.max() - df.col.min())/28))plt.triplot(points[:,0], points[:,1], tri.simplices, color=&quot;black&quot;)plt.plot(points[:,0], points[:,1], 'o')sns.scatterplot(data=df, x= &quot;row&quot;, y=&quot;col&quot;, hue = &quot;r&quot;, linewidth = 0, palette= &quot;Paired&quot;, legend = None )for index in range(len(Label_TB)): plt.text(x= Label_TB.row.iloc[index], y=Label_TB.col.iloc[index], s= str(int(Label_TB.r.iloc[index])), horizontalalignment='center', verticalalignment='center',)[sns.lineplot(x=vor.vertices[line][:,0], y = vor.vertices[line][:,1]) for line in vor.ridge_vertices if -1 not in line]sns.lineplot([1,1],[1,1]).set(xlim=(df.row.min(),df.row.max()), ylim=(df.col.min(),df.col.max()))plt.show() Correct Adjacent points by shared boundary def Get_vertices(Index, vor): return [Vertic for Vertic in vor.ridge_vertices if Vertic[0] in vor.regions[vor.point_region[Index]] and Vertic[1] in vor.regions[vor.point_region[Index]]]Adjacent_dic = {}for Source in neiList.keys(): Source_Vtc = Get_vertices(Source, vor) for Target in neiList[Source]: Tar_Vtc = Get_vertices(Target, vor) Result = [i for i in Tar_Vtc if i in Source_Vtc] if len(Result)!= 0 : print(Source+10, Target+10) Adjacent_dic = {}for Source in neiList.keys(): Source_Vtc = Get_vertices(Source, vor) for Target in neiList[Source]: Tar_Vtc = Get_vertices(Target, vor) Result = [i for i in Tar_Vtc if i in Source_Vtc] if len(Result)!= 0 : print(Source+1, Target+1) if Source + 1 not in Adjacent_dic.keys(): Adjacent_dic.update({Source+1: [Target+1]}) else: Adjacent_dic[Source+1] += [Target+1] Ellipse Regression (Fit) import cv2import numpy as npfrom matplotlib.patches import Ellipseimg = cv2.imread('mask.png', 0)img[img&gt;=63.22401581839193] = 255img[img&lt;=24.62768758842168,] = 255TMP = pd.DataFrame(img)TMP['Y'] = TMP.indexTMP_L = TMP.melt(id_vars='Y')TMP_L = TMP_L[TMP_L.value!= 255]# Convert data to the correct formatX = np.array([[i, ii] for i,ii in zip(x_points, y_points)])# Fit ellipseellipse = cv2.fitEllipse(TMP_L[['Y', &quot;variable&quot;]].to_numpy().astype(int))fig, ax = plt.subplots()ax.scatter(TMP_L.Y, TMP_L.variable)#ax.set_aspect(&quot;equal&quot;)ellipse_patch = Ellipse(ellipse[0], width=ellipse[1][0], height=ellipse[1][1], angle=ellipse[2], facecolor='red', alpha=0.5)ax.add_artist(ellipse_patch)plt.show() center: ellipse[0] major axis: ellipse[1][1] minor axis: ellipse[1][0] angle: ellipse[2] Calculate the point if it is in the ellipse from numpy.linalg import eig, invdef point_in_ellipse(point, center, width, height, angle): # Convert the point and center to the ellipse-centered coordinate system cos_a = np.cos(angle) sin_a = np.sin(angle) x, y = point[0] - center[0], point[1] - center[1] x_ = cos_a*x + sin_a*y y_ = -sin_a*x + cos_a*y cx, cy = 0, 0 # Calculate the semi-major and semi-minor axes of the transformed ellipse a_ = width/2 b_ = height/2 # Check if the transformed point is inside the unit circle if ((x_ - cx)/a_)**2 + ((y_ - cy)/b_)**2 &lt;= 1: return True else: return False# TMP_L is from the code aboveTMP_L['Color'] = [point_in_ellipse(TMP_L[['Y', 'variable']].iloc[i], ellipse[0], ellipse[1][0], ellipse[1][1], np.radians(ellipse[2])) for i in range(len(TMP_L))]plt.scatter(TMP_L.Y, TMP_L.variable, c = TMP_L.Color)plt.show()","link":"/2022/04/07/Python/py_cellmask/"},{"title":"Regression Examples in Scikit-learn|Python","text":"Regression Picture Index of Scikit-learn Linear Regression Non-negative least squares Common pitfalls in interpretation of coefficients of linear models Lasso and Elastic Net for Sparse Signals Compressive sensing: tomography reconstruction with L1 prior (Lasso) Lasso model selection: Cross-Validation / AIC / BIC Joint feature selection with multi-task Lasso Lasso and Elastic Net Lasso and Elastic Net for Sparse Signals Lasso and Elastic Net for Sparse Signals Polynomial regression: extending linear models with basis functions","link":"/2021/06/09/Python/sklearn-regression/"},{"title":"Navigating the Challenges of Sparse Datasets in Machine Learning","text":"Sparse datasets are ubiquitous in the machine learning landscape, and navigating the challenges they present is crucial for developing robust and efficient models. In this blog post, we’ll delve into why sparse datasets can cause poor performance in some machine learning algorithms, explore solutions to overcome these challenges, and provide code snippets for a hands-on understanding. Understanding Sparse Datasets Sparse datasets are characterized by having a large proportion of missing or zero values. This sparsity can result from various scenarios, such as user-item interactions in recommendation systems or word occurrences in text data. While handling sparse data can be intricate, understanding its challenges is the first step towards crafting efficient solutions. import numpy as npimport matplotlib.pyplot as plt# Example of a sparse matrixnum_rows = 100num_cols = 100# Define the density of the sparse matrix# Density is the proportion of non-zero elements in the matrixdensity = 0.05# Generate a random sparse matrixsparse_matrix = np.random.choice([0, 1], size=(num_rows, num_cols), p=[1-density, density])# Visualizing the sparse matrixplt.spy(sparse_matrix, marker='.', color='salmon')plt.title('Visualization of a Sparse Matrix')plt.show() Challenges Posed by Sparse Datasets Insufficient Information: Learning meaningful patterns becomes difficult due to the scarcity of non-zero values. High Dimensionality: The curse of dimensionality can affect distance-based algorithms by distorting the meaningfulness of distances between data points. Overfitting: The model might capture noise as patterns, resulting in poor generalization to unseen data. Computational Inefficiency: Some algorithms struggle with processing high-dimensional sparse data efficiently. Imbalance: Sparse datasets might introduce class imbalance, leading to biased models. Feature Importance: Determining which features are informative is challenging in sparse scenarios. Distance Measures: For algorithms that rely on distance measures, such as k-nearest neighbors (KNN) or support vector machines (SVM), sparse datasets can distort distances between data points, making it difficult to find similarities and differences. Strategies to Overcome the Challenges Dimensionality Reduction PCA (Principal Component Analysis) can help in reducing the feature space while retaining the most important information. from sklearn.decomposition import PCA# Initializing PCA and fitting on the sparse datapca = PCA(n_components=2)reduced_data = pca.fit_transform(sparse_matrix)# Visualizing the reduced dataplt.scatter(reduced_data[:, 0], reduced_data[:, 1], marker='o', color='b')plt.title('Visualization of Reduced Data')plt.show() Imputation Filling missing values based on certain strategies, such as mean imputation, can mitigate the impact of sparsity. from sklearn.impute import SimpleImputer# Initializing the imputer and performing imputationimputer = SimpleImputer(strategy='mean')imputed_data = imputer.fit_transform(sparse_matrix) Feature Selection Retaining only the most informative features can lead to improved model robustness. from sklearn.feature_selection import SelectKBest, chi2# Define target_variable for the sake of example# It could be any array of labels corresponding to each data point (row) in your sparse_matrix# For instance, it can be created as follows (assuming a classification task with two classes, 0 and 1):target_variable = np.random.choice([0, 1], size=(num_rows,), p=[0.5, 0.5])# Initializing feature selection method and selecting the best featuresselector = SelectKBest(chi2, k=2)selected_data = selector.fit_transform(sparse_matrix, target_variable) The target_variable is the dependent variable we are trying to predict in a supervised learning task. In the context of the code snippet, it should be the label or the output corresponding to each data point (row) in your sparse_matrix. In this example, target_variable is generated randomly, assuming a binary classification task. In a real-world scenario, target_variable would contain the actual labels of your data points. For each row in your sparse_matrix, there should be a corresponding label in target_variable. Regularization L1 and L2 regularization can prevent overfitting by penalizing large coefficients. from sklearn.linear_model import Lasso# Initializing Lasso with L1 regularizationlasso_model = Lasso(alpha=0.1)lasso_model.fit(features, target_variable) Ensemble Methods Random Forests, an ensemble method, can aid in improving generalization and managing overfitting. from sklearn.ensemble import RandomForestClassifier# Initializing and training a RandomForest Classifierrf_model = RandomForestClassifier(n_estimators=100, random_state=42)rf_model.fit(features, target_variable) Conclusion While sparse datasets pose several challenges in machine learning, ranging from high dimensionality to overfitting, a variety of strategies and techniques exist to navigate these issues. By adopting appropriate methods such as dimensionality reduction, imputation, and regularization, we can harness the potential of sparse data and build effective and robust machine learning models. pre { background-color:#38393d; color: #5fd381; }","link":"/2023/09/27/Python/sparse-datasets/"},{"title":"Python|Threading: Thread-based parallelism for beginner","text":"Tutorial from RealPython[1] Python threading allows you to have different parts of your program run concurrently and can simplify your design. If you’ve got some experience in Python and want to speed up your program using threads, then this tutorial is for you![1:1] What’s a Threading? Threading is a separate flow of execution. In bash, you can run a background process by adding a symbol &amp; at the end of commands. In python, we can achieve this with the example below. As you might expect, if you run the codes below, thread_function(3) will be started at the end of thread_function(4) PYTHONimport threadingimport timedef thread_function(Time): for i in range(Time): time.sleep(i) print(i)thread_function(4)thread_function(3) 0 1 2 3 0 1 2 But if we execute it in a threading or background process, they can run simultaneously. PYTHON- thread_function(4)+ x = threading.Thread(target=thread_function, args=(4,))+ x.start()+ # x.join()thread_function(3) 0 0 1 1 2 2 3 This is how we expect the background process, or daemon threads, to be performed. join() Some times, we’d like waiting for the threads. By doing so, we can call .join() to do so. By uncomment x.join(), we can get the same result as the first. PYTHONimport threadingimport timedef thread_function(Time): for i in range(Time): time.sleep(i) print(i)x = threading.Thread(target=thread_function, args=(4,))x.start()x.join()thread_function(3) 0 1 2 3 0 1 2 Working in a loop threads = list() for Time in range(5): x = threading.Thread(target=thread_function, args=(Time,)) threads.append(x) x.start() 0 0 0 0 1 1 1 2 2 3 ThreadPoolExecutor import threadingimport timeimport concurrent.futuresdef thread_function(Time): for i in range(Time): time.sleep(i) print(i,&quot;from&quot;, Time) print(Time, &quot;is Down&quot;)if __name__ == &quot;__main__&quot;: with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor: executor.map(thread_function, range(10)) 0 is Down 0 from 1 0 from 2 1 is Down 0 from 3 0 from 4 1 from 2 2 is Down 0 from 5 1 from 4 1 from 3 1 from 5 2 from 4 2 from 3 3 is Down 0 from 6 1 from 6 2 from 5 3 from 4 4 is Down 0 from 7 2 from 6 1 from 7 3 from 5 2 from 7 3 from 6 4 from 5 5 is Down 0 from 8 3 from 7 1 from 8 4 from 6 2 from 8 4 from 7 3 from 8 5 from 6 6 is Down 0 from 9 1 from 9 5 from 7 2 from 9 4 from 8 3 from 9 5 from 8 6 from 7 7 is Down 4 from 9 6 from 8 5 from 9 6 from 9 7 from 8 8 is Down 7 from 9 8 from 9 9 is Down The code creates a ThreadPoolExecutor as a context manager, telling it how many worker threads it wants in the pool. It then uses .map() to step through an iterable of things, in your case range(3), passing each one to a thread in the pool.[1:2] TEST import threading, timedef sleep(): time.sleep(30) print(&quot;sleep is down&quot;)x = threading.Thread(target=test, args=())x.start()x = threading.Thread(target=test, args=())x.is_alive() https://realpython.com/intro-to-python-threading/ ↩︎ ↩︎ ↩︎","link":"/2021/03/19/Python/threading/"},{"title":"RNN, Recurrent Neural Network","text":"RNN, Recurrent Neural Network A Recurrent Neural Network (RNN) is a class of artificial neural network that has memory or feedback loops that allow it to better recognize patterns in data. RNNs are an extension of regular artificial neural networks that add connections feeding the hidden layers of the neural network back into themselves - these are called recurrent connections. The recurrent connections provide a recurrent network with visibility of not just the current data sample it has been provided, but also it’s previous hidden state. A recurrent network with a feedback loop can be visualized as multiple copies of a neural network, with the output of one serving as an input to the next. Unlike traditional neural networks, recurrent nets use their understanding of past events to process the input vector rather than starting from scratch every time. A RNN is particularly useful when a sequence of data is being processed to make a classification decision or regression estimate but it can also be used on non-sequential data. Recurrent neural networks are typically used to solve tasks related to time series data. Applications of recurrent neural networks include natural language processing, speech recognition, machine translation, character-level language modeling, image classification, image captioning, stock prediction, and financial engineering. We can teach RNNs to learn and understand sequences of words. RNNs can also be used to generate sequences mimicking everything from Shakespeare to Linux source code, to baby names. © NVDIA Recurrent neural networks have memory to remember important past events, which is essential for successful sequence learning. Regular neural networks have fixed input size, while recurrent networks can handle sequences of any length. They process each element of a sequence one at a time, making them suitable for processing sequential data. A Sample Example There is an example from Abid Ali Awan, 2022. The training data is from kaggle MasterCard Stock Data # Importing the librariesimport numpy as npimport pandas as pdimport matplotlib.pyplot as pltfrom sklearn.preprocessing import MinMaxScalerfrom sklearn.metrics import mean_squared_errorfrom tensorflow.keras.models import Sequentialfrom tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectionalfrom tensorflow.keras.optimizers import SGDfrom tensorflow.random import set_seedset_seed(455)np.random.seed(455)# Read the datadataset = pd.read_csv( &quot;/home/ken/Downloads//Mastercard_stock_history.csv&quot;, index_col=&quot;Date&quot;, parse_dates=[&quot;Date&quot;]).drop([&quot;Dividends&quot;, &quot;Stock Splits&quot;], axis=1)print(dataset.head()) Open High Low Close Volume Date 2006-05-25 3.748967 4.283869 3.739664 4.279217 395343000 2006-05-26 4.307126 4.348058 4.103398 4.179680 103044000 2006-05-30 4.183400 4.184330 3.986184 4.093164 49898000 2006-05-31 4.125723 4.219679 4.125723 4.180608 30002000 2006-06-01 4.179678 4.474572 4.176887 4.419686 62344000 This code is for visualizing the training and testing data. We use the data from the previous year as the training data to predict the data for the last four years. tstart = 2016tend = 2020def train_test_plot(dataset, tstart, tend): dataset.loc[f&quot;{tstart}&quot;:f&quot;{tend}&quot;, &quot;High&quot;].plot(figsize=(16, 4), legend=True) dataset.loc[f&quot;{tend+1}&quot;:, &quot;High&quot;].plot(figsize=(16, 4), legend=True) plt.legend([f&quot;Train (Before {tend+1})&quot;, f&quot;Test ({tend+1} and beyond)&quot;]) plt.title(&quot;MasterCard stock price&quot;) plt.show()train_test_plot(dataset,tstart,tend) Detailed explain The code defines a function `train_test_plot` that takes in a dataset, a start year `tstart`, and an end year `tend`. It plots the `High` column of the dataset for the years between `tstart` and `tend`, and the `High` column of the dataset for the years after `tend+1`. This function is then called with the `dataset`, `tstart`, and `tend` variables that were previously defined from reading in the Mastercard stock history data. The resulting plot shows the trend of the Mastercard stock price for the years before `tend+1` (train data) and the years after `tend+1` (test data). The plot helps to visualize how the dataset is split into training and testing sets for model development and evaluation. def train_test_split(dataset, tstart, tend): train = dataset.loc[f&quot;{tstart}&quot;:f&quot;{tend}&quot;, &quot;High&quot;].values test = dataset.loc[f&quot;{tend+1}&quot;:, &quot;High&quot;].values return train, testtraining_set, test_set = train_test_split(dataset, tstart, tend)sc = MinMaxScaler(feature_range=(0, 1))training_set = training_set.reshape(-1, 1)training_set_scaled = sc.fit_transform(training_set)def split_sequence(sequence, n_steps): X, y = list(), list() for i in range(len(sequence)): end_ix = i + n_steps if end_ix &gt; len(sequence) - 1: break seq_x, seq_y = sequence[i:end_ix], sequence[end_ix] X.append(seq_x) y.append(seq_y) return np.array(X), np.array(y)n_steps = 60features = 1# split into samplesX_train, y_train = split_sequence(training_set_scaled, n_steps)# Reshaping X_train for modelX_train = X_train.reshape(X_train.shape[0],X_train.shape[1],features) Detailed explain The code defines several functions to prepare the dataset for training the RNN model. The train_test_split function takes in the dataset, tstart, and tend variables and returns the High column values of the dataset for the years between tstart and tend as the training set and the High column values of the dataset for the years after tend+1 as the test set. The MinMaxScaler function from sklearn.preprocessing is used to scale the training_set values between 0 and 1. Then, the split_sequence function is defined to split the training set into input-output sequences of length n_steps. This function takes in a sequence and the number of time steps to split the sequence into. Next, n_steps and features are defined as 60 and 1, respectively. The split_sequence function is then called to split the training_set_scaled into X_train (input sequences) and y_train (output sequences) for the RNN model. Finally, X_train is reshaped to a 3D tensor to match the input shape required by the RNN model, with dimensions (number of samples, number of time steps, number of features). The number of samples is inferred from the input data, number of time steps is set to n_steps, and number of features is set to 1. In this code, we only focus on the “High” column. After splitting the data into training_set and test_set using a predefined function, they are still one-dimensional with lengths of 1259 and 195, respectively. Next, we need to reshape the training set and scale it using MinMaxScaler. We then define a number of steps (n_steps) for the input sequence. This is similar to defining a sliding window, with the window size determined by the number of steps. Based on the features of this window, we can predict the information beyond the window. LSTM Model # The LSTM architecturemodel_lstm = Sequential()model_lstm.add(LSTM(units=125, activation=&quot;tanh&quot;, input_shape=(n_steps, features)))model_lstm.add(Dense(units=1))# Compiling the modelmodel_lstm.compile(optimizer=&quot;RMSprop&quot;, loss=&quot;mse&quot;)model_lstm.summary()model_lstm.fit(X_train, y_train, epochs=50, batch_size=32)dataset_total = dataset.loc[:,&quot;High&quot;]inputs = dataset_total[len(dataset_total) - len(test_set) - n_steps :].valuesinputs = inputs.reshape(-1, 1)#scalinginputs = sc.transform(inputs)# Split into samplesX_test, y_test = split_sequence(inputs, n_steps)# reshapeX_test = X_test.reshape(X_test.shape[0], X_test.shape[1], features)#predictionpredicted_stock_price = model_lstm.predict(X_test)#inverse transform the valuespredicted_stock_price = sc.inverse_transform(predicted_stock_price)def plot_predictions(test, predicted): plt.plot(test, color=&quot;gray&quot;, label=&quot;Real&quot;) plt.plot(predicted, color=&quot;red&quot;, label=&quot;Predicted&quot;) plt.title(&quot;MasterCard Stock Price Prediction&quot;) plt.xlabel(&quot;Time&quot;) plt.ylabel(&quot;MasterCard Stock Price&quot;) plt.legend() plt.show()def return_rmse(test, predicted): rmse = np.sqrt(mean_squared_error(test, predicted)) print(&quot;The root mean squared error is {:.2f}.&quot;.format(rmse))plot_predictions(test_set,predicted_stock_price)return_rmse(test_set,predicted_stock_price) Detailed explain The code is building a LSTM (Long Short-Term Memory) neural network model for time-series forecasting. First, the code splits the dataset into training and testing sets using a specified time period. It then applies feature scaling to the training set using MinMaxScaler, which scales the data to a range between 0 and 1. The function split_sequence is defined to prepare the training data into input-output pairs. Given a sequence of data points, this function divides the data into input sequences (X) of length n_steps and the corresponding output values (y). The LSTM model is defined using the Sequential class from Keras. It has one LSTM layer with 125 units and a tanh activation function. The output from the LSTM layer is then passed to a Dense layer with one unit. The model is compiled with the RMSprop optimizer and mean squared error (mse) loss function. After defining the model, the training set is used to fit the model for 50 epochs with a batch size of 32. Next, the testing set is prepared by selecting the required number of time steps from the end of the dataset, scaling it, and then splitting it into input-output pairs using the same split_sequence function. The input sequence is then reshaped into a 3D format that can be input into the LSTM model. Finally, the model is used to make predictions on the testing set, and the predictions are inverse transformed to get the actual stock prices. GRU Model model_gru = Sequential()model_gru.add(GRU(units=125, activation=&quot;tanh&quot;, input_shape=(n_steps, features)))model_gru.add(Dense(units=1))# Compiling the RNNmodel_gru.compile(optimizer=&quot;RMSprop&quot;, loss=&quot;mse&quot;)model_gru.summary()model_gru.fit(X_train, y_train, epochs=50, batch_size=32)GRU_predicted_stock_price = model_gru.predict(X_test)GRU_predicted_stock_price = sc.inverse_transform(GRU_predicted_stock_price)plot_predictions(test_set, GRU_predicted_stock_price)return_rmse(test_set,GRU_predicted_stock_price) Detailed explain The code is defining and training a GRU (Gated Recurrent Unit) model for predicting stock prices. First, the model is defined using the Keras Sequential API. The model has one GRU layer with 125 units and “tanh” activation function, and a Dense output layer with one unit. The model is then compiled using “RMSprop” optimizer and “mse” loss function. The model is trained using the training data, X_train and y_train, with 50 epochs and a batch size of 32. Then, the model is used to predict the stock prices for the test set using the predict method. The predicted prices are then inverse-transformed using the MinMaxScaler to obtain the actual stock prices. Finally, the predicted prices are plotted against the actual prices using the plot_predictions function and the root-mean-square error (RMSE) is computed using the return_rmse function. RNN in Action Prepair the functions def split_sequence(sequence, n_steps): X, y = list(), list() for i in range(len(sequence)): end_ix = i + n_steps if end_ix &gt; len(sequence) - 1: break seq_x, seq_y = sequence[i:end_ix], sequence[end_ix] X.append(seq_x) y.append(seq_y) return np.array(X), np.array(y)def Data_prepare(training_set, n_steps = 60, features =1): #sc = MinMaxScaler(feature_range=(0, 1)) training_set = training_set.reshape(-1, 1) #training_set_scaled = sc.fit_transform(training_set) # split into samples X_train, y_train = split_sequence(training_set_scaled, n_steps) # Reshaping X_train for model X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],features) return X_train, y_train import pandas as pdData = &quot;/media/ken/DATA/tracking_test/WT_court10min_ID.csv&quot;TB = pd.read_csv(Data, index_col=0)# select the Fly_8 as an example#for ID in TB.ID.unique()[:12]:ID = &quot;Fly_8&quot;training_set_X = TB.X[TB.ID==ID][:2000].to_numpy()test_set_X = TB.X[TB.ID==ID][2000:3000].to_numpy()training_set_Y = TB.Y[TB.ID==ID][:2000].to_numpy()test_set_Y = TB.Y[TB.ID==ID][2000:3000].to_numpy()plt.plot(training_set_X, training_set_Y)plt.plot(test_set_X, test_set_Y)plt.show() n_steps = 60features = 2training_set = TB[[&quot;X&quot;, &quot;Y&quot;]][TB.ID==ID][:2000].to_numpy()X_train, y_train = split_sequence(training_set, n_steps)X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],features)test_set = TB[[&quot;X&quot;, &quot;Y&quot;]][TB.ID==ID][2000:3000].to_numpy()X_test, y_test = split_sequence(test_set, n_steps)X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],features)model_gru = Sequential()model_gru.add(GRU(units=125, activation=&quot;tanh&quot;, input_shape=(n_steps, features)))model_gru.add(Dense(units=2))# Compiling the RNNmodel_gru.compile(optimizer=&quot;RMSprop&quot;, loss=&quot;mse&quot;)model_gru.summary()model_gru.fit(X_train, y_train, epochs=50, batch_size=32)GRU_predicted_stock_price = model_gru.predict(X_test)#GRU_predicted_stock_price = sc.inverse_transform(GRU_predicted_stock_price)plt.plot(GRU_predicted_stock_price[:,0], GRU_predicted_stock_price[:,1])plt.plot(test_set[:,0], test_set[:,1])plt.show()Predict = []Track = X_train[-1] for i in range(1000): Predict += model_gru.predict(np.array([Track])).tolist() Track = np.concatenate([Track[1:], [Predict[-1]]])plt.plot(np.array(Predict)[:,0], np.array(Predict)[:,1])plt.plot(GRU_predicted_stock_price[:,0], GRU_predicted_stock_price[:,1])plt.plot(test_set[:,0], test_set[:,1])plt.show()# plot for other flytest_set = TB[[&quot;X&quot;, &quot;Y&quot;]][TB.ID==ID].to_numpy()X_test, y_test = split_sequence(test_set, n_steps)X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],features)plt.plot(GRU_predicted_stock_price[:,0], GRU_predicted_stock_price[:,1])plt.plot(test_set[:,0], test_set[:,1])plt.show() pre { background-color:#38393d; color: #5fd381; }","link":"/2023/05/02/Python/rnn/"},{"title":"torch: Start with Deep Learning","text":"Torch: Start with Deep Learning Mostly from ChatGPT4 import torchimport torch.nn as nnclass Net(nn.Module): def __init__(self): super(Net, self).__init__() self.hidden = nn.Linear(50, 100) # 隐藏层，接收的输入大小为50，输出的大小为100 self.relu = nn.ReLU() # 激活函数 self.output = nn.Linear(100, 2) # 输出层，输出的大小为2，对应两个类别 def forward(self, x): x = self.hidden(x) x = self.relu(x) x = self.output(x) return x# 实例化模型model = Net()# 首先，我们定义损失函数和优化器。因为我们假设这是一个二分类问题，所以我们使用交叉熵损失（CrossEntropyLoss）。为了优化模型，我们使用随机梯度下降（SGD）criterion = nn.CrossEntropyLoss()optimizer = torch.optim.SGD(model.parameters(), lr=0.01)# 接下来，我们生成一些假的训练数据。假设我们有100个样本，每个样本是一个50维的向量：inputs = torch.randn(100, 50)labels = torch.randint(0, 2, (100,)) # 随机生成0或1作为标签# 然后，我们进行一次前向传播、反向传播和权重更新：# 前向传播for epochs in range(100): outputs = model(inputs) loss = criterion(outputs, labels) # 反向传播和权重更新 optimizer.zero_grad() loss.backward() optimizer.step() print('Loss:', loss.item())# 这样，你的模型就进行了一次训练。# 要进行预测，你可以直接使用模型对输入进行前向传播：# 生成一些假的测试数据test_inputs = torch.randn(5, 50)# 前向传播outputs = model(test_inputs)# 使用softmax函数得到每个类别的概率，并使用argmax得到预测的类别_, predicted = torch.max(outputs, 1)print('Predicted:', predicted) How to use GPU for training 首先，检查你的系统是否支持CUDA（即GPU计算）： device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)print(device) # 如果你的系统支持CUDA，应该打印出'cuda:0' 然后，将模型转移到GPU： model = Net().to(device) 然后，将模型转移到GPU： for epoch in range(2): # 进行2个epoch running_loss = 0.0 for i, data in enumerate(trainloader, 0): inputs, labels = data[0].to(device), data[1].to(device) # 转移到GPU optimizer.zero_grad() outputs = model(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() running_loss += loss.item() if i % 2000 == 1999: # 每2000个batch打印一次平均loss值 print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000)) running_loss = 0.0print('Finished Training') 同样，当你进行预测时，也需要确保数据被转移到了GPU： correct = 0total = 0with torch.no_grad(): for data in testloader: images, labels = data[0].to(device), data[1].to(device) # 转移到GPU outputs = model(images) _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum().item()print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total)) 保存和继续训练 保存整个模型： torch.save(model, 'model.pth') 只保存模型参数： torch.save(model.state_dict(), 'params.pth') 加载整个模型： model = torch.load('model.pth') 只加载模型参数： model.load_state_dict(torch.load('params.pth')) optimizer = torch.optim.SGD(model.parameters(), lr=0.01) # 以随机梯度下降为例criterion = torch.nn.CrossEntropyLoss() # 假设是分类问题for epoch in range(num_epochs): # 清零梯度 optimizer.zero_grad() # 前向传播 outputs = model(new_data) # 计算损失 loss = criterion(outputs, new_labels) # 反向传播 loss.backward() # 更新参数 optimizer.step() pre { background-color:#38393d; color: #5fd381; }","link":"/2023/07/03/Python/torch-dp/"},{"title":"Video to audio | Python |mp4 to mp3","text":"Quick Start: moviepy Cite: taoquns 2019 # pip install moviepyfrom moviepy.editor import *video = VideoFileClip('test.mp4')audio = video.audioaudio.write_audiofile('test.mp3') Requirement moviepy decorator tqdm requests numpy imageio pillow imageio_ffmpeg ffmpy3 Cite: © Jumping boy; 2019 from ffmpy3 import FFmpegff = FFmpeg(inputs={'周笔畅-最美的期待(伴奏版).mp4': None}, outputs={'output.mp3': None})print(ff.cmd)ff.run()","link":"/2021/04/23/Python/video2audio/"},{"title":"wordcloud","text":"The color palette from the R package worldcloud2 is very awesome. But it has some bugs. I can not set the mask for the world cloud. In python, this package is much user-friendly. To be notice, the mask picture is very important. You can only use the rgb format. The picture has “0, 0, 0” for the background, “255, 255, 255” for the background. rgbi format is not supported even if it is very similar to rgb. from os import pathfrom PIL import Imageimport numpy as npimport matplotlib.pyplot as pltfrom wordcloud import WordCloud, STOPWORDS## Read the whole text.text = open('tmp.txt').read()## read the mask image## taken from## http://www.stencilry.org/stencils/movies/alice%20in%20wonderland/255fk.jpgalice_mask = np.array(Image.open(&quot;/home/ken/Downloads/cloud.png&quot;))stopwords = set(STOPWORDS)stopwords.add(&quot;said&quot;)wc = WordCloud(background_color=&quot;white&quot;, max_words=512, mask=alice_mask, max_font_size=10, # 根据你的图片大小定义 stopwords=stopwords)## generate word cloudwc.generate(text)## store to filewc.to_file(&quot;alice.png&quot;)## showplt.imshow(wc, interpolation='bilinear')plt.axis(&quot;off&quot;)plt.figure()plt.imshow(alice_mask, cmap=plt.cm.gray, interpolation='bilinear')plt.axis(&quot;off&quot;)plt.show()## remove punctuationSpecial = &quot;”&quot;TT = text.translate(str.maketrans(' ', ' ', string.punctuation))TT = TT.translate(str.maketrans('', '', string.whitespace[1:]))TT = TT.translate(str.maketrans('', '', string.digits))TT = TT.lower()TT = TT.split(&quot; &quot;)TT = list(set(TT))for i in string.ascii_lowercase: try: TT.remove(i) except: print(i)f = open(&quot;list&quot;,'a')for i in TT: f.write(i+'\\n')f.close() https://amueller.github.io/word_cloud/auto_examples/colored.html#colored-py","link":"/2020/06/23/Python/wordcloud/"},{"title":"yolov5","text":"pre { background-color:#38393d; color: #5fd381; } Blogs: Difference Between a Batch and an Epoch in a Neural Network YOLOv5模型训练, 2020 Batch Video: deeplizard, 2017[1] Apeer_micro, 2021[2] The number of the samples in a group been trained. As a result, the training speed was largely improved by a large batch. But at the same time, the performance of the model might decreased. small batch → Less accurate large batch → computer time and over fit the dataset batch size of 32 or 64 is a good starting point Epochs The times of back-forward Exp: Sampel: 3000 BatcCh 32 epochs: 500 32 samples will be taken at a time to train the network To go through all 300 samples it takes 3000/32 = 94 iterations → 1 epoch. This process continues 500 times (epochs). Practice Youtube: Roboflow: How to Train YOLO v5 on a Custom Dataset; 2020 Blog with data set: YOLOv5模型训练, 2020 My experience Train a small group of data set Some blogs suggest that we should avoid to label one thing multiple times. I want to know how really it affects. I found a small set of data which has only 105 imgas in trainning set. They labeled two classes as mask-on and mask-off. For testing, I’ll repeat all labeles as class 3 which stands for face. After trainning with the same arguments, both model would be used to detect the test dataset and results would be recorded. Aruguments for training with two GPU python -m torch.distributed.launch --nproc_per_node 2 train.py --img 640 --batch-size 16 --epochs 500 --data ../png_DB/mask/data.yaml --weights yolov5s.pt --device 0,1 Script for repeat the labels. PS: There is a very important features for yolov5: if the location of two labels are identical, one of the class would be deleted. At the first time, I just simpliy duplicate all boxs and change the class into a new one. After training, results shows that there are no single labeled face in the training set. So, I have tried to add 0.0001 into each location for make the class ‘2’ different from the origin one. rm -rf mask2cp -r mask mask2cd mask2cat */labels/*|wc -lfor i in $(ls */labels/*)do echo &quot;&quot; &gt;&gt; $ipaste &lt;(awk '$1=2;{print}' $i| uniq| awk '{print $1}') &lt;(awk '$1=2;{print $2+0.00001&quot; &quot;$3+0.00001&quot; &quot;$4+0.00001&quot; &quot;$5+0.00001&quot; &quot;}' $i| grep -v &quot;^2 &quot;) --delimiters=&quot; &quot; &gt;&gt; $idonecat */labels/*|wc -lcd testcp labels/* imagescp ../../classes.txt images 805 1743 As you can see, before the repeat, there are 805 targets. After repeat the labels, we’ll update the label information in data.yaml vim data.yaml nc: 3 names: ['mask', 'no-mask', 'face'] Detacte and result extrect python3 detect.py --weight runs/train/mask/weights/best.pt --source ../png_DB/mask/train/images --save-txtcat runs/detect/exp2/labels/*| awk '{print $1}'| sort| uniq -c| sed 's/^ *//' The result: Class Model1 Model2 Truth mask 595 570 573 no_mask 131 110 123 face 0 646 687 As you can see, from the result 1 Advice for Best Training Results First, please read the Tips for Best Training Results First thing frist: Label the target well! This is the key step for all work. Large batch as you can! Chech the result, try to increasing the epecho as yor “val/obj_loss” didn’t increase Deeplizard; Batch Size in a Neural Network explained; 2017; Youtube. ↩︎ Apeer_micro; Tutorial 97 - Deep Learning terminology explained - Batch size, iterations and epochs; 2021; Youtube ↩︎","link":"/2021/11/06/Python/yolov5/"},{"title":"DNA is Not Destiny","text":"DNA is Not Destiny Why it started with Chapter 6 I started to write these notes until I read half of the book. I can’t exactly remember the contents but it left a good impression for me. So, I decided to finish it and make some notes now. Chapter 6: Race and Ancestry It is interesting to know about our biological race from DNA testing. It may look cool if the biological identity feat your social identity and could have a positive effect on you, like the girl known that she has Native American DNA and made a closer relationship with other native Americans. The problem is that when the biological identity collided with your social identity, Wayne Joseph for instance, who was identified as African American and advocating for this group but actually has no DNA comes from Africa. It just like you are been told that your father is not your biological father or your son/daughter is not yours. It is hard to imaging for us cause we humans have and need a strong sense of belonging. Japanese believe that their intestine is longer for Westerners for fitting the rice diet rather than bread. As a result, they suggested that ban American beef since it is not suitable for the Japanese intestine. Biological identity &amp; Social identify, why is it matters? Statistics show: people who read about races is the product of the social culture rather than gene are more willing to make friends with Blacks. Asian Americans read about race is the product of the social culture rather than gene are more confident to blend in American culture and community. Author has divided the topics of social &amp; biological effects. For me, I prefer to take them as a whole. One should be the product of the interaction between natural and nurture. But it is too complicated to talk about the knowledge we have at present. And maybe this is why the author prefers to talking with them respectively in this book o. Chapter 7: Essences and the Seductive Allure of Eugenics In the western world, eugenic is a contemptuous idea since it connected the Nazis. But it is much temper in Asian areas. Intelligence and Essences The experiment about comprising or disorganizing students made different consequences on American students and Japanese students. American students preferred to gain confidence from the comprises and try to practice the same project because they believe they are good at it. But people who were criticized prefer to picking up other works and give up what they don’t good at. But the controversial results present at Japanese students who prefer to practice more with the project which had negative feedback. This is interesting. Because though teachers and parents are debated about this topic for many years but almost none of them are holding the view from students. If they are restricted to their personal experience and may cause problems on their students, like prevent their students to make progress or give up the project too early. How Heritable is IQ? The author mentioned about the difference in heritability of IQ among wealthier and poor populations. The index is as high as 80% in wealthier communities but as low as 10% in poor groups. It is interesting to see that those two groups have such disparity. And this is the reason why I’m always taking care of all kinds of statistic reports or results weather are they significantly or not. As I always said, I strongly believe that humans are the product of the interaction of DNA and environment. For the first sight, I thought that one possibility is that the most of wealthier parents were well educated and so, they have touched their limits of IQ. As a result, their offspring are closing to them. For poor communities, some of them are not well educated, or may even have poor health. Both of these can affect the results of the IQ test. On the other hand, education is easy to get compared with the old days and so, developed (educated) kids were easy to show smarter than their parents who are far from to touch their IQ limits.","link":"/2020/07/25/LearnNotes/DNA_Is_NotDestiny/"},{"title":"English Vocabularies and Sentences about fish tank","text":"English Vocabularies and Sentences about fish tank 欢迎评论，或者补充～评论不了可以B站私信我: 史上最不正經的生物狗 Source: AQUAPROS 2019[1] English Chinese string algae 丝藻 Moss 莫斯 Prune (Pruning) 修剪 garden aquarium 草缸 cory fish 鼠鱼 farm 渔场 quarantine 隔离 a school of fish 鱼群 nano fish 小鱼 cyano(bacteria) 蓝藻(蓝细菌) scraper 刮刀 dwarf hair grass plecos 清道夫 snails 螺 A big pile of Moss BiliBili: 史上最不正經的生物狗 AQUAPROS 2019; Adding 300 FISH! To Ancient Gardens Planted Aquarium; Youtube ↩︎","link":"/2020/08/11/LearnNotes/Eng_fish/"},{"title":"瓦雀.py| 使用python腳本更新維護語雀文檔","text":"瓦雀.py 自己寫肯定是不可能的， 瓦雀那麼好用， 爲什麼要自己寫呢？？？ ummmm， 爲什麼我的代碼都變了？？？ 本地明明是 except: Date= str(grep(&quot;b'Date:&quot;,lines)).replace(&quot;b'&quot;,'') From= Decode(str(grep(&quot;b'From:&quot;,lines)).replace(&quot;b'&quot;,'')) To= Decode(str(grep(&quot;b'To:&quot;,lines)).replace(&quot;b'&quot;,'')) Subject= Decode(str(grep(&quot;b'Subject:&quot;,lines)).replace(&quot;b'&quot;,'')) print(&quot;&quot;,From,To,&quot;\\n&quot;,Subject,'\\n\\n',&quot;this mail are purely composed by img or html&quot;,sep='\\n') print('\\n\\n'+Date) 上傳以後，就翻車了。。 github和語雀問原作者，似乎一直沒有回 = = except: Date= str(grep(&amp;quot;b&amp;#39;Date:&amp;quot;,lines)).replace(&amp;quot;b&amp;#39;&amp;quot;,&amp;#39;&amp;#39;) From= Decode(str(grep(&amp;quot;b&amp;#39;From:&amp;quot;,lines)).replace(&amp;quot;b&amp;#39;&amp;quot;,&amp;#39;&amp;#39;)) To= Decode(str(grep(&amp;quot;b&amp;#39;To:&amp;quot;,lines)).replace(&amp;quot;b&amp;#39;&amp;quot;,&amp;#39;&amp;#39;)) Subject= Decode(str(grep(&amp;quot;b&amp;#39;Subject:&amp;quot;,lines)).replace(&amp;quot;b&amp;#39;&amp;quot;,&amp;#39;&amp;#39;)) print(&amp;quot;&amp;quot;,From,To,&amp;quot;\\n&amp;quot;,Subject,&amp;#39;\\n\\n&amp;#39;,&amp;quot;this mail are purely composed by img or html&amp;quot;,sep=&amp;#39;\\n&amp;#39;) print(&amp;#39;\\n\\n&amp;#39;+Date) 好吧， 那我還是自己寫一個把。 反正API都已經公開了。而且語雀很多語法， 不支持。 正好可以， 個性化一些小東西。 避免一些bug和尷尬。 基礎 查看 repositories Document import requestsUSER = ${你的repors前面那段名字}## 比如， 你的主頁是 https://www.yuque.com/xiaoming## 則， USER = ‘xiaoming’url = 'https://www.yuque.com/api/v2/users/' + USERheader = {&quot;X-Auth-Token&quot;: &quot;Your Token&quot;}requests.get(url, headers = header).json() {'data': {'id': 691897, 'type': 'User', 'space_id': 0, 'account_id': 494138, 'login': 'liuwenkan', 'name': 'Karroben',... 這裏可以獲得你自己的ID和一些主頁身份信息。 之後就可以用ID來做請求了。 url = 'https://www.yuque.com/api/v2/users/' + USER + &quot;/repos&quot;## or url = 'https://www.yuque.com/api/v2/users/' + ID + &quot;/repos&quot;Repo_Result = requests.get(url, headers = header).json()['data'] 現在， 你可以查看Repo的信息了。 這裏包括了所有倉庫及其統計信息。 如果不想查看， 請直接忽略。重要的是， 我們需要 倉庫 所對應的 ID 比如， 我需要blog倉庫的ID for i in Repo_Result: if 'blog' == i['slug']: print(i['id']) 646554 有了ID， 就可以查看倉庫內的文章了。 同樣的， 我們更新文章，也需要獲得ID 發表一篇新文章 Document data 格式 Doc_ID = '646554'url = 'https://www.yuque.com/api/v2/repos/'+Doc_ID+'/docs'data = { #'id': 我不想指定， 還是隨機吧 'slug': 'test3' , # 這個還是最好要一個。 這個是網址 'title': '又來測試了', # 這就不用多說了吧。 'format': 'markdown', # 這必須markdown 呀 'body': &quot;# 這是第一個小標題&lt;br&gt;這是正文\\n這個看看有效沒，換行符號&quot;, 'status': &quot;1&quot; # 0 是草稿， 直接發佈把}BACK = requests.post(url, data= data, headers = header).json()['data']print(Doc_Result[0]) 這就， 成功啦～！ 註： slug 必須是唯一的， 所以最好先檢查slug是否存在 def Slug_check(slug): try: requests.get(url+'/'+slug, headers = header).json()['status'] print('slug is unique') return True except: print('Please check the slug. It may be occupied already.') return False 查看倉庫中的文章 Repos_ID = '646554'url = 'https://www.yuque.com/api/v2/repos/'+Repos_ID+'/docs'Doc_Result = requests.get(url, headers = header).json()['data']print(Doc_Result[0]) {'id': 32290390, 'slug': 'test3', 'title': '又來測試了', 'description': None, 'user_id': 691897, 'book_id': 646554, 'format': 'markdown', 'public': 1, 'status': 1, 'view_status': 0, 'read_status': 1, 'likes_count': 0, 'comments_count': 0, 'content_updated_at': '2021-03-03T14:33:25.000Z', 'created_at': '2021-03-03T14:33:25.000Z', 'updated_at': '2021-03-03T14:33:43.000Z', 'published_at': '2021-03-03T14:33:25.000Z', 'first_published_at': '2021-03-03T14:33:25.000Z', 'draft_version': 0, 'last_editor_id': 691897, 'word_count': 24, 'cover': None, 'custom_description': None, 'last_editor': {'id': 691897, 'type': 'User', 'login': 'liuwenkan', 'name': 'Karroben', 'description': '博客:https://karobben.github.io\\n若不兼容情况, 请移步gitpage浏览(看地址)', 'avatar_url': 'https://cdn.nlark.com/yuque/0/2019/jpeg/anonymous/1576914522864-5dabd37e-9a90-4ee4-96b4-a1973dbcede4.jpeg', 'followers_count': 21, 'following_count': 2, 'created_at': '2019-12-21T07:49:03.000Z', 'updated_at': '2021-03-03T11:29:54.000Z', '_serializer': 'v2.user'}, 'book': None, '_serializer': 'v2.doc'} 可以看見， 第一篇文章， 是最新發的。 更新這篇文章把， 已知id是32290390 Doc_ID = '32290390'url = 'https://www.yuque.com/api/v2/repos/'+Repos_ID+'/docs/'+Doc_IDdata = { #'id': 我不想指定， 還是隨機吧 'slug': 'test3' , # 這個還是最好要一個。 這個是網址 'title': '標題也改一下把', # 這就不用多說了吧。 'format': 'markdown', # 這必須markdown 呀 'body': &quot;# 這是第一個小標題\\n\\n這是正文\\n換行符號.`來看看代碼框把'\\n'`&quot;, 'status': &quot;1&quot; # 0 是草稿， 直接發佈把}Doc_Result = requests.put(url, data = data, headers = header).json()['data']print(Doc_Result[0]) 完美～ 腳本化 配置文件準備 準備yuque.yml文件 yuque.ymlrepo: 'xiaoming/blog' Markdown 標題格式 ---title: &quot;&quot;url: ''date: ''--- 爲了安全起見， 我選擇單獨把Token保存在一個文件裏面， 給路徑來讀取 echo $Token &gt; ~/.yuqueToken import yamlimport requestsimport osdef Yml_json(yml): f = open(yml, 'r') ystr = f.read() aa = yaml.load(ystr, Loader=yaml.FullLoader) return aadef ReporsID_get(Identity): url = 'https://www.yuque.com/api/v2/users/' + Identity['repo'].split('/')[0]+&quot;/repos&quot; header = {&quot;X-Auth-Token&quot;: Identity['Token']} List = requests.get(url, headers = header).json()['data'] for i in List: if Identity['repo'].split('/')[1] == i['slug']: Repos_ID = i['id'] return Repos_IDdef DocList_get(Repos_ID): header = {&quot;X-Auth-Token&quot;: Identity['Token']} url = 'https://www.yuque.com/api/v2/repos/'+str(Repos_ID)+'/docs' Doc_Result = requests.get(url, headers = header).json()['data'] return Doc_Resultdef MDbody_clean(MD_body): MD_body = MD_body[MD_body.find('---',1)+3:] # 語雀不支持&lt;pre&gt;標籤 MD_body = MD_body.replace(&quot;&lt;pre&gt;&quot;, '```text') MD_body = MD_body.replace(&quot;&lt;/pre&gt;&quot;, '```') # 添加封面圖片 F = open(MD,'r').read() Data_header = yaml.load(F.split('---')[1], Loader=yaml.FullLoader) try: CP = Data_header['covercopy'] except: CP = &quot;&quot; MD_body = &quot;|![](&quot; + Data_header['cover']+&quot;)|\\n&quot; + &quot;|:--:|\\n&quot; + &quot;|&quot;+CP+&quot;|\\n&quot; + MD_body # 加個尾巴 MD_body += ''' --- * Enjoy~ 本文由&lt;span style='color:salmon'&gt;Python腳本&lt;/span&gt;[GitHub](https://karobben.github.io/2021/03/02/Python/yuqueAPI)/[語雀](https://www.yuque.com/liuwenkan/python/yuque_api)自動更新 &lt;span style='color:salmon'&gt;由於語法渲染問題而影響閱讀體驗， 請移步博客閱讀～&lt;/span&gt; GitHub: [Karobben](https://github.com/Karobben) Blog:[Karobben](https://karobben.github.io/) BiliBili:[史上最不正經的生物狗](https://space.bilibili.com/393056819) ''' return MD_bodydef MDupDate(MD, Repos_ID, Doc_list): # read MD file F = open(MD,'r').read() Data_header = yaml.load(F.split('---')[1], Loader=yaml.FullLoader) # find the ID by slug/url for i in Doc_list: if Data_header['url'] == i['slug']: data = { #'id': 我不想指定， 還是隨機吧 'slug': i['slug'], # 這個還是最好要一個。 這個是網址 'title': Data_header['title'], # 這就不用多說了吧。 'format': 'markdown', # 這必須markdown 呀 'body': MDbody_clean(F), 'status': &quot;1&quot; # 0 是草稿， 直接發佈把 } Doc_ID = i['id'] header = {&quot;X-Auth-Token&quot;: Identity['Token']} url = 'https://www.yuque.com/api/v2/repos/'+str(Repos_ID)+'/docs/'+ str(Doc_ID) Doc_Result = requests.put(url, data = data, headers = header).json()['data'] print(MD,&quot;is updated&quot;)Token = open('/home/ken/.yuqueToken','r').read().strip()Identity = Yml_json('yuque.yml')Identity.update({'Token':Token})Repos_ID = ReporsID_get(Identity)Doc_list = DocList_get(Repos_ID)for MD in os.listdir(): if &quot;.md&quot; == MD[-3:]: print(&quot;updating for:&quot;, MD) try: MDupDate(MD, Repos_ID, Doc_list) except: print( '\\033[91m' + &quot;UPDAT FAILED!!!&quot; + '\\033[0m') 最後， 我麼把他寫成腳本吧 功能: 更新markdown文件 獨立語雀標題 填上icarus的封面圖 添加尾墜 添加Gitpage本文鏈接 修改語雀不支持的&lt;pre&gt;標籤不能： 創建新文件(請使用瓦雀， 我怕太多太混亂了) 目錄編輯(瓦雀即可實現) 使用 echo {your token} &gt; token.filepython waque.py -t token.file -i post.md #!/usr/bin/env python3import argparseparser = argparse.ArgumentParser()parser.add_argument('-i','-I','--input',nargs='+') #输入文件parser.add_argument('-t','-T','--token') #输入文件parser.add_argument('-c','-C','--category', default= &quot;summary.md&quot;) #输入文件args = parser.parse_args()INPUT = args.inputToken = args.tokenCategory = args.categoryimport threadingimport concurrent.futuresimport yamlimport requestsimport os, redef Yml_json(yml): f = open(yml, 'r') ystr = f.read() aa = yaml.load(ystr, Loader=yaml.FullLoader) return aadef ReporsID_get(Identity): url = 'https://www.yuque.com/api/v2/users/' + Identity['repo'].split('/')[0]+&quot;/repos&quot; header = {&quot;X-Auth-Token&quot;: Identity['Token']} List = requests.get(url, headers = header).json()['data'] for i in List: if Identity['repo'].split('/')[1] == i['slug']: Repos_ID = i['id'] return Repos_IDdef DocList_get(Repos_ID): header = {&quot;X-Auth-Token&quot;: Identity['Token']} url = 'https://www.yuque.com/api/v2/repos/'+str(Repos_ID)+'/docs' Doc_Result = requests.get(url, headers = header).json()['data'] return Doc_Resultdef MDbody_clean(MD_body): MD_body = MD_body[MD_body.find('---',1)+3:] # 語雀不支持&lt;pre&gt;標籤 try: AA = re.findall(&quot;&lt;pre[^&gt;]+&gt;&quot;, MD_body) for PRE in AA: MD_body = MD_body.replace(PRE, '```text') except: PRE = &quot;&lt;pre&gt;&quot; print(PRE, &quot;IAMHERE&quot;) print(MD_body) MD_body = MD_body.replace(&quot;&lt;pre&gt;&quot;, '```text') MD_body = MD_body.replace(&quot;&lt;/pre&gt;&quot;, '```') # 添加封面圖片 F = open(MD,'r').read() Data_header = yaml.load(F.split('---')[1], Loader=yaml.FullLoader) try: CP = Data_header['covercopy'] CP = &quot;|![](&quot; + Data_header['cover']+&quot;)|\\n&quot; + &quot;|:--:|\\n&quot; + &quot;|&quot;+CP+&quot;|\\n&quot; except: CP = &quot;&quot; # 添加本文github鏈接 try: git_url = &quot;&quot;.join([ &quot;\\n&lt;span style='color:salmon'&gt;由於語法渲染問題而影響閱讀體驗， 請移步博客閱讀～&lt;/span&gt;&quot;, &quot;\\n[本文GitPage地址]&quot;, &quot;(https://karobben.github.io/&quot;, str(Data_header['date']).split(' ')[0].replace(&quot;-&quot;,&quot;/&quot;), &quot;/&quot;, os.getcwd().split(&quot;/&quot;)[-1],&quot;/&quot;, MD[:-3], &quot;)\\n&quot;]) except: git_url = &quot;&quot; # 合併前面的所有 MD_body = CP+ git_url + MD_body # 加個尾巴 MD_body += ''' --- **Enjoy~** 本文由&lt;span style='color:salmon'&gt;Python腳本&lt;/span&gt;[GitHub](https://karobben.github.io/2021/03/02/Python/yuqueAPI)/[語雀](https://www.yuque.com/liuwenkan/python/yuque_api)自動更新 %%% GitHub: [Karobben](https://github.com/Karobben) Blog:[Karobben](https://karobben.github.io/) BiliBili:[史上最不正經的生物狗](https://space.bilibili.com/393056819) '''.replace(&quot;%%%&quot;,git_url) return MD_bodydef MDupDate(MD, Repos_ID, Doc_list): # read MD file F = open(MD,'r').read() Data_header = yaml.load(F.split('---')[1], Loader=yaml.FullLoader) # find the ID by slug/url if Data_header['url'] in [x['slug'] for x in Doc_list]: # 如果有單獨指定語雀標題： try: if Data_header['ytitle'] == &quot;&quot; : Title = Data_header['title'] else: Title = Data_header['ytitle'] except: Title = Data_header['title'] data = { #'id': 我不想指定， 還是隨機吧 'slug': Data_header['url'], # 這個還是最好要一個。 這個是網址 'title': Title, # 這就不用多說了吧。 'format': 'markdown', # 這必須markdown 呀 'body': MDbody_clean(F), 'status': &quot;1&quot; # 0 是草稿， 直接發佈把 } Doc_ID = [x['id'] for x in Doc_list][[x['slug'] for x in Doc_list].index(Data_header['url'])] header = {&quot;X-Auth-Token&quot;: Identity['Token']} url = 'https://www.yuque.com/api/v2/repos/'+str(Repos_ID)+'/docs/'+ str(Doc_ID) Doc_Result = requests.put(url, data = data, headers = header).json()['data'] print(MD,&quot;is updated&quot;) else: print(MD,' \\033[91m', &quot;這個文件還沒有被創建。我懶得寫一個新建接口了（防止太混亂）\\n所以請覈對以後， 先上新建這個文件，再來更新把= =推薦用瓦雀直接創建&quot;, '\\033[0m')def Categ(Category): try: List = open(Category,'r').read().replace(&quot; &quot;,'').split(&quot;](&quot;) Cate_list = [A.split(&quot;)&quot;)[0] for A in List][1:] return &quot;導入成功&quot;, Cate_list except: return &quot;導入失敗&quot;, []def run(MD): print(&quot;updating for:&quot;, MD) Cate_state , Cate_reuslt = Categ(Category) print(&quot;目錄:&quot;, Cate_state) try: Data_header = yaml.load(open(MD,'r').read().split('---')[1], Loader=yaml.FullLoader) if Data_header['url'].lower() not in Cate_reuslt and Cate_state == &quot;導入成功&quot; : print(MD +' \\033[91m', &quot;該文檔未加入目錄&quot;, '\\033[0m') MDupDate(MD, Repos_ID, Doc_list) except: print( MD + ' \\033[91m' + &quot;UPDAT FAILED!!!&quot; + '\\033[0m') # 線程等待Token = open(Token,'r').read().strip()# Token = open('/home/ken/.yuqueToken','r').read().strip()Identity = Yml_json('yuque.yml')Identity.update({'Token':Token})Repos_ID = ReporsID_get(Identity)Doc_list = DocList_get(Repos_ID)for MD in INPUT: run(MD)'''if __name__ == &quot;__main__&quot;: with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor: executor.map(run, INPUT)'''","link":"/2021/03/02/Python/yuqueAPI/"},{"title":"English Vocabulary Substituted for Writing","text":"English Vocabulary Substituted for Writing 欢迎评论，或者补充～评论不了可以B站私信我: 史上最不正經的生物狗 Word Word2 Property Trans Ambition aspiration n. 抱負 Anger Pique n. Avoid circumvent v. body corpse n. 尸体 Believe creed, doctrine n. (刺客信条) Cafeteria canteen n. 食堂 Cheat coax, procure v., n. 哄骗，诱劝 Clean neat; neatly n. 干净 Conquer subjugate v. Drink imbibe v. Force compulsory, oblige v. 强迫做… Forward-looking insightful, longsighted, provident, visionary adj. 有远见的 Game contest, competition, match n. 比赛 Garbage detritus n. 垃圾 Glass land prairie, steppe n. (大)草地 Grades tally n. (游戏 等)积分 Group party, faction, school Interrupt interject v. 打断 Native idiomatic adj. 地道的，地方特色的(语言) Possible feasible, practicable, achievable, reasonable Quiet serene, tranquil, peaceful, quiescent adj. Quickly; shortly evanescent; ephemeral adj. 转瞬即逝 Ranch pasture, farm, rancho n. Ratify authorize v. Run into scurry off to 快走(跑)到 Remember recite, regurgitate, rote v. 照搬背诵 Out going gregarious adj. Sad dismal adj., n. Salty briny adj. 多盐的 Separate steps discrete steps 分开(各自)步骤 Search scour, hunt, quest v. 搜寻 (scouring the woods for a kid) Should ought auxv. 本应该 (2You ought to work hard) Similar to akin to 和 … 一样 Slim slender adj. Tell impart, communicate, inform, convey v. 告知，传授 Totally utterly, completely, absolutely, extremely, entirely adv. Waste squander n. Wine dram, Whisky, n. hillbilly: (侮辱)乡下人 BiliBili: 史上最不正經的生物狗","link":"/2020/07/16/LearnNotes/Eng_w/"},{"title":"urwid | An TUI lib for python development","text":"urwid Reference：http://urwid.org/tutorial/index.html Urwid Tutorial Minimal Application Global Input Display Attributes High Color Modes Question and Answer Signal Handlers Multiple Questions Simple Menu Cascading Menu Horizontal Menu Adventure Game Main tutorial: http://urwid.org/manual/index.html Library Overview Main Loop Widgets Displayed Event Loops Display Modules Raw and Curses Display Modules Other Display Modules Setting a Palette Widgets Widget Layout Box, Flow and Fixed Widgets Included Widgets Decoration Widgets Container Widgets ListBox Contents Custom Widgets Widget Metaclass User Input Keyboard Input Mouse Input Text Layout Custom Text Layouts Text Layout Structures Encodings Supported Unicode Support Pass-through Support Future Work Display Attributes Using Display Attributes Foreground and Background Settings Recommended Combinations Canvas Cache Composite Canvases Cache Lifetime Future Work Quick Start: import urwidtxt = urwid.Text(u&quot;Hello World&quot;)fill = urwid.Filler(txt, 'top') #'top', 'middle', 'bottom'loop = urwid.MainLoop(fill)loop.run() Global Input import urwiddef show_or_exit(key): if key in ('q', 'Q'): raise urwid.ExitMainLoop() txt.set_text(repr(key))txt = urwid.Text(u&quot;Hello World&quot;)fill = urwid.Filler(txt, 'top')loop = urwid.MainLoop(fill, unhandled_input=show_or_exit)loop.run() Display Attributes import urwiddef exit_on_q(key): if key in ('q', 'Q'): raise urwid.ExitMainLoop()palette = [ ('banner', 'black', 'light gray'), ('streak', 'black', 'dark red'), ('bg', 'black', 'dark blue'),]txt = urwid.Text(('banner', u&quot; Hello World &quot;), align='center')map1 = urwid.AttrMap(txt, 'streak')fill = urwid.Filler(map1)map2 = urwid.AttrMap(fill, 'bg')loop = urwid.MainLoop(map2, palette, unhandled_input=exit_on_q)loop.run() 原图 去掉‘bg’ 去掉‘streak’ 解释： txt， 最顶层，标签是‘banner’，获取palette中‘banner’的设置map1， 和txt 一个道理。txt 丢到map1， map1丢到 fill， fill丢到map2， 一层盖一层。 Question and Answer import urwiddef exit_on_q(key): if key in ('q', 'Q'): raise urwid.ExitMainLoop()class QuestionBox(urwid.Filler): def keypress(self, size, key): if key != 'enter': return super(QuestionBox, self).keypress(size, key) self.original_widget = urwid.Text( u&quot;Nice to meet you,\\n%s.\\n\\nPress Q to exit.&quot; % edit.edit_text)edit = urwid.Edit(u&quot;What is your name?\\n&quot;)fill = QuestionBox(edit)loop = urwid.MainLoop(fill, unhandled_input=exit_on_q)loop.run() Signal Handlers import urwidpalette = [('I say', 'default,bold', 'default', 'bold'),]ask = urwid.Edit(('I say', u&quot;What is your name?\\n&quot;))reply = urwid.Text(u&quot;&quot;)button = urwid.Button(u'Exit')div = urwid.Divider()pile = urwid.Pile([ask, div, reply, div, button])top = urwid.Filler(pile, valign='top')def on_ask_change(edit, new_edit_text): reply.set_text(('I say', u&quot;Nice to meet you, %s&quot; % new_edit_text))def on_exit_clicked(button): raise urwid.ExitMainLoop()urwid.connect_signal(ask, 'change', on_ask_change)urwid.connect_signal(button, 'click', on_exit_clicked)urwid.MainLoop(top, palette).run() Simple Menu import urwidchoices = u'Chapman Cleese Gilliam Idle Jones Palin'.split()def menu(title, choices): body = [urwid.Text(title), urwid.Divider()] for c in choices: button = urwid.Button(c) urwid.connect_signal(button, 'click', item_chosen, c) body.append(urwid.AttrMap(button, None, focus_map='reversed')) return urwid.ListBox(urwid.SimpleFocusListWalker(body))def item_chosen(button, choice): response = urwid.Text([u'You chose ', choice, u'\\n']) done = urwid.Button(u'Ok') urwid.connect_signal(done, 'click', exit_program) main.original_widget = urwid.Filler(urwid.Pile([response, urwid.AttrMap(done, None, focus_map='reversed')]))def exit_program(button): raise urwid.ExitMainLoop()main = urwid.Padding(menu(u'Pythons', choices), left=2, right=2)top = urwid.Overlay(main, urwid.SolidFill(u'\\N{MEDIUM SHADE}'), align='center', width=('relative', 60), valign='middle', height=('relative', 60), min_width=20, min_height=9)urwid.MainLoop(top, palette=[('reversed', 'standout', '')]).run() Pop-up Menu import urwiddef menu_button(caption, callback): button = urwid.Button(caption) urwid.connect_signal(button, 'click', callback) return urwid.AttrMap(button, None, focus_map='reversed')def sub_menu(caption, choices): contents = menu(caption, choices) def open_menu(button): return top.open_box(contents) return menu_button([caption, u'...'], open_menu)def menu(title, choices): body = [urwid.Text(title), urwid.Divider()] body.extend(choices) return urwid.ListBox(urwid.SimpleFocusListWalker(body))def item_chosen(button): response = urwid.Text([u'You chose ', button.label, u'\\n']) done = menu_button(u'Ok', exit_program) top.open_box(urwid.Filler(urwid.Pile([response, done])))def exit_program(button): raise urwid.ExitMainLoop()menu_top = menu(u'Main Menu', [ sub_menu(u'Applications', [ sub_menu(u'Accessories', [ menu_button(u'Text Editor', item_chosen), menu_button(u'Terminal', item_chosen), ]), ]), sub_menu(u'System', [ sub_menu(u'Preferences', [ menu_button(u'Appearance', item_chosen), ]), menu_button(u'Lock Screen', item_chosen), ]),])class CascadingBoxes(urwid.WidgetPlaceholder): max_box_levels = 4 # def __init__(self, box): super(CascadingBoxes, self).__init__(urwid.SolidFill(u'/')) self.box_level = 0 self.open_box(box) # def open_box(self, box): self.original_widget = urwid.Overlay(urwid.LineBox(box), self.original_widget, align='center', width=('relative', 80), valign='middle', height=('relative', 80), min_width=24, min_height=8, left=self.box_level * 3, right=(self.max_box_levels - self.box_level - 1) * 3, top=self.box_level * 2, bottom=(self.max_box_levels - self.box_level - 1) * 2) self.box_level += 1 # def keypress(self, size, key): if key == 'esc' and self.box_level &gt; 1: self.original_widget = self.original_widget[0] self.box_level -= 1 else: return super(CascadingBoxes, self).keypress(size, key)top = CascadingBoxes(menu_top)urwid.MainLoop(top, palette=[('reversed', 'standout', '')]).run() Horizontal Menu import urwidclass MenuButton(urwid.Button): def __init__(self, caption, callback): super(MenuButton, self).__init__(&quot;&quot;) urwid.connect_signal(self, 'click', callback) self._w = urwid.AttrMap(urwid.SelectableIcon( [u' \\N{BULLET} ', caption], 2), None, 'selected')class SubMenu(urwid.WidgetWrap): def __init__(self, caption, choices): super(SubMenu, self).__init__(MenuButton( [caption, u&quot;\\N{HORIZONTAL ELLIPSIS}&quot;], self.open_menu)) line = urwid.Divider(u'\\N{LOWER ONE QUARTER BLOCK}') listbox = urwid.ListBox(urwid.SimpleFocusListWalker([ urwid.AttrMap(urwid.Text([u&quot;\\n &quot;, caption]), 'heading'), urwid.AttrMap(line, 'line'), urwid.Divider()] + choices + [urwid.Divider()])) self.menu = urwid.AttrMap(listbox, 'options') # def open_menu(self, button): top.open_box(self.menu)class Choice(urwid.WidgetWrap): def __init__(self, caption): super(Choice, self).__init__( MenuButton(caption, self.item_chosen)) self.caption = caption # def item_chosen(self, button): response = urwid.Text([u' You chose ', self.caption, u'\\n']) done = MenuButton(u'Ok', exit_program) response_box = urwid.Filler(urwid.Pile([response, done])) top.open_box(urwid.AttrMap(response_box, 'options'))def exit_program(key): raise urwid.ExitMainLoop()menu_top = SubMenu(u'Main Menu', [ SubMenu(u'Applications', [ SubMenu(u'Accessories', [ Choice(u'Text Editor'), Choice(u'Terminal'), ]), ]), SubMenu(u'System', [ SubMenu(u'Preferences', [ Choice(u'Appearance'), ]), Choice(u'Lock Screen'), ]),])palette = [ (None, 'light gray', 'black'), ('heading', 'black', 'light gray'), ('line', 'black', 'light gray'), ('options', 'dark gray', 'black'), ('focus heading', 'white', 'dark red'), ('focus line', 'black', 'dark red'), ('focus options', 'black', 'light gray'), ('selected', 'white', 'dark blue')]focus_map = { 'heading': 'focus heading', 'options': 'focus options', 'line': 'focus line'}class HorizontalBoxes(urwid.Columns): def __init__(self): super(HorizontalBoxes, self).__init__([], dividechars=1) # def open_box(self, box): if self.contents: del self.contents[self.focus_position + 1:] self.contents.append((urwid.AttrMap(box, 'options', focus_map), self.options('given', 24))) self.focus_position = len(self.contents) - 1top = HorizontalBoxes()top.open_box(menu_top.menu)urwid.MainLoop(urwid.Filler(top, 'middle', 10), palette).run() Frames urwid.Text 不能:{Column, AttrMap} --&gt; Mainloop 可:{Filler, Frame } -&gt; Mainloop Column -&gt; Filler -&gt; MainloopText -&gt; Filler -&gt; MainloopColumn -&gt; Filler -&gt; AttrMap -&gt; MainloopText -&gt; Filler -&gt; AttrMap -&gt; Mainloop Frame Frame(header=hdr, body=map2) Text -&gt; AttrWrap &gt; header Columns -&gt; Filler -&gt; AttrMap -&gt; body ListBox Filler -&gt; ListBox Padding -&gt; SimpleListWalker -&gt; ListBox [Text, Pile, Columns] -&gt; SimpleListWalker -&gt; ListBox [Text, Pile, Columns]-&gt; SimpleListWalker -&gt; ListBox -&gt; AttrWrap -&gt; Frame Exampels Source: https://github.com/urwid/urwid/tree/master/examples browse.py bigtext.py treesample.py calc.py tour.py edit.py fib.py graph.py terminal.py input_test.py pop_up.py palette_test.py more examples: programcreek.com pop_up.py P-raw ##!/usr/bin/env pythonimport urwidclass PopUpDialog(urwid.WidgetWrap): &quot;&quot;&quot;A dialog that appears with nothing but a close button &quot;&quot;&quot; signals = ['close'] def __init__(self): close_button = urwid.Button(&quot;that's pretty cool&quot;) urwid.connect_signal(close_button, 'click', lambda button:self._emit(&quot;close&quot;)) pile = urwid.Pile([urwid.Text( &quot;^^ I'm attached to the widget that opened me. &quot; &quot;Try resizing the window!\\n&quot;), close_button]) fill = urwid.Filler(pile) self.__super.__init__(urwid.AttrWrap(fill, 'popbg'))class ThingWithAPopUp(urwid.PopUpLauncher): def __init__(self): self.__super.__init__(urwid.Button(&quot;click-me&quot;)) urwid.connect_signal(self.original_widget, 'click', lambda button: self.open_pop_up()) def create_pop_up(self): pop_up = PopUpDialog() urwid.connect_signal(pop_up, 'close', lambda button: self.close_pop_up()) return pop_up def get_pop_up_parameters(self): return {'left':0, 'top':1, 'overlay_width':32, 'overlay_height':7}fill = urwid.Filler(urwid.Padding(ThingWithAPopUp(), 'center', 15))loop = urwid.MainLoop( fill, [('popbg', 'white', 'dark blue')], pop_ups=True)loop.run() 原来程序: 在 pop up 的框里面加一个退出按钮结构解析: close_button = urwid.Button(&quot;that's pretty cool&quot;) #定义一个button 名称urwid.connect_signal(close_button, 'click', # button 的作用 lambda button:self._emit(&quot;close&quot;))pile = urwid.Pile([urwid.Text( #一段文字,加上前面的button &quot;^^ I'm attached to the widget that opened me. &quot; #pile 在一起 &quot;Try resizing the window!\\n&quot;), close_button])fill = urwid.Filler(pile) #封装self.__super.__init__(urwid.AttrWrap(fill, 'popbg')) #完成 可以看出基本结构为, Button -&gt; Pile + Button -&gt; Filler因此, 除了加入button title和 signal 外, 还需要在 pile处, 一起打包.测试: esc_button = urwid.Button(&quot;Esc&quot;)urwid.connect_signal(esc_button, 'click', lambda button:self._emit(&quot;close&quot;))pile = urwid.Pile([urwid.Text( &quot;^^ I'm attached to the widget that opened me. &quot; &quot;Try resizing the window!\\n&quot;), close_button,esc_button]) 直接加的话, 按键会依次排列: Button 位置等属性 用 urwid.Padding(close_button, ‘left’, 18) 参数 调整button 位置, 结果一个上左, 一个右下注: 18 为字符数 这里用到一个新函数 ,参考来源:stackoverflow urwid.Columns 基本用法: urwid.Columns([button1, button2]) def on_exit_clicked(button): raise urwid.ExitMainLoop()## button, 加在上文 p-raw 的 9~11行之间button = urwid.Button(u'Exit')urwid.connect_signal(button, 'click', on_exit_clicked)## button的排序, 加载urwid.Pile() 里面urwid.Columns([ urwid.Padding(close_button, 'left'), urwid.Padding(button, 'right', 8),]), 完整代码:pop-2 ##!/usr/bin/env pythonimport urwiddef on_exit_clicked(button): raise urwid.ExitMainLoop()class PopUpDialog(urwid.WidgetWrap): &quot;&quot;&quot;A dialog that appears with nothing but a close button &quot;&quot;&quot; signals = ['close'] def __init__(self): close_button = urwid.Button(&quot;that's NOT COOL&quot;) urwid.connect_signal(close_button, 'click', lambda button:self._emit(&quot;close&quot;)) button = urwid.Button(u'Exit') urwid.connect_signal(button, 'click', on_exit_clicked) pile = urwid.Pile([urwid.Text( &quot;^^ I'm attached to the widget that opened me. &quot; &quot;Try resizing the window!\\n&quot;), urwid.Columns([ urwid.Padding(close_button, 'left'), urwid.Padding(button, 'right', 8), ]), ]) fill = urwid.Filler(pile) self.__super.__init__(urwid.AttrWrap(fill, 'popbg'))class ThingWithAPopUp(urwid.PopUpLauncher): def __init__(self): self.__super.__init__(urwid.Button(&quot;click-me&quot;)) urwid.connect_signal(self.original_widget, 'click', lambda button: self.open_pop_up()) def create_pop_up(self): pop_up = PopUpDialog() urwid.connect_signal(pop_up, 'close', lambda button: self.close_pop_up()) return pop_up def get_pop_up_parameters(self): return {'left':0, 'top':1, 'overlay_width':32, 'overlay_height':7}button = urwid.Button(u'Exit')urwid.connect_signal(button, 'click', on_exit_clicked)pile = urwid.Pile([urwid.Padding(ThingWithAPopUp(), 'center', 15),button])fill = urwid.Filler(pile)loop = urwid.MainLoop( fill, [('popbg', 'white', 'dark blue')], pop_ups=True)loop.run() pop window size 修改这里就好了~ def get_pop_up_parameters(self): return {'left':0, 'top':1, 'overlay_width':32, 'overlay_height':7} 魔改 左右各一个list:将pile 放入column中 把pop-2 的 51,52行改成 pile = urwid.Pile(body_A)col = urwid.Columns([pile,urwid.Text(&quot;│&quot;),('fixed',14,pile)])fill = urwid.Filler(col) bigtext.py 非常靓的一个 排版区 # Create chars_availcah = urwid.Text(&quot;Characters Available:&quot;)self.chars_avail = urwid.Text(&quot;&quot;, wrap='any')ca = urwid.AttrWrap(self.chars_avail, 'chars')chosen_font_rb.set_state(True) # causes set_font_event call# Create Edit widgetedit = self.create_edit(&quot;&quot;, &quot;Urwid &quot;+urwid.__version__, self.edit_change_event)# ListBoxchars = urwid.Pile([cah, ca])fonts = urwid.Pile([urwid.Text(&quot;Fonts:&quot;)] + self.font_buttons, focus_item=1)col = urwid.Columns([fonts,('fixed',16,chars)], 3, focus_column=1)bt = urwid.Pile([bt, edit], focus_item=1)l = [bt, urwid.Divider(), col]w = urwid.ListBox(urwid.SimpleListWalker(l))# Framew = urwid.AttrWrap(w, 'body')hdr = urwid.Text(&quot;Urwid BigText example program - F8 exits.&quot;)hdr = urwid.AttrWrap(hdr, 'header')w = urwid.Frame(header=hdr, body=w) Frame 排版结构 继续魔改. 首先发现一个bug, 虽然说按F8 退出, 但是按完以后, 只出来一个 pop window, 写着quit, 然后, 就没有然后了. 所以我们先来加一个Esc 按钮吧~ (以后再说) Refresh Eample import urwidimport timeimport sys'''https://github.com/bavanduong/urwid-example/blob/master/clock.py'''class Clock: def keypress(self, key): if key in ('q', 'Q'): raise urwid.ExitMainLoop() def setup_view(self): self.clock_txt = urwid.BigText( time.strftime('%H:%M:%S'), urwid.font.HalfBlock5x4Font()) self.view = urwid.Padding(self.clock_txt, 'center', width='clip') self.view = urwid.AttrMap(self.view, 'body') self.view = urwid.Filler(self.view, 'middle') def main(self): self.setup_view() loop = urwid.MainLoop( self.view, palette=[('body', 'dark cyan', '')], unhandled_input=self.keypress) loop.set_alarm_in(1, self.refresh) loop.run() def refresh(self, loop=None, data=None): self.setup_view() loop.widget = self.view loop.set_alarm_in(1, self.refresh)if __name__ == '__main__': clock = Clock() sys.exit(clock.main()) 實戰 Todolist Bilibili 信息板","link":"/2020/06/23/Python/urwid/"},{"title":"Digestion System of Fish","text":"Digestion System of Fish General Digestion tracks Mouth Buccal cavity Pharynx Oesophagus Stomach Intestine Anus Cloaca img from ourmarinespecies.com, copyright belongs to author Sharks reference:The Shark Digestive System Digestive Tracks Mouth Grain Foods Lack of salivary amylase Esophagus Stomach Spiral Intestine (small intestine) The place absorption and nutrients and toxins take palce Duodenum (the first part of the spiral intestine) pyloric sphincter/ pylorus (First part of Duodenum) The muscle expands and contrast to control the food into the duodenum (Spiral valve in the inside of intestine) Colon (an enlarged Intestine) water absorption Rectum and Cloaca (the waste expelled) Digestive Organ Liver detoxification (hepatic portal system) HPS: gathering the blood from the GI track and taking it back to the liver to be detox. storage Clucose produces vile Squalene (Shark) It allows buoyancy because the oil is lighter than water bile (looks like green blister) stores at gallbladder Spleen Produces, stores, and breaks down blood cells ** Major Part of Immune system** for shark(fish) Pancreas exocrine function: Pancreatic juices. endocrine function: regulating blood sugar (insulin). Rectal Gland salt gland: salty homeostasis Digestive System and Physiology of Digestion in Fishes reference:Video Pancrease exocrine secretion into Intestine Endocrine secretion of the hormones insulin and glucagon Liver Priduce bile synthesis and stores glycogen Other Glands Mucosal &amp; sybmucosal lining of the fish contain some glands Glandular structure of stomach comprises the gastric glands in the cardiac and the pyloric regions Gastric Phase of Digestion Pepesin predominant gastric enzyme Trypsin Carbohydrases Reference: Fish digestive system| scoliodon digestive system","link":"/2020/08/12/LearnNotes/Fish_dygestion/"},{"title":"高考笔记整理","text":"网上高考笔记搜罗: 大家加油！！ 本文为我突发奇想的简单搜索整理而成。结果质量参差不齐。为了给大家更好的参考，我在链接后， 加上了发表时间， 阅读和下载次数(如果有的话)，希望能够帮助大家。 如果大家有自己的笔记，或者别的链接，欢迎在评论处留言， 我会认真对待， 酌情更新。如果评论区失效（网络问题或者没有github账号）， 也可以私信我的B站账号: 史上最不正經的生物狗 专栏 高中生学习分享写文章 知乎资料超多， 但是没有分类整理。可以自行参考 学习方法网各个阶段都有， 值得了解 高考网超多试卷， 随心下载 新东方在线新东方旗下的学习网站 数学 高中数学笔记(自己整理)!!! – 百度文库 1巫1 2016 21981阅读; 244下载; 63页 英语 高中英语语法大全 最新整理 – 学习方法网 学习方法网 2018 来源:网络综合 | 作者:佚名 | 本文已影响 3026 人 历年阅读理解题目 – 新东方在线 新东方在线 2016~2018 66套 物理 133页高中物理笔记（高清版），没有最全！建议高中生收藏，打印，家长转给孩子 – 知乎 高中生学习分享写文章 2019 多图手写，好像不全 化学 高中化学重要知识点详细总结全套笔记 – 学习方法网 学习方法网来源:网络综合 | 作者:佚名 生物 高考生物备考笔记(完整版) – 百度文库 h377683120的店 2018 692阅读; 1下载(30元); 84页 政治 高考政治备考笔记(全) – 百度文库 安普合 2020 29阅读; 3下载; 49页 地理 高中地理全套笔记 – 百度文库 知识天空的店 2020 48阅读; 2下载(5元); 101页 历史 高中历史全套笔记 – 百度文库 才情数学人 2018 4935阅读; 277下载(1元); 288页 BiliBili：史上最不正經的生物狗","link":"/2020/07/15/LearnNotes/GKNotes/"},{"title":"English Sentences Collection for Sencond Language Learner","text":"English Sentences Collection for Sencond Language Learner details { font-size:20px; padding-top:20px; } details div{ padding-top:10px; background:#ffe3e0; } details fb{ background:#77C5DB; } details fr{ background:salmon; } details fg{ background:#C1EE91; } I am collecting some English sentences for second language learner. Chinese translation where pop up when you click the sentence 1. Gutman gives plantation owners little credit for these achievement. Gutman 没有把这些成功归功于地主们 (GRE Reading) 2. He's always trying to ingratiate himself with the teacher. 他总是设法讨好老师 (Shanpei) 3. As my won studies have advanced, I have been increasingly impressed. 当我的研究取得进展时，我被惊艳到了 (Scientific American) 4. The country's population has dwindled to half of its former size. 这个国家的人口已经缩减到了从前的一半 (Shanbei) 5. His grandfather hired two itinerate farm workers. 他祖父雇佣了两名农场短工 (Shanbei) 6. Unhappily, some of frailties—our need for ever-increasing security among them—are presently maladaptive today. 不幸的是，这些弱点中的一些弱点——包括我们对不断增加的安全感的需求——目前不适应人类发展 (GRE Reading, Adapted) 7. He has showed xenophobic sentiment to bitterly oppose immigration policy. 他强烈反对移民政策, 表现出了排外情绪 (Shanbei) 8. Whether this resistance results (resistence the growth of harmful fungi) from exclusion of harmful fungi through competition for sites, from metabolic change involving antibiotic production, or from increased vigor is undetermined. 植物抵抗力的增加是来自地盘的争夺以抵抗有害真菌，来自抗菌素产生的变化，还是来自活力的增强，这到现在还未确定 (GRE Reading) Wheter xxx results from xxx, from xxx, or from xxx is undetermined. 9. Mycorrhizal fungi have escaped widespread investigation until recently for two reasons. 根菌由于一下俩个原因而未被广泛研究 (GRE, Adapted) Generaly, fungi can not escape from the research. So, it is an rhetorical style. 真菌是无法主动逃脱研究员的调查, 因此这里可以算一种拟人修饰. 10. The fungi cannot as yet be cultivated in the absence of living root. 这种真菌目前还不能在没有活根的情况下所培养(GRE Reading) As yet, 目前为止 11. Your refusal to answer will be regarded as tantamount to an admission of guilt. 你拒绝回答将被视作等同于承认有罪(Shanbei) 1. regard as... 2. tantamount to... 12. Not even remotely, the additional input of thermal energy into the circulating refrigerant via the evaporator accounts for the difference in the energy equation. 一点也没有. 额外通过蒸发机而输入到循环流动制冷剂中的热量,就使得输入能量与输出能量不对等(输入大于输出)(GRE Reading) accounts for... the difference in the energy equation. 注:全句的动词为accounts 13. Demand for new machine is outstripping supply. 新机器目前供不应求 outstripping supply 14. Even the requirement that biomaterials processed from these materials be nontoxic to host tissue can be meet by techniques derived from studying the reactions of tissue cultures to biomaterials or from short-term implants. 即使生物材料对宿主的无毒性也可以通过观察培养组织对生物材料的反应,或者短期移植的应激反应 的技术手段来实现(GRE Reading) \"A can be meet by B\" mean by doing B, we could achive or aquire A. 可以通过做 A(a perpose, result, commodity, etc. ) 来实现/获得 B 15. Our fundamental understanding of how implant devices adhere to tissues remains woefully incomplete. 我们对于移植材料和(受体)组织是如何粘合的基础认识都是非常不完善的 (GRE Reading) woefully 做程度副词 表示负状态的 \"非常的\"... 16. I used to be petrified of spiders when I was a kid. 我小时候只要看见蜘蛛就会被吓的僵硬(Shanbei) Notice: be petrified of; be petrified by/with &lt;br&gt; 17. He drank copious amounts of beer. 他喝了大量的酒(Shanbei) 18. Jean Wagner's most enduring contribution to the study of Afro-American poetry is his insistence that it be analyzed in a religious, as well as secular, frame of reference. Jean Wagner在黑人诗歌方面最深远的贡献是他的主张: 这些诗歌应该拿宗教和世俗的的框架来参考(他们的价值) (GRE Reading) endring contribution, long-lasting contribution... his insistence, his idea, his perspective, his piontview, his standpoint... 19. The two, he argued, form a symbiotic union in which religious feelings are often applied to racial issues and racial problems are often projected onto a metaphysical plane. 他认为, 这两个手法被变成老人一个共生体: 用宗教的情感去述说种族问题, 把种族问题投射到形而上学的层面, (GRE Reading) endring contribution, long-lasting contribution... his insistence, his idea, his perspective, his piontview, his standpoint... 20. No matter what happens, he always has an air of detachment. 無論發生了什麼, 他都是一副事不關己的態度. (Shanbei) 21. Due to a slight technical hitch the meeting will be starting fifteen minutes later. 由於技術故障的原因,會議將會被推遲15min. (Shanbei) 22. She didn't want to take on a job that would entail a lot of travelling. 她不想找一個經常出差的工作. (Shanbei) 23. My interest in painting was purely perfunctory. 我對畫畫完全只有3分熱度.(我只是不得以才敷衍一下隨便畫畫) (Shanbei) 24. My time is too valuanle to waste on frivolous games. 我的時間非常寶貴,纔不能浪費在遊戲上. (Shanbei) 25. We're all impressed by her ebullient personality. 我們都被她元氣滿滿的性格給驚豔到了. (Shanbei) ebullient: 充滿自信的, 熱情洋溢的,精力充沛的 26. The charming pastoral scenery attracted plenty of tourists. 迷人的田園風景吸引來了很多遊客. (Shanbei) 有了 PASTORAL, 再也不用寫the scenery of village 了 27. I balked at the prospect of spending over 12 hours on the train. 想到要在火車上呆12個多小時, 我猶豫了. (Shanbei) Balk: hesitate. Balked at the prospect of.... 28. Sushi is a quintessential Japanesse cuisine. 壽司是一種典型的日料. (Shanbei) Quintissential: typical, essentric Cuisine:\\ kwi-ˈzēn \\, style of cooking. 29. Is English a compulsory subject? 英語是必修科目嘛？ (Shanbei) Compulsory: 必修的，強制執行的 Compulsory Subject: 必修課 30. The loss of protein is an obvious feature during senescence. 蛋白質流失是衰老過程中的典型特徵。 (Shanbei) Senescence aging 的最好替代辭 31. Having surfeited himself on ice cream, he skipped the dinner. 由於吃冰太多淇淋吃到噁心了，他不吃晚飯了。 (Shanbei) Sufeit: 1, an overabundant supply; 2, disgust casued by excess 32. My friends keep badgering me to buy that washing machine. 我的朋友不斷的纏著讓我買洗衣機。 (Shanbei) Bagering: 1,to harass or urge persistently; pester; nag. 33. The overall task looks forbidding, but the stakes are too high not to undertake. 整個任務看起來幾乎做不到，但是由于他的代價太高而(我們)不得不做到。 (GRE Reading) 34. The new drug has an adverse impact on human healt. 這個新藥有損健康(副作用) (Shanbei) Adverse impact: side effect 35. The sun dissipated the mist. 陽光把霧驅散了。 (Shanbei) 36. It would be imprudent to put all your eggs in one basket. 把所有雞蛋放在一個籃子裏是不明智的. (Shanbei) Imprudent: 37. The food spplies necessary to sustain the large vent communities, however, must be many times the ordinary fallout. 热泉口的生物群落所需的食物是正常掉落食物量的好几倍. (GRE Reading) Ordinary order: The food must be many times the ordinary fallout supplies necessary to sustain the large vent communities. Verb: Supplies 38. If such astonishing concentrations of bacteria were typical of vent outflow, then food within the vent would dwarf any contributions from advection. 如果如此大量的细菌是热泉的典型特征的话,那么漂流对热泉中总食物量的贡献几乎为零 (GRE Reading) If...than; dwarf any contributions 39. No other communities on Earth are independent of photosythesis. 地球上没有除此外的群落可以独立于光合作用(营生). (GRE Reading) independent of: 40. Why, then, was it Friedan who became the prophet of women's emancipation in the United States? 那麼爲什麼Friedan成了美國的婦女解放者先驅? (GRE Reading) the prophet of women's emancipation: prophet 常用的意思是 on who foretells future events; 這裏的意思爲: an effective or leading spokesman for a cause, doctrine, or group. 先驅, 領頭人, 發言人. 因此這裏爲, 女性解放的先驅(領導者, 倡導者) 41. The country had entered the silent, fearful fortress of the anticommunist McCarthy years, and Beauvoir was suspected of Marxist sympathies. 整個國家陷入了沉默,恐慌的反共產主義的堡壘中 McCarthy 年代, 而 Beauvoir 被懷疑成了馬克思主義信仰者. (GRE Reading) 42. A good dictionary is indispensable for learning a foreign languiage. 一個好的詞典對於學一門外語來說, 是不可或缺的. (Shanbei) indispensable: 不可或缺的 43. The educationist advocates analytical thinking, rather than rote learning. 這個教育家提倡用分析性的思維學些, 而不是死記硬背型的學習 (Shanbei) rote learning 44. The growing emphasis on deterrence is bound to offer increasing scope for women to become involved in novel types of noncombat military assignments. 軍事威懾重要性的增強, 增加了 女性 在典型的非戰鬥方面的軍事任務 的用武之地 的範圍. (GRE) 45. Why then the two years that passed before he translated his private misgivings into public dissent. 爲什麼過了兩年, 他(馬丁路德金)才把他的個人懷疑(異議)轉化成了公衆異議? misgiving: A feeling of doubt or suspicion especially concerning a future event. dissent: To differ in opinion (GRE) 46. Members of the union's negotiating team insisted on several changes to the company's proposal before they would support it, making it clear that they would brook no compromise. 聯會的談判隊伍的人員堅持改變公司的幾個提議才能獲得他們的支持, 並且很清楚的表示沒有妥協的餘地. brook no compromise: 忍受沒有的妥協 -- 無法忍受(自己)妥協;不可能做出妥協. (GRE) 相似表達: touch nothing! (什麼都別碰) 47. Films that critics have slumbered through rarely generate industry excitement, even though the critics' somnolent/lethargic reception may be less the fault of the movie than of its unfortunate time slot near a fatiguing film festival's conclusion. Ummmmm, 我先多看幾遍. (GRE 填空) 48. Even though women in U.S. would not gain right to vote until 1920, throughout the 19-century many feminist goals were gradually realized/achieved, especially the right of married women to control their own property. 19世紀, 女權主義開始慢慢的形成, 尤其是婚後女性的財產所有權, 儘管1920年, 美國才通過了女性投標選舉的權利 would not... until(GRE 填空) 49. A new television documentary focuses on one of the prime minister's defining contradiction portraying her as a woman who cultivated an image of abstemiousness, but who liked to live grandly. 一個新的電視紀錄片專注於一個首相的矛盾, 並把她描繪成一個被培養成了一個有節制的人, 但是她卻想過非常grandly的生活 gradnly / abstemiousness 這裏做了一組反義詞. 但是我, 想不出, 太好的, 翻譯 - - 唉...(GRE 填空) 50. So far, researchers have found no evidence of seasonal breading among vent-dewlling species that provide their offspring with yolk to sustain them or among vent-dwelling species found in areas of the ocean with not seasonal algae blooms. 哈哈哈, 反正我看懂了, 你們先自己想一下(GRE Reading) 51. who's up, who's down and who's chiseling on the side. 誰得誰失,誰在背後操盤(James Reston) 52. By sheer fluke, one of the shipowner's epmployees was in the city. 非常湊巧的是, 船主人的一個水手就在這個城(Shanbei) 53. Of course, there is far more oil underground than can be recovered. It may be in a pool too small or too far from a potential market to justify the expense of drilling. 事實上，未被開採的油田遠比被開採的多。他們可能因量太少，或者太偏僻而使得開採成本高於投入(而未被開採) (TOEFL Reading 4-3) 54. To indicate that supposed proof for Heyerdahl’s theory has an alternative explanation. 爲了表明，Heyerdahl的假說的論點有其他可選方案 (說明，Heyerdahl 的假說， 可能是錯誤的， 或可能性很低) (TOEFL Reading 5-2) 55. Nothing but fear from here on out.. From here on out: from this time forward (从此以后) BiliBili: 史上最不正經的生物狗","link":"/2020/02/10/LearnNotes/Eng/"},{"title":"Effects of black soldier fly (Hermetia illucens) larvae meal protein as a fishmeal replacement on the growth and immune index of yellow catfish (Pelteobagrus fulvidraco)","text":"Effects of black soldier fly (Hermetia illucens) larvae meal protein as a fishmeal replacement on the growth and immune index of yellow catfish (Pelteobagrus fulvidraco) Cite: Xiaopeng Xiao, Peng Jin, Longyu Zheng, et al. “Effects of black soldier fly (Hermetia illucens) larvae meal protein as a fishmeal replacement on the growth and immune index of yellow catfish (Pelteobagrus fulvidraco)” Aquaculture Research(2018): 1569-1577. Abstract 65 days feeding trial 0% (control), 13%, 25%, 37%, 48%, 68%, 85% and 100%. Increasing weight growth performance Increasing immune index 29.1% of replacement has the best effect on growth and immune index could partially replace the fish meal MATERIALS AND METHODS Six day old BSFL was collected at the first day as it appearance of pre-pupae. Results Category Higher Lower Normal Notes Growth performance T13%, T25%, T37% and T48% Feed Conversion Ratio T13%, T25%, T37% and T48% Not Significant Protein productive value T13%, T25%, T37%, T48% and T68% Not Significant crude lipid T37% and T48% LZM activity T68% and T100% Discussion 25% of the replacement has the best effects on the fish. replacement is up to 48% This agree with up to 45% replacement in juvenile European seabass(Magalh~ aes et al., 2017).[1] yellow mealworms meal could only replace 18% of the FM diet.(Su et al.,2017)[2] The value of Lue is higher than previous studies. Chitin might influence the feed intake, availability and digestibility of the nutrients and growth performance of the fish (Cummins et al., 2017)[3] Increasing the immune index, might casued by the Chitin Chitin may also responsible to the decrease of the palatable. Rui Magalhãesab, Antonio, Sánchez-Lópezbc, Renato Silva Leal, et al., (2017). Black soldier fly (Hermetia illucens) prepupae meal as a fish meal replacement in diets for European seabass (Dicentrarchus labrax). Aquaculture, 476, 79–85. https://doi.org/10.1016/j.aquaculture.2017.04.021 ↩︎ Su, J., Gong, Y., Cao, S., Lu, F., Han, D., Liu, H., et al., (2017). Effects of dietary Tenebrio molitor meal on the growth performance, immune response and disease resistance of yellow catfish (Pelteobagrus fulvidraco). Fish &amp; Shellfish Immunology, 69, 59–66. https://doi.org/10.1016/j.fsi.2017.08.008 ↩︎ Cummins, V. C. Jr, Rawles, S. D., Thompson, K. R., Velasquez, A., Kobayashi, Y., Hager, J. &amp; Webster, C. D. (2017). Evaluation of black soldier fly (Hermetia illucens) larvae meal as partial or total replacement of marine fish meal in practical diets for pacific white shrimp (Litopenaeus vannamei). Aquaculture, 473, 337–344. https://doi.org/10.1016/j.aquaculture.2017.02.022 ↩︎","link":"/2020/12/27/LearnNotes/Paper_BSFlylavea_Catfish_2018/"},{"title":"Introduction to Drosophila","text":"Introduction to Drosophila Other infor you can read: socmucimm, 2014 This notes from the Youtube video: Walter Jahn; GENETICS: Drosophila; 2020 Usual USA/Upstream Activating Sequences Videos: Lecture 5 Drosophila; UVUProfessor; 2015/02/09 Text Lecture: DEVELOPMENTAL BIOLOGY 3230; utah.edu Why Drosophila Ideal for genetic studies Rapid life cycle Readiness to bread Polytene chromosomes Phenotypic mutatans Superficial Cleavage Pull the egg surface down and to form cell membrane Centrally located yolk confines cleavage to the cytoplasmic rim of the egg Syncytial blastoderm All cleavage nuclei are contained within a common cytoplasm Cellular blastoderm Each somatic nucleus is partitioned into a single cell © Gerhard Scholtz, Carsten Wolff Watters, Chris. (2005). Video Views and Reviews: Cytokinesis: A Phenomenon Overlooked Too Often. Cell biology education. 4. 10-8. 10.1187/cbe.04-08-0049. © utah.edu © Marc F Schetelig Carsten, et al. Gastrulation Reading Materials: Martin, Adam. (2020). The Physical Mechanisms of Drosophila Gastrulation: Mesoderm and Endoderm Invagination. Genetics. 214. 543-560. 10.1534/genetics.119.301292. © Martin, Adam, et al. © Dr. Brian E. Staveley Fuse, Naoyuki &amp; Yu, Fengwei &amp; Hirose, Susumu. (2013). Gprk2 adjusts Fog signaling to organize cell movements in Drosophila gastrulation. Development (Cambridge, England). 140. 10.1242/dev.093625. Mid-blastula transition Gastrulation begins Slowdown of nuclear division Increase in RNA transcription Ventral furrow Invagination of prospective mesoderm Cephalic furrow Separates procephalon from the germ band Germ band Convergent extension Anterior-Posterior Polarity Maternal effect genes Gap genes Pair-rule genes Segment polarity genes Homeotic selector genes Development Janardhan, P. &amp; Hebert, M. &amp; Ikeuchi, Katsushi. (1998). The space-time map applied to Drosophila embryogenesis. 144 - 153. 10.1109/BIA.1998.692429. Ninova, Maria &amp; Ronshaugen, Matthew &amp; Griffiths-Jones, Sam. (2014). Conserved Temporal Patterns of MicroRNA Expression in Drosophila Support a Developmental Hourglass Model. Genome biology and evolution. 6. 10.1093/gbe/evu183. Oocyte develops and inside the ovary surrounded by support cells Nurse and follicle cells deposit maternal effect mRNA and proteins, and send signal essential for development to the Oocyte. After fertilization, the embryo establishes distinct regions based on expression patterns of maternal and zygotic genes. Segmentation and differentiation of the embryo corresponds to adult structures. Maternal effect genes bicoid and Hunchback Define anterior organizing center Nanos and Caudal Define posterior organizing center Torso Define terminal boundary region A-P Pattern Gene Expression patterns Gap gene expression pattern Inhibit each other by followed the hierarchy of them Pair-rule gene: fushi tarazu Segment Polarity genes: engrailed and wingless Segments and Parasegements Homeotic (Bub) Genes","link":"/2021/08/31/LearnNotes/Intro/"},{"title":"DNA Damage","text":"DNA Damage DNA is vulnerable to damage resulting from endogenous metabolites, environmental and dietary carcinogens, some anti-inflammatory drugs, and genotoxic cancer therapeutics. Cells respond to DNA damage by activating complex signalling networks that decide cell fate, promoting not only DNA repair and survival but also cell death. The decision between cell survival and death following DNA damage rests on factors that are involved in DNA damage recognition, and DNA repair and damage tolerance, as well as on factors involved in the activation of apoptosis, necrosis, autophagy and senescence. The pathways that dictate cell fate are entwined and have key roles in cancer initiation and progression. Furthermore, they determine the outcome of cancer therapy with genotoxic drugs. Understanding the molecular basis of these pathways is important not only for gaining insight into carcinogenesis, but also in promoting successful cancer therapy. In this Review, we describe key decision-making nodes in the complex interplay between cell survival and death following DNA damage. © Wynand P. Roos; 2016 In the event of DNA damage, cells activate DNA repair pathways to facilitate the removal of replication barriers. Conversely, in instances of irreparable DNA damage, cells are prompted to undergo programmed cell death[1]. Reactive oxygen species (ROS), a by-product of regular cellular metabolism, along with various environmental and endogenous genotoxic factors, pose a threat to the stability of DNA and other macromolecules[2]. In response to oxidative DNA damage, cells activate cell cycle checkpoints, leading to the arrest of the cell cycle and cessation of DNA replication. This creates a time window during which DNA repair pathways, such as excision repair, can effectively identify and repair DNA damage induced by oxidative stress. Excision repair is a critical system for repairing oxidative stress-induced DNA damage[3]. © Wynand P. Roos; 2016 Key damage tolerance mechanisms for cell survival[4][5][6]: non-homologous end joining (NHEJ) homologous recombination (HR), MMR, BER, nucleotide excision repair (NER) protein-linked DNA break (PDB) repair in combination with DDR signallin. Three immediate-early sensors in the DDR - PI3K-related kinases (PIKKs)[7]: ataxia telangiectasia mutated (ATM) ATM is frequently mutated in tumours[8], which is accompanied by a gain of therapeutic resistance[9]. ATM mutation increased risk of breast cancer[10] nad colon cancer[11] more frequently altered than ATR[12] ataxia telangiectasia and Rad3-related (ATR) functionally compromised ATR also show malignancy DNA-dependent protein kinase (DNA-PK) ATM and ATR promote cell death in instances of high DSB levels[13] © Wynand P. Roos; 2016 pre { background-color:#38393d; color: #5fd381; } L.H. Pearl, A.C. Schierz, S.E. Ward, B. Al-Lazikani, F.M. Pearl Therapeutic opportunities within the DNA damage response Nat. Rev. Cancer, 15 (3) (2015), pp. 166-180 ↩︎ M. Majidinia, B. Yousefi DNA damage response regulation by MicroRNAs as a therapeutic target in cancer DNA Repair, 47 (2016), pp. 1-11 ↩︎ Davies, Kelvin JA, ed. Oxidative damage &amp; repair: Chemical, biological and medical aspects. Elsevier, 2013. ↩︎ Roos, W. P. et al. The translesion polymerase Rev3L in the tolerance of alkylating anticancer drugs. Mol. Pharmacol. 76, 927–934 (2009). ↩︎ Ashour, M. E., Atteya, R. &amp; El-Khamisy, S. F. Topoisomerase-mediated chromosomal break repair: an emerging player in many games. Nat. Rev. Cancer 15, 137–151 (2015). ↩︎ Stingele, J., Habermann, B. &amp; Jentsch, S. DNA–protein crosslink repair: proteases as DNA repair enzymes. Trends Biochem. Sci. 40, 67–71 (2015). ↩︎ Rogakou, E. P., Pilch, D. R., Orr, A. H., Ivanova, V. S. &amp; Bonner, W. M. DNA double-stranded breaks induce histone H2AX phosphorylation on serine 139. J. Biol. Chem. 273, 5858–5868 (1998) ↩︎ Stankovic, T. et al. ATM mutations in sporadic lymphoid tumours. Leuk. Lymphoma 43, 1563–1571 (2002). ↩︎ Kim, H. et al. Having pancreatic cancer with tumoral loss of ATM and normal TP53 protein expression is associated with a poorer prognosis. Clin. Cancer Res. 20, 1865–1872 (2014). ↩︎ Swift, M., Morrell, D., Massey, R. B. &amp; Chase, C. L. Incidence of cancer in 161 families affected by ataxia-telangiectasia. N. Engl. J. Med. 325, 1831–1836 (1991). ↩︎ Thompson, D. et al. Cancer risks and mortality in heterozygous ATM mutation carriers. J. Natl Cancer Inst. 97, 813–822 (2005). ↩︎ Khanna, K. K. Cancer risk and the ATM gene: a continuing debate. J. Natl Cancer Inst. 92, 795–802 (2000). ↩︎ Pusapati, R. V. et al. ATM promotes apoptosis and suppresses tumorigenesis in response to Myc. Proc. Natl Acad. Sci. USA 103, 1446–1451 (2006). ↩︎","link":"/2023/03/12/LearnNotes/Paper-dna-damage/"},{"title":"Black soldier fly larvae meal can replace fish meal in diets of sea-water phase Atlantic salmon (Salmo salar)","text":"Black soldier fly larvae meal can replace fish meal in diets of sea-water phase Atlantic salmon (Salmo salar) Cite: Belghit, Ikram, et al. “Black soldier fly larvae meal can replace fish meal in diets of sea-water phase Atlantic salmon (Salmo salar).” Aquaculture (2019): 609-619. Abstract black soldier fly larvae (insect meal) replacing to fish meal did not affect the apparent digestibility coefficients (ADC) of protein, lipid, amino acids and fatty acids, or the digestive enzyme activities Feed intake, daily growth increase, and feed conversion ratio were also unaffected Whole body protein, lipid and amino acid composition were not affected Liver lipid accumulation was not affected by replacing the fishmeal with insect meal Results Category Higher Lower Normal Notes Dietary composition - LC-HUFAs eicosapentaenoic acid (20:5n-3, EPA)- docosahexaenoic acid (22:6n-3, DHA)- total n-3 fatty acids - n-6 fatty acid- essential AA Groth performance and somatic index - tripled their weight during the 114 day - no significant effects of IM inclusion on final weight Digestibility - crude protein (n = 3)- crude lipid (n = 3)- amino acids (n = 3)- fatty acids (n = 3)- brush boarder enzyme leucine aminopeptidase (n = 18)- trypsin activity (n = 3)- total bile acids level (n = 3) Fish composition - lauric acid- EPA- DHA - dry matter- crude protein- crude lipid- amino acid composition- ARA- PUFA- stearidonic acid Plasma - Glu (n = 18) - AST (n = 18) - Hg (n = 3)- ALT (n = 3)- FFA (n = 18)- TAG (n = 18)- Chol (n = 3)- Tprot (n = 3)- Na+ (n = 18) liver lipid storage - the size distribution Sensory - rancid odor- off-odor- rancid flavor of the baked fillet- moisture release - color intensity of the cooked salmon - pleasant odor- flavor differences- color scores of raw salmon - softer in raw but opposite in baked Discussion Sea-Water Phase Atlantic Salmon no negatively affect feed intake growth performance nutrient utilization Similarly results in diet Substituted on blackspot sea bream (Lates calcarifer): yellow mealworm (Tenebrio molitor) housefly maggot (Musca domestica) However, reduced growth and feed utilization has been reported in juvenile turbot and rainbow trout (Author: Caused by chitin?) (chitin can decrease the FA synthesis and to increase TAG hydrolysis in rat liver) Salmonids fed diets containing BSF larvae raised on fish offal or seaweeds grew better than fish fed dietary BSF larvae raised without marine nutrients. Low level of lysine in the insect-based diet had no effect on European seabass. low level of taurine may effact the lipid deposition of the liver but we didn’t detected it. (hepatosomatic index)","link":"/2020/07/07/LearnNotes/Paper_BSFlylavea_salmon_2019/"},{"title":"Modifications of digestive enzymes in trout (Oncorhynchus mykiss) and sea bream","text":"Modifications of digestive enzymes in trout (Oncorhynchus mykiss) and sea bream (Sparus aurata) in response to dietary fish meal replacement by plant protein sources Cite: Santigosa E, Sanchez J E, Medale F, et al. Modifications of digestive enzymes in trout (Oncorhynchus mykiss) and sea bream (Sparus aurata) in response to dietary fish meal replacement by plant protein sources[J]. Aquaculture, 2008, 282(1): 68-74. General Information trout (Oncorhynchus mykiss) img from: nyfalls.com, Copyright belongs to the author Abstract Three experimental diet (50%, 75%, 100%) Rainbow trout and gilthead sea bream Compare the digestion enzymes Post-prandial protease and α-amylase activities protease Activities change chymotrypsin-like bands α-amylase activities does not affected histology Change intestinal length Weight change only on PP100 Introduction ###P1: Plant protein substitution for economy Shortcomings: hgih carbohydrate levels isoflavones low methionine levels anti-nutritional factors They can: impede protein digestion impair immune responses intestinal inflammation. End: Yellow perch is one of the most sensitive species for this change. P2: Pancreas Serine-protease (trypsin, chymotrypsin, elastase and collagenase) Glucosidases hydrolyze starch into lineal chains P3: Our purpose Protine and Carbohydrate digestion histology M&amp;M Chemicals Diets, animals and growth experiment Post-parndial experiment and sampling Preparation of extracts and determination of soluble protein Enzyme assays Zymograms: characterization of protease fractions and inhibition by PP diets Proximal intestine histological analysis Statistical analysis Results Enzymes activities Alkaline Protease Trout fed diets PP50 and PP75 showed only a slight post-feeding increase in this activity. Sea bream fed the FM diet showed a maximum of 6.93±1.03 U protease·mg− 1 protein·min− 1. This value decreased gradually as the percentage of plant protein increased Amylase a significant post-prandial increase in this activity was recorded only in PP75 and PP100 fed trout. Replacement of fish meal by plant protein did not induce significant changes in α-amylase activity in either species. Growth Performance Intestine Growth Related Notes: Transcriptomic analysis of juvenile Chinese sea bass (Lateolabrax maculatus) anesthetized by MS-222 (tricaine methanesulfonate) and eugenol De novo characterization of the liver transcriptome of javelin goby Synechogobius hasta and analysis of its transcriptomic profile following waterborne copper exposure Physiological and transcriptomic responses to fishmeal-based diet and rapeseed meal-based diet in two strains of gibel carp (Carassius gibelio) Transcriptomic response to soybean meal-based diets as the frst formulated feed in juvenile yellow perch (Perca favescens)","link":"/2020/08/12/LearnNotes/Paper_Diet_Switch_Fish4/"},{"title":"Diet switch| Black soldier fly larvae (BSFL) meal","text":"Evaluation of black soldier fly (Hermetia illucens) larvae meal as partial or total replacement of marine fish meal in practical diets for Pacific white shrimp (Litopenaeus vannamei) Cite: Cummins Jr, Vaun C., et al. “Evaluation of black soldier fly (Hermetia illucens) larvae meal as partial or total replacement of marine fish meal in practical diets for Pacific white shrimp (Litopenaeus vannamei).” Aquaculture 473 (2017): 337-344. Abstract Grade level BSFL replacements for protein from fishmeal were fed. replacement from 7%, 14%, 21%, 28%, to 36% (100% replacement to fishmeal) growth performance could be maintain when replacement ratio &lt; 25% Results To begin with, the author talked about the difference between BSFL and FM. Which could responsible for the different growth performance. On the other hand, it explained an appropriate replacement could maintain the shrimp growth. Discussion The survival ratio was not affected by the replacement. To consider the bodyweight gain, replacement &lt;20% is appropriate. To consider the protein and lipid composition, replacement &lt;7% is reasonable. Chia … maybe not affect palatability since shrimp can digest it appropriately. The author also talked about the feeding environment of the shrimp with they didn’t take the experiment and have no data. PS In this paper, the author finished the experiment of replacing FM with the BSFL and the data shows that it does not affect the survival ratio. However, with the increase of replacement, the BWG, protein, and lipid composition was affected. In the discussion part, the author re-informed that the BSFL was different from the FM. The ratio of EAA/NEAA may be responsible for the relatively poor growth performance in higher ratio replacement diets. Though there are no experiments and data from the Chia and Culture environment(Green water VSFresh water), the other discussed them that they may not be important and have very limited effects on this experiment. © iStock Black Soldier Fly Full-Fat Larvae Meal as an Alternative to Fish Meal and Fish Oil in Siberian Sturgeon Nutrition: The Effects on Physical Properties of the Feed, Animal Growth Performance, and Feed Acceptance and Utilization cite: Rawski, Mateusz, et al. “Black Soldier Fly Full-Fat Larvae Meal as an Alternative to Fish Meal and Fish Oil in Siberian Sturgeon Nutrition: The Effects on Physical Properties of the Feed, Animal Growth Performance, and Feed Acceptance and Utilization.” Animals 10.11 (2020): 2119. Summary: The replacement was up to 30%. feed Acceptance was increased by 10% and a higher replacement ratio no effects on feed digestibility Introduction 1. The population of the sturgeon decreased dramatically during the second half of the 20th century. 2. The plant protein-based diet is the main substitute for fish protein for carnivores. But sturgeons are highly sensitive to phytoestrogens. 3. Insects are one of the main foods for juvenile sturgeons 4. Defatting may decrease nutrition, for instance, AA and antimicrobial protein, in insect meal. Results As it shows in the Summary Discussion 1. compared the BSFL ingredient with other researches. 2. Talked about how the non-protein resources of N could affect the crude protein conversion factor. 3. Mineral balance of the diet. 4. Physical properties of BSFL food pellets. 5. The palatability of the BSFL meal: fatty, chitin, and free amino acids. 6. Chitin shows antiviral activity and stimulates immune system ability. But it also reduces palatability, digestibility coefficients, and growth performance. PS One marvelous thing is this research selected a fish that consume insects as the main food in juvenile age. So, they supposed the replacement diet has more beneficial effects than disadvantages on sturgeons. And it is. Besides, research was also focusing on how BSFL changes the physical properties of the feeding pellets which was rarely discussed among other papers. It also connected the physical properties to the palatability and digestibility coefficients of the pellets, though they have no data from this experiment. After that, they talked about the chitin, which has positive effects on fish when the concentration ratio is appropriate. However, this experiment shows that sturgeon could take all of advantages from chitin because not only the full-fatty BSFL has less chitin, but also sturgeon are highly adaptive to chitin diets in nature. © indiamart.com Development of black soldier fly larvae production technique as an alternate fish feed cite: Rana, KM Shakil, et al. “Development of black soldier fly larvae production technique as an alternate fish feed.” International Journal of Research in Fisheries and Aquaculture 5.1 (2015): 41-47. Abstract They tried a few diets for BSF feeding. And then feeding the fish with BSFL diet by the replacing ratio of T1(0%), T1(25%), T3(50%), and T4(100%). The growth performance of monosex tilapiawas T3 &gt; T2 &gt; T1 ≈ T4. PS This research has two main parts. The first part is about rearing the BSF with different diets which I’d like to ignore. The second part is treating tilapia with gradient BSFL diets. They compared other few BSFL substitute diets kinds of research in discussion and concluded that they had a similar result: replacement ratio is up to 50%… Yeap, that’s all. Let’s move on! Result 1. No significant growth performance, appetite, feed intake, conversion ratio, feed efficiency, or total digestibility were performed. A significant increase in apparent protein digestibility was observed. 2. Blood components have no significant differences. 3. Skin mucus immune response shows immune activity was boosted. Discussion Comparing the results from the Result part to other papers. Replacement of Fish Meal by Black Soldier Fly (Hermetia illucens) Larvae Meal: Effects on Growth, Haematology, and Skin Mucus Immunity of Nile Tilapia, Oreochromis niloticus. cite: Tippayadara, Nisarat, et al. “Replacement of Fish Meal by Black Soldier Fly (Hermetia illucens) Larvae Meal: Effects on Growth, Haematology, and Skin Mucus Immunity of Nile Tilapia, Oreochromis niloticus.” Animals 11.1 (2021): 193. Abstract 100% percent rate substitution shows no side effect on Nile Tilapia © howtoaquaponic.com Efficacy of insect larval meal to replace fish meal in juvenile barramundi, Lates calcarifer reared in freshwater cite: Katya, Kumar, et al. “Efficacy of insect larval meal to replace fish meal in juvenile barramundi, Lates calcarifer reared in freshwater.” International Aquatic Research 9.4 (2017): 303-312. Abstract: 0, 25%, 50%, 75%, and 100% replacement. BSFL as inferior protein ingredient to FM; 8 weeks trial. No significant different between 0%, 25%, and 50%. Crude protein and moisture were not affected. The broken line regression model believes that the substitution was up to 28.4%. Result 1.BSFL contains high crud lipids. Soybean meal containing high fiber contains. 2. Survival rates were from 80.5% to 100%. Discussion It mentioned that the concentration of the BSFL could change by the feeding trails. The protein pf BSFL is inferior to FM, but parallel to soybean protein. After that, the author talked about other insect diet replacements and the effects of chitin, which is worthy to study further. © aquariumglaser Effects of black soldier fly (Hermetia illucens) larvae meal protein as a fishmeal replacement on the growth and immune index of yellow catfish (Pelteobagrus fulvidraco). cite: Xiao, Xiaopeng, et al. “Effects of black soldier fly (Hermetia illucens) larvae meal protein as a fishmeal replacement on the growth and immune index of yellow catfish (Pelteobagrus fulvidraco).” Aquaculture research 49.4 (2018): 1569-1577. Abstract: The lysozyme activity reaches the maximum at 48% BSFL diet. The 25% of replacement has the highest body weight gain ratio. The survival rate was not significant among control and trials. Introduction The fish industry is growing, and fish food is important. 2. Plant protein substitute is cheap but inferior to fishmeal. It also compensates for human nutrition. 3. Animal protein is good and maybe a good choice. 4. Insect is awesome. Result The highest WGR was found in T25%. The performance was poorer after the replacement larger than 68%. Body indexes were not significantly changed. No significant differences in moisture, ash, or crude protein were found. crude lipid significantly different in some diets. LZM is higher but not significant in trials. Serum SOD is significantly higher in some trials. Hepatopancrea SOD, Phagocytic percentage, and Phagocytic index didn’t show a significant change. Discussion Compared to other researches, our result… The survival ratio is not significant but lower, which agrees with xxx’s research. Growth performance is different among species. Nutrition … Immune: the function of some properties… the BSFL diet increased the immunity of yellow catfish. © wikimedia Dietary Inclusion of Black Soldier Fly (Hermetia Illucens) Larvae Meal and Paste Improved Gut Health but Had Minor Effects on Skin Mucus Proteome and Immune Response in Atlantic Salmon (Salmo Salar) cite: Weththasinghe, Pabodha, et al. “Dietary Inclusion of Black Soldier Fly (Hermetia Illucens) Larvae Meal and Paste Improved Gut Health but Had Minor Effects on Skin Mucus Proteome and Immune Response in Atlantic Salmon (Salmo Salar).” Frontiers in Immunology 12 (2021): 114. Abstract gut health plasma biochemical parameters immune response and skin mucus proteome fishmeal and plant protein (Control-1); three BSFL meal diets, substituting 6.25% (6.25IM), 12.5% (12.5IM) and 25% (25IM) of protein; two BSFL paste diets, substituting 3.7% (3.7IP) and 6.7% (6.7IP) of protein and an extra control diet with 0.88% of formic acid (Control-2). 6.25IM diet reduced enterocyte steatosis in pyloric caeca, improved distal intestine histology, and reduced IgM in distal intestine. 12.5IM diet reduced enterocyte steatosis in pyloric caeca, improved distal intestine histology, had a higher plasma lysozyme content compared to 6.25IM, tend to increase phagocytic activity in head-kidney macrophages-like cells 25IM diet improved distal intestine histology, but showed mild-moderate enterocyte steatosis in pyloric caeca, increased IFNg and reduced IgM in distal intestine. 3.7IP diet caused mild inflammatory changes in distal intestine, although it reduced enterocyte steatosis in pyloric caeca. 6.7IP diet reduced enterocyte steatosis in pyloric caeca and improved distal intestine histology. Increasing level of BSFL meal in the diet linearly decreased plasma C-reactive protein, whereas increasing level of BSFL paste linearly increased plasma antioxidant capacity. BSFL meal and paste had minor effects on the expression profile of proteins in skin mucus and no effects on immune markers in splenocytes. BSFL meal showed no negative effect on liver and muscle health as indicated by plasma alanine aminotranseferase, asparate aminotransferase and creatine kinase. replacing conventional protein sources with low to moderate levels of BSFL meal (6.25% and 12.5%) or paste (3.7% and 6.7%) reduced enterocyte steatosis in pyloric caeca, while replacing up to 25% with BSFL meal or 6.7% with paste improved distal intestine histology. Further, dietary inclusion of BSFL meal and paste had minor effects on skin mucus proteome and immune response in Atlantic salmon.","link":"/2021/02/21/LearnNotes/Paper_BSFlylavea_review/"},{"title":"Transcriptomic analysis of juvenile Chinese sea bass (Lateolabrax maculatus) anesthetized by MS-222 (tricaine methanesulfonate) and eugenol","text":"Transcriptomic analysis of juvenile Chinese sea bass (Lateolabrax maculatus) anesthetized by MS-222 (tricaine methanesulfonate) and eugenol Cite: Dong, H., Wang, W., Duan, Y. et al. Transcriptomic analysis of juvenile Chinese sea bass (Lateolabrax maculatus) anesthetized by MS-222 (tricaine methanesulfonate) and eugenol. Fish Physiol Biochem (2020). https://doi.org/10.1007/s10695-019-00755-x General Information Statistic information Content Words Ratio Total Words 3624 100% Abstract 306 8.43% Introduction 512 14.11% M&amp;M 685 18.88% Results 821 22.63% Discussion 1300 35.83% Background Lateolabrax maculatus: © baike.baidu.com MS-222 &amp; eugenol: Fish anesthetics. Abstract M &amp; E are two widely used fish anesthetics. This experiment reveals the transcriptomic changing during the recovering from fish anesthetics (6h after treated). RNA from gills and livers were extracted and compared. Non essential data filled here. Some DEGs participated in human disease and metabolism.(ps: ummmm…WHAT? = =) Two treatment interested different pathways. MS-222 may affect metabolism and immunity and more harmful than eugenol. PS: Abstract briefly introduced the purpose &amp; results of the experiment. First, it revealed the toxicity of two anesthetics, and second, it can improve our understanding on some human diseases(maybe??) and the detoxification of the fish in the transcription level. Introduction P1: What is anesthetics; The contribution of anesthetics; Which anesthetics are available; How do them work; P2: Wide geography-distribution(It’s an important commercial species). Anesthetic could reduce the mortality during transportation. P3: Some related experiments had done but not on the same page. So, with the evidences of this experiment, people can make a better choice between MS-222 and eugenol. M&amp;M Skip (^ ^ ) Animal Sample extraction RNA extraction, library preparation, and Illumina Hiseq sequencing De novo assembly and annotation Differentially expressed genes Single nucleotide polymorphism and simple sequence repeat detection Result Transcriptome sequence assembly Annotation and function analysis Differentially expressed genes SNP and SSR detection Transcriptome sequence assembly Raw reads Clean reads Unigenes Annotated Genes Annotation and function analysis COG (p1) GO (p2) KEGG (p3) Table (sample, Raw reads) Differentially expressed genes Unigenes DEGs count(unique genes, annotated genes) (Charts &amp; tables) GO Unique/interested Go-Terms Charts KEGG Unique/interested pathways SNP and SSR detection Skip Discussion P1-General result from DEGs Less DEGs found in eugenol-treated livers sample Pathways associated with human diseases and metabolism were found in both samples. E group is intrested in detoxification and xenobiotics; M group is interested in organismal system P2-Comparative Stress graph LR; Stress-->|Stress Related|Diseases; Diseases-->|Change|Oxidants; Diseases-->|Change|Anesthetic; Diseases-->|Change|Antioxidants; Antioxidants-.->|Reduce|Stress; Eugenol is less harmful than MS-222 Eugenol group: 22 DEGs involved in 30 different pathways related xenobiotics biodegradation and metabolism, which means detoxification activities of the livers. MS-222 group: higher levels of AST, ALT, AKP, which reveals MS-222 cause more damages to livers.(explain: can not be metabolized) GST (Glutathione-S-transferase) BG: low activity of GST means low detoxification ability. Different responses of facing MS-222 in different species from previous research. Our result: L. maculatus is more vulnerable. A smaller number of DEGs may reveals lees intervention of E compared with M. (PS: = = smaller…) Additionally, eugenol is natural and may easier to metabolized. (PS: … Good, I just learned another skill to fill more words on discussion section) P3 Stress &amp; Metabolism BG: liver glucose oxidation is enhanced. Amino acid evolved in gluconeogenesis during the stress responses. Those pathways are enriched in both groups. Recent start verified point 1. P4 Pathways involved in environmental information processing Jak-STAT signaling, PI3KAkt signaling, TNF signaling, and cytokine-cytokine receptor interaction. BG: HPI-&gt;Cotisol; stress can inhibit inflammatory cytokine production and induce apoptosis, proliferation, and phagocytosis of immune cells. Here: More DEGs related immune-related pathways are found in E group. BG: stress affects HPG and may affect reprodctive performance; Here: Some DEGs involved in productive activities are found in M group. BG: Lethimonier observed that stress-induced cortisol inhibited vitellogenesis, Here: We found it here, too. Conclusion: MS-222 is more harmful than eugenol. P5 Gill &amp; Livers Result: not change the original functions of the organs P6 Conclusion MS-222 revealed that all these anesthetics regulate the metabolic and immune pathways in the fish, and MS-222 may trigger more damages on the fish liver and reproduction. Related papers: Morais S, Pratoomyot J, Taggart JB, Bron JE, Guy DR, Bell JG, Tocher DR (2011b) Genotype-specific responses in Atlantic salmon (Salmo salar) subject to dietary fish oil replacement by vegetable oil: a liver transcriptomic analysis. BMC Genomics 12:255 Morais S, Edvardsen RB, Tocher DR, Bell JG (2012a) Transcriptomic analyses of intestinal gene expression of juvenile Atlantic cod (Gadus morhua) fed diets with Camelina oil as replacement for fish oil. Comp Biochem Physiol B Biochem Mol Biol 161:283–293. Tacchi L, Secombes CJ, Bickerdike R, Adler MA, Venegas C, Takle H, Martin SA (2012) Transcriptomic and physiological responses to fishmeal substitution with plant proteins in formulated feed in farmed Atlantic salmon (Salmo salar). BMC Genomics 13:363 Related Notes: De novo characterization of the liver transcriptome of javelin goby Synechogobius hasta and analysis of its transcriptomic profile following waterborne copper exposure Physiological and transcriptomic responses to fishmeal-based diet and rapeseed meal-based diet in two strains of gibel carp (Carassius gibelio) Transcriptomic response to soybean meal-based diets as the frst formulated feed in juvenile yellow perch (Perca favescens)","link":"/2020/07/07/LearnNotes/Paper_RNASeq_Fish1/"},{"title":"Liver and Steroid Hormones—Can a Touch of p53 Make a Difference?","text":"Liver and Steroid Hormones—Can a Touch of p53 Make a Difference? Cite: Charni-Natan M, Aloni-Grinstein R, Osher E and Rotter V (2019) Liver and Steroid Hormones—Can a Touch of p53 Make a Difference? Front. Endocrinol. 10:374. doi: 10.3389/fendo.2019.00374 Read the full paper General Information Background Liver: © Charni 2019 Abstract Liver serving as a hormonal secretory gland. Steroid hormones is important Liver is important to Steroid hormones homeostasis P53 has impact on Liver Hypothesis: P53-&gt; Liver -&gt; Steroid hormones -&gt; Diseases New way to diseases treatment (Maybe) Introduction P1: BG Steroid hormones: reproductive metabolic homeostasis Steroid hormones synthesis derived from cholesterol synthesized by adrenal cortex, gonads, and placenta. Five groups: (based on nuclear receptor)(1–5) mineralocoriticoids glucocorticoids androgens estrogens progestogens P53 Responding for stress Regulating hormones expression This discuss is focus on bidirectional relationship between different steroid hormones and liver and dependently on p53. Steroid Hormones Homeostasis Regulation by the Liver Cholesterol Cholesterol Genesis(15) de-novo production hydrolysis of stored cholesterol interiorization of plasma membrane cholesterol from LDL and HDL Metabolism Metabolism(16, 17) 5αR1 (liver enzyme 5α-reductase 1) 5αR1-KO mice exhibited augmented mRNA levels of various hepatic metabolic regulators genes (e.g., Acc1, Agpat2, Cpt2, and Dgat2) in comparison to WT mice(18). CYP (cytochromes P450 enzymes) metabolism of many drugs and lipophilic compounds(19) CYP3A4, CYP19, CYP2C2B1, and CYP2C11 are the liver CYPs and take part in steroid hormones hydroxylation and processing CYP3A4(20,21) hydroxylases several steroids such as cortisol, androstenedione, testosterone, and progesterone CYP19 (Aromatase)(10) transforms androgens to estrogens by the removal of C19 carbon and the aromatization of the steroid A ring. CYP2C11 and CYP2B1(10) regulate hydroxylation of testosterone Nuclear receptors complexes NRC such as PXR, VDR, RXR were also found to bind CYP3A4 chromatin and affect its expression (23, 24) Steroids Conjunction exerted by such as sulfotransferare and uridine diphosphate-glucuronosyltransferases (UGT) ransfer the steroid hormones into higher polarity metabolites that are better suited to be excreted from the body(10). The sulfotransferases that are expressed by hepatic cells and are related to steroids conjugations are HSST, EST, SULT 2A1, and SULT 1E1 (25). be regulated by androgens, GCs, and nuclear receptors such as PXR(27). sulfotransferase inhibition as well as EST KO, led to the acceleration of free steroids and thus to sexual abnormalities (10,26). UGTs Two subfamilies UGT2B mainly expressed in the liver and is related the processing of steroid hormones(28). UGT it induce glucuronidation of steroids, a process that interrupts steroids activity, and enables their elimination. Tegulated by several xenobiotics compounds (e.g., PCN, PB), which were reported to increase their mRNA expression levels in rats’ livers (29). Transportation As steroids, these hormones are lipophilic thus, when secreted into the blood stream they need to be bound to carrier proteins SHBG (Sex hormone binding globulin) CBG (Corticosteroid binding globulin) This carriers are glycoproteins which are mainly secreted by liver.(30, 31). Carrier proteins bind steroids and turn them to be biologically inactive (32). effect different molecular pathways and signaling such as apoptosis (33, 34) Regulation: factors such as glucose (35), thyroid hormone &lt; id=&quot;b_p18&quot;sup&gt;(36), and other factors such as the hepatocyte nuclear factor 4α (HNF-4α) (37), PPAR-γ (38), and p53 (14). Glucocorticoids (GC) Glucocorticoids are vital endocrine regulators of homeostasis and adaptation to environmental variations. potent anti-inflammatory and immunosuppressive agents(40) Cortisol(42) a main glucocorticoid secreted by the adrenal cortex essential for immune system, vascular tone maintance etc Played a major role during stress and severe illness by increasing cardiac output and vascular tonus and decreasing pro-inflammatory cytokines release(43,44) under the control of: (42) HPA (hypothalamus-pituitary-adrenal ) ACTH (adrenocorticotropic hormone) CRH (corticotropin-releasing hormone) low-density lipoproteins (LDL) cholesterol insufficiency impair the production of cortisol (45) NAFLD (Non-alcoholic fatty liver disease) Metabolic disorder, characterized by hepatic steatosis, the presence of free fatty acids or triglycerides in the liver(46). Mice: high fat diets &amp; chronically elevated GC(47) Patients: elevated GC levels(48) (Skip) Mineralocorticoids synthesized by the adrenal cortex that influence salt and water balance. (Skip) Androgens Androgens are the principal male sex hormones that regulated masculinizing (雄性化作用) effects and male sexual behavior. DHT(dehydroepiandrosterone) it can bind androgen receptor(AR) as well as testosterone(82) Estrogens Estrogens are female principal sex hormone. E2 (17β estradiol) is essential for human … Citation 1. Falkenstein E, Tillmann HC, Christ M, Feuring M, Wehling M. Multiple actions of steroid hormones–a focus on rapid, non-genomic effects. Pharmacol Rev. (2000) 52:513–56. 2. Becker KL. Principles and Practice of Endocrinology and Metabolism. Lippincott Williams &amp; Wilkins (2001). 3. Holst JP, Soldin OP, Guo T, Soldin SJ. Steroid hormones: relevance and measurement in the clinical laboratory. Clin Lab Med. (2004) 24:105–18. doi: 10.1016/j.cll.2004.01.004 4. Frye CA. Steroids, reproductive endocrine function, and affect. A review. Minerva Ginecol. (2009) 61:541–62. 5. Birzniece V. Hepatic actions of androgens in the regulation of metabolism. Curr Opin Endocrinol Diabetes Obes.(2018) 25:201–8. doi: 10.1097/MED.0000000000000405 15. Hu J, Zhang Z, Shen WJ, Azhar S. Cellular cholesterol delivery, intracellular processing and utilization for biosynthesis of steroid hormones. Nutr Metab. (2010) 7:47. doi: 10.1186/1743-7075-7-47 16. Thigpen AE, Silver RI, Guileyardo JM, Casey ML, Mcconnell JD, Russell DW. Tissue distribution and ontogeny of steroid 5α-reductase isozyme expression. J Clin Invest. (1993) 92:903–10. doi: 10.1172/JCI116665 17. El-Awady MK, El-Garf W, El-Houssieny L. Steroid 5α reductase mRNA type 1 is differentially regulated by androgens and glucocorticoids in the rat liver. Endocr J. (2004) 51:37–46. doi: 10.1507/endocrj.51.37 18. Livingstone DE, Di Rollo EM, Mak TC, Sooy K, Walker BR, Andrew R. Metabolic dysfunction in female mice with disruption of 5α-reductase 1. J Endocrinol. (2017) 232:29–36. doi: 10.1530/JOE-16-0125 19. Zimniak P, Waxman DJ. Liver cytochrome P450 metabolism of endogenous steroid hormones, bile acids, and fatty acids. In: Schenkman JB, Greim H, editors. Cytochrome P450. Berlin, Heidelberg: Springer Berlin Heidelberg (1993) p. 123–44. doi: 10.1007/978-3-642-77763-9_8 20. Waxman DJ, Attisano C, Guengerich FP, Lapenson DP. Human liver microsomal steroid metabolism: identification of the major microsomal steroid hormone 6 β-hydroxylase cytochrome P-450 enzyme. Arch Biochem Biophys. (1988) 263:424–36. doi: 10.1016/0003-9861(88)90655-8 21. Niwa T, Murayama N, Imagawa Y, Yamazaki H. Regioselective hydroxylation of steroid hormones by human cytochromes P450. Drug Metab Rev. (2015) 47:89–110. doi: 10.3109/03602532.2015.1011658 10. You L. Steroid hormone biotransformation and xenobiotic induction of hepatic steroid metabolizing enzymes. Chem Biol Interact. (2004) 147:233–46. doi: 10.1016/j.cbi.2004.01.006 23. Wang K, Chen S, Xie W, Wan YJ. Retinoids induce cytochrome P450 3A4 through RXR/VDR-mediated pathway. Biochem Pharmacol. (2008) 75:2204–13. doi: 10.1016/j.bcp.2008.02.030 24. Istrate MA, Nussler AK, Eichelbaum M, Burk O. Regulation of CYP3A4 by pregnane X receptor: The role of nuclear receptors competing for response element binding. Biochem Biophys Res Commun. (2010) 393:688–93. doi: 10.1016/j.bbrc.2010.02.058 25. Strott CA. Sulfonation and molecular action. Endocr Rev. (2002) 23:703–32. doi: 10.1210/er.2001-0040 26. Strott CA. Sulfonation and molecular action. Endocr Rev. (2002) 23:703–32. doi: 10.1210/er.2001-0040 27. Runge-Morris M, Wu W, Kocarek TA. Regulation of rat hepatic hydroxysteroid sulfotransferase (SULT2-40/41) gene expression by glucocorticoids: evidence for a dual mechanism of transcription 28. Girard C, Barbier O, Veilleux G, El-Alfy M, Belanger A. Human uridine diphosphate-glucuronosyltransferase UGT2B7 conjugates mineralocorticoid and glucocorticoid metabolites. Endocrinology. (2003) 144:2659–68. doi: 10.1210/en.2002-0052 29. Vansell NR, Klaassen CD. Increase in rat liver UDP glucuronosyltransferase mRNA by microsomal enzyme inducers that enhance thyroid hormone glucuronidation. Drug Metab Dispos. (2002) 30:240–6. doi: 10.1124/dmd.30.3.240 30. Avvakumov GV, Cherkasov A, Muller YA, Hammond GL. Structural analyses of sex hormone-binding globulin reveal novel ligands and function. Mol Cell Endocrinol. (2010) 316:13–23. doi: 10.1016/j.mce.2009.09.005 31. Lin HY, Muller YA, Hammond GL. Molecular and structural basis of steroid hormone binding and release from corticosteroid-binding globulin. Mol Cell Endocrinol. (2010) 316:3–12. doi: 10.1016/j.mce.2009.06.015 32. Mendel CM. The free hormone hypothesis: a physiologically based mathematical model. Endocr Rev. (1989) 10:232–74. doi: 10.1210/edrv-10-3-232 33. Fortunati N, Catalano MG, Boccuzzi G, Frairia R. Sex hormone-binding globulin (SHBG), estradiol and breast cancer. Mol Cell Endocrinol. (2010) 316:86–92. doi: 10.1016/j.mce.2009.09.012 34. Hammond GL. Plasma steroid-binding proteins: primary gatekeepers of steroid hormone action. J Endocrinol. (2016) 230:R13–25. doi: 10.1530/JOE-16-0070 35. De Moor P, Joossens JV. An inverse relation between body weight and the activity of the steroid binding -globulin in human plasma. Steroidologia. (1970) 1:129–36. 36. Javitt NB. Hep G2 cells as a resource for metabolic studies: lipoprotein, cholesterol, and bile acids. FASEB J. (1990) 4:161–8. doi: 10.1096/fasebj.4.2.2153592 37. Selva DM, Hogeveen KN, Innis SM, Hammond GL. Monosaccharideinduced lipogenesis regulates the human hepatic sex hormone-binding globulin gene. J Clin Invest. (2007) 117:3979–87. doi: 10.1172/JCI32249 38. Selva DM, Hammond GL. Peroxisome-proliferator receptor γ represses hepatic sex hormone-binding globulin expression. Endocrinology. (2009) 150:2183–9. doi: 10.1210/en.2008-1289 14. Charni M, Molchadsky A, Goldstein I, Solomon H, Tal P, Goldfinger N, et al. Novel p53 target genes secreted by the liver are involved in non-cell-autonomous regulation. Cell Death Differ. (2016) 23:509–20. doi: 10.1038/cdd.2015.119 40. Vandewalle J, Luypaert A, De Bosscher K, Libert C. Therapeutic Mechanisms of Glucocorticoids. Trends Endocrinol Metab. (2018) 29:42–54. doi: 10.1016/j.tem.2017.10.010 42. Arlt W, Stewart PM. Adrenal corticosteroid biosynthesis, metabolism, and action. Endocrinol Metab Clin North Am. (2005) 34:293–313. doi: 10.1016/j.ecl.2005.01.002 43. Snijdewint FG, Kapsenberg ML, Wauben-Penris PJ, Bos JD. Corticosteroids class-dependently inhibit in vitro Th1- and Th2- type cytokine production. Immunopharmacology. (1995) 29:93–101. doi: 10.1016/0162-3109(94)00048-K 44. Yang S, Zhang L. Glucocorticoids and vascular reactivity. Curr Vasc Pharmacol. (2004) 2:1–12. doi: 10.2174/1570161043476483 45. Cicognani C, Malavolti M, Morselli-Labate AM, Zamboni L, Sama C, Barbara L. Serum lipid and lipoprotein patterns in patients with liver cirrhosis and chronic active hepatitis. Arch Intern Med. (1997) 157:792–6. doi: 10.1001/archinte.1997.00440280120012 45. Cicognani C, Malavolti M, Morselli-Labate AM, Zamboni L, Sama C, Barbara L. Serum lipid and lipoprotein patterns in patients with liver cirrhosis and chronic active hepatitis. Arch Intern Med. (1997) 157:792–6. doi: 10.1001/archinte.1997.00440280120012 Tsochatzis EA, Newsome PN. Non-alcoholic fatty liver disease and the interface between primary and secondary care. Lancet Gastroenterol Hepatol. (2018) 3:509–17. doi: 10.1016/S2468-1253(18)30077-3 D’souza AM, Beaudry JL, Szigiato AA, Trumble SJ, Snook LA, Bonen A, et al. Consumption of a high-fat diet rapidly exacerbates the development of fatty liver disease that occurs with chronically elevated glucocorticoids. Am J Physiol Gastrointest Liver Physiol. (2012) 302:G850–63. doi: 10.1152/ajpgi.00378.2011 Rockall AG, Sohaib SA, Evans D, Kaltsas G, Isidori AM, Monson JP, et al. Hepatic steatosis in Cushing’s syndrome: a radiological assessment using computed tomography. Eur J Endocrinol. (2003) 149:543–8. doi: 10.1530/eje.0.1490543 Shen M, Shi H. Sex hormones and their receptors regulate liver energy homeostasis. Int J Endocrinol. (2015) 2015:294278. doi: 10.1155/2015/294278","link":"/2020/07/07/LearnNotes/Paper_Charni2019/"},{"title":"De novo characterization of the liver transcriptome of javelin goby Synechogobius hasta and analysis of its transcriptomic profile following waterborne copper exposure","text":"De novo characterization of the liver transcriptome of javelin goby Synechogobius hasta and analysis of its transcriptomic profile following waterborne copper exposure Cite: Chen, Q., Luo, Z., Huang, C. et al. De novo characterization of the liver transcriptome of javelin goby Synechogobius hasta and analysis of its transcriptomic profile following waterborne copper exposure. Fish Physiol Biochem 42, 979–994 (2016). https://doi.org/10.1007/s10695-015-0190-2 General Information Statistic information Content Words Ratio Total Words 5424 100% Abstract 234 4.31% Introduction 598 11.03% M&amp;M 1475 27.19% Results 1143 21.07% Discussion 1974 36.39% Background Synechogobius hasta: © wikimedia Abstract Physiological study of S. hasta exposure to the Cu is studied, but RNA-Seq is not. (PS: this experiment is Unique) Some Statistic information from RNA-seq. Major change of pathways are… This experiment is pretty useful. Introduction P1: Cu contamination is harmful. Comprehensive understanding of the mechanisms is lack. P2: Problems caused by Cu exposure are too complicate to be explained by few regulatory entities, as a result, a whole gene expression profiling is need. P3: Though, previous studies find that lipid deposition and metabolic activity were changed,they focus on few genes only. Now, it is the first time for people profiling the RNA-Seq of this species. M&amp;M Fish and Cu exposure Sampling and total RNA extraction cDNA library preparation and Illumina sequencing De novo assembly and function annotation Identification of differentially expressed genes Real-time quantitative PCR (qPCR) validation Statistical analysis Results Illumina sequencing and de novo transcriptome assembly Function annotation and classification of unigenes Differentially expressed genes involved in immune system Differentially expressed genes involved in apoptosis Differentially expressed genes involved in signal transduction Validation of differential gene expression by qPCR Illumina sequencing and de novo transcriptome assembly Reads and Assemble result statistic with tables. Function annotation and classification of unigenes Annotation software and data base, figures and tables. GO ontology: statistic; tables; charts. KEGG ontology: statistics and examples Differentially expressed genes involved in immune system Fatty acid metabolism was changed, pathway charts was insert. Differentially expressed genes involved in immune system Changes in some specific pathways with table Differentially expressed genes involved in apoptosis Genes Change in apoptosis pathway with charts Differentially expressed genes involved in signal transduction MAPK and NFkB; tables. Validation of differential gene expression by qPCR The expression levels of 25 genes was validate. Discussion Liver transcriptome of S. hasta generated by RNAseq Differentially expressed genes involved in lipid metabolism Differentially expressed genes involved in immune system Differentially expressed genes involved in apoptosis Differentially expressed genes involved in signal transduction Liver transcriptome of S. hasta generated by RNAseq Statistic information of De novo result. (PS: you may think this things was mentioned before. Yes, it is, But here, the author made a comparing with other species. So, it is ok to recite them again) COG is useful, GO is useful, KEGG is useful. (PS: What the hex??? Probably is because this paper was published in 2015. So, it might be done at 2014 or even earlier.) Differentially expressed genes involved in lipid metabolism General background information and cited a bunch of recent study(PS: his study). But the RNA-Seq is absent. So, this experiment is useful and meaningful.(PS: Again, recite the lyrics from the Abstract and Introduction) It provide the evidences of mitochondrial damage and inhibition of B-oxidation. (PS: Gosh, finally, we see something new. And end of this section.) Differentially expressed genes involved in immune system BG information of immune system and the benifitial of the RNA-Seq. (PS: Suggest to ignore) Interested Pathways and their BG infor. Filled with a list of DEGs, and compared few of them with other studies. suggest that immune reaction were involved in Cu-induced stress. Differentially expressed genes involved in apoptosis BG infor for Apoptosis and CASP3. Calpain up-regulated; caspase-3 down-regulated, this was support in other two reports. (PS: They spend 236 words to interpret five words: Calpain up-regulated; caspase-3 down-regulate) Differentially expressed genes involved in signal transduction BG: for MAPK pathway. Evidences from other papers. Here: c-fos involved in this pathway. Cu could induce ROS to active MAPK to elevate the phosphorylation. (PS: No ending sentence for this paragraph. The last sentence is lack of coherent.) (P2) BG: NFkB is an important redox-sensitive TF for immune-response. Here: NFkB down-regulated. But, there have no consensus on it. So, more experiments are needee. (PS: This paragraph is mach readable than few previous) BG: important of Ca2+ and Cu2+ can effect Ca2+ Here: Cu down-regulated genes in the calcium signaling pathway. The understanding of this process is helpful. Conclusion: This experiment is unique and this experiment has lots of potential contributions… PS: Finally, I finished this paper. Personally, I’m not suggesting anyone to read this paper really much. Because it is a kind of wasting time if you want to learn how to writing from this passage. You can perceive that too much of non-sense words are filled for words-accumulating. And some sentences are lack of coherent. But, of course, it could be a good counter example because it is not the worst, it’s still a readable paper, it’s just not a good model. And I just don’t like it. Related papers: Morais S, Pratoomyot J, Taggart JB, Bron JE, Guy DR, Bell JG, Tocher DR (2011b) Genotype-specific responses in Atlantic salmon (Salmo salar) subject to dietary fish oil replacement by vegetable oil: a liver transcriptomic analysis. BMC Genomics 12:255 Morais S, Edvardsen RB, Tocher DR, Bell JG (2012a) Transcriptomic analyses of intestinal gene expression of juvenile Atlantic cod (Gadus morhua) fed diets with Camelina oil as replacement for fish oil. Comp Biochem Physiol B Biochem Mol Biol 161:283–293. Tacchi L, Secombes CJ, Bickerdike R, Adler MA, Venegas C, Takle H, Martin SA (2012) Transcriptomic and physiological responses to fishmeal substitution with plant proteins in formulated feed in farmed Atlantic salmon (Salmo salar). BMC Genomics 13:363 Related Notes: Transcriptomic analysis of juvenile Chinese sea bass (Lateolabrax maculatus) anesthetized by MS-222 (tricaine methanesulfonate) and eugenol Physiological and transcriptomic responses to fishmeal-based diet and rapeseed meal-based diet in two strains of gibel carp (Carassius gibelio) Transcriptomic response to soybean meal-based diets as the frst formulated feed in juvenile yellow perch (Perca favescens)","link":"/2020/07/07/LearnNotes/Paper_RNASeq_Fish2/"},{"title":"Dietary plant-protein substitution affects hepatic metabolism in rainbow trout (Oncorhynchus mykiss)","text":"Dietary plant-protein substitution affects hepatic metabolism in rainbow trout (Oncorhynchus mykiss) Cite: Vilhelmsson, Oddur, et al. “Dietary plant-protein substitution affects hepatic metabolism in rainbow trout (Oncorhynchus mykiss).” British Journal of Nutrition 92.1 (2004): 71-80. General Information Background img from: nyfalls.com, Copyright belongs to the author Abstract Substitute gradient SPC15 has a best growth performance SPC75 has a worst growth performance SPC 15 and SPC30 had the highest protein efficiency ratio Daily feed intake was significantly decreased Survival rate were higher in SPC15, SPC30, and SPC45 SPC15 and SPC30 showed significantly higher protein and amino acid (AA) retention Introduction ###P1: BG BG of Aquaculture P2: BG BG of Soybean meal in Aquaculture P3: BG BG of Pearl Gentian Grouper M&amp;M Diet formulation Feeding trial Sample collection and calculation formula for growth performance Biochemical analysi Statistical analysis QEthical statement Results Growth performance and biometry Nutritional composition Protein and individual AA ADCs and retention in muscle Growth performance and biometry Survival SPC 15, SPC 30, and SPC 45 (from 94% to 96%) as compared to SPC 60 and SPC 75 (P &lt; 0.05) BWG, WGR, SGR, and PER SPC15 BWG: average body weight gain; WGR: Weight gain ratio; SGR: specific growth rate, survival; PER: protein efficiency ratio FCR (feed conversion ratio) SPC15 DFI (Daily feed intake) SPC0 Nutritional composition Muscle protein SPC0, SPC15, SPC30 &gt; SPC45, SPC60, SPC75 Whole Body Moisture content gradually increased Crude protein SPC30, SPC45 &gt; SPC60, SPC75 Muscle AA histidine, lysine and methionine Negative related Methionine: H, SPC30; L, SCP75 Lysine: H, SPC15； L，SPC75 Discussion P1 Introduction Other studies This experiment P2 Regression Model Predict the best ratio for Growth performance improving P3 Tolerate Comparing Some fish have high tolerate of plant meal but not Grouper P4 Growth Performance &amp; feed intake Growth performance related but not depend by feed intake. The best growth performance is SPC15, but the highest uptake ratio is SPC0 P5 Poor Nutrition Value Anti Nutrition Factors (ANF) &amp; Lower Content of Amino Acids ANF phytic acid, trypsin inhibitor, raffinose, and glycinin phytic, trypsin: feed intake and growth P6-7 Phytic and Trypsin Mild effects on growth compared with previous studies: We have a lower concentration of phytic as well as trypsin. (Other studies) reduction in the bio-availability of Phosphorus, Calcium, Magnesium, and Zinc P8-9 General Conclusion P10 Summary Conclusion SPC 11-14% can optimize the growth performance. SPC30 can still remain beneficial for the grouper.","link":"/2020/07/07/LearnNotes/Paper_Vilhelmsson2004/"},{"title":"Physiological and transcriptomic responses to fishmeal-based diet and rapeseed meal-based diet in two strains of gibel carp (Carassius gibelio)","text":"Physiological and transcriptomic responses to fishmeal-based diet and rapeseed meal-based diet in two strains of gibel carp (Carassius gibelio) Cite: Xu, W., Jin, J., Han, D. et al. Physiological and transcriptomic responses to fishmeal-based diet and rapeseed meal-based diet in two strains of gibel carp (Carassius gibelio). Fish Physiol Biochem 45, 267–286 (2019). https://doi.org/10.1007/s10695-018-0560-7 General Information Statistic information Content Words Ratio Total Words 5104 100% Abstract 218 4.27% Introduction 824 16.14% M&amp;M 1403 27.49% Results 654 12.81% Discussion 2005 39.28% Background Synechogobius hasta: Img from: link Abstract fishmeal &amp; Rapeseedmeal to explore the effects of protein source. Two strains are feed. Growth performance,body composition, hematologic indices, and hepatic transcriptomes were measured. A prefer FM, F prefer RM Different involved in lots of metabolic pathways Introduction P1: graph LR; Fishmeal-->|Good protein source|Expensive-->Health; Plant_protein-->|poor utility, anti-nutritional|Cheep-->|Change inner environment|Impair_Health; P2: Previous mainly researches are focus on dietary background, genetic backgrounds are essential, too. As a result, understanding of molecular mechanisms is needed. P3: NGS could achieving it. See bass response similar to fishmeal diet, but response different to plant-based diet. P4:G. carp is important. A: fast growth; B: fast growth &amp; Diseases resist. M&amp;M Materials and methods Experimental fish and rearing conditions Sample collection Chemical analysis Transcriptome analysis Quantitative real-time PCR Statistical analysis Results Growth performance Physiological and biochemical indices in plasma Transcriptome analysis results Confirmation of RNA-seq data by qRT-PCR Growth performance Counts and table Physiological and biochemical indices in plasma Statistics and table Transcriptome analysis results Statistics and tables Confirmation of RNA-seq data by qRT-PCR Discussion P1-2 Poor Growth Performance Different response to plant protein. It is regulated by the gene in liver which involved in protein/lipid metabolism. Metabolic, digestive, cell signals… are also changed. Metabolic response interact with genotype. P3 Essential Amino Acids. Challenges: The rapeseeds lack of lysine and methionine. Imbalanced amino acid diet. Responds: Low body protein deposition OAT(ornithine aminotransferase) improved to generates more nonessential AA. graph LR; RM-->|Lack of| EAA; EAA-->|Decrease|SGR; SGR-->Body_Protein_Deposition_Reduction; EAA-->|Decrease|FE; FE-->Body_Protein_Deposition_Reduction; EAA-->|Decrease|PRE; PRE-->Body_Protein_Deposition_Reduction; Plant_Protein-->|impact uptake|AA; Protein_Deposition-->|related|Protein_Structure; Protein_Deposition-->|related|Digestive_Process; Protein_Deposition-->|related|Antinutritional_Factors; oat-->|Transamination|N_homeostasis; P4 Lipid metabolism hmdh high expression: Cholesterol Synthesis; Appropriate explanation: Plant sterols affect membrane properties, modify phospholipid order, impair cholesterol absorption. To response it, liver increased the cholesterol synthesis. Structure: graph LR; Cell_Membrane-.->|absorb|Lipid; Lipid-->|Affected by|Fatty_Acid_Profiles-->|Lack in |Plant_Dietary; Plant_Dietary-->|Contain|2.Plant_Sterols-->|Affect|Cell_Membrane; Plant_Dietary-->|upregulated|1.hmdh; 1.hmdh-->|Rate Limiting|Sterol_Synthesis; Sterol_Synthesis -.->|Increase|Lipid P5 Higher FR Related higher expression genes–&gt; compensation mechanism for poor protein dietary. Structure: graph LR; HigherFR-->|verified by RNA-Seq|DEGs; DEGs-->|Explain|Compensation; Compensation-->|to|Poor_Protein_Dietary; P6 Overall … Different responses to RM diet between strains F better use RM than A.(similar found in rainbow trout) RAN-seq in strain F feed with RM Digestive enzyme activated Higher plasma AA at 2h after diet Better growth performance Genes included in assy, gcsp2, serc expressed lower higher PRE RAN-seq in strain A feed with RM immune response-related genes, including xxx, but unaltered in strain F. This indicate higher inflammatory response in strain A, associated some other reports. Strain F has lower LRE with RM group. arachidonic acid metabolism were lower in F, which related to immune responses. F had lower lipid deposition to lower inflammatory responses Genes, like XXX, related phospholipid metabolism had lower expression in F. Take together Diet had interaction with Genotype. Conclusion Skip! Related papers: Morais S, Pratoomyot J, Taggart JB, Bron JE, Guy DR, Bell JG, Tocher DR (2011b) Genotype-specific responses in Atlantic salmon (Salmo salar) subject to dietary fish oil replacement by vegetable oil: a liver transcriptomic analysis. BMC Genomics 12:255 Morais S, Edvardsen RB, Tocher DR, Bell JG (2012a) Transcriptomic analyses of intestinal gene expression of juvenile Atlantic cod (Gadus morhua) fed diets with Camelina oil as replacement for fish oil. Comp Biochem Physiol B Biochem Mol Biol 161:283–293. Tacchi L, Secombes CJ, Bickerdike R, Adler MA, Venegas C, Takle H, Martin SA (2012) Transcriptomic and physiological responses to fishmeal substitution with plant proteins in formulated feed in farmed Atlantic salmon (Salmo salar). BMC Genomics 13:363 PS I think that the author did a good job on the discussion secession. First of all, he mad a conclusion about the Growth performance of the corps. This is what what we can see at the first glance, and one of the direct purpose of this experiment. On the other hand, the author gave a general summery of the different in metabolic, digestives, and cell signals change, etc. After that, the author focused on two widely concerned challenges in plant meals: lacking of some essential amino acids and lipid deficiency. As a result, the body protein deposition was definitely affected and oat was involved in Nitrogen compensate. About the Lipid metabolism, they found that the gene hmdh are respond to keep cholesterol homeostasis. After this discussion, the author are focused in talking about the interaction of the diet and genotype, the part makes this experiment unique. Above of, this discussion is a good example to show how to handle a discussion, how to write a story logically and neatly. Related Notes: Transcriptomic analysis of juvenile Chinese sea bass (Lateolabrax maculatus) anesthetized by MS-222 (tricaine methanesulfonate) and eugenol De novo characterization of the liver transcriptome of javelin goby Synechogobius hasta and analysis of its transcriptomic profile following waterborne copper exposure Transcriptomic response to soybean meal-based diets as the frst formulated feed in juvenile yellow perch (Perca favescens)","link":"/2020/07/07/LearnNotes/Paper_RNASeq_Fish3/"},{"title":"Transcriptomic response to soybean meal-based diets as the frst formulated feed in juvenile yellow perch (Perca favescens)","text":"Transcriptomic response to soybean meal-based diets as the frst formulated feed in juvenile yellow perch (Perca favescens) Cite: Kemski, M.M., Rappleye, C.A., Dabrowski, K. et al. Transcriptomic response to soybean meal-based diets as the first formulated feed in juvenile yellow perch (Perca flavescens). Sci Rep 10, 3998 (2020). https://doi.org/10.1038/s41598-020-59691-z General Information Statistic information Content Words Ratio Total Words 3309 100% Abstract 171 5.17% Introduction 700 21.15% Results 939 28.38% Discussion 1499 45.30% Conclusion 163 4.93% Background Synechogobius hasta: （图片转自 nanfa.org，版权属于原作者） Abstract Plant protein diet substitute became more and more common. Purpose of this paper. Experiment Design. Resutl Conclusion Introduction ###P1: Is Soybean awesome?(BG information of Soybean meal) Shortcomings: hgih carbohydrate levels isoflavones low methionine levels anti-nutritional factors They can: impede protein digestion impair immune responses intestinal inflammation. End: Yellow perch is one of the most sensitive species for this change. P2: Impacts It has more negative affects on juvenile fish than adults. P3: Transcriptomic Studies Short period study: Lots of related studies have been down and show that the digestive and metabolic system were impaired. Long period(12 weeks) studies: Increased in immune related and inflammation related genes, and donw regulation of metabolic pathway. P4 This Experiment is unique!!! P4:G. carp is important. A: fast growth; B: fast growth &amp; Diseases resist. M&amp;M Materials and methods Experimental fish and rearing conditions Sample collection Chemical analysis Transcriptome analysis Quantitative real-time PCR Statistical analysis Results Feeding trial Transcriptomic responses Up-regulation of genes found in SBM fed fish Down-regulation of genes found in SBM fed fish Quantitative real-time PCR validation Whole body lipids and cholesterol analysis Feeding trial Survival Counts and Table Transcriptomic responses Basic statistics and figures Up-regulation of genes found in SBM fed fish Basic statistics and figures Down-regulation of genes found in SBM fed fish Basic statistics and figures Quantitative real-time PCR validation General Statement Whole body lipids and cholesterol analysis Discussion P1 Introduction Plant protein is imperative Potential utility: optimal feeds Previous studies has P2 BG information (PS: I don’t think this paragraph is needed…) P3 Weight are not significantly different. Acceptance diet. P4 Intestine Previous studied revealed three different regions of intestine. And the mid region is the target. (PS: Does the author try to show that this design of the experiment is appropriate or??) P5 Up-regulated gene in mid gut cholesterol biosynthesis cholesterol is only found in animal materials. cholesterol intake was impaired by phytosterols. P6 Cholesterol Biosynthesis genes, rate-controlling enzyme ware up-regulated. Increasing the synthesis of cholesterol to matain the homeostasis. P7 Growth Performance Reduced cholesterol levels can cause a reduction in growth Support cholesterol to improving growth. cholesterol synthesis is a high energy expenditure. Compounds are highly involved in fatty acid P8 lipid Gene involved in lipid metabolism and transport were up-regulated. This change is involved in cholesterol homeostasis. The change happens in intestine as well as livers compared with previous experiment. P9 Over Overall Despite the changes, the total body lipid doesn’t have a significantly different after 61 days of feeding. So as the cholesterol. Increased cholesterol biosynthesis is compensated the lower diet intake. This result is different from a study done in rainbow trout. Plasma cholesterol content reduces in European seabass and Atlantic salmon with SPM feeding. Explain: excess cholesterol in the body is stored Conclusion Though, total weight and lipid are not significantly changed between two groups is because some how the fish compensated the different, like de novo cholesterol. It is one of the first study that … main the growth. biosynthesis Related papers: Morais S, Pratoomyot J, Taggart JB, Bron JE, Guy DR, Bell JG, Tocher DR (2011b) Genotype-specific responses in Atlantic salmon (Salmo salar) subject to dietary fish oil replacement by vegetable oil: a liver transcriptomic analysis. BMC Genomics 12:255 Morais S, Edvardsen RB, Tocher DR, Bell JG (2012a) Transcriptomic analyses of intestinal gene expression of juvenile Atlantic cod (Gadus morhua) fed diets with Camelina oil as replacement for fish oil. Comp Biochem Physiol B Biochem Mol Biol 161:283–293. Tacchi L, Secombes CJ, Bickerdike R, Adler MA, Venegas C, Takle H, Martin SA (2012) Transcriptomic and physiological responses to fishmeal substitution with plant proteins in formulated feed in farmed Atlantic salmon (Salmo salar). BMC Genomics 13:363 Related Notes: Transcriptomic analysis of juvenile Chinese sea bass (Lateolabrax maculatus) anesthetized by MS-222 (tricaine methanesulfonate) and eugenol De novo characterization of the liver transcriptome of javelin goby Synechogobius hasta and analysis of its transcriptomic profile following waterborne copper exposure Physiological and transcriptomic responses to fishmeal-based diet and rapeseed meal-based diet in two strains of gibel carp (Carassius gibelio)","link":"/2020/07/07/LearnNotes/Paper_RNASeq_Fish4/"},{"title":"Nutritional Wheat Amylase-Trypsin Inhibitors Promote Intestinal Inflammation via Activation of Myeloid Cells (Sparus aurata) in response to dietary fish meal replacement by plant protein sources","text":"Nutritional Wheat Amylase-Trypsin Inhibitors Promote Intestinal Inflammation via Activation of Myeloid Cells (Sparus aurata) in response to dietary fish meal replacement by plant protein sources Cite: Zevallos, Victor F., et al. “Nutritional wheat amylase-trypsin inhibitors promote intestinal inflammation via activation of myeloid cells.” Gastroenterology 152.5 (2017): 1100-1113. General Information Background Mice: （图片转自 havahart.com，版权属于原作者） Abstract BG Wheat amylase-trypsin inhibitors (ATIs) ATIs activation of the toll like receptor 4 (TLR4) METHODS: Feed to Mice RESULTS CONCLUSIONS: Gluten-containing cereals have by far the highest concentrations of ATIs that activate TLR4. Orally ingested ATIs are largely resistant to proteases and heat, and increase intestinal inflammation by activating gut and mesenteric lymph node myeloid cells. Introduction ###P1: Plant protein substitution for economy Shortcomings: high carbohydrate levels isoflavones low methionine levels anti-nutritional factors They can: impede protein digestion impair immune responses intestinal inflammation. End: Yellow perch is one of the most sensitive species for this change. P2: Pancreas Serine-protease (trypsin, chymotrypsin, elastase and collagenase) Glucosidases hydrolyze starch into lineal chains P3: Our purpose Protine and Carbohydrate digestion histology M&amp;M Chemicals Diets, animals and growth experiment Post-parndial experiment and sampling Preparation of extracts and determination of soluble protein Enzyme assays Zymograms: characterization of protease fractions and inhibition by PP diets Proximal intestine histological analysis Statistical analysis Results Enzymes activities Alkaline Protease Trout fed diets PP50 and PP75 showed only a slight post-feeding increase in this activity. Sea bream fed the FM diet showed a maximum of 6.93±1.03 U protease·mg− 1 protein·min− 1. This value decreased gradually as the percentage of plant protein increased Amylase a significant post-prandial increase in this activity was recorded only in PP75 and PP100 fed trout. Replacement of fish meal by plant protein did not induce significant changes in α-amylase activity in either species. Growth Performance Intestine Growth Related Notes: Transcriptomic analysis of juvenile Chinese sea bass (Lateolabrax maculatus) anesthetized by MS-222 (tricaine methanesulfonate) and eugenol De novo characterization of the liver transcriptome of javelin goby Synechogobius hasta and analysis of its transcriptomic profile following waterborne copper exposure Physiological and transcriptomic responses to fishmeal-based diet and rapeseed meal-based diet in two strains of gibel carp (Carassius gibelio) Transcriptomic response to soybean meal-based diets as the frst formulated feed in juvenile yellow perch (Perca favescens)","link":"/2020/07/07/LearnNotes/Paper_WheatInhi/"},{"title":"思維導圖軟件","text":"思維導圖軟件 1. 億圖 官網, 下載地址 優點： 模板多 風格清新 多格式輸出(office聯動) 操作界面類似office，易上手 可部分替代ppt 使用感覺類似ppt，易上手 多版本適配: 国产ARM架构-银河麒麟/UOS 国产龙芯架构-银河麒麟/UOS 国产兆芯架构-银河麒麟/UOS 缺點： 如果購買付費版， 以下缺點都將消失 導出有水印 Limited output formats for non-subscirb users Limited Nodes for free user 主界面 PPT類似的操作界面和方式 多格式導出 In free version, you can only export the result as XML/PDF/jpg files. 2. Xmind Install 官網, 下載地址 Ubuntu sudo apt install xmind Manjaro: yay -S xmind 優點： 輕量， 使用簡單， 沒有太多花哨的功能 專注思維導圖， 模板漂亮 缺點： 導出格式少 功能少，散枝不自由 文字編輯能力弱","link":"/2020/07/07/LearnNotes/SF_Xmind/"},{"title":"Effects of fishmeal replacement by soy protein concentrate on growth performance, apparent digestibility, and retention of protein and amino acid in juvenile pearl gentian grouper","text":"Effects of fishmeal replacement by soy protein concentrate on growth performance, apparent digestibility, and retention of protein and amino acid in juvenile pearl gentian grouper Cite: Chen, Yan, et al. “Effects of the replacement of fishmeal by soy protein concentrate on growth performance, apparent digestibility, and retention of protein and amino acid in juvenile pearl gentian grouper…” PLOS ONE 14.12 (2019). General Information Background Synechogobius hasta: （图片转自 hx888.com，版权属于原作者） Abstract Substitute gradient SPC15 has a best growth performance SPC75 has a worst growth performance SPC15 and SPC30 had the highest protein efficiency ratio Daily feed intake was significantly decreased Survival rate were higher in SPC15, SPC30, and SPC45 SPC15 and SPC30 showed significantly higher protein and amino acid (AA) retention Introduction ###P1: BG BG of Aquaculture P2: BG BG of Soybean meal in Aquaculture P3: BG BG of Pearl Gentian Grouper M&amp;M Diet formulation Feeding trial Sample collection and calculation formula for growth performance Biochemical analysi Statistical analysis QEthical statement Results Growth performance and biometry Nutritional composition Protein and individual AA ADCs and retention in muscle Growth performance and biometry Survival SPC 15, SPC 30, and SPC 45 (from 94% to 96%) as compared to SPC 60 and SPC 75 (P &lt; 0.05) BWG, WGR, SGR, and PER SPC15 BWG: average body weight gain; WGR: Weight gain ratio; SGR: specific growth rate, survival; PER: protein efficiency ratio FCR (feed conversion ratio) SPC15 DFI (Daily feed intake) SPC0 Nutritional composition Muscle protein SPC0, SPC15, SPC30 &gt; SPC45, SPC60, SPC75 Whole Body Moisture content gradually increased Crude protein SPC30, SPC45 &gt; SPC60, SPC75 Muscle AA histidine, lysine and methionine Negative related Methionine: H, SPC30; L, SCP75 Lysine: H, SPC15； L，SPC75 Discussion P1 Introduction Other studies This experiment P2 Regression Model Predict the best ratio for Growth performance improving P3 Tolerate Comparing Some fish have high tolerate of plant meal but not Grouper P4 Growth Performance &amp; feed intake Growth performance related but not depend by feed intake. The best growth performance is SPC15, but the highest uptake ratio is SPC0 P5 Poor Nutrition Value Anti Nutrition Factors (ANF) &amp; Lower Content of Amino Acids ANF phytic acid, trypsin inhibitor, raffinose, and glycinin phytic, trypsin: feed intake and growth P6-7 Phytic and Trypsin Mild effects on growth compared with previous studies: We have a lower concentration of phytic as well as trypsin. (Other studies) reduction in the bio-availability of Phosphorus, Calcium, Magnesium, and Zinc P8-9 General Conclusion P10 Summary Conclusion SPC 11-14% can optimize the growth performance. SPC30 can still remain beneficial for the grouper.","link":"/2020/07/07/LearnNotes/Paper_Yan2020/"},{"title":"Effects of culture density and feeding frequency on the growth performance, digestive enzyme activity and tissues histology in hybrid grouper (Epinephelusfuscoguttatus♀×E. lanceolatus♂)","text":"Abstract A 6 week 5×2 two factorial experiment 5 culture densities 1.1 kg m−3(0.55 kg fish per tanks, CD1.1) 2.2 kg m-3(1.1 kg fish per tank, CD2.2) 3.3 kg m−3(1.65 kg fish per tank, CD3.3) 4.4 kg m−3(2.2 kg fish per tank, CD4.4) 5.5 kg m−3(2.75 kg fish per tank, CD 5.5) 2 feeding frequencies(FF) 2 meals a day (FF2) 3 meals a day (FF3) growth performance body composition digestive enzyme activity tissues histology ID Density Feeding Frequency G1 CD1.1 FF3 G2 CD2.2 FF3 G3 CD3.3 FF3 G4 CD4.4 FF3 G5 CD5.5 FF3 G6 CD1.1 FF2 G7 CD2.2 FF2 G8 CD3.3 FF2 G9 CD4.4 FF2 G10 CD5.5 FF2 Result Weight Gain - High: G7; G1;- Lowest: G3;- FF2 &gt; FF3 Muscle - G8 &gt; G2-G6- No significantly different between G8 and other groups Protein Content similar like the muscle Serum - glutamic oxaloacetic aminotransferase (AST), alanine aminotransferase (ALT), triglyceride (TG) and cholesterol (CHO)- Immune function: albumin (ALB), serum lysozyme (LZY), superoxide dismutase (SOD) and alkaline phosphatase (AKP) were significantly affected Density - pepsin and lipase in stomach, intestine and liver were significantly affected Histological Structure - Normal: G1, G2, G7 and G8- Other groups were damaged to varying degrees Introduction graph LR; FF(daily feeding patterns); CD(intensive fish-farming); FC(growth performance); NC(nutritional conditions); SL(stress levels); MP(management procedures); WQ(water quality); FF-->FC; rhythms-->FC; CD-->FC; WQ-->SL; FF-->SL; rhythms-->SL; CD-->SL; NC-->SL; MP-->SL; Feeding frequency regulating the feed intake growth and chemical composition reduction of aquaculture production cost preventing water quality deterioration Challenge: Overfeed: Canoverload: decreasing digestive efficiency and reductions Insufficient FF: poor growth; high mortality; sporadic feeding and low feeding rates may contribute to reduced growth as well as increased hunger, intraspecific aggression, and increased rate of cannibalism[1] Intensive Intensive fish-farming practices often cause stress and poor health in fish. welfare aquaculture profitability High Density stunts fish survival percentage weight gain specific growth rate physical injuries stress susceptibility to disease swimming behaviour intensify aggression The results are attributed to social interactions competition for food and/or space[2], leading to the establishment of hierarchies[3]. Materials and Methods Skip Result Discussion Weight Blood Muscle moisture in the muscle gradually decreased with the increase of CD Protein, fat and ash showed a gradual decline enzyme activities pepsin activity and amylase activity FF2 &gt; FF3 activity increased as the increase of CD except intestinal amylase Folkvord A, Ottera H (1993).Effects of initial size distribution, day length, and feeding frequency on growth, survival, and cannibalism in juvenile Atlantic cod (Gadusmorhua L.). Aquaculture 114: 243-260 ↩︎ Lloyd M J , Bates A E . Influence of density-dependent food consumption, foraging and stacking behaviour on the growth rate of the Northern abalone, Haliotis kamtschatkana[J]. Aquaculture, 2008, 277(1-2):24-29. ↩︎ Cristina E. Trenzado and Manuel de la Higuera and Amalia E. Morales. Influence of dietary vitamins E and C and HUFA on rainbow trout (Oncorhynchus mykiss) performance under crowding conditions[J]. Aquaculture, 2007. ↩︎","link":"/2020/08/12/LearnNotes/Paper_fish_dencity/"},{"title":"Advance BioChemistry: How Organism are Related","text":"The Big Bang The big bang → Earth condensation → Microbes → Anabaena with heterocytes → Oxygen appear in the atmosphere → Endosymbiotic (mitochondria) → Endosymbiotic (chloroplast) → Oxygen reach to 22% → Sponges → Trilobites → landing → reptile → mammal like reptile → pangaea separates → flowering plaints/E. coli → primate → Homo © dailyinfographic How Similar We Are In the GMP synthesis, E. coli and eucaryotic organisms are doing the same pathway. This shared process highlights the similarities in fundamental biochemical pathways across diverse species. When compare to E. coli to human cell, E.coli are way more complicated than human cell: all amino acid: It can synthesize all amino acids, whereas humans can’t produce all of them endogenously. Food: Capable of consuming more than 100 types of food. Environments: Can thrive in a wide range of environments, showcasing its adaptability. In contrast, human cells seem more like simplified microbes. The evolution might have played a role in streamlining certain processes in eukaryotes. Ribosomes in Chemistry It precisely matches the protein shelves, making it extremely conservative in its function. Secondary structures are paramount, leading to mutations that are commonly paired to preserve structure and function. Due to the matched protein structure, the rate of gene drift is limited, ensuring stability. Research on this ribosome led to the discovery of Archaea, prompting a revision in our understanding of the tree of life. Gene Transfer Among Microbes Gene transfer, often referred to as Horizontal Gene Transfer (HGT), is a prevalent phenomenon among microbes. The mechanisms include: Uptake of free DNA from the environment. Plasmid-mediated transfer. Conjugative mating. Virus-mediated transfer (transduction). However, HGT is less common in Eukaryotes, with a few exceptions. Operon: A Unique Feature of Microbes Microbes often have related functional genes located in proximity. This arrangement is no accident. These genes are regulated by operons, ensuring they function in sync. The clustering of these genes is believed to have arisen due to evolutionary pressures and random events, but once established, they provide a selective advantage. © Peter Karp, 2007 pre { background-color:#38393d; color: #5fd381; }","link":"/2023/08/21/LearnNotes/UIUC-AdBC-1/"},{"title":"Super Conductor","text":"Super Conductor Source: The Stuff of Dreams, Scientific American; Oct 2019 Could new theoretical and computational advances finally deliver the elusive room-temperature superconductor? BCS theory (Bardeen–Cooper–Schrieffer theory) The properties of Type I superconductors were modeled successfully by the efforts of John Bardeen, Leon Cooper, and Robert Schrieffer in what is commonly called the BCS theory. A key conceptual element in this theory is the pairing of electrons close to the Fermi level into Cooper pairs through interaction with the crystal lattice. This pairing results from a slight attraction between the electrons related to lattice vibrations; the coupling to the lattice is called a phonon interaction. – R Nav1. Electron moves through the lattice will pull the atoms in lattice, and bunches positives charges together as a result.1. The positive charges will pull another electron into the first wake, Cooper pair formed between the two particulars.1. Those pairs behavior like waves name as Bose-Einstein condensate that is too large to be impeded by the lattice and so flows through it without any resistance at all. ©2019 Scientific American AAAAAAAAAAAAAAAAAAA Machine learning in super conductor 2018, one algorithm trained on a database of thousands of materials, developed ability to identify superconductors in another data set with 92 percent accuracy and to estimate their critical temperatures.It did so using only simple elemental properties such as atomic weight and melting temperature. Shortcoming: There is something you do which works, and you just keep doing exactly the same thing to make it work, and why you do it you have no idea. --Somayazulu Extra Reading Superconducting Transistor © news.mit.edu Transistor: “Transistor, semiconductor device for amplifying, controlling, and generating electrical signals. Transistors are the active components of integrated circuits, or “microchips,” which often contain billions of these minuscule devices etched into their shiny surfaces. Deeply embedded in almost everything electronic, transistors have become the nerve cells of the Information Age.”-- Michael Riordan[1] Applying[2]: Highly sensitive situation: Monitory brain activity quantum and classical computing. Josephson junction: Traditional superconducting transistor is a device invented in the 1960s. Essentially two superconductors separated by a thin insulator. Shortcoming of the traditional superconducting transistor: finicky expensive prone to err low temperature working environment Cryotron Developed by Dudley Buck, MIT electrical engineer, in 1956. The device was little more than two superconducting wires: One was straight, and the other was coiled around it. Much smaller than current computing switches like vaccum tubes. 1959, Buck died in suddenlu at age 32. The program was ceased. Superconducting Nanowire To overcome the disadvantages of Josephson junction, Karl Berggren’s group developed the nanowire, whcih is based on the Cryotron. Switch is triggered by magnetic, rather than heat. The infromation of this block was mainly form Science Daily[2:1] Michael Riordan Professor of Physics, Institute for Particle Physics, University of California at Santa Cruz, and Professor of History and Philosophy of Science, Stanford University, Stanford, Calif. Author of Crystal…link ↩︎ Daniel Ackerman MIT News Office, Nanowire could provide a stable, easy-to-make superconducting transistor, Feb 11, 2021. ScienceDaily. link ↩︎ ↩︎","link":"/2020/02/07/LearnNotes/Super-Conductor/"},{"title":"Advanced Molecular &amp; Cell Biology 2","text":"Cellular Biology 2 Bacterial gene are clustered by function (it could regulated by a same prone) THe invention of most cellular enzymatic mechanisms and biochemical pathways occured early in microbs and we are inherits it. Do human continue to evolve? mtDNA mutation making more heat than ATP. Common in Artuc peoples Sickle-cell hemogolobin mutations conferring malarial resistance. 3 CCR5 delta32 mutation impairing HIV binding to white blood cells. Found esp. In NE, Speculate that it protected against some other pathoge 700 years ago/ Pre-disposition of hunter-gathere populations t obesity and type-2 diabetes in wester diet. Mutation in the Tibetan populations enabling high blood O2 EPAS2 variatn inherited form Denisovans. Multople copies of salivary amylase in populations with high-starh diet Q1: whay aren’t there alternative forms of life on Earth? Nasa: search for L-isoleucine Separated perticula questions from biology and lack of the big picture. Z ion channel; Methane; virus; Phosphorite sugar, ribosome, Chromosome separation, Chaperones. So, the question is What is ‘life’? Metabolism pathway is very complicated. , The hard part about bilogy is its complexity: from isolated cell → clonal collaboration → consotia of multiple species → Tissues → Systems Even a single cell too complex to be understand. Which genes are necessary for something to live? it could help ua to understadn how a cell work, how life evolved build an artificial organism. Number of Genes: E. Coli: 4200 Stretomyctes: 9000 saccharomyces cerevisiae: 6200 human: 22000 What are the essential parts of a cell? Mycoplasma genitalium: 525 genes, an intracellular parasite. Lack a cell wall. in a stable environment, so a few adaptive strategies Depends on hosts as a source of nutrients. What genes are universal? Hemophilus influenzae: 1815, 256 shared with M. geneitalium. Challenge: different isozymes could perform the same critial processe: rebonucleoacid redundant: With/without oxygen BActeria and eukarya make esterified lipids. Humans oxidize NADH via a respiratry chain, yeast do it by making alcohol. The specific mechanisms are non-universal- but they are essential to the organism. Reasoning from first principles. Transport Energy: carry lots of thermodynamic unfavorite actions for life. Which Genes cannot be knocked out without loss of viability insert transposon: gene knock out: sequencing the clone and get the non-essential genes No mutation list: tRNA synthetases Ribosome Translation factors Protein secretion Chaperones DNA replication Transcription Cell division Nucleotide synthesis Cofactor synthesis Fatty acid synthesis Cell wall synthesis Some ventral metabolism 171 gene in E. Coli were not knocked out. biosynthetic genes and catabolic genes (medial is rich in lots of source) 435 genes are essential for microplasmid and it growth much slower than normal pre { background-color:#38393d; color: #5fd381; }","link":"/2023/08/23/LearnNotes/UIUC-AdBC-2/"},{"title":"Advanced Molecular &amp; Cell Biology 1","text":"DNA Structure; RNA Polymerase Properties; $\\sigma$ Factor 70 !!! Main purpose for this lecture DNA sequences drive specific Protein:DNA interactions, which is fundamental for processes like transcription. Transcription steps can be experimentally defined, allowing for detailed understanding and manipulation. General Properties Response Element Recognition: Response elements are DNA sequences that are recognized and bound by transcription factors, enabling regulation of gene expression. HAT/PTM Complexes: Histone acetyltransferases (HAT) and post-translational modifications (PTM) play pivotal roles in regulating gene expression by modifying histones and other proteins. Chromatin Remodeling: This process allows for accessibility of transcriptional machinery to the DNA by changing the structure of chromatin. Mediator: A complex that acts as an interface between transcriptional activators, RNA polymerase, and other transcriptional machinery. The environment inside a cell is overcrowded, causing molecules to move rapidly, which influences various cellular processes. © bionumbers.com Subunits have Distinct Functions (RNAP) © golifescience P122; Figure 6.1 Initial Steps Promoter Search: RNA polymerase locates promoter regions, an ATP-consuming process, to initiate transcription. Closed Promoter Complex Formation: RNA polymerase binds to the promoter region without unwinding the DNA double helix. Open Promoter Complex Formation: The DNA double helix unwinds, allowing RNA polymerase to initiate RNA synthesis. $\\sigma$ Factors Driving Specificity/Stability Background: Core enzyme indiscriminate about the T4 genes it transcribes, it also transcribes both DNA strands. Experiment: RNA made by the holoenzyme did not hybridize with authentic T4 RNA, confirming it is made asymmetrically like the in vivo RNA. About 30% of the RNA made by the core enzyme hybridized with authentic T4 RNA and became RNase-resistant. Conclusion: The core enzyme transcribes both DNA strands, unlike the holoenzyme that transcribes asymmetrically. This suggests the core enzyme’s activity is not as specific as the holoenzyme’s. $\\sigma$ factors are essential for promoter recognition and transcription initiation. They stabilize DNA-bound RNA Polymerase, ensuring efficient transcription. Filter Binding Assay: DNA molecules can pass through a filter, but the $\\sigma$ factor cannot. When mixed together, DNA molecules associate with the $\\sigma$ factor, preventing them from passing through. $\\sigma$ factor aligns RNA Polymerase at a promoter, ensuring accurate transcription initiation. Assay for Locating the ‘Melted’ DNA: Radio labeling is used to tag specific DNA sequences. Methylation of DNA occurs at specific sites. Cleavage of DNA at methylated sites provides insights into DNA regions that are “melted” or unwound during transcription. Technics Filter binding assay P108, Figure 5.35 Nitrocellulose Membrane Filters and DNA-Protein Interaction Background: Nitrocellulose membrane filters have long been used for filter-sterilizing solutions. They are also known to bind DNA, but under specific conditions. Key Points: Binding Conditions: Single-stranded DNA: Binds readily to nitrocellulose. Double-stranded DNA: Does not bind to nitrocellulose by itself. Protein: Binds to nitrocellulose. When bound to double-stranded DNA, the protein-DNA complex will bind to the filter. Assay Demonstrations: Figure 5.35a: Labeled double-stranded DNA passed through the filter shows that it does not bind to nitrocellulose. All labeled material found in the filtrate. Figure 5.35b: Labeled protein is filtered and is found to bind to the nitrocellulose filter. Demonstrates that proteins can bind independently. Figure 5.35c: Labeled double-stranded DNA mixed with a binding protein shows that the protein-DNA complex binds to the filter. The radioactivity is found bound to the filter, confirming the interaction. Conclusion: Filter binding assays using nitrocellulose membrane filters serve as a direct measure of DNA-protein interaction. This makes nitrocellulose filters a useful tool for studying such interactions. Methylation-S1 nuclease Figure 6.15; P133 Figure 6.16; P134 Background: In 1979, Ulrich Siebenlist carried out an experiment to identify the base pairs melted by RNA polymerase in a T7 phage early promoter. The aim was to understand the local DNA melting involved in the formation of an open promoter complex. Key Points: Experiment Strategy: Step 1: End-label the promoter DNA. Step 2: Add RNA polymerase to form an open promoter complex, which involves local DNA melting. Step 3: Methylate exposed adenines with dimethyl sulfate (DMS). Step 4: Remove RNA polymerase to allow the region to close. Step 5: Treat the DNA with S1 nuclease, which specifically cuts single-stranded DNA. Step 6: Electrophorese the labeled DNA fragments to determine their lengths. Chemical Agent Used: Dimethyl sulfate (DMS) methylates exposed adenines, preventing them from base-pairing with thymines in the opposite strand when the region closes. S1 Nuclease: Specifically cuts where an adenine had been in a melted region and had become methylated. Results: A series of fragments extending from position 13 to 29 were observed, rather than a neat set. The length of the melted region was estimated to be 12 base pairs. G–C pairs were not detected due to the experimental conditions used for methylation. Conclusion: The melted region in the T7 phage early promoter was identified to extend from positions 13 to 29 and to have a length of approximately 12 bp. This is in agreement with previous estimates. The experiment revealed that the melted region is precisely where RNA polymerase begins transcribing, which is of biological significance. However, the presence of G–C pairs in the region could not be verified due to limitations in the methylation conditions used. pre { background-color:#38393d; color: #5fd381; }","link":"/2023/08/22/LearnNotes/UIUC-AdMC-1/"},{"title":"Molecule and Cellular Biology 5","text":"Points for the lecture Gene regulation by manipulation of DNA structure (bending, looping, twisting) Activation does not always involve direct interaction with RNAP Genomes are packaged and spatially organized Reading: 8.3 DNA Looping and Post-Translation Modification (PTM) Glutamine Synthesis Unknown NtrC Controls glnA Promoter from a Distance &amp; How Does a Distant Element Works? Unknown Enhancers Function Over Long Distances loop require the ATP and a littel amout of DNA NtrC RNAP-Interactions Prefer a 390-bpIntervening Sequence DNA Looping, in general, Requires &gt;250 b.p. pre { background-color:#38393d; color: #5fd381; }","link":"/2023/09/05/LearnNotes/UIUC-AdMC-5/"},{"title":"Molecule and Cellular Biology 4","text":"cAMP Levels Control ‘Catabolite Repression’ Catabolite Activator Protein: Ira Pastan and his colleagues demonstrated that cAMP, added to bacteria, could overcome catabolite repression of the lac operon and a number of other operons, including the gal and ara operons. A protein involved in gene regulation was discovered and named CAP by Zubay and CRP by Pastan’s group. We will use the name CAP to refer to this protein and crp as the gene. CAP mechanism: Mutation Discovery: Zubay’s team found mutations in the lac promoter preventing CAP and cAMP from boosting lac transcription. Binding Site Location: Research pinpointed the CAP-cAMP binding site upstream of the lac promoter. CAP-cAMP Complex Formation: cAMP modifies CAP’s shape, increasing its affinity for the binding site. Open Promoter Complex Assistance: The CAP-cAMP complex helps RNA polymerase to form an open promoter complex, aiding transcription initiation. Role in Transcription: The complex aids in efficient lac operon transcription, helping the cell adapt to nutritional changes. In this process, the CAP-cAMP complex facilitates the initiation of transcription in response to environmental cues, enhancing the cell’s adaptability. Regulation: many layers Positive Reg: alpha-subunit of RNAP DNA bending Weak promoters CAP: Catabolic activator protein repressor responsible to low level of Lactose so it wound transcript when Lactose is low CAP responsible to the low level of Glu and help the transcription When Glu is low and lactose is high, the repressor is cleared and CAP is on. The transcription is started. CAP is a receptor to bind the cAMP. cAMP-CAP complex contribute the activation of the gene expression. CAP Binding Induces DNA Bending Figure 10.27 CAP bends DNA &gt;90° around the center of symmetry. Study Focus: Investigation of the DNA bending effect due to CAP–cAMP binding using electrophoresis. Method: Prepared equal length DNA fragments of the lac operon with varied CAP-binding site positions. Bound CAP–cAMP to each fragment. Performed electrophoresis to observe the migration rates of the DNA-protein complexes. Findings: DNA fragments exhibited different migration rates, indicating DNA bending. The degree of bending was estimated to be around 90 degrees, aligning reasonably with the 100 degrees found in later x-ray crystallography studies. Implication: The observed DNA bending is believed to facilitate optimal interactions between proteins and DNA in the complex. CAP-cAMP Binding Functionally Similar to Up Element P182; Figure 7.19 Study Focus: Importance of interaction between CAP and RNA polymerase’s aCTD in transcription stimulation. Experiment Details: Used RNA polymerases with both normal and truncated a-subunits to transcribe cloned lac operons in vitro. Findings: Truncated a-subunits could function like wild-type in absence of CAP-cAMP. Truncated a-subunits weren’t stimulated by CAP-cAMP, indicating the necessity of aCTD for CAP-cAMP stimulation. Hypothesis: CAP-cAMP dimer, binding to its activator site, interacts with aCTD, enhancing polymerase’s affinity for the promoter, similar to aCTD’s role with UP elements. CAP promoters 3 Classes of CAP Regulated Promoters Unknown Attribute Class I Class II Class III Activation Requires only CAP Requires only CAP Requires CAP and additional regulators CAP/CRP Binding Site Upstream of the promoter Overlaps the promoter, replacing -35 region Variable, typically &gt;90 bp upstream Prototype LacP1 GalP1 None Location (from start point) Centered 61.5 bp upstream Centered 41.5 bp upstream More than 90 bp upstream Examples - - AraBAD, malK promoter CAP Operators Display Periodicity: The greatest activation was seen at distances of -41.5 and -61.5 which correspond exactly to the spacings observed in CLASS II and CLASS I CRP-activated promoters, respectively. DNA Bending as a Regulatory Mechanism Illustrate Description - Promoter bashing of a hypothetical two-region promoter. The promoter is cloned upstream of the lacZ reporter gene. Point mutations that inactivate each region are made (the red Xs) and the region is cloned onto a plasmid and inserted into E. coli cells, grown up, and has the presence of reporter measured. The binding of Protein B in this example is necessary for RNA polymerase to bind and initiate transcription.- In a laboratory setting, it may not be known that the promoter consists of two regions – single mutations can be made along the promoter, the promoter can be sequenced, and the levels of reporter assayed to find boundaries for each region. © wiki araBAD Operon araBAD encodes enzymes responsible for arabinose breakdown Operon is catabolite repressed, and thus requires CAP.cAMP for activation of transcription Activation also requires the complex of AraC. arabinose as an activator Explains why araBAD is only transcribed in the presence of arabinose Components: araO2: Far upstream binding site for AraC. araO1: Located between positions -106 and -144, another binding site for AraC. araI: Divided into araI1 (-56 to -78) and araI2 (-35 to -51), each can bind one monomer of AraC. araA-D: Four genes in the ara operon where araB, araA, and araD are for arabinose metabolizing enzymes and araC is for encoding the control protein AraC. araPBAD: Promoter for rightward transcription of araB, A, and D. araPC: Promoter for leftward transcription of araC. States: Without Arabinose (Repressed State): AraC binds to araO2 and araI1. Causes DNA looping between the binding sites, repressing the operon. With Arabinose (Derepressed State): Arabinose alters AraC conformation. AraC binds to araI1 and araI2, breaking the repression loop. The operon is derepressed. Positive Control: Involves CAP and cAMP. They bind to a site upstream of the araBAD promoter. DNA looping facilitates CAP’s contact with polymerase, enhancing its binding to the promoter, thereby stimulating transcription. Figures: Figure 7.21a: Illustrates the three binding sites of AraC. Figure 7.21b: Shows the repression loop in the absence of arabinose. Figure 7.21c: Depicts the derepressed state with the presence of arabinose and how CAP-cAMP complex influences transcription. This structure helps in detailing the different components involved and the states of the ara operon based on the presence or absence of arabinose, along with the role of CAP and cAMP in its regulation. It also mentions the figures that visualize these processes. Arabinose Metabolism System Promoter Bashing Identified Two Operator Sites for Repression DNA Bending Requires both araO2 and araI Sites How can araO2 control transcription from a promoter over 250 bp downstream? The most reasonable explanation is that the DNA in between these remote sites (the operator and the promoter) loops out as illustrated in Sure! Here is a summarized version of the passage in note form: P184; Figure 7.22 Experiment setup: Objective: Verify AraC-induced DNA loop formation in the ara operon in the absence of arabinose. Materials: 404-bp supercoiled minicircle DNA containing araO2 and araI sites, 160 bp apart. AraC protein. Method: Electrophoresis to measure DNA loop formation by monitoring changes in electrophoretic mobility. Findings: AraC induces loop formation: Evidence: A new high-mobility band observed upon addition of AraC, indicating looped minicircle (Figure 7.22, compare lanes 1 and 2). Loop stability depends on both araO2 and araI: Tested using: Wild-type minicircle. Minicircle with mutant araO2. Minicircle with mutations in both araI sites. Results: Wild-type: Half-time of dissociation ~100 min (50% conversion to unlooped form in 90 min, lanes 3-5). araO2 mutant: Loop broke in &lt;1 min, indicating a crucial role in loop maintenance (lanes 7 and 8). araI mutant: Half-time of loop breakage &lt;10 min, underscoring its role in loop stability. Conclusion: AraC can induce DNA looping at the ara operon in the absence of arabinose. Both araO2 and araI sites are vital for loop stability; mutations in either site destabilize the loop significantly, showcasing their roles in the AraC-mediated DNA looping mechanism. Spacing is Important AraC Binding to araO2 is Disrupted by Arabinose Binding &amp; Regulation of araPBAD P184; Figure 7.21 Experiment Setup: Objective: Understand the effect of arabinose on the AraC-induced DNA loop and elucidate the role of araI2 in AraC binding. Materials: Looped minicircles (404-bp supercoiled DNA with araO2 and araI sites). Arabinose. AraC protein. Methods: Electrophoresis to observe the influence of arabinose on loop stability. Methylation interference to study AraC contacts with araI sites in different states. Findings: Arabinose breaks the repression loop: Evidence: Disappearance of the looped DNA band upon adding arabinose before electrophoresis (refer to Figure 7.23). Reformation of broken loop: Conditions: Removal of arabinose allowed the broken loop to re-form, illustrating reversible control mediated by arabinose. AraC’s contact shifts from araO2 to araI2: Evidence: Methylation interference: AraC contacts araI1 but not araI2 in the looped state. Two araI1 bases were lightly methylated in looped DNA and heavily methylated in unlooped DNA, indicating crucial roles in looping. Mutation study: AraI2 mutations didn’t affect AraC binding in looped state but significantly influenced it in the unlooped state, highlighting its role in AraC binding post-loop breakage. Conclusion: Arabinose disrupts the AraC-induced DNA loop by altering AraC’s affinity for binding sites: it loses affinity for araO2 and gains affinity for araI2, a dynamic regulatory mechanism controlling the ara operon (depicted in Figure 7.21b and c). The role of araI2 is crucial in AraC binding in the unlooped state, facilitating the reformation of the loop upon arabinose removal. AraC autoregulates its Own Expression Molecular Biology; Weaver, Robert: Fifth edition Background: araO1’s function: Not involved in the repression of araBAD transcription. Location: Positioned to control the transcription of the araC gene (refer to Figure 7.24). Autoregulation Mechanism: Transcription Direction: The araC gene is transcribed leftward from the Pc promoter. Binding to araO1: As AraC levels increase, it binds to araO1. Inhibition of Transcription: The binding of AraC to araO1 inhibits further leftward transcription from Pc. Control of AraC Levels: The process prevents excessive accumulation of AraC, ensuring self-regulation of its synthesis levels. Conclusion: Autoregulation: The mechanism through which AraC controls its own synthesis by inhibiting transcription upon binding to araO1 is termed autoregulation. Regulatory Balance: This autoregulation helps maintain a balance in AraC levels, avoiding its overproduction and ensuring optimal functioning of the operon regulatory system.- Positive promoter elements Lactose operon promoter: -35 and -10 sequences are the two binding site of the CRP-cAMP. One of them are mutated, the binding still performed. But simultaneous mutation would decrease the expression level. CAP is a universal transcription promoter CAP is a sequence-specific DNA binding protein CAP responds to cAMP levels in the cell. it binds a dimer cAMP-CAP binding is required for high expression of the lac operon-- conserves the cells energy. TGTGA sequence So far, hundreds of genes have been discovered which are under the control of the CAP-cAMP complex. Among them are genes involved in cell division, carbon metabolism, flagellar synthesis (controlling the motility), cell energy, nitrogen utilization, iron uptake and drug resistance CAP recruitment Forma- tion of the closed promoter complex conversion of the closed promoter complex to the open promoter complex. P19 DNA binding doesn’t change so much, but the transcription activation is different. Eukaryol: homodimer Prokaryotic /heterodimers Class 1: far away from the gene Class 2: closer to the gene Kb creating close k2: transition close to the open Different promoter classes Utilize different protein regions. pre { background-color:#38393d; color: #5fd381; }","link":"/2023/08/31/LearnNotes/UIUC-AdMC-4/"},{"title":"Advanced Molecular &amp; Cell Biology 2","text":"Points for the lecture: Subunits of any complex typically have distinct activities The distinct functions of subunits are evident in the RNA polymerase complex, where each subunit specializes in a particular aspect of transcription. For instance, the α subunit is crucial for initiation and interaction with regulatory proteins. Sigma factors, in part, determine promoter specificity Sigma factors are essential for guiding the RNA polymerase to specific sets of genes, ensuring the right genes are expressed under certain conditions. Two modes of transcriptional termination in bacteria These are the Rho-independent and Rho-dependent mechanisms. Each has its unique sequence cues and processes to halt transcription. Transcription Initiation In Four Steps Forming the closed promoter complex This is the initial binding of the RNA polymerase to the promoter region without unwinding the DNA. Forming the open promoter complex Here, the DNA around the promoter region unwinds, providing a single-stranded template for transcription. Incorporating the first few nucleotides RNA polymerase begins the synthesis of the RNA strand. It’s a crucial step, ensuring the fidelity of the process. Promoter clearance After successful initiation, the RNA polymerase moves forward, leaving the promoter region, and enters the elongation phase of transcription. → Source $\\sigma$ Factor is Recycled After initiation, the sigma factor can dissociate from the RNA polymerase and be used again for another round of transcription initiation. This recycling process is efficient for the cell. It is discoverd in a very simply assay. After add the fresh core, it got more transcription products. Red curve: Only one round of chain initiation is possible at low ionic strength because (core) polymerase does not dissociate from DNA. Green curve: Fresh core polymerase added. (Products surge) Förster Resonance Energy Transfer (FRET) experiment: retain the core during the cycle. “FRET studies have been pivotal in understanding sigma factor dynamics during transcription. By employing FRET, the interaction between sigma factors and the core RNA polymerase during various stages of transcription was elucidated.” $\\sigma$ Can Remain with Elongating RNAP If he doesn’t release, it goes slower. By attach the accepter at the end of the gene, once doner from the factor attached the accepter and the light signal changed, which means $\\sigma$ factor stay with the DNA. © Eva Stejskalova Determing Mechanism(s) of Action aka, Biochemistry Run-Off Transcription Assay This assay is designed to assess how quickly RNA polymerase can transcribe a given DNA template. By analyzing the rate and extent of transcription, insights into the efficiency of the transcription process under various conditions can be obtained. Objective: To mutate a gene’s promoter and observe the effects of mutations on the accuracy and efficiency of transcription.Requirements: To check whether transcription is accurate, i.e., starts at the right place. To quantify how much of this accurate transcription has occurred. P103; Figure 5.31 Methodology: Preparation of DNA Fragment: Start with a DNA fragment containing the gene you want to transcribe. Restriction Enzyme Cutting: Cut the fragment with a restriction enzyme in the middle of the transcribed region. In Vitro Transcription: Transcribe the truncated gene fragment in vitro using labeled nucleotides, so the resulting transcript is labeled. Run-Off Mechanism: Since the gene has been cut in the middle, the RNA polymerase will reach the end and “run off”, giving the method its name. Measure Transcript Length: The length of the run-off transcript confirms the starting point of transcription based on the known location of the restriction site. Advantages: Simplicity: Compared to S1 mapping or primer extension, run-off transcription is simpler. Quantitative: It can serve as a quantitative method to measure the rate of in vitro transcription. Limitations: In Vitro Only: The method relies on in vitro transcription and cannot provide information about cellular transcript concentrations. Accuracy: It is effective only for genes that are accurately transcribed in vitro. Applications: After identifying the physiological transcription start site through other methods like S1 mapping or primer extension, run-off transcription can be used to quantify transcription rates in vitro. Summary: Run-off transcription is a simple, yet effective method for studying the efficiency and accuracy of transcription for a gene, especially in in vitro settings. It is particularly useful for quantitative analysis of transcription rates. Test the speed of the transcription Bound $\\sigma$ Factor Promotes RNAP Pausing Abortive Initiation Predominates Background: Until 1980, it was widely believed that transcription initiation was completed upon the formation of the first phosphodiester bond, connecting the first two nucleotides in the RNA chain. Breakthrough Study by Carpousis and Gralla: Experimental Setup: E. coli RNA polymerase DNA with a mutant E. coli lac promoter (lac UV5 promoter) Heparin (prevents reassociation between DNA and RNA polymerase) Labeled ATP (to label RNA products) Methodology: Incubated the polymerase, DNA, heparin, and labeled ATP. Ran gel electrophoresis on the products to measure their sizes. Key Findings:Presence of Small Oligonucleotides: They found small RNA fragments ranging from 2-6 nucleotides (nt) in length.Sequence Matching: The sequences of these small oligonucleotides matched the beginning of the expected transcript from the lac promoter.Many Oligonucleotides per Polymerase: When the amount of these oligonucleotides was compared to the number of RNA polymerases, there were many oligonucleotides per polymerase. P127; Figure 6.7 Implications: Abortive Transcripts: The polymerase was producing many small, abortive transcripts without leaving the promoter region. Complex Initiation Process: Transcription initiation is more complex than previously thought, involving a stage where multiple abortive transcripts are produced. Role of Heparin: Heparin in the assay prevented free RNA polymerase from reassociating with the DNA, confirming that the abortive transcripts were made by the same polymerase without it detaching from the DNA. Follow-up Research: Other researchers have corroborated these findings, even discovering abortive transcripts up to 9 or 10 nt in size. Summary: The study by Carpousis and Gralla showed that transcription initiation is a complex process involving the generation of multiple abortive transcripts. This groundbreaking work has significantly deepened our understanding of the transcription initiation process in E. coli. Electro Mobility Shift Assay (EMSA) P109; Figure 5.36 Background: Understanding DNA–protein interactions is crucial for various aspects of molecular biology, including gene regulation. Gel mobility shift assay, also known as electrophoretic mobility shift assay (EMSA), is a technique that allows for the visualization of these interactions. Principle: The basic idea is that a small, labeled DNA fragment will move through an electrophoretic gel much more slowly when it is bound to a protein compared to when it is unbound. Methodology: Preparation: A short, double-stranded DNA fragment is labeled. Binding: This labeled DNA is then mixed with the protein of interest. Electrophoresis: The DNA-protein complex is subjected to gel electrophoresis. Detection: The gel is exposed to autoradiography to visualize the labeled species. Key Findings: Naked DNA: Without any bound protein, the labeled DNA shows high mobility in the gel (Lane 1). DNA-Protein Complex: When the DNA is bound to a protein, its mobility through the gel decreases significantly (Lane 2). This is the basic “shift” that gives the assay its name. Supershift: When the DNA is bound to two proteins, its mobility decreases even further (Lane 3). This is termed a “supershift” and can involve either another DNA-binding protein, a protein that binds to the first protein, or an antibody specific to the first protein. Applications: Study of Protein-DNA Interactions: Allows researchers to understand which proteins can bind to a specific DNA sequence. Supershift Analysis: Useful in identifying secondary proteins or antibodies that can further bind to the DNA-protein complex. Quantitative Analysis: The degree of shift can also provide quantitative insights into the binding affinities. Summary: EMSA is a powerful and versatile technique for studying DNA–protein interactions. It allows not only the qualitative identification of interacting proteins but also offers clues about the binding dynamics through supershifts. Radioisotopically Labeled ATP T4 poly… to tag the DNA end and so, it could create radio-labeled Only $\\beta$’ Subunit of Core RNAP Binds All Promoters rifampicin actually blocks early elongation b-subunit from a rifampicin-resistant bacterium, the resulting polymerase was antibiotic-resistant. b-subunit came from an antibiotic-sensitive bacterium, the reconstituted enzyme was antibiotic-sensitive, $\\beta$ and $\\sigma$ Bind to ‘Open’ DNA Strands Detecting Protein:DNA Complexes by Crosslinking (Chromatin Immunoprecipitation (ChIP), Figure 5.39) The small 262-309 fragment of b9 is critical for stimulating s binding to the non-template DNA strand, and mutations within this fragment significantly interfere with the binding. P142; Figure 6.24 Fragment 1-550: This fragment of b9 induced binding between s and the non-template strand DNA. Smaller Fragments: All fragments could induce binding; fragment 260-550 worked only at low temperature. Critical Fragment 262-309: A small fragment with 48 amino acids significantly stimulated binding at room temperature. Mutations (R275, E295, A302): Known to interfere with s binding to promoters and caused significant interference in binding to the non-template strand in the -10 region. Strong Promoters Have Another Conserved DNA Element (UP element) © Dr. Tracy Nixon P143; Figure 6.26 DNase Footprinting DNase Footprinting: Uses DNase I to cut unprotected DNA regions. Dimethylsulfate (DMS) Footprinting: Uses DMS to methylate adenine bases in DNA. Hydroxyl Radical Footprinting: Uses hydroxyl radicals to cleave DNA. DNase Footprinting Steps: End-Label DNA: Only one strand is labeled per experiment. Protein Binding: The target protein is allowed to bind to the DNA. DNase I Treatment: Mild conditions used to ensure only one cut per DNA molecule on average. Protein Removal: The protein is removed to leave only the DNA. Gel Electrophoresis: DNA fragments are separated on a high-resolution gel. Control &amp; Multiple Concentrations: A control with DNA alone is included. Different protein concentrations are tested to observe gradual disappearance of bands. Outcome: The “footprint” region on the gel corresponds to the DNA region protected by the protein, revealing the protein’s binding site on the DNA. Significance: Helps in identifying the exact DNA regions or bases involved in binding with a specific protein. Strong Promoters Have Another Conserved DNA Element -35 box and -10 box. As long as the promoter binding site close to the gene. Higher Activity Requires ‘Up’stream Sequence and Carboxyl-terminus of $\\alpha$-subunit example: wilde-type-88 → create lots of DNA; -44: almost makes no DNA $\\alpha$-235 → never makes lot amount of DNA Result: $\\alpha$ initiation the recognition. DNA Footprinting the position which protein binds the DNA where never be replicated/transcript. As a result, there is a area of the gel lost and know ans the footprint. $\\alpha$ Subunit Binds Up Element Independently C-Terminal Domain of $\\alpha$ Subunit Can Bind the “Up” Element When Present Transcription Termination Termination is an essential step to ensure only the required genes are transcribed and to prepare RNA polymerase for another round of transcription. Both Rho-independent and Rho-dependent mechanisms have unique triggers and processes to ensure efficient termination. Only certain regions of a genome are transcribed Transcription complexes assemble at promoters and disassemble at the 3’ end of genes at specific termination sequences Two types of termination sequences: Rho-independent termination (Central dogma forward) Formation of an RNA Hairpin: thermodynamic favorite Intrinsic Termination Depends on Adenine Run Rho-dependent termination (got in the control) Rho binds to transcript at rho loading site and pause polymerase Hairpin forms; polymerase pauses; roh catches up. Rho helices releases transcript and causes termination Initiation or Termination can be Used for Regulation Significant: In the microbes, a single operon usually activate a serious of protein for a pathway. But we usually only need apart of the genes as a result, the termination study is very important in microbe engineering Housekeeping vs. Regulated “Housekeeping genes are essential for the day-to-day functions of the cell and are continuously transcribed. On the other hand, regulated genes are transcribed only under specific conditions. The cell uses various transcription factors and sigma factors to control the expression of these genes.” Expression of housekeeping genes is constitutive (essentially) Housekeeping genes have strong promoters and are efficiently and nearly continuously transcribed *housekeeping genes whose products are required at low levels have weaker promoters Regulated genes are expressed at different levels under different conditions using specific operators/response elements within each promoter Sigma Factor Directed Transcription Programs “E. coli, a model bacterium, utilizes different sigma factors to control the transcription of various sets of genes. Depending on the environmental conditions, E. coli can switch between these sigma factors to ensure the appropriate genes are being expressed.” Bacterial Gene Regulators E. coli can choose between 7 sigma factors and about 350 transcription factors to fine tune its transcriptional output An Rev Micro Vol. 57: 441-466 T. M. Gruber Sigma subunit Type of gene controlled # of genes controlled RpoD $\\sigma^{70}$ Growth/housekeeping ~1000 RpoN $\\sigma^{54}$ N2; stress response ~15 RpoS Stationary phase, virulence ~100 RpoH $\\sigma^{32}$ Heat shock ~40 RpoF Flagella-chemotaxis ~40 RpoE ? ~5 FecI Ferric citrate transport ~5 [R]poD: means find by gene screening [P]…: Discovered by Chemical way Stress: make very unique proteins for survival Different sigma, different RNA (may other sigmas), Different way (final products) Sigma Factors Enable Large Changes in Gene Programs Directing Simple and Cascade Responses Sigma Factor Regulation “Sigma factors are regulated at multiple levels to ensure appropriate cellular responses. For instance, the sigma factor σ32 is a heat-shock protein. Under normal conditions, it’s unstable and degraded quickly. However, under heat-shock conditions, it’s stabilized, allowing the cell to respond to the stress.” $\\sigma ^{32}$ is the first $\\sigma$ factor bing studied. $\\sigma ^{32}$ Controls Expression of the Proteins that Control It (a.k.a. Feedback loop) $\\sigma ^{32}$ Is Continuously Produced but Rapidly Degraded $\\sigma ^{32}$ Regulation is a Balanced Sensor HSPs Reactivate $\\sigma ^{70}$ During Recovery !!! ? what happened between $\\sigma ^{32}$ and $\\sigma ^{70}$? How cell make the choice? - $\\sigma ^{32}$ is a heat-shock protein. It would degreedated without heat-shock. Heat-shock genes stabilized the $\\sigma ^{32}$. In this case, the $\\sigma ^{32}$ could win the competition which $\\sigma ^{70}$ DnaK, DnaJ, and GrpE are heat-shock proteins work to protect the $\\sigma ^{32}$. pre { background-color:#38393d; color: #5fd381; }","link":"/2023/08/23/LearnNotes/UIUC-AdMC-2/"},{"title":"Molecule and Cellular Biology 3","text":"Reading for this week: Book Molecular Biology Chapters 7.1, 7.2 Review: Transcription activation by catabolite activator protein (CAP). Busby, S. and Ebright, R.H. J Mol Biol. 1999 Oct 22;293(2):199-213. Bacterial nucleoid-associated proteins, nucleoid structure and gene expression. Dillon, S.C. and Dorman C.J. Nat Rev Microbiol. 2010 Mar;8(3):185-95. Journal Club Paper (to be presented the following week): A phage-encoded nucleoid associated protein compacts both host and phage DNA and derepresses H-NS silencing. Son B, Patterson-West J, Arroyo-Mendoza M, Ramachandran R, Iben JR, Zhu J, Rao V, Dimitriadis EK, Hinton DM. Nucleic Acids Res. 2021 doi: 10.1093/nar/gkab678. Points for the lecture: Transcription can be actively regulated Small molecules can control gene programs Operons help balance protein expression in a pathway co-regulate as unite Protein allostery Many level, 1. small molecular, 2. DNA (Bind something to make conformation change.) Transcription factors can bend DNA Role of Regulatory Proteins in Transcription Initiation Regulatory proteins bind to specific DNA sequences (operator/response element) and control initiation of transcription Repressors - regulatory proteins that prevent transcription of a negatively regulated gene *negatively regulated genes can only be transcribed in the absence of the repressor Activators - regulatory proteins that activate transcription of a positively regulated gene Repressors and Activators are often allosteric proteins modified by ligand binding Agonist - positively acting ligand Antagonist - negatively acting ligand Activator Strategies for Transcriptional Regulation Ligand binding triggers promoter association and RNA is produced (Trigger the initiation) Ligand binding triggers promoter dissociation and RNA is not produced (Stop the transcription) THe contact is so much and some of the mechanism are still not figured out. Repressor Strategies for Transcriptional Regulation Ligand binding triggers promoter dissociation and RNA is produced Ligand binding triggers promoter association and RNA is not produced Transcription Factors Bind Operators (bacteria)/Response Elements (eukaryotes) Eu: Inhancers, depends on different regulation gene, far away from the genes. Ba: almost all close to the gene !!! How do you find an Operator/Response Element? - Operators - Many TFs bind inverted repeats as dimers - More interactions = greater affinity - Enhancer - Promoter ‘Bashing’ lacZ could be a report aod transcription reporter and change the color of the cell in this assay. - Linker-scanner Mutagenesis to Refine Position of Promoter Proximal Elements (after the Promoter ‘Bashing’) peron Bacteria and viruses often express functionally operative genes from a single promoter to help insure uniform expression DNA order: Activator binding site promoter, Repressor binding sit (Operator) Example: Lactose (Lac) Operon Lactose permease (Lacy) B-Galactosidase (LacZ) Thiogalactoside transacetylase (LacA) !!! What about the Lactose operon: The lac operon in E. coli is one of the most well-studied systems for gene regulation. This operon contains genes for enzymes required for the metabolism of lactose, a disaccharide sugar. The operon consists of three genes: - **lacZ**: Codes for \\(\\beta\\)-galactosidase, which hydrolyzes lactose into glucose and galactose. - **lacY**: Codes for galactoside permease, a transport protein that facilitates the entry of lactose into the cell. - **lacA**: Codes for galactoside transacetylase, whose function is not entirely clear. These genes are transcribed into a single polycistronic mRNA, meaning that they are expressed together. This allows for coordinated control of these functionally related genes. - **Negative Control: The Brake** In the absence of lactose, a protein called the lac repressor binds to the operator region of the operon, blocking RNA polymerase and thus preventing transcription. This is a form of negative control; it keeps the operon turned off when lactose is not present, which is efficient for the cell. - **Positive Control: The Accelerator** The lac operon also has a system for positive control, mediated by an activator protein that responds to glucose levels in the cell. This activator is cAMP-CAP (cAMP Receptor Protein). When glucose levels are low, cAMP levels are high, allowing CAP to bind and enhance the transcription of the lac operon. - **Diauxic Growth: Switching from Glucose to Lactose** When E. coli is grown in a medium containing both glucose and lactose, it exhibits diauxic growth. The bacteria consume glucose first and only switch to lactose metabolism once glucose is depleted. This switch involves a lag phase where the lac operon is activated, allowing the cells to make the enzymes needed for lactose metabolism. - Advantages of Dual Control 1. **Economic Efficiency**: Negative control ensures that the enzymes for lactose metabolism are not produced when lactose is not present. This is energy-efficient. 2. **Resource Prioritization**: Positive control ensures that even if lactose is present, the lac operon will not be fully activated if glucose is also available. This allows E. coli to prioritize the easier-to-metabolize glucose. In summary, the lac operon is a sophisticated system that allows E. coli to adapt to changing nutritional conditions efficiently, ensuring that it utilizes available resources in a manner that is both effective and economical. The Operon Model (History) A landmark in the history of Molecular Biology was the proposal of the operon model of genetic regulation by François Jacob and Jacques Monod in 1961. The core of the model was that the level of proteins in cells was controlled at a genetic level. The theory also predicted the existence of mRNA-an unstable intermediate between the genome and the expressed protein. Before this work the prevailing model was called the instruction hypothesis that stated that all proteins were present in a cell, but that in the absence of an inducer they were not properly folded and were inactive. Jacob and Monod were awarded the Nobel Prize in 1965 for their work on characterising genes involved in lactose utilization Differential Growth based on Carbon Source Glucose is more rapidly used than lactose, so cells grow faster on glucose. When both present growth is bi- phasic, which is called a diauxic shift. When you mix up them, the bacteria make the choice. They know when and how to switch the strategies. Cell numberBiological Purpose of Lac Operon LacZ gene: encodes $\\beta$ -galactosidase enzyme that breaks down disaccharide lactose into glucose and galactose to be used as source of energy for cell. LacY gene: encodes $\\beta$ -galactoside permease, a membrane-bound protein that helps transport lactose across the membrane of cell. LacA gene: encodes  -galactoside transacetylase enzyme involved in catabolism of disaccharide (exact role is less clear) Genetic Screen Based on Enzymatic Activity (Blue: lacZ activity) 5-bromo-4-chloro-3-indolyl-$\\beta$D-galactoside Natural &amp; Synthetic Small Molecules IPTG is a non-metabolized analog of allolactose that induces Lac operon but is not broken down by enzymes. Lactose is a disaccharide composed of galactose and glucose linked in a  configuration (1-&gt;4). -galactosidase, the product of the lacZ gene, cleaves this disaccharide into galactose and glucose which can then both be metabolized by the cell. E. coli does not always make this enzyme. It is an inducible enzyme which is synthesized only when lactose is present and when glucose is absent from the growth media. Glucose is one of the few sugars which E. coli will use preferentially over all other sugars because it can be directly routed into glycolysis after phosphorylation without any other modifications. Merodiploids Helped to Unravel the Role of Genes in the lac operon Studying the Lac Operon Isolation and analysis of mutants defective in Lac operon function allowed Jacob and Monod to formulate an accurate Lac operon model PRIOR to the advent of molecular cloning e.g., wild type E. coli form colonies that are blue on IPTG/ XGAL plates and white on XGAL plates Mutants that form white colonies on IPTG/XGAL plates can be isolated * this phenotype is often due to a mutation in a Lac structural gene * the number and location of Lac structural genes can be identified by complementation analysis Mutants that form blue colonies on XGAL (no IPTG) can be isolated * this phenotype is often due to a mutation in either the Lac repressor gene or Lac operator * Lac repressor versus operator mutations can be distinguished by cis-trans test F’ plasmids carrying different pieces of E. coli chromosome can be isolated in HFR strains, allowing the creation of partial diploids. F’ plasmid can carry wild type or mutant versions of Lac operon between strains Complementation Analysis and Cis-Trans Tests Phenotypes and Genotypes of Mutants Defective in Lac Operon Function Lower case letter with superscript asterisk indicates location of mutation In practice, you would not know the location; you would only know the phenotypes (blue or white color on XGAL/IPTG or XGAL) of the haploid (or homozygous diploid) and the heterozygous diploid e.g., The diploid resulting from conjugating mutants 2 and 3 give a normal phenotype, consistent with mutations 1 and 2 being recessive and located in different structural genes (i.e., in the diploid there is at least one normal copy of each gene and a correspondingly normal protein) Mutaion -&gt; got the different phynotype -&gt; trans is protine, cis is DNA. -&gt; Bind the two mutation: Make the crosses and repeat the phenotype. They don’t know what are they yet. The name is made by them and the mechanim are solved years later after the sequencing techs. ‘Trans’ and ‘Cis’ In genetic terminology: The lac repressor is a trans-acting element trans = across The operator is a cis-acting element cis=near The lac repressor is a sequence-specific DNA-binding protein that Negatively regulates expression of the lac operon structural genes. Trans Complementation Merodiploid: lacZ - / F’ lacY - lacI lacO lacZ lacY lacA lacI lacO lacZ lacY lacA ‘Simple’ Mechanism for Gene Regulation by Lac Repressor P170; Figure 7.3 Negative Control Operon naturally “on.” Turned “off” by repressor protein from lacI gene. Allosteric Regulation Repressor is allosteric; its shape changes. Inducer is allolactose, changes repressor shape. Changed repressor can’t bind to operator, operon “on.” Basal Level &amp; Initial Activation Repression “leaky,” small amounts of β-galactosidase and permease always present. Enough for initial lactose uptake and allolactose creation. Positive Feedback (Snowball Effect) Derepression leads to more β-galactosidase and permease. More lactose uptake and allolactose creation. Operon stays “on” if lactose present and glucose absent. Summary Negative control via repressor. Allosteric regulation via allolactose. Initial activation via “leaky” repression. Positive feedback maintains activation. Lactose Levels “Tune” the Response In the absence of lactose there are only 1-5 molecules of each of the lacZYA proteins in the cell. Following induction, up to 5000 molecules of - galactosidase can accumulate within minutes. As lactose is cleaved and used as a carbon source for growth the lactose levels drop. Eventually free repressor molecules will accumulate once more and the lac operon will be switched off. Impact of Inducer on Repressor DNA binding P174; Figure 7.6 Challenges Faced The lac repressor is in very low concentration in the cell. No easy assay to identify the protein was available. Strategies Used Used a mutant E. coli strain with repressor mutation (lacI t). This mutation made the repressor bind to IPTG (isopropylthiogalactoside) more tightly. This allowed for detection of the repressor in very impure extracts. Purification Gilbert and Müller-Hill were able to purify the protein because they could now detect it. Operator-Binding Studies Conducted by Melvin Cohn and colleagues. Used nitrocellulose filter-binding assay. Results Typical saturation curve observed for repressor–operator binding in the absence of inducer. No binding observed in the presence of the synthetic inducer, IPTG. Summary Gilbert and Müller-Hill successfully purified the lac repressor using a mutant strain. Cohn’s team demonstrated that inducer (IPTG) blocks repressor–operator binding. Protein Allostery (Induced Conformational Changes) Lac Repressor Does Not Prevent RNAP Binding Unknow sours P175; Figure 7.8 Traditional Assumption: Assumed that lac repressor denies RNA polymerase access to the promoter. Contradictory Evidence Pastan’s 1971 Experiment: Showed that RNA polymerase could bind to the lac promoter even in the presence of repressor. Straney and Crothers (1987): Showed that polymerase and repressor can bind together to the lac promoter. Alternative Explanations Straney and Crothers: Suggested repressor blocks the formation of an open promoter complex. Krummel and Chamberlin: Proposed that repressor blocks the transition from the initial transcribing complex to the elongation state, trapping the polymerase in a nonproductive state. Supporting Evidence Jookyung Lee and Alex Goldfarb’s Experiment Used a run-off transcription assay. Found that RNA polymerase is engaged on the DNA template even in the presence of repressor. Noted the appearance of shortened abortive transcripts (about 6 nt long) in the presence of repressor, suggesting repressor may lock the polymerase into a nonproductive state. Summary Repressor doesn’t seem to block RNA polymerase from accessing the lac promoter. Evidence suggests that the repressor may lock the polymerase into a nonproductive state, limiting it to making only abortive transcripts. What is the Mechanism of Repression? Influence of Regulators on RNAP:Promoter Complexes $$ R + P \\underset{K_ B}{\\rightleftharpoons} RP_ c \\underset{k_ 2}{\\rightarrow} RP_ o $$ R is RNA polymerase P is the promoter RPc is the closed promoter complex RPo is the open promoter complex. KB Definition: Indicates RNA polymerase’s binding affinity to a promoter. Influenced by: Repressors or activators affecting RNA polymerase binding. k2 Definition: Represents the rate-limiting step in forming an open complex; its physical meaning can vary between promoters. Influenced by: Repressors or activators affecting RNA polymerase-promoter interactions. Insights Understanding KB and k2 helps in deciphering the effects of auxiliary proteins on RNA polymerase-promoter dynamics. It can hint at how the binding affinity is influenced and the complexities involved in open complex formation. Impact of Repressor on RNAP At the lacUV5 promoter, the values of KB and k2 in the presence or absence of repressor are: Condition KB (M⁻¹) k2 (s⁻¹) No repressor 1.9 x 10⁷ M⁻¹ 6.7 x 10⁻² s⁻¹ With repressor 2.5 x 10⁹ M⁻¹ 2.5 x 10⁻² s⁻¹ Data from Straney &amp; Crothers (1987) Cell 51: 699-707. The UV5 mutation changes the -10 region of the lacP promoter so that it more closely resembles the consensus -10 sequence. It is a stronger promoter than lacP. These data indicate that the lactose repressor INCREASES the binding of RNAP 130-fold; suggest that repressor might be considered a activator. Repressor DECREASES k2 3-fold. Repressor Dimers Bind on Same Face of DNA Unknown By insert the DNA fragment between the operator and UV5, the transcription efficiency is changed. Key Findings: Repression maxima: Occur at distances integral to the DNA double helix pitch (59.5, 70.5, 81.5, 92.5, 115.5, 150.5 nm). Wild-type lac operon: Has a 92.5 nm spacer distance between operators. Gal operon: Features a 115.5 nm spacer distance between operators. Longer distances: Display smaller effects, with distances over 400 bp having little to no impact. Non-integral multiples: No repression observed, aligning with the DNA looping model’s predictions. Implications: DNA Looping Model: The observations support a model where interaction is easy when proteins are bound on the same DNA face without needing torsional changes. DNA Pitch: Estimated to be 11.1 bp or 3.4 nm in vivo, based on repression maxima data. Limitations: Distances under 59.5 nm could not be measured due to interference with the promoter. Repressor Binds as a Tetramer DNA Bending Enables Proteins to Bind Cooperatively to Separated Sites Molecular Biology; Weaver, Robert: Fifth edition bending BEND FORMATION REQUIRES THAT BOTH PROTEINS BIND TO THE SAME FACE OF THE DNA No bending PROTEINS BOUND TO SITES ON OPPOSITE SIDES OF DNA HELIX CANNOT INTERACT Lac Tetramer Stabilizes Bent DNA Detected by EMSA Gel electrophosphate Promoter Contains 3 Operator Sites P176; Figure 7.10 P176; Figure 7.11 How to Resolve if Operator 2 or 3 is preferred? Chromatin Immunoprecipitation (ChIP) Assay Determines the relative DNA Occupancy of a Target Protein at a Particular Site in vivo ChIP-Seq can Determine Genome-wide Binding Site Useage of a Target Protein Operator 1 + Operator 2: bind different place of the DNA and bind the DNA. Then Promoter is loaded much easier. Lac Repressor Binding to be next: Multiple Regulators pre { background-color:#38393d; color: #5fd381; }","link":"/2023/08/29/LearnNotes/UIUC-AdMC-3/"},{"title":"Molecule and Cellular Biology 6","text":"Points for the lecture: λ life cycle is regulated through molecular events Events are ‘tuned’ for propagation of the phage Competition between factors dictates activity state λ Phage How λ Gets In Components and Structure Genome: 48,502 bp of double-stranded DNA (dsDNA). Chromosome in the capsid: Structure: Linear dsDNA. Special Feature: 12 nt single-stranded DNA (ssDNA) cohesive termini. Capsid: Head: Comprises products of B, C, Nu3, D, and E genes. Tail: Formed by products of J and H genes. Infection Process Attachment: The phage attaches to the host cell’s maltose receptor, a product of the E. coli lamB gene. Injection: Injects its linear dsDNA chromosome into the host cell. Circularization: Mechanism: Annealing occurs between complementary 3’ overhanging cos sites. Outcome: Linear dsDNA transforms into a circular form, facilitating the integration into the host’s genome. Notes The cohesive termini and the specific structure of the capsid play crucial roles in the bacteriophage’s ability to infect and integrate into the host genome. Understanding the precise infection mechanism can offer insights into bacterial immunity and potential applications in bacterial genetics research. Life Choice Depends on Genetic Switch 1. Lytic Mode Initial Phase: DNA Entry: Phage DNA enters the host cell. Transcription: Host RNA polymerase transcribes phage DNA. Translation: Phage mRNAs are translated to produce phage proteins. Replication Phase: DNA Replication: Phage DNA replicates. Assembly: New phages are assembled from DNA and protein components. Final Phase: Lysis: The host cell undergoes lysis, releasing progeny phages. Result: The host cell is killed. 2. Lysogenic Mode Initial Phase: DNA Entry: Phage DNA enters the cell. Early Gene Expression: Early genes are transcribed and translated. Repressor Role: λ Repressor (CI) Appearance: A 27-kD phage protein appears. Binding: CI binds to two phage operator regions. Effect: It shuts down transcription of all phage genes except for cI (gene coding for λ repressor). Integration Phase: Integration: Phage DNA integrates into the host genome. Lysogen Formation: The host with integrated phage DNA is termed a lysogen. Prophage: The integrated DNA is referred to as a prophage. Maintenance Phase: Reproduction: The phage DNA replicates alongside host DNA. Advantage: Allows the phage to multiply without creating new phage particles, giving it a “free ride.” Induction Phase (Conditional): Trigger: Exposure to mutagenic chemicals or radiation. Effect: The lysogenic cycle can be broken, shifting the phage into the lytic phase. Notes λ Phage Characteristics: It is a temperate phage, meaning it can follow both lytic and lysogenic paths. Versatility: λ phage showcases more versatility compared to virulent phages like T2, T4, T7, and SPO1, which always follow the lytic path. Lysogenic Stability: The lysogenic state can be stable indefinitely, beneficial for the phage as it ensures its survival and replication without killing the host. λ Genome is Organized By Function © bx.psu.edu HEAD &amp; TAIL Region (left side of the RECOMBINATION Region) Structure: Encodes for the structural proteins constituting the phage’s capsid. Terminase Enzyme: Required for processing rolling circle multimers into unit genome-length pieces during DNA packaging. RECOMBINATION Region Genes: Int: Necessary for the integration of the phage into the bacterial host chromosome during lysogenic growth. Xis: Facilitates the excision of the phage from the host chromosome during induction. Others: A variety of other genes facilitating integration and excision processes. REGULATION Region Immunity Region: Involved in the phage’s self-immunity processes. Switch Control: Houses genes controlling the switch between lysogenic and lytic growth. Q Antiterminator Protein: Part of the regulatory mechanism. Anti-Q RNA: Works alongside the Q protein in regulation. PR’: Constitutes a secondary regulation region, working in conjunction with Q protein and Anti-Q RNA. REPLICATION Region Genes: O: Replication protein gene. P: Another gene involved in replication. Origin of Replication: The starting point for the DNA replication process. LYSIS Region Gene Count: Contains four genes. Function: The genes in this region are generally involved in the lysis of the host cell, facilitating the release of new phage particles. Note Different Regions: Each region in the bacteriophage genome is designated for a different function, playing a crucial role in the phage’s life cycle, either helping in its replication, regulation of its life cycle, or in the processes leading to the integration into or excision from the host genome. λ Inserts into the Host Genome by Recombination λ has 7 Promoters PR expresses the replication genes as well as the anti-repressor, Cro, the transcriptional activator cII, and the anti-terminator, Q protein. PL expresses the recombination genes as well as the anti-terminator, N, and the cIII protein. PR’ expresses the lysis proteins, and the head and tail proteins. PRE expresses the repressor gene, cI, to establish lysogeny. PRM expresses the repressor gene, cI, to maintain lysogeny. PI expresses the int gene to synthesize the Integrase protein. PaQ drives synthesis of a short anti-sense RNA which blocks translation of Q gene mRNA. Protein Expression is Stage Dependent Event l Gene Expressed Comment Initial infection Cro, N Only N and Cro are synthesized until the decision point is reached Lytic pathway Cro, N, Q, late genes Cro predominates at operators, N and Q are antiterminators Lysogenic pathway cI, cII, cIII, int cII and cIII collaborate to establish cI synthesis; after genome integration, only cI is expressed during maintenance of lysogeny. Consequences of Early Gene Expression Cro repressor mRNA made from PR and translated. N antiterminator mRNA made from PL and translated. Allows transcription and translation of cII and cIII. cII/cIII proteins activate PRE, causing transcription of cI Concentrations of cI and Cro proteins build up Initial Events Molecular Decision-Making: Choice between Lysis &amp; Lysogeny Determined by relative concentrations of cI and Cro, which act oppositely on PRM the promoter for Repressor Maintenance PRM requires cI protein, therefore not active just after infection. Inhibited by Cro. Cro lower affinity for PRM but is made earlier. Cro binds same operator sites as cI, but not as efficiently or stably. At low levels, will slow down, but not stop expression of N , cIII (PL) or cII, P, Q (PR). At high levels, cII and cIII are prevented from being transcribed, so no cI. λ Immunity Region © genes.atspace.org Lysogeny Unknown N is an Anti-Terminator Molecular Biology; Weaver, Robert: Fifth edition; P206 P207; Figure 8.14 Physical and Functional Layout Location: Situated downstream of the PL promoter and its respective operator, OL. Nut Site: Contains specific sequences, box A and box B, which play crucial roles in the functioning of the N protein. Functionality in the Absence of N Protein Transcription Start: Commences at the PL promoter. Transcription Termination: Occurs at a terminator site situated downstream of the N gene. The RNA polymerase releases the N mRNA here. Functionality in the Presence of N Protein N Protein Synthesis: Once the N gene has been transcribed, the N protein materializes. Binding to Nut Site: The N protein binds to the nut site on the transcript. Alteration of RNA Polymerase: The N protein collaborates with a complex of host proteins, altering the RNA polymerase to overlook the terminator site and proceed with transcription into the delayed early genes. Involvement of Host Proteins Nus Proteins: These include NusA, NusB, and NusG, which have roles in both the phage and host cell processes. Ribosomal S10 Protein: Participates in protein synthesis in the host cell. Antitermination: N and NusA can facilitate antitermination in close proximity to the nut site, forming a short-range antitermination complex with the RNA polymerase. Processive Antitermination Long-Range Effect: In natural circumstances, antitermination occurs hundreds of base pairs downstream of nut sites, requiring the involvement of all Nus proteins and S10 for stability. Persistent Complex: A stable complex is formed, continuing until reaching the terminator. Nut Site Interaction RNA Interaction: Rather than interacting with the nut site itself, the complex interacts with its transcript. RNA-binding Domain: The region in N essential for nut recognition features an arginine-rich domain akin to RNA-binding domains. Protection from RNase: A full assembly of the five proteins in the complex shields both boxes A and B from RNase attacks. RNA Loop Formation Sustained Signal: The RNA between the nut site transcript and the RNA polymerase forms a loop, maintaining the association of N with both, thus providing a continuous signal to the polymerase until it reaches the terminator. Evidence: Experiments have indicated that alterations in the RNA polymerase b-subunit gene can obstruct N-mediated antitermination, suggesting a potential association between the RNA polymerase, N, and the nut site transcript during transcription. Conclusion The gene N encodes for the N protein which plays a pivotal role in the antitermination process during the phage lifecycle. It acts by binding to the nut site of the transcript and altering RNA polymerase activity, facilitating transcription beyond the terminator site. This mechanism leverages both short-range and processive antitermination, guided by a complex interplay of different proteins and the intricate structure of the nut site and its transcript. The stability and sustained activity of this system are central to its function, maintaining a persistent signal through RNA loop formations that guide the RNA polymerase over substantial distances. N Prevents Stem-loop Formation P208; Figure 8.15 Background Initial Hypothesis: N restricts the RNA polymerase pausing vital for termination. Research by Gusarov and Nudler (2001): Contradicted the initial hypothesis, highlighting that N doesn’t significantly affect pausing but instead influences the formation of the terminator hairpin. Mechanism N Binding to RNA: N binds to the portion of RNA supposed to form the upstream part of the terminator hairpin, thereby slowing down its formation. Preventing Hairpin Formation: Without the hairpin structure, the termination process cannot proceed, a mechanism somewhat similar to overriding transcription attenuation seen in the trp operon. Role of NusA Interaction with Elongation Complex (EC): As EC synthesizes a string of U’s, it pauses after adding the seventh nucleotide, positioning the potential upstream part of the hairpin to bind to the RNA polymerase’s upstream binding site (UBS). Time Constraint: The pause lasts for about 2 seconds, within which the hairpin should form to ensure termination; otherwise, the polymerase progresses without terminating. Stimulation of Termination: NusA weakens the connection between the potential upstream part of the hairpin and the UBS, encouraging quick hairpin formation and subsequently promoting termination. Comprehensive Model (Gusarov and Nudler, 2001) Dual Binding: Both N and NusA bind to the RNA segment meant to form the upstream part of the hairpin. Blocking Hairpin Formation: By binding to the RNA segment, N prevents the quick formation of the hairpin. NusA’s Role: While connected to N, NusA also associates with the RNA segment, further slowing down the hairpin formation. Outcome: Due to the hindered hairpin formation, RNA polymerase moves forward without engaging in the termination process. Conclusion N prevents termination not by limiting RNA polymerase pausing but by binding to the RNA segment that is crucial for forming the terminator hairpin, consequently slowing down its formation. NusA plays a dual role, both facilitating and slowing down hairpin formation depending on its interactions with either the RNA or N. The intricate interaction between N, NusA, and the RNA orchestrates whether the termination proceeds or not. PL source: wiki In addition to N, the early transcript of PL codes for: cIII required to protect the activator protein, cII Xis normally required for excision of a prophage Int normally required for integration of a prophage. Background Context: Early lytic growth phase of bacteriophages. Concerned Molecules: Xis and Int proteins. Primary Regulator: N protein. Mechanism Role of N Protein: Transcriptional Impact: Influences RNA polymerase to bypass the tI transcription terminator and continue transcription through the sib region. Attachment: Remains attached to the ternary transcription complex. Sib Region: Characteristic: Houses the signal for an RNase III processing site. Effect on mRNA: Transcripts passing through this region undergo structural changes to form a hairpin configuration. Action of RNase III: Recognition: Identifies the hairpin structure in the transcripts. Cleavage: Splits the transcript at the identified site, leaving free 3’ ends. Exonuclease Activity: Degradation: Enzymes present in the cell degrade the free 3’ ends further. Impact on Xis and Int: The coding regions for Xis and Int largely get destroyed before translation can occur, reducing their expression significantly. Retroregulation Definition: A regulatory mechanism where the stability and translatability of mRNA are controlled post-transcriptionally, affecting the subsequent expression of certain genes (in this case, Xis and Int). Outcome in the Context: Ensures limited expression of Xis and Int during the early lytic growth phase, maintaining control over the developmental pathway of the bacteriophage through intricate regulation at the RNA level. Conclusion Efficiency in Regulation: Retroregulation efficiently controls the expression of Xis and Int proteins during early lytic growth through a series of RNA modifications and processing, preventing their significant expression and translation during this phase. Regulatory Network: The process involves a network of actions including the N protein’s influence on RNA polymerase, hairpin formation guided by the sib region signal, RNase III-mediated cleavage, and exonuclease-induced degradation, demonstrating a tight regulatory mechanism at work during bacteriophage development. cIII Inhibits Proteolysis of cII cII half-life alone is &lt; 1min but with cIII it is ~ 5 min pre { background-color:#38393d; color: #5fd381; }","link":"/2023/09/07/LearnNotes/UIUC-AdMC-6/"},{"title":"Antibody 12&#x2F;23 rule","text":"How Does Antibody Fragments Jointed Together? We all know that antibodies are composed of V, D, and J segments, which originate from different locations on the chromosome. But how are they connected together after post-transcriptional modification? The 12/23 rule is the fundamental mechanism that ensures proper recombination of these segments. The V region, or V domain, of an immunoglobulin heavy or light chain is encoded by more than one gene segment. For the light chain, the V domain is encoded by two separate DNA segments. The first segment encodes the first 95–101 amino acids of the light chain and is termed a V gene segment because it encodes most of the V domain. The second segment encodes the remainder of the V domain (up to 13 amino acids) and is termed a joining or J gene segment[1]. What Is 12/23 Rule Video tutorial: Daniel Levy; 2013. VDJ Gene Recombination The 12/23 rule is a principle in V(D)J recombination, a process crucial for generating the diversity of antibodies and T-cell receptors. It states that recombination can only occur between gene segments flanked by recombination signal sequences (RSS) with spacers of 12 base pairs (bp) and 23 bp. This ensures proper alignment and prevents inappropriate recombination events, maintaining the integrity and functionality of the immune system’s response. © Charles A. Janeway This image illustrates the 12/23 rule in the context of V(D)J recombination. Recombination Signal Sequences (RSS): Heptamer: A conserved sequence of 7 base pairs. Nonamer: A conserved sequence of 9 base pairs. Spacer: The region between the heptamer and nonamer, either 12 or 23 base pairs long. V(D)J Recombination Process: Segments: V (Variable), D (Diversity), and J (Joining) segments. Rule Application: The 12/23 rule ensures that only segments with RSS of different spacers (12 and 23 bp) recombine, facilitating the correct assembly of these segments. The image visually represents how the rule guides the alignment and recombination of V, D, and J gene segments, which is essential for generating the diversity of antibodies and T-cell receptors. How It Worked The heptamer and nonamer is the recombination signal sequences (RSSs). The (RAG1-RAG2)2 endonuclease complex (RAG) specifically recognizes and cleaves a pair of RSSs[2] © Ru H[2:1] How Does It Applied IgDetective IgDetective, published by Vikram Sirupurapu and Yana Safonova[3], is a tool for detecting and naming antibodies based on the 12/23 rule. This tool leverages the stringent application of the 12/23 rule among mammals, making it suitable primarily for mammalian species. Test: not suitable for birds like chicken williamdlees-Digger This is another open source tool developed by William D. Lees[4], aimed at annotating the positions of V/D/J genes on newly assembled genomes. According to the results shown in the documentation, it has very high accuracy. Prerequisite: a set of known core coding region allele sequences Position-weighted matrices Some technic details worthy to know: The search for V-sequences uses the parameters gapopen 5, gapextend 5, penalty -1, word_size 11. D and J searches, word_size is reduced to 7 to reflect the shorter sequences D sequences the evalue is set to 100 rather than the default of 10 to widen the search. How it find the heptamers and nonamers: Type Functionality criteria V RSS nonamer and heptamer pass PWM thresholds, and match canonical consensus, if defined.L-PART1 and L-PART2 pass PWM thresholds and splice to form a coding sequence with no STOP-CODONs that is in-frame with the V sequence.V-REGION is in-frame and has first and second cysteines at the correct positions in the IMGT alignment.No STOP-CODONs are present in the V-REGION before the second cysteine. D RSS nonamers and heptamers match canonical consensus, if defined. J RSS nonamer and heptamer pass PWM thresholds, and match canonical consensus, if defined.The J-motif is found at the expected position relative to the end of the J sequence.The donor splice is found at the expected position, given the length of the matched sequence. Limitation: It only supports IMGT well-annotated species because it relies on germline annotation from the IMGT database. Merits: Easy used and to be understood (write by python). © William D. Leeszs extract_refs -L IGH &quot;Gallus gallus&quot;fix_macaque_gaps Gallus_gallus_IGHV_gapped.fasta \\ Gallus_gallus_IGHV_gapped_fixed.fasta IGHcat Gallus_gallus_IGHV.fasta Gallus_gallus_IGHD.fasta Gallus_gallus_IGHJ.fasta \\ &gt; Gallus_gallus_IGHVDJ.fastaparse_imgt_annotations --save_sequence IMGT000014.fasta \\ &quot;https://www.imgt.org/ligmdb/view.action?format=IMGT&amp;id=IMGT000014&quot; \\ IMGT000014_genes.csv IGHcat IMGT000014.fasta &gt; Mmul_051212.fastamkdir motifscd motifsparse_imgt_annotations \\ &quot;https://www.imgt.org/ligmdb/view?format=IMGT&amp;id=IMGT000014&quot; \\ IMGT000014_genes.csv IGHcalc_motifs IGH IMGT000014_genes.csvcd ..makeblastdb -in Gallus_gallus_IGHV.fasta -dbtype nuclmakeblastdb -in Gallus_gallus_IGHD.fasta -dbtype nuclmakeblastdb -in Gallus_gallus_IGHJ.fasta -dbtype nuclblastn -db Gallus_gallus_IGHV.fasta -query Mmul_051212.fasta -out mmul_IGHV.out \\ -outfmt 7 -gapopen 5 -gapextend 5 -penalty -1 -word_size 11blastn -db Gallus_gallus_IGHD.fasta -query Mmul_051212.fasta -out mmul_IGHD.out \\ -outfmt 7 -gapopen 5 -gapextend 5 -penalty -1 -word_size 4 -evalue 100blastn -db Gallus_gallus_IGHJ.fasta -query Mmul_051212.fasta -out mmul_IGHJ.out \\ -outfmt 7 -gapopen 5 -gapextend 5 -penalty -1 -word_size 4blastresults_to_csv mmul_IGHV.out mmul_ighvdj_blastresults_to_csv mmul_IGHD.out mmul_ighvdj_ -ablastresults_to_csv mmul_IGHJ.out mmul_ighvdj_ -afind_alignments Gallus_gallus_IGHVDJ.fasta \\ Mmul_051212.fasta \\ &quot;mmul_ighvdj_nw_*.csv&quot; \\ -ref imgt,Gallus_gallus_IGHVDJ.fasta \\ -align Gallus_gallus_IGHV_gapped_fixed.fasta \\ -motif_dir motifs \\ Mmul_051212.csvdigger ../../../Duck/data/GCA_015476345.1_ZJU1.0_genomic.fna \\ -v_ref Homo_sapiens_IGHV.fasta \\ -d_ref Homo_sapiens_IGHD.fasta \\ -j_ref Homo_sapiens_IGHJ.fasta \\ -v_ref_gapped Homo_sapiens_IGHV_gapped.fasta \\ -ref imgt,Homo_sapiens_IGHVDJ.fasta \\ -species Chicken \\ -locus IGH \\ IMGT000035.csv How It Really Looks Like in Human Genome I randomly checked a few sequences from the homo genome and found that those regions from different V, D, and J genes are very similar. It could because that the 12/23 rule is not very stringent but flexible. But it could also caused by they are prevented to be recombined. pre { background-color:#38393d; color: #5fd381; } Janeway C, Travers P, Walport M, et al. Immunobiology: the immune system in health and disease[M]. New York: Garland Pub., 2001. ↩︎ Ru H, Zhang P, Wu H. Structural gymnastics of RAG-mediated DNA cleavage in V (D) J recombination[J]. Current opinion in structural biology, 2018, 53: 178-186. ↩︎ ↩︎ Sirupurapu V, Safonova Y, Pevzner P A. Gene prediction in the immunoglobulin loci[J]. Genome research, 2022, 32(6): 1152-1169. ↩︎ Lees W D, Saha S, Yaari G, et al. Digger: directed annotation of immunoglobulin and T cell receptor V, D, and J gene sequences and assemblies[J]. Bioinformatics, 2024, 40(3): btae144. ↩︎","link":"/2024/05/18/LearnNotes/ab1223rule/"},{"title":"Naive Bayes and Bayes NetWork","text":"Naïve Bayes The problem with likelihood: Too many words What does it mean to say that the words, x, have a particular probability? Suppose our training corpus contains two sample emails: Email1: Y = spam, X =&quot;Hi there man – feel the vitality! Nice meeting you…&quot; Email2: Y = ham, X =&quot;This needs to be in production by early afternoon…&quot; Our test corpus is just one email: Email1: X=&quot;Hi! You can receive within days an approved prescription for increased vitality and stamina&quot; How can we estimate P(X=&quot;Hi! You can receive within days an approved prescription for increased vitality and stamina&quot;|Y = spam)? One thing we could do is: $P(W = \\text{“hi”} | Y = \\text{spam}), P(W = \\text{“hi”} | Y = \\text{ham})$ $P(W = \\text{“vitality”} | Y = \\text{spam}), P(W = \\text{“vitality”} | Y = \\text{ham})$ $P(W = \\text{“production”} | Y = \\text{spam}), P(W = \\text{“production”} | Y = \\text{ham})$ Then the approximation formula for $P(X | Y)$ is given by: $$ P(X = x | Y = y) \\approx \\prod_{i=1}^{n} P(W = w_i | Y = y) $$ In this context, $W$ represents a word in a document, $X$ represents the document itself, $Y$ represents the class (spam or ham), $w_i$ represents the $i$-th word in the document, and $n$ is the total number of words in the document. The product is taken over all words in the document, assuming that the words are conditionally independent of each other given the class label $Y$. Why naïve Bayes is naïve? We call this model &quot;naïve Bayes&quot; because the words aren't really conditionally independent given the label. For example, the sequence &quot;for you&quot; is more common in spam emails than it would be if the words &quot;for&quot; and &quot;you&quot; were conditionally independent. True Statement: P(X = for you|Y= Spam &gt; P( W = for |Y = Spam)(P = you |= Spam) The naïve Bayes approximation simply says: estimating the likelihood of every word sequence is too hard, so for computational reasons, we'll pretend that sequence probability doesn't matter. Naïve Bayes Approximation: P(X = for you |Y = Spam) ≈ P(W = for |Y = Spam)P( W= you |Y= Spam) We use naïve Bayes a lot because, even though we know it's wrong, it gives us computationally efficient algorithms that work remarkably well in practice. MPE = MAP using Bayes’ rule $$ P(Y= y | X= x) = \\frac{P(X =x| Y=y)P(Y = y)}{P(X =x)} $$ Definition of conditional probability: $$ P(Y|f(X), A) = \\frac{P(f(X)|Y, A)P(Y|A)}{P(f(X)|A)} $$ Floating-point underflow That equation has a computational issue. Suppose that the probability of any given word is roughly P(W = Wi|Y = y) ≈ 10-3, and suppose that there are 103 words in an email. Then ∏ni=1 P(W = Wi|Y = y) = 10-309,which gets rounded off to zero. This phenomenon is called “floating-point underflow”. Solution $$f(x) = \\underset{y}{\\mathrm{argmax}} \\left( \\ln P(Y = y) + \\sum^n_{i=1} \\ln P(W = w_i | Y = y) \\right)$$ Reducing the naivety of naïve Bayes Remember that the bag-of-words model is unable to represent this fact: True Statement: P(X = for you|Y= Spam &gt; P( W = for |Y = Spam)(P = you |= Spam) Though the bag-of-words model can’t represent that fact, we can represent it using a slightly more sophisticated naïve Bayes model, called a “bigram” model. N-Grams: Unigram: a unigram (1-gram) is an isolated word, e.g., “you” Bigram: a bigram (2-gram) is a pair of words, e.g., “for you” Trigram: a trigram (3-gram) is a triplet of words, e.g., “prescription for you” 4-gram: a 4-gram is a 4-tuple of words, e.g., “approved prescription for you” Bigram naïve Bayes A bigram naïve Bayes model approximates the bigrams as conditionally independent, instead of the unigrams. For example, P(X = “approved prescription for you” | Y= Spam) ≈ P(B = “approved prescription” |Y = Spam) × P(B = “prescription for” | Y= Spam) × P(B = “for you” |Y = Spam) The naïve Bayes model has two types of parameters: The a priori parameters: P(Y = y) The likelihood parameters: P(W = wi| Y = y) In order to create a naïve Bayes classifiers, we must somehow estimate the numerical values of those parameters. Model parameters: feature likelihoods P(Word | Class) and priors P(Class) Parameter estimation: Prior The prior, P(x), is usually estimated in one of two ways. If we believe that the test corpus is like the training corpus, then we just use frequencies in the training corpus: $$ P(Y = Spam) = \\frac{Docs(Y=Spam)}{Docs(Y=Spam) + Docs(Y \\neq Spam)} $$ where Docs(Y=Spam) means the number of documents in the training corpus that have the label Y=Spam. If we believe that the test corpus is different from the training corpus, then we set P(Y = Spam) = the frequency with which we believe spam will occur in the test corpus. Parameter estimation: Likelihood The likelihood, ***P(W = wi|Y = y), is also estimated by counting. The “maximum likelihood estimate of the likelihood parameter” is the most intuitively obvious estimate: $$ P(W=w_i| Y = Spam) = \\frac{Count(W=w_i, Y = Spam)}{Count(Y = Spam)} $$ where Count(W=wi, Y = Spam) means the number of times that the word wi occurs in the Spam portion of the training corpus, and Count(Y = Spam) is the total number of words in the Spam portion. Laplace Smoothing for Naïve Bayes One of the biggest challenge for Bayes is it can’t handle unobserved situation. The basic idea: add $k$ “unobserved observations” to the count of every unigram If a word occurs 2000 times in the training data, Count = 2000+k If a word occur once in training data, Count = 1+k If a word never occurs in the training data, then it gets a pseudo-Count of $k$ Estimated probability of a word that occurred Count(w) times in the training data: $$ P(W = w) = \\frac{k + \\text{Count}(W = w)}{k + \\sum_v (k + \\text{Count}(W = v))} $$ Estimated probability of a word that never occurred in the training data (an “out of vocabulary” or OOV word): $$ P(W = \\text{OOV}) = \\frac{k}{k + \\sum_v (k + \\text{Count}(W = v))} $$ Notice that $$ P(W = \\text{OOV}) + \\sum_w P(W = w) = 1 $$ Naïve Bayes for Numerical Values For Numerical values, we could do regression first and calculate the possibilities of the feature based on the regression results. Here we take Gaussian-distribution data as example. Simulate training data: import numpy as npdef Gaussian_sm(mean, std_dev, num_samples = 1000, seed = 0): # Simulate a set of Gaussian-distribution by mean and std np.random.seed(seed) return np.random.normal(mean, std_dev, num_samples)X1_Set1 = Gaussian_sm(0, 1, 1000, 0)X1_Set2 = Gaussian_sm(2, 1, 1000, 1)X = np.concatenate([X1_Set1.reshape(-1, 1), X1_Set2.reshape(-1, 1)])y = np.array([0] * len(X1_Set1) + [1] *len(X1_Set2)) Split data into training and test set import random# select 20% of data as test data setdef DataSplit(X, y, rate = .2): random.seed(0) mask_test = random.sample(range(X.shape[0]), int(X.shape[0]*.2)) mask_train = [i for i in range(X.shape[0]) if i not in mask_test] X_train = X[mask_train] y_train = y[mask_train] X_test = X[mask_test] y_test = y[mask_test] return X_train, y_train, X_test, y_testX_train, y_train, X_test, y_test = DataSplit(X, y) Calculate Mean and std for each set in training data set def CalculateMeanStd(X_train): mean = [] std = [] for i in set(y_train): mean += [np.mean(X_train[y_train == i], axis=0)] std += [np.std(X_train[y_train == i], axis=0)] return np.array(mean).T, np.array(std).Tmean, std = CalculateMeanStd(X_train) Function for calculating the density in Gaussian: You can calculate the probability density of a value ( x ) in a Gaussian distribution using the probability density function (PDF) of the normal distribution. The formula is: $$ f(x | \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(x - \\mu)^2}{2 \\sigma^2}} $$ Where: $ x $ is the value you are evaluating. $ \\mu $ is the mean of the distribution. $ \\sigma $ is the standard deviation of the distribution. def gaussian_probability_density(x, mean, std): # Calculate the probability density using the Gaussian formula exponent = -(np.array([x - i for i in mean.T]) **2) / (2 * std.T.reshape(2, -1, x.shape[1]) ** 2) posb = (1 / (std.T.reshape(2, -1, x.shape[1]) * np.sqrt(2 * np.pi))) * np.exp(exponent) return posb.prod(axis=2).Tprobability = gaussian_probability_density(X_test, mean, std)probability[:4] array([[2.52243058e-03, 2.37361612e-01], [1.59978264e-01, 1.07963005e-03], [2.85861680e-03, 2.46842341e-01], [1.55356019e-01, 3.11973217e-01]]) This is the possibilities of data from X_test in class 0 or 1. For quick count the accuracy, we could do: from collections import CounterCounter(probability.argmax(axis =1) == y_test) Counter({True: 343, False: 57}) According to this results, we could know that the accuracy of this model is 85.75% import matplotlib.pyplot as pltplt.figure(figsize=(8, 3))color ={0: 'salmon', 1: 'steelblue'}plt.scatter(X_test.flatten(), y_test, c = [color[i] for i in probability.argmax(axis =1)], alpha = .7)plt.xlabel('Feature')plt.ylabel('Real class')plt.show()plit.close() As you can see, it perfectly find the best threads which is near the 1. Multiple Features In the example above, we only test for the single features. Similarly, we could calculate the possibilities by each when we have multiple features. And we multiple all the possibilities at the end. $$ P(X = x | Y = y) \\approx \\prod_{i=1}^{n} P(W = w_i | Y = y) $$ For example, we have 3 features: # data simulateX1_Set1 = Gaussian_sm(0, 1, 1000, 1)X1_Set2 = Gaussian_sm(2, 1, 1000, 1)X2_Set1 = Gaussian_sm(0, 1, 1000, 2)X2_Set2 = Gaussian_sm(2, 1, 1000, 2)X3_Set1 = Gaussian_sm(0, 1, 1000, 3)X3_Set2 = Gaussian_sm(2, 1, 1000, 3)X = np.array([np.concatenate([X1_Set1, X1_Set2]), np.concatenate([X2_Set1, X2_Set2]), np.concatenate([X3_Set1, X3_Set2])]).Ty = np.array([0] * len(X1_Set1) + [1] *len(X1_Set2))# split dataX_train, y_train, X_test, y_test = DataSplit(X, y)# Calculate Mean and std mean, std = CalculateMeanStd(X_train)# run the prediction probability = gaussian_probability_density(X_test, mean, std)Counter(probability.argmax(axis =1) == y_test) Counter({True: 388, False: 12}) According to this result, when we increasing the features by simply added 2 more duplicates, the accuracy is increased from 85.75% into 97%. After visualized the results based on the first 2 features and given different shape based on the true classes, different color into predicted classes, almost all of the results in the overlap region are correct, too. # visualize the result bay first 2 features.mask1 = y_test==0mask2 = y_test!=0Shape = {0:'s', 1:'o'}plt.scatter(X_test[:,0][mask1], X_test[:,1][mask1], c = [color[i] for i in probability.argmax(axis = 1)[mask1]], marker = 's', alpha = .7)plt.scatter(X_test[:,0][mask2], X_test[:,1][mask2], c = [color[i] for i in probability.argmax(axis = 1)[mask2]], marker = 'o', alpha = .7)plt.show() Bayesian Networks Why Network? Example: $Y$ is a scalar, but $X = [X_1, … , X_{100}]^T$ is a vector Then, even if every variable is binary, $P(Y = y|X = x)$ is a table with $2^{101}$ numbers. Hard to learn from data; hard to use. A better way to represent knowledge: Bayesian network Each variable is a node. An arrow between two nodes means that the child depends on the parent. If the child has no direct dependence on the parent, then there is no arrow. Space Complexity of Bayesian Network graph LR B --> A E --> A A --> J A --> M Without the Bayes network: I have 5 variables, each is binary, so the probability distribution $P(B, E, A, M, J)$ is a table with $2^5 = 32$ entries. With the Bayes network: Two of the variables, B and E, depend on nothing else, so I just need to know $P(B = ⊤)$ and $P(E = ⊤)$ — 1 number for each of them. M and J depend on A, so I need to know $P(M = ⊤|A = ⊤)$ and $P(M = ⊤|A = ⊥)$ – 2 numbers for each of them. A depends on both B and E, so I need to know $P(A = ⊤|B = b, E =e)$ for all 4 combinations of $(b, e)$ Total: 1+1+2+2+4 = 10 numbers to represent the whole distribution! $$ P(B = T \\mid J = T, M = T) = \\frac{P(B = T, J = T, M = T)}{P(J = T, M = T)} \\\\ = \\frac{P(B = T, J = T, M = T)}{P(J = T, M = T)} + \\frac{P(B = L, J = T, M = T)}{P(J = T, M = T)} \\\\ = \\sum_{e=T}^{L} \\sum_{a=T}^{L} P(B = T, E = e, A = a, J = T, M = T) \\\\ = \\sum_{e=T}^{L} \\sum_{a=T}^{L} P(B = T) P(E = e) \\ × \\\\ P(A = a \\mid B = T, E = e) P(J = T \\mid A = a) P(M = T \\mid A = a) $$ Variables are independent and/or conditionally independent Independence graph TD B --> A E --> A Variables are independent if they have no common ancestors $ P(B = \\top, E = \\top) = P(B = \\top)P(E = \\top)= P(B = \\top) $ !!! Independent variables may not be conditionally independent The variables B and E are not conditionally independent of one another given knowledge of A If your alarm is ringing, then you probably have an earthquake OR a burglary. If there is an earthquake, then the conditional probability of a burglary goes down: $P(B = \\top| E = \\top, A = \\top) \\neq P(B = \\top| E = \\bot, A = \\top)$ This is called the “explaining away” effect. The earthquake “explains away” the alarm, so you become less worried about a burglary. Conditional Independence graph TD A --> J A --> M The variables J and M are conditionally independent of one another given knowledge of A If you know that there was an alarm, then knowing that John texted gives no extra knowledge about whether Mary will text: $P(M = \\top | J = \\top , A = \\top)=P(M = \\top | J = \\bot, A = \\top)= P(M = \\top| A = \\top)$ Conditionally Independent variables may not be independent The variables J and M are not independent! If you know that John texted, that tells you that there was probably an alarm. Knowing that there was an alarm tells you that Mary will probably text you too: $P(M = \\top| J = \\top) \\neq P(M= \\top| J = \\bot)$ Variables are conditionally independent of one another, given their common ancestors, if (1) they have no common descendants, and (2) none of the descendants of one are ancestors of the other $ P(U = T, M = T \\mid A = T) = P(U = T \\mid A = T)P(M = T \\mid A = T) $ How to tell at a glance if variables are independent and/or conditionally independent graph LR B --> A E --> A A --> J A --> M Variables are independent if they have no common ancestors $P(B = \\top, E = \\top) = P(B=\\top)P(E =\\top)$ Variables are conditionally independent of one another, given their common ancestors, if: they have no common descendants, and none of the descendants of one are ancestors of the other $P(J = \\top, M = \\top| A = \\top) = P(J = \\top| A = \\top) P (M = \\top| A = \\top)$ pre { background-color:#EEFFEF ; color: #5fd381; }","link":"/2024/02/01/LearnNotes/ai-bayes/"},{"title":"Hidden Markov Model","text":"A Hidden Markov Model is a Bayes Network with these assumptions: • Yt depends only on Yt-1 • Xt depends only on Yt The belief network conveys the independence assumption: $$ for\\ all\\ i \\geq 0, P(S_{i+1}|S_i) = P (S_1|S_0) $$ $$ P(S_i = s) = \\sum_{s’} P(S_{i+1} = s \\mid S_i = s’) * P(S_i = s’) $$ In the context of the equation you’re referring to, $ s $ and $ s’ $ represent states in a Markov chain. Typically, $ s $ is used to denote the current state, while $ s’ $ (read as “s prime”) denotes a subsequent or different state that the system can transition into from the current state $ s $. The summation over $ s’ $ in the equation indicates that you’re summing over all possible subsequent states that the system can transition to from the current state $ s $. This is part of the definition of a stationary distribution for a Markov chain, where the probability of being in any given state $ s $ is equal to the sum of the probabilities of transitioning to state $ s $ from all possible previous states $ s’ $, weighted by the probability of being in state $ s’ $ at the previous time step. Key advantage of a hidden Markov model: Polynomial-time complexity Suppose there are |y| different speech sounds in English, and the length of the utterance is d centiseconds (|y| ≈ 50, d ≈ 100) Without the HMM assumptions, to compute f(x)= argmaxP(y1, … , yd|x1, … , xd) requires a time complexity of O{|y|d} ≈ 50100 With an HMM, each variable has only one parent, so inference is O{|y|d} ≈ 502 The computationally efficient algorithm that we use to compute f(x)= argmaxP(y1, … , yd|x1, … , xd) is called the Viterbi algorithm, named after the electrical engineer who first applied it to error correction coding. it works much better than bayes Text generated by a naïve Bayes model (unigram model): Representing and speedily is an good apt or come can different natural here he the a in came the to of to expert gray come to furnishes the line message had be these… Text generated by a HMM (bigram model): The head and in frontal attack on an English writer that the character of this point is therefore another for the letters that the time of who ever told the problem for an unexpected… Applications of HMMs Speech recognition HMMs: Observations are acoustic signals (continuous valued) States are specific positions in specific words (so, tens of thousands) Machine translation HMMs: Observations are words (tens of thousands) States are cross-lingual alignments Robot tracking: Observations are range readings (continuous) States are positions on a map Viterbi Algorithm The Viterbi algorithm is a computationally efficient algorithm for computing the maximum a posteriori (MAP) state sequence $$ f(x)= argmax_{y_1, … , y_d}P(y_1, … , y_d|x_1, … , x_d) $$ Notation Initial State Probability: $ \\pi_i = P(Y_1 = i)$ Transition Probability: $a_{i,j} = P(Y_t=j| Y_{t-1} = i)$ Observation Probabilities: $b_j(x_t) = P(X_t = x_t|Y_t=j)$ Node Probability: Probability of the best path until node $ j $ at time $ t $ $$ v_t(j) = \\max_{y_1,…,y_{t-1}} P(Y_1 = y_1 ,…, Y_{t-1} = y_{t-1}, Y_t = j, X_0 = x_0, …, X_t = x_t) $$ Backpointer: which node precedes node $ j $ on the best path? $$ \\psi_t(j) = \\arg\\max_{y_{t-1}} \\max_{y_1,…,y_{t-2}} P(Y_1 = y_1 ,…, Y_{t-1} = y_{t-1}, Y_t = j, X_0 = x_0, …, X_t = x_t) $$ How HMM Worked Initiation → Iteration → Termination → Back-Tracing Initiation $v_1(i) = \\pi_ib_i(x_1)$ Iteration $v_t(j) = max v_{t-1}(i)a_{i,j}b_j(x_t)$ Termination $y_d = argmax v_d{i}$ Back-Tracing $y_t = \\psi_{t+1}(y_{t+1})$ Example Question Richard Feynman is an AI. He cannot see the weather, but he can see whether or not his creator, Elspeth Dunsany, brings an umbrella to work. Let $ R_t $ denote the event “it is raining on day $ t $,” and let $ U_t $ denote the event “Dr. Dunsany brings her umbrella on day $ t $.” Dr. Dunsany is an absent-minded professor; she often brings her umbrella when it’s not raining, and often forgets her umbrella when it’s raining. Richard’s model of Dr. Dunsany’s behavior includes the parameter $ P(R_1 = T) = 0.5 $, and the parameters shown in the tables below. What is $ P(R_2 = F, U_1 = T, U_2 = T) $? $ P(R_t = T | R_{t-1} = r_{t-1}) $ $ r_{t-1} = F $ $ r_{t-1} = T $ $ r_t = F $ 0.4 0.1 $ r_t = T $ 0.8 0.7 $P(U_t = T | R_t = r_t)$ $r_t = F$ $r_t = T$ $ r_{t-1} = F $ 0.4 0.1 $ r_{t-1} = T $ 0.8 0.7 Initial State Probability: $ P(R_1 = T) = 0.5 $ Transition Probabilities: $ P(R_t = T | R_{t-1} = F) = 0.8 $ $ P(R_t = T | R_{t-1} = T) = 0.7 $ $ P(R_t = F | R_{t-1} = F) = 0.4 $ $ P(R_t = F | R_{t-1} = T) = 0.1 $ Observation Probabilities (Probability of Dr. Dunsany bringing her umbrella given the weather): $ P(U_t = T | R_t = F) = 0.4 $ (Probability she brings an umbrella when it’s not raining) $ P(U_t = T | R_t = T) = 0.1 $ (Probability she brings an umbrella when it is raining) These probabilities define the initial state distribution, the transition dynamics, and the observation model of a system, which are essential components of probabilistic models like Hidden Markov Models (HMMs). The scenario you’ve presented involves conditional probabilities and is a typical example used in Bayesian inference or probabilistic models. Given the information in the image, we can calculate the probability that Dr. Dunsany brings her umbrella on day 2 given that it’s not raining on day 2, but it was raining on day 1. The information given includes: The initial probability that it’s raining on day 1: $ P(R_1 = T) = 0.5 $ The conditional probabilities of bringing an umbrella given the weather: $ P(R_t = T | R_{t-1} = r_{t-1}) $: The probability that Dr. Dunsany brings an umbrella on day $ t $ given the weather on day $ t-1 $. $ P(U_t = T | R_t = r_t) $: The probability that Dr. Dunsany brings an umbrella on day $ t $ given the weather on day $ t $. With the tables provided, we can calculate the probability that Dr. Dunsany brings her umbrella on day 2 given the conditions specified. We can apply the law of total probability to consider all possible weather scenarios from the previous day. Here is the formula based on the total probability theorem: $ P(R_2 = F, U_1 = T, U_2 = T) = \\\\ \\sum_{r_{t-1} \\in {T, F}} P(R_2 = F | R_1 = r_{t-1}) \\cdot P(U_1 = T | R_1 = r_{t-1}) \\cdot P(U_2 = T | R_2 = F) $ We would then substitute the values from the tables into the formula to calculate the desired probability. Would you like to proceed with this calculation? pre { color: #5fd381; }","link":"/2024/02/12/LearnNotes/ai-hmm/"},{"title":"OPTICAL SPECTROSCOPY – THE ABSORPTION PROCESS","text":"OPTICAL SPECTROSCOPY – THE ABSORPTION PROCESS © wiki Small wavelength; High frequency; Blue end of the visible spectrum Long wavelength; Low frequency; Red end of the visible spectrum Energy of visible light is about 100-500 kJ/mol Beer’s Law and Absorbance $$ \\frac{I}{I_ 0} = 10^ {-\\frac{kc(\\Delta y)}{2.303}} = 10^ {- \\epsilon c (\\Delta y)} = 10^ {-A} $$ Define of absorbance: $ A = \\epsilon c (\\Delta y)$ or $A=\\epsilon c l $ ε: Molar extinction coefficient c: concentration in M Δy: path length in cm (some place use l as Δy) © imamagnets Application of Absorbance Use UV-Vis absorbance to calculate the concentration of the molecules like DNA, protein, etc. $A=\\epsilon (\\lambda) c l$ Molecule λ (nm) ε (×10-3) (M-1cm-1) Adenine 260.5 13.4 Adenosine 259.5 14.9 NADH 340, 259 6.23, 14.4 NAD+ 260 18 FAD 450 11.2 Tryptophan 280, 219 5.6, 47 Tyrosine 274,222,193 1.4, 8, 48 Phenylalanine 257, 206, 188 0.2, 9.3, 60 Histidine 211 5.9 Cysteine 250 0.3 Quantum Mechanical Transition Probability The probability per unit time that a molecule in state 1 will end up in state 2 in the presence of an oscillating electromagnetic field at the resonance frequency Energy of the light = Difference between energy levels $$ Rate_ {1 → 2} = B_ {12} \\rho (\\nu)[S_ 1] $$ B12: rate constant ρ(ν): radiation field density S1: Concentration of molecules in the ground state Rate constant dependents on the transition dipole moment $B_{12} \\propto \\langle \\mu \\rangle^2$ $\\langle \\mu \\rangle = \\int \\Psi_2 (q_e\\vec{r})\\Psi dV$ Transition dipole moment: $\\langle \\mu \\rangle \\propto$ overlap between $\\Psi_1$ and $\\Psi_2$ Dipole approximation When a light wave hit hydrogen atom, the r from the atom into electron is far smaller than the λ. $\\because r &lt;&lt; \\lambda$ $\\vec{\\mu} = - q\\vec{r}$ $Energy = -\\vec{\\mu}\\cdot\\vec{E}$ $\\vec{\\mu}$: matter $\\vec{E}$: Electric Field (amplitude of light) © Sentry The transition dipole reflects the change of electron distribution by excitation © wikipedia Transition dipole moment Overlap of wavefunctions and transition probability $$\\mu_{mn} = \\int_{-\\infty}^{\\infty} \\Psi_n^* \\left( \\sum_{i=1}^{N} q_e \\vec{r}_i \\right) \\Psi_m , dr $$ Where: $N$: Number of electrons in a molecule $\\vec{r}_i$: Position of each electron $q_e$: electron charge $\\Psi_n$: Excited state (or final state) molecular wave function $\\Psi_m$: Ground state (or initial state) molecular wave function Note: each molecular wavefunction depends on the position of BOTH Nucleus AND electron but for now, let’s focus on electron wavefunction (i.e. no structural change of molecular structure or atom position). Larger overlap of initial and final state wavefunctions means higher transition probability, which generates higher extinction coefficient (Fermi’s golden rule). Wavefunction overlap: Larger wavefunction overlap of initial and final state means higher transition probability, which generates higher extinction coefficient (Fermi’s golden rule). Orbital Symmetry: $\\int_{-\\infty}^{\\infty} f(r ) , dr = 0 \\quad \\text{if} \\quad f(r )$ is an odd function; i.e., $f(-x) = -f(x)$ $\\int_{-\\infty}^{\\infty} f(r ) , dr \\neq 0 \\quad \\text{if} \\quad f(r )$ is an even function; i.e., $f(-x) = f(x)$ So: $\\Psi_n^* \\tilde{\\Psi}_m$ must be an even function; or: $\\Psi_n^* \\Psi_m$ must be an odd function (e.g., } $\\pi$ and $\\pi^ *$ state Dipole strength and Oscillator strength Traditional ways to quantify the “strength of a transition” Dipole strength: $D_{mn} = |\\mu_{mn}|^2 = 9.18 \\times 10^{-3} \\int \\left( \\frac{\\varepsilon}{\\nu} \\right) d\\nu $ Oscillator strength: $f_{mn} = 4.315 \\times 10^{-9} \\int \\varepsilon(\\nu) d\\nu $ Area under the spectrum associated with the m→n transition $ f_{mn} \\approx 0.1-1 $ Strong absorption (heme, chlorophyll, organic dyes) $ f_{mn} \\approx 10^{-5} $ Weak absorption Kuhn-Thomas sum rule for oscillator strengths In any molecule with N electrons the sum of the oscillator strengths from any one state to all of the other states is equal to the sum of the electrons $$ \\sum_j f_{ij} = N $$ This means that the area underneath the absorption spectrum is a constant (ground state is the initial state). If a molecule is perturbed (change environments) then if one transition goes down, another must go up. Every transition is associated with a transition dipole The transition dipole is a vector: Direction: point in the direction of the electron displacement Amplitude: Strength of the absorption. Possible transitions in UV-Vis light range © ucla.edu σ→σ* often requires absorption of photons higher than the UV- vis range (200-700 nm). What determines the probability of a transition? (strength of the absorption band) Orbital overlap (wavefunction) π →π * Large overlap, more likely to happen, strong absorption n →π * Small overlap, weak absorption Spin multiplicity Electrons prefer not to change its intrinsic spin direction after absorption. Effective light-matter interaction Transition Rate: $$ Rate_{1 \\rightarrow 2} = B_{12} \\rho(\\nu) [S_1]$$ Radiation field density Component of the Electric Field: $$ E_{\\parallel} = |\\vec{E}| \\cos \\theta$$ Density of States: $$ \\rho(\\nu) \\propto |E_{\\parallel}|^2 = |\\vec{E}|^2 \\cos^2 \\theta$$ Effective light-matter interaction The density of states $\\rho(\\nu)$ is proportional to the square of the parallel component of the electric field: $$ \\rho(\\nu) \\propto |E_{\\parallel}|^2 = |\\vec{E}|^2 \\cos^2 \\theta$$ This relationship is depicted through diagrams that illustrate the electric field vector $\\vec{E}$ relative to the molecular transition dipole moment $\\vec{\\mu}$. The alignment of $\\vec{E}$ with $\\vec{\\mu}$ affects the absorption, with maximum absorption when they are parallel and zero absorption when they are perpendicular. This is exemplified by the molecular orientations of adenine shown in the image. Absorption, emission, and stimulated emission The rates of absorption, emission, and stimulated emission can be described by the following equations: Rates Equetion Absorption Rate $ Rate_{abs} = B_{12} \\rho(\\nu) [S_1] $ Emission Rate $ Rate_{emi} = -A_{21} [S_2] $ Stimulated Emission Rate $ Rate_{se} = -B_{21} \\rho(\\nu) [S_2] $ At steady state, the rate of upward transitions (absorption) equals the rate of downward transitions (emission and stimulated emission): $$ B_{12} \\rho(\\nu) [S_1] = A_{21} [S_2] + B_{21} \\rho(\\nu) [S_2] $$ A21, B12, and B21 are called Einstein coefficients. It can be shown that: B12=B21 $\\frac{A_ {21}}{B_ {21}} = \\frac{16\\pi^ 2 \\hbar \\nu^ 3}{c^ 3}$ Faster spontaneous emission at higher Frequency In a typical UV-Vis spectroscopy (electronic transitions) Conditions: $ A \\gg B \\rho(\\nu) $ Einstein coefficients relationships: $ B_{12} \\rho(\\nu) [S_1] = A_{21} [S_2] + B_{21} \\rho(\\nu) [S_2] \\approx A_{21} [S_2] $ Approximations: $ \\frac{B_{12} \\rho(\\nu)}{A_{21}} \\frac{[S_2]}{[S_1]} \\ll 1 $ Population of states: $ [S_2] \\ll [S_1] $ The population of the excited state never builds up to a significant amount. laser requires stimulated emission rate constant, i.e. B21, to be much larger than the spontaneous emission rate constant, i.e. A21. So, UV laser is harder to make than visible light laser Boltzmann Distribution The probability $P_i$ of a system being in a state i with energy $E_i$ at temperature T is given by: $$ P_i = \\frac{e^{-\\frac{E_i}{k_B T}}}{\\sum_{i=0}^{M} e^{-\\frac{E_i}{k_B T}}} = \\frac{e^{-\\frac{E_i}{k_B T}}}{Q} $$ Where: $Q$: Partition function $E_i$: Energy of the ith state $k_B$: Boltzmann constant $= 1.38 \\times 10^{-23} J/K$ $T$: Temperature (K) The ratio of probabilities between two states i and j is given by: $$ \\frac{P_i}{P_j} = e^{-\\frac{(E_i - E_j)}{k_B T}} = e^{-\\frac{\\Delta E}{k_B T}} $$ Quantum Mechanical Harmonic Oscillator © Mauricio Alcolea Palafox © Anas Al-Rabadi The panel left: wave funciton, the panel right: porbability of finding a nuclei Solve the time-independent Schrödinger Equation (for the nucleus) with $ V(x) = \\frac{1}{2}kx^2 $ The time-independent Schrödinger Equation is: $ -\\frac{\\hbar^2}{2m} \\frac{d^ 2\\Psi(x)}{dx^2} + V(x)\\Psi(x) = E\\Psi(x) $ We get a set of wave functions and a set of energies: $ \\Psi_n(x) \\quad$ (set of wave functions) $ E_n \\quad $ (set of energies) For a harmonic oscillator potential, the energy levels are given by: $ E_n = \\left(n + \\frac{1}{2}\\right)\\hbar\\omega $ $ \\omega_0 = \\sqrt{\\frac{k}{m_r}} = 2\\pi\\nu_0 $ where $ n = 0,1,2,3,\\ldots $ © wikipedia Vibrational energy of the nuclei on top of electronic energy © oe1.com Jablonski energy diagram VERTICAL TRANSITION: consider the nuclei to remain in the same place during an electronic transition. At thermal equilibrium, most molecules will be in the lowest vibrational state Franck-Condon factor (nuclear) The total wavefunction $\\Psi(r, R)$ is a product of the electronic $\\Psi_{el}(r, R)$ and nuclear $\\Psi_{nuc}®$ wavefunctions: $$ \\Psi(r, R) = \\Psi_{el}(r, R)\\Psi_{nuc}( R) $$ electrons refers to $\\Psi_{el}(r, R)$ nuclei refers to $\\Psi_{nuc}(R )$ Transition from vibrational level i of the ground electronic state to the vibrational level j of the exited electronic state is given by: $$ \\vec{\\mu}_ {g \\rightarrow ex,j} = \\left( \\vec{\\mu}_ {g \\rightarrow ex} \\right) \\int \\Psi_ {nuc(j)}^* \\Psi_ {nuc(i)} dR $$ The electron transition dipole moment $\\vec{\\mu}_{g \\rightarrow ex}$ represents the Electron transition dipole moment. Rest of the integral represents the Nuclear overlap Factor, also known as the Franck-Condon factor. Vibrational structure and the Franck- Condon principle: vertical transitions Spectroscopic broadening Intrinsic Column1 Column2 Column3 Vibrational Structure Overlapping Electronic Bands Environment: solvent effect 25% λ1 (state 1) 50% λ2 (state 2) 25% λ3 (state 3) Solvent effects on the absorption spectrum of anisole © PSIBERG Team to left: Bathochromic or Red shift to right: Hypsochromic or Blue shift The nature of the changes are not always simple to predict. How does the solvent influence the ground and excited states? SOLVENT POLARITY: permanent dipole of the solvent molecules measured by the static dielectric constant. ε~r~ SOLVENT POLARIZABILITY: electron polarizability measured by index of refraction. n Hydrogen bonding (protic vs. aprotic solvent) More on the dielectric constant Material 1: High εr, therefore higher ability to cancel out (stabilize) the original source charge Material 2: Low εr, The ability to insulate charge or The ability to stabilize charges The relative permittivity $\\varepsilon_r$ as a function of frequency $\\omega$ is given by: $$ \\varepsilon_r(\\omega) = \\frac{\\varepsilon(\\omega)}{\\varepsilon_0} $$ Where: $\\varepsilon_0$: vacuum permittivity (= 1.0) $\\varepsilon$: material’s absolute permittivity $\\varepsilon_r$: relative permittivity or dielectric constant Examples of relative permittivity for different materials: $\\varepsilon_r$ (styrofoam) = 1.03 $\\varepsilon_r$ (dry wood) = 1.4 - 2.9 $\\varepsilon_r$ = 20 Relative permittivity values for various solvents: Solvent Hexane Ether Ethanol Methanol Water $\\varepsilon_r$ 2 4.3 25.8 31 81 Small value means it is non-polar solvent. Large value means it is a polar solvent. Polar effects on transitions between molecular orbitals © Vaishali Gupta Compound λ(nm) Intensity/ε Transition with lowest energy CH₄ 122 intense σ→σ* (C-H) CH₃CH₃ 130 intense σ→σ* (C-C) CH₃OH 183 200 n→σ* (C-O) CH₃SH 235 180 n→σ* (C-S) CH₃NH₂ 210 800 n→σ* (C-N) CH₃Cl 173 200 n→σ* (C-Cl) CH₃I 258 380 n→σ* (C-I) CH₂=CH₂ 165 16000 π→π* (C=C) CH₃COCH₃ 187 950 π→π* (C=O) CH₃COCH₃ 273 14 n→π* (C=O) CH₃CSCl₃ 460 weak n→π* (C=S) CH₃N=NCCH₃ 347 15 n→π* (N=N) Polarity effect on π-π* transitions Typical π-π* transitions: the dipole gets larger in the same direction More stabilization, energy increases; high solvent polarity results in a RED SHIFT (of the absorption peak). In a more polar state: More stabilization, energy increases; high solvent polarity results in a RED SHIFT (of the absorption peak). Typical n-π* transitions: the dipole of the chromophore gets smaller or shifts direction after excitation. Less stabilization, energy increases; high solvent polarity results in a BLUE SHIFT (of the absorption peak) Example: spectral shifts of mesityl oxide © wikipedia The solvent effects on the absorption maxima (λmax) for the π→π* and n→π* transitions in acetone: solvent Static dielectric constant λmax (nm) π→π* (Red shift) λmax (nm) n→π* (Blue shift) Hexane 2 229.5 327 Ether 4.3 230 326 Ethanol 25.8 237 315 Methanol 31 238 312 Water 81 244.5 305 Red shift indicates a lower energy transition as the dielectric constant increases. Blue shift indicates a higher energy transition as the dielectric constant decreases. The transitions are characterized by their molar absorptivities (ε): n→π*: ε = 40M⁻¹cm⁻¹ π→π*: ε = 12,600M⁻¹cm⁻¹ Indol (Tryptophan) π-π* transitions © Neera Sharma La: large excited state dipole (lower energy state) Lb: Smaller excited state dipole Solvent polarizability measured by the index of refraction dipole is induced in the solvent by the dipole of the chromophore (ground state and excited state) No nuclear movement involved. Purely due to electrons ground state dipole ( ← ) excited state (↑) induced dipoles in solvent ( ← ) Some values of solvent index of refraction solvent Index of refraction Perfluoropentane 1.239 Water 1.333 Ethanol 1.362 Iso-octane 1.392 Chloroform 1.446 Carbontetrachloride 1.463 Note that water is less polarizable than iso-octane although clearly water is a much more polar solvent (larger dielectric constant) Influence on the energy levels of π, n, π* orbitals by solvent polarizability π - π* transitions: red shift in more polarizable solvent π* interacts with solvent dipoles more strongly than π n - π* transitions: blue shift in more polarizable solvent n interacts with solvent dipoles more strongly than π* Solvent can influence the energy of both the ground and the excited states Rhodopsin: a protein “solvent” effect on the absorption spectrum of retinal vision is due to same pigment proteins in rod and cone cells: λmax = 500 nm (rod cell) λmax = 414 nm (blue cone) λmax = 533 nm (green cone) λmax = 560 nm (red cone) Same chromophore: 11-cis retinal “spectral tuning” by interaction with amino acid residues nearby WT: 500 nm G90S: 487 nm T118A: 484 nm E122D: 477 nm A292S: 489 nm A295S: 498 nm T/E/A triple mutant: 453 nm pre { background-color:#38393d; color: #5fd381; }","link":"/2024/01/30/LearnNotes/absorption/"},{"title":"Learning Progress","text":"Learning Biological inspiration: Long-term potentiation A synapse is repeatedly stimulated More dendritic receptors More neurotransmitters A stronger link between neurons Mathematical Model this Biological Learning Model: X = input signal; f(X) = output signal Learning = adjust the parameters of the learning machine so that f(x) becomes the function we want Mathematical Model of Supervised Learning D = {(x1, y1), …, (xn, yn)} = training dataset containing pairs of (example signal xi, desired system output yi) Supervised Learning = adjust parameters of the learner to minimize E[ℓ(Y, f(X))] ℓ: loss function Decision tree learning: An example The Titanic sank. You were rescued. You want to know if your friend was also rescued. You can’t find them. Can you use machine learning methods to estimate the probability that your friend survived? (Calculate the possibility of your friend also be rescued) Gather data about as many of the passengers as you can. X = variables that describe the passenger, e.g., age, gender, number of siblings on board. Y = 1 if the person is known to have survived Learn a function, f(X), that matches the known data as well as possible Apply f(x) to your friend’s facts, to estimate their probability of survival Decision-tree learning*: 1st branch = variable that best distinguishes between groups with higher vs. lower survival rates (e.g., gender) 2nd branch = variable that best subdivides the remaining group Quit when all people in a group have the same outcome, or when the group is too small to be reliably subdivided. © wikipedia In each leaf node of this tree: Number on the left = probability of survival Number on the right = percentage of all known cases that are explained by this node A decision tree is an example of a parametric learner The function f(x) is determined by some learned parameters In this case, the parameters are: Should this node split, or not? If so, which tokens go to the right-hand child? If not, what is f(x) at the current node? Titanic shipwreck example: Θ = [Y, female, Y, age ≤ 9.5, N, f(x) = 0.73, …] A mathematical definition of learning Environment: there are two random variables, X and Y, that are jointly distributed according to P(X,Y) Data: P(X, Y) is unknown, but we have a sample of training data D = {(x~1~, y~1~), ..., (x~n~, y~n~)} Objective: We would like a function � that minimizes the expected value of some loss function, ℓ(Y , f(x)) : ℛ = E[ℓ(Y, f(x))] Definition of learning: Learning is the task of estimating the function f, given knowledge of D. Training vs. Test Corpora Training Corpus = a set of data that you use in order to optimize the parameters of your classifier (for example, optimize which features you measure, how you use those features to make decisions, and so on). Measuring the training corpus accuracy is important for debugging: if your training algorithm is working, then training corpus error rate should always go down. Test Corpus = a set of data that is non-overlapping with the training set (none of the test tokens are also in the training dataset) that you can use to measure the error rate. Measuring the test corpus error rate is the only way to estimate how your classifier will work on new data (data that you’ve never yet seen) Training error is sometimes called “optimization error”. It happens because you haven’t finished optimizing your parameters. Test error = optimization error + generalization error Evaluation Test Corpus = a dataset that is used only to test the ONE classifier that does best on DevTest. From this corpus, you learn how well your classifier will perform in the real world. Early stopping Learning: Given $\\mathcal{D} = {(x_1, y_1), \\ldots, (x_n, y_n)}$, find the function $f(X)$ that minimizes some measure of risk. Empirical risk: a.k.a. training corpus error: $R_{\\text{emp}} = \\frac{1}{n} \\sum_{i=1}^{n} \\ell(y_i, f(x_i))$ True risk, a.k.a. expected test corpus error: $R = \\mathbb{E}[\\ell(Y, f(X))] = R_{\\text{emp}} + R_{\\text{generalization}}$ Usually, minimum test error and minimum dev error don’t occur at the same time … but early stopping based on the test set is cheating, … so early stopping based on the dev set is the best we can do w/o cheating. Summary Biological inspiration: Neurons that fire together wire together. Given enough training examples (xi, yi), can we learn a desired function so that f(x) ≈ y? Classification tree: Learn a sequence of if-then statements that computes f(x) ≈ y Mathematical definition of supervised learning: Given a training dataset, D = {(x1, y1), …, (xn, yn)} , find a function f that minimizes the risk, ℛ = E[ℓ(Y, f(x))]. Overtraining: $ℛ_ {emp} = \\frac{1}{n} \\sum^n_{i=1} ℓ*y_i, f(x_i))$ reaches zero if you train long enough. Early Stopping: Stop when error rate on the dev set reaches a minimum pre { background-color:#38393d; color: #5fd381; }","link":"/2024/02/02/LearnNotes/ai-learning/"},{"title":"Behavior Analysis","text":"What is behavior research Behavioral research, often referred to as behavior science, is the scientific study of the behavior of human beings and animals. It involves the systematic collection and analysis of data in order to understand and explain how individuals behave in certain situations. Behavioral research spans multiple disciplines including psychology, sociology, anthropology, cognitive science, neurology, and even computer science, and it encompasses a variety of specific fields of study, such as behavioral psychology, behavioral economics, and behavioral neuroscience. Here are a few reasons why we study behavior: Understand Mechanisms: Understanding the mechanisms that underlie behavior can give us insights into why individuals act the way they do. This can involve studying the brain and nervous system to understand the physiological basis of behavior. Predict Behavior: By understanding the factors that influence behavior, researchers can predict how individuals will behave in different circumstances. This has applications in many fields, from marketing (predicting consumer behavior) to public health (predicting adherence to health guidelines). Change Behavior: Once we understand and can predict behavior, we can also try to change it. This can involve designing interventions to promote beneficial behaviors or discourage harmful ones. Evaluate Interventions: Behavioral research is also used to evaluate the effectiveness of interventions designed to change behavior. How to study behaviors As for how we study behaviors, it often involves the following steps: Observation: The first step is often to observe the behavior in its natural context, in order to get a sense of what is happening and to generate hypotheses. Measurement: Researchers then need to find a way to measure the behavior in a systematic and reliable way. This can involve anything from timing a rat in a maze, to counting the number of times a bird performs a specific action, to administering questionnaires to human participants. Experimentation: Once the behavior has been measured, researchers can conduct experiments to test their hypotheses. This typically involves manipulating one or more variables and observing the effect on the behavior. Analysis: The data collected in the experiment is then analyzed, often using statistical methods, to determine whether the observed effects are statistically significant. Interpretation and Publication: The results are then interpreted in light of the original hypotheses, and the study is usually written up and published in a scientific journal, so that other researchers can evaluate and build on the findings. Overall, behavioral research is a vast field that offers insights into the complexities of behavior and provides a foundation for making predictions and interventions in various sectors of life and society. Common things we can do with in behavior analysis Social network analysis: Consider each animal as a node and an interaction as an edge in a network. You can use graph analysis techniques to identify which animals have the most interactions (central nodes), which ones tend to interact with each other (clusters), and whether the pattern of interactions changes over time. Behavioral change over time: Analyze the animals’ behaviors (like wing extensions or movement patterns) over time. Look for patterns or triggers for specific behaviors - do they happen more frequently at certain times or after specific interactions? Collective behavior: You can look at the group-level behaviors. For example, if the group tends to move together, you can calculate the polarization of the group, which is a measure of how much the animals’ movement directions align with each other. If the group tends to stay together, you can calculate the nearest neighbor distance or the density of the group, which are measures of the group’s cohesion. Individual vs. group behavior: Try comparing individual behaviors to the group behavior. Are there certain individuals that often initiate group movements? Are there individuals that often behave differently than the group? Correlation between movement and behavior: Investigate if there’s a correlation between the movement of an animal (speed, acceleration, etc.) and its specific behaviors like wing extensions. Does a specific behavior trigger a change in movement or vice versa? Response to stimuli: If your data includes any events or stimuli (like changes in the environment or the appearance of food or predators), you can analyze how these affect the animals’ behavior. Do these events trigger specific behaviors or changes in interaction patterns? To quantify the interactions, you could count the number of interactions each animal has, the frequency of interactions, the average duration of interactions, etc. You could also quantify the result of each interaction - for example, does one animal tend to move away after interacting with another? You would need to use statistical methods and possibly machine learning techniques to perform these analyses, depending on the complexity of your data and the questions you’re trying to answer. You might also find it helpful to visualize your data, both to help you understand it and to communicate your results to others. Something more we may can do Machine Learning and Predictive Analysis: You can use supervised learning if you have labeled data, or unsophisticated learning if you don’t, to discover patterns in the data and make predictions about future behavior based on past data. For example, you can try to predict when and where certain behaviors will occur, or predict the outcome of interactions based on their initial conditions. Multivariate Behavioral Analysis: Investigate the relationships between different behaviors. For example, does a wing extension by one animal often lead to a similar action by another animal? Or does a particular movement pattern often precede or follow certain interactions? These patterns might not be visible in a univariate analysis of individual behaviors, but may emerge when looking at multiple behaviors together. Complex Network Analysis: Go beyond basic social network analysis and use techniques from complex network analysis. For example, you might look at motifs (recurring patterns of interactions), centrality measures (which animals are most central or influential in the network), community structure (groups of animals that interact more with each other than with the rest of the group), etc. Spatio-temporal Analysis: Study the behavior of the group as a function of both space and time. For example, do the animals exhibit different behaviors or interactions in different parts of the container? Or at different times? Comparative Analysis: If you have data for different groups of animals, you might compare their behaviors. Are there consistent differences between groups, or between the same group at different times? Ethological Modeling: Based on your data, you could develop models of animal behavior. These models could be mathematical, computational, or conceptual, and they could help you better understand the principles underlying the behaviors you observe. Fractional Order Statistics: This is a newer branch of statistics that can be used to model complex systems, it might be helpful if the data shows heavy-tailed distributions or long-range correlations. pre { background-color:#38393d; color: #5fd381; }","link":"/2023/07/27/LearnNotes/behavior-research/"},{"title":"Artificial Intelligent 1","text":"Random Variable Probability: Exp1: $Pr(A) &gt; 0$ which means that A has non-negative probability. Exp2: $Pr(A) = 1$ means when event A occurs, the probability is 1. Exp3: $Pr(A \\cap B) = Pr(A) × Pr(B)$ when events A and B are independent. What is Random Variable? We use capital letters to denote the random variable We use a small letter to denote a particular outcome of the experiment $P(X=x)$ means the probability of the occurs for value x. Here $P(X=x)$ is a number, the $P(X)$ is a distribution. Example Event = [Cloud, Cloud, Rain] In this Weather event P(X), it the probability of: Cloud: $P(X=Cloud) = \\frac{2}{3}$. Rain: $P(X=Rain) = \\frac{1}{3}$ Sun: $P(X=sun) = 0$ The random variable we used in the example above is Discrete random variable, but sometimes we have to use continues random variable. For example: $X \\in R$ (the set of all positive real numbers) Because we have two types of random variable, the function for calculating the sun of all possible variables are different: Probability Mass Function (pmf): For discrete random variable If X is a discrete random variable, then P(X) is its probability mass function (pmf). A probability mass is just a probability. P(X=x) = Pr(X=x) is the just the probability of the outcome X = x Thus: $0 \\leqslant P(X=x)$ $ 1 = \\sum _x{P(X=x)}$ Probability Density Function (pdf): If X is a density random variable, then P(x) is its probability density function (pdf). A probability density is NOT a probability. Instead, we define it as a density $P(X=x) = \\frac{d}{dx} Pr(X \\leqslant x)$ $0 \\leqslant P(X=x)$ $ 1 = \\int_{-\\infty}^\\infty {P (X=x)dx}$ Jointly Random Variables Two or three random variables are “jointly random” if they are both outcomes of the same experiment. For example, here are the temperature (Y, in °C), and precipitation (X, symbolic) for six days in Urbana: Date X=Temperature (°C) Y=Precipitation January 11 4 cloud January 12 1 cloud January 13 -2 snow January 14 -3 cloud January 15 -3 clear January 16 4 rain For this table, we could have joint random variables P(X=x, Y=y): P(X=x,Y=y) snow rain cloud clear -3 0 0 1/6 1/6 -2 1/6 0 0 0 1 0 0 1/6 0 4 0 1/6 1/6 0 Notation: Vectors and Matrices A normal-font capital letter (X) is a random variable, which is a function mapping from the outcome of an experiment to a measurement A normal-font small letter (x) is a scalar instance A boldface small letter (x) is a vector instance A boldface capital letter (X) is a matrix instance P(X=x) is the probability that random variable X takes the value of the vector x. This is just a shorthand for the joint distribution of x1, x2, …, xn When X is a random matrix Marginal Distributions Suppose we know the joint distribution P(X,Y). We want to find the two marginal distributions P(X): If the unwanted variable is discrete, we marginalize by adding: $P(X) = \\sum_ y P(X,Y=y)$ If the unwanted variable is continuous, we marginalize by integrating: $P(X) = \\int P(X,Y=y)$ Backing the table above, we could know that the marginal distributions of: P(X) = 1/6 + 1/6 = 1/3; 1/6; 1/6; 1/6 + 1/6 = 1/3 P(Y) = 1/6; 1/6; 1/6 + 1/6 + 1/6 = 1/2; 1/6 PS: Some place also write P(X) as PX(X) or PX(i) and P(Y) as PY(Y) or PY(j). Joint and Conditional distributions With the joint possibility and marginal possibility, we could now calculating the Joint and Conditional distributions, which is P(Y|X) P(Y|X) is the probability (or pdf) that Y = y happens, given that X = x happens, over all x and y. This is called the conditional distribution of Y given X. P(X|Y) is the conditional probability distribution of outcomes P(X=x|Y=y) The conditional is the joint divided by the marginal: $P(X=x|Y=y) = \\frac{P(X = x, Y = y)}{P(Y= y)}$ Exp of Joint and Conditional Distribution *P(X|Y = cloud)* $P(X|Y=could) = \\frac{P(X, Y = y)}{P(Y = cloud)}$ $=\\frac{\\frac{1}{6}\\ \\ 0\\ \\ \\frac{1}{6}\\ \\ \\frac{1}{6}}{\\frac{1}{2}}$ So, the result is a vector = {1/3, 0, 1/3, 1/3} According to the example, we could know that: Joint = Conditional×Marginal; which is: $$ P(X,Y) = P(X|Y)P(Y) $$ Independent Random Variables Two random variables are said to be independent, which means P(X|Y) = P(X) In other words, knowing the value of Y tells you nothing about the value of X. According to this, we can also know: $\\because$ P(X,Y) = P(X|Y)P(Y) $\\therefore$ P(X,Y) = P(X)P(Y) Pr(A⋀B) = Pr(A)Pr(B) Expectation The expected value of a function is its weighted average, weighted by its pmf or pdf. For discrete X and Y: $ E[f(X, Y)] = \\sum_{x,y} f(x, y)P(X = x, Y = y) $ If X is continuous: $ E[f(X, Y)] = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} f(x, y)P(X = x, Y = y) ,dx,dy $ Covariance The covariance of two random variables is the expected product of their deviations: $$ Covar(X,Y) = E[(X- E[X])(Y-E[Y])] $$ ( E[X] ) is the expected value (or mean) of the random variable X. ( E[Y] ) is the expected value (or mean) of the random variable Y. ( X - E[X] ) is the deviation of X from its mean (how far X is from its mean). ( Y - E[Y] ) is the deviation of Y from its mean (how far Y is from its mean). ( E\\left[(X - E[X])(Y - E[Y])\\right] ) is the expected value of the product of these deviations. Example Suppose we have two random variables, X and Y, with the following values: X: 1, 2, 3 Y: 2, 3, 4 First, we calculate the $E[X]$ and $E(Y)$: $E[X] = \\sum_{i=i}^3 f(x_i)P(x_i) = 1×\\frac{1}{3}+ 2×\\frac{1}{3}+3×\\frac{1}{3} = 2$ $E[Y] = \\sum_{i=i}^3 f(y_i)P(y_i) = 2×\\frac{1}{3}+ 3×\\frac{1}{3}+4×\\frac{1}{3} = 3$ PS: $E[X] = mean(X)$ because when we calculating them through the whole list, we would count them one by one even though they are duplicated. In this case, if one element for example, the frequent of the x in X is 50% and the lenghth of the X is 10, we list x 5 times as the frequent of 1/10 equals doing one time by $x * \\frac{1}{2}$ Next, we calculate the deviations of each value from their means: Deviations for $X-E[X] = [1-2, 2-2, 3-2] = [-1, 0, 1]$ Deviations for $Y-E[Y] = [2-3, 3-3, 4-3] = [-1, 0, 1]$ Now we multiply these deviations pairwise and sum them up: $ (-1 \\times -1) + (0 \\times 0) + (1 \\times 1) = 1 + 0 + 1 = 2 $ Since we have three observations, we divide the sum by 3-1 (in the case of sample covariance) or simply by 3 (if we are dealing with a population). So, if we treat these as a population, the covariance is: Covar$(X, Y) = \\frac{2}{3}$ This positive value suggests that X and Y tend to increase together. for python code: import numpy as npfrom collections import CounterX = np.array([1, 2, 3, 4, 4, 6])Y = np.array([1, 2, 3, 3, 5, 6])(X - X.mean()) @ (Y - Y.mean()) / (len(X))X = np.array([1, 2, 3, 4, 4, 6])Y = np.array([6, 5, 4, 3, 2, 1])(X - X.mean()) @ (Y - Y.mean()) / (len(X)) 2.5556 -2.6665 In this case, the covariance &gt; 0 means it is positively associated, covariance &lt; 0 means X and Y are negative-associated. Covariance = 0 means they are not associated at all. Covariance Matrix: Suppose X = [X1, … , Xn] is a random vector. Its matrix of variances and covariances (a.k.a. covariance matrix) is In other places, the covariance equation are mostly write as: $$ Cov(X,Y) = \\frac{\\sum(X_i-\\bar{X})(Y_j-\\bar{Y})}{n} $$ We can expected that they are the same because mostly, we expected the mean value is the expected value for a random variable. \\ tokens\\ correctly\\ classified}{n\\ tokens\\ total}$ Error Rate Equivalently, we could report error rate, which is just 1-accuracy: $Error Rate = \\frac{n\\ tokens\\ incorrectly\\ classified}{n\\ tokens\\ total}$ Bayes Error Rate The “Bayes Error Rate” is the smallest possible error rate of any classifier with labels “y” and features “x”: $Error Rate = \\sum_x P(X=x)\\underset{y}{min} P(Y \\neq y |x=x)$ It’s called the “Bayes error rate” because it’s the error rate of the Bayesian classifier The problem with accuracy In most real-world problems, there is one class label that is much more frequent than all others. Words: most words are nouns Animals: most animals are insects Disease: most people are healthy It is therefore easy to get a very high accuracy. All you need to do is write a program that completely ignores its input, and always guesses the majority class. The accuracy of this classifier is called the “chance accuracy.” It is sometimes very hard to beat the chance accuracy. If chance=90%, and your classifier gets 89% accuracy, is that good, or bad? The solution: Confusion Matrix: Confusion Matrix = • (m, n)th element is the number of tokens of the mth class that were labeled, by the classifier, as belonging to the nth class. © Aniruddha Bhandari Confusion matrix for a binary classifier Suppose that the correct label is either 0 or 1. Then the confusion matrix is just 2x2. For example, in this box, you would write the # tokens of class 1 that were misclassified as class 0 Than, you got TP (True Positives), FN (False Negatives), FP (False Positives), and TN (True Negative) The binary confusion matrix is standard in many fields, but different fields summarize its content in different ways. In medicine, it is summarized using Sensitivity and Specificity. In information retrieval (IR) and AI, we usually summarize it using Recall and Precision. Specificity and Sensitivity Specificity = True Negative Rate (TNR): $TNR = P(f(X) =0|Y=0) = \\frac{TN}{TN+FP}$ Sensitivity = True Positive Rate (TPR): $TRP = P(f(X) =1|Y=1) = \\frac{TP}{TP+FN}$ Precision: $P=P(Y =1|f(x)=1)=\\frac{TP}{TP+FP}$ Recall: Recall = Sensitivity = TPR: $R = TRP = P(f(X) =1|Y=1) = \\frac{TP}{TP+FN}$ Training Corpora Training vs. Test Corpora Training Corpus: a set of data that you use in order to optimize the parameters of your classifier (for example, optimize which features you measure, how you use those features to make decisions, and so on). Test Corpus: a set of data that is non-overlapping with the training set (none of the test tokens are also in the training dataset) that you can use to measure the accuracy. Measuring the training corpus accuracy is useful for debugging: if your training algorithm is working, then training corpus accuracy should always go up. Measuring the test corpus accuracy is the only way to estimate how your classifier will work on new data (data that you’ve never yet seen). Accuracy on which corpus? Large Scale Visual Recognition Challenge 2015: Each competing institution was allowed to test up to 2 different fully-trained classifiers per week. One institution used 30 different e-mail addresses so that they could test a lot more classifiers (200, total). One of their systems achieved &lt;46% error rate – the competition’s best, at that time. Is it correct to say that that institution’s algorithm was the best? Training vs. development test vs. evaluation test corpora Training Corpus: a set of data that you use in order to optimize the parameters of your classifier (for example, optimize which features you measure, what are the weights of those features, what are the thresholds, and so on). Development Test (DevTest or Validation) Corpus: a dataset, separate from the training dataset, on which you test 200 different fully-trained classifiers (trained, e.g., using different training algorithms, or different features) to find the best. Evaluation Test Corpus: a dataset that is used only to test the ONE classifier that does best on DevTest. From this corpus, you learn how well your classifier will perform in the real world. Summary Bayes Error Rate: $$ Error Rate = \\sum_x P(X=x)\\underset{y}{min} P(Y \\neq y |x=x) $$ Confusion Matrix, Precision &amp; Recall (Sensitivity) $$P=P(Y =1|f(x)=1)=\\frac{TP}{TP+FP}$$ $$R = TRP = P(f(X) =1|Y=1) = \\frac{TP}{TP+FN}$$ Training Corpora pre { background-color:#38393d; color: #5fd381; }","link":"/2024/01/26/LearnNotes/ai-probability/"},{"title":"Binomial Distribution | Introduction and examples","text":"What Is Binomial Video tutorial: Wrath of Math, 2017, YouTube Binomial is a simplistic polynomial. It has two terms, which could be numeral, variable, or combined element. for example: $3x +4$ $x+5$ $x^2 + 5x$ As you can see, they are all binomials. What Is Binomial Experiment A binomial experiment is a statistical experiment that has the following properties: The experiment consists of n repeated trials. Each trial can result in just two possible outcomes. We call one of these outcomes a success and the other, a failure. The probability of success, denoted by P, is the same on every trial. The trials are independent; that is, the outcome on one trial does not affect the outcome on other trials. Cite: Stat Trek[1] For example, the experiment about flipping a coin and counting the probabilities of each side. Binomial Distribution A binomial random variable is the number of successes x in n repeated trials of a binomial experiment. The probability distribution of a binomial random variable is called a binomial distribution. [1:1] For example, when we flip a coin two times, We can have the results: Result Probability Head * 2 25% Head, Tail 50% Tail * 2 25% $$ b(x; n, P) = C_{n}^{x} * P^ x (1 - P)^{(n - x)} $$ $$ C_{n}^{x} = \\frac{ n!}{ x! (n - x)! } $$ The properties of the Binomial Distribution: The mean of the distribution $μx$ is equal to $n \\times P$ . The variance $σ2x$ is $nP( 1 - P) $. The standard deviation $σx$ is $\\sqrt{nP( 1 - P ) }$. AND $x$: The number of successes that result from the binomial experiment. $n$: The number of trials in the binomial experiment. $P$: The probability of success on an individual trial. $Q$: The probability of failure on an individual trial. (This is equal to 1 - P.) $n!$: The factorial of n (also known as n factorial). $b(x; n, P)$: Binomial probability - the probability that an $n$ trial binomial experiment results in exactly $x$ successes, when the probability of success on an individual trial is $P$. $C_n^x$: The number of combinations of $n$ things, taken $x$ at a time. Cite: Stat Trek[1:2] Example 1: Suppose a die is tossed 5 times. What is the probability of getting exactly 2 fours?[1:3] So, we have 5 times, which means $n = 5$; We need exactly four * 2, which means $x = 2$; The probability of a single trial is 1/6, which give $P = 1/6$ According to the function above, we can have: $b(2; 5, 1/6) = C_{5}^{2} * (1/6)^ 2 (1 - (1/6))^{(5 - 2)}$ In R, we can calculate the binomial with the function dbinom as dbinom(2, 5, 1/6). Now we have the results: $b(2; 5, 1/6) = 0.160751$ Example 2: $b(x; n, P) = \\frac{ n!}{ x! (n - x)!} \\times P^ x (1 - P)^{(n - x)}$ Let’s back to the coin. When we flip it once, and the chances of Head is obviously 50%. Which is: $b(1; 1, 1/2) = \\frac{ 1!}{ 1! (1 - 1)!} * 0.5^ 1 (1 - 1)^{(1 - 1)}$ $b(1; 1, 1/2) = 1 * 0.5 * 1$ $b(1; 1, 1/2) = 0.5$ When we flip it twice, we can have 4 results: HH, HT, TH, TT the chance we have only one head is dbinom(1, 2, 1/2), which is 50%. (HT, TH) the chance we have two heads is dbinom(2, 2, 1/2), which is 25%. (HH) the chance we have heads from 0 to all is: 0.25, 0.5, 0.25, which means $1: 2:1$ Now, let’s try to flip it triple times, so we have 8 results: HHH, HHT, HTH, THH HTT, THT, TTH, TTT one head: HTT, THT, TTH: $3/8 = 0.375$ $b(1; 3, 1/2) = \\frac{ 3!}{ 1! (3 - 1)!} \\times 0.5^ 1 (1 - 0.5)^{(3 - 1)}$ $b(1; 3, 1/2) = 3 \\times 0.5 \\times 0.25$ $b(1; 3, 1/2) = 0.375$ two head: HHT, HTH, THH: $3/8 = 0.275$ $b(2; 3, 1/2) = \\frac{ 3!}{ 2! (3 - 2)!} \\times 0.5^ 2 (1 - 0.5)^{(3 - 2)}$ $b(2; 3, 1/2) = 3 \\times 0.25 \\times 0.5$ $b(2; 3, 1/2) = 0.375$ the chance we have head from 0 to all is: 0.125, 0.375, 0.375, 0.125, which means $1:3:3:1$ With the increase of the flipping number to 10, for instance, we can have the ratio: for( n in c(1:10)){ Result = c() for(x in c(0:n)){ Result = c(Result, dbinom(x, n, 1/2)/ dbinom(0, n, 1/2)) } print(Result)} 1 1 1 1 2 1 1 3 3 1 1 4 6 4 1 1 5 10 10 5 1 1 6 15 20 15 6 1 1 7 21 35 35 21 7 1 1 8 28 56 70 56 28 8 1 1 9 36 84 126 126 84 36 9 1 1 10 45 120 210 252 210 120 45 10 1 // 基于准备好的dom，初始化echarts实例 var myChart = echarts.init(document.getElementById('echarts6660')); // 指定图表的配置项和数据 var option = option = { xAxis: { type: 'category', name: 'Concentration of the Substrate (S)', nameLocation: \"middle\", nameTextStyle: {fontSize: 25, padding: [10, 0, 0, 0] , }, data: [0,1,2,3,4,5,6,7,8,9,10,11] }, yAxis: { type: 'value', name: \"Velacity (V0)\", max: 330 , nameLocation: \"middle\", nameTextStyle: {fontSize: 25, padding: [0, 0, 10, 0] , }, }, legend: { data: ['n = 10', \"n = 7\"] }, series: [{ name: 'n = 10', smooth: true, areaStyle: {}, data: [1, 10, 45, 120, 210, 252, 210, 120, 45, 10, 1], type: 'line', }, { name: 'n = 7', smooth: true, areaStyle: {}, data: [1, 7, 21, 35, 35, 21, 7, 1], type: 'line', } ] }; // 使用刚指定的配置项和数据显示图表。 myChart.setOption(option); Poisson theorem[2] When The $n$ is infinite large, we can have: $$ \\lim_ {n \\to \\infty} C_ n ^x P^ x (1 - P)^{(n - x)}, x = 0, 1, 2, … $$ Let’s say, $nP = \\lambda $ When the $n$ is very large and the $P$ is infinite small, we can have: $$ C_ n ^x P^ x (1 - P)^{(n - x)} \\approx \\frac{\\lambda ^ x}{x!} e^ {-\\lambda} $$ I have no idea how it works. So, I’m gonna stopping here. Stat_Trek, Binomial Probability Distribution ↩︎ ↩︎ ↩︎ ↩︎ 蔡高玉, 2016, 浅谈二项分布及其应用, 《考试周刊》 2016年A5期 期刊 ↩︎","link":"/2021/04/08/LearnNotes/binomial/"},{"title":"Stem Cells: An Insider&#39;s Guide","text":"Stem Cells: An Insider’s Guide Author: Paul Knoepfler Just as the name of this book, it more reads like a guide, or, a collection of well-sorted and organized blog posts. It does not mean it is informal. It just this book much similar to the free-style of texts on the internet. You can really read it without too much of, like when you have to concentrate and being critical to read a paper or a STEM textbook, to read. The author noticed that there are lots of steroid-type or prejudice opinions on stem cells most contributed to the commercial-advertises of stem cell therapy, though its potentials and probabilities are worth it. So, for correcting the name of the stem cells, Dr. Paul Knoepfler from U.C. Davis gave his opinions and advice on how people should, especially non-specialists and people who are the potential of stem cell treatment patients, respond to this area, for example, how to acquire more information to do self-teaching, should they take this therapy, how can companies make tricks and lies to dramatize it, what kind of results are they come with, and most importantly, how this industry works so people can understand that the result may not fit their expectation very well.","link":"/2021/01/17/LearnNotes/books_stemcell_ig/"},{"title":"Advanced Mathematics 1","text":"集合 交并补 Latex Math symbols 交: $A \\cap B={x| x \\in A\\ and\\ x \\in B }$ 并: $A \\cup B={ x| x \\in A\\ or\\ x \\in B }$ 补: $A-B={x|x \\in A\\ and\\ x \\notin B } = A \\cap \\overline{B} $ 基础运算 交换律: $A \\cap B = B \\cap A; A \\cup B = B \\cup A$ 结合律: $A \\cap (B \\cap C) = (A \\cap B) \\cap C; A \\cup (B \\cup C) = (A \\cup B) \\cup C$ 分配率: $A\\cap(B \\cup C)=(A \\cap B) \\cup (A \\cap C); A \\cup (B \\cap C)=(A \\cup B)\\cap(A \\cup C)$ 对偶律, De Morgan’s laws: $\\overline{ A \\cap B} = \\overline{A} \\cup \\overline{B}; \\overline{ A \\cup B} = \\overline{A} \\cap \\overline{B}$ 吸收率: $A\\cup(A\\cap B) = A; A \\cap(A \\cup B) = A$ 幂等律: $A\\cup A = A; A \\cap A = A$ $0-1$律: $A \\cup \\varnothing = A; A \\cap \\varnothing = \\varnothing; A \\cup X = X; A \\cap X = A$ 对合律: $\\overline{\\varnothing}=X; \\overline{X} = \\varnothing; A \\cap \\overline{A} = \\varnothing; \\overline{\\overline{A}} = A$","link":"/2021/03/19/LearnNotes/class-math1/"},{"title":"Birds Ig","text":"Specific in Birds Until 2024/5/23, the only annotated bird in IMGT is Chicken. According to the IMGT, chicken heavy chain gene has only 1 functional V gene , 3 functional D genes, and 1 J gene. This is hugely difference from human or other mammals. Birds have three classes of antibody: IgM (the only class in all vertebrates), IgY, and IgA. Not been directly determined but inferred from size estimates of the intact molecules of IgM and IgA, they could form polypeptide chains[1]. In addition, ducks have a smaller form of IgY, called IgY (ΔFc). IgM is the only class of antibody that is found in all vertebrate. IgM is larger than that of a true tetrameric IgM, such as occurs in teleost fish[2] and thus both are likely to be pentameric. IgY is the major low-molecular weight form of antibody found circulating in birds, where it has sometimes been referred to as IgG. An IgY-like molecule is likely to have been the evolutionary precursor of both IgG and IgE immunoglobulins[3][4]. Chicken The first avian genomic MHC map was the chicken minimal and essential one on chromosome 16. This map, spanning 92 kb and harboring 19 genes, was then extended to be 242 kb containing 46 genes[5][6]. Chicken (Gallus gallus) IGH locus on chromosome 31 The chicken (Gallus gallus) IGH locus is on chromosome 31. The orientation of the locus is reverse (REV). The chicken (Gallus gallus) IGH locus spans 116 kilobases (kb), from 10 kb upstream of the most 5’ gene in the locus, IGHV1-83 §, to 10 kb downstream of the most 3’ gene in the locus, IGHJ (F). The Locus representation encompasses 120 kb. The chicken (Gallus gallus) IGH locus consists of 94 IGHV genes belonging to 1 IGHV subgroup, 4 IGHD belonging to 1 IGHD set, 1 IGHJ gene belonging to 1 IGHJ set and 3 IGHC genes. The IGHV genes span 97 kilobases (kb), the IGHD genes span 7251 bases (b) and the IGHJ gene span 12 kilobases (kb). source: Imgt https://www.imgt.org/ligmdb/view?id=IMGT000014 The generation of antibody binding-site diversity is very well understood for the chicken: Parvari R, Avivi A, Lentner F, Ziv E, Tel-Or S, Burstein Y, et al. Chicken immunoglobulin gamma-heavy chains: limited VH gene repertoire, combinatorial diversification by D gene segments and evolution of the heavy chain locus. EMBO J. 1988;7:739–44. Reynaud CA, Anquez V, Dahan A, Weill JC. A single rearrangement event generates most of the chicken immunoglobulin light chain diversity. Cell. 1985;40:283–91. Reynaud CA, Anquez V, Grimal H, Weill JC. A hyperconversion mechanism generates the chicken light chain preimmune repertoire. Cell. 1987;48:379–88. Reynaud CA, Dahan A, Anquez V, Weill JC. Somatic hyperconversion diversifies the single Vh gene of the chicken with a high incidence in the D region. Cell. 1989;59:171–83. Duck The newest Duck genome is available at BMC: Jiaxiang Hu, et al; 2024[7]. The old one ZJU1.0[8] has (GCF_015476345.1) 33 chromosomes (not included sexual and mitochondira). For the SKLA1.0 (GCA_037218355.1), it covers 40 chromosomes (included in Z chromosome). For the ZJU1.0, they used 115 SMRT cells were sequenced with PacBio RS II. In SJKA1.0, they integrated Nanopore, Bionano, and Hi-C data. It also contains a complete genomic map of the MHC. In E. W´ojcik and E. Smalec’s work in 2017[9], they described 1-13 autosomes. In there karyotyping analysis result, the got about 84 dots for Anas platyrhynchos. © E. W´ojcik; 2017 Anseriform birds (ducks and their relatives) are the closest relatives of the chickens which was well understood and be studied. Ducks have the same hematopoietic tissues as chickens, including bone marrow, gut associated lymphoid tissue, spleen, thymus and the Bursa of Fabricius, a specialized organ for B lymphoid development. However, there is one notable difference. Ducks have lymph nodes, which are completely absent in chickens[10]. a single functional rearrangement of the variable (V) region, like chicken. generate diversity through gene conversion from a pool of pseudogenes. V region element and the pseudogenes appear to consist of a single gene family (The same as the Chicken) Further analysis of 26 heavy chain joining (JH) and 27 light chain JL segments shows there is use of a single J segment in ducks. From: Lundqvist M L, et al.[1:1] The overwhelming evidence is that all birds express only a single class of immunoglobulin light (L) chain[11][12] most closely related to the λ chain of the mammals [13][14]. The suggestion of additional classes of L chain in the birds [15] has not been substantiated at the amino acid sequence or genetic level. Duck IgY Ducks IgY: secreted form a receptor form with a hydrophobic membrane-spanning C-terminus truncated form termed IgY(ΔFc) Difference and similarities in other species: No truncated form: Chickens express only the full-length and membrane-receptor forms of IgY[3:1]. Has truncated form: A small form of IgY (5.7S) is produced by some species of turtles[16]. Duck immune response inept: lacking: precipitation, agglutination, complement fixation and opsonization[17][18] (related the lacks an Fc region). Duck IgA IgA has been described to date only in mammals and birds secretions of the gut, respiratory and reproductive tracts, as well as in tears, bile and (in mammals) the milk IgA of mammals is typically a dimer. Duck IGH: a single family of VH sequences a single expressed JH element JH is immediately downstream of a D segment Duck IGL: there are few functional coding VL and JL elements in the germline diversification most likely arises in large measure from gene conversion events from an extensive suite of germline VL-related sequences; (Genomic Southern blot analysis showed that there is a large family of germline VL-related sequences in the mallard duck[11:1]) It is not known whether there is a single functional V and J element in the duck L chain locus, however, that is the simplest explanation of the results. muscovy duck were at least two functional VL genes[19]. a single family of VL sequences pre { background-color:#38393d; color: #5fd381; } Lundqvist M L, Middleton D L, Radford C, et al. Immunoglobulins of the non-galliform birds: antibody expression and repertoire in the duck[J]. Developmental &amp; Comparative Immunology, 2006, 30(1-2): 93-100. ↩︎ ↩︎ Leslie GA, Clem LW. Phylogeny of immunoglobulin structure and function. 3. Immunoglobulins of the chicken. J Exp Med. 1969;130:1337–52. ↩︎ Parvari R, Avivi A, Lentner F, Ziv E, Tel-Or S, Burstein Y, et al. Chicken immunoglobulin gamma-heavy chains: limited VH gene repertoire, combinatorial diversification by D gene segments and evolution of the heavy chain locus. EMBO J. 1988;7:739–44. ↩︎ ↩︎ Magor KE, Higgins DA, Middleton DL, Warr GW. One gene encodes the heavy chains for three different forms of IgY in the duck. J Immonol. 1994;153:5549–55. ↩︎ Kaufman J, Milne S, Göbel TW, Walker BA, Jacob JP, Auffray C, et al. The chicken B locus is a minimal essential major histocompatibility complex. Nature. 1999;401:923–5. ↩︎ Shiina T, Briles WE, Goto RM, Hosomichi K, Yanagiya K, Shimizu S, et al. Extended gene map reveals tripartite motif, C-type lectin, and Ig superfamily type genes within a subregion of the chicken MHC-B affecting infectious disease. J Immunol. 2007;178:7162–72. ↩︎ Hu J, Song L, Ning M, et al. A new chromosome-scale duck genome shows a major histocompatibility complex with several expanded multigene families[J]. BMC biology, 2024, 22(1): 31. ↩︎ Li J, Zhang J, Liu J, et al. A new duck genome reveals conserved and convergently evolved chromosome architectures of birds and mammals[J]. Gigascience, 2021, 10(1): giaa142. ↩︎ Wójcik E, Smalec E. Constitutive heterochromatin in chromosomes of duck hybrids and goose hybrids[J]. Poultry Science, 2017, 96(1): 18-26. ↩︎ Flajnik MF, Miller KM, Du Pasquier L. Evolution of the immune system. In: Paul WE, editor. Fundamental immunology. 5th ed. Philadelphia: Lippincott Williams and Wilkins; 2003. p. 519–70. ↩︎ Magor KE, Higgins DA, Middleton DL, Warr GW. cDNA sequence and organization of the immunoglobulin light chain gene of the duck, Anas platyrhynchos. Dev Comp Immunol. 1994;18:523–31. ↩︎ ↩︎ Reynaud CA, Dahan A, Weill JC. Complete sequence of a chicken lambda light chain immunoglobulin derived from the nucleotide sequence of its mRNA. Proc Natl Acad Sci USA. 1983;80:4099–103. ↩︎ Grant JA, Sanders B, Hood L. Partial amino acid sequences of chicken and turkey immunoglobulin light chains. Homology with mammalian lambda chains. Biochemistry. 1971;10:3123–32. ↩︎ Kubo RT, Rosenblum IY, Benedict AA. The unblocked N-terminal sequence of chicken IgG lambda-like light chains. J Immunol. 1970;105:534–6. ↩︎ Leslie GA. Evidence for a second avian light chain isotype. Immunochemistry. 1977;14:149–51. ↩︎ Leslie GA, Clem LW. Phylogeny of immunoglobulin structure and function, VI. 17S, 7.5S and 5.7S anti-DNP of the turtle, Pseudamys scripta. J Immunol. 1972;108:1656–64. ↩︎ Grey HM. Duck immunoglobulins. II. Biologic and immunochemical studies. J Imunol. 1967;98:820–6. ↩︎ Humphrey BD, Calvert CC, Klasing KC. The ratio of full length IgY to truncated IgY in immune complexes affects macrophage phagocytosis and the acute phase response of mallard ducks (Anas platyrhynchos) Dev Comp Immunol. 2004;28:665–72. ↩︎ McCormack WT, Carlson LM, Tjoelker LW, Thompson CB. Evolutionary comparison of the avian IgL locus: combinatorial diversity plays a role in the generation of the antibody repertoire in some avian species. Int Immunol. 1989;1:332–41. ↩︎","link":"/2024/05/23/LearnNotes/birdig/"},{"title":"Principles of Biochemistry 1 |Chiral, Orbital| Class Notes |HarvardX","text":"Unit 1, introduction Course in Edx Why so much carbon is needed for organism It is facility for organism use one molecule for versatility of functions. Carbon can build different shape and geometry of molecules: linear chain branched chain cyclical structure Structure diversity leads to functional diversity. Carbon’s versatility hybrid orbital © courses.lumenlearning.com3 barbell shape orbital of carbon: 2px, 2py, 2pz There are 2 shells for Carbon. 1s and 2s. In 2s, there is an inner subshell, 2s/2ns, 3 orbital in outer subshell, 2px, 2py, and 2pz More for Carbon electron orbital: Chemical Assignment © chemistry-assignment.com Ground state: 6C: $1s2\\ |\\ 2s2\\ |\\ 2px1\\ |\\ 2py1\\ |\\ 2pz0$ $sp^3$-Hybridization: 6C: $1s2\\ |\\ 2s1\\ |\\ 2px1\\ |\\ 2py1\\ |\\ 2pz1$; ($2pz1$ from $2s$) $sp^2$ Hybridization: 6C: $1s2\\ |\\ sp^23\\ |\\ 2px0\\ |\\ 2py0\\ |\\ 2pz1$; ($sp^23$ comes from $2s1\\ |\\ 2px1\\ |\\ 2py1$) $sp$-Hybridization: 6C: $1s2\\ |\\ sp2\\ |\\ 2px0\\ |\\ 2py1\\ |\\ 2pz1$ Ground state In Ground state, there are two electrons unpaired orbiting in 2p and leaving the 3sd unoccupied orbital 2pz. And this how Covalent Bond formed: one orbital for each atom carrying an unpaired electron. Hence that, carbon can only from two covalent bonds. Exited state The electron in carbon can shift around and so, one electron from 2s promoted into 2spz orbital, to form 4 unpaired electrons. sp3-Hybridization: Mathane (CH4) $sp^23 = 2s1+2px1+2py1$ 4 unpaired electrons are unstable since the orbitals are not identity. So, they have to went through a process name as hybridization to form $sp^3$ orbital. The newly formed $sp^3$ orbital has 25% s character and 75% of p character. For forming a methane, they apart from each other as they can and forming four identical $190.5^{\\circ}$ from each other. Which is a tetrahedron. © chemistry-assignment.com sp2-Hybridization: ethylene (C2H4) $sp^2 3= 2s 1 + 2p 2 $ © chemistry-assignment.com $sp^2$ has 33% s character and 67% p character and arranged in Trigonal Planar structure. $120^{\\circ}$ apart from each other. The remaining $2pz$ orbital (Unhybridised 2p-orbital illustrate in the image above.) is orthogonal to the plane containing the $sp2$ orbitals. ~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ © chemistry-assignment.com To Make a ethylene, 2 $sp^2$ orbit fuse head to head form a $\\sigma$ covalent.The sideways overlap of the $2pz$ orbits, lead to the formation of new covalent boned called $\\pi$ bond between two carbons. Remainning $4*sp2$ orbitals covalent with $H^+$ to form 4 carbon hydrogen bonds.The electrons involved in $\\pi$ bond occupy a ring shape space circulate the $\\sigma$ bond. $\\sigma$: sigma sp-Hybridization: acetylene (C2H2) $sp2 = 2s+ 2px$ © chemistry-assignment.com ~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ © chemistry-assignment.com $sp$ orbital are $180^{\\circ}$ from each otherOther two unpaired electrons are remain on $2py;\\ 2pz$ obirtals.Two $sp$ orbital come head to head to form a $\\sigma$ covalent bond.Sideways overlap between paires of 2p orbitals on each carbon lead the formation of 2 $\\pi$ bonds between carbons.Remainning $sp$ orbitals fuse with hydrogen to form 2 carbon hydrogen covalent bonds. The geometry and reactivity of the bonds Bond Length ($A$) Bond strength ($kcal/mol$) $\\Delta EN$ $C-H$ 1.09 99 0.4 $O-H$ 0.96 110 1.4 $N-H$ 1.02 84 0.9 $C=O$ 1.23 174 1 $C-C$ 1.54 88 0 $C=C$ 1.34 147 0 Shape: $O-H$ is shorter than $C-C$; Strength: $C-C$ stronger than $C=C$; Electronegativity: One electron has a stronger pull on the electrons. Configuration Isomers Single bond: enantiomer Molecule containing a chiral center could exist in different configurations. Double bond Maleix acid Fumaric acid Cis-configuration Trans-configuration As you can see the structure of Maleix acid and Fumaric acid above, they have the same composition but a different structure since the double bond blocked the free rotation of the $C-C$ axis. So, they have the different =configuration=, or =stereoisomers=. Significant Same composition with different configuration leads to functional diversity. exp: $( R)-Carvone$ and $(S)-Carvone$ bind different neural receptors in your nose. As a result, $( R)-Carvone$ leads to a fresh spearmint smell, but $(S)-Carvone$ leads to a pungent caraway smell. $R-Carvone$ $S-Carvone$ Structure Dynamic Two covalent bonds prohibited rotation. Though single covalent bond made rotation possible and it has infinite number of configurations in theory, majority of them are prefer to stay in a stable structure (low free energy state). Caffeine from PubChem: More reading materials about chiral: libretexts: 5.1: Chiral Molecules 3D models are embedded from molview.org","link":"/2021/03/19/LearnNotes/edx-biochm-1/"},{"title":"Acoustics","text":"Acoustics waveform, phase, amplitude (usually expressed in log units known as decibels, abbreviated dB), and frequency. For human listeners, the amplitude and frequency of a sound pressure change at the ear roughly correspond to loudness and pitch, respectively. Humans can detect sounds in a frequency range from about 20 Hz to 20 kHz. Most small mammals are sensitive to very high frequencies, but not to low frequencies. © Lars Chittka; Axel Brockmann Fragile X Syndrome (FXS) - Sensory Processing Deficits Introduction Definition: FXS is a neurodevelopmental disorder leading to intellectual disability. Link to Autism: Leading known genetic cause of autism. Sensory Processing in FXS General Characteristics: Abnormal sensory processing, particularly sensory hypersensitivity. Manifestations: Auditory, tactile, or visual defensiveness or avoidance. Clinical and behavioral studies show auditory hypersensitivity, impaired habituation to repeated sounds, and reduced auditory attention. Visuospatial Impairments: Significant deficits observed. Noted problems in processing texture-defined motion stimuli, temporal flicker, perceiving ordinal numerical sequences, and maintaining dynamic object identity during occlusion. Animal Models: Fmr1 KO Rodents General: Fragile X mental retardation 1 (Fmr1) gene knockout (KO) rodents used as FXS models. Findings: Seizures. Abnormal visual-evoked responses. Auditory hypersensitivity. Altered acoustic startle responses. Abnormal processing in the auditory system. Tactile Symptoms: Individuals with FXS show tactile defensiveness. Fmr1 KO mice have impaired tactile stimulation frequency encoding and larger receptive fields in the somatosensory cortex. Review Focus: Discusses clinical, functional, and structural studies on sensory processing deficits in FXS across: Auditory. (We only focus on Auditory in this note) Visual. Somatosensory domains. Significance of Animal Models: Observations in FXS humans and Fmr1 KO rodents are similar, suggesting conservation of basic sensory processing circuits across species. Offers a translational platform to develop biomarkers and understand underlying mechanisms. Conclusion: Emphasizes the value of pre-clinical studies in animal models of FXS. Belief: Understanding mechanisms in basic sensory processing circuits/behaviors can boost the search for new therapeutic approaches in FXS. Introduction Prevalence and Impact: intellectual disability, Link to Autism: One of the leading genetic causes. Statistics: Affects 1 in 4,000 boys and 1 in 8,000 girls. Genetic Origin: Gene Impacted: Fragile X mental retardation 1 (FMR1) gene. Causes: Silencing, Deletion, Loss-of-function mutation. Consequences: Results in the non-expression or nonfunctionality of the fragile X mental retardation protein (FMRP). About FMRP: Type: A messenger RNA (mRNA)-binding protein. Functions: Regulates several aspects of mRNA metabolism, including: Nuclear export. Transport to synaptic terminals. Activity-dependent ribosome stalling. Protein translation. FMRP’s Role in Synaptic Function and Translation Regulation Translation Regulation: FMRP regulates the translation of mRNAs at synapses. Some of these mRNAs encode proteins linked to synaptic plasticity. Impact of Absence of FMRP: Results in dysregulation of protein translation and increased protein synthesis. This may contribute to altered signaling of metabotropic glutamate receptor 5 (mGluR5). This altered signaling may lead to exaggerated long-term depression (LTD) in the hippocampus. Matrix Metalloproteinase-9 (MMP-9): FMRP negatively regulates MMP-9 translation in neurons because MMP-9 levels are elevated in FXS. mGluR5 and MMP-9 potentially mediate changes in synaptic functions. They might signal through the phosphatidylinositol-3-kinase (PI3K)/mammalian target of rapamycin complex 1 (mTORC1) and extracellular signal-regulated kinase pathways to amplify cap-dependent translation. Recent Data on FMRP: Suggests that FMRP might directly regulate PI3K and mTORC1 signaling. This regulation could occur through other signaling proteins like phosphatidylinositol-3-kinase enhancer, phosphatase and tensin homolog, neurofibromin 1, and tuberous sclerosis 2. FMRP Targets: All three isoforms of eukaryotic translation initiation factor 4 G. Eukaryotic translation elongation factor 1 and 2. Argonaute proteins. Dicer. Dysregulation of these targets might contribute to enhanced neuronal translation in FXS. Role of Dysregulated Pathways and FMRP in Dendritic Spine Morphology and Neurophysiology Dysregulated Pathways in FXS: Dysregulated PI3K/mTOR signaling. Enhanced mGluR5-dependent LTD. Increased MMP-9 activity. Reduced activity of the voltage and $Ca^{2+}$ activated ( K^+ ) (BKCa or BK) channel. These might contribute to the immature dendritic spine morphology in rodent models of FXS. FMRP’s Role in Mice: Might regulate neuronal branching. Regulates dendritic spine development. Clinical Studies in Humans: Alterations observed in dendritic spine number and morphology in the cortex of FXS humans. A notable prevalence of immature dendritic spines. Dendritic abnormalities are consistent anatomical features linked with intellectual disability. FMRP’s Predominant Activity: Mainly related to the regulation of synaptic functions. Yet, there’s limited knowledge about: How synaptic alterations due to the absence of FMRP lead to neurophysiological and behavioral deficits in humans with FXS. The reason why abnormal dendritic spine development alone doesn’t explain the increased cortical excitability seen in FXS. Using auditory reaction time to measure loudness growth in rats Abstract Introduction: Auditory Reaction Time (RT): Established as a reliable proxy for loudness perception in humans. Reaction Time-Intensity (RT-I) Functions: Effectively mirror equal loudness contours in humans. Easier to obtain than equal loudness judgments, particularly in animal subjects. Factors Affecting Loudness Estimation: Sound Intensity: Primary factor. Other Acoustic Factors: Stimulus duration. Bandwidth. Background Noise Effect: Simulates loudness recruitment. Rapid loudness growth near threshold, but stabilizes at suprathreshold levels. Study Objectives: Examine if RT-I functions can reliably measure loudness growth in rats. Obtain auditory RTs across varying: Stimulus intensities. Durations. Bandwidths. Experiments conducted in both quiet conditions and amidst background/masking noise. Findings: Reaction time patterns across different stimulus parameters: Repeated consistently over several months in rats. Generally align with human loudness perceptual data. Significance: Results lay foundational understanding for upcoming studies on loudness perception in animal models. Potential to explore loudness perceptual disorders in animals. Introduction Exploring Loudness Perception Beyond Traditional Methods Standard Tool: Pure Tone Audiogram: Essential for hearing research but limited in scope. Loudness Perception: Beyond hearing threshold, loudness perception for louder sounds is crucial. Clinical Metrics: Uses scales like ULL and LDL where listeners rate discomfort from various sound intensities. Human Psychophysical Studies: Equal loudness contours: Listeners compare sound loudness to a standard tone, a labor-intensive method. Measuring Loudness Perception in Animals Traditional Measures: LDLs and equal loudness contours: Useful for humans but impractical for animals. Auditory Reaction Time (RT): Used as an indirect metric of loudness in animals. In humans, a faster RT correlates with perceived loudness. Advantages of RT: Reliable for both normal-hearing and hearing-impaired listeners. Easier to obtain than traditional measures, making it useful for various species. Certainly! I’ll further condense and clarify the content: Loudness Perception Factors in Humans Intensity: Main determinant, but not the sole factor. Duration: Longer sounds (up to 300 ms) seem louder. Bandwidth: Wider bandwidths make sounds feel louder. Background Noise: Can mimic “loudness recruitment”, where sounds just above threshold feel quiet but get rapidly louder. Evaluating Reaction Time-Intensity (RT-I) Functions in Rats Objective: Check if RT-I in rats matches human patterns of perceived loudness. Method: Measured auditory RTs in rats for various: Intensities Durations Bandwidths Conducted in quiet and with background noise. Expectations: If rats and humans perceive loudness similarly: RTs should decrease as intensity, duration, and bandwidth increase. RTs should rise near the hearing threshold when background noise is present. Aims and Challenges in Developing an Animal Behavioral Model for Loudness Perceptual Disorders Primary Goal: Develop a behavioral model in animals to study loudness perceptual disorders, specifically loudness recruitment and hyperacusis. Challenges: Accounting for effects of drug or noise on hearing. E.g., High-dose salicylate can cause hearing loss, tinnitus, and possibly hyperacusis. Noise often leads to hearing loss, loudness recruitment, and potentially tinnitus and hyperacusis in some listeners. A successful model should distinguish: Loudness recruitment from hyperacusis. Hyperacusis from tinnitus. Tinnitus-like Percept Study: Effect of broadband noise vs. tonal masker on RTs was studied. Goal: Understand the influence of a “tinnitus-like” percept on loudness growth. Hypothesis: Tinnitus-like 16 kHz masker won’t affect RT-I functions for 4 kHz tones but might impact the loudness growth of 16 kHz tones. Stability of RTs in Rats: Beyond comparing rat RT-I functions to humans, the study aimed to test RT stability over time. This is crucial as animal psychoacoustic studies span weeks or months. A consistent loudness perception metric is needed, especially when no experimental manipulations are applied. Result Impact of Stimulus Duration on Auditory Reaction Time (RT) Experiment Setup: Reaction time-intensity (RT-I) functions were measured for broadband noise bursts (BBN) across three durations: 20 ms, 100 ms, and 300 ms. Main Findings: RTs for BBN decreased with rising stimulus intensity for all tested durations. Rats had quicker RTs (i.e., reacted faster) with longer stimulus durations. No significant interaction found between sound level and stimulus duration. Results imply rats perceived longer sounds as louder, similar to human perception. Detailed Results: RTs for 300 ms BBN were significantly faster than for 100 ms and 20 ms BBN. Significant differences were observed: Between 20 ms and 300 ms BBN across all sound levels. Between 100 ms and 300 ms BBN at specific dB levels: 40, 50, 60, and 80 dB SPL. Impact of Stimulus Bandwidth on Auditory Reaction Time (RT) in Rats Hypothesis: Wider band stimuli would sound louder (and thus induce faster RTs in rats) compared to narrower band or pure tone stimuli, based on human data. Key Findings: Rats reacted faster to stimuli with increased bandwidth, aligning with the hypothesis that wideband stimuli sound louder. Detailed Observations: RTs for Broadband Noise Bursts (BBN) were faster than for 16 kHz pure tones at most sound levels, excluding 30 dB SPL. RTs for BBN were also faster compared to 16–20 kHz Narrow Band Noise (NBN) for specific dB levels: 30, 40, 50, and 60 dB SPL. Conclusion: Just as with duration, these results indicate that RT is a reliable metric for loudness perception in rats, mirroring known human data on loudness perceptions of different bandwidth sounds. Effects of Background Noise on Loudness Perception in Rats Experiment Setup: Measured RT-I functions for Broadband Noise Bursts (BBN) in quiet and with low-level background noise (2-20 kHz, 60 dB SPL). Main Findings: In the presence of background noise, rats had: Slower RTs for lower intensity sounds. Regular RTs for higher intensity sounds. These patterns suggest the rats experienced recruitment-like perceptions in noise. As intensity increased just above threshold, RT decrease was sharper in noise than in quiet, aligning with loudness recruitment patterns. Background Noise Effects: Significant effects found on RTs for lower intensity stimuli when compared to quiet conditions. In particular, differences were noted at 30, 40, and 50 dB SPL BBN levels. This indicates that, like humans, rats experience a recruitment-like loudness growth in the presence of background noise. Effects of 16 kHz Masker: No recruitment-like effects on RTs for 4 kHz tones. Rats reacted slightly faster at 40 and 50 dB SPL tones with the 16 kHz masker. However, the effect might be due to task performance variability. For 16 kHz tones, the masker had a significant effect, especially at 60 dB SPL. This suggests that animals with tinnitus might show recruitment-like behaviors for sounds close to the tinnitus frequency. Discussion RT-I functions in rats align with established human loudness perception research, suggesting they’re a valid measure of rat loudness growth. Their consistency over four months indicates the RT-I approach reliably reflects loudness perception in rats. Key Findings on Noise Exposure and Hearing Loudness Recruitment: Noise and drugs can cause hearing loss. This loss can lead to “loudness recruitment,” where soft sounds seem quickly loud, but this doesn’t affect louder sounds. Using Rats to Understand Loudness: In our tests, rats exposed to background noise showed symptoms similar to loudness recruitment. Hyperacusis: This is when everyday sounds seem too loud. Certain studies, including ours, used reaction times to detect hyperacusis in animals. Our tests found that a high aspirin dose made rats more sensitive to certain sound levels. Noise Exposure’s Role: Extended noise exposure in rats caused both loudness recruitment and hyperacusis-like behaviors. Reaction Time-Intensity (RT-I) as a Model for Loudness Growth: Loudness Growth in Animals: Our RT-I conditioning model effectively maps loudness growth in animals. It can predict how noise or drug exposure influences loudness perception. Hyperacusis vs. Loudness Recruitment: Hyperacusis: Faster reaction times at moderate-high sound intensities. Loudness Recruitment: Regular reaction times at these intensities. Differentiating between tinnitus and hyperacusis is crucial. Studying Tinnitus: Prior studies on tinnitus using RT-I functions lacked comprehensive results. In our experiment, using a “tinnitus-like” background showed recruitment-like loudness growth for tones at tinnitus pitch. Other tones remained unaffected. Hyperacusis showed a different pattern than tinnitus. Thus, RT-I functions can potentially distinguish between the two. However, the overlap of tinnitus with hearing loss complicates this distinction. Conclusion and Future Directions: Auditory reaction time mirrors loudness perception both in rats and humans. RT-I functions can screen for hearing disorders in rats post noise/drug exposure. Our goal is to expand this model, compare it with human loudness contours, and integrate neural and biochemical measures in future studies. Testing the Central Gain Model: Loudness Growth Correlates with Central Auditory Gain Enhancement in a Rodent Model of Hyperacusis Abstract Central Gain Model of Hyperacusis Theory: Auditory input ↓ → Neuronal gain ↑ → Over-amplification &amp; loudness ↑. Study Objective Link: Sound-evoked activity changes ↔ Loudness perceptual alterations. Methodology Operant Conditioning Task: Measure: Loudness via auditory stimuli reaction time. Chronic Electrophysiological Recordings: Locations: Auditory cortex &amp; inferior colliculus (awake animals). Goal: Daily loudness perception ↔ Neurophysiological sound encoding. Salicylate-induced Model Purpose: Validate the paradigm. Effects of high sodium salicylate doses: Temporary hearing loss. Neural hyperactivity. Auditory disruptions (e.g., tinnitus, hyperacusis). Findings Salicylate effects: Alters: Loudness growth &amp; Evoked response-intensity. Results: Consistent with: Temporary hearing loss &amp; hyperacusis. Correlation: Loudness growth ↔ Sound-evoked activity (individual animals). Conclusion Strong support: Central gain model of hyperacusis. Value: Experimental design for within-subject comparison. Introduction part 1 Hyperacusis Definition: Auditory disorder where moderate sounds → intolerably loud/painful. Type: Common with sensorineural hearing loss. Central Gain Model (CGM) Concept: Maladaptive response in auditory system due to hearing loss. Mechanism: Central auditory system adjusts for hearing sensitivity. Dysregulation &amp; central auditory pathway over-amplification → normal sounds perceived as excessively loud. Support: Accounts for major hyperacusis features. Strong evidence backing. Validation Need: Relate central gain changes &amp; loudness perception. Human Imaging Findings: Hyperacusis patients → increased sound-evoked activity. Limitation: Can’t link neurophysiological changes &amp; hyperacusis development. Animal Models Advantage: Detailed hyperacusis examination. Findings: Hearing loss (due to noise/drugs) → central gain increase. Limitation: Between-group comparisons. Acute measurements from anesthetized subjects. → Focus on specific auditory areas. Few studies link central gain &amp; loudness. part 2 Challenges in Hyperacusis Study Direct Relationship Needs: Objective loudness perception indicators. Indicators should reflect both hearing loss &amp; hyperacusis in single animals. Inter-subject Variability: Hearing loss is a hyperacusis trigger but not a guaranteed outcome. Not all animals develop hyperacusis even under similar conditions. Loudness Perception Indicator: RT-I RT-I: Measures loudness growth via subject’s reaction time (RT) to varied sound intensities. Closely linked with human loudness growth &amp; equal loudness contours. Usage: Reflects loudness recruitment in hearing impaired humans &amp; animals. Captures hyperacusis-like changes (example: rats treated with sodium salicylate). Animal Models &amp; Hyperacusis Variability Need: Relate neural hyperactivity with hyperacusis-like behavior in each animal. Our Approach: Combine psychophysical &amp; electrophysiological methods. Track changes in both loudness perception &amp; sound-evoked activity longitudinally. Methodology Chronic Implants: Locations: Auditory cortex (AC) &amp; inferior colliculus (IC). Purpose: Monitor sound-evoked activity in awake animals &amp; avoid anesthesia issues. Benefit: Directly link sound encoding with daily loudness growth assessment per animal. Validation of Combined Approach Test: Effect of salicylate on RT-I &amp; neural activity in the same animals. Findings: Salicylate-induced changes in RT-I &amp; sound-evoked activity coexist in individual animals. Supports the central gain model. Validates the combined behavioral-electrophysiological paradigm. Result Stable behavioral and electrophysiological measures of loudness growth Experiment Overview Tested Animals: 8 rats. Procedure: Go/No-go operant conditioning paradigm. Electrodes chronically implanted in primary AC &amp; central nucleus of the IC. Observations LFP Tuning Curves: Well-tuned for frequency. AC &amp; IC electrodes matched for characteristic frequency in each hemisphere. Baseline RT-I &amp; LFP I/O Functions (broadband noise burst 30–90 dB SPL): RTs: Decreased from ~325 ms (30 dB SPL) to ~140 ms (90 dB SPL). AC I/O Functions: Amplitude increased from ~30 mV (30 dB SPL) to ~70 mV (90 dB SPL). IC I/O Functions: Amplitude grew from ~40 mV (30 dB SPL) to ~125 mV (90 dB SPL). Consistency: No significant differences observed across baseline sessions in RT-I, AC, or IC I/O functions. Conclusion: Behavioral &amp; electrophysiological responses are stable without any explicit manipulation. Salicylate-induced hyperacusis and hyperactivity Post-Baseline Testing with Sodium Salicylate (SS) Treatment Procedure: Animals received 200 mg/kg SS injection (i.p.). Assessments made 2 hours post-SS and again after 24 hours. Data Analysis: RTs &amp; AC/IC LFP amplitudes normalized to maximum average baseline values. Observations 2 Hours Post-SS: Low-Intensity Noise Bursts (30 dB SPL): RTs → Slower than baseline. AC/IC Amplitudes → Smaller than baseline. Interpretation: Cochlear hearing loss likely from SS-mediated ototoxicity. Moderate-to-High Intensities (70-90 dB SPL): RTs → Faster than baseline → Suggests sounds perceived louder (possible hyperacusis). AC/IC Amplitudes → Larger than baseline → Indicates enhanced central gain. Observations 24 Hours Post-SS: Both behavioral and electrophysiological changes observed at 2 hours post-SS were reversed. Likely due to drug washout. Salicylate-induced gain modulation Results Analysis Based on Fig. 2A-C Observation: SS alters loudness growth &amp; LFP responses. At low intensities: Slower RTs &amp; decreased LFPs. At high intensities: Faster RTs &amp; enhanced LFPs. Result: Steeper slope of response functions → Central gain theory hallmark. Response Gain Assessment - Approach 1: Fit RT-I &amp; AC/IC LFP response functions with linear regression. Check slope changes (normalized response/dB) due to SS. 2 hours post-SS: RT, AC, IC functions → Greater slopes than baseline. 24 hours post-SS: Slopes → No significant deviation from baseline. Response Gain Assessment - Approach 2: Transform baseline RT/AC/IC response function to post-SS equivalent. Scatter plots depict change in response magnitude at each intensity post-SS. Interpretation: Below 45° line → Decreased response post-SS. Above 45° line → Increased response post-SS. Scatter Plot Analysis: Plots fitted with linear regression (2 &amp; 24 hours post-SS). Slope (R Gain) describes magnitude of gain modulation by SS: ( R \\text{ Gain} &gt; 1 ) → Enhanced response gain. ( R \\text{ Gain} &lt; 1 ) → Decreased response gain. ( R \\text{ Gain} = 1 ) → No change in response gain. Key Findings: Baseline sessions: Response gain consistent across RT-I or AC/IC LFP functions. 2 hours post-SS: Slope &gt; 1 for RT, AC, IC → Increased response gain. More robust gain increase observed in AC than IC. 24 hours post-SS: Response growth rate reverted to baseline. Within-subject relationship between RT, AC and IC gain changes Results Analysis Based on Fig. 2 &amp; 3 Salicylate’s Effects: Alters response gain for RT and LFP I/O functions. Central gain enhancement linked with altered loudness perception. Individual Animal Analysis (Fig. 3): Animal with substantial RT-I alteration post-SS also had pronounced changes in AC/IC I/O functions. Animal with modest RT-I alteration post-SS exhibited minor changes in AC/IC I/O functions. RT-I &amp; AC/IC I/O functions reverted to baseline levels 24h post-SS in both cases. Subject-by-Subject Analysis: Behavioral &amp; electrophysiological changes due to salicylate are correlated within individual animals. Majority of subjects exhibited increased response gain (R G +) post-SS. RT-I function: 7/8 animals had significant change. AC I/O function: 6/8 animals had significant increase. IC I/O function: 5/8 animals had significant change. All gain changes reverted to baseline 24h post-SS. Hypothesis Testing: Correlation found between individual AC &amp; RT-I and between individual IC &amp; RT-I response gains. AC and RT-I gain changes showed close concordance in magnitude. Distinguishing Hyperacusis from Loudness Recruitment: Increase in response gain doesn’t necessarily indicate hyperacusis. Response gain doesn’t determine if responses overshoot baseline. Changes in loudness &amp; neural activity post-SS were significantly correlated. Decreased sensitivity to low-intensity sounds post-SS linked to response changes in AC and IC. Hyperacusis-like behavior at moderate-to-high intensities more correlated with cortical than subcortical response changes. Discussion Discussion: → Objective: Link hyperacusis &amp; central gain enhancement. Methods: Psychophysical-electrophysiological approach. Stable loudness &amp; auditory-evoked functions from animals. Assessed salicylate effects on RT-I &amp; AC/IC I/O. Findings: Salicylate: Alters RT-I &amp; AC/IC I/O → Suggests hearing loss &amp; hyperacusis. Loudness &amp; sound-evoked activity affected by salicylate are correlated. Significance: Supports central gain model of hyperacusis. Within-subject comparisons valuable; inter-subject variability is a strength. Mutations causing syndromic autism define an axis of synaptic pathophysiology Abstraction Topic: Tuberous sclerosis complex (TSC) &amp; fragile X syndrome (FXS): Genetic diseases with intellectual disability &amp; autism. Hypothesis: Cause: Mutations in genes regulating neuronal protein synthesis. Excessive protein synthesis might be a core mechanism for intellectual disability &amp; autism. Method &amp; Findings: Used: Electrophysiological &amp; biochemical assays in the hippocampus of Tsc2+/- and Fmr1-/y mice. Result: Synaptic dysfunction due to mutations falls at opposite ends of a physiological spectrum. Synaptic, biochemical, cognitive defects in mutants can be corrected by modulating metabotropic glutamate receptor 5 (mGluR5) in opposite directions. Deficits vanish when mice carry both mutations. Conclusion: Optimal synaptic plasticity &amp; cognition occur within a specific range of mGluR5-mediated protein synthesis. Deviating from this range results in shared behavioural impairments. Introduction Background: &gt;1% have Autism Spectrum Disorder (ASD). 50% of them also have intellectual disability (ID). Main cause: Unknown. Some known: Genetic syndromes. Fragile X Syndrome (FXS): Caused by FMR1 gene silencing. Fmr1 knockout mouse: ↑ protein synthesis via mGluR5. Inhibiting mGluR5 corrects FXS. Hypothesis: Some ASD &amp; ID from gene mutations affecting synaptic mRNA. Altered protein synthesis common in autism &amp; ID? Study Aim: Examine: TSC mutation → same protein synthesis abnormalities as FXS? If yes, one treatment could benefit both disorders. Result TSC mutations affect synaptic function Reasons: Single-gene disorder → ASD &amp; ID symptoms like FXS. Affected gene in receptor-to-mRNA translation pathway. Valid mouse models available. Some mouse models respond to protein synthesis treatments. TSC Details: Caused by TSC1 or TSC2 gene mutations. Form TSC1/2 complex. TSC1/2 inhibits Rheb → specific for mTOR in mTORC1 complex. Excessive mTORC1 → ↑ mRNA translation &amp; cell growth. TSC symptoms: Hamartoma growths due to functional allele inactivation. Some TSC neurological symptoms: Tumor growth in cortex. Other symptoms (cognitive &amp; autism): Abnormal synaptic signaling. Mouse Model: Tsc1 or Tsc2 mutants → hippocampus-dependent learning/memory deficits. No brain tumors or seizures. Used Tsc2+/- model. TSC2 mutations more severe &amp; common in humans. Tsc2+/- mice treated with mTORC1 inhibitor (rapamycin) → improved hippocampal memory. Potential drug treatment for TSC &amp; FXS. Hypothesis: TSC synaptic dysfunction → ↑ protein synthesis (due to ↑ mTORC1). mTORC1 links mGluR5 to protein synthesis. mTOR ↑ protein synthesis also in Fmr1-/y mouse (controversial). mGluR-LTD: Electrophysiological measure of local mRNA translation. Exaggerated LTD in Fmr1-/y → led to mGluR FXS theory. Study: Examine mGluR-LTD in Tsc2+/- mouse hippocampus. Protein synthesis and mGluR-LTD in Tsc2+/- mice LTD Induction: Used Gp1 mGluRs (mGluR 1 &amp; 5) activation with DHPG in hippocampal slices. Tsc2+/- mice showed deficient DHPG-induced LTD compared to WT (Fig. 1a). Similar deficit observed with patterned electrical stimulation (Fig. 1b). Tsc2+/- Synaptic Function: Basal synaptic transmission in CA1 was normal (Supplementary Fig. 1). NMDA-receptor-dependent LTD was also similar between Tsc2+/- and WT (Fig. 1c). DHPG-induced ERK1/2 phosphorylation (indicator of Gp1 mGluR signalling) unchanged in Tsc2+/- (Fig. 1d). Concluded: Deficit in mGluR-LTD isn’t from global synaptic or Gp1 mGluR signalling disruption. LTD Mechanisms: Two mechanisms in WT: Reduced presynaptic glutamate release probability. Reduced postsynaptic AMPA receptors. Postsynaptic change needs immediate mRNA translation in hippocampal pyramidal neurons. Cycloheximide (protein synthesis inhibitor) reduced LTD in WT (Fig. 2a) but not in Tsc2+/- (Fig. 2b). Suggests: Tsc2+/- has selective loss of protein-synthesis-dependent component of LTD. Comparison with Fmr1-/y Mouse: Tsc2+/-'s electrophysiological results contrast Fmr1-/y, where mGluR-LTD is enhanced. Fmr1-/y has increased basal mRNA translation downstream of mGluR5. Tsc2+/- showed decreased [35S] methionine/cysteine protein incorporation under basal conditions (Fig. 2d). Arc Protein: Reduced Arc expression in Tsc2+/- hippocampal slices (Fig. 2e). Arc is synthesized in response to Gp1 mGluR activation and required for mGluR-LTD. Significant reduction in Arc translation in Tsc2+/- hippocampus (Fig. 2f). Indicates: mGluR-LTD deficiency in Tsc2+/- due to decreased translation of LTD-stabilizing proteins, including Arc. LTD deficit caused by excess mTOR activity Goal: Understand if the Tsc2+/- mutation’s impact on mGluR-LTD is due to unchecked mTOR activity. Key Findings: Rapamycin restored mGluR-LTD in Tsc2+/- to normal levels. This treatment didn’t affect the WT mice. The rescue in Tsc2+/- was due to restored protein synthesis. Conclusion: Uncontrolled mTOR activity in Tsc2+/- hinders the protein synthesis needed for mGluR-LTD. Effect of mGluR5-positive allosteric modulation mGluR5’s Role in Tsc2+/- Model of TSC: Background: FXS issues are fixed by lowering mGluR5 signaling. Thought of boosting mGluR5 signaling for TSC. mGluR5 PAM’s Impact: A PAM boosts mGluR-LTD in Tsc2+/- mice. This corrects the protein-dependent part of LTD. PAM (CDPPB) also fixes protein and Arc synthesis issues. Behavioral Effects: Tsc2+/- mice struggle in a fear task. mGluR5 and new protein synthesis are crucial for this. CDPPB treatment before training helps Tsc2+/- mice. Conclusion: Boosting mGluR5 might help treat TSC cognitive problems. Fmr2/y and Tsc21/2 mutations cancel each other Contrasting Effects of FXS and TSC Mutations on mGluR5 and Memory: Initial Findings: FXS and TSC mutations show opposite impacts on protein-synthesis-dependent LTD. They respond oppositely to mGluR5 treatments. Experiment with Combined Mutations: Introduced an Fmr1 deletion to Tsc2+/- background. mGluR-LTD was reduced in Tsc2+/- and increased in Fmr1-/y. Mice with both mutations showed mGluR-LTD similar to WT. Memory Impairment Comparison: Tsc2+/- and Fmr1-/y have similar cognitive issues, despite opposite synaptic alterations. Both have a context discrimination memory deficit. However, double mutants don’t show this deficit, suggesting both mutations might counteract each other’s effects on behavior. Discussion LTD, Protein Synthesis, and Genetic Disorders: Context: LTD and mGluR5-related protein synthesis are significant in FXS. FXS arises from the absence of FMRP, an mRNA-binding protein inhibiting translation. In the Fmr1-/y mouse, there’s heightened protein synthesis and exaggerated LTD via an mGluR5-ERK1/2 pathway. mTOR Significance: Elevated mTOR activity suppresses protein synthesis vital for LTD in Tsc2+/- mice. Hyperphosphorylation of FMRP or increased translation of certain mRNAs might explain this suppression. Arc, crucial for mGluR5-related long-term plasticity, is under-translated in Tsc2+/- mice. mGluR-LTD differences in Tsc2+/- and Fmr1-/y mice suggest distinct regulation by FMRP and TSC1/2. Potential Treatments: Rapamycin, though beneficial, has limitations due to immunosuppressive properties. mGluR5 PAMs might target synaptic mechanisms causing cognitive and behavioral issues in TSC. Implications for ASD: TSC and FXS are significant genetic risk factors for ASD and intellectual disability. While Fmr1 mutation leads to exaggerated protein synthesis and LTD, Tsc2 mutation causes the opposite. Both can be balanced out in combined mutations. This suggests that ASD’s genetic causes might produce similar effects by deviations from the norm. Therapies for one type of ASD might not work for all, emphasizing personalized treatments. Deletion of Fmr1 from Forebrain Excitatory Neurons Triggers Abnormal Cellular, EEG, and Behavioral Phenotypes in the Auditory Cortex of a Mouse Model of Fragile X Syndrome Abstract Fragile X Syndrome and Sensory Processing Deficits: Context: Fragile X syndrome (FXS) is a primary genetic cause of autism, marked by sensory processing anomalies. In humans with FXS and Fmr1 knockout (KO) mouse model: EEG shows enhanced resting gamma power and diminished sound-evoked gamma synchrony. Matrix Metalloproteinase-9 (MMP-9): Past studies indicate elevated MMP-9 levels might influence these EEG anomalies by affecting perineuronal nets (PNNs) around parvalbumin (PV) interneurons in the auditory cortex of Fmr1 KO mice. Effects of Fmr1 Deletion in Excitatory Neurons: Cortical MMP-9 gelatinase activity, mTOR/Akt phosphorylation, and resting EEG gamma power increase. Density of PV/PNN cells decrease. CreNex1 /Fmr1Flox/y cKO mice show heightened locomotor activity but not anxiety-like behaviors. Implications: FMRP changes in cortical excitatory neurons can produce cellular, electrophysiological, and behavioral phenotypes in Fmr1 KO mice. Suggests local cortical circuit abnormalities play a role in sensory processing deficits in autism spectrum disorders. Fragile X Syndrome and Sensory Processing Deficits: An In-depth Study Introduction Introduction &amp; Background: Fragile X syndrome (FXS) is a monogenic form of autism spectrum disorders (ASD). Caused by a CGG repeat expansion in the Fmr1 gene, leading to downregulation of fragile X mental retardation protein (FMRP). Symptoms include anxiety, intellectual disability, and abnormal sensory processing, particularly auditory hypersensitivity. Auditory Hypersensitivity in FXS: Both humans with FXS and Fmr1 knockout (KO) mice exhibit auditory hypersensitivity. Electroencephalographic (EEG) studies in these subjects have shown increased resting EEG gamma band power, which could underlie sensory hypersensitivity. The Role of Matrix Metalloproteinase-9 (MMP-9): MMP-9 levels are elevated in FXS brains and could affect the development of parvalbumin (PV)-expressing inhibitory interneurons. MMP-9 is secreted from various cell types including astrocytes and neurons. It can also mediate changes in synaptic functions through the PI3K/Akt/mTOR pathway. Cell-Specific Effects: FMRP is expressed in multiple levels and cell types in the auditory pathway. The origin and cell type specificity of abnormal EEG recordings are still unknown. Objective of the Current Study: To understand the impact of deleting Fmr1 specifically from forebrain excitatory neurons. Findings: Deletion of FMRP from forebrain excitatory neurons was sufficient to elicit FXS-associated symptoms. This includes enhanced MMP-9 activity, increased mTOR/Akt signaling, impaired PV/PNN expression, and hyperactive behaviors. Implications: The study suggests that FMRP in excitatory neurons is critical for normal cortical activity. Highlights novel mechanisms potentially leading to sensory hypersensitivity in FXS and possibly other forms of ASD. Result Goals: Check if issues in auditory cortex of Fmr1 KO mice persist in adulthood. Examine effects of FMRP deletion on brain and behavior. Key Results: Reduced density of PV cells in layer 4 of auditory cortex in Fmr1 KO mice. Lower density of WFA+ PNN cells in both layer 4 and 2/3 in Fmr1 KO mice. Poor formation of PNNs around PV cells in Fmr1 KO mice. Implications: The observed deficits are long-lasting, suggesting they may cause enhanced sound sensitivity in Fmr1 KO mice. FMRP Immunoreactivity Was Significantly Reduced in Excitatory Neurons of Auditory Cortex of Adult CreNex1 /Fmr1Flox/y cKO Mice Method: Used CreNex1 and Fmr1flox/flox KO mice to specifically delete FMRP in forebrain excitatory neurons. Key Results: Significant reduction in FMRP in the auditory cortex of CreNex1/Fmr1Flox/y cKO mice compared to controls. No significant change in cell density in the auditory cortex. No significant changes in FMRP expression in other parts of the auditory pathway like the inferior colliculus and auditory thalamus. Implications: The deletion of FMRP is specific to forebrain excitatory neurons in the auditory cortex and doesn’t affect other regions, confirming the targeted nature of the genetic manipulation. Deletion of FMRP from Excitatory Neurons Reduces PV, PNN, and PV/PNN Colocalization in the Auditory Cortex of Adult CreNex1 /Fmr1 Flox/y cKO Mice Method: Studied cell density in the auditory cortex of specific knockout mice (CreNex1/Fmr1Flox/y cKO) and control mice (Fmr1Flox/y). Results: Fewer PV cells in knockout mice in two brain layers (L4 and L2/3). Fewer WFA+ PNN cells in the same layers in knockout mice. Less overlap of PV and WFA+ PNN cells in knockout mice in both layers. Implications: Loss of FMRP in excitatory neurons affects these cells. This could disrupt overall brain network function. Total Aggrecan Levels Are Reduced, While Cleaved Aggrecan Levels and Gelatinase Activity Are Enhanced in the Auditory Cortex of Adult CreNex1 /Fmr1 Flox/y cKO Mice Method: Conducted a gelatinase activity assay and measured aggrecan levels in the auditory cortex of specific mouse models. Results: Higher gelatinase activity in both Fmr1 KO and Cre Nex1/Fmr1 Flox/y cKO mice compared to controls. Lower levels of full-length aggrecan and higher levels of cleaved aggrecan in both Fmr1 KO and Cre Nex1/Fmr1 Flox/y cKO mice. Increased ratio of cleaved aggrecan to total aggrecan in these mice. Implications: The increased gelatinase activity, likely due to elevated MMP-9 levels, may contribute to the loss of PNNs. The cleavage of aggrecan, a key component of PNNs, is also affected. The loss of FMRP in excitatory neurons may underlie these molecular changes, affecting overall neural network integrity. Deletion of FMRP from Excitatory Neurons Triggers a Decrease in PV Levels, While Akt and mTOR Phosphorylation Is Increased in Auditory Cortex of Adult CreNex1 /Fmr1 Flox/y cKO Mice Key Findings on PV Levels and Akt/mTOR Signaling Method: Measured levels of Parvalbumin (PV) and phosphorylated forms of Akt and mTOR in the auditory cortex of specific mouse models. Results: Significant decrease in PV levels in the auditory cortex of Fmr1 KO and Cre Nex1/Fmr1 Flox/y cKO mice. Higher levels of phosphorylated (i.e., active) forms of Akt and mTOR in these mouse models compared to their controls. Implications: The decrease in PV levels is consistent with earlier findings in autism mouse models and might be linked to network dysfunction. Enhanced Akt/mTOR signaling could contribute to synaptic changes and hyperexcitability seen in FXS and other autism spectrum disorders. The deletion of FMRP in excitatory neurons is sufficient to trigger these molecular changes, pointing to its pivotal role in the auditory cortex of adult mice. Resting EEG Gamma Power Is Enhanced in the Auditory Cortex of Adult CreNex1 /Fmr1 Flox/y cKO Mice Key Findings on Impaired Neural Oscillations and Local Circuit Defects Objective: To determine if deficits in forebrain excitatory neurons cause abnormal neural oscillations similar to global Fmr1 KO mice. Methods: Baseline EEG raw power in auditory cortex examined for Cre Nex1/Fmr1 Flox/y cKO mice (n=9) and control Fmr1Flox/y mice (n=9). Analyzed various frequency bands during a 5-minute resting period. Results: Enhanced high-frequency oscillations observed in the auditory cortex of Cre Nex1/Fmr1 Flox/y cKO mice. Significant increase in low gamma power (30-55 Hz) in the auditory cortex of these mice. Implications: The abnormal low gamma power likely stems from local circuit defects, similar to global Fmr1 KO mice. These local circuit defects may be related to observed increases in gelatinase activity and reduced PV+ cell density and WFA+ PNNs around PV+ neurons. The results suggest that specific types of neurons may be critical for the neural oscillation abnormalities observed in FXS and potentially other autism spectrum disorders. This study adds to the understanding that local cortical circuit abnormalities, possibly related to impaired PV+ interneuron function, contribute to neural oscillation deficits in FXS. Gamma Synchronization Is Not Affected in Adult CreNex1 /Fmr1 Flox/y cKO Mouse Auditory Cortex Key Findings on Phase Locking and Gamma Synchronization Objective: To investigate if increased baseline gamma in Cre Nex1/Fmr1 Flox/y cKO mice impacts the consistency of sound-evoked gamma synchronization. Methods: Used “chirp” stimuli with varying modulation frequencies, both up and down, presented 300 times each. Employed Inter-Trial Phase Coherence (ITPC) analysis to measure phase consistency across trials. Results: Despite increased baseline gamma in Cre Nex1/Fmr1 Flox/y cKO mice, there were no significant differences in gamma band ITPC compared to controls. Similar patterns observed for both up- and down-chirps. Implications: The lack of difference in gamma ITPC suggests that the gamma synchronization deficits in global Fmr1 KO mice are not solely due to excitatory neurons in the forebrain. This opens up the possibility that other cell types in the cortex or subcortical sites could be responsible for these deficits. The study suggests that while local circuit defects may contribute to baseline gamma power, they may not be the sole factor affecting gamma synchronization in response to auditory stimuli in FXS. Increased Non–Phase-Locked STP Is Observed in the Auditory Cortex of Adult CreNex1 /Fmr1 Flox/y cKO Mice during Chirp Stimulation Studied gamma power in Cre Nex1/Fmr1 Flox/y cKO mice. Found increased lower gamma power. Suggests local circuit issues. Induced Power Is Significantly Enhanced in the Auditory Cortex of Adult CreNex1 /Fmr1 Flox/y cKO Mice Tested auditory cortex responses to noise bursts at 4 Hz and 0.25 Hz rates. Cre Nex1/Fmr1 Flox/y cKO mice showed reduced phase locking in the beta range (20-30 Hz). Increased “ongoing” response was observed in the beta to low gamma range (10-50 Hz). These effects persisted in repeated sound stimulation. Results suggest increased variability and reduced suppression of ongoing activity in cKO mice. Excitatory Neuron-Specific Adult CreNex1 /Fmr1 Flox/y cKO Mice Display Increased Locomotor Activity, but No Anxiety-Like Behavior Mice were tested for activity and anxiety using elevated plus maze and open field (OF) tests. Cre Nex1/Fmr1 Flox/y cKO mice showed more arm entries and higher speed, indicating increased locomotor activity. No difference was observed in time spent in open arms, suggesting no change in anxiety levels. In the OF test, cKO mice also crossed more lines and moved faster, confirming increased activity. No significant difference in time spent in center or thigmotaxis, again suggesting no change in anxiety. Conclusion: Deleting FMRP from forebrain excitatory neurons increases activity but doesn’t affect anxiety-like behaviors. Discussion Study aims to understand sensory processing issues in Fragile X Syndrome (FXS), a genetic cause of Autism Spectrum Disorder (ASD). Deleting Fmr1 from forebrain excitatory neurons causes abnormal EEG patterns in adult auditory cortex. This deletion also increases gelatinase activity, affecting Perineuronal Nets (PNNs) around Parvalbumin (PV) neurons. PV neurons are crucial for sensory processing; their dysfunction may underlie sensory issues in FXS. The study also finds higher mTOR/Akt phosphorylation in the cortex, suggesting altered signaling pathways. Reduced excitation to PV neurons may lead to their decreased activity and function. Low-gamma band power in auditory cortex is specifically increased; this could influence sensory and cognitive processes. Both cortical and sub-cortical structures likely contribute to auditory processing deficits in FXS. Future research is needed to explore effects of Fmr1 deletion in other brain areas and cell types for a system-level understanding. Role of Enhanced Gelatinase Activity in CreNex1 /Fmr1Flox/y cKO Mice The study elaborates on the intricate relationship between the loss of the FMRP protein and various neural and behavioral phenomena in Fragile X Syndrome (FXS). Here’s a breakdown: Molecular Mechanisms Perineuronal Nets (PNNs) and Parvalbumin (PV) Neurons: PNNs surround PV neurons and are crucial for their function. Aggrecan, a component of PNNs, is degraded by gelatinases (MMP-2, MMP-9), affecting the structure and function of PNNs. Gelatinase Activity: The study found increased gelatinase activity in the auditory cortex of mice lacking FMRP, indicating that this may contribute to impaired PNN formation. Signaling Pathways: Increased gelatinase activity can also affect the mTOR and Akt signaling pathways, which are implicated in FXS and regulate neuronal excitability. Auditory Cortex and Sensory Processing MMP-9 and Sensory Responses: Deletion or reduction of MMP-9 activity in mice normalized auditory responses and PNN formation, highlighting its therapeutic potential. Subcortical Contributions: While the study indicates cortical deficits, it also suggests that subcortical areas may contribute to the observed abnormalities. Behavioral Aspects Locomotor Activity: Mice with FMRP deletion in forebrain excitatory neurons showed increased locomotor activity but no anxiety-like behaviors. Role of FMRP in Other Areas: FMRP loss in other brain regions like the hippocampus may contribute to other FXS symptoms like learning and memory deficits. Future Directions Astrocytes and MMP-9: The study proposes to investigate how astrocytes may be involved in regulating MMP-9 activity and PNN formation. Multi-Electrode EEGs: To get a comprehensive understanding, the study recommends exploring electrocortical activity in different brain areas. Overall, the study provides a multi-faceted understanding of how FMRP loss impacts neural circuits and behaviors, offering potential therapeutic targets like MMP-9 for FXS. Certainly! Here’s a more elegant and concise summary of the research findings and their implications. Conclusion Key Insights Parvalbumin Neurons: Deletion of the Fmr1 gene in forebrain excitatory neurons impinges upon the integrity and function of parvalbumin-positive (PV+) inhibitory neurons. Matrix Enzymology: Elevated activity of the enzyme MMP-9 remodels the extracellular scaffolding around PV+ neurons, potentially altering cellular signaling cascades. Electrophysiological Nuances: The study discerns a specific alteration in resting low-gamma EEG power, correlated with hyperactive behaviors but not with anxiety. Symptomatic Specificity: The research delineates that cortical deficits are responsible for some, but not all, features of Fragile X Syndrome, underscoring a nuanced impact of the Fmr1 deletion. Clinical Implications The findings elegantly illuminate avenues for targeted therapeutic strategies, offering the prospect of interventions honed to specific cellular actors and neural circuits implicated in Fragile X Syndrome. By delving into the intricacies of cellular and circuit-level changes, this study enriches our understanding of Fragile X Syndrome and opens new horizons for targeted therapeutic interventions. pre { background-color:#38393d; color: #5fd381; }","link":"/2023/08/23/LearnNotes/acoustics/"},{"title":"Principles of Biochemistry 10 |Lipids Related Membrane-Function and Pathology| Class Notes |HarvardX","text":"Lipids for Membrane Functions Membrane Curvature Bilayer Asymmetry Membrane Fluidity Membrane Curvature The conical shape of lipids was more prefer the inner layer which means the two layers of the membrane are asymmetrical. Exp: Phosphatidylcholine - cylindrical shape Phosphatidylethanolamine - Conical shape Human Red Blood Cells The lipid asymmetry of the membrane of the red blood cell: © Verkleij et al[1:1] In aged red blood cells, the composition of the leaflet is changed. The phosphatidylserine appears on the surface of red blood cells and becomes predominant. This gives a signal to the macrophages to clear them out. Maintain the asymmetry Lipid transport proteins are responsible for maintaining asymmetry. Flipase: outer into inner Floppase: Inner into outer Scramblase: Both directions The lipids composition of the ER, Golgi apparatus and the cell membrane are very similar. The Fluidity of the Membrane Situation 1: Full of Saturated, long fatty acid tails: The membrane was packed much denser It has low fluidity It is called a Paracrystalline state Situation 2: The membrane with shorter and unsaturated tails: Packing much looser More fluid It is called a fluid state Situation 3: Cholesterol During the Golgi transport, a part of sphingolipids and cholesterol are transported into the cell membrane. Intercalate between fatty acid tails Disturb the tight packing improve fluidity and maintain the rigidity of the Paracrystalline state At a physiological Tm, a membrane existed between these two states. Protein and lipids in the membrane Exp: lipid draft FRAP FRAP: Fluorescence Recovery After Photobleaching © zeiss-campus Label of lipids Make a small dark spot with laser Measure the time the dark became fluorescence again. Fluorescence recovery is due to the near lipids diffusion. So, we can make a graph to show how long it takes to determine the diffusion-coefficient. $$ s = \\sqrt{ 4Dt} $$ $s$: Average distance traveled $D$: Diffusion Coefficient $t$: Time Membrane proteins © teaching.ncl.ac.uk Protein Diffusion The diffusion velocity of the protein is variable. Similar to lipids: Photoreceptor. Very slow: chloride bicarbonate in red blood cell, which has interaction in the intracellular region of other protein networks, membrane skeleton. Protein Functions The total concentration and composition of the protein are highly variable. Protein Position Integral membrane protein: fully embedded in the lipid. Peripheral protein: with lipids that are inserted into the lipid bilayer. Functions Signal Transduction Molecular transportation (Pumps / Channels) Ion Glucose Water Signal Role of the lipids Both too little and too many lipids were causing pathologies. Lipid droplets: Few: Lipodystrophy &amp; Cachexia Lipids Maintain The fate of lipid droplets The form of the lipid droplets is controlled by the rate of triacylglycerol synthesis and the rate of mobilization by lipolysis High energy state: GPAT, AGPAT, and MGAT catalyze the addition of fatty acids to glycerol or to monoacylglycerol to produce diacylglycerol DGAT1 and DGAT2 contributed to the final synthesis of triacylglycerol triacylglycerol stored in the endoplasmic reticulum triacylglycerol will then accumulate between the two leaflets of the ER to form a small bump Finally buds off and became a lipid droplet. Genetic mutation reducing the activity of the AGPAT is implicated in over 50% of congenital generalized lipodystrophy. Low energy state: Any mutation leading to uncontrolled activation of lipolysis will also result in lipodystrophy. Exp: mutations prevent perilipin inhibition of ABHD5 binding to the lipase ATGL, leading to constitutive activation of lipolysis, and ultimately to lipodystrophy. Acquired Lipodystrophy Exp: Autoimmune reaction and drug treatment. HIV-associated acquired lipodystrophy. Nucleoside reverse transcriptase inhibitors: mitochondrial toxicity. Protease inhibitors: inhibit a protein needed for the processing of the nuclear protein lamin A. High Body Fat Situation Two diseases: Neutral Lipid Storage Disease; Metabolic Syndrome Neutral Lipid Storage Disease Adipocytes: Very large lipid droplets; Dominated by the TAG. Monogenic Disease Two Types of NLSD: Cardiomyopathy: Characterized by a type of heart disorder NLSD-M: Characterized by Ichthyosis (Sin takes on fish-scale-like appearance) NLSD-I NLSD-M The associated gene is ATGL, which catalyzes the first step of triacylglycerol. Mutation of this gene prevented its recruitment. Connection with Cardiomyopathy: This mutation impairment the release of energy fuels and impacts the tissues such as the cardiac muscle. NLSDI NLSD-I: Chanarin-Dorfman Syndrome Associated gene: $\\alpha/\\beta$-hydrolase domain-containing protein 5 (ABHD5) ABHD5: triacylglycerol to diacylglycerol Ichthyosis: “Ichthyo”: Having to do with fish “-osis”: pathology, or abnormal. The skin of the patient was dry and rough like fish scales Causes: Abundant abnormal lipid deposits in the skin, which could reduce the permeability of the skin. The outer layer of the skin was made by lipid-based Extracellular Matrix The permeability of this layer is functional when lipolysis is functional. Impaired lipolysis leads abnormal deposition of triacylglycerol. Result: breakdown of the mortar holding the bricks; makes the skin taking on a dry, rough, and scale-like appearance. Metabolix Syndrome Metabolix Syndrome is characterized by a cluster of pathologies: high blood level of triacylglycerol, cholesterol, and LDL, hyperglycemia, and insulin resistance. Polygenic disease. Ectopic fat deposition -[Lipotoxity; inflammation]-&gt; insulin resistance -&gt; Type 2 diabetes perilipin: control the size of the lipid droplets. (by initiating a chain reaction to lipid degradation.) inflammation: lipid gives the extra ATP in a muscle which recruits more adipocytes and attracts the macrophages. digraph F { rankdir = UD; edge [style=solid]; node [style=filled, font=Courier]; subgraph cluster_0{ subgraph A { rank = \"same\"; Adipocyte Padipocyte [label = \"Pre-adipocyte\"] } MAdipocyte [label = \"Mature Adipocyte\"] style=filled; color=lightgrey; node [style=filled,color=white]; label = \"Differentiation\"; } CDeath [label = \"Cell Death\"] Adipocyte -> MAdipocyte Padipocyte -> Adipocyte [label =\"Insulin and Cortisol|AKT2, PPARr\"] MAdipocyte -> CDeath [label=\"Lamin A, ZMPSTE24\"] MAdipocyte -> Adipocyte } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });digraph F { node [style=filled,color=white, shape =box]; rankdir =\"UD\" subgraph cluster_0{ subgraph A { rank = \"same\"; Catecholamine GP AD } Catecholamine GP [label =\"trimeric G protein\"] AD [label =\"adenylyl cyclase\"] style=filled; color= darkorange; label = \"Cell Membrane\"; } subgraph cluster_1{ ABAT [ label = \" ABHD5 | ATGL\" shape = \"record\" ]; perilipin marr0002 [ label = \" HSL | FABP4\" shape = \"record\" ] ; LD [label = \"lipid droplet\", shape = plain] style=filled; color=deepskyblue3; label = \"Surface of lipid droplet\"; } subgraph B { rank = \"same\"; marr0001 [ shape=diamond,style=filled,label=\"\",height=.1,width=.1] ; ATP cAMP [label =\"cyclic AMP\"] } subgraph C { rank = \"same\"; ABHD5 PKA ATGL } Catecholamine -> GP [label = \"active\"] GP -> AD [label = \"active\"] AD -> marr0001 [label = \"catalytic\"] ATP -> marr0001 [dir =none] marr0001 -> cAMP cAMP -> PKA [label = \"active\"] PKA -> perilipin [label = \"phosphate\"] PKA -> HSL [label = \"activate\"] perilipin -> ABHD5 [label = \"activate\"] perilipin -> LD [label = \"remodeling the surface of the droplets\"] ABHD5 -> ATGL [label = \"recruit\"] HSL -> marr0002 [dir = none] FABP4 -> marr0002 [dir = none] marr0002 -> LD ATGL -> ABAT:f0 -> LD } var viz = new Viz(); var code = document.getElementById(\"graphviz-1-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-1\").append(element) }); digraph F { rankdir = LR; edge [style=solid]; node [style=filled, font=Courier]; subgraph M { rank = same; Start [label = \"Ectopic Fat Deposition\", shape = box, fillcolor = \"#FF0000\" ]; End [label = \"Type 2 diabetes\" , shape = box, color = coral]; Con1 [label = \"Insulin Resistance\", shape = diamond, color = green, size = 3]; } Start -> Con1 [label = \"Lipotoxity; inflammation\" ] Con1 -> End } var viz = new Viz(); var code = document.getElementById(\"graphviz-2-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-2\").append(element) }); Verkleij, A.J.; Zwaal, R.F.A.; Roelofsen, B.; Comfurius, P.; Kastelijn, D.; van Deenen, L.L.M.The asymmetric distribution of phospholipids in the human red cell membrane. A combinedstudy using phospholipases and freeze-etch electron microscopy. Biochim. Biophys. Acta 1973,323, 178–193 ↩︎ ↩︎","link":"/2021/04/14/LearnNotes/edx-biochm-10/"},{"title":"Principles of Biochemistry 11 |Carbohydrates| Class Notes |HarvardX","text":"Introduction Carbohydrates have structure variety, functional variety, both chemical and physical. Aldoses Ketoses The Chain ends with a carboxyl group When the carboxyl group was not in the terminal (C2 in nature) -ose -ulose © vivadifferences.com C3 and C4 carbohydrates are too sample to be found in a complex molecule. They are metabolic intermediates. C5 pentose has abounded in ribose and deoxyribose form. C6 hexose was very popular in both structure and energy resources. Enantiomers Identify the number of the asymmetry carbon in monosaccharides. Exp Glyceraldehyde: One asymmetric carbon Two enantiomers Sharing most of the chemical properties Affect polarized light When the polarized light goes through a cell that contains our chiral sugar, the plane of the polarized light will rotate. The rotation direction: clockwise: Dextrorotatory; (+)-glyceraldehyde counterclockwise: Levorotatory; (-)-glyceraldehyde D/L series © masterorganicchemistry.com The steps of determing the D/L series: Write the developed chemical structure (vertical) Place the ketone/aldehyde group at the top of the structure Number the carbon started from the top Identify the asymmetry carbon. When the hydroxyl group carried by the bottom-most asymmetry carbon is: on the right: D series on the left: L series The D/S series is kind of arbitrary and not really corresponded with enantiomers Most of the monosaccharides in cells are belong to the D series. Pentose © Pubchem ID:229 Chemical Feature: Schiff reaction: Shiff reagent (pink) + sulfur dioxide -&gt; Discolored Adding aldehyde -&gt; recolored (pink) Hypothesized: the aldehyde is linear: free aldehyde group and it could recolor the Schiff reagent. Observed: aldose failed to recolor the Schiff reagent Conclusion: It doesn’t have a free aldehyde group, it’s not linear but cyclic. Physical Feature: Theoretically, the D-Glucose has unique physical properties like melting Tm, degree of rotation of polarized light. But two distinct methods synthesized D-glucose has different physical properties. Synthesis Melting Temperature Specific Rotation Form Methoud 1 $146^ \\circ C$ $+112^ \\circ$ $\\alpha ^ {_ -}D^ {_ -}glucose$ Methoud 2 $150^ \\circ C$ $+18^ \\circ$ $\\beta^ {_ -} D^ {_ -}glucose$ Cyclic Structure Structural analysis a show that hexose and pentose exist in a cyclic structure. The linear structure represents only 0.02% of the molecules of sugar in this solution Cyclic Formation © glossary.periodni.com $aldehyde + alcohol \\to hemiacetal $ $ketone + alcohol \\to hemiketal $ D-glucose -&gt; attack the fount or back, to form the alpha or beta cyclic glucose © masterorganicchemistry.com Pryan and Furan Hexose: Pryan; $\\alpha^ {_ -}D^ {_ -}glucopyranose$ Ketose: Furan; $\\beta^ {_ -}D^ {_ -}ribofuranose$ Significance D-Glucose: A much stable form: $\\alpha^ {_ -}D^ {_ -}glucopyranose$ A much unstable form: $\\alpha^ {_ -}D^ {_ -}glucofuranose$ Conformations Chair and Boat conformations! Saccharides poly-formation $\\alpha^ {_ -}D^ {_ -}Glucose + \\beta^ {_ -}D^ {_ -}Glucose$ $\\alpha^ {_ -}D^ {_ -}Glucose + \\alpha^ {_ -}D^ {_ -}Glucose$ Maltose: $1 \\to 4 glycosidic linkage$ Trehalose: $ 1 \\to 1 glycosidic linkage$ © Pubchem ID:6255 © Pubchem ID:7427 $\\beta^ {_ -}D^ {_ -}Galactose + \\beta^ {_ -}D^ {_ -}Glucose$ $\\alpha^ {_ -}D^ {_ -}Glucose + \\beta^ {_ -}D^ {_ -}Fructose$ Lactose: $1 \\to 4 glycosidic linkage$ Sucrose: $1 \\to 2 glycosidic linkage$ © Pubchem ID:6134 © Pubchem ID:5988 Glycogen © Pubchem ID:146037391 Basic Structure A polymer of $\\alpha ^{_ -}D ^{_ -} Glucose$ Main Stream: reducing end: $1^{_ -} 4\\ glycosidic linkage$ Branch Streams: non-reducing ends: $1^{_ -} 6\\ glycosidic linkage$ Synthesis Initiation Glycogenin-Try194 + UDP-glucose CC-glycogen synthase (complex) glycogenin will catalyze the next three units to form the primer. Then, the glycogen synthase would able to elongate the chain. Elongation Branches ~ every 10 units up to 55,000 glucose units ~ 2,100 nonreducing ends digraph{ Glycogenin [ label = \" Glycogenin\" shape = \"record\" ]; Glycogenin1 [ label = \" Glycogen synthase|{ Glucose| Glycogenin}\" shape = \"record\" ]; Glycogenin2 [ label = \" Glycogen synthase|{ Glucose| Glucose| Glycogenin}\" shape = \"record\" ]; Glycogenin3 [ label = \" Glycogen synthase|{ Glucose| Glucose| Glucose| Glycogenin}\" shape = \"record\" ]; Glycogenin4 [ label = \" Glycogen synthase|{ Glucose| Glucose| Glucose| Glucose| Glycogenin}\" shape = \"record\" ]; UDP1 [label = \"UDP\"] UDPG1 [label = \"UDP-glucose\"] UDP2 [label = \"UDP\"] UDPG2 [label = \"UDP-glucose\"] UDP3 [label = \"UDP\"] UDPG3 [label = \"UDP-glucose\"] UDP4 [label = \"UDP\"] UDPG4 [label = \"UDP-glucose\"] ms1 [label = \"\", shape = none, height=0,width=0] ms2 [label = \"\", shape = none, height=0,width=0] ms3 [label = \"\", shape = none, height=0,width=0] ms4 [label = \"\", shape = none, height=0,width=0] Glycogenin -> ms1 [dir= none] ms1 -> Glycogenin1 UDPG1 -> ms1 -> UDP1 [color = \"red\"] Glycogenin1 -> ms2 [dir= none] ms2 -> Glycogenin2 UDPG2 -> ms2 -> UDP2 [color = \"red\"] Glycogenin2 -> ms3 [dir= none] ms3 -> Glycogenin3 UDPG3 -> ms3 -> UDP3 [color = \"red\"] Glycogenin3 -> ms4 [dir= none] ms4 -> Glycogenin4 UDPG4 -> ms4 -> UDP4 [color = \"red\"] } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });digraph{ G6P [label = \"Glucose-6-phosphate\"] G1P [label = \"Glucose-1-phosphate\"] Pi2 [label = \"Pi * 2\"] UDPG [label = \"UDP-Glucose\"] NonGC[label = \"Nonreducing end of glycogen chain\"] NonGC1[label = \"Nonreducing end of glycogen chain\"] NonGC2[label = \" with brach glycogen chain\"] mm0 [label = \"\", shape = none, height=0,width=0] mm1 [label = \"\", shape = none, height=0,width=0] mm2 [label = \"\", shape = none, height=0,width=0] mm3 [label = \"\", shape = none, height=0,width=0] mm4 [label = \"\", shape = none, height=0,width=0] subgraph A{ rank = same mm4 NonGC1 } Glucose ->mm0 [dir = none, color=\"red\"] Pi -> mm0 [label = \"hexokinase|glucokinase\", color=\"red\"] mm0 -> G6P [color=\"red\"] G6P -> G1P -> mm1 -> UDPG [color=\"red\"] UTP -> mm1 [dir = none] mm1 -> PPi [label=\"high energy cost\"] PPi -> mm2 -> Pi2 H20 -> mm2 [dir = none] UDPG -> mm3 [dir = none, color=\"red\"] mm3 -> NonGC [label=\"glycogen synthase\" , color=\"red\"] NonGC -> mm4 [dir = none, color=\"red\"] NonGC1 -> mm4 [color=\"red\", color=\"red\"] mm4 -> NonGC2 [label = \"Glycogen branching enzyme\", color=\"red\"] } var viz = new Viz(); var code = document.getElementById(\"graphviz-1-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-1\").append(element) });","link":"/2021/04/15/LearnNotes/edx-biochm-11/"},{"title":"Principles of Biochemistry 12 |Glycolysis| Class Notes |HarvardX","text":"Glycolysis Free Energy of Hydrolysis Coupling $PEP + H_ 2O \\longrightarrow Pyruvate + P_ i$ $\\ \\ \\ \\ \\Delta G^ {\\circ} = -62 kJ/mol$ $ADP + P_ i \\longrightarrow ATP + H_ 2O$ $\\ \\ \\ \\ \\Delta G^ {\\circ} = +30 kJ/mol$ Since they share the common reactacts, this two reaction could be combined together, which was called coupling $PEP + ADP \\overset{Pyruvate Kinase}{\\longrightarrow} Pyruvate + ATP$ $\\ \\ \\ \\ \\Delta G^ {\\circ} = -32 kJ/mol$ Coupling: Common reactacts Catalyzed by one enzyme Example 1 $PEP + H_ 2O \\longrightarrow Pyruvate + P_ i$ $\\ \\ \\ \\ \\Delta G^ {\\circ} = -62 kJ/mol$ $Glucose + P_ i \\longrightarrow Glucose^ {_ -} 6 ^{_ -} phosphate + H_ 2O$ $\\ \\ \\ \\ \\Delta G^ {\\circ} = +14 kJ/mol$ The Enzyme were dose not shared by this two reaction As as result, they can not be coupled Example 2 $ATP + H_ 2O \\longrightarrow ADP + P_ i$ $\\ \\ \\ \\ \\Delta G^ {\\circ} = -30 kJ/mol$ $Glucose + P_ i \\longrightarrow Glucose^ {_ -} 6 ^{_ -} phosphate + H_ 2O$ $\\ \\ \\ \\ \\Delta G^ {\\circ} = +14 kJ/mol$ Coupled Reaction: $Glucose + ATP \\overset{hexokinass}{\\longrightarrow} Glucose^ {_ -} 6 ^{_ -} phosphate + ADP$ $\\ \\ \\ \\ \\Delta G^ {\\circ} = -16 kJ/mol$ Pyruvate and NADH . digraph{ rankdir = \"UD\" subgraph cluster_0{ hexo1 [label = \"\", shape = hexagon, width = 1, height = .8] node [style=filled,color=white]; label = \"Glucose\"; color = \"white\"; labeljust=l labelloc=b } subgraph cluster_1{ hexo2 [label = \"\", shape = hexagon, width = 1, height = .8] node [style=filled,color=white]; label = \"Glucose-6-phosphate\"; URL=\"https://www.bing.com\"; subgraph C{ rank = same P1 -> hexo2 [dir = none, headport = \"nw\", arrowhead =\"none\"] } color = \"white\"; labeljust=l labelloc=b } subgraph cluster_2{ hexo3 [label = \"\", shape = hexagon, width = 1, height = .8] node [style=filled,color=white]; label = \"Fructose-6-phosphate\"; URL=\"https://www.bing.com\"; subgraph C{ rank = same P2 -> hexo3 [dir = none, headport = \"nw\", arrowhead =\"none\"] } color = \"white\"; labeljust=l labelloc=b } subgraph cluster_3{ hexo4 [label = \"\", shape = hexagon, width = 1, height = .8] node [style=filled,color=white]; label = \"Fructose-1,6-phosphate\"; URL=\"https://www.bing.com\"; subgraph C{ rank = same P3 -> hexo4 [dir = none, headport = \"nw\", arrowhead =\"none\"] hexo4 -> P4 [dir = none, arrowhead =\"none\"] } color = \"white\"; labeljust=l labelloc=b } ATP1 [label=\"ATP\"] ADP1 [label=\"ADP\"] ATP2 [label=\"ATP\"] ADP2 [label=\"ADP\"] ATP3 [label=\"ATP\", color=\"salmon\", style=\"filled\"] ADP3 [label=\"ADP\"] ATP4 [label=\"ATP\", color=\"salmon\", style=\"filled\"] ADP4 [label=\"ADP\"] P1 [label=\"\", shape = circle, color= \"cyan3\", height = 0.3, width = 0.3] P2 [label=\"\", shape = circle, color= \"cyan3\", height = 0.3, width = 0.3] P3 [label=\"\", shape = circle, color= \"cyan3\", height = 0.3, width = 0.3] P4 [label=\"\", shape = circle, color= \"cyan3\", height = 0.3, width = 0.3] NAD1 [label = \"Pi, NAD+\"] NADH1 [label = \"H+, NADH\", color=\"salmon\", style=\"filled\"] BSG [label = \"1,3-\\nBisphosphoglycerate\", shape = underline] Phos [label = \"3-Phosphoglycerate\", shape = underline] Pho2 [label = \"2-Phosphoglycerate\", shape = underline] Phoe [label = \"Phosphoenol-\\npyruvate\", shape = underline] Pyru [label = \"Pyruvate\", shape = underline] mm1 [label = \"Hexokinase\" , shape = box, color = \"coral\", fontcolor = \"coral\"] mm2 [label = \"Phosphoglucose\\nisomerase\" , shape = box, color = \"coral\", fontcolor = \"coral\"] mm3 [label = \"Phospho\\nFructokinase\" , shape = box, color = \"coral\", fontcolor = \"coral\"] mm4 [label = \"Aldolase\" , shape = none, color = \"coral\", fontcolor = \"coral\"] mm5 [label = \"Triose\\nphosphate\\nisomerase\" , shape = box, color = \"coral\"] mm6 [label = \"\" , shape = none, width = 0, height = 0] mm7 [label = \"Phosphoglycerate\\nkinase\" , shape = box, color = \"coral\", fontcolor = \"coral\"] mm8 [label = \"Phosphoglycerate\\nMutase\" , shape = box, color = \"coral\", fontcolor = \"coral\"] mm9 [label = \"Enolase\" , shape = box, color = \"coral\", fontcolor = \"coral\"] mm10 [label = \"Pyruvate\\nkinase\", shape= box, color = \"coral\", fontcolor = \"coral\"] hexo1 -> mm1 [dir = none , color = \"deeppink\"] mm1 -> hexo2 [ color = \"deeppink\"] hexo2 -> mm2 [dir = none , color = \"deeppink\"] mm2 -> hexo3 [ color = \"deeppink\"] hexo3 -> mm3 [dir = none , color = \"deeppink\"] mm3 -> hexo4 [ color = \"deeppink\"] hexo4 -> mm4 [dir = none , color = \"deeppink\"] mm4 -> GAP [color = \"deeppink\"] DHAP -> mm4 [dir = back , color = \"deeppink\"] DHAP -> mm5 [dir = back , color = \"deeppink\", headport = w] mm5 -> GAP [color = \"deeppink\", tailport = e] GAP -> mm6 [dir = back , color = \"deeppink\"] mm6 -> BSG [color = \"deeppink\"] NAD1 -> mm6 [dir = none , tailport = w, headport = n, style = dashed] mm6 -> NADH1 [tailport = n, headport = w, style = dashed] BSG -> mm7 [dir = back, color = \"deeppink\"] mm7 -> Phos [color = \"deeppink\"] Phos -> mm8 [dir = back, color = \"deeppink\"] mm8 -> Pho2 [color = \"deeppink\"] Pho2 -> mm9 [dir = back, color = \"deeppink\"] mm9 -> Phoe [color = \"deeppink\"] H2O -> mm9 [dir = back, color = \"deeppink\"] Phoe -> mm10 [dir = back, color = \"deeppink\"] mm10 -> Pyru [color = \"deeppink\"] subgraph A{ rank = same ATP1 -> mm1 [dir = none , color = \"blue\"] mm1 -> ADP1 [color = \"blue\"] } subgraph B{ rank = same ATP2 -> mm3 [dir = none , color = \"blue\"] mm3 -> ADP2 [color = \"blue\"] } subgraph BB{ rank = same ADP3 -> mm7 [dir = none , color = \"blue\"] mm7 -> ATP3 [color = \"blue\"] } subgraph BC{ rank = same ADP4 -> mm10 [dir = none , color = \"blue\"] mm10 -> ATP4 [color = \"blue\"] } subgraph C{ rank = same mm4 DHAP [label= \"Dihydroxyacetone\\nphosphate\", shape = underline] GAP [label= \"Glyceraldehyde\\n3-phosphate\", shape = underline] } subgraph D { rank = same NADH1 mm6 } subgraph E { rank = same H2O mm9 } } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });digraph{ node [shape = plain] edge [dir = none] mm1 [label = \"\" , shape = none, height = 0, width = 0] mm2 [label = \"\" , shape = none, height = 0, width = 0] mm3 [label = \"\" , shape = none, height = 0, width = 0] mm4 [label = \"\" , shape = none, height = 0, width = 0] mm5 [label = \"\" , shape = none, height = 0, width = 0] PEP [label = \"Phosphoenolpyruvate\\n(PEP)\"] G6P [label = \"Glucose-6-phosphate\"] Height [label=\"High free energy\\nkJ/mol\"] Low [label=\"Low free energy\\nkJ/mol\"] ATP [shape=\"star \", color=\"salmon\", style=\"filled\"] Height-> mm1 [dir = back] mm1 -> mm2 -> mm3 -> mm4 -> mm5 mm5 -> Low [dir = true] \"-62\" -> mm1 -> PEP {rank = same; \"-62\"; mm1; PEP} \"-30\" -> mm3 -> ATP {rank = same; \"-30\"; mm3; ATP} \"-14\" -> mm5 -> G6P {rank = same; \"-14\"; mm5; G6P} } var viz = new Viz(); var code = document.getElementById(\"graphviz-1-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-1\").append(element) });digraph{ node [shape =\"box\"] CO2 [label = \"CO2\", shape = none, fontcolor=\"blue\"] CO22 [label = \"CO2\", shape = none, fontcolor=\"blue\"] NADH1 [label = \"NADH\", shape = none, fontcolor=\"salmon\"] NAD1 [label = \"NAD+\", shape = none, fontcolor=\"salmon\"] NAD2 [label = \"NAD+\", shape = none, fontcolor=\"salmon\"] NADH2 [label = \"NADH\", shape = none, fontcolor=\"salmon\"] AceCoA [label = \"Acetyl-CoA\"] \"Citric acid cycle\" [shape = \"underline\"] mm1 [label = \"\" , shape = none, height = 0, width = 0] mm2 [label = \"\" , shape = none, height = 0, width = 0] mm3 [label = \"\" , shape = none, height = 0, width = 0] mm4 [label = \"\" , shape = none, height = 0, width = 0] Pyruvate -> mm1 [dir= none] CO2 -> mm1 [dir = back] mm1 -> AceCoA AceCoA -> \"Citric acid cycle\" Pyruvate -> mm2 [dir= none] Pyruvate -> mm3 [dir= none] mm2 -> CO22 [headport=\"e\"] mm2 -> Acetaldehyde [label = \"Pyruvate\\ndecarboxylase\"] Acetaldehyde -> mm4 [dir= none] mm4 -> Ethanol [label = \"Alcohol\\ndehydrogenase\"] NADH1 -> mm4 [dir= none, color= \"darksalmon\"] mm4 -> NAD1 [color= \"darksalmon\"] mm3 -> Lactate [label = \"Lactate\\ndehydrogenase\"] NADH2 -> mm3 [dir = none; color= \"darksalmon\"] mm3 -> NAD2 [color= \"darksalmon\"] subgraph cluster_0{ mm1; CO2; AceCoA; \"Citric acid cycle\" label = \"Aerobic\" {rank=\"same\"; mm1; CO2} fontsize = 30 fontcolor = \"white\" color = \"darksalmon\" style = \"filled\" } subgraph cluster_2{ CO22; mm2 {rank = \"same\"; mm3; NADH2; NAD2} Acetaldehyde; Lactate; Ethanol {rank = \"same\"; NADH1; NAD1; mm4} label = \"Anaerobic\" fontsize = 30 fontcolor = \"white\" color = \"deepskyblue3\" style = \"filled\" } } var viz = new Viz(); var code = document.getElementById(\"graphviz-2-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-2\").append(element) });","link":"/2021/04/16/LearnNotes/edx-biochm-12/"},{"title":"糖尿病","text":"糖尿病 来源: 百科名醫 簡介: 糖尿病是一组以高血糖为特征的代谢性疾病。高血糖则是由于胰岛素分泌缺陷或其生物作用受损，或两者兼有引起。糖尿病时长期存在的高血糖，导致各种组织，特别是眼、肾、心脏、血管、神经的慢性损害、功能障碍。 临床表现 类型一: 多饮、多尿、多食和消瘦 严重高血糖时出现典型的“三多一少”症状，多见于1型糖尿病。发生酮症或酮症酸中毒时“三多一少”症状更为明显。 类型二: 疲乏无力，肥胖 多见于2型糖尿病。2型糖尿病发病前常有肥胖，若得不到及时诊断，体重会逐渐下降。 目前国际上通用WHO糖尿病分型方法将糖尿病分为1型糖尿病（T1DM）、2型糖尿病（T2DM）、其他特殊类型糖尿病和妊娠糖尿病（GDM）四类。–头条百科 病因 遗传因素 1型或2型糖尿病均存在明显的遗传异质性。糖尿病存在家族发病倾向，1/4～1/2患者有糖尿病家族史。临床上至少有60种以上的遗传综合征可伴有糖尿病。1型糖尿病有多个DNA位点参与发病，其中以HLA抗原基因中DQ位点多态性关系最为密切。在2型糖尿病已发现多种明确的基因突变，如胰岛素基因、胰岛素受体基因、葡萄糖激酶基因、线粒体基因等。 环境因素 进食过多，体力活动减少导致的肥胖是2型糖尿病最主要的环境因素，使具有2型糖尿病遗传易感性的个体容易发病。1型糖尿病患者存在免疫系统异常，在某些病毒如柯萨奇病毒，风疹病毒，腮腺病毒等感染后导致自身免疫反应，破坏胰岛素β细胞。 1型糖尿病 自身免疫系统缺陷 血液中可查出多种自身免疫抗体，如谷氨酸脱羧酶抗体(GAD抗体)、胰岛细胞抗体（ICA抗体）等,可以损伤人体胰岛分泌胰岛素的B细胞。 遗传因素 第6对染色体的HLA抗原异常上。 病毒诱因 1型糖尿病的发生，往往出现在病毒感染流行之后。如引起流行性腮腺炎和风疹及能引起脊髓灰质炎病毒，都可以在1型糖尿病中起作用。 其他 如牛奶、氧自由基、一些灭鼠药等，这些因素是否可以引起糖尿病，科学家正在研究之中。 检查 血糖 是诊断糖尿病的惟一标准。有明显“三多一少”症状者，只要一次异常血糖值即可诊断。无症状者诊断糖尿病需要两次异常血糖值。可疑者需做75g葡萄糖耐量试验。 尿糖 常为阳性。血糖浓度超过肾糖阈（160～180毫克/分升）时尿糖阳性。肾糖阈增高时即使血糖达到糖尿病诊断可呈阴性。因此，尿糖测定不作为诊断标准。 尿酮体 酮症或酮症酸中毒时尿酮体阳性。 糖基化血红蛋白（HbA1c） 是葡萄糖与血红蛋白非酶促反应结合的产物，反应不可逆，HbA1c水平稳定，可反映取血前2个月的平均血糖水平。是判断血糖控制状态最有价值的指标。 糖化血清蛋白 是血糖与血清白蛋白非酶促反应结合的产物，反映取血前1～3周的平均血糖水平。 血清胰岛素和C肽水平 反映胰岛β细胞的储备功能。2型糖尿病早期或肥胖型血清胰岛素正常或增高，随着病情的发展，胰岛功能逐渐减退，胰岛素分泌能力下降。 血脂 糖尿病患者常见血脂异常，在血糖控制不良时尤为明显。表现为甘油三酯、总胆固醇、低密度脂蛋白胆固醇水平升高。高密度脂蛋白胆固醇水平降低。 免疫指标 胰岛细胞抗体（ICA），胰岛素自身抗体（IAA）和谷氨酸脱羧酶（GAD）抗体是1型糖尿病体液免疫异常的三项重要指标，其中以GAD抗体阳性率高，持续时间长，对1型糖尿病的诊断价值大。在1型糖尿病的一级亲属中也有一定的阳性率，有预测1型糖尿病的意义。 尿白蛋白排泄量，放免或酶联方法 可灵敏地检出尿白蛋白排出量，早期糖尿病肾病尿白蛋白轻度升高。 治疗 自我监测 随着小型快捷血糖测定仪的逐步普及，病人可以根据血糖水平随时调整降血糖药物的剂量。1型糖尿病进行强化治疗时每天至少监测4次血糖（餐前），血糖不稳定时要监测8次（三餐前、后、晚睡前和凌晨3：00）。强化治疗时空腹血糖应控制在7.2毫摩尔/升以下，餐后两小时血糖小于10mmol/L，HbA1c小于7%。2型糖尿病患者自我监测血糖的频度可适当减少。 口服药物治疗 （1）磺脲类药物 2型DM患者经饮食控制，运动，降低体重等治疗后，疗效尚不满意者均可用磺脲类药物。因降糖机制主要是刺激胰岛素分泌，所以对有一定胰岛功能者疗效较好。对一些发病年龄较轻，体形不胖的糖尿病患者在早期也有一定疗效。但对肥胖者使用磺脲类药物时，要特别注意饮食控制，使体重逐渐下降，与双胍类或α-葡萄糖苷酶抑制剂降糖药联用较好。下列情况属禁忌证： 一是严重肝、肾功能不全； 二是合并严重感染，创伤及大手术期间，临时改用胰岛素治疗； 三是糖尿病酮症、酮症酸中毒期间，临时改用胰岛素治疗； 四是糖尿病孕妇，妊娠高血糖对胎儿有致畸形作用，早产、死产发生率高，故应严格控制血糖，应把空腹血糖控制在105毫克/分升（5.8毫摩尔/升）以下，餐后2小时血糖控制在120毫克/分升（6.7毫摩尔/升）以下，但控制血糖不宜用口服降糖药； 五是对磺脲类药物过敏或出现明显不良反应。 （2）双胍类降糖药 降血糖的主要机制是增加外周组织对葡萄糖的利用，增加葡萄糖的无氧酵解，减少胃肠道对葡萄糖的吸收，降低体重。 ①适应证肥胖型2型糖尿病，单用饮食治疗效果不满意者；2型糖尿病单用磺脲类药物效果不好，可加双胍类药物；1型糖尿病用胰岛素治疗病情不稳定，用双胍类药物可减少胰岛素剂量；2型糖尿病继发性失效改用胰岛素治疗时，可加用双胍类药物，能减少胰岛素用量。 ②禁忌证严重肝、肾、心、肺疾病，消耗性疾病，营养不良，缺氧性疾病；糖尿病酮症，酮症酸中毒；伴有严重感染、手术、创伤等应激状况时暂停双胍类药物，改用胰岛素治疗；妊娠期。 ③不良反应 一: 胃肠道反应。最常见、表现为恶心、呕吐、食欲下降、腹痛、腹泻，发生率可达20%。为避免这些不良反应，应在餐中、或餐后服药。 二: 是头痛、头晕、金属味。 三: 是乳酸酸中毒，多见于长期、大量应用降糖灵，伴有肝、肾功能减退，缺氧性疾病，急性感染、胃肠道疾病时，降糖片引起酸中毒的机会较少。 （3）α葡萄糖苷酶抑制剂 1型和2型糖尿病均可使用，可以与磺脲类，双胍类或胰岛素联用。 ①伏格列波糖餐前即刻口服。 ②阿卡波糖餐前即刻口服。 主要不良反应有: 腹痛、肠胀气、腹泻、肛门排气增多。 （4）胰岛素增敏剂 有增强胰岛素作用，改善糖代谢。可以单用，也可用磺脲类，双胍类或胰岛素联用。有肝脏病或心功能不全者者不宜应用。 （5）格列奈类胰岛素促分泌剂 ① 瑞格列奈为快速促胰岛素分泌剂，餐前即刻口服，每次主餐时服，不进餐不服。 ② 那格列奈作用类似于瑞格列奈。 胰岛素治疗 胰岛素制剂有动物胰岛素、人胰岛素和胰岛素类似物。根据作用时间分为短效、中效和长效胰岛素，并已制成混合制剂，如诺和灵30R，优泌林70/30。 （1）1型糖尿病 需要用胰岛素治疗。非强化治疗者每天注射2～3次，强化治疗者每日注射3～4次，或用胰岛素泵治疗。需经常调整剂量。 （2）2型糖尿病 口服降糖药失效者先采用联合治疗方式，方法为原用口服降糖药剂量不变，睡前晚10∶00注射中效胰岛素或长效胰岛素类似物，一般每隔3天调整1次，目的为空腹血糖降到4.9～8.0毫摩尔/升，无效者停用口服降糖药，改为每天注射2次胰岛素。 胰岛素治疗的最大不良反应为低血糖。 运动治疗 增加体力活动可改善机体对胰岛素的敏感性，降低体重，减少身体脂肪量，增强体力，提高工作能力和生活质量。运动的强度和时间长短应根据病人的总体健康状况来定，找到适合病人的运动量和病人感兴趣的项目。运动形式可多样，如散步，快步走、健美操、跳舞、打太极拳、跑步、游泳等。 饮食治疗 饮食治疗是各种类型糖尿病治疗的基础，一部分轻型糖尿病患者单用饮食治疗就可控制病情。 总热量 总热量的需要量要根据患者的年龄、性别、身高、体重、体力活动量、病情等综合因素来确定。首先要算出每个人的标准体重，可参照下述公式：标准体重（kg）=身高（cm）-105或标准体重（kg）=[身高（cm）-100]×0.9；女性的标准体重应再减去2kg。也可根据年龄、性别、身高查表获得。算出标准体重后再依据每个人日常体力活动情况来估算出每千克标准体重热量需要量。根据标准体重计算出每日所需要热卡量后，还要根据病人的其他情况作相应调整。儿童、青春期、哺乳期、营养不良、消瘦以及有慢性消耗性疾病应酌情增加总热量。肥胖者要严格限制总热量和脂肪含量，给予低热量饮食，每天总热量不超过1500千卡，一般以每月降低0.5～1.0kg为宜，待接近标准体重时，再按前述方法计算每天总热量。另外，年龄大者较年龄小者需要热量少，成年女子比男子所需热量要少一些。 碳水化合物 碳水化合物每克产热4千卡，是热量的主要来源，现认为碳水化合物应占饮食总热量的55%～65%，可用下面公式计算：根据我国人民生活习惯，可进主食（米或面）250～400g，可作如下初步估计，休息者每天主食200～250g，轻度体力劳动者250～300g，中度体力劳动者300～400g，重体力劳动者400g以上。 蛋白质蛋白质每克产热量4千卡。占总热量的12%～15%。蛋白质的需要量在成人每千克体重约1g。在儿童，孕妇，哺乳期妇女，营养不良，消瘦，有消耗性疾病者宜增加至每千克体重1.5～2.0g。糖尿病肾病者应减少蛋白质摄入量，每千克体重0.8g，若已有肾功能不全，应摄入高质量蛋白质，摄入量应进一步减至每千克体重0.6g。 脂肪 脂肪的能量较高，每克产热量9千卡。约占总热量25%，一般不超过30%，每日每千克体重0.8～1g。动物脂肪主要含饱和脂肪酸，植物油中含不饱和脂肪酸多。糖尿病患者易患动脉粥样硬化，应以植物油为主，更有利于控制血总胆固醇及低密度脂蛋白胆固醇水平。 危害 头条百科 急性严重代谢紊乱：指糖尿病酮症酸中毒和高渗性非酮症糖尿病昏迷。 感染性疾病：糖尿病容易并发各种感染，血糖控制差者更易发生也更严重。 慢性并发症 可累及全身各重要器官，可单独出现或以不同组合同时或先后出现。 微血管病变：糖尿病肾病、糖尿病视网膜病变、心脏微血管病变等。 糖尿病心肌病：心脏微血管病变和心肌代谢紊乱可引起心肌广泛灶性坏死，可诱发心力衰竭、心律失常、心源性休克和猝死。 糖尿病大血管病变：主要是糖尿病心脑血管疾病，如动脉粥样硬化性心血管疾病、脑梗死等。 神经系统并发症：可累及周围神经病变和植物神经病变。表现为四肢末梢麻木、刺痛；体位性低血压、尿潴留等。 糖尿病足：指与下肢远端神经异常和不同程度周围血管病变相关的足部溃疡、感染和（或）深层组织破坏，是糖尿病最严重和治疗费用最多的慢性并发症之一，是非外伤性截肢的最主要原因。 其他：糖尿病还可引起眼部、口腔、皮肤等疾病。 其他 中国2型糖尿病防治指南(2017年版) 中华医学会糖尿病学分会 - 1980 年的 0.67% 飙升至 2013 年的 10.4% - 肥胖人群糖尿病患病率升高了 2 倍 - 满族15.0%、汉族14.7%、维吾尔族12.2%、壮族12.0%、回族10.6%、藏族4.3%。 糖代谢状态分类 (WHO 1999) 糖代谢分类 空腹血糖 糖负荷后2h血糖 正常血糖 &lt;6.1 &lt;7.8 空腹血糖受损(IFG) ≥6.1，&lt;7.0 &lt;7.8 糖耐量异常(IGT) &lt;7.0 ≥7.8，&lt;11.1 糖尿病 ≥7.0 ≥11.1 糖尿病的诊断标准 诊断标准 静脉血浆葡萄糖(mmol/L) (1)典型糖尿病症状(烦渴多饮、多尿、多食、不明原因的体重下降)加上随机血糖或加上 ≥11.1 (2)空腹血糖或加上 ≥7.0 (3)葡萄糖负荷后2h血糖无典型糖尿病症状者，需改日复查确认 ≥11.1 注：空腹状态指至少8 h没有进食热量；随机血糖指不考虑上次用餐时间，一天中任意时间的血糖，不能用来诊断空腹血糖异常或糖耐量异常 1 型糖尿病病因和发病机制尚不清楚，其显著的病理学和病理生理学特征是 胰岛B细胞数量显著减少和消失 所导致的胰岛素分泌显著下降或缺失。 2 型糖尿病的病因和发病机制目前亦不明确，其显著的病理生理学特征为 胰岛素调控葡萄糖代谢能力的下降 (胰岛素抵抗) 伴随 胰岛B细胞功能缺陷 所导致的胰岛素分泌减少 ( 或相对减少 ) 发病特点 1 型糖尿病特点 发病年龄通常小于30岁 三多一少症状明显 以酮症或酮症酸中毒起病 体型非肥胖 空腹或餐后的血清C肽浓度明显降低 出现自身免疫标记 如谷氨酸脱羧酶抗体(GADA)、胰岛细胞抗体 (ICA)、人胰岛细胞抗原 2 抗体 (IA-2A)、锌转运体 8 抗体 (ZnT8A) 等 如果不确定分类诊断，可先做一个临时性分类用于指导治疗。 注: 人隐匿性自身免疫糖尿病 (LADA)， 在起病早期与 2 型糖尿病的临床表现类似，需要依 靠 GADA 以及其他胰岛自身抗体的检测才能明确诊断。 胰岛B细胞功能遗传性缺陷所致特殊类型糖尿病 线粒体DNA突变糖尿病：线粒体基因突变糖尿病是最为多见的单基因突变糖尿病，占中国成人糖尿病中的 0.6%。绝大多数线粒体基因突变糖尿病是由线粒体亮氨酸转运 RNA 基因 [tRNALeu(UUR)] 上的线粒体核苷酸序位 3243 上的A → G(A3243G) 突变所致。最为常见的临床表现为母系遗传、糖尿病或伴耳聋。对具有下列一种尤其是多种情况者应疑及线粒体基因突变糖尿病： ① 在家系内糖尿病的传递符合母系遗传。 ② 起病早伴病程中胰岛 B 细胞分泌功能明显进行性减低或尚伴体重指数低且胰岛自身抗体检测阴性的糖尿病者。 ③ 伴神经性耳聋的糖尿病者。 ④ 伴中枢神经系统、骨骼肌表现、心肌病、视网膜色素变性、眼外肌麻痹或乳酸性酸中毒的糖尿病患者或家族中有上述表现者。对疑似者首先应 tRNALeu(UUR)A3243G 突变检测。 青少年的成人起病型糖尿病(MODY)： MODY 是一种以常染色体显性遗传方式在家系内传递的早发但临床表现类似 2 型糖尿病的疾病。 MODY 是临床诊断。目前通用的 MODY 诊断标准是三点： ① 家系内至少三代直系亲属内均有糖尿病患者，且其传递符合常染色体显性遗传规律。 ② 家系内至少有一个糖尿病患者的诊断年龄在25岁或以前。 ③ 糖尿病确诊后至少在两年内不需使用胰岛素以控制血糖。 MODY 分型 基因 临床特征 1 肝细胞核因子-4α(HNF-4α) 青春期或成年早期进行性胰岛素分泌受损；高出生体重及新生儿暂时性低血糖；对磺脲类敏感 2 葡萄糖激酶(GCK) 病情稳定，非进行性空腹血糖升高；通常无需药物治疗；微血管并发症罕见；OGTT后2 h血糖较空腹血糖轻度升高(&lt;3mmol/L) 3 肝细胞核因子-1α(HNF-1α) 青春期或成年早期进行性胰岛素分泌受损；肾糖阈下降；OGTT后2 h血糖较空腹血糖显著升高(5mmol/L)；对磺脲类敏感&gt; 5 肝细胞核因子-1β(HNF-1β) 血糖升高伴肾发育性疾病(肾囊肿)；泌尿生殖道畸形；胰腺萎缩；高尿酸血症；痛风 10 胰岛素(INS) 胰岛素分泌缺陷，通常需要胰岛素治疗 13 钾离子通道Kir6.2(KCNJ11) 胰岛素分泌缺陷，对磺脲类敏感 糖尿病高危人群 成年人中糖尿病高危人群的定义 在成年人(&gt;18岁)中，具有下列任何一个及以上的糖尿病危险因素者: 年龄≥40岁； 有糖尿病前期(IGT、IFG或两者同时存在)史； 超重(BMI≥24)或肥胖(BMI≥28)和(或)中心型肥胖(男性腰围≥90 cm，女性腰围≥85 cm)； 静坐生活方式； 一级亲属中有2型糖尿病家族史； 有妊娠期糖尿病史的妇女； 高血压[收缩压≥140mmHg(1mmHg=0.133 kPa)和(或)舒张压≥90 mmHg]，或正在接受降压治疗； 血脂异常[高密度脂蛋白胆固醇(HDL-C)≤0.91 mmol/L和(或)三酰甘油(TG)≥2.22 mmol/L]，或正在接受调脂治疗； 动脉粥样硬化性心血管疾病(ASCVD)患者； 有一过性类固醇糖尿病病史者； 多囊卵巢综合征(PCOS)患者或伴有与胰岛素抵抗相关的临床状态(如黑棘皮征等)； 长期接受抗精神病药物和(或)抗抑郁药物治疗和他汀类药物治疗的患者[35-36]。 中心型肥胖是2型糖尿病最重要的高危人群 儿童和青少年中糖尿病高危人群的定义 在儿童和青少年(≤18岁)中，超重(BMI&gt;相应年龄、性别的第85百分位)或肥胖(BMI&gt;相应年龄、性别的第95百分位)且合并下列任何一个危险因素者： 一级或二级亲属中有2型糖尿病家族史； 存在与胰岛素抵抗相关的临床状态(如黑棘皮征、高血压、血脂异常、PCOS、出生体重小于胎龄者)； 母亲怀孕时有糖尿病史或被诊断为GDM. 药物干预预防2型糖尿病 在糖尿病前期人群中进行药物干预的临床试验显示，降糖药物二甲双胍、α- 糖苷酶抑制剂、噻唑烷二酮类药物 (TZDs), GLP-1 受体激动剂 以及 减肥药奥利司他 等药物治疗可以降低糖尿病前期人群发生糖尿病的风险。 对于糖尿病前期个体，只有在强化生活方式干预6个月效果不佳，且合并有其他危险因素者，方可考虑药物干预，但必须充分评估效益风险比和效益费用比，并且做好充分的医患沟通和随访。 2型糖尿病患者，早期进行严格血糖控制可以降低糖尿病微血管和大血管病变的发生. 阿司匹林对心血管疾病具有一定的保护作用。 防控基本原则 近期目标 是通过控制高血糖和代谢紊乱来消除和防止出现急性代谢并发症 远期目标 是通过良好的代谢控制达到 预防 慢性并发症、 提高 患者生活质量和 延长 寿命的目的。 糖尿病患者在诊断后，应接受糖尿病自我管理教育，掌握相关知识和技能，并且不断学习。 糖尿病自我管理教育和支持应以患者为中心，尊重和响应患者的个人爱好、需求和价值观，以此指导临床决策。 糖尿病自我管理教育是患者的必修教育课，该课程应包含延迟和预防2型糖尿病的内容，并注重个体化。 糖尿病自我管理教育和支持可改善临床结局和减少花费。 当提供糖尿病自我管理教育和支持时，健康教育提供者应该考虑治疗负担和患者自我管理的自我效能和社会与家庭支持的程度。 医护工作者应在最佳时机为糖尿病患者提供尽可能全面的糖尿病自我管理教育。 在规范化的专科糖尿病教育护士培养基础上，为患者提供糖尿病自我管理教育。 血糖监测 毛细血管血糖监测 Self-Monitoring of Blood Glucose (SMBG) 频率 4~7次/周 HbA1c (糖化血红蛋白) HbA1c在临床上已作为评估长期血糖控制状况的金标准，也是临床决定是否需要调整治疗的重要依据 正常参考值为: 4%~6% 阶段 频率 治疗之初 3月/次 治疗目标达到 6月/次 注意: 贫血和血红蛋白异常疾病的患者，HbA1c的检测结果是不可靠的 GA (糖化白蛋白) GA能反映糖尿病患者检测前2~3周的平均血糖水平 正常参考值为: 11%~17% 注意: 患有肾病综合征、肝硬化等影响白蛋白更新速度的疾病的患者，GA 的检测结果是不可靠的。 CGM (持续葡萄糖监测) 葡萄糖传感器皮下监测 © 中华医学会糖尿病学分会 2018 糖尿病急性并发症 急性并发症 糖尿病酮症酸中毒(DKA) 慢性并发症 糖尿病肾病(CKD) 糖尿病视网膜病变白内障、青光眼、视网膜血管阻塞及缺血性视神经病变等 糖尿病自主神经病变 血管自主神经病变 消化系统自主神经病变 泌尿生殖系统自主神经病变 其他自主神经病变 糖尿病性下肢血管病变 糖尿病足病 导致截肢和死亡 妊娠期显性糖尿病 也称妊娠期间的糖尿病，指孕期任何时间被发现且达到非孕人群糖尿病诊断标准: 空腹血糖 ≥ 7.0mmol/L 或糖负荷2h后 血糖 ≥ 11.1mmol/L，或随机血糖 ≥ 11.1mmol/L。 老年糖尿病的并发症 急性并发症包括HHS、DKA及乳酸酸中毒。部分老年糖尿病患者以HHS为首发症状。DKA多因停用胰岛素或出现感染、外伤等应激情况时诱发。乳酸酸中毒常见于严重缺氧及肾功能不全的患者。血糖、渗透压、酮体、血气及乳酸检测有助于鉴别诊断。老年糖尿病急性并发症死亡率较高，需要及时启用胰岛素治疗。 慢性并发症糖尿病大血管病变以动脉粥样硬化为基本病理改变，主要包括心、脑及下肢血管病变，具有症状相对较轻或缺如，但病变范围广泛且严重，治疗困难，预后差等特点，是老年糖尿病伤残和死亡的主要原因。随着增龄及糖尿病病程增加，微血管病变患病率增高。糖尿病视网膜病变常见，但因多伴有白内障致使实际诊断率下降。老年糖尿病肾损害是多种危险因素共同作用的结果，血肌酐水平不能准确反映肾功能状态，需要计算肌酐清除率。老年糖尿病患者神经系统损害常见，包括中枢神经系统病变、周围神经病变、自主神经病变等。 老年综合征老年糖尿病患者易于出现包括跌倒、痴呆、尿失禁、谵妄、晕厥、抑郁症、疼痛、睡眠障碍、药物滥用、帕金森综合征、压疮、便秘、营养不良、听力障碍和衰弱综合征等在内的老年综合征，严重影响患者的生活质量和预期寿命，增加了糖尿病管理的难度 [418]。对此类患者更需要全面评估后慎重考虑治疗获益与风险的平衡，确定以改善生活质量为主的安全治疗策略。 中医理论 © 中华医学会糖尿病学分会 2018 古人所述消渴病，多以“三多一少”为主要表现，以阴虚为本，燥热为标主论，采用上、中、下三消辨证。而现代，糖尿病多以肥胖为特征。 More papers Journals for diabetes Name SCI 中科院分区 2020 Journal of Diabetes Research 收录 3区 2.965 metaflammation Jixin Zhong et al., 2017 oral microbiome J. Long et al., 2017 sample size: Diabetes obese non‐diabetics normal weight non‐diabetics 98 99 97 Result: multiple bacteria taxa in the phylum Actinobacteria (放线菌门) are associated with the risk of type 2 diabetes. Some are also associated with the prevalence of obesity, suggesting that the oral microbiome may play an important role in diabetes etiology. Type 2 Diabetes Mellitus Related Genes ABCC8, Haptoglobin, KCNJ11, ACDC, ENPP1, TNF-α, and TCF7L2. Evans Adu Asamoah 2020 PNPLA2 Chinese Han population: 2 tagSNPs, PNPLA2 rs28633403 (A&gt;G) and rs1138714 (A&gt;G), were associated with DKD (Diabetic kidney disease). Function: This gene encodes an enzyme which catalyzes the first step in the hydrolysis of triglycerides in adipose tissue. Mutations in this gene are associated with neutral lipid storage disease with myopathy. Jul 2010 Hailing Zhao 2020 ADIPOQ ADIPOQ rs2241766 Gene Polymorphism and Predisposition to Diabetic Kidney Disease. Qiuxia Han 2020 调节巨噬细胞极化可减轻糖尿肾病 Attenuation of Diabetic Nephropathy in Diabetic Mice by Fasudil through Regulation of Macrophage Polarization Fajiang Xie 2020","link":"/2020/07/02/LearnNotes/diabetes/"},{"title":"Principles of Biochemistry 14 |Glycolysis in Bacterial| Class Notes |HarvardX","text":"Aerobes Condition Metabolic pathways in becteria that operate with Low O2 Exp: E. Coli Multiple fermentation product: For example, lactate, ethanol, acetate, citrate. © HarvardX © HarvardX Fermentation Branches © HarvardX Anaerobic Respiration and ATP Respiration Type O2 Electron Receptor Product $\\Delta G (kJ/2e^ -)$ Cellular Respiration O2 is sufficient O2 H2O -219.07 Fermentation O2 is not used Varieties Varieties Anaerobic (Denitrifier)) O2 is not used NO3- N2 -209.46 Anaerobic (Metal Reducer)) O2 is not used Fe3+ Fe2+ -206.12 Anaerobic (Sulfidogen)) O2 is not used SO42- HS- -20/24 Anaerobic (Mehtanogen)) O2 is not used CO2 CH4 -14.58 Dinitrifying Fe^2+^: Ferrous iron hemoglobin Fe^3+^: Ferric iron methemoglobin $2NO_ 3 ^- + 12H^ + 10 e^ - \\to N_ 2 + 6 H_ 2O$ $NO_ 3 ^- \\to NO_ 2 ^-$ Nitrate to Nitrite $NO_ 2 ^- \\to NO$ Nitric oxide $NO\\ \\ \\to N_ 2O$ Nitrous oxide $N_ 2O\\ \\to N_ 2$ Dinitrogen © HarvardX; Dinitrifying Bacterial and human health The exist of bacterial: Colonization: Begins at birth First from mother Then from environment Diversity: Nutrient availability Physical/chemical environment Anti-microbial defenses Microbe interaction and modification of the local environment Beneficial: Pathogen defence Metabolic function Immune system maintain Energy balance Disrabtion: digraph{ rankdir = \"LR\" mm1 [label=\"\", shape=none, width=0, height = 0] NO [label=\"NO2- + 2H+||NO + H2O\", shape = \"record\", color = \"none\"] Fe [label=\"Fe2+||Fe3+\", shape = \"record\", color = \"none\"] NO3 -> NO:f1 NO:f1 -> mm1 [dir =none, headport = n] NO:f3 -> mm1 [dir =back, headport = s] mm1 -> Fe:f1 [dir =none, tailport = n] mm1 -> Fe:f3 [tailport = s] } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });","link":"/2021/04/28/LearnNotes/edx-biochm-14/"},{"title":"Principles of Biochemistry 15 |Citric Acid Cycle| Class Notes |HarvardX","text":"Quick View of the Citric Acid Cycle Key of the pathway: Electron donating and accepting. Fuel molecules will pass the electrons to universal electron acceptors, such as as NAD+ and FAD. © HarvardX Glucose is not the only source to contribute Citric acid. Some bacteria convert amino acid or fatty acid to Acetyl-CoA to feed citric acid cycle. Oxidative Decarboxylation Pyruvate to Acetly-CoA © tuscany-diet.net Pyruvate Dehydrogenase Complex (PDH complex): E1, E2, E3 In bacteria, the PDH complex contains the catalytic core formed by eight trimers, each made of three E2 subunits. Each one of these 24 E2 subunits is divided into three domains-- a flexible deployment domain. The number of the E1, E2, and E3 is varied from species to species. More Structure information: tuscany-diet.net The Activity of the PDH complex is relied on Co-Enzymes: E1 THiamine phosphate (TPP) E2 Coenzyme A(CoA) Lipoate (Lipoic acid) E3 Flavine adenine dinucleotide (FAD) Nicotinamide adenine dinucleotide (NAD+) 4 Steps of Oxidative Decarboxylation Decarboxylation Oxidation Trasfer Regeneration General view: © tuscany-diet.net Acytyl Coa here could be converted into lipids and this is how the glucose was converted into fatty acid. But even thought the process of oxidative decarboxylation is reversible, mammals which lack of called a glyoxylate cycle can not turn lipids to glucose Decarboxylation Catalyzed by E1 Carbon from TPP is very acidic and can be deprotanated and react with pyruvate © HarvardX Pyruvate bind the active site of E1, CO2 is released. The active site of E1 is connected to the surface of E1 by a 20-angstrom long hydrophobic channel. So our hydroxylethyl TPP, the product of the first reaction is at the bottom of this channel Oxidation Catalyzed by E1 Disulfide bond from lipoamide arm is broken. © HarvardX Thioester group have very high free energy. The flexible arm of lipoamide that is bound to E2 will penetrate into the channel in E1 and bring the reactive part of the lipoamide arm very close. And lipoamide arm swings ot of the E1 active side and enters the catalytic core formed by the E2 subunits. Transfer Catalyzed by E2 © HarvardX Acetyl coenzyme A is released and fully reduced arm is formed. 4. Regeneration © HarvardX the Reduced dihydrolipoamide swings from E2 to E3, where the dusulfide bond is regenerated, FADH2 isformd, and then re-oxidized again by transferring its electrons and protons to NAD+ that was bound to E3. PDH complex regulation PDH complex activity depens on the energey states of the cell. When the energy state is high, which has high concentration of ATP, PDH activity was inhibited. Allosteric reugulaion of PDH Energy State High Acetyl-CoA High NADH High ATP High Fatty Acid High Allosteric activators Low concentration Energy: high concentration of CoA, NAD+, and AMP Phosphorylation $$ PDH \\underset{Phosphatase(PDP)}{\\overset{Kinase(PDK)}{\\rightleftharpoons }} PDH^ {_ -}p $$ PDK phosphorylates the PDH complex on E1 and in activate the PDH Acetyl-CoA, NADH, and ATP anctivate the PDK. Pyruvate and ADP prohibit the activity of PDK. Calcium which release during the muscle contraction will activate the PDP. Citric Acid Cycle The function of the citric acid cycle Reduce the electron donors which used in ATP synthesis. Acetyl-CoA was full oxidized and generate CO2 Acetyl-CoA was coming from Glucose (Pyruvate), Fatty Acid, and Amino Acid. Producing precursors for fatty acid and amino acid biosynthesis Oxaloacetate, a citric acid intermediate plays a bypass role: $Pyruvate \\to Oxaloacetate \\to Malate \\overset{Out of Mitochondira}{\\to} PEP \\to Glucose$ (PEP: Phosphoenolpyruvate) Acetyl-CoA to Glucose Not possible in mammals: pyruvate to Acytyl-CoA is highly exergonic. Stoichiometry of the citric acid cycle: The Carbon was lost: As a result, the reversible reaction requires the bypass reaction to prevent the carbon-losing. Some organism like Archea, Bacteria, Protists, Plants, and Fungi are able to revers the Acetyl-CoA to Pyruvate. © HarvardX Enzymes for Gluconeogenesis In mammals, two key enzymes are lacked for the the Gluconeogenesis: Glyoxylate and Succinate Human healthy with Glyoxylate Cycle Effects: Environment changes Food source shifts Invade other organisms Fungi and Bacteria Stagonospora nodorum: It can cause diseases on cereals. It is a necrotic pathogen that relies on glyoxylate cycle during the infection. Increased malate synthase activity during spore germination and virulence. And this activity increases further with the fungus becomse more virulent. Experiment: The mutation of the mls 1 fungus are unable to create lesions. (Inactivation of the malate synthesis) Colletotrichum lagenarium which could cause lesions on both fruit and leaves of melon plants. The ability of creating lesions are decreased in icl 1 knok-out fungus. (Lacking isocitrate lyase) Candida albicans In microbiota of mammalian skin and gastrointestial-tract Implicate in fungal infections of mucosal surfaces, sytemeic infections in immunocompormised patients. During proliferation, it relies on: Isocitrate lyase(ICL) Malate synthetase(MS) Irg 1 is essential for the activity of the macrophage. LPSs (Lipopolysaccharides), a natural component of the bacterial outer membrane Connection Irg 1 triger the production of itaconic acid. itaconic acid prohibit the isciotrate lyase produced by pathogenic bacteria to blocking the Glyoxylate cycle. itaconic acid is derived from citric acid cycle. Relation IRG-1 is the enzyme that catalyzes the decarboxylation of cis-aconitate. Example of Mycobacterium tuberculosis Hypothesis: Limited Nutrition At the beginning of the process, the bacteria allows them to use acetate and acetyl groups as a food source. (C2) This metabolic switch included the activation of the glyoxylate cycle. Response to phagocytose Increasing their level of isocitrate lyase isocitrate lyase upregulates the glyoxylate cycle to compensating the itaconic acid. Survive The compensate effect allow it survive inside macrophages. Evidence: isocitrate lyase silence M. tuberculosis do not survive in macrophages. itaconic acid inhibits the growth of M. tuberculosis in the presence of citrateas a sole source of carbon. Because the isocitrate lyase and malate synthase are not found in human, they could be got targets in therapies. Y. pestis expression ripABC operon: RipA, RipB, RipC. Vitro experiments shown that those three protein could convert itaconic acid into pyruvate. digraph{ LPS [label=\"LPS stimulatoin\"] IRG1 [label=\"Expression of\\nimmunoresponsive gene 1 (Irg1)\"] Analysis [label = \"Analysis of metabolites\\nvia mass spectrometry\"] Macrophage -> LPS -> IRG1 -> Analysis } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });","link":"/2021/04/28/LearnNotes/edx-biochm-15/"},{"title":"Principles of Biochemistry 13 |Glycolysis in Red Blood Cell| Class Notes |HarvardX","text":"Red Blood Cell © Philip W Kuchel, et al. Physiological Adaptation of RBC: one third of the volume is occupied by hemoglobin. lack of intercellular organelles, like Mitochondrial allows deformation for moving through narrow capillaries lactate fermentation Cori cycle: lactate catabolism Cori Cycle Rapoport-Luebering shunt It is a pathway that converts 1, 3-bisphosphoglycerate, one intermediate of glycolysis, into its isomer, 2,3-BPG. As a bypass pathway, the ATP generation was avoid. As a result, most cells have a very low lever of the 2,3-BPG. But it is very high in RBC since this molecule has a very important function in release of Oxygen. NADH was produced in Glycolysis works for maintaining the iron in Fe2+ state, which was used to carry the Oxygen. NADH maintains reduced iron HMP shut HMP shut could protect RBC from reactive oxygen species. Defense against ROS Oxygen Tranportaion Conformation Chage: R-State (oxygenated, high affinity) T-State (non-oxygenated, low affinity) Affinity Cooperative binding: Dynamic Oxygen biding Releasing about 25% of oxygen When it is needed, it could releasing 75% of O2 $$ Hb \\underset{O_ 2}{\\overset{K1}{\\rightleftharpoons}} HbO_ 2 \\underset{O_ 2}{\\overset{K2}{\\rightleftharpoons}} Hb(O_ 2)_ 2 \\underset{O_ 2}{\\overset{K3}{\\rightleftharpoons}} Hb(O_ 2)_ 3 \\underset{O_ 2}{\\overset{K4}{\\rightleftharpoons}} Hb(O_ 2)_ 4 $$ © HarvardX Binding affinity change Leftward shift: higher affinity Rightward shift: lower affinity PH The PH changed, which also connected the change of concentration’s level of CO2: Muscle: CO3, reducing the PH, which causing Rightward shift, and decreasing the affinity, increasing the releasing of the O2 Lungs: CO3 reduced, PH increased. 2,3-BPG In the T-shape it was bond In the R-shape, the bond was crushed and 2.3-BPG was released. digraph{ rankdir = \"UD\" node [shape = box ] Lactates1 [label =\"Lactate *2\"] Lactates2 [label =\"Lactate *2\"] ATP [shape = \"none\"; fontcolor = \"white\"] ATP6 [label = \"ATP *6\"; shape = \"none\"; fontcolor = \"white\"] Glucose [label = \"Glucose\", shape =\"hexagon\", height = 1] Glucose2 [label = \"Glucose\", shape =\"hexagon\", height = 1] mm1 [label = \"\" , shape = none, height = 0, width = 0] mm2 [label = \"\" , shape = none, height = 0, width = 0] mm3 [label = \"\" , shape = none, height = 0, width = 0] mm4 [label = \"\" , shape = none, height = 0, width = 0] Lactates1 -> Lactates2 [label = \"transport\"; style =\"dashed\"] Lactates2 -> mm2 [arrowhead = none; headport=\"n\"] mm2 -> Glucose2 subgraph cluster_1{ label = \"Red Blood Cell\" style = \"filled\" color = \"crimson\" fontsize = 20 Glucose; mm1; {rank=same; Glucose; Lactates1; mm1} Glucose->mm1 [dir = none] mm1 -> Lactates1 mm1 -> ATP } subgraph cluster_2{ label = \"Liver\" style = \"filled\" color = \"deeppink4\" fontsize = 20 Glucose2; Lactates2 ATP6 -> mm2 } } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });digraph{ ATP3 [label=\"ATP\", color=\"salmon\", style=\"filled\"] ADP3 [label=\"ADP\"] BSG [label = \"1,3-\\nBisphosphoglycerate\", shape = underline] Phos [label = \"3-Phosphoglycerate\", shape = underline] BPG [label = \"2,3 - BPG\", shape = \"box\"] mm7 [label = \"Phosphoglycerate\\nkinase\" , shape = box, color = \"coral\", fontcolor = \"coral\"] BSG -> mm7 [dir = back, color = \"deeppink\"] mm7 -> Phos [color = \"deeppink\"] BSG -> BPG [label =\"mutase\", dir=both, color = \"red\"] BPG -> Phos [label = \"Rapoport-\\nLeubering shunt\", color = \"red\", tailport =\"s\"] {rank=\"same\"; BSG; BPG} subgraph BB{ {rank = same; ADP3; mm7} {rank = same; ATP3; Phos} ADP3 -> mm7 [arrowhead =none, headport = \"s\"; color = \"blue\"] mm7 -> ATP3 [tailport = \"s\"; color = \"blue\"] } } var viz = new Viz(); var code = document.getElementById(\"graphviz-1-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-1\").append(element) });digraph{ rankdir = \"LR\" mm1 [label = \"\" , shape = none, height = 0, width = 0] mm2 [label = \"\" , shape = none, height = 0, width = 0] mm3 [label = \"\" , shape = none, height = 0, width = 0] Fe [ label = \" Fe(3+)-Hb || Fe(2+)-Hb\" shape = \"record\" color = \"white\" ]; cytochrome [ label = \" Reduced\\ncytochrome b5 || Oxidized\\ncytochrome b5\" shape = \"record\" color = \"white\" ]; NAD [ label = \" NAD+ || NADH\" shape = \"record\" color = \"white\" ]; Glu [ label = \" Glyceraldehyde\\n-3-P ||1,3-\\nbisphosphoglycerate\" shape = \"record\" color = \"none\" ]; Fe:f1 -> mm1 [arrowhead = none, headport =\"N\", color = \"red\"] Fe:f3 -> mm1 [dir = \"back\", headport =\"s\", color = \"red\"] mm1 -> cytochrome:f1 [arrowhead = none, tailport =\"N\"] mm1 -> cytochrome:f3 [tailport =\"s\"] cytochrome:f3 -> mm2 [arrowhead = none, headport =\"s\", color = \"red\"] cytochrome:f1 -> mm2 [dir = \"back\", headport =\"n\", color = \"red\"] mm2 -> NAD:f1 [tailport =\"n\"] mm2 -> NAD:f3 [arrowhead = none, tailport =\"s\"] NAD:f1 -> mm3 [arrowhead = none, headport =\"n\", color = \"red\"] NAD:f3 -> mm3 [dir = \"back\", headport =\"s\", color = \"red\"] mm3 -> Glu:f1 [tailport =\"n\"] mm3 -> Glu:f3 [tailport =\"s\"] subgraph cluster_1{ Glu label = \"Glucose Glycolysis\" style = \"filled\" color = \"aquamarine2\" fontcolor = \"salmon\" fontsize = 20 } } var viz = new Viz(); var code = document.getElementById(\"graphviz-2-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-2\").append(element) });digraph{ subgraph cluster_1{ hexo2 [label = \"\", shape = hexagon, width = 1, height = .8] node [style=filled,color=white]; label = \"Glucose-6-phosphate\"; URL=\"https://www.bing.com\"; subgraph C{ rank = same P1 -> hexo2 [dir = none, headport = \"nw\", arrowhead =\"none\"] } color = \"white\"; labeljust=l labelloc=b } subgraph cluster_2{ hexo3 [label = \"\", shape = hexagon, width = 1, height = .8] node [style=filled,color=white]; label = \"Fructose-6-phosphate\"; URL=\"https://www.bing.com\"; subgraph C{ rank = same P2 -> hexo3 [dir = none, headport = \"nw\", arrowhead =\"none\"] } color = \"white\"; labeljust=l labelloc=b } subgraph cluster_3{ hexo4 [label = \"\", shape = hexagon, width = 1, height = .8] node [style=filled,color=white]; label = \"Fructose-1,6-phosphate\"; URL=\"https://www.bing.com\"; subgraph C{ rank = same P3 -> hexo4 [dir = none, headport = \"nw\", arrowhead =\"none\"] hexo4 -> P4 [dir = none, arrowhead =\"none\"] } color = \"white\"; labeljust=l labelloc=b } mm2 [label = \"Phosphoglucose\\nisomerase\" , shape = box, color = \"coral\", fontcolor = \"coral\"] mm3 [label = \"Phospho\\nFructokinase\" , shape = box, color = \"coral\", fontcolor = \"coral\"] mm4 [label = \"Aldolase\" , shape = none, color = \"coral\", fontcolor = \"coral\"] mm5 [label = \"Triose\\nphosphate\\nisomerase\" , shape = box, color = \"coral\"] mm6 [label = \"\" , shape = none, height = 0, width = 0] mm7 [label = \"\" , shape = none, height = 0, width = 0] P1 [label=\"\", shape = circle, color= \"cyan3\", height = 0.3, width = 0.3] P2 [label=\"\", shape = circle, color= \"cyan3\", height = 0.3, width = 0.3] P3 [label=\"\", shape = circle, color= \"cyan3\", height = 0.3, width = 0.3] P4 [label=\"\", shape = circle, color= \"cyan3\", height = 0.3, width = 0.3] hexo2 -> mm2 [dir = none , color = \"deeppink\"] mm2 -> hexo3 [ color = \"deeppink\"] hexo3 -> mm3 [dir = none , color = \"deeppink\"] mm3 -> hexo4 [ color = \"deeppink\"] hexo4 -> mm4 [dir = none , color = \"deeppink\"] mm4 -> GAP [color = \"deeppink\"] DHAP -> mm4 [dir = back , color = \"deeppink\"] DHAP -> mm5 [dir = back , color = \"deeppink\", headport = w] mm5 -> GAP [color = \"deeppink\", tailport = e] hexo2 -> mm6 [headport = \"w\"; dir = none] mm6 -> mm7 [dir = none] HMP -> hexo3 [headport = \"w\"; color =\"red\"] HMP -> DHAP [headport = \"w\"; color =\"red\"] subgraph C{ rank = same mm4 DHAP [label= \"Dihydroxyacetone\\nphosphate\", shape = underline] GAP [label= \"Glyceraldehyde\\n3-phosphate\", shape = underline] } subgraph cluster_4{ node [shape = none] NADP [label =\"NADP+\"] Red [label = \"Reduced\\nglutathione\"] Oxi [label = \"Oxidized\\nglutathione\"] DeROS [label = \"Destroyed\\nROS\"] mm8 [label = \"\" , shape = none, height = 0, width = 0] mm9 [label = \"\" , shape = none, height = 0, width = 0] mm7 -> HMP {rank = \"same\"; mm6; mm7; HMP} NADP -> mm7 [dir = none, headport = \"e\"; color=\"red\"] mm7 -> NADPH [tailport = \"w\"; color=\"red\"] NADPH -> mm8 [dir = none, headport = \"w\"] mm8 -> NADP [tailport = \"e\", color=\"black\"] {rank = \"same\"; NADP; NADPH} Oxi -> mm8 [dir = none, headport = \"e\"; color=\"red\"] mm8 -> Red [tailport = \"w\"; color=\"red\"] Red -> mm9 [dir = none, headport = \"w\"] mm9 -> Oxi [tailport = \"e\", color=\"black\"] {rank = \"same\"; Oxi; Red} ROS -> mm9 [dir = none, headport = \"e\"; color=\"red\"] mm9 -> DeROS [tailport = \"w\"; color=\"Red\"] {rank = \"same\"; ROS; DeROS} label = \"HMP shut:\\ndefense\\nagainst ROS\" fontcolor = \"white\" fontsize = 20 style = \"filled\" color = \"darksalmon\" labeljust= \"l\" } } var viz = new Viz(); var code = document.getElementById(\"graphviz-3-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-3\").append(element) });","link":"/2021/04/24/LearnNotes/edx-biochm-13/"},{"title":"Principles of Biochemistry 17 |ATP Synthesis| Class Notes |HarvardX","text":"Quick View $NADH + H^ + frac{1}{2}O_ 2 \\to NAD^ + H_ 2O$ 1. $NAD^ + + H^ + 2e^ - \\to NADH$ E’O2~~ = - 0.32V 2. $ frac{1}{2}O_ 2 + 2H^ + + 2e^ - \\to H_ 2O$ E’O1~~ = + 0.82V $\\Delta G’^ {\\circ} = -nF\\Delta E’^ {\\circ} $ $n = 2$ $F = 96.5kJ/Vmol$ $\\Delta E’^ {\\circ} = E’^ {\\circ}_ acceptor - E’^ {\\circ} _ donor $ $\\ \\ \\ \\ \\ \\ \\ \\ =0.82 -(-0.32)$ $\\ \\ \\ \\ \\ \\ \\ \\ =1.114 V$ $\\Delta G’^ {\\circ} = -220.1kJ/mol$ The movement of the proton: $NADH + 11H^ +_ M + frac{1}{2}O_ 2 \\to NAD^ + 10H^ +_ I +H_ 2O$ Energetic of a proton Gradient: $\\Delta = RT\\ ln(frac{C_ I}{C_ M})+ ZF\\Delta \\Psi$ Chemical Potential + Electrical Potential Derivation In a simple reaction: S -&gt; P $\\Delta G = \\Delta G’^ {\\circ} + RT\\ ln[P]/[S]$ But in Transport across a membrane, there are no covalent bonds formed. As a result, the $\\Delta G’^ {\\circ} = 0$ $\\Delta G = RT\\ ln \\frac{C_ I}{C_ M}$ $ln(C_ I/ C_ M) = 2.3log(C_ I / C_ M)$ $\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ = 2.3(log(C_ I) - log(C_ M))$ $\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ = 2.3(log[H^ +]_ I - log[H^ +]_ M)$ $pH = 1 / log[H^ +]= - log[H^ +]$ $ln(C_ I/ C_ M) = 2.3(pH_ M - pH_ I)$ $ln(C_ I/ C_ M) = 2.3 \\Delta pH$ $$ \\Delta G = 2.3 RT \\Delta pH + F\\Delta \\Psi (when Z =1) $$ Experimental value: $\\Delta \\Psi = 0.15 - 0.2 V$ Matrix pH &gt; IMS pH $\\Delta pH = +0.75$ Energy cost to pump H+ $\\Delta G = 2.3 RT \\Delta pH + F\\Delta \\Psi = 20kJ/mol H^ +$ Energy cost to pump 10 moles H^+ $\\Delta G = 200 kJ/mol$ The energy released by the transport of electrons through ETC: $220 kJ/mol$ of NADH oxidized, which is enough for pump 10 protons. ATP Synthase It’s huge: over half of megadalton Like a motor Two main parts: F0 sub-unit: one driven by protons F1 sub-unit: one driven by ATP The ATP hydrolysis decrease the ATP, the proton pump drives the reverse action of ATP hydrolysis. F0 sub-unit It contains 10 to 15 c-chains and each c-chain is composed of two alpha-helices scanning. On the one side of the c-chain, there is a-chain that contains a proton channel and isolates a couple of c-chains from surround lipids. F1 sub-unit It is an ATP driving motor that contains five types of chains: $\\gamma$ and $\\epsilon$ chains from the axle (the center) are also called a stalk. The stalk interact with the c-ring of the F0 sub-units, and rotate through a ring of six chains: 3 $\\alpha$ and 3 $\\beta$ chains that from the rest of the F1 subunit $\\delta$ anchors the hexamer to the B subunit that embed into membrane and prevent itself rotating. 3 pair of $\\alpha$ and $\\beta$ dimmer in the bottom of the ATP synthase and form the core of this enzyme. both of them could bind ATP. $\\alpha$ chain might have a catalytic regulatory role $\\beta$ chain has only catalytic role The stalk is not symmetrical and forces the $\\beta$ chains into 3 distinct conformations. Binding Change Model Paul Boyer. $\\beta$ Chains have three distinct states on ATP synthase: O state: open state, low affinity to ATP and ADP which means ATP and ADP could bind and lose easily. L state: loss conformation. it has a high affinity to ADP and inorganic phosphate. T state: tight conformation which is the high avidity for ATP Each $\\beta$ chain was bound with a molecule of ATP. As a result, three ATP are produced per turn of the stalk. Protons Caclultion There is 10 to 15 (#N) number of c-chains in a ring. So, it needs #N protons. to flow back to through F0. A full turn of c-chain also corresponded with producing 3 APT molecules. Therefore, the proton need for each ATP is #N/3 proton motive force ATP is used outside of mitochondria. Adenine translocase coordinates the ATP-ADP exchange. ATP carries 4 negative charges, ADP carries 3 negative charges. ATP transport causing one negative charge into the interspace. phosphate Phosphate translocase is responsible for the transport of PO4- It’s neutralized the charge brings by ATP transport.","link":"/2021/05/12/LearnNotes/edx-biochm-17/"},{"title":"Principles of Biochemistry 16 |Electron Transport| Class Notes |HarvardX","text":"Quick View $NADH, FADH_ 2 \\to NAD^ +, FAD + e^ -$ $e^ - + O_ 2 \\to H_ 2O | ADP + Pi \\to ATP$ Universal electron acceptor NAD $NAD^ + \\rightleftharpoons NADH + H^ +$ Exp: Malate dehydrogenase $malate \\to oxaloacetate$ $ C_ 4H_ 6O_ 5 + NAD^ + \\to C_ 4H_ 4O_ 5 + NADH + H^ +$ NADP NADP is the nicotinamide adenine dinucleotide phosphate, NADPH fules electron to anabolic reactions or biosynthesis reaction, and not directly involved in ATP synthesis. NADH fules electron to electron transport chain and is resbonsible for catabolic reactions and ATP synthesis. FAD Flavin adenine dinucleotide, family of vitamin B2. $reduced substrate + FAD \\rightleftharpoons FADH^ + + Oxidized substrate $ $reduced substrate + FADH^ + \\rightleftharpoons FADH_ 2 - + Oxidized substrate $ What drives the flows the electron Electron affinity Electron affinity was measured by reduction potential Electron will flow from the donor into receptor which has higher reduction potential. $Donor(e^-) \\to Receptor$ $low reduction potential \\to high reduction potential$ As a result, we can find that the flow of the electrons was driven by the free energy, which is $\\Delta G$ We can have the function: $\\Delta G = -nF\\Delta E$ $\\Delta G’^ { \\circ} = -nF\\Delta E’^ { \\circ} $ $n$: Number of e- transferred $F$: Faraday constant Exp: Calculating $\\Delta G^ {'\\circ}$ for a redox reaction This is a second reaction in the fermentation pathway $Acetaldehyde + NADH + H^ \\to ENthonal + NAD^ $ Step 1: seperate the reaction Reaction Energy $Acetaldehyde + 2H^ + 2e^ -\\to ENthonal $ $E’^ { \\circ} = -0.197V$ $NAD^ + 2H^ + 2e^ -\\to NADH + H^ +$ $E’^ { \\circ} = -0.320V$ $\\Delta E’^ { \\circ} = E’^ { \\circ}_ {acceptor} - E’^ { \\circ}_ {donor}$ $\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ = (-0.197V) - (-0.320V)$ $\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ = 0.123V$ The $\\Delta E’^ {\\circ}$ is larger than 0, which suggest the reaction is spontaneous. We can also verify this by calculate the $\\Delta G$: $\\Delta G’^ {\\circ} = -nF\\Delta E’^ {\\circ}$ $\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ = -2(96.5 kJ/Vmol)(0.123V)$ $\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ = - 23.7 kJ/mol$ $\\Delta G’^ {\\circ} $ is lesser than 0 which confirmed it is spontaneous. Exp2: under nonstandard condition: [Acetaldeyde], [NADH] = 1M [ethanol],[NAD+] = 0.1 M $E_ {acetald} = E’^ {\\circ} \\frac{RT}{nF} Ln\\frac{[acetaldehyde]}{[ethanol]} = - 0.167V$ $E_ {NAD^ +} = E’^ {\\circ} \\frac{RT}{nF} Ln\\frac{[NAD^ +]}{[NADH]} = - 0.350V$ $\\Delta E’^ { \\circ} = E’^ { \\circ}_ {acceptor} - E’^ { \\circ}_ {donor}$ $\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ = (-0.167V) - (-0.350V)$ $\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ = 0.183V$ $\\Delta G = -nF\\Delta E$ $\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ = -2(96.5 kJ/Vmol)(0.183V)$ $\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ = - 35.3 kJ/mol$ Spontaneous under these conditions Electron carriers Ubiquinone (Q) © PubChem:5281915 It is called Benzoquinone (Q) with a very long isoprenoid tail and it is extremely hydrophobic and diffuses inside the inner membrane of the Mt. $H^ + + e^ - + Q \\to QH\\cdot$: semi-reduced semiquinone QH $H^ + + e^ - + QH \\to QH_ 2$: full coenzyme QH2 (Ubiquinone) Cytochromes 3 types of Cytochromes were defined by the hemes. Heme A: cytochrome A Heme B: cytochrome B Heme C: cytochrome C © PubChem:126456446 © PubChem:4973 © PubChem:439171 Integral membrane protein Integral membrane protein Peripheral membrane protein Electron Transport $NADH \\overset{Complex I}{\\to} Q \\overset{Complex II}{\\to} Cyt_ b \\overset{Complex III}{\\to} Cyt_ {c_ 1} \\overset{Complex III}{\\to} Cyt_ c \\overset{Complex IV}{\\to} Cyt_ a \\overset{Complex IV}{\\to} Cyt_ {a_ 3} \\overset{Complex IV}{\\to} O_ 2$ Electron can’t skip the intermediate steps in this chain. Complex I © molview: pdbid=3m9s The grey part is the hydrophobic tail which elongated into inner membrane. (Which is supposed have only one tail…) Complex I: NADH-ubiquinone oxidoreductase It as a L shape, with an arm in mitochondria matrix and eleongated into the inner membrane. FMN univeral electron acceptor in its arm interacte with NADH. $FMN + H^ + + e^ - \\to FMNH\\cdot$ $FMNH\\cdot + H^ + + e^ - \\to FMNH_ 2$ Electron transferring inner Complex I: $FNA \\to N-2 \\to Q \\to QH_ 2$ Complex II © molview: pdbid=1nek The model shows the polarity properties of the complex II. Hydrophobic residues are exposed to the outer side of the cone-tip which embedded into the inner membrane. Compelx II: succinate dehydrogenase It both serves to citric acid cycle and electron transprot. In citric acid cycle, it catalyzes the conversion of succinate into fumarate. Anal part of Compelx II in the mitochondira matrix which contains FAD. FAD attached: SdhA -&gt; SdhA: FAD passed to sdhB: Fe-S centers -&gt; passed to SdhC and D: heme b and Q. PS: Q could also comse from (Acyl-CoA dehydrogenase) Complex III © molview: pdbid=1bgy The neck of the molecule exposed grey hydrophobic aria which indicate the inner membrane area of the protein. Compelx III has three main funtional groups: Cyt c1 subunits Reiske cneter: Fe-S cyt b subunit: Two coenzyme Q biding site Q0 and QI Cyt c can only accept one electron each but coenzyme Q supposed to donate two electron. The compelx III solving this by running The Q cycle: Electron Passing path: $e_ 1^ - \\to Fe-S \\to cyt\\ c$ $e_ 2^ - \\to cyt\\ b_ L \\to cyt\\ b_ H \\to Q$: semi-quinone$ Blue line: Coenzyme Q transport Red line: electron transport Green line: Hydrogen transport Dash line: New resource of coenzyme Q Overall: $$ QH_2 + 2 cyt\\ c_ {ox} + H^ +_ m \\to Q + 2cyt\\ c_ {red} + 4 H^ +_ i $$ Complex IV: © molview: pdbid=1oco Complex IV: Cytochrome oxidase It is a dimer which each monomer has 13 subunits. e-#1: $cyt\\ c \\to Cu^ {_ -}A \\to Heme a \\to heme a_ 3 \\to Cu-B$ Cu-B is reduced and lost it function. e-#2: $cyt\\ c \\to Cu^ {_ -}A \\to Heme a \\to heme a_ 3$ Heme a2 is reduced and works as the hemoglobin which could bind O2 O2: $Fe^ {2+_ -}O^ {\\ \\ -} {2} Cu^ +$ e-#3 and H+: $Fe^ {2+_ -}O\\ \\ \\ \\ HO^ {_ -} Cu^ +$ e-#4: $Fe^ {3+}\\ \\ \\ 2H_ 2O\\ \\ \\ Cu^ {2+}$ $$ 4 cyt\\ c_ {red} + 8H^ +_ m +O_ 2 \\to 4cyt\\ c_ {ox} + 2H_ 2O+ 4H^ +_ i $$ digraph{ \"Step1\" [ label = \"{ QH2| Q}\" shape = \"record\" ]; \"Step2\" [ label = \"{ | Q*}\" shape = \"record\" ]; \"Step3\" [ label = \"{ QH2| Q*}\" shape = \"record\" ]; \"Step4\" [ label = \"{ | QH2}\" shape = \"record\" ]; \"Step5\" [ label = \"{ QH2| Q}\" shape = \"record\" ]; Step1 -> Step2 -> Step3 -> Step4 -> Step5 OUT1 [label = \"membrane\"] QH21 [label = \"QH2\"] QH22 [label = \"QH2\"] H1 [label = \"2H+\"] H2 [label = \"2H+\"] Q1 [label = \"Q\"] Q2 [label = \"Q\"] Q3 [label = \"Q\"] Q21 [label = \"Q2\"] Q22 [label = \"Q2\"] Step1:f0 -> OUT1 [color=\"red\", label=\"e1\"] Step1:f0 -> Step1:f1 [color=\"red\", label=\"e2\"] Step1:f0 -> H1 -> OUT1 [color = \"green\"] Step1:f0 -> Q1 -> OUT1 [color = \"blue\"] QH21 -> Step2:f0 [style=\"dotted\"] Step3:f0 -> OUT1 [color=\"red\", label=\"e1\"] Step3:f0 -> Step3:f1 [color=\"red\", label=\"e2\"] Step3:f0 -> H2 -> OUT1 [color = \"green\"] Step3:f0 -> Q2 -> OUT1 [color = \"blue\"] Step4:f1 -> Q21 -> OUT1 [color = \"blue\"] QH22 -> Step4:f0 [style=\"dotted\"] Q3 -> Step5:f1 [style=\"dotted\"] Q22 -> Step5:f0 [style=\"dotted\"] subgraph cluster_1{ Step1 Step2 Step3 Step4 Step5 } } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });","link":"/2021/05/11/LearnNotes/edx-biochm-16/"},{"title":"Principles of Biochemistry 18 |Regulation of glycolysis in liver cells| Class Notes |HarvardX","text":"Allosteric Enzyme It is a class of regulated with distinct regulatory and catalytic subunit. Aspartate Transcarbamoylase (ATCase) Catalyzes the first step of the biosynthesis of pyrimidine $Carbamoyl\\ phosphate + Aspartate \\overset{ATCase}{\\rightleftharpoons}$ $N^ {_ -} carbamoylaspartate + pi \\to … \\to CTP$ CTP: Cytidine Triphosphate In the experiment, CTP$\\uparrow$ cause the ATCase activity$\\downarrow$ CTP has no chemical similar structure to the substrates of ATCase CTP does not interact with ATCase The experiment of Distance migration When ATCase separated on the sucrose gradient purified as a single peak can both bind with CTP and substrates and inhibited by CTP When pretreated ATCase separated on the sucrose gradient two peaks. One can only bind the CTP Another can only bind the substrates That means ATCase contains two types of subunits: Regulatory subunit: bind CTP Catalytic subunit: bind substrates This is what the Allosteric Enzyme which has a catalytic site distinct from the regulatory site. Terminology Allos = other ster = structure subunits of ATCase It has six subunits organized into three dimers, six regulatory subunits that are organized into three dimers. When binding with the substrate (asperate), it changes conformation from T to R state. T: Inactive state, predominant without substrates R: activate, stabilized by substrate binding Homotropic allosteric behavior homotropic regulation: Example: Set the ATCase with two substrates: Carbamoyl phosphate: constant concentration. Aspartate: increasing concentration Result: it is a sigmoidal curve (S shape). Example2: The same condition as above but only with the catalytic subunit of ATcase: We obtain a hyperbolic curve which looks like a curve that we would get with a Michaelian enzyme. Hypothesis: The Allosteric protein are oligomeric (made of several subunits in a symmetrical fashion) Each subunit contains only one binding site for any given ligand. The enzyme can exist in at least 2 states (such as T and R) Another model: KNF model KNF model assumes a sequential progression from T to R. Single T conformation: No ligand bound to the enzyme. Conformation Changed: One ligand binds to one subunit Conformation change transmitted to the neighboring vacant subunit Enzyme-limited reaction Substrate-limited reaction: The speed of the reaction decided by the supply of the substrate Enzyme-limited reaction: The activity of the enzyme is low untile the enzyme was activated by some specific effector What is the Enzyme-limited reaction $Fructose-6P +ATP \\overset{PFK-1}{\\longrightarrow} Fructose-1,6-P + ADP$ Phosphofructokinase-1 (PFK-1) $$ \\frac{[Fructose-1,6-P][ADP]}{[Fructose-6-P][ATP]} = R_ f $$ Vivo Vitro Rf 0.04 250 The ratio difference between Vivo and Vitro indicates that the PFK-1 was in a real low activity under normal conditions. Regulations Allosteric regulation: Allosteric regulators usually reflect cell metabolic state Fasta regulation (a few milliseconds) Reversible convalent modification: IE-phosphorylation Slower than allosteric (a few seconds) Transcriptional regulation The slowest form of regulation PFK-1 regulation ATP ATP is an inhibitor of the PFK-1 Low [ATP]: The curve of PFK-1 is hyperbolic: A very low concentration of PFK-1 could have a high level of activity. High [ATP]: The curve of PFK-1 is sigmoidal: The activities of PFK-1 are low until its concentration is higher than a specific level. Physiological significance: PFK-1 is not needed when the ATP is sufficient. AMP AMP is an activator of the PFK-1. As a result, the ratio of ATP and AMP could regulate the activity of the PFK-1. $\\frac{[ATP]}{[AMP]}$ is high: - High energy state - ATP is abundant - PFK-1’s activity is suppressed. $\\frac{[ATP]}{[AMP]}$ is low: - Low energy state - ATP is a deficiency - PFK-1’s activity is increased. Why not ADP ADP is a poor indicator of the cell energy state indicator. Because: $$ 2 ADP \\overset{Adenylate \\ kinase}{\\longrightarrow} ATP + AMP $$ On the other hand, the AMP is more sensible to the ADP. concentration: $[AMP] &lt; [ADP] &lt; [ATP]$ changing scale: $AMP &gt; ADP &gt; ATP$ (sensitivity) others Citrate inhibited PFK-1 by enhancing the ATP inhibitor effect. PFK-2 $$ fructose-6-bisphosphate +ATP \\overset{PFK-2}{\\longrightarrow} fructose-2,6-bisphosphate + ADP $$ In the liver, the ATP is always high, the fructose-2,6-biphosphate played the role of ATP. The fructose-2,6-bisphosphate dampened the effect of ATP on PFK-1. © HarvardX PFK-2 contains: kinase domain: phosphorylation of the substrates phosphate domain: dephosphorylation the produces The function of the two domain was regulated by other factors and indirectly control the activity of PFK-1 PFK-2 in liver PFK-2 is regulated by the [Glu]Blood. We know that: $[Glu]_ {Blood} \\approx [Glu]_ {Liver} $ When [GluBlood] is high, Glu stats to be metabolized, As a result, a feed-forward stimulation occurs: $\\uparrow[F-6-P] \\to \\ \\uparrow PFK-2 \\to \\ \\uparrow[F-2,6-P] \\uparrow Glycolysis$ When [GluBlood] is low, Glu stats to be metabolized, $\\uparrow FBPase$ activity $\\downarrow F-2,6-BP$ $\\downarrow PFK-1$ activity Glucagon -&gt; Gs -&gt; convert ATP to cAMP -&gt; PKA -&gt; PFK-2(phosphate and inhibitate) -&gt; PFK-1 decrease Liver When The [Glu]Blood is high: [ATP] is high, too: Muscle: Hexokinase was prohibited (by G-6-P) activity of PFK-1 $\\downarrow$ (by ATP) Glu was taken by the liver and be converted into Glycogen and fat. Liver: Glucokinase: Not inhibited by glucose-6-P High Km Activities of Glycolysis $\\downarrow$ (by ATP) Glycogen and fatty acid synthesis are activated.","link":"/2021/05/14/LearnNotes/edx-biochm-18/"},{"title":"Principles of Biochemistry 20 |Liver and Muscle Metabolism| Class Notes |HarvardX","text":"Over view glycolysis, citric acid cycle, and oxidative phosphorylation have significant effects on metabolism and catabolism. The substrates and products from metabolism could be used to synthesis nuclide acid, fatty acid, and protein. So, the processes of metabolism should be precisely regulated. Allosteric regulation (e.g., PFK1) It’s the quickest way to regulate the pathway. Reversible covalent modification (interactive Enzyme phosphorylation) is slower than allosteric regulation. Common in reciprocal regulation of the catabolic and anabolic pathway. Translation, transcriptional, and post-translational control Compartmentalization Establishment of gradients across membranes Who all metabolic pathways are connected Three main “Hubs” for metabolic pathways: Glucose-6-phosphate Pyruvate Acetyl-CoA Amino acid catabolism feeds the citric acid cycle Citric acid cycle intermediates feed amino acid synthesis Metabolic networks are a conduit for carbon backbones: To build new molecules To break them down for energy Metabolism adaptation Skeletal Muscle (motion): Fast ATP synthesis Red Blood cells (oxygen delivery): Minimal metabolism Brain cells (ion pumping): Neurotransmitter synthesis Liver (metabolism): Regulator Processes Toxins Processes nutrients from digestion Controls glucose homeostasis (Maintains [Glucose]blood ~4mM) High blood glucose level: Transport GLUT2 in the surface of the hepatocyte could transport glucose very efficiently. Transfer $Glucose + Pi \\overset{Glucokinase}{\\longrightarrow} Glucose^{_ -}6^{_ -}P$ Glucokinase is an isoform of hexokinase in the liver. It won’t be prohibited by the products. Catabolism $Glucose^{_ -}6^{_ -}P \\longrightarrow Glycogen$ Low blood glucose level: Glycogen broken-down: $$ Glycogen + Pi \\overset{Glycogen\\ phosphorylase}{\\longrightarrow} Glucose^{_ -}1^{_ -}P \\overset{Phosphogluco-mutase}{\\longrightarrow} Glucose^{_ -}6^{_ -}P \\overset{Glucose 6-phosphatase}{\\longrightarrow} Glucose $$ Fates of Fatty acids Incorporated int TAG, lipoproteins Bind to albumin, feed muscle Storage in lipid droplets (fatty liver) Fates of Amino acids Incorporated into liver proteins Incorporated into serum proteins Exported as free amino acids in the blood Precursors to other biomolecules Nucleotides, hormones, porphyrins Pyruvate, acetyl-ACoA Glucose Muscle Metabolism Muscle consumes 50% of oxygen and 90% during active works. The skeletal muscle could carry anaerobic breath during the energy burst. But cardiac muscle can’t. It’ll cause cell death and/or heart attack. Cardiac muscle: Aerobic metabolism Requires O2 Sensitive to low pH Ion gradients disrupted by pH changes Phosphocreatine system In cytoplasm $$ Phosphocreatine + ADP + H^+ \\overset{Creatine\\ Kinase}{\\rightleftharpoons} creatine + ADP $$ This system is both common in skeletal and cardiac muscles. H+ was consumed, the pH was Maintained. The recovery speed of phosphocreatine could be improved by exercise. Creatine Kinase is distributed in the inner membrane, cytoplasm, and inter-membrane of the mitochondria. limited of phosphocreatine system: During the intense muscle contraction, the ATP and phosphocreatine power the muscle for 5 to 6 seconds. short term, media term, and long term activities The quickest speed of 100-meter racing is 9.58, the pH of the blood dropped from 7.4 to 7.2. But the record of 1000 meter is 132. If the sport keeps the speed like 100 meters, he can finish it with 95s, and the pH of the blood would drop to 6.8, and the cell would die. So, there are other metabolic pathways that get involved in the 1000 meter race compared with the 100-meter race. In this situation, glycogen was broken down. In a much longer race, like a marathon, more energy was needed. Cori Cycle Glucose-alanine cycle Cycle Type of Fibers Slow twitch Type I Fast twitch Type IIa Fast twitch Type IIb - fatty acid- oxidation - fatty acid- glycolysis - glycolysis- fermentation - mitochondria- myoglobin - mitochondria- myoglobin- glycogen - glycogen Marathon 1000 meter race 100 meter race digraph{ node [shape=box] G6P [label= \"Glucose-6-P\", color=\"red\", shape=\"diamond\", style=\"filled\"] Pyruvate [color=\"green\", shape=\"diamond\", style=\"filled\"] ACoA [label = \"Acetyl-CoA\", color=\"skyblue\", shape=\"diamond\", style=\"filled\"] \"Amino\\nAcids\" -> Glucose -> G6P [color = \"red\"] G6P -> Pyruvate -> ACoA Lactate -> Glucose [color = \"red\"] Glycogen -> G6P [dir=both, color = \"red\"] G6P -> \"Pentose phosphate\\npathway\" [color = \"red\"] Lactate -> Pyruvate [dir=both, color = \"green\"] Alanine -> Pyruvate [dir=both, label=\"deamination\\ntransamination\", color = \"green\"] \"Fatty\\nacids\" -> ACoA [label = \"β-oxidation\", color = \"skyblue\"] \"Amino\\nAcids\" -> ACoA [color = \"skyblue\"] \"Ketone\\nBodies\" -> ACoA [dir = both, color = \"skyblue\" label = \"to brain\"] Cholesterol -> ACoA [color = \"skyblue\"] ACoA -> \"Fatty acids\" [color = \"skyblue\"] subgraph cluster_0{ label = \"Mitochondrial\" fontsize = 20 fontcolor = \"red\" ACoA, \"Ketone\\nBodies\",\"Fatty\\nacids\" } } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });digraph{ rankdir = \"LR\" Glucose [label=\"Glucose\", color =\"red\", style =\"filled\"] Glucose2 [label=\"Glucose\", color =\"red\", style =\"filled\"] Lactate [label=\"Lactate\", color =\"green\", style =\"filled\"] Lactate2 [label=\"Lactate\", color =\"green\", style =\"filled\"] inter [label = \"\", width = 0, height =0] subgraph cluster_0{ label =\"Muscle\" Glucose -> Lactate [label =\"Activity\"] Glucose -> Glycogen [label =\"Rest\"] {rank=same; Lactate, Glucose} } Lactate -> Lactate2 [style=dotted, label=\"blood\", color=\"red\"] subgraph cluster_1{ label =\"Liver\" Lactate2 -> inter [dir = none] ATP -> inter inter -> Glucose2 {rank=same; Lactate2, inter, Glucose2} } Glucose2 -> Glucose [style=dotted, label=\"blood\", color=\"red\"] } var viz = new Viz(); var code = document.getElementById(\"graphviz-1-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-1\").append(element) });digraph{ Glucose [label=\"Glucose\", color =\"red\", style =\"filled\", shape=\"hexagon\"] Glucose2 [label=\"Glucose\", color =\"red\", style =\"filled\", shape=\"hexagon\"] Alanine [label=\"Alanine\", color =\"green\", style =\"filled\"] Alanine2 [label=\"Alanine\", color =\"green\", style =\"filled\"] \"NH\" [label=\"-NH₂\", color =\"skyblue\", style =\"filled\"] \"NH2\" [label=\"-NH₂\", color =\"skyblue\", style =\"filled\"] Py [label=\"Pyruvate\", color = \"pink\", style = \"filled\"] Py2 [label=\"Pyruvate\", color = \"pink\", style = \"filled\"] inter [label=\"\", width = 0, height =0] inter2 [label=\"\", width = 0, height =0] subgraph cluster_0{ label =\"Muscle\" Glucose \"Amino\\nacids\" -> \"NH\" -> inter -> Alanine Py -> inter {rank=same;\"Amino\\nacids\", \"NH\", inter, Alanine} } Alanine -> Alanine2 [label = \"Blood\", style = dotted, color =red] Glucose2 -> Glucose [label = \"Blood\", style = dotted, color =red] subgraph cluster_1{ label =\"Liver\" Alanine2 -> inter2 -> NH2 -> \"Urea\" inter2 -> Py2 -> Glucose2 Py2 -> \"Citric acid\\ncycle\" {rank=same; Alanine2, inter2, Py2, Glucose2} } } var viz = new Viz(); var code = document.getElementById(\"graphviz-2-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-2\").append(element) });","link":"/2021/06/15/LearnNotes/edx-biochm-20/"},{"title":"Principles of Biochemistry 19 |Gluconeogenesis| Class Notes |HarvardX","text":"Introduction The brain will consume on average 120 grams of glucose per day. It is insufficient from the food. Gluconeogenesis Gluconeogenesis is not simply the reverse of glycolysis Limited reactions (3) Three metabolic valve enzymes (rate-limiting/Enzyme-limited) Those reactions are highly exergonic and irreversible. Substrate-limited reactions (7) Near equilibrium Reversible Three bypass reactions $$ Pyruvate + ATP + GTP + HCO_ 3 ^- \\rightleftharpoons PEP + ADP + GDP + P_ i + CO_ 2 $$ $\\Delta G’^ {\\circ} = 0.9\\ kJ/mol$ $[PEP]$ low $\\Delta G = -25\\ kJ/mol$ The reaction is spontaneous and irreversible Pyruvate $\\to$ PEP In mitochondria: $Alanine \\to Pyruvate$ Pyruvate carboxylase Pyruvate + ATP $\\overset{biotin}{\\longrightarrow}$ Oxalocetate + ADP (coenzyme: Biotin) Oxalocetate + NADH $\\overset{Malate\\ dehydrogenase}{\\rightleftharpoons}$ Malate + NAD+ (The change of free energy is nearly zero) 2.1. {Malate}Mitochondria $\\overset{alpha-ketoglutarate\\ transporter}{\\longrightarrow}$ {Malate}Cytosol Malate + NAD+ $\\to$ Oxaloacetate + NADH Oxaloacetate + GTP $\\overset{PEP\\ carboxykinase}{\\rightleftharpoons}$ PEP + GDP Glyceraldehyde 3-phosphate NAD+ $\\rightleftharpoons$ 1,3-Bisphosphoglycerate + NADH Source of NADH $$ [\\frac{NADH}{NAD^ +}]_ {cyt} &lt;&lt; [\\frac{NADH}{NAD^ +}]_ {min} $$ NADH is not permeable to the membrane of mitochondria. So, the NADH does not come from mitochondria. $Lactate + NAD^ + \\to Pyruvate NADH$ The second bypass reaction $$ Fru-1,6-biphophotate \\overset{Fructose\\ 1,6\\ biphosphatase}{\\longrightarrow} Fru-6-phosphate \\ $$ $$ \\Delta G’^ {\\circ} = - 16.3kJ/mol $$ The third bypass reaction $$ Glucose-6-P \\overset{Glucose\\ 6\\ biphosphatase}{\\longrightarrow} Glucose $$ $$ \\Delta G’^ {\\circ} = -13.8kJ/mol $$ Free energy Glycolysis Gluconeogenesis -63 kJ/mol -16 kJ/mol Blood glucose regulation The liver: Balances glycolysis and Gluconeogenesis Controls glycogen synthesis and degradation Glycogen metabolism is regulated by hormones. Low blood glucose As a result, the glycogen synthesis was inactivated. High blood glucose GSK is the inactivator of the Glycogen synthase. Without the inactivator, the activation of glycogen synthase was increased. PP1 PP1 is a part of a complex called Glycogen synthase phosphatase which contains Glycogen-targeting regulatory subunit. It’s a member of the family of glycogen-targeting regulatory subunits and could recruit the glycogen synthase phosphatase to glycogen particles. In high blood glucose level: PP1 dephosphorylates both enzymes (Glycogen synthase and Glycogen phosphorylase), so the glycogen synthase becomes activated, and the glycogen phosphorylase is now inactive. Inactivate a protein called phosphorylase kinase and inhibit glycogen breakdown Insulin would decrease the concentration of cAMP which responsible to activate PKA. (PKA could prohibit the function of PP1) (Glycogen phosphorylase: breakdown the glycogen) In low a concentration of blood glucose, PKA inhibits the PP1. ==In low blood glucose level Glycogen phosphorylase would bind to the Glycogen synthase phosphatase which inhibited the PP1. So, glycogen synthesis is inhibited. Glycogen-targeting regulatory subunit has two kinds of isoform: GL in the muscle. regulation in muscle low blood glucose PKA cold phosphorylates GM. Upon phosphorylation, PP1 dissociates from GM which could reduce the catalytic efficiency of PP1. (Substrate is recognized and recruited by GM). PKA also phosphorylates the inhibitor of the PP1 and then binds it to the PP1 to inhibit the activity of PP1. delay effect on synthase No additional Glucose: Glycogen phosphorylase is in an R state Added Glucose: turn to T state, PP1GL complex is released in now an active form. T state of Glycogen phosphorylase is more accessible for PP1GL complex PP1GL complex could now quickly bind the glycogen synthase and stimulation the glycogen synthesis Diabetes Diabetes Mellitus: Elevated levels of blood sugar Deficiency in insulin activity Two main groups of diabetes: Type I juvenile-onset diabetes (age of 25) Genetic, autoimmune, environmental Reduced insulin secretion $\\beta$-cell loss Hard to prevent Type II Adult-onset (40 to 60 years) Genetic and environmental factors Resistance towards insulin Eventual $\\beta$-cell loss and reduced insulin secretion relatively easy to prevent Gestational (pregnant woman) Temporary insulin resistance Relapse may occur (to Type II diabetes) Common complication: Hyperglycemia Organ damage (eyes, kidneys, and nerves.) Controlling Type II Diabetes: Long-term and continuous regulation of blood sugar Strict dietary control Type I diabetes (Insulin-dependent diabetes) Less than 10% of the diabetics sudden onset Immune system attacks $\\beta$-cells Causes: Viral infections initiate autoimmunity Genetic factors contribute Severe $\\beta$-cell loss = insufficient insulin secretion: undernourished underweight ketone body production metabolic acidosis lower the blood pH Coxsackievirus targets to pancreatic $\\beta$-cell and the $\\beta$-cell has a very limited ability of regeneration. Genetic factors: TYK2 TYK2 is the protein of which associate with interferon receptor, which presents INF $\\alpha/\\beta$ and recognized by the phagocyte. The ineffectiveness of TYK2 loss of function increases the protection against type 1 diabetes by decreasing the antiviral and apoptotic responses. PTPN2 could prevent the down-regulation of the antiviral in apoptotic activities. Lipolysis Inhibition of hormone-sensitive lipase: HSL HSL could convert diacylglycerol into monoacylglycerol. Triacylglycerol (TAG) synthesis: Conversion of glucose to glycerol 3-P in liver and adipocytes. Increased TAG synthesis in liver and adipocytes Increased TAG transport from liver to adipocytes Upregulation of lipoprotein lipase gene Most tissues: Increased amino acid uptake Activation of translation initiation factors Activation of protein synthesis Hyperglycemia High glucose in blood, very low glucose in the cell High fasting blood glucose &gt; 126 mg/dL excess of glucose in the urine Osmotic pressure Exessive urination, polyuria, and dehydration Excessive thirst, polydipsia Cell stress Tissue Damage: Exp, oxidative damage in $\\beta$-cell Tissue starvation Polyphagia: (feel constantly hungry) Glyconeogenesis Hyperglycemia Degrade lipids to fatty acids adipose tissue wasting ketone bodies synthesis Low blood pH and ketoacidosis Hypertriacylglycerolemia Excessive very-low-density lipoproteins due to low activity of lipoprotein lipase Effect on insulin-insensitive tissues protein glycation small blood vessels retina red blood cells Treatment for Type I Diabetes It is caused by loss of insulin secretion because of loss of $\\beta$-cell. The obvious treatment is the administration of purified insulin. Subcutaneous injection (fat layer) Other injection sites (the part rich in adipose tissues) abdomen top of your thigh back of your arm pump-assisted infusion It should avoid quick absorption in order to prevent from frequent injection Exogenous insulin administration Standard intensive Healthy blood glucose level ~225mg/dL ~150mg/dL ~100mg/dL glycated Hb levels ~8-9% ~7% &lt; 6% Side effect: It was caused by the time and dose of the insulin injected. Less or more could cause damages: To many: blood glucose levels &lt; 100mg/dL Hypoglycemia Children &lt; 8 yrs: brain development Elderly: heart attacks and stroke Type II diabetes Type II diabetes is characterized by the cell loss responsible for the circulating insulin. Glucose uptake As a result, our body controls the level of blood glucose by dynamically manipulating the number of Glucose pumps (GLUT-4) on the surface of receptor cells which responsible for the circulating insulin. Insulin Receptor Tyrosine phosphorylation of the receptor and IRS-1 recruitment $\\overset{phosphatase}{\\longrightarrow}$ Insulin Receptor inactivation $\\overset{proteosome}{\\longleftarrow}$ Receptor and IRS-1 degradation IRS-1 phosphorylation and PI3K activation $\\overset{S/T Kinase}{\\longrightarrow}$ IRS-1 inactivation Conversion of PIP2 into PIP3 $\\overset{phosphatase}{\\longrightarrow}$ Conversion of PIP2 into PIP3 Inactive PDK1 and Akt Decreased glucose uptake and glycogen synthesis Activation of PDK1 and Akt Increased glucose uptake and glycogen synthesis Insulin resistance adipocytes lead to chronic inflammation Adipocyte secretion of anti-inflammatory molecules decreases and adipocyte’s secretion of pro-inflammatory molecules increases. Exp: MCP-1, a chemical that attracts macrophages. Glucose transport inside muscle is still normal Microphages infiltrated in adipose tissue secrete TNF-alpha Result: increase lipolysis followed by increased fatty acid export to tissue, including muscle. excessive fatty acid in tissue in ectopic fat deposition and interference with the targeting of glucose transporter at the surface of cells. The consequence is the progression toward full insulin resistance. One hypothesis: insulin overproduction Hyperglycemia could trigger a large amount of insulin production. Proinsulin is heavily produced in the inner cellular ER and Golgi system. Over synthesis of this could damage the function of the ER and Golgi, which failed to remove the C-protein and produce misfolded insulin. Accumulation of misfolded insulin triggered apoptosis. Conclusion: Obesity is a risk factor leading to ectopic fat deposition and ultimately to lipotoxicity and chronic inflammation which finally developed into insulin resistance and insulin deficiency. Prevention Aerobic exercise, reduced caloric intake, healthy diet Lower glucose production by the liver Increase insulin production or sensitivity (e.g., sulfonylureas) Function of sulfonylureas Normal signaling pathway: digraph{ Surface [label=\"Liver cell Surface\"] Glucagon -> Surface [label=\"bind\"] PK [label=\"Phosphorylase\\nkinase\"] GP [label = \"Glycogen\\nPhosphorylase\"] Surface -> G ATP -> G -> cAMP -> PKA -> PK -> GP } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });digraph{ IR [label = \"Insulin receptor\"] Insulin -> IR [label = \"bind\"] IR -> \"IRS-P\" [label= \"phosphorylate\"] \"IRS-P\" -> \"Protein kinase\" \"Protein kinase\" -> GSK [label=\"inactivate\"] GSK -> \"GSK-P\" } var viz = new Viz(); var code = document.getElementById(\"graphviz-1-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-1\").append(element) });digraph{ rankdir=\"LR\" node [shape=\"box\"] \"Coxsackievirus\\ninfection\" -> \"Severe\\nimmune\\nresponse\" -> \"Type I diabetes\\nvia B-cell loss\" } var viz = new Viz(); var code = document.getElementById(\"graphviz-2-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-2\").append(element) });digraph{ rankdir = \"UD\" node [shape = box] EFD [label = \"Ectopic fat deposition\"] Obesity -> EFD EFD -> \"Insulin\\nresistance\" [label = \"Lipotoxicity\\nIncreased inflammation\"] EFD -> \"Insulin\\ndeficiency\" -> \"Type 2 Diabetes\" \"Insulin\\nresistance\" -> \"Type 2 Diabetes\" } var viz = new Viz(); var code = document.getElementById(\"graphviz-3-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-3\").append(element) });digraph{ node [shape=box] IR [label = \"Insulin\\nreceptor\"] inter_1 [label=\"\", shape = none, width=0, height=0] inter_2 [label=\"\", shape = none, width=0, height=0] Insulin -> IR [label = \"binding\"] IR -> \"vesicles\\n+\\nGLUT-4\" [label = \"stimulate\"] \"vesicles\\n+\\nGLUT-4\" -> inter_2 [label =\"merge\" dir =none] membrane -> inter_2 [dir =none] inter_2 -> \"membrane\\n+\\nGLUT-4\" Glucose -> \"membrane\\n+\\nGLUT-4\" -> \"Inner Cell\" {rank = same; Glucose, \"Inner Cell\" ,\"membrane\\n+\\nGLUT-4\"} \"membrane\\n+\\nGLUT-4\" -> \"vesicles\\n+\\nGLUT-4\" [label=\"lack of insulin\", color=\"red\", fontcolor=\"red\"] } var viz = new Viz(); var code = document.getElementById(\"graphviz-4-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-4\").append(element) });digraph{ node [shape = \"box\"] AM [label = \"Abnormal\\nMetabolism\"] inter_1 [label=\"\", shape = none, width=0, height=0] inter_2 [label=\"\", shape = none, width=0, height=0] \"Type 2 Diabetes\" -> AM AM -> Tissues -> \"(down)\\nGlucose\\nuptake\" -> inter_1 AM -> Liver -> \"(up)\\nGluconeogenesis\\nGlycogenolysis\" -> inter_1 Liver -> \"(up)\\n Ketone\\nbodies\" -> inter_2 AM -> Adipocytes-> \"(up)\\nLipolysis\" -> \"(up)\\nFree fatty acids\\nin plasma\" -> inter_2 inter_1 -> Hyperglycemia inter_2 -> Ketoacidosis {rank = same Liver, Tissues, Adipocytes } {rank = same \"(down)\\nGlucose\\nuptake\" \"(up)\\nGluconeogenesis\\nGlycogenolysis\" \"(up)\\n Ketone\\nbodies\" \"(up)\\nFree fatty acids\\nin plasma\" } } var viz = new Viz(); var code = document.getElementById(\"graphviz-5-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-5\").append(element) });digraph{ node [shape =\"box\"] sulfonylureas [bgcolor=\"red\"] Glucose-> ATP \"K+\" -> \"K+ pump\" \"Ca+\" -> \"Ca+ pump\" \"K+\" -> \"Ca+\" [label= \"depolarization\", style = \"dotted\"] sulfonylureas -> \"K+ pump\" [label=\"close\", color=\"red\"] \"insulin secretion\" -> insulin {rank= same; \"K+\"; \"Ca+\"} subgraph cluster_0{ label =\"β-cell\" fontsize = 20 fontcolor =red {rank= same; \"K+ pump\"; \"Ca+ pump\"} ATP -> \"K+ pump\" [label=\"close\", color=\"red\"] \"Ca+ pump\" -> \"insulin secretion\" [label=\"depolarization\"] } } var viz = new Viz(); var code = document.getElementById(\"graphviz-6-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-6\").append(element) });","link":"/2021/06/07/LearnNotes/edx-biochm-19/"},{"title":"Principles of Biochemistry 22 |Nucleic acids| Class Notes |HarvardX","text":"Quick review Building blocks of nucleic acids Energy currency in cells (ATP) Precursors of universal electron acceptors Signaling molecules RAN: Ribose; DNA: Deoxyribose Purines: A (Adenine), G (Guanine) pyrimidine: T (Thymine), C (Cytosine), U (Uracil) Nucleosides: pentos + purine/pyrimidine nucleic acid without a phosphate group e.g. Adenosine Nucleotides: petos + purine/pyrimidine + one or more phosphates Nucleic acid with three phosphates group e.g. ATP DNA/RNA: polymerized Nucleotides are linked by a phosphodiester linkage Ribonucleotide: RNA Dexoyribonucleotide: DNA Nucleotides Biosynthesis PRPP: phosphoribosyl pyrophosphate PRPP + base $\\to$ NMP + PPi novo pathway: PRPP + amino acids + HCO3- + folate + … $\\to$ nucleotide Glucose-6-P $\\overset{Pentose\\ phosphate\\ pathway}{\\to}$ Ribose-5-P $\\to$ PRPP Another contribution of nucleotides Coenzyme A; cAMP Novo nucleotide biosynthesis Inositol monophosphate (IMP) $\\to$ AMP/GMP PRPP $\\to$ IMP has 11 steps carbonyl activation $Glycine + ATP \\to Glycine-P + ADP $ The carbonyl oxygen of glycine is activated by phosphorylation. Displacement by amine $Glycine-P + NH_ 2 -R \\to Glycine-NH-R$ R is nucleotide … Purine Biosynthesis: By Biochemistry Den (Recommended) By Hidaya Aliouche, B.Sc. by Sagar Aryal IMP to AMP/GMP Regulation of the synthesis Biosynthesis of pyrimidine $UMP \\to UTP \\to CTP$ Formation of the pyrimidine-ring: $Carbamoyl-P + Aspartate \\overset{ATCase}{\\longrightarrow} Carbamoyl aspartate$ $Carbamoyl aspartate \\overset{Dihydroorotase}{\\longrightarrow} Dihydroorotate$ $Dihydroorotate + NAD^ +\\overset{Dihydroorotate\\ Dihydroorotase}{\\longrightarrow} Orotate + NADH + H^ +$ Pyrimidine assemble $Orotate + PRPP \\to UMP + PP_ i + CO_ 2$ $UMP + 2ATP \\to UTP + 2ADP$ $UTP + ATP + Gln \\to CTP + ADP + P_ i + Glu$ NDP to dNDP Cancer Treatment The cancer cell is more sensitive than normal cells to inhibitors of nucleotide biosynthesis $dUMP \\overset{Thymidylate\\ synthase}{\\longrightarrow} dTMP$ Folate cycle Catabolism Pyrimidine catabolism $Uridine + Pi \\underset{phophorylase}{\\overset{Pyrimidine-}{\\longleftrightarrow}} Ribose-1-phosphate + Uracil$ $Uracil + NADPH \\to Dihydrouracil + NADP^ +$ $Dihydrouracil \\overset{Ring cleavage}{\\longrightarrow} \\beta-alanine + CO_ 2 + NH_ 4^ +$ Adenosine degradation $Adenosine \\ monophosphate (AMP) + H_ 2O \\to P_ i + Adenosine$ $Adenosine + H_ 2O \\to Inosine + NH_ 3$ $Inosine + H_ 2O \\to Ribose + Hypoxanthine$ $Hypoxanthine + O_ 2 + H_ 2O \\to Xanthine+ H_ 2O_ 2$ Guanosine degradation $GMP + P_ i \\to Guanosine + H_ 2O$ $Guanosine + H_ 2O \\to Ribose + Guanine$ $Guanine + H_ 2O \\to Xanthine + NH_ 3$ $Xanthine \\overset{Xanthine \\ oxidase}{\\longrightarrow} Uric \\ acid$ Accumulation of Uric acid in blood could cause gout. treatment Reduce the formation of uric acid Hypoxanthine and Allopurinal could serve as potent xanthine oxidase inhibitors. By restricted the production of the uric acid, the xanthine remained. But it is more soluble and easy to be cleaned. Uric acid degradation $Uric acid \\overset{Urate oxidase}{\\longrightarrow} Allantoin$ Pyrimidine/Purine salvage Pyrimidine $Uracil \\longleftrightarrow Ribose-1-P$ $Ribose-1-P \\overset{Pyrimidine \\ phosphorylase}{\\longleftrightarrow} Uridine + P_ i$ Purine $Adenine + PRPP \\overset{APRT}{\\longrightarrow} Adenosine \\ monophosphate$ APRT: adenine phosphoribosyltransferase. $Guanine + PRPP \\overset{HPRT}{\\longrightarrow} Guanine \\ monophosphate$ HPRT: hypoxanthine guanine phosphoribosyltransferase. Lesch-Nyhan disease Genetic deficiency in HPRT X-linked (Uncommon in females) It causes Hyperuricemia, Severn neurological symptoms Allopurinol treats hyperuricemia, but no neurological symptoms. digraph F { rankdir = LR; \"node1\" [ label = \" | IMP| \" shape = \"record\" color = white fontcolor = \"red\" fontsize = 20 ]; \"node2\" [ label = \" Adenylosuccinate| | XMP\" shape = \"record\" color = white fontcolor = \"red\" fontsize = 20 ]; \"node3\" [ label = \" AMP| | GMP\" shape = \"record\" color = white fontcolor = \"red\" fontsize = 20 ]; node1:f2 -> node2:f1 -> node3:f1 [ style = \"bold\"] node1:f2 -> node2:f3 -> node3:f3 [ style = \"bold\"] Asp -> node2:f1 [color = \"red\"] node3:f1 -> Fumarate [color = \"red\"] GTP -> node2:f1 -> \"GDP+Pᵢ\" [color = \"green\"] \"H₂O\" -> node2:f3 \"NAD⁺\" -> node2:f3 Gln -> node3:f3 -> Glu [color = \"red\"] ATP -> node3:f3 -> \"AMP + PPᵢ\" [color = \"green\"] } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });digraph { node [shape = none] inter1 [ label = \"\", width=0, height =0] En1 [label = \"PRPP\\nsynthase\", fontcolor=\"cyan\"] En2 [label = \"Gln-PRPP\\namidotransferase\", fontcolor=\"cyan\"] En3 [label = \"Adenylosuccinate\\nsynthase\", fontcolor=\"cyan\"] En4 [label = \"IMP\\ndehydrogenase\", fontcolor=\"cyan\"] En5 [label = \"XMP-glutamine\\namidotransferase\", fontcolor=\"cyan\"] subgraph{ node [fontcolor = \"crimson\"] AGI [label =\"AMP\\nGMP\\nIMP\" ] AMP2 [label = \"AMP\"] GMP2 [label = \"GMP\"] } subgraph{ node [fontcolor = \"green\"] ATP; GTP } \"Ribose-5-P\" -> En1 -> PRPP -> En2 -> \"5-P-ribosylamine\" -> IMP -> En3 -> Adenylosuccinate -> inter1 -> AMP IMP -> En4 -> XMP -> En5 -> GMP AGI -> En1 [arrowhead = \"tee\", color = \"crimson\"] AGI -> En2 [arrowhead = \"tee\", color = \"crimson\"] AMP2 -> En3 [arrowhead = \"tee\", color = \"crimson\"] GMP2 -> En4 [arrowhead = \"tee\", color = \"crimson\"] GTP -> En3 [color = \"green\"] ATP -> En5 [color = \"green\"] } var viz = new Viz(); var code = document.getElementById(\"graphviz-1-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-1\").append(element) });digraph{ subgraph{ node [shape = ellipse, fontcolor =\"brown\", color = grey, style = \"filled\"] TS [label = \"thymidylate\\nsynthase\"] DR [label = \"dihydrofolate\\nreductase\"] SHT [label = \"serine\\nhydroxymethyl-\\ntransferase\"] } subgraph main{ node [shape = none] \"N5,N10-Methylene\\nTHF\" -> TS -> \"7,8-dihydrofolate\" -> DR -> THF -> SHT -> \"N5,N10-Methylene\\nTHF\" [style = \"bold\"] } NADPH -> DR -> \"NADP+\" [color = red] serine -> SHT -> Glycine [color = red] subgraph cluster_0{ label = \"Cancer Drag\" node [shape=box, color = red, style = \"filled\"] edge [arrowhead=\"tee\", color = red] FD [label = \"FdUMP\"] ME [label = \"Methotrexate\"] } FD -> TS [arrowhead=\"tee\", color = red] ME -> DR [arrowhead=\"tee\", color = red] } var viz = new Viz(); var code = document.getElementById(\"graphviz-2-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-2\").append(element) });","link":"/2021/06/18/LearnNotes/edx-biochm-22/"},{"title":"Principles of Biochemistry 21 |Brain Metabolism| Class Notes |HarvardX","text":"Hormones regulate metabolism A similar hormone: Adrenaline Adrenaline works similarly to glucagon. But instead of the liver, the muscle is the key target of adrenaline. Growth hormone could also affect blood levels. It is derived from the gradual consumption of fatty acids and not by gobbling glucose. Thyroid hormones (thyroxine) could both regulated anabolic and catabolic pathways. Overdose: Metabolic overdrive Thyroid hypertrophy Weakness, sweating, weight loss, irregular heartbeat. Limited dose: Incidence increases with age Slow metabolism Weight gain, fatigue, cold sensitivity Function: Activates noradrenaline release Noradrenaline stimulates thermogenin in brown fat Promotes uncoupling of ETC Heat production In other tissues: promotes simultaneous synthesis and degradation of molecules. Heat production Conclusion: Tissue specificity of action Permits coordination between tissues Critical for maintaining homeostasis Glucocorticoids: They promote survival in the time of stress and scarcity by slowing the rate of nucleic acid synthesis and protein synthesis. Insulin Glucagon Adrenaline Growth Hormone Thyroid Hormone Cortisol Origin $\\beta$-cells $\\alpha$-cell Adrenal medulla Pituitary gland Thyroid gland Adrenal cortex Stimulus $\\uparrow$ [Glucose]blood $\\downarrow$[Glucose]blood Fear, stress, exercise Age-dependent Circadian Prolonged stress Liver - Glycogen synthesis- Glycolysis- Fatty acid synthesis - Glycogenolysis- Gluconeogenesis- Glucose Release Glucagon - Ketogenesis- Gluconeogenesis- Glycogen synth - Glycogenolysis- Gluconeogenesis - Gluconeogenesis- Glycogen synthesis- Fatty acid oxidation Muslce - Glucose uptake- Glycogen synth- Amino acid synth Reduce glucose uptake - Glycogenolysis- Glycolysis - AA uptake- AA synth - Proteolysis- Amino acid synth - Reduce glucose uptake- Proteolysis Adipose - Glucose uptake- Fatty acid synth - Reduce glucose uptake- Release fatty acid Release fatty acid - Lipolysis- Reduced glucose uptake - Lipolysis- Fatty acid synth - Reduce glucose uptake- Lipolysis Blood Glucose Decrease Increase Glucagon stable stable stable Free Fatty Acid Decrease Increase Glucagon Increase stable stable Blood-brain barrier Capillaries © HarvardX Capillaries are the smallest blood vessels formed by a ring of endothelial cells. The structure of brain capillaries is very different. Some large molecules pass through fluid channels called fenestra directly from the blood to the interstitial fluid. But capillaries in the brain don’t have fenestra. Gases and water: In the brain, H2O, CO2, and O2 are diffuse freely across the endothelial. Fuel molecules Glucose Glucose is transported by facilitated diffusion witch carried by GLUT1. It was 50,000 faster than sample diffusion. It was also found in cardiac muscle and red blood cells. monocarboxylic acid lactate, pyruvate, and ketone bodies. facilitated diffusion: MCT1 essential fatty acid e.g., $\\Omega$ 3 fatty acid. The transport of fatty acid was poorly understood. essential amino acid by specific transporters. non-essential fatty acids are blocked. proteins insulin: transcytosis Hypoglycemia: Glycine is a major inhibitory neurotransmitter in the spinal cord. $3^ {_ -}P^ {_ -}glycerate \\to Serine \\to Glycine$ $3^ {_ -}P^ {_ -}glycerate +NAD^ +\\to NADH + 3^ {_ -}phosphohydroxy\\ pyruvate$ $3^ {_ -}phosphohydroxy\\ pyruvate + Glut. \\to 3^ {_ -}P^ {_ -}serine + \\alpha^ {_ -} kg$ $3^ {_ -}P^ {_ -}serine + PO_ 4 \\to Serine$ $Serine + THF \\to Glycine + 5,10^ {_ -}methyl^ {_ -}THF + H_ 2O $ Glutamate is a critical excitatory neurotransmitter in circuits for memory and learning. $\\gamma^ {_ -}aminobutyric\\ acid$ (GABA) is the major inhibitory neurotransmitter in many neuronal circuits. $\\alpha^ {_ -}ketoglutarate + NH_ 3 + NADH \\to NAD^ + + Glutamate$ (In glial cells) $Glutamate \\to Glutamine$ (In glial cells) $Glutamine \\to Glutamine$ (back to neurons) $Glutamate + CO_ 2 \\to CO_ 2 + \\gamma^ {_ -}aminobutyric\\ acid$ (in neurons) Catecholamine synthesis Catecholamine synthesis $Tyrosine + O_ 2 + BH_ 4 \\to BH_ 2 + Dopa$ $Dopa + CO_ 2 \\to Dopamine$ In some specific neurons $Dopamine + O_ 2 + Ascorbate \\to Norepinephrine + H_ 2O + Dehydroascorbate$ $Norepinephrine + CH_ 3 \\to Epinephrine$ Norepinephrine acts both as a hormone, by increasing blood pressure or being part of the fight or flight response (increase alertness) Epinephrine is a hormone that has an important function in homeostasis. Transport of neurotransmitters Transport protein in the membrane of storage vesicle V-ATPase: H+ Pump VMAT2: NT in, H+ out Neurons: high energy demands Synthesize many neurotransmitters Require energy and O2 The brain also requires many lipids For vesicle turnover To form the myelin sheath FA synthesis also has high energy demands. Metabolism Disorder: Phenylketonuria (PKU) One gene-one protein disorder disease. Mentally retarded Children with peculiar musty odor urine. Ferric chloride test: Diabetic urine: turn reddish target: acetoacetic acid -PUK patients: Dark Green target: phenylpyruvate He tests 420 mentally impaired patients: 8 had elevated phenylalanine 2% of the population in the mental hospital compared to 0.01% in the general population. Healthy population: $phenylalanine \\overset{PHA+BH_ 4}{\\longrightarrow} tyrosine$ PAH (phenylalanine hydroxylase) BH4 is the cofactor of PAH PKU patients Inactivation of PAH makes phenylalanine remain at a toxic level among blood and tissues. Untreated children: &lt; 6 months: normal 6-12 months: lethargic 12 months: Seizures Severe mental retardation Severe Eczema Microcephaly Phenylalanine in blood Healthy Mild(HPA) Mild PKU PKU (uM) Concentration &lt;20 120-600 360-1200 &gt;1200 It is passed down generations in an autosomal recessive pattern. Treatment Most causes are the miss-fold of the protein. The PKU Diet The treatment is limited. The most popular measure is taking the PKU Diet which has limited phenylalanine. Kuvan (sapropterin dihydrochloride) It is a form of BH4. It works for some of the patients. But the PKU diet is still needed. PAH PAH belongs to a family of biopterin aromatic amino acid-dependent hydroxylases that convert phenylalanine, tyrosine, and tryptophan into tyrosine, L-DOPA, and oxitriptan respectively. The classic PKU is caused by the malfunction of PHA. The mild PKU is caused by the regeneration of BH4: $BH_ 2 \\overset{PCD+DHPR}{\\longrightarrow} BH_ 4$ Monomer PAH has three domains: Catalytic domain (73% of mutation) Self-association domain (6% of mutation) The regulatory domain (21% of mutation) allosteric mechanism Active form PAH is Tetramer Allosteric regulation Closed Ei form turn to Ea form when the regulatory domain was activated. Both regulatory domain and catalytic domain have a binding site of phenylalanine. BH4 BH4 is the coenzyme of PAH. It also binds the regulatory site and helps PAH to stay in an inactive form. Phosphorylation phosphorylating the serine residue occupying position 16 in the regulatory domain. PAH becomes active at a lower concentration of free phenylalanine. Treatment Limited intakes of protein-rich food like meat and potatoes Persisting neurological or psychosocial issues and poor quality of life despite early intervention Nutritional deficiencies due to diet The financial burden due to the cost of special medical food and dietary supplements. Phenylalanine in excess in the blood acts as a competitive inhibitor, limiting the transport of tyrosine and tryptophan in the brain. GMP GMP are proteins derived from whey, the residual liquid left after curd formation which is low in phenylalanine. neurological complication Despite the restricted diet, some patients still developed neurological complications because they have problems with BH4 biosynthesis or regeneration. 60% of them affect the enzymes PCD and DHPR. Among these patients, the administration of a daily dose of 20 mg of BH4 per kg body weight could improve this situation. BH4 acts as a PAH-specific chaperone to leading the correct folding. PKU with mental-disorder The accumulation of phenylalanine: Oxidative stress Free radicals - form when oxygen interacts with certain molecules Results in highly reactive atoms with an odd number of electrons Has “free” electrons available for pairing Antioxidants Compounds that can “donate” an electron Neutralize oxidative effects Neurotransmitters Lipid Metabolism Bioenergetics Calcium ROS, reactive oxygen species ROS is the most important group of free radicals in the biology system. nature product of cellular metabolism low concentration Maintained by Antioxidants High concentration causes: oxidative stress. Cell components such as DNA, proteins, and cell membranes are damaged Relationship with PKU PKU diet reduced the injection of antioxidants $\\downarrow$ PKU diet also limited the synthesis of antioxidants $\\downarrow$ Increased ROS production by chronic exposure to Phe and metabolites Phe inhibition of the synthesis of endogenous antioxidants Oxidative Stress in Brain Neurotransmitter Precursors Tyrosine is a precursor of neurotransmitters catecholamines. Tryptophan is a precursor of the neurotransmitter serotonin. Inhibitors Natural inhibitors of the enzymes responsible for the syntheses of L-DOPA and dopamine, 5-hydroxytryptophan, and serotonin. Dopamine Deficit Parkinson - like symptoms Anhedonia Depression Serotonin Deficit OCD - like symptoms Impulsivity Depression Fatty acid DHA-Ethylester in brain The most abundant polyunsaturated $\\Omega$-3 fatty acid Responsible for many functions Low levels of DHA correlated to severely depressed patients Low levels of DHA lower the activity of neuronal activity and increase cell death A component of the myelin sheath (Damaged:) Cognitive disruption Neuropathies Difficulty controlling movements and balance Energy creatine/phosphocreatine system: The key enzyme, creatine kinase, was inhibited by phenylalanine. $Phosphoenolpyruvate +ADP \\overset{Pyruvate\\ kinase}{\\longrightarrow} Pyruvate + ATP$ The key enzyme, Pyruvate kinase, was inhibited by phenylalanine. The energy production restrictions largely affect the red blood cell and a high level of glycolysis damages the red blood cell structure integrity and are actively phagocytosed. Anemia observed. Ketone Bodies Under normal fasting condition, blood sugar level is low The citric acid cycle slows down Liver cells produce ketone bodies The main source of fuel for the brain Synthesis of ketone bodies is decreased by high levels of Phe PKU patients can’t produce as much Decrease in ATP synthesis in the brain Calcium High concentration of phenylalanine activates PMCA: increase in calcium concentration efflux (out). Plasmid Ca2+ is low Long term of phenylalanine exposure: chronic effects: PMCA was inactivated, Plasmid Ca2+ is high, the triggering of action potential is affected. digraph{ subgraph cluster_0{ color = \"pink\" style = filled label=\"Hypoglycemia\" fontsize = 20 node [ shape=\"box\"] GLUT1 [label = \"GLUT1 initially compensate\"] MCT1 [label = \"MCT1 Upregulation\"] NT [label = \"NT synthesis decreases\"] \"low [Glucose]\" -> GLUT1 [label=\"stimulate\"] GLUT1 -> MCT1 [label=\"failed to compensate\"] } subgraph cluster_1{ label=\"Hypoxia\" color = \"skyblue\" style = filled fontsize = 20 node [ shape=\"box\"] \"Increase in fermentation\" -> \"Accumulation of NADH₁ FADH₂\" -> NT } MCT1 -> NT [label=\"still in energy deficiency\"] NT -> \"Dangerously low fuel levels\" -> \"Severe brain damage\" } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });digraph{ Tyrosine2 [label = \"Tyrosine\"] node [shape=box] Diet -> Tyrosine subgraph cluster_0{ label = Liver fontsize = 20 color = \"pink\" style = filled Phenylalanine -> Tyrosine2 } Tyrosine2 -> Tyrosine subgraph cluster_1{ label = \"Catecholamine synthesis\" fontsize = 20 color = \"green\" style = filled Tyrosine -> Dopamine -> Norepinephrine -> Epinephrine } } var viz = new Viz(); var code = document.getElementById(\"graphviz-1-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-1\").append(element) });digraph{ node [shape=box] BOS [label =\"Brain Oxidative Stress\", color=\"skyblue\", style=\"filled\"] NCD [label = \"Neuronal Cell Death and Brain Aging\", color=\"pink\", style=\"filled\"] BOS -> \"Astrocytes are impaired\\n(Signal transduction)\" -> NCD BOS -> \"Inflammation\" -> NCD BOS -> \"imbalance in superoxide level\" -> NCD } var viz = new Viz(); var code = document.getElementById(\"graphviz-2-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-2\").append(element) });","link":"/2021/06/16/LearnNotes/edx-biochm-21/"},{"title":"Principles of Biochemistry 23 |Carbohydrate metabolism| Class Notes |HarvardX","text":"Transporters Glucose is not permeable to the cell membranes. So, the transporter is needed for cells absorbing glucose. Quick View: Glucose Transporters (GUL1) Passive transport: Glucose moves with the concentration gradient Not a channel: Transport is slower than diffusion Model of GUL1: Stepwise transfer Monosaccharide import Glucose, galactose, fructose use GLUT transporters. RBCs: glucose and galactose but not fructose transported by GLUT1 Liver: GLUT2 transports glucose, galactose, and fructose Glycolysis of monosaccharide galactose This net gain of 2 ATP per galactose from glycolysis fructose In glycolysis, hexokinase has a much higher affinity for glucose than for glucose. As a consequence, it phosphorylates the fructose only when the concentration of glucose is low. e.g.: adipocytes $$ Fructose +ATP \\overset{Fructokinase}{\\longrightarrow} Fructose^ {_ -}1^ {_ -}P + ADP \\overset{Aldolase}{\\longrightarrow} Glyceraldehyde + DHAP + (ADP) \\overset{Triose\\ kinase}{\\longrightarrow} Glyceraldehyde ^ {_ -} 3 ^ {_ -} P + ADP $$ DHAP: Dihydroxyacetone phosphonate Moannose Moannose $\\to$ Glucose-6-P Polysaccharides Digestion: Polysaccarides $\\to$ oligosaccharides $\\to$ disaccharides Pentose Phosphate Pathway Oxidative $$ Glucose^ {_ -}6^ {_ -}P + 2NADP^ + \\to Ribose^ {_ -}5^ {_ -}P + 2NADPH $$ Non-oxidative $$ Ribose^ {_ -}5^ {_ -}P \\overset{Transketolase}{\\longrightarrow} \\ \\ \\overset{Transaldolase}{\\longrightarrow} Fructose^ {_ -}1,6^ {_ -} 2P $$ NADPH = Reducing potential Fatty acid synthesis ROS neutralization Ribose-5-P $\\to$ PRPP $\\to$ Nucleotide synthesis © HarvardX Medical Consequence NADPH is used to turn oxidized Glutathione to reduced Glutathione. Glutathione could reduce the H2O2 and hemoglobin aggregates. G6PD Deficiency Glucose-6-P Dehydrogenase (G6PD) Deficiency © PDB:1DPG $$ Glucose-6-P \\overset{Glucose-6-P Dehydrogenase}{\\longrightarrow} 6-Phosphoglucono-\\delta-lactone $$ This enzyme was made by dimer. N-terminal is the site of the NADPH interactive center. $\\alpha$ and $\\beta$ domains are keeping the dimer structure. The deficiency of this enzyme Red blood cells encounter oxidative stress - a large amount of iron &amp; hemoglobin, highly oxygenate tissue lack mitochondria Dependent on the pentose phosphate pathway for reducing agents Hemoglobin aggregates lead to the formation of Heinz bodies that affect the elastic properties of red blood cells and also contribute to hemolysis. Heinz bodies: Heinz bodies (Heinz-Ehrlich bodies) Inclusions within red blood cells composed of denaturing hemoglobin The hallmark of G6PD deficiency Classes Result I - Extreme deficiency - chronic haemolytic anaemia II - Severely deficiency (1-10% residual activity), acute haemolytic anaemia III - Moderately deficient(10-60%) IV - Normal activity (60-150%) V - Increased Activity(&gt;150%) X chromosome linked Gene Discovery Soldiers received Primaquine, an anti-malarial drug that adds oxidative stress to blood cells Some became anemic - had G6PD deficiency. Leading Acute hemolytic anemia (AHA) Primaquine induces lethal oxidative damage to different strains of Plasmodium. In healthy people, the oxidative damage could be prevented by the reduced Glutathione Factors affecting the severity of AHA: G6PD Activity Red Cell Aging Drug dose Prevention Triggering Agents Drug Ingestion of Fava Bean Infection Diseases like diabetes, myocardial infraction Intense physical exercise Severe neonatal jaundice neurological consequences The peak of bilirubin in the blood due to accumulation of hemoglobin breakdown (hallmark) Favism Fava beans contain high concentrations of: Nonvolatile glucosides (vicine, convivine) Aglycones: Produce free radicals Can trigger a hemolytic response in G6PD-deficient people. Cures for G6PD Deficiency The most important measure is prevention - avoidance of the drugs and foods that cause hemolysis In severe cases of hemolysis, blood transfusions might be necessary, or even dialysis in acute renal failure. Some patients benefit from the removal of the spleen as red blood cells are lysed there. The distribution of the G6PD is correlated to the distribution of malaria, which leads to a hypothesis that the G6PD is a selective advantage in parts of the world. digraph{ node [shape = box] inter1 [label=\"\", width =0, height = 0] inter2 [label=\"\", width =0, height = 0] \"UDP-Glucose\" [label = \"UDP-Glucose\", style = \"filled\", color = \"skyblue\"] \"UDP-Glucose2\" [label = \"UDP-Glucose\", style = \"filled\", color = \"skyblue\"] Galactose -> inter1 -> \"Galactose-1-P\" \"Galactose-1-P\" -> inter2 -> \"UDP-Galactose\" ->\"UDP-Glucose\" -> \"Glucose-1-P\" [dir = both] ATP -> inter1 -> ADP [color = red, style = \"dotted\"] \"UDP-Glucose2\" -> inter2 -> \"Glucose-1-P\" [dir = both, color = skyblue, style = \"dotted\"] \"UDP-Glucose2\" -> \"UDP-Glucose\" [dir = none, style = \"dotted\", color = \"red\"] } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });digraph{ subgraph{ node [shape = none, weight = 0, height = 0, fontcolor=\"skyblue\"] inter1 [label = \"Glucose-6-P\\ndehydrogenase\"] inter2 [label = \"Gluconolactonase\"] inter3 [label = \"6-Phosphogluconate\\ndehydrogenase\"] inter4 [label = \"Phosphopentose\\nisomerase\"] } subgraph{ node [shape = hexagon ] \"Glucose-6-P\" \"6-Phosphoglucono-δ-lactone\" \"Ribose-5-phosphate2\" [label = \"Ribose-5-phosphate\", shape = pentagon] } subgraph{ node [shape = underline] \"6-Phosphogluconate\" \"Ribulose-5-P\" \"Ribose-5-phosphate\" } node [shape = line] \"Glucose-6-P\" -> inter1 -> \"6-Phosphoglucono-δ-lactone\" -> inter2 -> \"6-Phosphogluconate\" -> inter3 -> \"Ribulose-5-P\" -> inter4 -> \"Ribose-5-phosphate\" -> \"Ribose-5-phosphate2\" [dir = both, style=\"bold\"] subgraph{ edge [color = \"red\", style = \"dotted\"] \"NADP⁺2\" [label = \"NADP⁺\"] NADPH2 [label = \"NADPH\"] \"NADP⁺\" -> inter1 -> NADPH [dir = both] \"H₂O\" -> inter2 -> \"H⁺\" [dir = both] \"NADP⁺2\" -> inter3 -> NADPH2 [dir = both] inter3 -> \"CO₂\" } } var viz = new Viz(); var code = document.getElementById(\"graphviz-1-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-1\").append(element) });digraph{ rankdir = \"LR\" node [shape=box] GLY [label = \"Glyceraldehyde-3-P\"] DIH [label = \"Dihydroxyacetone-P\"] FRU [label = \"Fructose-1,6-P\"] edge [dir = both, fontcolor = \"skyblue\"] subgraph{ rank = same GLY -> DIH [label = \"Triose Phosphate\\nisomerase\"] } GLY -> FRU [label = \"Aldolase\"] DIH -> FRU [label = \"Aldolase\"] FRU -> \"Fructose-6-P\" [label = \"Fructose-1,6-\\nbisphosphate\"] } var viz = new Viz(); var code = document.getElementById(\"graphviz-2-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-2\").append(element) });","link":"/2021/06/22/LearnNotes/edx-biochm-23/"},{"title":"Principles of Biochemistry 2 |Entropy| Class Notes |HarvardX","text":"What is life? Carbon is the base of life. But organisms are not only a piece of carbon. Living life constantly carries a series of energy exchange processes. Types of Metabolism Entropy and reaction Gibb’s free energy equation $$ G = H - TS $$ G: Free engergy H: Enthalpy T: Temperature S: Entropy Enthalpy (H): Total energy of the system (Energy in bonds) Entropy (S): Quantitative expression for the randomness of the system; (the disorder of the system, the amount of energy that cannot do work) Temperature (T): Temperature; Degrees Kelvin $TS$: Increased temperature intensifies random molecular motion, leading to increased disorder. Free Energy (G): The only portion of the energy that is able to do work. In a cell that carries reactions, the amount of energy lost as heat, which contributes to random motion, increased entropy, and the reaction was irreversible. Spontaneous Reaction In a spontaneous reaction, the free energy is decreased, therefor: $\\Delta G &lt; 0$ Because: $\\Delta G = \\Delta H - T\\Delta S$ As a result: $\\Delta H &lt; T \\Delta S$ So, $\\Delta H$ is negative: $(-)\\Delta H$, the heat is release, it is a exothermic reaction. $\\Delta H$ is positive: $(+)\\Delta H$, the heat is absorbed, it is a endothermic reaction. The parameters of the reaction: Spontaneous or not; Equilibrium constant; Directionality; Velocity; Equilibrium A reaction can occur spontaneously only if $\\Delta G$ is negative. (exergonic) A system is at equilibrium and no net change can take place if $\\Delta G = 0$ A reaction can not occur spontaneously, only input of free energy to lead it happens when the $\\Delta G &lt;0$ . (endergonic) Equilibrium constant $S \\rightleftharpoons P$ The concentration of S and P constantly changes. This ration is called: Equilibrium constant ($K_{eq}$) $K_{eq} = \\frac{[P]_ {eq} } { [S]_{eq}}$ Significant: most chemical reactions are reversible. By knowing the $K_{eq}$ and the initial the concentration, we can predict the direction of reaction. Calculating Exp. 1: Dihydroxyacetone phosphate (DHAP) Glyceraldehyde 3-phosphate (G3P) $$DHAP \\rightleftharpoons G3P$$ $K_{eq} = \\frac{[G3P]}{[DHAP]}$ $\\ \\ \\ \\ \\ \\ \\ = 0.475$ Stabdard free energy change ($\\Delta G^{\\circ}$): $$\\Delta G^{\\circ} = -RTln(K_{eq})$$ R: gas constant T: temperature expressed in degrees Kelvin. So, a standard condition is a condition that the reaction proceeds at a constant temperature-- T equals 298 Kelvin or $25^{\\circ}$C: $$T = 298K = 25^{\\circ}C$$ Reactants and products = $1M$ $R = 1.98 \\times 10^{-3} kcal^1 mol^{-1} deg^{-1}$ $\\Delta G^{\\circ} = -RTln(K_{eq})$ $\\ \\ \\ \\ \\ \\ \\ \\ = - (1.98 \\times 10^{-3}) \\times 298 \\times ln(0.0475)$ $\\ \\ \\ \\ \\ \\ \\ \\ = 1.80 kcal/mol$ So, the $\\Delta G^{\\circ}$ is positive. But the thing that determines the property spontaneously is the free energy change. It gives a function $$\\Delta G = \\Delta G^{\\circ}+ RTln(K)$$ Here, K is the actual ratio of glyceraldehyde 3-phosphate and dihydroxyacetone phosphate concentrations in the cell. In this example, the concentration of the DHAP is $2 \\times 10^{-4}M$ and the G3P’s concentration is $3 \\times 10^{-6}M$ (the initial of the concentration). Under this condition, We now have: $\\Delta G = \\Delta G^{\\circ}+ RTln(K)$ $\\ \\ \\ \\ \\ \\ \\ = 1.80 + RTln(\\frac{[G3P]}{[DHAP]})$ $\\ \\ \\ \\ \\ \\ \\ = 1.80 + (1.98 \\times 10^{-3}) \\times 298 \\times ln(\\frac{3 \\times 10^{-6}}{2 \\times 10^{-4}})$ $\\ \\ \\ \\ \\ \\ \\ = - 0.7 kcal/mol$ As a result, the $\\Delta G &lt; 0$ That’s means, it is a spontaneous reaction! Delta G We already know that: $\\Delta G = \\Delta G^{\\circ}+ RTln(K)$ When there are no works is down, then, $\\Delta G = 0$: $0 = \\Delta G^{\\circ} + RTln(K_{eq})$ $\\Delta G^{\\circ} = - RTln(K_{eq})$ Calculating Exp. 2: In the following reaction: $S \\longrightarrow P $ $K_{eq}=4$ Initial concentration of P and S: $[P]= 10M;[S]=1M$ The forward reaction is ?: Standard Calculation: $\\Delta G = \\Delta G^{\\circ} + RTln(K)$ $\\Delta G = - RTln(K_{eq}) + RTln(K)$ $\\Delta G = RT(RTln(K) - ln(K_{eq}))$ $\\Delta G = RT(ln(10) - ln(K_{4}))$ $\\Delta G = 1.98 \\times 10^{-3} \\times 298 \\times (ln(10) - ln(4))$ $\\Delta G = 0.5406482kcal/mol$ or can avoid the calculation: $\\Delta G = \\Delta G^{\\circ} + RTln(K)$ $\\Delta G = - RTln(K_{eq}) + RTln(K)$ $\\Delta G = RT(ln(K) - ln(K_{eq}))$ $\\Delta G = RT(ln(10) - ln(K_{4}))$ $\\because RT &gt; 0$ $\\because ln(10) - ln(K_{4}) &gt; 0$ $\\therefore RT \\times ( ln(10) - ln(K_{4}) ) &gt; 0$ $\\therefore \\Delta G &gt; 0$ Another way: $\\because K_{eq} = \\frac{[P_{eq}]}{[S_{eq}]} = 4$ $\\because K = \\frac{P}{S} = 10$ $\\therefore K_{eq} &lt; K$ $\\therefore ln(K) - ln(K_{eq}) &gt; 0$ $\\because RT &gt; 0$ $\\therefore RT \\times ( ln(10) - ln(K_{4}) ) &gt; 0$ $\\therefore \\Delta G &gt;0$ Cover: Walkowski, Slawomir &amp; Szymas, Janusz. (2011). Quality evaluation of virtual slides using methods based on comparing common image areas. Diagnostic pathology. 6 Suppl 1. S14. 10.1186/1746-1596-6-S1-S14. digraph F { rankdir = DU; subgraph cluster_1 { rank = UD minerals [label = \"minerals\", shape = box, fillcolor = \"#FF0000\" ]; O2 [label = \"O2\", shape = diamond, color = green, size = 2]; CO2 [label = \"CO2\", shape = diamond, color = green, size = 2]; organics [label = \"organics\" , shape = box, color = coral]; } subgraph cluster_0 { Food [label = \"Food\", shape = box, color = deepskyblue1]; Sun [label = \"Sun\", shape = box, color = deepskyblue1]; } subgraph cluster_2 { Metabolism [label = \"Metabolism\", shape = circle, color = pink, size = 3]; Catabolism [label = \"Use for variety bio-activities\"] Anabolism [label = \"Build body component\"] Metabolism -> Anabolism [label = Anabolism]; Metabolism -> Catabolism [label = Catabolism]; } subgraph cluster_0 { style=filled; color=lightgrey; node [style=filled,color=white]; label = \"Potential Energy\"; } subgraph cluster_1 { node [style=filled]; label = \"Surrounding Energy\"; color=blue } subgraph cluster_2{ node [style=filled]; label = \"Living Cell\"; color= red } Food -> Metabolism [ label = \"Catabolism\" ]; Sun -> Metabolism; minerals -> Metabolism; organics -> Metabolism; O2 -> Metabolism; CO2 -> Metabolism; } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });digraph F { NSunlight [label = \"Not Sunlight\"]; Organisms -> Sunlight -> Phototrophs; Organisms -> NSunlight -> Chemotrophs; Phototrophs -> Food; Phototrophs -> CO2; Chemotrophs -> Food -> Heterotrophs; Chemotrophs -> CO2 -> Autotrophs; subgraph cluster_0{ node [style=filled]; label = \"Energy source\"; color= blue Sunlight; NSunlight; Phototrophs; Chemotrophs; } subgraph cluster_1{ node [style=filled]; label = \"Carbon Source\"; color= pink; Food; CO2; } subgraph cluster_2{ node [style=filled]; label = \"Metabolic type\"; color= red; Autotrophs; Heterotrophs; } {rank=\"same\"; Heterotrophs; Autotrophs} Heterotrophs -> Autotrophs [label = CO2; color= red]; Heterotrophs -> H2O -> Autotrophs [ color= red]; Autotrophs -> O2 -> Heterotrophs [ color= blue]; Autotrophs -> organics -> Heterotrophs [ color= blue]; } var viz = new Viz(); var code = document.getElementById(\"graphviz-1-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-1\").append(element) });","link":"/2021/03/23/LearnNotes/edx-biochm-2/"},{"title":"Principles of Biochemistry 25 |Cancer and Metabolism| Class Notes |HarvardX","text":"Cancer Normal: Low rate of division Metabolize glucose to CO2: Glycolysis + TCA + Oxidative phosphorylation Cancer Cell: Metabolic reprogramming: conventional pathways have altered activity due to genetic mutations and the tumor microenvironment Enables increased growth, rapid division Healthy cells with rapid division: Embryo development, immune responses, wound healing Similar metabolic reprogramming as in cancer Factors Internal factors Genetic mutation: HIF1; PI3K-ATK/mTOR; MYC; KRAS; p53 External Tumor microenvironment: Hypoxia; Nutrient concentration; pH. Metabolic Adaptation: Bioenergetics: Rapid ATP synthesis; Biomass production Increased Biosynthesis: Carbohydrates; Proteins; Nucleic Acids; Lipids Maintaining redox status: Maintain the ratio of oxidized and reduced molecules Warburg Effect Otto Warburg’s observation (1924): Tumor tissues uptake glucose, release lactate Anaerobic glycolysis, even when O2 is available Response to heterogeneous/hypoxic conditions in the tumor microenvironment Rapid glucose and glutamine uptake by cancer cells starve neighboring differentiated cells. Lactate secretion makes the microenvironment acidic, which undermines immune cell responses. NADPH production helps tumor cells tolerate their high ROS production Hypothesis Anaerobic Fermentation could generate two more NDAH witch could be used in the generation of the pentose phosphate pathway. The carbon served to the growth and division. Evidence Pyruvate Kinase in Warburg Effect Gene Splicing Isoform Tissue Distribution L Exon2 L Liver L Exon1 R Red Blood Cells M Exon9 M1 Adult M Exon9 M2 Embryo and Tumor Tumors switch isoforms and use PKM2 less active pyruvate kinase M2 supports the carbon retention that enables rapid cancer cell growth. p53, LKB1/AMPK mutation is easy to be found among tumor tissues. Cancer metabolites Oncometabolites: metabolic compounds observed in higher concentration in cancer tissue than healthy tissue. Example: 2-hydroxyglutarate (2HG) In normal cells: $isocitrate + NAD(P )^+ \\overset{IDH}{\\longrightarrow} \\alpha^{_-}ketoglutarate + NAD(P )H + H^+ + CO_2$ IDH: Isocitrate Dehydrogenase Variantes of IDH: Enzyme Cofactor Substrate Localization IDH1 NADP+ Isocitrate Cytosol IDH2 NADP+ Isocitrate Mitochondria IDH3 NAD+ Isocitrate Mitochondria IDH1 and IDH2 mutate in certain cancers: Accept α KG substrate. New product 2HG is a cancer metabolite $$ isocitrate \\underset{Wild-type\\ IDH1/IDH2}{\\overset{NAD(P )^+ \\to NAD(P )H + H^+ + CO_2}{\\longrightarrow}} \\alpha^{_-}ketoglutarate \\underset{Mutant\\ IDH1/IDH2}{\\overset{ NAD(P )H + H^+ \\to NAD( P)^+ }{\\longrightarrow}} 2-hydroxyglutarate $$ mTOR directly affects translation Effects eukaryotic elongation factor 4E (elF4E) This leads to overall increased translation Metabolism in Cancer Cell © HarvardX Reactive Oxygen Species Reactive Oxygen Species (ROS) Low levels: Cell proliferation; Survival pathway media levels: Increased mutagenesis; Cancer cells more adaptive: faster growth, fewer controls on proliferation High levels: Oxidative stress; Cell death High levels of ROS mean less ATP was produced. At the same time, a high level of H2O2 was produced. It increased the level of oxidized nucleotides which causing more mutations in our gene: nitrogen-based guanine to 8-oxoguanine. Prohibited some phosphatase that kinase could not be activated, and the proliferation and growth could not be stopped. To prevent oxidative stress and cell death leads to from high levels of ROS, Antioxidants like NADPH and GSH (Glutathione) were largely produced. $$ 2GSH \\underset{Glutathione\\ peroxidase}{\\overset{H_2O_ 2 \\to 2H_ 2O}{\\longrightarrow}} GSSG \\underset{Glutathione\\ reductase}{\\overset{NADPH + H^+ \\to NADP^+}{\\longrightarrow}}2GSH $$ GSH: Reduced Glutathione GSSG: Oxidized Glutathione Also, the main source of NADPH comes from the pentose phosphate pathway. cachexia Cachexia: Metabolic syndrome Muscle wasting adipose tissue wasting Increased energy expenditure Anabolism in tumor cell Metabolic stress decreased energy intake Tumor needs lots of energy metabolic precursors. Except for intake from food, adipose tissue and muscle tissue is the main source of the provider. The adipose tissue provides fatty acid and reduces the intake of TAG. Furthermore, it causes inflammation. Lactate released from tumor tissues was transported into the liver and back to the tumor after the lactate was converted into glucose. Glutamine has come from muscle. Autophagy: protein degradation UCPs: ATP $\\downarrow$ Growth Factors$\\downarrow$ : Protein synthesis$\\downarrow$ Brain: change the neuropeptide affecting the sense of smell and taste decreased appetite to leads the anorexia Gut: Microbiota infection and inflammation Heart: Increase energy consumption digraph{ node [shape = box] inter1 [label = \"\" , shape = none, weight = 0, height=0] Lactate [color = \"red\"] Glucose -> inter1 -> Private -> TCA [ color = \"blue\"] Private -> Lactate [color = \"blue\"] { edge [arrowhead = tee, color = \"red\"] p53 -> inter1 HIF1 -> TCA \"LKB1/\\nAMPK\" -> mTOR } {rank=same; mTOR; p53; inter1} mTOR -> inter1 mTOR -> HIF1 -> inter1 } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });digraph{ rankdir=\"LR\" subgraph I { node [shape= none, width = 0, height = 0, fontcolor = skyblue, font = bold] inter1 [label = \"Glutamine-\\ncysteine ligase\"] inter2 [label = \"Glutathione\\nsynthetase\"] inter3 [label = \"Malate\\ndehydrogenase\"] } subgraph A {rank = same node [shape = box] GC [label = \"Glu-Cys\"] Gln -> Glu -> inter1 -> GC -> inter2 -> GSH } subgraph B { edge [color = red, style = dotted] CA1 [label = \"Cysteine\\nATP\"] ATP1 [label = \"ATP\"] CA2 [label = \"Cysteine\\nATP\"] ATP2 [label = \"ATP\"] CA1 -> inter1 -> ATP1 CA2 -> inter2 -> ATP2 } Glu -> \"&alpha;-KG\" -> Malate -> inter3 subgraph cluster_0 { label = \"TCA cycle\" \"&alpha;-KG\" [shape = box] Malate [shape = box] } subgraph C { rank = same Pyruvate [shape = box] inter3 -> Pyruvate \"NADP⁺\" -> inter3 -> NADPH [color = red, style = dotted] } } var viz = new Viz(); var code = document.getElementById(\"graphviz-1-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-1\").append(element) });","link":"/2021/06/26/LearnNotes/edx-biochm-25/"},{"title":"Principles of Biochemistry 24 |Fatty Acid Metabolism| Class Notes |HarvardX","text":"The Building block of the Fatty acid $$ Acetyl-CoA + ATP + HCO^ - _3 \\overset{ACC}{\\longrightarrow} malonyl-CoA + ADP $$ ACC: Acetyl Coenzyme A Carboxylase Fatty Acid Synthesis (FAS) A long single polypeptide chain few distinct domains with specific enzymatic activities. Domains are coordinated during fatty acid synthesis As you can see, the ACP domain is at the center of the Enzyme $Acetyl-CoA \\overset{MAT}{\\longrightarrow} CoA-SH + Acetyl$ $Acetyl + KS \\to Acetyl$-KS MAT would cleavage of malonyl CoA Three carbon malonyl group binds to ACP ACP-malonyl(3C); KS-acetyl(2C) A five steps reaction is going to join the group in KS and ACP domain Condensation (KS) malonyl(3C)-ACP $\\overset{decarboxylate}{\\longrightarrow}$ (2C)-ACP + CO2 ACP-R(2C) + Acetyl(2C)-KS $\\to$ ACP-R(4C) + KS-SH Reduction (KR) ketone group in R(4C) was removed by KR with the help of NADPH ACP-R(ketone)+NADPH + H+ $\\overset{KR}{\\longrightarrow}$ ACP-R(hydroxyl) + NADP+ Dehydration (HD) ACP-R(hydroxyl) $\\overset{HD}{\\longrightarrow}$ ACP-R(C=C) + H2O double carbon bond was formed and a water molecule was released. Reduction (ER) ACP-R(C=C) +NADPH + H+ $\\overset{HD}{\\longrightarrow}$ ACP-R(C-C) + NADP+ Two H+ was added to the R group and turn the double bond into a single carbon-carbon bond. 4 carbon saturated fatty acid was formed. Translocation R(4C)-ACP $\\to$ R(4C)-KS ACP domain is ready for a new 2 carbon chain (Acetyl group) and starts a new cycle to form an even number fatty acid chain It could also accept a Propionyl (3C) to form an odd carbon number chain Terminated When the number of carbon is larger than 16, the TE domain is easy to work on it and release to be a palmitic acid or palmitate. To conclusion: $$ 8\\ Acetyl-CoA + 7\\ ATP + 14\\ NADPH + 14\\ H^+ \\to Palmitate + 8\\ CoA + 6\\ H_2O + 7\\ ADP + 7\\ P_i + 14\\ NADP^+ $$ Desaturation © HarvardX Acetyl-CoA Shuttle Acetyl-CoA was made by mitochondria. But Fatty acid synthesis occurred in the cytoplasm. So, a shuttle was needed to transport the Acetyl-CoA from mitochondria to the cytoplasm. longer fatty acid synthesis ER: Elongation of Palmitate The palmitate is bond to the cytoplasmic phase of the ER and is modified here. Malonyl-CoA would be the source of the 2C groups. Fatty Acid Unsaturation Regulation ACC was inhibited by AMPK (AMP is high) in low nutrients palmitoyl CoA prohibited the activity when there are enough fatty acids It could be activated by Citrate in high nutrients By hormones Insulin promote the activity of ACC (high-blood-sugar) Glucogaon promote the inactivate of ACC (low-blood-sugar) Epinephrine promote the inactivate of ACC (fight-or-flight) Acyl-carnitine Shuttle © HarvardX Recall: Fatty acid Adipocytes – Stored Lipase enzyme – Disassemble Bound to protein – form lipid droplets. Bound to serum albumin – To blood Transport protein – Taken by tissue Acyl-carnitine shuttle – Mitochondria Palmitate Transport palimate +CoA-SH + ATP $\\overset{Acyl-CoA\\ synthesis}{\\longrightarrow}$ Palmitoyl-CoA + AMP +PPi Place: Outer mito membrane Palmitoyl-CoA + Carnitine $\\overset{CPT1}{\\longrightarrow}$ Palmitoylcarnitine + CoA-SH Place: Outer mito membrane CPT1: Carnitine palmitoyltransferase. It acts as a gatekeeper Palmitoylcarnitineout-membrane $\\overset{Porin}{\\longrightarrow}$ Palmitoylcarnitineinner-membrane-space Place: Outer mito membrane to inner mito membrane space PS: It could be transported before or after the reaction in step 2. Palmitoylcarnitineinner-membrane-space $\\overset{Translocase}{\\longrightarrow}$ Palmitoylcarnitineinner-mito Palmitoylcarnitine + CoA-SH $\\overset{CPT2}{\\longrightarrow}$ Palmitoyl-CoA + carnitine carnitinematrix $\\overset{Translocase}{\\longrightarrow}$ carnitineinter-membrane-space β-Oxidation Order β-Oxidation Synthesis 1 1. Oxidation 4. Condensation 2 2. Hydration 3. Reduction 3 3. Oxidation 2. Dehydration 4 4. Thiolysis 1. Reduction Oxidation (introduce a double bound into acyl CoA) $Acyl-CoA + FAD \\to trans-\\Delta^2-Enoyl-CoA+FADH_2$ FADH2 to the ETC Hydration (of the double bond) $trans-\\Delta^2-Enoyl-CoA+FADH_2 + H_2O$ $\\overset{enoyl\\ CoA\\ hydratase}{\\longrightarrow}$ $L-3-hydroxyacyl-CoA$ Oxidation (L-3-hydroxyacyl CoA dehydrogenase) $L-3-hydroxyacyl-CoA NAD^+ \\to 3-Ketoacyl-CoA + NADH + H^+$ Thiolysis (β-ketothiolase) $3-Ketoacyl-CoA + CoA-SH \\to Acetyl-CoA + Acyl-CoA$ Acyl-CoA now could go through a new cycle of β oxidation. Energy production of β-oxidation E.G.: 16C carbon fatty acid α Palmitoyl-CoA(16C) + 7 FAD + 7 NAD+ + 7 CoA + 7 H2O ⟶ 8 acetyl-CoA + 7 FADH2 + 7 NADH + 7 H+ 8 Acetyl-CoA can yield 80 ATP 7 FADH2 can yield 10.5 ATP 7 NADPH can yield 17.5 ATP 108 - 2 = 106ATP in toltal 2ATP was used to turn the Plamitate into Plamitoyl-CoA Odd number of the carbon chain palmitate The final step of β-oxidation was yielding an acetyl-CoA and a propionyl-CoA(3C). propionyl-CoA was converted into Succinyl-CoA Palmitoleoyl-CoA (Δ9) The first three rounds of β-oxidation proceed as they would with palmitoyl-CoA. The double bond is reached. cis-Δ3-Enoyl-CoA is produced. cis-Δ3-Enoyl-CoA $\\overset{isomerase}{\\longrightarrow}$ trans-Δ2-Enoyl-CoA When the double bond in the 4th Carbon: (Δ4)Acyl-CoA $\\overset{dehydrogenase}{\\longrightarrow}$ (Δ2,4)Acyl-CoA (Δ2,4)Acyl-CoA + NADPH + H+ $\\overset{2,4-Dienoyl-CoA\\ reductase}{\\longrightarrow}$ (Δ2)Acyl-CoA + NADP (Δ2)Acyl-CoA $\\overset{trans-\\Delta^3-enoyl-CoA\\ isomerase}{\\longrightarrow}$ tran-Δ2-Acyl-CoA ⟶ β-oxidation Metabolic Myopathies Severe: often fatal Less severe: Adult-onset Muscle weakness Cramps exercise intolerance heart failure Carnitine deficiency It was made by the liver or obtained from the diet OCTN2 Deficiency: OCTN2 is responsible for the transport of the carnitine. carnitine transport was affected including cardiac and skeletal muscle. Carnitine synthesis: synthesis by the liver at a lower level. palmitoylcarnitine was not made So, the palmitate could not enter the mitochondria lipid storage (unbalance between storage and breakdown) Treatment: oral carnitine Fibrates (PPAR activators) Gene expression: CPT2, Acyl-CoA synthetase; Acyl-CoA dehydrogenase CPT2 Deficiency Exercise intolerance Cramps Muscle weakness can be fatal The accumulation of carnitine molecules and causes irregular heartbeats. Treatment trigger factors avoid: prolonged exercises or fasting High carbohydrate diet Fibrates Acyl-CoA dehydrogenase VLCAD: very-long-change fatty acid (18C, 16C) Similar to CPT2 deficiency long-chain FFA in blood and urine MCAD: medium-chain (C10, C8) common accumulation of medium-chain of FFA, which is neurotoxic SCAD: short-chain (C6, C4) less severe accumulation of methylmalonic acid and cause Aciduria Treatment: Frequent, high-carb meals. VLCAD: Avoid very-long-chain fats. supplement triheptanoin digraph{ rankdir = \"LR\" \"node1\" [ label = \" KS| TE\" shape = \"record\", color = white ]; \"node2\" [ label = \" MAT| ACP| ER\" shape = \"record\", color = white ]; \"node3\" [ label = \" KR| HD\" shape = \"record\", color = white ]; node1:KS-> node2:MAT-> node3:HD node3:HD -> node2:ER [tailport=s, headport = s] node2:ER-> node3:KR [headport = \"e\"] node3:KR -> node2:ACP->node1:TE } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });digraph{ node [shape = box] ACOA1 [label = \"Acetyl-CoA\"] ACOA2 [label = \"Acetyl-CoA\"] Citrate1 [label = \"Citrate\"] Citrate2 [label = \"Citrate\"] Pyruvate2 [label = Pyruvate] \"Pyruvate*\" [label = \"Pyruvate*\", color = \"pink\", style = \"filled\"] Oxaloacetate2 [label = \"Oxaloacetate\"] NADPH2 [label = NADPH] NADP⁺2 [label = NADP⁺] Inter0 [label = \"\", width = 0, height = 0] Inter1 [label = \"shuttle\", color = \"pink\", style = \"filled\"] Inter2 [label = \"ATP citrate lyase\", fontcolor = \"skyblue\",shape = none] Inter3 [label = \"Malate Dehydrogenase\", fontcolor = \"skyblue\",shape = none] Inter4 [label = \"Malic enzyme\", fontcolor = \"skyblue\",shape = none] subgraph cluster_0{ label = \"Mitochondrial\" Pyruvate -> ACOA1 -> Inter0 -> Citrate1 -> Oxaloacetate -> Inter0 {rank = same; Citrate1; Oxaloacetate} \"Pyruvate*\" -> Oxaloacetate [label = \"Pyruvate\\nCarboxylase\", fontcolor =\"skyblue\"] } Citrate1 -> Inter1 -> Citrate2 -> Inter2 CoA -> Inter2 H₂O -> Inter2 ATP -> Inter2 -> ADP [style = \"dotted\", color = red] Inter2 -> ACOA2 [headport = e] Inter2 -> Oxaloacetate2 [headport = w] Oxaloacetate2 -> Inter3 -> Malate -> Inter4 -> Pyruvate2 -> \"Pyruvate*\" NADPH -> Inter3 -> NADP⁺ [style = \"dotted\", color = red] NADPH2 -> Inter4 -> NADP⁺2 [style = \"dotted\", color = red] } var viz = new Viz(); var code = document.getElementById(\"graphviz-1-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-1\").append(element) });","link":"/2021/06/25/LearnNotes/edx-biochm-24/"},{"title":"Principles of Biochemistry 3 |Amino acid to Protein| Class Notes |HarvardX","text":"Primary: Amino acid © HarvardX 4 groups: H group | amino group | carboxyl group | side chain (variable group). In the pH of 7.4: The amino group is positively charged, The carboxyl group is negatively charged. As a result, the amino acid is a neutral, zwitterion. Chiral, the amino acid made by organisms are all L-amino acids. As you can see in the 2D and 3D models below, when we write the formulae of the L and D form of the valine, we write it from Carboxyl to R Chain. When the Amino group against us is D-form. When the amino away from us is L-from. In the formulae, when the amino group on the left and the carboxyl group on the right, the side-chain out of the plane is L-form, divine into the plane is D-form. L-Valine D-Valine Interactions between amino aicd Van de Waals Interactions: weakest and only in short distances. Hydrogen bond: short distances and polar groups. Salt bridges (Ionic bond): Strongest non-covalent bond Difference between amino acid Aspartate Glutamate Aspartate is similar to Glutamate, which has a longer R chin contributing extra methane. This makes the result different since Glutamate has more number of rotamers. As a result, Glutamate has a better ability to position itself exactly in the right position. Histidine Histidine is often found in the activity sites of enzymes. Histidine Imidazole So, it could be either charged or uncharged at the same time in its imidazole group. As a result, it could be an electron shuttle. (From blue H+ to Green H^+ ^) © HarvardX Others Tyr is more acidic than Thr/Ser even though there are all alcohols. Sulfur atom: Methinoine: Cysteine: Oxidation/Reduction (Disulfide bond). Achiral amino acid: Glycine Proline Glycine has hydrogen on its side-chin. Proline’s side-chain covalent to the hydrogen group from C. These make proline has less but a unique conformation among other amino acids and contributes to the protein folding. Primary -&gt; Secondary -&gt; Tertiary -&gt; Quaternary Secondary: Beta sheet; Alpha helix, and loops. Peptide Structure C-$\\alpha$: Tetrahedral structure C-Carboxyl: Trigonal structure (which suggest that the peptide bond is a double bond) Distance: $C_{amines}=N &lt; C_{Carboxyl} -N &lt; C_{amines}-N$ $C_{carboxyl} - N = 1.32\\mathring{A}$ $C_{amines} - N = 1.469\\mathring{A}$ partial double bond character not rotate freely: remain two structure: cis/trans Most AA prefers to stay in a trans structure except proline. Rotation (dihedral angles) of the $C_{\\alpha}$ $\\phi: C_{\\alpha}-N$ (amino) Measurement: look down at the length of the $N-C_{\\alpha}$ from its most terminal end measure the angle between the two carbonyl carbons. (PS: Let’s just say, overlap the N and $C_{\\alpha}$, and measure the two carbonyl carbon) $\\psi: C_{\\alpha}-C$ (carboxyl) measure: Similarly, let’s overlap the $C_{\\alpha}-C$ atoms, and measure the angle of the two amino atoms. $\\omega: C_{carboxyl} - N = 0^{\\circ}/ 180^{\\circ}$ (peptide bond) $0^{\\circ}$: cis-form $180^{\\circ}$: trans-form Let’s take look at this simplified 3D model. First, we need to identify the $C_{\\alpha}$. It is placed right in the center which connected a carbon (grey in left), nitrogen (Blue in right), and two hydrogens (white in up and down) When measuring the $\\phi$, which is the angle of $C_{\\alpha}-N$ bond. After we overlap the $C_{\\alpha}$ and $N$ (from N to C), we could measure the angle by looking at carboxyls. In this case, I believe it is $90^{\\circ}$. When measuring the $\\psi$, which is the angle of $C_{\\alpha}-C$ bond. we overlap the $C_{\\alpha}$ and $C$ (from $C_{\\alpha}$ to $C$ carboxyl),and we can measure the angle by look at Aminos. Which I believe is around $155^{\\circ}$ PS: the angles are from 0 to 180 from clockwise and -0 to -180 from anti-clockwise. $\\phi$ $\\psi$ Ramachandran Plot: G.N. Ramachandran realized that not all $\\phi$ and $\\psi$ angles are allowed. When it goes into some specific angle, there are steric clashes. using molecular models to test the possible value of dihedral angles. only a few dihedral angles for normal natural proteins. The result was presented as a plot: Ramachandran Plot. Ramachandran Plot © HarvardX As shown in the Ramachandran plot, the dihedral angle falls into green forms alpha helix, hit in purple forms beta-sheet, or end in the grey area becomes a loop. Proline break alpha helix Proline break alpha helix Alpha helix In alpha-helix: Right-handed helix. each turn as 3.6 residues. Hydrogen bonds between nitrogen residue and carboxyl residue were formed. The side chain is towards us and slightly downwards towards the N-terminals. Exp: In a partial alpha-helix of ATP synthesis, all hydrophobic residues are in the same face which forms a hydrophobic core against another helix group. Beta sheet： string, arrow stands from N terminal to C terminal. Type: mixed, anti-parallel strands, parallel strands. When the beta-sheet was formed, the side chains were performed above or below the sheet. Exp: alternating aliphatic and polar residues could form a sheet with one hydrophobic side and one polar side. loop Alpha helix and beta-sheets need a series of repetitions to form a structure. If the pattern is not continued, they could be loops. So, all regions of the Ramachandran plot could form loops. glycine being very flexible, and proline being restricted, but being able to form cis peptide bonds. And so proline and glycine are often found within loop regions of proteins. Proline is technically an imino acid! This means that the R-group connects to the backbone at nitrogen AND C-alpha. This prevents hydrogen bonding that sustains the secondary structure of an alpha helix. Prolines are often found at the beginning and the end of alpha-helices. They can also make strong kinks in the helical structure because the N-terminal peptide bond is more constrained. Tertiary and Quaternary Structure Both structures are the result of non-covalent bond interactions: Van de Waals, hydrogen bond, and salt bridges. Tertiary: Arrangement of single peptide Quaternary: Arrangement of several peptides Example: alcohols dehydrogenase: Motif: The smallest secondary structures are assembled in a consistent way. (A commonly repeated arrangement of a few secondary structural elements.) exp: Beta alpha Beta motif: Domain: One or more motifs can assemble to form a compact globular structure. It is an independent folding unit in a protein. They can fold on their own when you isolate them independently from the rest of the protein. exp: Rossmann fold. The active site of an enzyme is often located in a loop region which could be shaped both chemically and structurally to provide specifically. And it is often in the crevasses between two domains that are rich in loops. dehydrogenase 3d model; © Molview.org In this enzyme, two identify Peptides joined by beta-sheets to form a functional quarternary structure. Domain-Fold: Fold: classify protein structure; An arrangement of secondary structural elements of a domain or protein Fold Rosman fold © Daniel A. Bochar[1] Rossmann fold was a sandwich structure which beta-sheet enveloped by alpha-helix. As you can see in the 3D model above, the Rossmann fold serves as an activity site for alcohol dehydrogenase. Beta fold: carbonic anhydrase © PDB:1HCB © PDB:1HCB Carbonic anhydrase catalyzes the inter-conversion of carbonic acid, the result of dissolved carbon dioxide and bicarbonate. It is therefore a critical enzyme for maintaining pH balance in the blood. Alpha helix fold: myoglobin © PDB:1mdb similar sequences have a similar structure, diversity sequences can still have a similar structure. All grey background image of molecular formulae comes from PubChem The side-chain of its pKa is 6. 3D structure model was embedded from molview.org Daniel A. Bochar, Jona. Freisen, Cynthia V. Stauffacher, Victor W. Rodwell,2.02 - Biosynthesis of Mevalonic Acid from Acetyl-CoA,Editor(s): Sir Derek Barton, Koji Nakanishi, Otto Meth-Cohn,Comprehensive Natural Products Chemistry,Pergamon,1999,Pages 15-44,ISBN 9780080912837,https://doi.org/10.1016/B978-0-08-091283-7.00035-7. ↩︎","link":"/2021/03/24/LearnNotes/edx-biochm-3/"},{"title":"Principles of Biochemistry 4 |Peptide Folding| Class Notes |HarvardX","text":"RNAse A Folding Properties When a peptide is folding, theoretically there are infinite conformations. But the entropy among them is different. They prefer to stay in a lower entropy form by thermodynamic low. This is thermodynamic stability. expect that, the hydrophobic interactions, disulfide bonds are also contributed the protein folding and make the folding predictable. Thermodynamic Protein folding funnel © Jon Lieff, MD The image shows left gave an illustration of the protein folding that follows the thermodynamic stability. Though there are infinite conformations for peptides, some of them contain higher free energy ($G$) which makes them unstable. The lower they fall into, the less $G$ they have, and the more stable they are. This naturally leads the peptide to fold into one (or maybe a few?) more “favorable” conformation Hydrophobic effect: These hydrophobic interactions have an impact not just on the primary structure but then lead to changes seen in the secondary and tertiary structure as well. Globular proteins acquire distinct compact native conformations in water as a result of the hydrophobic effect Libretexts: Introduction and Protein Structure It is a very highly cooperative process. As the start contacting each other, they constrain the backbone surrounding them and force other hydrophobic molecules to come close like a snowball effect. © PDB:5RSA Rnase A:It is a small and classical model system124 residues protein4 Disulfide bonds. © PDB:5RSA Anfinsen Experiment added 8 molar urea to RNAse A: 0% Activity Urea unfolding protein Remove Urea, 100% Activity Back Urea + $\\beta$-mercaptoethanol (destroy disulfide bond) dialysis of the Urea and $\\beta$-mercaptoethanol Reform disulfide bonds in an oxidizing environment Recover to 90% activity. Urea +$\\beta$-mercaptoethanol (destroy disulfide bond) Reform disulfide bonds in an oxidizing environment dialysis the Urea About 1% of activity Take the RNAse A from experiment 3 which has about 1% activity to a small concentration of $\\beta$-mercaptoethanol and it regains 90% of activity. Urea: high poly molecule to denature the protein $\\beta$-mercaptoethanol: destroy the disulfide bonds. Dialysis: Remove the Urea Oxidizing: Giving an oxidation environment to form disulfide bonds. What can we learn: Urea: a very poly molecule and inhibit the hydrophobic impact of protein folding. Most folding was followed thermodynamic low. So, they can return to natural folding spontaneously. Primary structure is sufficient to predict the higher structures. They don’t need templates or instructors. Protein folding funnel Protein folding funnel (As its show above) Folding intermediate: thermodynamic trap Protein may fold falsely trapped in the incorrect local as pointed out below. © schaechter.asmblog.org Protein folding kinetic Protein funnel. Starting from the high to the bottom of the funnel. phi and psi angle: the region. Only a serious fall in the region could form an alpha-helix or beta-sheet: that protein folding relies on very precise conformations of the backbone through their $\\phi-\\psi$ angles Magnitude: Levinthal’s paradox Peptide: 100. Hypothesis: 3 conformations for each. $3^100$ possible conformation. $0.1ps$ time per conformation. $10^27$ years to finish. Universe ~ $14 \\times 10^9$ years Because of the paradox, it becomes obvious that the protein cannot sample conformation space in a random fashion. Instead, the protein samples the space in a way consistent with statistical mechanics.[1] A Mathematical resolution for Levinthal’s paradox: R Zwanzig, A Szabo, and B Bagchi, 1992: Levinthal’s paradox Cooperativity Cooperativity in protein: Cooperativity is a phenomenon displayed by enzymes or receptors that have multiple binding sites where the affinity of the binding sites for a ligand is increased, positive cooperativity, or decreased, negative cooperativity, upon the binding of a ligand to a binding site.[2] Exp: Nucleation Condensation model: During the hydrophobic effect, more hydrophobic residues are closing to each other after the first pair of hydrophobic residues cooperated, and leads more hydrophobic residues to collapse into a hydrophobic core. After the hydrophobic core collapsed, the peptide started to form secondary structures since the residues are now in close proximity. Peptide -&gt; hydrophobic core -&gt; Secondary Structure -&gt; Higher Structure Diffusion collision model: In alpha-helix, the helix was hard to form at the beginning. But once the first hydrogen bond was connected, the peptide was constrained, which leads to the rest of the residues quickly connected because they were closer. Protein starting with form the secondary structure, followed by the tertiary structure Peptide -&gt; Secondary Structure -&gt; Higher Structure Computer Simulation molecular dynamic simulation Simulate the motion of the atom: Simulate the small protein in aquatic solution. Exp： 35 residues: headpiece domain of villin, cytoskeletal protein. Classic model. 6 microseconds. small fold contains 3 helices. started with a standard peptide collapse raptly own itself two out helices formed very quickly middle helix takes a long time to yield the simulation predicted structure is highly constant with experiment result. Protein folding in cell Environment: Cytoplasm is filled with lots of DNA, RNA, lipids, and proteins, etc, sort of things. This big jam may prohibit the folding of the peptide. Aggregates amyloid $\\beta$ Aggregates elimination: chaperones Chaperones: HSP70 Features: ATP-Bound substrate-free With the ATP hydrolysis, the conformation of the HSP70 was changed and the peptide was released. 3 domains: ATPase domain; substrate-binding domain; lipid domain. ATP hydrolysis: Lipid domain comes close to the substrate-binding domain Form a substrate-binding pocket, HSP70 binds the hydrophobic areas of the peptide to prohibit the miss folding introduced by the hydrophobic effect. HSP70: heat shock protein 70 Increases its expression during the increase of heat. Tm increase -&gt; protein denature Expression chaperones protein to prevent aggregates. It also responds to other stress: expression stress (too much expression) HSP60, GroEL: Cage structure to house the protein to fold. Overcome the kinetic trap; thermodynamically favorable aggregates. HSP70 Substance-free©PDB: 4b9q HSP70 Substance-binding©PDB: 2kho Reading Materials: Kerry Geiler, 2010: PROTEIN FOLDING: THE GOOD, THE BAD, AND THE UGLY Libretexts: Introduction and Protein Structure digraph F { rankdir = UD; subgraph A { rank = same; RNAse [label = \"RNAse A\", color = \"#FF0000\" ]; } subgraph B { rank = same; Urea [color = blue ]; ME1 [label = \"b-mercaptoethanol\" color = blue ] } subgraph cluster_1 { rank = same; label = \"Result\"; Result1 [label = \"100 %\", shape=box ; color = \"#FF0000\" ] Result2 [label = \"0 %\", shape=box ; color = \"#FF0000\" ] Result3 [label = \"100 %\", shape=box ; color = \"#FF0000\" ] Result4 [label = \"90 %\", shape=box ; color = \"#FF0000\" ] Result5 [label = \"1 %\", shape=box ; color = \"#FF0000\" ] Result6 [label = \"90 %\", shape=box ; color = \"#FF0000\" ] } subgraph cluster_1 { style=filled; color=lightgrey; node [style=filled,color=white]; label = \"Results\"; } RNAse -> Result1 [label=\"No treatment\"] RNAse -> Mix1 -> Result2 Urea -> Mix1 Urea -> Mix2 Mix2 -> Result3 [label = \"dialysis\"] Urea -> Mix3 ME1 -> Mix3 Mix3 -> Result4 [label = \"1. dialysis\\n2. oxidizing\"] Urea -> Mix4 ME1 -> Mix4 Mix4 -> Result5 [label = \"1. oxidizing \\n 2. dialysis\"] Result5 -> Mix5 -> Result6 ME1 -> Mix5 [label = \"a little\"] } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });digraph F { rankdir = UD; FalsFold [style=filled, label = \"Aggregates Fold\", color = red, shape=box] AFold [style=filled, label = \"Native Fold\", color = red, shape=box] RNA [style=filled, shape = diamond] Ribosome [style=filled, color = deepskyblue1] HSP70 [style=filled, color = deepskyblue1] RNA -> Polymers1 -> FalsFold Ribosome -> Polymers1 RNA -> Polymers2 -> AFold Ribosome -> Polymers2 HSP70 -> Polymers2 } var viz = new Viz(); var code = document.getElementById(\"graphviz-1-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-1\").append(element) });digraph A { rankdir = \"LR\" \"node0\" [ label = \"{ HSP70| ATP}\" shape = \"record\" ]; \"node1\" [ rankdir = \"UD\" label = \"{ HSP70| ADP | Peptide}\" shape = \"record\" ]; subgraph A { rank = same Peptide1 [label = \"Peptide\"] Peptide2 [label = \"Peptide\"] } Peptide1 -> node1:f2 [label=\"ATP hydrolysis\"] node0:f0-> Peptide1 node1:f0-> node0:f0 node1:f2 -> Peptide2 [label = \"Nucleotide exchange\"] } var viz = new Viz(); var code = document.getElementById(\"graphviz-2-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-2\").append(element) }); soft-matter, 2011: Levinthal’s Paradox ↩︎ Wikipedia: Cooperativity ↩︎","link":"/2021/03/26/LearnNotes/edx-biochm-4/"},{"title":"Principles of Biochemistry 5 | Enzyme Catalysis| Class Notes |HarvardX","text":"Enzyme Catalysis © Gerlt J A. 1994 Though the spontaneous reaction could happen automatically, it could run very slow without the help of the catalyzes. Why Enzyme Can Catalysis Transient covalent bonds Activate substrate, lower the activate-energy… Weak non-covalent interaction binding energy: $ \\Delta G_B$ (Figure: Enzymatic Reaction, D), needed energy to decrease the reaction Desolvation: weak interaction between water and substrate is replaced by weak interaction between the substrate and the enzyme. Catalysis is driven by structure and conformational changes. © HarvardX Exp: Beta-galactosidase $\\beta-glycosidic$ bond $\\alpha-glycosidic$ bond $\\beta-galactosidase$ can only hydrolysis the $\\beta-glycosidic$ bond but not $\\alpha-glycosidic$ bond though they are highly similar. Why enzyme Size of the enzyme Compared to the small active site, the enzyme is relatively large. Role of the outside residues: position the active residues in the right position optimizing catalysis by induced fit enzyme regulation: Methylation phosphorylation: tyrosine, serine, and threonine residues. enzyme complexes conformation changes after binding the substrate short peptide: few conformation possibilities. 3-point attachment model Phenomenon: In ethanol, two hydrogen bonds to the Carbon, and both of them are equally expected to be transferred to NADH， but only one of the hydrogen could be transferred. In this model, the enzyme attaches 3 positions of ethanol: methyl group hydroxyl group one specific hydrogen from the methylene group Protein Processing DNA -&gt; mRNA -&gt; Protein -&gt; Post translation modification: Substrate Dependence Allosteric Control Covalent Modification: Phosphorylation Proteolytic: from zymogen and proenzyme to functional protein by proteolytic enzyme digestion. Proteolytic The fate of the protein The different fate of protein translation: Translated freely in the cytoplasm by free ribosomes Transported into organisms once been translated Ribosomes were soon attached to the ER and peptides went to the Golgi transport system to Plasma membrane or lysosomes. Enzyme Chymotrypsin Chymotrypsin: a zymogen a digested enzyme created by the pancreas Started with an inactive form: chymotrypsinogen. work in the Duodenum to digest the food. 245 residues chymotrypsinogen + Trypsin -&gt; 15 residues peptide + 230 residues peptide $\\Pi-Chymotrypsin$: [1:15] S-S [16:245] (disulfide bond) Autolysis: [1:13] S-S [16-146] S-S [149:245] the mature form of chymotrypsin: $\\alpha-Chymotrypsin$ Insert an model: PDBID: Hormone: Insulin Insulin: secreted by the pancreas; regulating the level of blood glucose; Rre-pro-insulin: 110 residues Pro-insulin Folding: intramolecular disulfide bonds link together the N-terminal and the C-terminal Golgi Digested to insulin + C-peptide Secreted insulin: A (N-terminal)+ B (C-terminal) C-Protein: Previously Recognition: It’s for structure support and inactivity by-product. Recent research: involved in many physiological events. opposing with insulin in red blood cells Case 1: Revers Regulation In red blood cell: PDE3 + ATP -&gt; AMP When PED3 is deactivated: ATP is released, enzyme ENOS is working: ENOS + ATP + NO(nitric oxide) -&gt; Vasodilation C-Protein +[binding]+ GPR146 (receptors) -&gt; PKC -&gt; prohibited PDE3 Case 2: Both have inhibitory effects. WBC (White blood cell): release cytokines-&gt; active adhesion molecules of the endothelial cells -&gt; WBC attach to the endothelial cell -&gt; extravasation WBC binds both C-protein and insulin: decreases the release of cytokines: Prevent tissue infiltration to reduce inflammation. Case 3: C-Protein mediates the tuning of insulin signaling. Low insulin levels: C-peptide binds to the membrane receptor Activate G-protein Insulin signaling enhanced High insulin level: C-peptide binds the membrane receptor Activate another G-protein Insulin signaling repressed Conclusion: Protein processing is an important way to regulate protein activity: Stored as precursors to avoid toxicity Quick response to acute change with active precursors. digraph F { rankdir =\"LR\" subgraph A { rank = same node [style=filled, color = green]; DNA mRNA Protein } subgraph cluster_0 { rank = same node [style=filled, font=Courier, color = red, shape = box]; sub1 [label = \"Substrate Dependence\"] sub2 [label = \"Allosteric Control\"] sub3 [label = \"Covalent Modification\"] sub4 [label = \"Proteolytic\", shape = \"\", color = green ] style=filled; color=lightgrey; node [style=filled,color=white]; label = \"Post Translation Modification\"; } DNA -> DNA [label=\"Replication\"] DNA -> mRNA [label = \"Transcription\"] mRNA -> Protein [label = \"Translation\"] Protein -> sub1 Protein -> sub2 Protein -> sub3 Protein -> sub4 } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });digraph F { rankdir =\"LR\" ribosome1 [label=\"Free Ribosome\"] ribosome2 [label =\"ER Ribosome\"] PM [label = \"Plasma Membrane\"] Mitochondrial [label = \"Mitochondrial\"] subgraph A { rank = same Mitochondrial Preoxisome Nuclear Lysosomes Secretory PM } subgraph B { rank = same } ｍRNA -> ribosome1 -> Cytoplasm ribosome1 -> Mitochondrial ribosome1 -> Preoxisome ribosome1 -> Nuclear ｍRNA -> ribosome2 ribosome2 -> ER -> Golgi -> PM ER -> Lysosomes ER -> Secretory } var viz = new Viz(); var code = document.getElementById(\"graphviz-1-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-1\").append(element) });digraph F { node [style=filled, color = green, shape = box]; P1 [label = \"1-245\" ] subgraph cluster_1{ subgraph B{ rank = same P3_1 [label = \"1-13\"] P3_2 [label = \"16-146\"] P3_3 [label = \"149-245\"] } label = \"Autolysis: alpha-Chymotrypsin\" } subgraph cluster_0 { subgraph A{ rank = same P2_1 [label = \"1-15\"] P2_2 [label = \"16-245\"] } P2_1 P2_2 label =\"Trypsin: pi-Chymotrypsin\" } P1 -> P2_1 P1 -> P2_2 P2_1 -> P3_1 P2_2 -> P3_2 P2_2 -> P3_3 P2_1 -> P2_2 [label =\"disulfide\" arrowhead = \"none\", color = \"red\"] P3_1 -> P3_2 [label =\"disulfide\" arrowhead = \"none\", color = \"red\"] P3_2 -> P3_3 [label =\"disulfide\" arrowhead = \"none\", color = \"red\"] } var viz = new Viz(); var code = document.getElementById(\"graphviz-2-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-2\").append(element) });digraph F{ node [shape = box] Pre [label = \"Pre-pro-insulin\"] Pro [label = \"Pro-insulin\"] subgraph A{ rank = \"same\" Pro ProP [label = \"Pro-insulin\"] } ProC [label = \"C-terminal\"] ProN [label = \"N-terminal\"] subgraph B { rank = \"same\" } Pre -> Pro [label=\"remove part of AAs (Signal peptide)\"] Pro -> ProP [label=\"folding\"] ProN -> ProC [ label =\"disulfide\", color = \"red\", arrowhead=\"none\"] ProN->ProP->ProC [arrowhead=\"none\"] subgraph cluster_0{ CP insulin style=filled; color=lightgrey; node [style=filled,color=white]; label = \"Golgi: Final Product\"; } CP [label=\"C-protein\"] Out [label=\"Out Cell\"] ProP -> CP ProC -> insulin ProN -> insulin CP -> Out [label=\"secrete\"] insulin -> Out } var viz = new Viz(); var code = document.getElementById(\"graphviz-3-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-3\").append(element) });digraph F{ rankdir = \"UD\" CP [label = \"C-Protein\", style = \"filled\", color =\"green\"] insulin [style = \"filled\", color =\"red\"] subgraph cluster_0{ subgraph A { rank = same marr0001 PDE3 } \"marr0001\" [shape=diamond,style=filled,label=\"\",height=.1,width=.1] ; \"insulinR\" [label = \"insulin receptor\"] ATP -> marr0001 [dir=none,weight=1] marr0001 -> AMP PDE3 -> marr0001 [label=\"hydrolysis\"] GPR146 -> PDE3 [label =\"Prohibited\"] insulinR -> PDE3 [label =\"Activate\" arrowhead = \"tee\"] label =\"Red Blood Cell\" color = \"pink\" style=filled; } subgraph cluster_1{ subgraph AA{ rank = \"same\" marr0002 marr0003 } \"marr0002\" [shape=diamond,style=filled,label=\"\",height=.1,width=.1] ; \"marr0003\" [shape=diamond,style=filled,label=\"\",height=.1,width=.1] ; ENOS NO -> marr0003 [dir = \"none\"] marr0003 -> Vasodilation label = \"Endothelial Cell\" } CP -> GPR146 insulin -> insulinR ENOS -> marr0002 [arrowhead = \"none\"] ATP -> marr0002 [arrowhead = \"none\"] marr0002 -> marr0003 } var viz = new Viz(); var code = document.getElementById(\"graphviz-4-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-4\").append(element) });digraph F { \"marr0001\" [shape=diamond,style=filled,label=\"\",height=.1,width=.1] ; \"marr0002\" [shape=diamond,style=filled,label=\"\",height=.1,width=.1] ; subgraph A { rank = same insulin marr0001 marr0002 } subgraph B { rank = same CP cytokines } WB [label =\"White Blood Cell\", shape=\"circle\"] CP [label = \"C-Protein\", shape = \"box\", style = \"filled\", color = \"green\"] insulin [shape = \"box\", style = \"filled\", color=\"deeppink1\"] infiltration [shape =\"invhouse\", color = \"cadetblue1\", style = \"filled\"] WB -> marr0002 -> cytokines -> infiltration CP -> marr0001 insulin -> marr0001 marr0001 -> marr0002 [label=\"Prohibit\"] } var viz = new Viz(); var code = document.getElementById(\"graphviz-5-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-5\").append(element) });digraph{ node [shape = \"box\"] Hi [label = \"High insulin level\"] Li [label = \"Low insulin level\"] Is [label = \"insulin signaling\" ] subgraph A { rank = same CP1 [label = \"C-Protine\"] \"marr0001\" [shape=\"point\",style=filled,label=\"\",height=.1,width=.1] ; \"marr0002\" [shape=point,style=filled,label=\"\",height=.1,width=.1] ; } Hi -> marr0001 -> Receptor2 -> GP2 [ color =\"green\"] Li -> marr0002 -> Receptor1 -> GP1 [ color =\"red\"] marr0001 -> CP1 -> marr0002 [dir=none] GP1 -> Is [label=\"active\", color =\"red\"] GP2 -> Is [label=\"prohibit\", color = \"green\"] } var viz = new Viz(); var code = document.getElementById(\"graphviz-6-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-6\").append(element) });","link":"/2021/03/29/LearnNotes/edx-biochm-5/"},{"title":"Principles of Biochemistry 6 |Blood Coagulation| Class Notes |HarvardX","text":"Blood Clot Initiation Von Willebrand factor attaches to the collagen fibers. unfolding of the fiber and expose the bind sites of the vWWF attach the surface of the platelets platelets started to attach the lesion site. Extension consistant the recruitment of addition platelets. It was contributed by the fibrinogen, which has two binding sites for intergins. The release of ADP and thromboxane A2 by activate platelets attached. -&gt; soft plug Stabilization Conversion of fibrinogen into fibrin and the polymerization of the fibrin into a network of fibers. Stabilize anchored by thrombin. Four molecules: collagen Thrombin: initiate ADP/TxA: initiate pyhsical respons platelets shell Fibrinogen The third most abundant protein in blood plasma, consisting of two C-terminal domains. From fibrinogen to fibrin: controlled by the activation of the thrombin. cleave a small portion (18~20) to release 2 binding sites. binding sites could react with other fibrin’s C-terminal turned into a meshwork of fibers. meshwork extended from the base of the platelet plug into the lesion which tenses the platelet plug A positive feedback process © Wayne W. LaMorte; 2016 As shown above, the blood vessel has a few layers. Surrounding the endothelium, cells in the second layer of the vessel are characterized by expression tissue factors that could trigger blood coagulation. The lesion would expose the second layer and release the tissue factors. Two pathway of the coagulation cascade Extrinsic (first) Intrinsic: activated plates. Two pathway of the coagulation cascade Extrinsic VII: coagulation factor VII VIIa: activated coagulation factor VII TF + VII -&gt; TF - VIIa (composite) VIIa: IX -&gt; IXa IXa: X -&gt; Xa Xa + Va + TF Xa + Va + TF: pro-thrombin -&gt; thrombin thrombin: fibrinogen -&gt; fibrin thrombin: Va trhombin -&gt; VIIIa VIIIa: X -&gt; Xa thrombin: XIIIa XIIIa: polymerization Intrinsic path Initiated when some hazer or foreign be recognized. XII -&gt; XIIa XIIa: XI -&gt; XIa like above. Misbehavior of the Intrinsic pathway could cause blood clots to cause disease. The stop of the coagulation Thrombin: control the size of the blood clot. Thrombin + Protein S complexes -&gt; bind to thrombomodulin: form a ternary complex ternary complex -&gt; Protein C Protein C: Inactivation of IX and X to stop the clot. Two additional levels of inhibition: TFPIa binds and inactivates the ternary complexes (TF, VIIa, and Xa) Antithrombin 3 binds irreversibly to thrombin. It also responds to the inactivation of the IX, X, XI, and XII. Thrombus Detection Thrombus © Peter Caravan, Ph.D. Blood clot that forms in the arteries or veins of the body Can cause stroke, coronary artery disease, pulmonary embolism, deep vein thrombosis Affects millions of people and costs billions of dollars worldwide. Developing new imaging tools is essential for diagnosis and monitoring disease progression Fibrin imaging Fibrin is an attractive target for thrombus image only present in blood clots and wound hearling not found in circulating blood High density for disease, no background. Phage Display Phage library filter: incubate the phage with fibrin and collect the phage which bind with it. Phage proliferation: Incubate the phage with E. coli to proliferate them. Improve the affinity: Repeat the phase 1 and 2 over and over again. Characterize those phage Magnetic Resonance Imaging (MRI) Need large magnetic field and radiofrequency energy for detection Magnetic Resonance Imaging (MRI) It is able to detect the Hydrogen molecules and mobile molecules, which are mainly water and fats. Metal is another important resource, Gadolinium ion, especially. © pubchem:24847884 © Penka A Atanassova Label with radioactive isotope Positron Emission Tomography Label with fluorescent dye Fluorescent microscopy Label with EP-2014R: Fibrin-binding peptide coupled to 4 Gadolinium chelates. Binds reversibly and specifically to fibrin Low affinity for fibrinogen, albumin and other components of plasma High relaxivity: makes clots bright. digraph F { rankdir = \"LR\" subgraph cluster_0{ label = \"Human Blood Clot\" Platelets Fibrin Platelets -> Platelets_E Fibrin -> Fibrin_E subgraph A { rank = 1 Fibrin Fibrin_E } subgraph B { rank = 2 Platelets Platelets_E } Platelets_E [shape = box, label= \"form a soft plug\"] Fibrin_E [shape = box, label = \"fibrous protein forms a mesh\"] } } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });digraph F { rankdir = \"LR\" subgraph cluster_1{ node [shape= none] label =\"Three Phases of Blood Coagulation\" Initiation [label = \"1. Initiation\"] Extension [label = \"2. Extension\"] Stabilization [label = \"3. Stabilization\"] Cascade [label = \"Coagulation Cascade\", fontcolor = \"red\"] } subgraph cluster_2 { node [shape = box] In_1 [label = \"Von Willebrand factor (vWF) attaches to the collagen fibers.\"] In_2 [label = \"unfolding of the fiber and expose the bind sites of the vWF\"] In_3 [label = \"attach the surface of the platelets\"] In_4 [label = \"platelets started to attach the lesion site\"] label = \"Initiation\" In_1 -> In_2 -> In_3 -> In_4 subgraph A { rank = same In_4 In_3 In_2 In_1 } } Initiation -> In_1 subgraph cluster_3 { label = \"Extension\" Extension_1 [shape = none, label = \"Consistant the recruitment of addition platelets. It was contributed by the fibrinogen, which has two binding sites for intergins. The release of ADP and thromboxane A2 by activate platelets attached. to form a soft plug\"] } Extension -> Extension_1 subgraph cluster_4 { label = \"Stabilization\" Stabilization_Ex [shape = none, label = \"Conversion of fibrinogen into fibrin and the polymerization of the fibrin into a network of fibers\"] subgraph cluster_4_1{ node [shape =underline] ssub1 [label = \"1. collagen\"] ssub2 [label = \"2. Thrombin: initiate\"] ssub3 [label = \"3. ADP/TxA: \\n initiate pyhsical respons\"] ssub4 [laebl = \"5. Platelets Shell\"] label = \"Four molecules\" fontcolor = \"blue\" } } Stabilization -> ssub1 } var viz = new Viz(); var code = document.getElementById(\"graphviz-1-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-1\").append(element) }); digraph F { \"marr0001\" [shape=diamond,style=filled,label=\"\",height=.1,width=.1] ; \"marr0002\" [shape=diamond,style=filled,label=\"\",height=.1,width=.1] ; \"marr0003\" [shape=diamond,style=filled,label=\"\",height=.1,width=.1] ; \"marr0004\" [shape=diamond,style=filled,label=\"\",height=.1,width=.1] ; \"marr0005\" [shape=diamond,style=filled,label=\"\",height=.1,width=.1] ; \"marr0006\" [shape=diamond,style=filled,label=\"\",height=.1,width=.1] ; \"marr0007\" [shape=diamond,style=filled,label=\"\",height=.1,width=.1] ; \"marr0008\" [shape=diamond,style=filled,label=\"\",height=.1,width=.1] ; \"marr0009\" [shape=diamond,style=filled,label=\"\",height=.1,width=.1] ; TF [label =\"tissue factor\"] TF_VII [label = \"{Xa|Va}|{TF|VII}\" shape = record] Pthrombin [label = \"Pro-thrombin\"] Polymerization [shape = box] TF -> \"marr0001\" VII-> \"marr0001\" -> TF_VII TF_VII:f0 -> marr0002 [style = dotted] IX -> marr0002 [dir = none] marr0002 -> IXa IXa -> marr0003 [style = dotted] marr0003 -> Xa X -> marr0003 [dir = none] Xa -> marr0004 -> TF_VII:f2 Va -> marr0004 -> TF_VII:f3 TF_VII:f3 -> marr0005 [style = dotted] Pthrombin -> marr0005 [dir = none] marr0005 -> thrombin thrombin -> marr0006 [style = dotted] marr0006 -> fibrin fibrinogen -> marr0006 [dir = none] thrombin -> XIIIa [style = dotted] XIIIa -> marr0007 [style = dotted] marr0007 -> Polymerization fibrin -> marr0007 [dir =none] subgraph cluster_0 { label = \"Extrinsic Pathway\" TF VII TF_VII IXa IX X Xa Va Pthrombin thrombin marr0001 marr0002 marr0003 marr0004 marr0005 marr0006 marr0007 fibrin fibrinogen XIIIa Polymerization fibrin } subgraph cluster_i { label = \"Intrinsic Pathway\" XII -> marr0008 -> XIIa XIIa -> marr0009 [style= dotted] XI -> marr0009 [dir = none] marr0009 -> XIa } XIa -> marr0002 [style = dotted] } var viz = new Viz(); var code = document.getElementById(\"graphviz-2-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-2\").append(element) });","link":"/2021/03/31/LearnNotes/edx-biochm-6/"},{"title":"Principles of Biochemistry 8 |Enzyme Design| Class Notes |HarvardX","text":"The enzymes were used in different areas to fit different purposes. But there are so many restrictions before applying them in utility. As a result, enzyme modification is a huge leap for the enzyme industry. Tree enzyme design approaches: Rational Design Using existing structural information of the enzyme, and using a rational approach to replace specific amino acids with others. It is based on the structural information and another ligand for the enzyme. Drawbacks: Full structural information of the enzyme with and without substrate is required. Time-consuming Money Complexity Directed by Evolution Evolution on a very small scale in a controlled environment. White type protein; introducing a variety of mutations; Screen and select the result; back to the first step and mutated it again. Drawbacks: Not all enzymes are amenable to high-throughput screens. Semi-rational Design Iterative Saturation Mutagenesis (ISM) the selected sites are saturated with mutations. saturation mutagenesis is repeated to obtain an optimum variant Saturation Mutagenesis Mutation improves activity or modifies the specificity of enzymes located at, or near, the active site. The mutation improves the stability of the enzyme tend to away from the activity site. Example: lipase A T50: the temperature at which 50% of the enzyme remains properly folded and active after a given time interval. B-factor which could measure the flexibility of amino acid was applied, and the top 10 highest B-factor AA at 8 sites in wild-type structure were selected. Hypothesis: the mutation of these sites could increase the rigidity of the protein and wouldn’t affect the activity of the enzyme. © HarvardX Result: Condition: pre-incubation at $75^ \\circ C$ for $60 min$ Protein Residual Activity WT 0% Variant X 60% Variant XI 90% ISM applications Iterative Saturation Mutagenesis: Crystal structure -&gt; choose AA ‘Smart’ mutant library Assay enzyme activity Repeat Universal Blood Back ground: Universal blood is the blood, which could be used for any of the patients. AB blood type system: the different sugar groups found on glycolipids on the surface of the red blood cell. They have a glycoside hydrolase that cleaves the antigenic trisaccharides found in type A and B red blood cells. Goals: improve the activity of glycoside hydrolase Figure out the crystal structure of the enzyme Generate mutant library by degenerate-code PCR Screen for enzyme activity to cleave fluorescent glyco-substrate. Result: By repeating screen and selection, scientists finally replaced 6 AAs and increased 170-fold of activity compared to the wild type. Halohydrin dehydrogenase manufacture of pharmaceutical compounds. Background: Challenge: The production of the drug is often a mixture of stereoisomers. epoxide group: a common precursor in chemical synthesis which is very active. Normal circumstance: Halohydrin dehydrogenase + R-2-chloro-1-phenylethanol -&gt; pure product. S-2-chloro-1-phenylethanol: remains no change. Solution: Design an enzyme that could tolerate the S form of the substrates. Solving the crystal structure and determine the (7) amino acids in activity sites. Generate mutant enzyme library by degenerate codon PCR High throughput colorimetric screen for enzyme activity. Result: As a result, the combination use of the wild and mutation type enzyme was used to convert both forms of the substrates to the desired product. Diabetes sensors Background: Glucometers: convert glucose into a product and release electrons. Naturally, oxygen would accept electrons and lead to underestimating the level of glucose. Goals: Increasing the accuracy of the Glucometers. Target glucose oxidase amino acid sites were chosen based on functional information. build a mutagenesis lib: alanine 173 &amp; 332 increases both mediator and oxygen activities. phenylalanine 414, increased mediator activity, and decreased oxygen activity. valine 560 dramatically decreased oxygen activity. Muti-site saturation mutagenesis to find optimal oxygen-insensitive enzymes. Result: Variant 7 Wilde Position Mutate Adenine 173 valine Alanine 332 serine Phenylalanine 414 isoleucine Valine 560 threonine Alter the use of the cofactor Target: Increased the by-path method of reaction. The crystal structure was resolved and the residuals near the active site were determined. Site-saturation mutagenesis via PCR with NNK degenerate primers at the 54 positions. High throughput screens identified mutations at 12 sites that boosted NAD(H) usage. The best variant, Q350N was used as the template for ISM for the remaining 11 positions. An additional variant, Q350N/H171A, was discovered with further increased NAD(H) usage.","link":"/2021/04/11/LearnNotes/edx-biochm-8/"},{"title":"Cell Biology: Mitochondria | General","text":"Cell Membrane Phospholipid Bilayer. Dynamic fluid model FRAP: Fluorescence Recovery After Photobleaching © Niklas Lorén, et al. Prokaryotes and Eukaryotes Cells that have internal membranes are called Eukaryotes. © Michael W. Davidson and The Florida State University The layer of the ER is Cisternae. The space between the Cisterna is the lumen. Mitochondria Cardiolipin is an abundant lipid in the inner membrane but not in the outer membrane. The inner membrane is highly impermeable to small ions. Three classes of protein that makeup 76% of mass: critical for catalyzing a subset of reactions necessary for metabolism. transport protein F1F0APTase Matrix: Enzyme for the citric cycle. Moving of the Mitochondria That microtubule ware moves along the microtubule network. Those microtubules were remodeling and dynamically to respond the metabolic change or metabolic stress. As a result, the mitochondria can relocate through this work. The distribution of the mitochondria is diverse and depends on the type of the cell. For example, in neurons, mitochondria are rich in Axon Hillock[1] areas. Endosymbiosis: living together. Mitochondria Disease A cell could have a few or a more different set of mitochondria. As a result, people may look healthy though they carry malfunction mitochondria. Sometimes, the carrier who has enough healthy mitochondria could still cause problems. For example, her infant could be fetal because, during the egg division, one egg may randomly receive more malfunction-mitochondria and leading mitochondria diseases. Observed Evidence: (Threshold of mitochondria mutation) 20~40% of malfunction: you can still generate enough ATP. 50~60% of malfunction: disease presentation. 3-way IVF (3-way in vitro fertilization) Fertilization in a dish. Extract the nucleus from the mother and inject it into a donor egg. In this way, you’ll have three biology parents: sperm from your father. nucleus gene from your mother; mitochondria gene from donor mother. (It was approved in the UK but not in the US) Electronic Transport Chain Why electronic transport. The inner membrane is low-permeable for protons which could help to sustain a high proton gradient. The proton is the key to driving the F1F0APTase to synthesis the ATP by pumping the proton out of the matrix. Without the proton gradient, the ATP could not be generated and the cell would die. General: Complex I, III, and IV: directly pump the proton into the intermembrane space (have both electron carrier and proton pump). Complex II can promote the activity of complex III and IV. (has electron carrier only) They get the energy for pumping by transferring electrons through a series of coupled reactions. This linked process is what we call the electron transport chain. Complex I: NADH deposit two high-energy electrons and passed along Redox Centers. Redox Center: The bottom of the center has high affinity than the top. The adjacent redox center is ideal for electron jump. small energy was released by each jump which would be used to pump protons. The last redox center was passed two electrons to a Coenzyme Q Complex II: Similar to the complex I. High energy was released from FADH2 Electron was delivered into Coenzyme Q through the redox center. Difference: The liberated energy doesn’t use to pump protons. Complex III: The electrons were released from Coenzyme Q one electron was recyclable, the other will pass through two redox centers before reaching cytochrome C cytochrome C carry the electron into Complex IV Complex IV: four electrons convert a molecule of oxygen to two molecules of water. Coenzyme Q is hydrophobic and diffusion inner the bilayer. Cytochrome C is a peripheral protein and is associated with the inner face of the inner face membrane. More details at Biochemistry: Electronic transport Metabolism Term: Electron donor, Electron Acceptor. (O2 is the final electron accepter) Oxidation, Reduction 3 Steps of metabolism Glycolysis Citric Acid Cycle Oxidative Phosphorylation Electron transport The proton pump transported protons from matrix to Intermembrane space which made the Matrix side is basic, the intermembrane side is acidic. F1F0APTase Binding Change Model It is an F-class pump © HavardX When the C-subunit ring is rotating, the $\\gamma$ and $\\epsilon$ unit are rotated with c-subunit. However, the $\\alpha,\\ \\beta,$ and $\\delta$ was not rotating. $\\delta$ subunit is bound to B subunit which is embedded into the inner mitochondria membrane. Binding Change Model Other notes in Biochemistry Open state, Loss state, Tight state Conformation switches with the rotating of the $\\gamma$ subunit. or initial segment. This is the region where the plasma membrane generates nerve impulses; the axon conducts these impulses away from the soma or dendrites toward other neurons. Britannica ↩︎","link":"/2021/08/17/LearnNotes/edx-cellbio-1/"},{"title":"Python for Data Science","text":"Python for Data Science Insight: Data + Analysis &amp; Question -&gt; Insight build model, solving problems Exp: Amazon recommendation new books to customers by their reading records Prediction: take actions by the weather forecast. Why data science arise recently: big Data High performance of circulates Megabytes -&gt; Gigabytes -&gt; Terabytes -&gt; Petabytes -&gt; Exabytes -&gt; Zettabyte Week 1 Why is python Easy-to-read and learn Vibrant community Growing and evolving set of libraries Data management Analytical processing Visualization Applicable to each step in the data science process Notebooks Exp 1, Soccer Data Analysis: Feature Selection Five steps of Data processing: Acquire: Import raw data into your platform Prepare: Explore &amp; Visualization Analysis: Feature Selection Model Analyze the results report: Resent your findings Act: Use then Acquire Database Text File Online data Data Cleaning - Relational- Non-relational - Twitter- Sensor - Missing- Garbage- NULLs Data Visualization: Catch your attention and convey your message in a minimal time Prepare Exploring DataVisualizationPre-processingGetting data in shape correlation; general trends, Outliers Statistic heatmap: Distribution; Histogram: trends; boxplot: trends Line Graphs: Time serial; Scatter plots: Correlation; Clean &amp; Transform remove; merge; estimate remove outliers scaling: (normalization) aggregation feature selection Dimension reduction Data Manipulation Analyze Data Classification: Predict category Regression: Predict numeric value Clustering: Organize similar items or groups (Target marketing) Graph Analytics: find connections between entities (social networks) Association Analysis: capture associations between items (Customers’ purchase behavior) Select technique -&gt; Build model -&gt; validate model Evaluation of Results Predicted vs Correct Reporting What to present: Main results; Value; Model leading to Act Visualization tools: R; Python; JS: D3; Developers; Tableau; Timeline Action Turning Insight into Action Week2 Python is dynamic typing: Object means it could easily turn int to float.","link":"/2020/12/28/LearnNotes/edx_python_data/"},{"title":"Principles of Biochemistry 9 |Lipids Structure And Membrane Assembly| Class Notes |HarvardX","text":"Lipid Acid Fatty Acid Structure: Carboxyl head + Hydrocarbon tail. © pubchem; ID:5281 The length of the tail is variable The tail could be saturated or unsaturated (C=C double bond) Interacted with each other through **Van der Waals interaction. With a longer tail and more unsaturated bond, the fatty acid has more interactions and could pack together more tightly like animal fat. Most of them have an even number of the carbon Incorporated into lipids The tail of the fatty acid could link with different molecules to form different linkages. ester linkages The hydroxyl group in glycerol reacts with carboxyl group in fatty acid to form ester linkages. Phosphodiester linkage Phosphate group with hydroxyl group on glycerol or Sphingosine amide bond Carboxyl group links to the amino group of a Sphingosine forming an amide bond © pubchem; ID:70698413 © pubchem; ID:52929749 © pubchem; ID:6437496 Triacylglycerol Three fatty acids form 3 ester linkages with glycerol. The 3 fatty acids could be either identical or mixed. © pubchem; ID:11146 © pubchem; ID:131762421 Structural Lipids Two major structural lipids: glycerophospholipids (phosphoglycerides) glycerol backbone Phosphodiseter linkage that connects the third carbon to a variable Glycerol C1: Saturated fatty acid (C-16 ~ C-18) Glycerol C2: Unsaturated fatty acid (C-18 ~ C-20) Glycerol C3: Phosphate group which connected a hydrophilic head. The simplest head is the phosphate group connected with hydrogen, which is phosphatidic acid sphingolipids A molecule of sphingosine forms the backbone Both sphingosine and fatty acid groups are hydrophobic The variable group determined the function of the molecule Both the variable group and the fatty acid tails affect the function of the molecule. © pubchem; ID:192817 © pubchem; ID:319423558 The shape of fatty acids Illustration of the Cylindrical Shape and Conical Shape © Bruno Maggio Some structural lipids, such as phosphatidylcholine have a cylindrical shape, while other lipids, like phosphatidylethanolamine, have a conical shape, because they have a relatively small head group, and carry unsaturated fatty acids. As a result, placing more conical shape molecules in the inner layer helps the structure of the membrane more tightly. Cholesterol © pubchem; ID:5997 Cholesterol has four hydrocarbon rings and is very hydrophobic. It can interact with other structural lipids in the membrane. It limits lipids’ mobility and affects membrane fluidity. There are more than 1000 types of lipids we can find in an organism. And About 5% of the genes in a cell are for synthesizing lipids. Energy production of lipids Triacylglycerol Most Triacylglycerols are stored in a kind of cell named Adipocyte (Fat cell) in adipose tissue. With the adipocyte, the triacylglycerol was stored as very large lipid droplets which even against the membrane of the adipocyte. Immature adipocyte tissue: brown, large lipid droplets. Mature liver adipocytes: small and numerous lipid droplets. The DIFFERENT between Glycogen and triacylglycerol: The carbon in fatty acids is more reduced. As a result, one gram of the fatty acid has twice the energy as 2 gram glycogen after being completely oxidized. Hydrophobicity: The fatty acid was stored much tenser than the glycogen. The glycogen has 2/3 of the mass of water. Glycogen is a polymer of glucose units. Glycogen moves faster than triacylglycerol. On the other hand, triacylglycerol also contributed to the benefit of insulation and padding. Lipid Transportation Challenge 1: Hydrophobic Lipid droplets are surrounded by a monolayer of phospholipids with hydrophilic group heads outside. lipid-protein: perilipin, which could form a layer on the outer surface of the lipid droplets. Challenge 2: Coordination Triacylglycerol degradation (Lipolysis): tri -&gt; di: ATGL (Adipose triglyceride lipase); di -&gt;Mono: HSL (Hormone-sensitive lipase); Mono-&gt;two: MGL (Monoacylglycerol lipase); How are these enzymes activated? ATGH needs ABHD5 to be recruited at the surface of the lipid droplets. HSL and FABP4 complex in free cytoplasm could not be recruited. Active: Hormones such as adrenaline and noradrenaline from the catecholamine family. When are they activated? Catecholamine (Receptor) -&gt; trimeric G protein. trimeric G protein -&gt; adenylyl cyclase adenylyl -&gt; ATP -&gt; cyclic AMP Cyclic AMP -&gt; PKA PKA -(phosphate)-&gt; perilipin and HSL Perilipin-P active ABHD5 to recruit ATGL remodeling the surface of the droplets, increasing the access of the enzyme HSL-P: It could be recruited by the surface of the droplets. Challenge 3: Release of fatty acid Free fatty acid + FABP4 (chaperone): through the cytoplasm. FA is exposed to the bloodstream and associated with serum albumin to travel into the tissue in need. Glycerol was exposed in the cytoplasm and went through the cytomembrane through aquaporin, a channel protein. And then, they were transported into the liver through the bloodstream. (No chaperone, it’s hydrophilic) digraph F { node [style=filled,color=white, shape =box]; rankdir =\"UD\" subgraph cluster_0{ Fatty [label =\"Fatyy Acid\"] Fatty Glycerol Sphingosine style=filled; color=deeppink; label = \"Three Main Lipid Acids\"; } } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });digraph F { node [style=filled,color=white, shape =box]; rankdir =\"UD\" subgraph cluster_0{ subgraph A { rank = \"same\"; Catecholamine GP AD } Catecholamine GP [label =\"trimeric G protein\"] AD [label =\"adenylyl cyclase\"] style=filled; color= darkorange; label = \"Cell Membrane\"; } subgraph cluster_1{ ABAT [ label = \" ABHD5 | ATGL\" shape = \"record\" ]; perilipin marr0002 [ label = \" HSL | FABP4\" shape = \"record\" ] ; LD [label = \"lipid droplet\", shape = plain] style=filled; color=deepskyblue3; label = \"Surface of lipid droplet\"; } subgraph B { rank = \"same\"; marr0001 [ shape=diamond,style=filled,label=\"\",height=.1,width=.1] ; ATP cAMP [label =\"cyclic AMP\"] } subgraph C { rank = \"same\"; ABHD5 PKA ATGL } Catecholamine -> GP [label = \"active\"] GP -> AD [label = \"active\"] AD -> marr0001 [label = \"catalytic\"] ATP -> marr0001 [dir =none] marr0001 -> cAMP cAMP -> PKA [label = \"active\"] PKA -> perilipin [label = \"phosphate\"] PKA -> HSL [label = \"activate\"] perilipin -> ABHD5 [label = \"activate\"] perilipin -> LD [label = \"remodeling the surface of the droplets\"] ABHD5 -> ATGL [label = \"recruit\"] HSL -> marr0002 [dir = none] FABP4 -> marr0002 [dir = none] marr0002 -> LD ATGL -> ABAT:f0 -> LD } var viz = new Viz(); var code = document.getElementById(\"graphviz-1-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-1\").append(element) });","link":"/2021/04/13/LearnNotes/edx-biochm-9/"},{"title":"Principles of Biochemistry 7 |Enzyme Kinetics| Class Notes |HarvardX","text":"Reaction Velocity $\\beta-galactoside + H_ 2O \\xrightarrow{\\beta-galactosidase} Galactose + R-Group$ With the concentration of the reactants and product, we define the velocity of the reaction. The velocity of the reaction is either: the amount of product that is formed per unit of time the amount of substrate that is consumed per unit of time. Measure the velocity of beta-galactosidase $\\beta-galactosidase$ could convert the ONPG, a colorless compound, to Galactose and ONP, which is a yellow compound. It could be measured by the spectrophotometer. // 基于准备好的dom，初始化echarts实例 var myChart = echarts.init(document.getElementById('echarts5337')); // 指定图表的配置项和数据 var option = option = { xAxis: { type: 'category', name: 'Time', nameLocation: \"middle\", nameTextStyle: {fontSize: 25, padding: [10, 0, 0, 0] , }, data: [0,1,2,3,4,5,6,7,] }, yAxis: { type: 'value', name: \"Velacity (T)\", max: 330 , nameLocation: \"middle\", nameTextStyle: {fontSize: 25, padding: [0, 0, 10, 0] , }, }, legend: { data: ['Measured Velocity', \"Expected Velocity\", \"Initial Velocity\"] }, series: [{ name: 'Measured Velocity', smooth: true, data: [0, 150, 230, 270, 285, 290, 295, 297], type: 'line', }, { name: \"Expected Velocity\", data: [, 150, 260], type: 'line' }, { name: \"Initial Velocity\", data: [0 , 200], type: 'line', smooth:false, itemStyle:{ normal:{ lineStyle:{ width:2, type:'dotted' //'dotted'虚线 'solid'实线 } } }, }] }; // 使用刚指定的配置项和数据显示图表。 myChart.setOption(option); $$ V = \\frac{d[P]}{dt} $$ As we can see in the chart above, the velocity is changing over time since the substrate gets depleted. But the first part of the reaction is almost linear which give us the way to define the velocity of the enzyme (Initial velocity) Vmas: When the concentration of the enzyme was maintained, with the increase of the substrate’s concentration, the enzyme became the restriction factor. And so, it would not change its initial velocity and reach its max which is the feature of all enzymes. Kinetic Model // 基于准备好的dom，初始化echarts实例 var myChart = echarts.init(document.getElementById('echarts8403')); // 指定图表的配置项和数据 var option = option = { xAxis: { type: 'category', name: 'Concentration of the Substrate (S)', nameLocation: \"middle\", nameTextStyle: {fontSize: 25, padding: [10, 0, 0, 0] , }, data: [0,1,2,3,4,5,6,7,] }, yAxis: { type: 'value', name: \"Velacity (V0)\", max: 330 , nameLocation: \"middle\", nameTextStyle: {fontSize: 25, padding: [0, 0, 10, 0] , }, }, legend: { data: ['Measured Velocity', \"Expected Velocity\", \"Initial Velocity\"] }, graphic: [ { type: 'group', left: '20%', top: '10%', children: [ { type: 'text', z: 100, style: { text: 'Vmax', font: '20px Microsoft YaHei', } } ] }, { type: 'group', left: '20%', top: '45%', children: [ { type: 'text', z: 100, style: { text: '1/2 Vmax', font: '20px Microsoft YaHei', } } ] }, { type: 'group', left: '20%', top: '80%', children: [ { type: 'text', z: 100, style: { text: 'Km', font: '20px Microsoft YaHei', } } ] } ], series: [{ name: 'Measured Velocity', smooth: true, data: [0, 150, 230, 270, 285, 290, 295, 297], type: 'line', markLine: { data: [ {yAxis:320}, {yAxis:160}, {xAxis:1}, ] }, }, { name: \"Expected Velocity\", data: [, 150, 260], type: 'line' }, { name: \"Initial Velocity\", data: [0 , 200], type: 'line', smooth:false, itemStyle:{ normal:{ lineStyle:{ width:2, type:'dotted' //'dotted'虚线 'solid'实线 } } }, }] }; // 使用刚指定的配置项和数据显示图表。 myChart.setOption(option); $$ E + S \\underset{k_ {-1}}{\\overset{k_ 1}{\\rightleftharpoons } } ES \\underset{k_ {-2}}{\\overset{k_ 2}{\\rightleftharpoons } } P + E $$ E: Enzyme S: Substrate P: Product Since the concentration of the products was really low, the reverse reaction of $P + E \\to ES$ is ignoble. The Km was contributed by k1, k-1, and k2. Formation of ES: $V_ 1 = k_ 1[E][S]$ Degradation of ES: $V_ 2 = k_ {-1}[ES]+ k_ 2[ES]$ $\\ \\ \\ \\ \\ = [ES](k_ {-1} + k_ 2)$ Steady state: $V_ 1 = V_ 2$ $k_ 1[E][S]=[ES](k_ {-1} + k_ 2)$ Michaelis and Menten constant $$ \\frac{[E][S]}{[ES]} = \\frac{k_ {-1} + K_ 2}{k_ 1} = K_ m $$ When the $[ES]$ is the rate-limited step: High $K_ m$: low substrate affinity Low $K_ m$: high substrate affinity To calculate the free enzyme: $[E_ T] = [E] + [ES]$ $[E] = [E_ T] - [ES]$ $K_ m = \\frac{[E][S]}{[ES]}$ $\\ \\ \\ \\ \\ \\ = \\frac{([E_ T]- [ES]) [S] }{ [ES]}$ $\\ \\ \\ \\ \\ \\ =(\\frac{[E_ T]}{ES} -1)[S ]$ When the overdose of the substrate, all enzymes are combined with the substrate. As a result, we can have: $V_ 0 =k_ 2 [ES]$ $V_ {max} = k_ 2 [E_ T]$ $\\frac{V_ {max}}{V_ 0} = \\frac{K_ 2 [E_ t]}{K_ 2 [ES]} = \\frac{[E_ T]}{[ES]}$ Under these circumstance ($[E_ T] = [ES]$), we can have: $K_ m = (\\frac{V_ {max}}{V_ 0} -1)[S]$ $V_ 0 = \\frac{V_ {max}[S]}{K_ m + [S]}$ At the beginning of the chart above, the velocity of the Substrates is very low, too low to ignoble. Under these conditions, we can have: $V_ 0 = \\frac{V_ {max}[S]}{K_ m}$ When we have a very high concentration of Substrates, the $V_ 0$ is really high and theoretically equals the $V_ {max}$. As a result, we can have: $V_ 0 = \\frac{V_ {max}[S]}{[S]}= V_ {max}$ When the Concentration of the Substrate is equal to $K_ m$: $V_ 0 = \\frac{V_ {max}[S]}{K_ m + [S]}$ $V_ 0 = \\frac{V_ {max}[S]}{2[S]} = \\frac{V_ {max}}{2}$ Linearly the Michaelis and Menten equation $V_ 0 = \\frac{V_ {max}[S]}{K_ m + [S]}$ $\\frac{1}{V_ 0} = \\frac{K_m + [S]}{V_ {max}[S]}$ $\\frac{1}{V_ 0} = \\frac{K_m}{V_ {max}[S]} + \\frac{[S] }{V_ {max}[S]}$ Then, we have Lineweaver-Burk: $\\frac{1}{V_ 0} = (\\frac{K_m}{V_ {max}})(\\frac{1}{[S]}) + \\frac{1}{V_ {max}}$ $ y = mx+b$ $m$: $\\frac{k_ m}{V_ {max}}$ $b$: $\\frac{1}{V_ {max}}$ // 基于准备好的dom，初始化echarts实例 var myChart = echarts.init(document.getElementById('echarts4725')); // 指定图表的配置项和数据 var option = option = { xAxis: { type: 'category', name: 'Concentration of the Substrate (S)', nameLocation: \"middle\", nameTextStyle: {fontSize: 25, padding: [10, 0, 0, 0] , }, data: [-1,0,1,2,3,4,5,6,7,] }, yAxis: { type: 'value', name: \"Velacity (V0)\", max: 330 , nameLocation: \"middle\", nameTextStyle: {fontSize: 25, padding: [0, 0, 10, 0] , }, }, legend: { data: ['Measured Velocity', \"Expected Velocity\", \"Initial Velocity\"] }, graphic: [ { type: 'group', left: '20%', top: '10%', children: [ { type: 'text', z: 100, style: { text: '1 / V0', font: '20px Microsoft YaHei', } } ] }, { type: 'group', left: '20%', top: '75%', children: [ { type: 'text', z: 100, style: { text: '1 / Vmax', font: '20px Microsoft YaHei', } } ] }, { type: 'group', left: '70%', top: '80%', children: [ { type: 'text', z: 100, style: { text: '1 / [S]', font: '20px Microsoft YaHei', } } ] }, { type: 'group', left: '10%', top: '80%', children: [ { type: 'text', z: 100, style: { text: '-1 / Km', font: '20px Microsoft YaHei', } } ] }, { type: 'group', left: '30%', top: '60%', children: [ { type: 'text', z: 100, style: { text: 'Slope = Km / Vmax', font: '20px Microsoft YaHei', } } ] } ], series: [{ name: 'Measured Velocity', data: [0, 50,100, 150, 200, 250,300, 350, 400], type: 'line', markLine: { data: [ {xAxis:1, }, ] }, }, ] }; // 使用刚指定的配置项和数据显示图表。 myChart.setOption(option); As you can see, when: $0 = [S]$ Then: $0 = (\\frac{K_m}{V_ {max}})(\\frac{1}{[S]})$ $\\frac{1}{V_ 0} = \\frac{1}{V_ {max}}$ When in the intercept with X axis: $\\frac{1}{V_ 0} = (\\frac{K_ m}{V_ {max}})(\\frac{1}{[S]}) + \\frac{1}{V_ {max}}$ $0 = (\\frac{K_ m}{V_ {max}})(\\frac{1}{[S]}) + \\frac{1}{V_ {max}}$ $\\frac{K_ m}{V_ {max}[S]} = \\frac{-1}{V_ {max}}$ $\\frac{K_ m}{[S]} = -1$ $\\frac{1}{[S]} = \\frac{-1}{K_ m}$ Inhibitors PDF slide: HarvardX Competitive Inhibitor Bind to the active site of the enzyme to prohibit the reaction [ES] [EI] was formed and so we can make a prediction With the adding of the inhibitor, the affinity of the enzyme to the substrate was decreased, which suggest a $K_ m$ was increased. When substrate is higher, the $V_ {max}$ remain unchanged. Because the concentration of the inhibitor is constant, the substrate will out-compete the inhibitor. There for, the enzyme will reach the max velocity. Similarly, we can have the function: $$ EI \\underset{k’_ {1}}{\\overset{k’_ {-1}}{\\rightleftharpoons } } E + S \\underset{k_ {-1}}{\\overset{k_ 1}{\\rightleftharpoons } } ES \\underset{k_ {-2}}{\\overset{k_ 2}{\\rightleftharpoons } } P + E $$ $ \\frac{[E][I]}{[EI]} = \\frac{k’_ {-1}}{k’_ 1} = K_ I$ $ \\frac{K_ m}{K_ I} = \\frac{[E][S]}{[ES]} \\times \\frac{[EI]}{[E][I]}$ $ \\frac{K_ m}{K_ I}(\\frac{[I]}{[S]})= \\frac{[EI]}{[ES]} $ $ \\because [E_ T] = [E] + [ES] + [EI]$ $ \\therefore \\frac{K_ m}{K_ I}(\\frac{[I]}{[S]})= \\frac{[E_ T] - [ES] - [E]}{[ES]} $ $ \\therefore \\frac{K_ m}{K_ I}(\\frac{[I]}{[S]})= \\frac{[E_ T]}{[ES]} - 1 - \\frac{[E_]}{[ES]} $ $ \\because V_ 0 = k2[ES]; V_ max= K_ 2 [E_ T]$ $ \\therefore \\frac{V_ {max}}{V_ 0} = \\frac{[E_ T]}{[ES]}$ $ \\because K_ m = \\frac{[E][S]}{[ES]}$ $ \\therefore \\frac{K_ m}{[S]} = \\frac{[E]}{[ES]}$ $ \\therefore \\frac{K_ m}{K_ I}(\\frac{[I]}{[S]})= \\frac{V_ max}{V_ 0} - 1 - \\frac{K_ m}{[S]}$ Now, we can have the special points on chart: $\\frac{V_ {max}}{V_ 0} = 1 + \\frac{K_ m }{[S]} + \\frac{K_ m}{K_ I}(\\frac{[I]}{[S]})$ $\\frac{V_ {max}}{V_ 0} = K_ m (1+\\frac{[I]}{K_ I})\\frac{1}{[S]} + 1$ $\\frac{1}{V_ 0} = \\frac{K_ m}{V_ {max}} (1+\\frac{[I]}{K_ I})\\frac{1}{[S]} + \\frac{1}{V_ {max}}$ So, Compared the function which has no inhibitor, the Lineweaver-Burk equation: $\\frac{1}{V_ 0} = (\\frac{K_m}{V_ {max}})(\\frac{1}{[S]}) + \\frac{1}{V_ {max}}$ We can find that they are similar. // 基于准备好的dom，初始化echarts实例 var myChart = echarts.init(document.getElementById('echarts5238')); // 指定图表的配置项和数据 var option = option = { xAxis: { type: 'category', name: '1/S', nameLocation: \"middle\", nameTextStyle: {fontSize: 25, padding: [10, 0, 0, 0] , }, data: [-2,-1,0,1,2,3,4,5,6,7,] }, yAxis: { type: 'value', name: \"1/V0\", max: 330 , nameLocation: \"middle\", nameTextStyle: {fontSize: 25, padding: [0, 0, 10, 0] , }, }, legend: { data: ['With inhibitor', \"No inhibitor\"] }, graphic: [ { type: 'group', left: '20%', top: '10%', children: [ { type: 'text', z: 100, style: { text: '1 / V0', font: '20px Microsoft YaHei', } } ] }, { type: 'group', left: '70%', top: '10%', children: [ { type: 'text', z: 100, style: { text: 'Inhibited', font: '20px Microsoft YaHei', } } ] }, { type: 'group', left: '20%', top: '90%', children: [ { type: 'text', z: 100, style: { text: '1/K m, app', font: '20px Microsoft YaHei', } } ] }, { type: 'group', left: '75%', top: '35%', children: [ { type: 'text', z: 100, style: { text: 'Uninhibited', font: '20px Microsoft YaHei', } } ] }, { type: 'group', left: '20%', top: '75%', children: [ { type: 'text', z: 100, style: { text: '1 / Vmax', font: '20px Microsoft YaHei', } } ] }, { type: 'group', left: '70%', top: '80%', children: [ { type: 'text', z: 100, style: { text: '1 / [S]', font: '20px Microsoft YaHei', } } ] }, { type: 'group', left: '10%', top: '80%', children: [ { type: 'text', z: 100, style: { text: '-1 / Km', font: '20px Microsoft YaHei', } } ] }, { type: 'group', left: '30%', top: '60%', children: [ { type: 'text', z: 100, style: { text: 'Slope = Km / Vmax', font: '20px Microsoft YaHei', } } ] } ], series: [{ name: 'With inhibitor', data: [,0, 50,100, 150, 200, 250,300, 350, 400], type: 'line', markLine: { data: [ {xAxis:2, }, ] }, }, { name: 'No inhibitor', data: [0, 25,50, 75,100, 125, 150, 175,200, 225, 250], type: 'line', }, ] }; // 使用刚指定的配置项和数据显示图表。 myChart.setOption(option); Let’s say: $\\alpha = 1+\\frac{[I]}{K_ I}$ $\\therefore \\frac{1}{V_ 0} = \\frac{\\alpha K_ m}{V_ {max}} \\frac{1}{[S]} + \\frac{1}{V_ {max}}$ Compared to the linear equationL $y = mx + b$ the slope $m = \\frac{\\alpha K_ m}{V_ {max}}$ $\\alpha K_ m = K_ {m, app}$ $K_ {m, app} &gt; K_ m $ $K_ {m, app}$, apparent $K_ m$ Uncompetitive Inhibitor They bind the enzyme only if they enzyme associated with substrate. $E + S \\rightleftharpoons ES +I \\rightleftharpoons ESI $ $ E + S \\underset{k_ {-1}}{\\overset{k_ 1}{\\rightleftharpoons } } ES \\underset{k_ {-2}}{\\overset{k_ 2}{\\rightleftharpoons } } P + E$ $ESI \\underset{k’_ {1}}{\\overset{k’_ {-1}}{\\rightleftharpoons } } ES + I$ In this situation, with the increased of the $[S]$, the $[ES]$ and $[P]$ was increased. But the $[ESI]$ was increased, too. As a result, some of the enzyme will be trapped into a nonproductive complex and the $V_ {max}$ would be reduced. $\\frac{1}{V_ 0} = \\frac{K_ m }{V_ {max}}\\frac{1}{[S]} + \\frac{\\alpha’}{V_ {max}}$ $\\alpha’ = 1 + \\frac{[I]}{K;_ I}$ As a result, the slope of the Uncompetitive inhibition function and the noninhibitor function are is the same Mixed Inhibitor The inhibitor which can bind the activity site of the enzyme and the enzyme substrate complex to inhibitor the productivity. $EI \\underset{k’_ {1}}{\\overset{k’_ {-1}}{\\rightleftharpoons } } E + S \\underset{k_ {-1}}{\\overset{k_ 1}{\\rightleftharpoons } } ES \\underset{k_ {-2}}{\\overset{k_ 2}{\\rightleftharpoons } } P + E$ $S + EI \\underset{k’‘_ {1}}{\\overset{k’‘_ {-1}}{\\rightleftharpoons } } ESI \\underset{k’_ {1}}{\\overset{k’_ {-1}}{\\rightleftharpoons } } ES + I$ In this case, $K_ m$ could increase, decrease, or stay the same which depend on the relative rate of the formation of the enzyme-inhibitor complex and the formation of the ESI complex. In Lineweaver-Burk linear function: $\\frac{1}{V_ 0} = \\frac{\\alpha K_ m}{V_ {max}}\\frac{1}{[S]} + \\frac{\\alpha’}{V_max}$ $\\alpha = 1 + \\frac{[I]}{K_ I}$; Effect of EI formation $\\alpha’ = 1 + \\frac{[I]}{K’_ I}$; Effect of ESI formation Case 1: Inhibitor facors $E$ over $ES$: $ K_ I$ dominates over $K’ _ I$ $\\therefore K_ m$ increases $K_ {m, app} = \\frac{\\alpha K_ m}{\\alpha’}$ Noncompetitive Inhibitor: $\\alpha = \\alpha’$ $K_ {m, app} = \\frac{\\alpha K_ m}{\\alpha’}$ $K_ {m, app} = K_ m$ y-intercept-1 x-intercept-1 Inhibitor $V_ {max, app}$ $K_ {m, app}$ Absent $V_ {max}$ $K_ m$ Competitive $V_ {max}$ $\\alpha K_ m$ Uncompetitive $\\frac {V_ {max}}{\\alpha’}$ $\\frac{K_ m}{\\alpha’}$ Mixed $\\frac{V_ {max}}{\\alpha’}$ $\\frac{\\alpha K_ m }{\\alpha’}$","link":"/2021/04/02/LearnNotes/edx-biochm-7/"},{"title":"Understanding False Discovery Rate (FDR) and the Benjamini-Hochberg Method","text":"Understanding False Discovery Rate (FDR) and the Benjamini-Hochberg Method Warning This Passages is completely composed by ChatGPT4 In the realm of statistical analysis, particularly in fields inundated with vast datasets like genomics, neuroscience, and social sciences, the concept of False Discovery Rate (FDR) has become pivotal. This post delves into the essence of FDR, its significance in multiple hypothesis testing, and the widely adopted Benjamini-Hochberg (BH) method for FDR control. What is False Discovery Rate (FDR)? False Discovery Rate is a statistical measure used in multiple hypothesis testing to identify the proportion of false positives (incorrectly rejected null hypotheses) among all rejected hypotheses. In simpler terms, it represents the expected ratio of erroneous discoveries to the total number of discoveries. Importance of FDR: Multiple Comparisons Problem: When testing multiple hypotheses simultaneously, the likelihood of encountering false positives increases. Balancing Sensitivity and Specificity: FDR provides a balanced approach, controlling the rate of false discoveries while maintaining the ability to detect true effects. The Benjamini-Hochberg (BH) Method: Developed by Yoav Benjamini and Yosef Hochberg in 1995, the BH method is a practical approach to controlling the FDR in multiple testing scenarios. How the BH Method Works: Rank P-values: Arrange the p-values from individual hypothesis tests in ascending order. Calculate Adjusted P-values: Compute adjusted p-values using the formula: $$ \\text{Adjusted p-value} = \\min\\left(\\frac{\\text{Original p-value} \\times N}{\\text{Rank}}, 1\\right) $$ Here, $N$ is the total number of tests, and ‘Rank’ is the position of the original p-value in the ordered list. Interpretation: Compare these adjusted p-values with a pre-defined FDR threshold (e.g., 0.05). Tests with adjusted p-values below this threshold are deemed statistically significant. Advantages of the BH Method: Less Conservative: Unlike methods that control the family-wise error rate (FWER), the BH method is less stringent, leading to greater statistical power in detecting true effects. Adaptability: Works well across various disciplines where multiple hypothesis testing is common. Limitations: Assumption of Independence: The method assumes that tests are independent or positively dependent. Its effectiveness may diminish if this assumption is violated. FDR, Not FWER: It controls the rate of false discoveries, not the probability of making any Type I error. Application in R: In R, the p.adjust function is used for FDR adjustment, specifically with the “BH” method. This function modifies the original p-values from your tests, providing adjusted values that can be compared to your FDR threshold. p_values &lt;- c(0.01, 0.04, 0.03, 0.05, 0.20)adjusted_p_values &lt;- p.adjust(p_values, method = &quot;BH&quot;)print(adjusted_p_values) Other Adjustment Methods Here’s a comparison of various p-value adjustment methods in a tabular format: Method Description Advantages Limitations Suitable Data Bonferroni Correction Divides alpha level by the number of tests. Simple, very conservative, controls FWER. Too conservative, higher Type II error risk. Small number of hypotheses. Benjamini-Yekutieli (BY) Generalization of BH, works under any dependency. Controls FDR under any dependency structure. More conservative than BH. Tests with unknown dependencies. Holm-Bonferroni Sequentially compares p-values to adjusted alpha. Less conservative than Bonferroni, controls FWER. Still quite conservative with many tests. Moderately sized numbers of hypotheses. Šidák Correction Similar to Bonferroni, assumes independence. Less conservative than Bonferroni for independent tests. Assumes independence among tests. Independent hypotheses. False Discovery Rate (FDR) - BH Method Controls the expected proportion of false discoveries. Less conservative than FWER methods, more power. May not control FWER, assumes some test independence. Large-scale testing like genomics. This table provides an overview of the key features, advantages, limitations, and suitable applications for each method. The choice of method depends on the balance between the risk of false positives and the need for statistical power, as well as the nature and scale of the data being analyzed. Other than FDR Besides False Discovery Rate (FDR) methods like the Benjamini-Hochberg procedure, there are several other methods for adjusting p-values in the context of multiple hypothesis testing. These methods primarily aim to control different types of error rates. Here are some of the key methods: Family-Wise Error Rate (FWER) Methods: Bonferroni Correction: The simplest and most conservative method, which multiplies each p-value by the number of tests (or compares each p-value against the significance level divided by the number of tests). Holm-Bonferroni Method: A stepwise adjustment method that sequentially adjusts p-values in ascending order, slightly less conservative than the Bonferroni correction. Šidák Correction: Similar to Bonferroni but slightly less conservative, assuming that all tests are independent. Hochberg’s Method: Another step-up procedure that is less conservative than the Holm-Bonferroni method. Permutation Tests: Permutation-Based Adjustments: These involve recalculating p-values by comparing observed test statistics to their distribution under permutations of the data. This approach is particularly useful for complex or non-standard data structures. Bayesian Methods: Bayesian Adjustments: These involve using Bayesian statistics to adjust p-values, which can incorporate prior information and provide a different perspective on significance. False Coverage Rate (FCR) Procedures: Benjamini-Hochberg-Yekutieli Procedure: An extension of the BH procedure that controls the FCR, the expected proportion of incorrect coverage statements among all coverage statements made. Local False Discovery Rate (LFDR): LFDR Adjustments: Focuses on the probability that a particular null hypothesis is true given the observed p-value, providing a local (individual) measure of significance. Each of these methods has its strengths and weaknesses, and the choice of method depends on the specific goals of the analysis, the nature of the data, and the type of error control desired. For example, FWER methods are typically used when it’s crucial to minimize the chance of any false positives, while FDR methods are more appropriate when dealing with large numbers of tests and when some false positives can be tolerated to gain higher statistical power. Conclusion In conclusion, the landscape of statistical analysis, particularly in the context of multiple hypothesis testing, has been significantly enriched and diversified through various p-value adjustment methods. Among these, the Benjamini-Hochberg (BH) method stands out as a revolutionary approach. It offers a balanced and less conservative alternative for statistical inference, adeptly addressing the challenges posed by large-scale data analyses. The BH method, by controlling the False Discovery Rate (FDR), allows researchers to manage the trade-off between discovering true effects and limiting false positives effectively. Simultaneously, the existence of other methods such as the Bonferroni correction, Holm-Bonferroni, and Šidák adjustments, along with more complex procedures like permutation tests and Bayesian methods, underscores the diversity of tools available to researchers. Each method comes with its unique strengths and limitations, catering to different types of data and research objectives. For instance, FWER-controlling methods like the Bonferroni correction are invaluable in scenarios where even a single false positive is unacceptable, while FDR-controlling approaches like the BH method are more suitable for exploratory analyses with large datasets. The integration of these methods into statistical software such as R has further democratized access to sophisticated statistical tools, enabling researchers from various fields to apply the most appropriate methods to their data. This accessibility ensures that research findings are both robust and reliable, despite the inherent challenges of multiple comparisons. In essence, the BH method, along with other p-value adjustment techniques, equips researchers with the necessary tools to navigate the complexities of modern data landscapes confidently. They collectively ensure that researchers can uncover meaningful insights without the risk of being misled by false discoveries, thereby advancing the pursuit of knowledge across various scientific disciplines. pre { background-color:#38393d; color: #5fd381; }","link":"/2023/12/07/LearnNotes/fdr/"},{"title":"Fly crossover","text":"Fly Crossover Met_ {RNAi} （III） Gre_ {RNAi} （III） Hnf4_ {RNAi} （III） UAS-GFP （II） Target: $;\\frac{UAS_ {GFP}}{CyO}；\\frac{Hnf4_ {RNAi}}{TM_ 6b}$ $Sp/CyO；Met_ {RNAi} /TM6b$ $Sp/CyO；Gre_ {RNAi} /TM6b$ Line 1 $$ ;\\frac{+}{+};\\ Hnf4_ {RNAi}\\ \\ \\ \\times\\ \\ \\ ;\\frac{Sp}{CyO};\\ \\frac{Dr}{TM_ 6b} $$ F1: $;\\frac{Sp}{+};\\ \\frac{Dr}{Hnf4_ {RNAi}}$ $;\\frac{CyO}{+};\\ \\frac{Dr}{Hnf4_ {RNAi}}$ $;\\frac{Sp}{+};\\ \\frac{Hnf4_ {RNAi}}{TM_ 6b}$ $;\\frac{CyO}{+};\\ \\frac{Hnf4_ {RNAi}}{TM_ 6b}$ Line 2 $$ ;UAS_ {GFP}; \\ \\ \\times \\ \\ ;\\frac{Sp}{CyO};\\frac{Dr}{TM_ 6b} $$ F1: $;\\frac{UAS_ {GFP}}{Sp};\\frac{Dr}{+}$ $;\\frac{UAS_ {GFP}}{Sp};\\frac{TM_ 6b}{+}$ $;\\frac{UAS_ {GFP}}{CyO};\\frac{Dr}{+}$ $;\\frac{UAS_ {GFP}}{CyO};\\frac{TM_ 6b}{+}$ L2F2: $$ ;\\frac{UAS_ {GFP}}{CyO};\\frac{Dr}{+} \\ \\ \\times \\ \\ ;\\frac{UAS_ {GFP}}{CyO};\\frac{TM_ 6b}{+}$$ Ch2: $\\frac{UAS_ {GFP}}{CyO}$; $UAS_ {GFP}$ $CyO$ Dead Ch3: $\\frac{Dr}{+}$; $\\frac{CyO}{+}$; $\\frac{Dr}{CyO}$ $;UAS_ {GFP};\\frac{Dr}{+}$ $;\\frac{UAS_ {GFP}}{CyO};\\frac{Dr}{TM_ 6b}$ $;\\frac{UAS_ {GFP}}{CyO};\\frac{+}{+}$ $;\\frac{CyO}{CyO};\\frac{TM_ 6b}{+}$ L1F1; L2F2 crosses $$ ;\\frac{UAS_ {GFP}}{CyO};\\frac{Dr}{CyO} \\ \\ \\times\\ \\ s $$ $$ R^2 = 0.9889 $$ $$ y = -28.1452x + 135.5281 $$ x = (y - 135.5281) / (-28.1452)","link":"/2021/09/25/LearnNotes/fly-cross/"},{"title":"Fly Behaviors: Oder and Forage","text":"Behaviors Courtship Foraging The short neuropeptide F receptor regulates olfaction-mediated foraging behavior in the oriental fruit fly Bactrocera dorsalis (Hendel) © Hong-Fei Li, et al Abstract The short neuropeptide F (sNPF) signaling system, consisting of sNPF and its receptor (sNPFR), influences many physiological processes in insects, including feeding, growth and olfactory memory. sNPF regulates olfactory sensitivity in the oriental fruit fly Bactrocera dorsalis (Hendel) during starvation Behavior assay Flies were transferred to a clean mesh cage (40 cm × 40 cm × 40 cm) for acclimatization and starvation 1 day before the experiment. On the day of the experiment, flies (sex ratio 1:1) were transferred individually to a clean chamber (10 cm × 10 cm × 12 cm) and allowed to acclimatize for 20 min. Then, 10 μL of artificial food, or 0.5 g fully ripe orange, or 0.5 g fully ripe banana (Jayanthi et al., 2012; Rattanapun et al., 2009; Zhu et al., 2018) was placed in the center of the chamber. Foraging behavior was observed for 15 min. Latency was defined as the time elapsed before the fly landed on the food. All foraging behavior assays took place between 16:00 and 18:00. Elementary sensory-motor transformations underlying olfactory navigation in walking fruit-flies cite: Álvarez-Salvado, Efrén, et al. “Elementary sensory-motor transformations underlying olfactory navigation in walking fruit-flies.” Elife 7 (2018): e37815. © Efrén Álvarez-Salvado, et al Abstract Odor attraction in walking Drosophila melanogaster is commonly used to relate neural function to behavior, but the algorithms underlying attraction are unclear. Here, we develop a high-throughput assay to measure olfactory behavior in response to well-controlled sensory stimuli. We show that odor evokes two behaviors: an upwind run during odor (ON response), and a local search at odor offset (OFF response). Wind orientation requires antennal mechanoreceptors, but search is driven solely by odor. Using dynamic odor stimuli, we measure the dependence of these two behaviors on odor intensity and history. Based on these data, we develop a navigation model that recapitulates the behavior of flies in our apparatus, and generates realistic trajectories when run in a turbulent boundary layer plume. The ability to parse olfactory navigation into quantifiable elementary sensori-motor transformations provides a foundation for dissecting neural circuits that govern olfactory behavior. Aggressive Behavior Fighting fruit flies: A model system for the study of aggression Cite: || |:-:|Despite the importance of aggression in the behavioral repertoire of most animals, relatively little is known of its proximate causation and control. To take advantage of modern methods of genetic analysis for studying this complex behavior, we have developed a quantitative framework for studying aggression in common laboratory strains of the fruit fly, Drosophila melanogaster. In the present study we analyze 73 experiments in which socially naive male fruit flies interacted in more than 2,000 individual agonistic interactions. This allows us to (i) generate an ethogram of the behaviors that occur during agonistic interactions; (ii) calculate descriptive statistics for these behaviors; and (iii) identify their temporal patterns by using sequence analysis. Thirty-minute paired trials between flies contained an average of 27 individual agonistic interactions, lasting a mean of 11 seconds and featuring a variety of intensity levels. Only few fights progressed to the highest intensity levels (boxing and tussling). A sequential analysis demonstrated the existence of recurrent patterns in behaviors with some similarity to those seen during courtship. Based on the patterns characterized in the present report, a detailed examination of aggressive behavior by using mutant strains and other techniques of genetic analysis becomes possible. |© Selby Chen, et all| AB Despite the importance of aggression in the behavioral repertoire of most animals, relatively little is known of its proximate causation and control. To take advantage of modern methods of genetic analysis for studying this complex behavior, we have developed a quantitative framework for studying aggression in common laboratory strains of the fruit fly, Drosophila melanogaster. In the present study we analyze 73 experiments in which socially naive male fruit flies interacted in more than 2,000 individual agonistic interactions. This allows us to (i) generate an ethogram of the behaviors that occur during agonistic interactions; (ii) calculate descriptive statistics for these behaviors; and (iii) identify their temporal patterns by using sequence analysis. Thirty-minute paired trials between flies contained an average of 27 individual agonistic interactions, lasting a mean of 11 seconds and featuring a variety of intensity levels. Only few fights progressed to the highest intensity levels (boxing and tussling). A sequential analysis demonstrated the existence of recurrent patterns in behaviors with some similarity to those seen during courtship. Based on the patterns characterized in the present report, a detailed examination of aggressive behavior by using mutant strains and other techniques of genetic analysis becomes possible. A resource-poor developmental diet reduces adult aggression in male Drosophila melanogaster © Danielle Edmunds, et al Abstract resource-poor developmental nutrition might decrease adult aggression by limiting growth and energy budgets, or alternatively might increase adult aggression by enhancing motivation to compete for resources low-resource developmental diet reduced the probability of aggressive lunges in adults, as well as threat displays against rivals independent of diet-related differences in body mass Low-resource die: facing rivals → Males aggression↑ social effects Behavioural trials Pre-treatment 2 h: food-deprived in moist cotton wool Transfer to chamber: 20-mm diameter, 5-mm depth containing a food patch (5-mm diameter) In each pair, we arbitrarily designated one male as the focal male and the other as the rival male 20–21 pairs per combination 5-min acclimatisation period, 15 min recording scored the videos using JWatcher five aggressive behaviours (fencing, chasing, tussling, lunging and wing threat) Contest experience enhances aggressive behaviour in a fly: when losers learn to win © Giovanni Benelli, et al Abstract previous victories and defeats both enhance aggressive behaviour in olive fruit flies, allowing them to achieve higher fighting success in subsequent contests against inexperienced males.","link":"/2021/09/25/LearnNotes/fly-behavior/"},{"title":"Fourier Transforms","text":"Fourier Transforms Addtional infromation: Fourier Series and Fourier Transform Fourier Series Fourier series simply states that, periodic signals can be represented into sum of sines and cosines when multiplied with a certain weight. It further states that periodic signals can be broken down into further signals with the following properties. The signals are sines and cosines The signals are harmonics of each other Although both Fourier series and Fourier transform are given by Fourier , but the difference between them is: Fourier series is applied on periodic signals Fourier transform is applied for non periodic signals Fourier transform The Fourier transform simply states that that the non periodic signals whose area under the curve is finite can also be represented into integrals of the sines and cosines after being multiplied by a certain weight. The Fourier transform has many wide applications that include, image compression (e.g JPEG compression), filtering and image analysis. Cite: Learn DIP[1] Hsuty; 傅里叶级数(Fourier series)与傅里叶变换(Fourier transform) Fourier Transforms; Learn Signal System Fourier Series and Transform; Learn DIP ↩︎","link":"/2021/05/23/LearnNotes/fourier-transforms/"},{"title":"FLUORESCENCE SPECTROSCOPY","text":"FLUORESCENCE SPECTROSCOPY What happens after the molecule is excited? Fluorescence properties depend on what happens to the molecule during the ~10-8 sec during which it is excited. The decay after absorption includes 1. radiative decay ($K_f$) 2. Non-radiative decay($k_NR$) Fluorescence happens very fast because it back to the ground state very fast. In general, the decay brings the electron from excited state to the ground state (decay defines as events per sec ($k_f$)) Nan-radiative decay (exp: form of heat), the decay faster and does not generate photon. The energy transfer into solid molecules and spreed away. They don't went to exited state and generate photons. the quantum yields for phosphorescence are usually very low because the radiative decay rates are slow compared to typical nonradiative rates and quenching processes[1]. What are the processes of non-radiative decay? Unit: sec-1 Black = Non-radiative Red = Radiative (photon) ABS = absorption (1015)IC = internal conversion (kIC ≈ 1011~12) Q = quenchingIX=intersystem crossingS1→T0: 108; T1→S0: 102 Chem=photochemistrykf ≈ 108; kp ≈ 102 F = fluorescence P = phosphorescence Trans = energy transferkcollision ≈ 1010 M-1sec-1 Only apart of electron went to the S1 and they decay back to the ground state to generate fluorescence. Most of them when to S2 and decay faster., In this case, less energy lost through fluorescence. Those change are internal Change. When they when to T1 it transferred to other states (intersystem crossing) and generate phosphorescence. This state state decay very slow (phosphorescence decays for a few seconds or even more slow) Internal Conversion: energy loss due to collisions with solvent molecules collision rate = kcoll [solvent] kcoll ~1010M-1sec-1 [slovent]: 55M for water The rate of collision of a single molecule is ≈ 1011-1012sec-1 S1-S2: Heat. Fast IC (10-11sec): heat loss to solvent, all excited molecules are in the lowest vibrational state of S1 S0-S1: Heat. Slow IC (10-8sec): due to larger energy gap, therefore fluorescence is possible. What is the concentration of pure water? 1 L water = 1000 g water molecule = 18 g/mol So 1 L water = 1000/18 =55 mol [M] = 55 mol/1 L = 55 M The processes from the S2 to S1 is very fast and easily be absorbed and stored in the solvent. The processes from the S1 to the S0, the processes relatively slow. Concentration of bonds for solvent like water is very high, so it could store lots of energy. Solvent reorganization and the Stokes Shift Measure fluorescence at fixed λex as a function of λem Stokes shift: Emission spectrum is always red-shifted (lower energy) compared to the absorption spectrum Vibrational relaxation Solvent reorganization © libretexts.org © wikipedia Franck-Condon Overlap FactorsProb (0’→2’) ≅ Prob (2’←0’) etc The vibrational relaxation looks almost symitry. So, the peaks from the solvent reorganization should corresponded the states change in the vibrational relaxation. The emission shift (Stokes Shift) always as red-shifted (into right). So, the fluorescence always as less energy as the excited state. Solvent Effect The larger, the more effects (?) Dipole changes after absorption. But the solvent dipole doesn’t change. But this is not the favorite result, the dipole of the molecule changes (right) the solvent changes with the molecule. When the molecule back to the ground state and emitting fluorescence. But the solvent delay and change the ground the state of the molecule. It means the path from the S1 to S0 became shorter and the energy would used lesser. This phenomenon could be intensify by using more polar solvent. Absorption: ~ 10-15 sec Solvent reorganization (relaxation): ~ 10-10 sec Fluorescence: ~ 10-8 sec Step 1: Permanent Dipoles of solvent re-orient to adjust to the altered dipole of the excited fluorophore. Step 2: The dipole-dipole interaction in turn stabilizes S1 and destabilizes S0. Requires: 1. solvent polarity (dielectric constant, ε) 2. mobility of solvent (reorientation of solvent dipoles) How long can a molecule stay in its excited state? Excite some molecules to $ S_1 $ with a brief pulse of light at $ t = 0 $, $ N_0^ * $ excited state molecules Decay of the excited state population is exponential: $$ \\frac{dN^ *(t)}{dt} = -(k_ f + k_{NR})N^ *(t) $$ left: ?. right: Chemical rate total decay rate * total concentration So: $ N ^ * (t) = N_ 0 ^ * e ^ {-(k_f+k_ {NR})t} = N_0 ^ * e^ {-t/\\tau} \\quad$ where $N ^ * (t)$ is the number of excited molecules at time t. Define: fluorescence lifetime $ \\tau $ $ \\tau = \\frac{1}{k_f + k_{NR}} $ the processes when 1/e ? Hence, the equation for the decay of the excited state population: $ N^ *(t) = N_0^ * e^ {-t/\\tau} $ The meaning of the fluorescence lifetime τ has units of time (seconds) $[N_ {t=\\tau}^ *] = \\frac{N_ 0^ *}{e} \\approx 0/37N_ 0^ *$ After one lifetime following excitation, the probability of a molecule still being in the excited state is about 37%. The shorter the τ the faster the decay. Commonly used fluorescence in biological system, the τ ~ 1-10 ns How bright can a molecule be? Rate up: $S_ 0 \\rightarrow S_ 1 = I_ 0$, unit: [# of photons absorbed/sec] Rate down: $S_ 1 \\rightarrow S_ 0 = -(k_ f + k_ {NR}) \\cdot N ^*(t)$ Unit: [1/sec][# of photons] $N^ *(t)$ = concentration of excited state molecules at any time, $t$ $k_ {NR}$ = sum of all non-radiative rate constants $N^ *(t) = [S_1(t)]$, [# of molecules] Steady state: rate up = rate down $0 = \\frac{dN ^ *(t)}{dt} = I_ 0 - (k_ f + k_ {NR}) N ^ *(t)$ In the steady state $N ^ *(t)$ is constant $= N ^ * _ {SS}$ $I_0 = (k_f + k_{NR}) N ^ *_{SS}$ Fluorescence quantum yield (QY) $Q_f$ (QY): fraction of excited-state molecules that relax to the ground state by emitting a photon. photons/sec emitted in steady state $$ Q_f = \\frac{k_ f N^ *_ {SS}}{I_ 0} = \\frac{k_ f N^ *_ {SS}}{(k_ f + k_{NR})N^ *_ {SS}} $$ Since $I_0 = (k_f + k_{NR})N^*_{SS}$ photons/sec absorbed in steady state Quantum yield: $Q_f = \\frac{k_f}{(k_f + k_{NR})} = k_f \\times \\tau$ Recall $\\tau = \\frac{1}{(k_f + k_{NR})}$ What are the fluorophores in biological systems? Intrinsic Fluorescence of Proteins Absorption spectra Fluorescence spectra of amino acids in water “About 300 papers per year abstracted in Biological Abstracts report work that exploits or studies tryptophan (Trp) fluorescence in proteins…” Vivian et al. Biophysical Journal 2001 Lifetime (nsec) Absorption Fluorescence Wavelength (nm) Absorptivity (ε, M-1cm-1) Wavelength (λmax, nm) Quantum Yield (25°C) Tryptophan 2.6 280 5,600 348 0.20 Tyrosine 3.6 274 1,400 303 0.14 Phenylalanine 6.4 257 200 282 0.04 Maturation of GFP © zeiss Compound Lifetime (nsec) Wavelength (nm)(Absorption) Absorptivity (ε, M-1cm-1) Wavelength (λmax, nm) (Emission) Quantum Yield (25°C) (Emission) Tryptophan 2.6 280 5,600 348 0.20 Tyrosine 3.6 274 1,400 303 0.14 Phenylalanine 6.4 257 200 282 0.04 wtGFP 3.3/2.8 395/475 21,000 509 0.77 (Enhanced) EGFP (F64L, S65T) 2.7 484 56,000 507 0.60 Fluorescence Quenching Quenching: reduce the fluorescent signal. Static and dynamic quenching causing the similar result. But the processes are totally different. Static quenching: Formation of a “dark” complex of the ground state of the fluorophore and another molecule. Dynamic quenching: Collision between the excited state of the fluorophore and another molecule Enhancing the non-radiative decay to the ground state $$F = \\sigma × 𝐼 × 𝑄Y$$ $F$: fluorescence intensity (photons/sec) $\\sigma$: absorption cross-section (cm2) $I$: excitation light flux - photons/(cm2 sec) $QY$: Quantum yield (unitless) Mirror-image rule: between the citation and the shifting spectrum, they are symmetry. Static quenching (ground state) Fluorescent species $A$ can associate with quencher $Q$ to form a non-fluorescent complex $AQ$: $$ A + Q \\leftrightarrow AQ $$ The association constant $K_a$ is defined as: $$ K_a = \\frac{[AQ]}{[A][Q]} $$ The ratio of the fluorescence intensities without and with the quencher present is given by: $$ \\frac{F_0}{F} = \\frac{A_{tot}}{A} = \\frac{[A] + [AQ]}{[A]} = \\frac{[A] + [A][Q]K_a}{[A]} \\\\ = 1 + [Q]K_a $$ Fluorescence depends on the concentration of the quencher, $[Q]$ Data analysis yields the association constant F is after quenching It could quenching black radioactive object. Dynamic quenching: collision with the excited state $A + hv \\rightarrow A^ *$ (excitation) $ A^ * + Q \\xrightarrow{k_Q} A + Q + \\text{heat}$ (quenching) $A ^ * \\xrightarrow{k_f} A + hv’$ (fluorescence) $k_Q$: second order rate constant for collisional quenching The diagram illustrates the energy levels $S_1$ and $S_0$, with $k_f$ representing the rate of fluorescence, $k_{NR}$ the non-radiative decay, and $[Q]k_Q$ the rate of quenching by the quencher $Q$. There’s also an illustrative depiction of a molecule $A^*$ being quenched by $Q$ within a radius of 50Å. Only quenching excited molecule The energy levels $S_1$ and $S_0$ are shown with $k_f$ representing the rate of fluorescence, $k_{NR}$ the non-radiative decay, and $[Q]k_Q$ the rate of quenching by the quencher $Q$. Rate of decay due to collision: $$ \\frac{d[S_1]}{dt} = -k_Q[Q][S_1] $$ Total rate of decay: $S_1 \\rightarrow S_0$: $ \\frac{d[S_1]}{dt} = -k_f[S_1] - k_{NR}[S_1] - k_Q[Q][S_1] $ $ \\frac{d[S_1]}{dt} = -(k_f + k_{NR} + k_Q[Q])[S_1] $ The quantum yield in the presence of a quencher: $$ Q_f^{\\theta} = \\frac{k_f}{k_f + k_{NR} + k_Q[Q]} $$ No Quencher:$Q_f^0 = \\frac{k_f}{k_f + k_{NR}}$ Plus quencher:$Q_f^{\\theta} = \\frac{k_f}{k_f + k_{NR} + k_Q[Q]}$ The ratio of fluorescence intensities without and with the quencher is given by: $$ \\frac{F_0}{F} = \\frac{Q_f^ 0}{Q_f^ 0 + Q_f} \\\\ = \\frac{k_ f}{k_ f + k_ {NR}} \\times \\frac{k_ f + k_ {NR} + k_ Q[Q]}{k_ f} \\\\ = 1 + \\frac{k_Q[Q]}{k_f + k_{NR}} \\\\ = 1 + \\tau_0 k_Q[Q] $$ Where $\\tau_0 = \\frac{1}{k_f + k_{NR}}$ is the fluorescence lifetime (without quencher). Define: the Stern-Volmer constant $K_{SV} = k_Q \\tau_0$ $ \\frac{F_0}{F} = 1 + K_{SV} [Q] $ KSV measures the rate of quencher colliding into fluorophores at the excited state. The more the fluorophore is protected from solvent, the smaller the value of KSV. Slope: $K_{SV} = 8 M^{-1}$ (It descripts how strong the quencher it is. The larger (sharper), the stronger.)Separately measure $\\tau_0 = 4 ns$ Calculate $k_Q = \\frac{K_{SV}}{\\tau_0} = 2 \\times 10^9 M^{-1} sec^{-1}$ Dynamic and Static quenching have the same dependence on [Q] Dynamic quenching: $\\frac{F_0}{F} = 1 + K_{SV} [Q]$ Static quenching: $\\frac{F_0}{F} = 1 + K_a [Q]$ In each case, you will get a straight line if you plot $\\frac{F_0}{F}$ vs $[Q]$ How can one distinguish between static quenching and dynamic quenching? The differential equation for the decay of excited state molecules $N^*$ is given by: $$ \\frac{dN^ * (t)}{dt} = -(k_f + k_{NR} + k_Q[Q])N^ * (t) $$ This leads to the solution: $$ N^ * (t) = N ^ * _ 0 e ^ {-(k_f+k_{NR}+k_Q[Q])t} $$ And equivalently: $$ N^ * (t) = N ^ * _0 e^ {-\\frac{t}{\\tau}} $$ DYNAMIC QUENCHING: The lifetime of the excited state decreases as the concentration of the quencher is increased. In the presence of a quencher, the lifetime $\\tau$ is given by: $$ \\tau = \\frac{1}{(k_f + k_{NR} + k_Q[Q])} $$ Dynamic quenching Plus quencher No quencher $\\tau = \\frac{1}{(k_f + k_{NR} + k_Q[Q])}$ $ \\tau_0 = \\frac{1}{(k_f + k_{NR})} $ $Q_f^{+Q} = \\frac{k_f}{k_f + k_{NR} + k_Q[Q]} $ $ Q_f^{0} = \\frac{k_f}{k_f + k_{NR}} $ hence $$ \\frac{\\tau_0}{\\tau} = \\frac{Q_f^ {0}}{Q_f^ {+Q}} \\approx \\frac{F_0}{F} $$ Stern-Volmer plot will be the same if you plot lifetimes or fluorescence intensity Static quenching DOES NOT affect the lifetime of the excited state Static quenching (ground state) $$ A + Q \\leftrightarrow AQ $$ $$ K_a = \\frac{[AQ]}{[A][Q]} $$ Fluorescent species $A$ can form a non-fluorescent complex $AQ$ with quencher $Q$. The association constant $K_a$ is defined as the ratio of the concentration of the complex to the product of the concentrations of $A$ and $Q$. The ratio of the fluorescence intensities without and with the quencher is given by: $$ \\frac{F_0}{F} = \\frac{A_{tot}}{A} = \\frac{[A] + [AQ]}{[A]} = \\frac{[A] + [A][Q]K_a}{[A]} = 1 + [Q]K_a $$ The excited state species $A^*$ has the same properties in the presence of the static quencher. But there is less of it, so the fluorescence intensity decreases. If both static and dynamic quenching are occurring in the same sample $$ \\frac{F_0}{F} = (1 + k_Q \\tau_0 [Q])(1 + K_a [Q]) = (1 + K_{SV} [Q])(1 + K_a [Q]) $$ Trp94-(H±His18) form a dark complex: no fluorescence Trp94 + His18 ⇌ Trp94·(H+His18) DARK At acidic pH: Quantum yield of W94 (Qf) is decreased; Fluorescence lifetime of W94 (τ₀) is unchanged pre { background-color:#38393d; color: #5fd381; } Hurtubise RJ (1990) Phosphorimetry: Theory, Instrumentation, and Applications, VCH, New York. ↩︎","link":"/2024/02/06/LearnNotes/fluorescence/"},{"title":"Fruchterman Reingold layout","text":"Fruchterman–Reingold Fruchterman-Reingold is an algorithm used for force-directed graph drawing, which is a way of visualizing graph structures in a 2D or 3D space. The algorithm was first introduced by Thomas M. Fruchterman and Edward M. Reingold in 1991. The Fruchterman-Reingold algorithm works by simulating a physical system in which the nodes of a graph are treated as objects with electrical charges and the edges of the graph are treated as springs. The nodes are initially placed at random positions in the 2D or 3D space, and then the algorithm iteratively adjusts the position of the nodes based on the repulsion between the nodes and the attraction between the connected nodes. The nodes that are connected by an edge are pulled closer together, while the nodes that are not connected are pushed apart. The Fruchterman-Reingold algorithm aims to minimize the total energy of the system by finding an equilibrium state where the forces between the nodes and edges are balanced. The algorithm iteratively adjusts the positions of the nodes until it reaches the equilibrium state. The result is a visually pleasing graph layout that allows the viewer to easily see the connections and relationships between the nodes. The Fruchterman-Reingold algorithm is widely used in many fields such as social network analysis, information visualization, and bioinformatics. It has been implemented in many software packages, including Gephi, Cytoscape, and NetworkX. Fruchterman–Reingold is a type of layout which widely be used in the network, social network and protein-protein interaction network for instance, analysis. Who sad this? So, imagine that all the nodes are electrons that carry the same charge. As a result, they prefer to stay away from each other and distribute evenly in a limited space. However, the connections (edges) work like springs that pull two nodes together. If two groups have connections that frequently occur within the group, those nodes would prefer to be close to each other and form two large clusters because of the “springs”. The two groups would be away from each other because no/or a few of spring pulls them together, and the two huge groups of nodes would push the nodes outside the cluster. If a new node is added that has connections to both clusters and the number is significant enough, it could form an hourglass-like structure. And if there are a few other connections between two clusters at the same time, it would merge the two groups into a single one. Harel–Koren Fast Multiscaling layout Want to know more? This algorithm was published in 1991 by Fruchterman &amp; Reingold[1]. It is a undirected layout and modified from the spring-embedder model and VLSI technique called force-directed placement. By this methoud, it is mainly concerned about: Distribute the vertices evenly in the frame. Minimize edge crossings. Make edge lengths uniform. Reflect inherent symmetry. Conform to the frame. Repulsive forces $ f _{rep}(u,v) = \\frac{c _{rep}}{||p _v - p _u||^ 2} × \\overrightarrow{p _vp _u} $ Attractive forces $ f _{spring}(u,v) = c _{spring} × log\\frac{||p _v - p _u||}{\\ell} × \\overrightarrow{p _vp _u} $ $ f_{attr}(u,v) = f _spring(u,v)-f _{rep}(u,v) $ Resulting displacement vector $ F _u = \\sum _{v \\in V} f _{rep}(u, v) + \\sum _{uv \\in E} f _{attr} (u,v) $ More Details and example you can find at Philipp Kindermann’s Youtobe Video (2021) pre { background-color:#38393d; color: #5fd381; } Fruchterman, Thomas MJ, and Edward M. Reingold. “Graph drawing by force‐directed placement.” Software: Practice and experience 21.11 (1991): 1129-1164. ↩︎","link":"/2023/02/20/LearnNotes/fruchterman-reingold/"},{"title":"Structure of the Immunoglobulin","text":"The Structure of the Immunoglobulin © Adrian Y. S. Lee Immunoglobulins, commonly known as antibodies, are crucial proteins in the immune system that recognize and bind to specific antigens, such as bacteria and viruses, to help protect the body. Their structure is both unique and complex, consisting of several key components: Basic Structure: Immunoglobulins are Y-shaped molecules made up of four polypeptide chains - two identical heavy (H) chains and two identical light (L) chains. These chains are held together by disulfide bonds. Variable (V) and Constant © Regions: Variable Regions: The tips of the ‘Y’ shape consist of the variable regions of the light and heavy chains. These regions are highly diverse and are responsible for the antigen-binding specificity of the antibody. Constant Regions: The rest of the molecule forms the constant region, which is relatively conserved across different antibodies. The constant region of the heavy chains determines the class or isotype (e.g., IgG, IgM, IgA, IgE, IgD) of the antibody and mediates effector functions. Isotypes: Mammals have several classes of immunoglobulins (IgG, IgA, IgM, IgE, IgD), each with different roles in the immune response. These isotypes differ mainly in their heavy chain constant regions. Glycosylation: Many antibodies are glycosylated, meaning they have carbohydrate groups attached. This glycosylation can affect the antibody’s stability, distribution, and activity. Light Chain Types: There are two types of light chains in antibodies - kappa (κ) and lambda (λ). An individual antibody will have two identical light chains of one type. V(D)J © David B. Roth V(D)J recombination is a mechanism in the immune system that generates the immense diversity of antibodies (immunoglobulins) and T cell receptors necessary for the adaptive immune response. This process is named for the three gene segments involved in the recombination: Variable (V), Diversity (D), and Joining (J). So, V(D)J is the recombination unit. V(D)J in 3D Structure We take 5wl2 as example: ©PDB 5wl2 Kabat Number © pipebio The Kabat definition is based on sequence variability and is the most commonly used. Here is the CDR definition from Bioinf.org.uk L1 L2 L3 H1 H2 H3 Kabat L24-L34 L50-L56 L89-L97 H31-H35B H50-H65 H95-H102 How to make it in python: conda install bioconda::abnumber import pandas as pdfrom abnumber import ChainFasta = &quot;xxx.fa&quot;with open(Fasta, 'r') as F: Seq = F.read()KABAT = pd.DataFrame([dict(Chain(i, scheme='kabat')) for i in Seq.split('\\n')[:-2] if &quot;&gt;&quot; not in i]) pre { background-color:#38393d; color: #5fd381; }","link":"/2024/01/02/LearnNotes/igstructure/"},{"title":"Neuraminidase (NA) protein, a Quick View","text":"NA protein The influenza NA protein, or neuraminidase, is a critical component of the influenza virus and plays a vital role in the virus’s life cycle. Here’s an overview of its function and structure: Function of Influenza NA Protein Viral Release: Neuraminidase is primarily responsible for facilitating the release of newly formed virus particles from the host cell. It cleaves sialic acid residues on the host cell surface and on the viral envelope, which otherwise bind the emerging viral particles and prevent their release. Virus Spread: By cleaving sialic acid, NA protein aids in the spread of the virus. This cleavage prevents the aggregation of virus particles, enabling them to spread more efficiently from cell to cell. Role in Infection: It helps the virus penetrate the mucus layer of the respiratory tract, enhancing the virus’s ability to infect the host cells. Structure of Influenza NA Protein © Julie L. McAuley1; 19 Cytoplasmic Tail: Suggesting that the NA cytoplasmic tail is involved in critical viral functions, the N-terminal domain sequence is nearly 100% conserved across all IAV subtypes and consists of the sequence MNPNQK[1]. A complete loss of the tail domain[2] resulted in a 50% reduction in the amount of NA in infected cells. Transmembrane Domain: It contains a variable sequence of amino acids spanning residue numbers 7–29 and is predicted to form an alpha helix[1:1][3] with interspersed polar residues driving subunit-subunit interactions[4]. Stalk Region: Depending on the length of the stalk region, the NA may protrude slightly more or less above the viral envelope than the HA, which may influence the overall enzymatic activity of the virus[5][6]. The number and sequence of amino acid residues can vary considerably[1:2]. NA stalk truncation mutants of the 2009 pandemic virus A(H1N1)pdm09 showed greater lethality in mice and virulence in ferrets than the untruncated counterpart[7]. Head Domain: These catalytic sites are characterized by a large cavity with an unusually large number of charged residues in the pocket and around its rim[8][9]. The tetrameric form of NA is considered optimal for enzyme activity, and mutations that lead to instability of the tetramer lead to decreased enzyme activity [McKimm_96b][Fujisaki_12][^McKimm_13]. While it has been reported that monomers alone have no enzyme activity[3:1] and usually expression of recombinant soluble NA heads requires a synthetic tetramerization domain for active NA[10]. Active site: Arg118, Asp151, Arg152, Arg224, Glu276, Arg292, Arg371, and Tyr406 Framework residues: Glu119, Arg156, Trp178, Ser179, Asp198, Ile222, Glu227, Glu277, Asn294, and Glu425 Tetrameric Structure: The neuraminidase protein typically forms a tetramer, meaning four NA molecules join together to function. Head and Stalk Regions: The NA protein has two distinct regions: the head, which contains the active site for sialic acid cleavage, and the stalk, which anchors the protein to the viral envelope. Active Site: The active site is located in a pocket in the head region and is responsible for the enzyme’s sialic acid cleavage activity. Glycosylation Sites: These sites are present on the head region, where carbohydrate chains are attached. This glycosylation can affect the antigenicity and activity of the NA protein. Subtypes: There are several different subtypes of neuraminidase, categorized based on slight variations in their amino acid sequences. These variations can affect the protein’s function and its recognition by the immune system. Understanding the function and structure of the influenza NA protein is crucial for developing antiviral drugs and vaccines. Neuraminidase inhibitors, for example, are a class of antiviral drugs that block the activity of this protein, effectively preventing the virus from spreading within the host. Leading Research A paper[11] investigates the antigenic evolution of the neuraminidase (NA) protein in the H3N2 influenza virus. Using combinatorial mutagenesis and next-generation sequencing, the study focuses on seven specific residues in an antigenic region of NA. It finds that the local fitness landscape of this region is highly correlated across different H3N2 strains and reveals that local net charge balancing is a significant constraint in NA antigenic evolution. The study also demonstrates a correlation between epistasis and residue coevolution in naturally circulating influenza strains, providing important insights into the biophysical constraints on NA antigenic evolution. © Wang Y; 2021[11:1] Features from Other NA protein H1N1: K253R could reduce the 75% of virion-associated NA activity[12]. pre { background-color:#38393d; color: #5fd381; } Blok, J., and Air, G. M. (1982). Variation in the membrane-insertion and “stalk” sequences in eight subtypes of influenza type A virus neuraminidase. Biochemistry 21, 4001–4007. ↩︎ ↩︎ ↩︎ Garcia-Sastre, A., and Palese, P. (1995). The cytoplasmic tail of the neuraminidase protein of influenza A virus does not play an important role in the packaging of this protein into viral envelopes. Virus Res. 37, 37–47. doi: 10.1016/0168-1702(95)00017-K ↩︎ Air, G. M. (2012). Influenza neuraminidase. Influenza Other Respir. Viruses 6, 245–256. doi: 10.1111/j.1750-2659.2011.00304.x ↩︎ ↩︎ Nordholm, J., Da Silva, D. V., Damjanovic, J., Dou, D., and Daniels, R. (2013). Polar residues and their positional context dictate the transmembrane domain interactions of influenza A neuraminidases. J. Biol. Chem. 288, 10652–10660. doi: 10.1074/jbc.M112.440230 ↩︎ Harris, A., Cardone, G., Winkler, D. C., Heymann, J. B., Brecher, M., White, J. M., et al. (2006). Influenza virus pleiomorphy characterized by cryoelectron tomography. Proc. Natl. Acad. Sci. U. S. A. 103, 19123–19127. doi: 10.1073/pnas.0607614103 ↩︎ Matsuoka, Y., Swayne, D. E., Thomas, C., Rameix-Welti, M. A., Naffakh, N., Warnes, C., et al. (2009). Neuraminidase stalk length and additional glycosylation of the hemagglutinin influence the virulence of influenza H5N1 viruses for mice. J. Virol. 83, 4704–4708. doi: 10.1128/JVI.01987-08 ↩︎ Park, S., Il Kim, J., Lee, I., Bae, J. Y., Yoo, K., Nam, M., et al. (2017). Adaptive mutations of neuraminidase stalk truncation and deglycosylation confer enhanced pathogenicity of influenza A viruses. Sci. Rep. 7:10928. doi: 10.1038/s41598-017-11348-0 ↩︎ Colman, P. M., Varghese, J. N., and Laver, W. G. (1983). Structure of the catalytic and antigenic sites in influenza virus neuraminidase. Nature 303, 41–44. doi: 10.1038/303041a0 ↩︎ Varghese, J. N., McKimm-Breschkin, J. L., Caldwell, J. B., Kortt, A. A., and Colman, P. M. (1992). The structure of the complex between influenza virus neuraminidase and sialic acid, the viral receptor. Proteins 14, 327–332. doi: 10.1002/prot.340140302 ↩︎ Schmidt, P. M., Attwood, R. M., Mohr, P. G., Barrett, S. A., and McKimm-Breschkin, J. L. (2011). A generic system for the expression and purification of soluble and stable influenza neuraminidase. PLoS One 6:e16284. doi: 10.1371/journal.pone.0016284 [^McKimm_13]McKimm-Breschkin, J. L., Williams, J., Barrett, S., Jachno, K., McDonald, M., Mohr, P. G., et al. (2013). Reduced susceptibility to all neuraminidase inhibitors of influenza H1N1 viruses with haemagglutinin mutations and mutations in non-conserved residues of the neuraminidase. J. Antimicrob. Chemother. 68, 2210–2221. doi: 10.1093/jac/dkt205 [^Fujisaki_12]Fujisaki, S., Takashita, E., Yokoyama, M., Taniwaki, T., Xu, H., Kishida, N., et al. (2012). A single E105K mutation far from the active site of influenza B virus neuraminidase contributes to reduced susceptibility to multiple neuraminidase-inhibitor drugs. Biochem. Biophys. Res. Commun. 429, 51–56. doi: 10.1016/j.bbrc.2012.10.095 [^McKimm_96b]McKimm-Breschkin, J. L., McDonald, M., Blick, T. J., and Colman, P. M. (1996b). Mutation in the influenza virus neuraminidase gene resulting in decreased sensitivity to the neuraminidase inhibitor 4-guanidino-Neu5Ac2en leads to instability of the enzyme. Virology 225, 240–242. ↩︎ Wang Y, Lei R, Nourmohammad A, et al. Antigenic evolution of human influenza H3N2 neuraminidase is constrained by charge balancing[J]. Elife, 2021, 10: e72516. ↩︎ ↩︎ Liu T, Wang Y, Tan T J C, et al. The evolutionary potential of influenza A virus hemagglutinin is highly constrained by epistatic interactions with neuraminidase[J]. Cell Host &amp; Microbe, 2022, 30(10): 1363-1369. e4. ↩︎","link":"/2023/12/07/LearnNotes/h3n2na/"},{"title":"Understanding Antibodies and Phage Display: A Deep Dive","text":"The Magnificent World of Antibodies Antibodies, also known as immunoglobulins, are Y-shaped proteins produced by the immune system to neutralize foreign substances like bacteria and viruses. Let’s break down the components: Heavy Chain &amp; Light Chain The basic structure of an antibody is composed of two identical heavy chains and two identical light chains. Each chain is a sequence of amino acids, which fold into a specific three-dimensional shape. Heavy Chain (H): The heavy chains are the larger of the two, and they form the base of the Y-shape. They play a pivotal role in determining the class of an antibody (like IgG, IgM, IgA, etc.). Light Chain (L): The light chains pair with the heavy chains to form the arms of the Y-shaped antibody. Each antibody has one of two types of light chains - either kappa (κ) or lambda (λ). Complementarity-Determining Regions (CDR) Yuning Wang, PhD The tips of the “Y” arms contain a special region known as the CDR. This region is responsible for recognizing and binding to specific parts of foreign invaders, called antigens. Each antibody has six CDRs (three from the light chain and three from the heavy chain), which collectively determine its specificity. It’s like the “lock and key” model; the CDR is the lock, and the antigen is the key. The Magic of Phage Display Phage display is a high-throughput technology used to study protein-protein, protein-peptide, and protein-DNA interactions. It’s like a library, but instead of books, we have bacteriophages - viruses that infect bacteria. Basics of Phage Display © Justyna Bazan In phage display, a gene encoding a protein or peptide of interest is fused to a coat protein gene of a bacteriophage, causing the displayed protein to be expressed on the outside of the phage particle. This allows the protein to be physically linked to the genetic information that encodes it. Display of antibody fragments Typically, antibodies comprise two heavy chains and a pair of light chains interconnected through noncovalent bonds and disulfide bridges. However, unique antibodies without light chains, found in Camelidae serum, bind antigens using a specific VHH fragment. This fragment can recognize distinctive conformational epitopes due to its extended complementary-determining region 3 (CDR3). Antibody fragments’ expression in E. coli necessitates in vivo refolding to maintain their activity and function. A method for soluble recombinant protein expression in the cytoplasm of the Origami DE3 E. coli strain has been introduced. This method enhances the folding of heterologous proteins dependent on disulfide bonds. Intriguingly, scFv expressed in the bacterial cytoplasm displayed superior binding characteristics compared to periplasmic expression. While periplasmic expression offers suitable conditions for VH and VL pairing, co-expression of periplasmic chaperones has shown to significantly impact soluble scFv productivity. Various antibody fragments, including Fab, Fv, scFv, and their modifications, are employed in phage display technology. These fragments, particularly scFv, have been expressed on the phage surface without compromising antibody affinity. The CRAbs construct, comprising two scFv fragments targeting adjacent epitopes, is one notable example. © Justyna Bazan; Fab (the antigen-binding fragment), scFab (the single chain antigen-binding fragment), scFabΔC (the scFab variant without cysteins), scFv (the single chain fragment variable), Fv (the fragment variable), VHdAb (the antibody with one variable heavy chain domain), CRAb (the construct specific to adjacent epitopes on the antigen) Antibody Fragment Description Fab VH-CH and VL-CL segments linked by disulfide bonds. Used in tumor imaging. Fv Comprises only the VL and VH regions. scFv A commonly used antibody fragment consisting of VL and VH regions stabilized by (Gly4Ser)3 linker. VHH Unique fragment found in Camelidae serum antibodies, targeting unique conformational epitopes. CRAbs Construct with two scFv fragments specific to adjacent epitopes of the same antigen. Diabodies Formed by dimerization of molecules and connection of antibody fragments. Technical Details of Phage Display 1. Phage Biology Basics: Bacteriophages, or phages, are viruses that infect bacteria. They are composed of a protein coat that encases their genetic material, which can be either DNA or RNA. The life cycle of a phage includes attaching to a bacterial cell, injecting its genetic material, and then using the host’s machinery to replicate and produce new phage particles. 2. Fusion Proteins in Phage Display: The principle behind phage display is the creation of fusion proteins. A gene of interest (encoding the protein or peptide to be displayed) is inserted into a phage coat protein gene, leading to the expression of a fusion protein on the phage surface. Commonly used coat proteins for display include pIII and pVIII of the M13 filamentous phage. 3. Constructing the Library: A diverse collection of DNA sequences is cloned into phage vectors to produce a library. This library represents a vast array of different peptides or proteins displayed on the phage surface. The library’s diversity can range from millions to billions of unique sequences, making it a powerful tool for screening. 4. Biopanning and Selection: Biopanning is the iterative process of enriching phages that bind to a specific target from a diverse library. The process involves incubating the phage library with a target (e.g., a protein, cell, or tissue), washing away non-binding phages, and then amplifying the bound phages by infecting bacteria. This cycle is typically repeated several times to enrich for high-affinity binders. 5. Elution and Analysis: After the final round of biopanning, bound phages are eluted, often by changing pH or adding a competitive ligand. The DNA from these phages is then sequenced to identify the displayed peptides or proteins. Modern techniques like next-generation sequencing can be used to analyze vast numbers of sequences simultaneously. 6. Applications in Drug Discovery: Phage display is instrumental in antibody engineering. Therapeutic antibodies like adalimumab (Humira) were discovered using phage display. It’s also used to discover peptide ligands for various targets, which can lead to the development of new drugs or diagnostic tools. 7. Challenges and Considerations: While phage display is a powerful tool, it’s essential to consider factors like the library’s quality and diversity, the stringency of washing steps during biopanning, and potential biases introduced during phage amplification. Some proteins or peptides may not be displayed well on the phage surface due to folding issues or interference with phage assembly. Advanced Insights Library Creation: Scientists can create vast libraries of phages displaying a diverse array of peptides or proteins. When looking for a needle in a haystack (like a specific antibody for a new disease), this library becomes invaluable. Biopanning: This is the process of selecting phages that bind to a specific target. The library is exposed to a target (like a protein receptor), and non-binding phages are washed away. Those that bind are amplified, creating a pool of potential candidates. Applications: Phage display has revolutionized medicine, especially in the field of drug discovery. It’s instrumental in identifying therapeutic antibodies, understanding disease mechanisms, and even vaccine development. pre { background-color:#38393d; color: #5fd381; }","link":"/2023/10/31/LearnNotes/immun/"},{"title":"Learn Japanese Words Every Day","text":"Install the input for linux sudo apt install mozc-server mozc-data fcitx-mozc mozc-utils-guireboot Learn Japanese Words Every Day P3, アローラ！！ Video Date Sentences Trans Extra material 22/10/11 振 り 向 い ちゃ うような 冒険 をしていたいみたい 21/10/05 太陽 も 月 もポケモンもあのコも 21/10/04 ただ 待 ってずっと 立 っていたって 始 まろない Phase 2, short sentences Date Sentences Trans Extra material 21/10/19 冗談 よ、わかってる 21/05/11 君に決めた 21/05/10 レッツゴー何度 も 歩 き出だす 隣 21/05/09 レッツゴー転んで すりむいて 21/04/30 先 も 見 えない果て も知らない世界が そこにあるけど 21/04/29 あの日 だってこの日 だっていつだって そうしていた 21/04/28 3で 仲間 に なろう よ 3 let’s be friends 21/04/27 2. 笑 うか 泣 いたって 2. No mater you laugh or cry, we should… 21/04/26 1. バトルを した なら 1. After a battle! 21/04/25 ためらう ことなど ナイ!トライ! Do be hesitate or something like that! Try it! 21/04/24 はじめましては いつだって 初めてさ Always say hello when first time you meet. 21/04/23 いつか 描い た 未来 がボクのポケットに あるから Because the future I drew someday is in my pocket 21/04/22 123 で飛び込め 1, 2, 3, please join us 21/04/21 全部 ボールの 中 に All in the ball 21/04/20 いつも 思い出 は どれも Every time I have any memories 21/04/19 １ 秒 先 だってまだ 知 らないけど I don’t know yet a second away 21/04/18 手さぐり で 見 えない 今日 の 中 In today’s world that can be seen by the hand 21/04/17 たとえ 火 の 中、 水 の 中 Even in fire, in water 21/04/16 見 送 りならいらない You don’t need to see me off. 21/04/15 キミに 見 せたい 不思議 の 世界 The mysterious world I want to show you Video 21/04/14 出 かける 準備 はできたかい? Are you ready to go? Video 21/04/13 ねえ、まだまだまだ？ 急 いで！ Hey, not yet? hurriedly! Video 21/04/13 私 は 誰 だ。ここはどこだ Who am I? Where am I? Web Link 21/04/12 こんにちわ，お 久 しぶりですね。お 元気 ですか Web Link 21/04/11 いただきますごちそうさまでした Thank you for this meal. Thanks for the feast. Video Phase 1, Vocabulary Date Hiragana Katakana Romanization Translation …/…/… ぴかちゅう ピカチュウ pikachu pikachu …/…/… さとし サトシ satoshi Ash 21/03/26 ばか バカ baka idiot 21/03/27 こんにちは コンニチハ Kon’nichiwa hello 21/03/28 おはよう オハヨウ ohayou good morning 21/03/29 すごいね スゴイネ sugoi ne great, awesome 21/03/29 お久ひさしぶり オヒサシブリ oo hisashi buri long time no see 21/03/30 頑張 れ ガンバレ ganbare Come on; You can do it 21/03/30 お帰かえりなさい オカエリナサイ oo kaeri nasai Welcome to back 21/03/31 行いきましょう イキマショウ iki masho yo Let’s go 21/03/31 何なに ナニ nani ?? 21/03/31 なるほど ナルホド naruhodo I got it 21/04/01 本ほん当どうにすみません ホンドウニスミマセン hontoni sumimasen Sorry 21/04/01 ありがとうございます アリガトウゴザイマス arigatou gozai masu thank you 21/04/02 かわいい カワイイ kawaii cute 21/04/02 へえ ヘエ hee 21/04/02 ごもっとも ゴモツトモ go mottomo totally (right) 21/04/02 嘘うそをつく ウソヲツク usou wo tsuku lie 21/04/03 ただいま タダイマ tadaima I’m back 21/04/03 えろ げーむ エロ ゲーム ero game erotic game 21/04/03 素す晴ばらしいです スバラシイデス subarashi desu fantastic 21/04/03 嫌いやな感かんじ イヤナカンジ iya na kanji It’s disgusting. 21/04/04 初はじめまして、どうぞよろしくお愿ねがいします ハジメマシテ、ドウゾヨロシクオネガイシマス hajimemashite 、 dozo yoroshiku oo ne ga i shi masu Nice to meet you. I look forward to working with you. 21/04/05 今こん晩ばんは コンバンハ konbanwa Good evening 21/04/06 いらっしゃいませ イラツシヤイマセ iratshai mase welcome 21/04/07 本ほん当どうに? ホンドウニ hontoni? really? 21/04/08 怖こわい 怖こわい kowai Scary 21/04/09 いただきます イタダキマス itadaki masu Thank you for this meal 21/04/10 お休やすみ オヤスミ oo yasumi Thank you for this meal 21/04/23 そういうことで souiu koto de So that’s it 21/04/23 失礼 します shitsurei shi masu Farewell 21/05/18 ちくしょう chikusho Ding-singing","link":"/2021/03/28/LearnNotes/japan/"},{"title":"Wet Lab Techs with Brief Explained","text":"Wet Lab Techs with Brief Explained Gel Shift Assays–EMSA What is EMSA The interaction of proteins with DNA is central to the control of many cellular processes including DNA replication, recombination and repair, transcription, and viral assembly. One important technique for studying gene regulation and determining protein–DNA interactions is the electrophoretic mobility shift assay (EMSA). An advantage of studying protein–DNA interactions by an electrophoretic assay is the ability to resolve complexes of different stoichiometry or conformation. Another major advantage is that the source of the DNA-binding protein may be a crude nuclear or whole cell extract, in vitro transcription product or a purified preparation. EMSA can be used qualitatively to identify sequence-specific, DNA-binding proteins (such as transcription factors) in crude lysates and, in conjunction with mutagenesis, to identify the important binding sequences within the upstream regulatory region of a given gene. EMSA can also be utilized quantitatively to measure thermodynamic and kinetic parameters. @ ThermoFisher 2022 Brief explained: During Gel electrophoration, if we add DNA (oligo) and protein together and the protein could interact with the DNA, the transfer speed of DNA is much slower because protein is dragging them. One of a standard kit for EMSA: LightShift™ Chemiluminescent EMSA Kit from thermofisher. (documentation) © ThermoFisher According its documentation, a group should have at least 3 tracks: labeled DNA: which works as negative control. It shows them band when there are no protein-DNA interaction. labeled DNA + protein: The main track for results. The position of DNA shifts because proteins interact with them. The movement of DNA is hindered by proteins. labeled DNA + protein + overload unlabeled DNA: By competition, most proteins interact with unlabeled DNA because the quantity of them is higher them labeled. As a result, we can see a dim-shifted band or no shifted band at all. The track could eliminate false positives brought by protein-label tag binding. Publication used: Shyamsunder, Pavithra, et al. “Identification of a novel enhancer of CEBPE essential for granulocytic differentiation.” Blood, The Journal of the American Society of Hematology 133.23 (2019): 2507-2517. Eamples in paper © Shyamsunder, 2019 In this paper, they showed the 4th track, which is protein + unlabeled DNA. In the panel right, there are weak shifted bind which could be the protein. Luciferase Report Assay What is a Luciferase Report Assay? A luciferase reporter assay is a test that investigates whether a protein can activate or repress the expression of a target gene using luciferase as a reporter protein (Carter &amp; Shieh, 2015). The synthesis of the reporter protein and the addition of a substrate results in a chemical reaction with bioluminescence (or the emission of photons) as a by-product. This bioluminescence directly corresponds with the effect of the protein on expression of the target gene. © GoldBio, 2022; © Scholl, et al., 2014 © GoldBio, 2022; Scholl, Zackary &amp; Yang, Weitao &amp; Marszalek, Piotr. (2014). Chaperones Rescue Luciferase Folding by Separating Its Domains. The Journal of biological chemistry. 290. 10.1074/jbc.M114.582049. After inserting the target DNA segment in the plasmid, the vector is transferred into cells. If proteins could interact with the segment, luciferase would express and cells could illuminate. © Chrysostomos Tornari; 2010 pre { background-color:#38393d; color: #5fd381; }","link":"/2022/11/09/LearnNotes/lab-techs/"},{"title":"Light in Physics","text":"Mathmatic Description of the Light In the equation you’ve provided: $$ E(x,t) = E^0 \\sin\\left[2\\pi \\left(\\frac{x}{\\lambda} - \\frac{t}{T}\\right)\\right] $$ This represents a sinusoidal wave function, where $E(x,t)$ is the electric field of the light wave at a position $x$ and at time $t$. Here’s what the terms mean: $E^0$ is the amplitude of the wave, which indicates the maximum strength of the electric field. $\\lambda$ (lambda) is the wavelength of the light, which is the distance over which the wave’s shape repeats. $T$ is the period of the wave, which is the time it takes for one complete cycle of the wave to pass a point. ($\\frac{1}{T} = \\nu$) The reason both $\\lambda$ and $T$ are present in the equation is because they describe different aspects of the wave: $\\lambda$ describes the spatial repetition of the wave along the $x$-axis. $T$ describes the temporal repetition of the wave along the $t$-axis (time). The term $\\frac{x}{\\lambda} - \\frac{t}{T}$ is the phase of the wave, which determines the position of the peaks and troughs of the wave at any given time $t$ and position $x$. It’s not meant to equal zero; instead, it changes with time and position to represent the propagation of the wave through space and time. The phase changes as time goes by, indicating that the peaks and troughs of the wave are moving. If $\\frac{x}{\\lambda} - \\frac{t}{T}$ were always zero, it would imply a stationary wave, not a propagating one. The product $2\\pi$ times the phase gives you the argument of the sine function in radians, which is necessary because the sine function is periodic with a period of $2\\pi$. This means that the wave repeats itself every $2\\pi$ radians, which corresponds to one wavelength in space and one period in time. Plot codes import matplotlib.pyplot as pltimport numpy as npdef waveFun(x, t = 0, lamb = 1, pi = np.pi, T = 1, E0 = 1): E = E0 * np.sin(2 * pi * (x/lamb - t/T)) return E Y = range(-50,50)X = range(0,100)Points = []for x in X: for y in Y: Dis = np.sqrt((x/10)**2 + (y/10)**2) Points += [[x, y, waveFun(Dis)]]Points = np.array(Points)plt.figure(figsize=(7, 5))plt.scatter(Points[:, 0], Points[:, 1] + 0.5, c= Points[:, 2], marker='o', cmap=plt.cm.coolwarm,)plt.show() Example 1: Single Location Position Let’s set the $\\lambda$ as 1, T as 10, and x = 0. Then, the equation could be simplified as $E(0, t) = sin[2\\pi(0 - \\frac{t}{10})]$. And the change of the E0 with T could be show as the animation below. The E0 corresponded with the t Static View by using x axis as t Example 2: Multiple Observation Locations If we observe more positions, let’s say, 0 to 10, and using the full function, we could get an animation like below. This is the propagating wave we could observe in 10 different locations. © psu Direction of the Wave When t increases, x increases =&gt; “+” direction on x; When t increases, x decreases =&gt; “-” direction on x. Speed of the Wave $velocity = \\frac{\\lambda}{T} = \\lambda \\nu$ $\\nu$ id frequency ($\\frac{1}{T}$) of the wave. So, the light of the wave is: $c = \\lambda \\nu$ Energy of the Wave Energy of a wave is proportional to the square of the amplitude (in classical mechanics) $\\rho(\\nu)$: energy per unit volume $$ \\rho(\\nu) = constant\\ x (E^ o)^ 2 $$ Classic: Energy is dependent on amplitude QM: Energy is dependent on frequency Commonly used notation Wave Vector ($k$): The wave vector is defined as $\\frac{2\\pi}{\\lambda}$, where $\\lambda$ is the wavelength of the wave. The wave vector points in the direction of the wave’s propagation and has a magnitude equal to the number of wave cycles per unit distance. The notation $\\hat{k}$ represents a unit vector in the direction of $k$, so the wave vector $k$ is sometimes written as $\\frac{2\\pi}{\\lambda} \\hat{k}$, emphasizing its direction. Angular Frequency ($\\omega$): This is defined as $2\\pi\\nu$, where $\\nu$ is the frequency of the wave. It represents how many radians the wave cycles through per unit time. Phase ($\\phi$): The phase is a term that allows us to specify where in its cycle the wave is at $t = 0$ and $x = 0$. It lets us define the “zero point” or starting point of the wave at a place other than the origin of our coordinate system. $$E(x,t) = E^0 \\sin(kx - \\omega t + \\phi)$$ $$H(x,t) = H^0 \\sin(kx - \\omega t + \\phi)$$ Why Standard Form? The first function form expresses the wave in terms of its wavelength λ and period T, which are perhaps more intuitive when you're first learning about waves. It makes it very clear that the wave repeats itself every wavelength λ in space and every period T in time. The second function is the standard form. It's particularly useful in more advanced topics like wave interference, diffraction, and quantum mechanics, where the concept of phase space and the relationship between position and momentum (or wavelength and frequency) are crucial. For example, when you want to mimic the interference of the wave, the previous function could became extreamly complcated because the only difference between two wave is phase. More descriptions These equations describe how the electric and magnetic fields oscillate as a function of space and time, which is characteristic of electromagnetic waves such as light. The quantities $E^0$ and $H^0$ are the maximum strengths of the electric and magnetic fields, respectively. In an electromagnetic wave, the electric and magnetic fields are perpendicular to each other and to the direction of wave propagation. The equations show that both fields oscillate in sync (they have the same phase $\\phi$) but are described by separate equations since they are perpendicular components. The term $kx - \\omega t$ indicates that the wave is moving in the positive $x$-direction. If the wave were moving in the negative $x$-direction, the sign in front of $\\omega t$ would be positive. The factor $\\sin(kx - \\omega t + \\phi)$ varies between (-1) and (1), causing the electric and magnetic field strengths to oscillate between $-E^0$ to $E^0$ and $-H^0$ to $H^0$, respectively. The wave thus carries energy and, if it is light, can be observed as it interacts with matter. Huygen’s Principle (1678) Waves spread as if each region of space is behaving as a source of new waves of the same frequency and phase. So, Huygen’s principle applied to light showing a wave front. Diffraction When we konw d, D, X, and θ we could calcualate the λ (wave length): When the light patten shows the dark point, we know that the phase between two waves is $n\\frac{\\lambda}{2}$ So the $\\Delta \\phi$ of the first dark spot would be $\\frac{\\lambda}{2}$ According to the plot, the λ would be (path4 - path3) * 2 $ = \\frac{d}{2}sin\\theta$ When the angle is very small, we have $sin\\theta \\approx tan\\theta = \\frac{X}{2}\\frac{1}{D}$ So finally, we could get: $\\frac{d}{2}\\frac{X}{2D} = \\frac{\\lambda}{2}$ $\\lambda = \\frac{dX}{2D}$ Two wave interference (center: y1 = -15, y2 = 15) Three wave interference (y1 = 10, y2 = 0, y3 = -10) © gsu stlawu.edu $$ n\\lambda = d sin\\theta_n \\approx d tan\\theta_n = d \\frac{x_ n }{D} $$ Each photon is represented as a plane wave at the slits. The square of the amplitude of the recombined wave is proportional to the probability of finding the photon at this point Plot code import matplotlib.pyplot as pltimport numpy as npimport pandas as pdY = range(-50,50)X = range(0,100)def waveFun(x, t = 0, lamb = 1, pi = np.pi, T = 1, E0 = 1): E = E0 * np.sin(2 * pi * (x/lamb - t/T)) return E def WaveE(X, Y, dy = 0): Points = [] for x in X: for y in Y: Dis = np.sqrt((x/10)**2 + (y/10)**2) Points += [[x, y + dy, waveFun(Dis)]] Points = np.array(Points) return PointsP1 = WaveE(X, Y, 0)P2 = WaveE(X, Y, 10)P3 = WaveE(X, Y, -10)P1 = pd.DataFrame(P1, columns = ['x', 'y', &quot;E1&quot;])P2 = pd.DataFrame(P2, columns = ['x', 'y', &quot;E2&quot;])P3 = pd.DataFrame(P3, columns = ['x', 'y', &quot;E3&quot;])TB = pd.merge(P1, P2)TB = pd.merge(TB, P3)TB['E'] = TB.E1 + TB.E2 + TB.E3fig, ax = plt.subplots(subplot_kw={&quot;projection&quot;: &quot;3d&quot;}, figsize=(6,6))ax.plot_trisurf(TB.x, TB.y, TB.E, vmin=TB.E.min() * 2, cmap=cm.coolwarm)plt.show()#plt.figure(figsize=(5, 5))#plt.scatter(TB.x, TB.y, c= TB.E, marker='o', cmap=plt.cm.coolwarm,)#plt.show() Principle of Superposition At the beginning of the story, let’s say there are two same waves with different $\\phi$ which: $\\phi_2 - \\phi_1 = \\pi$ In this case, the Intensity of this two wave is: $E^2_{sum} = (E_1 + E_2 )^2 = 0$ ps: Not $E^2_{sum} = E_1^2 + E_2^2 \\neq 0$ (Destructive interference) For Two Traveling Waves Two sine waves with the same amplitude but slightly different frequencies traveling at the same velocity in the same direction $ E(x,t) = E^o sin(k_1 x - \\omega _1 t) +E^o sin(k_2 x - \\omega _2 t) $ $ = 2 E^o cos [\\frac{[k_1 - k_2]}{2}x - \\frac{\\omega _1 - \\omega _2}{2}t] sin[\\frac{[k_1 - k_2]}{2}x - \\frac{\\omega _1 - \\omega _2}{2}t] $ Direction $$ 𝑛_1 \\cdot sin 𝜃_1 = 𝑛_2 \\cdot sin 𝜃_2 $$ pre { background-color:#38393d; color: #5fd381; } Extra Explore Becuase we konw: $E(x,t) = E^0 \\sin\\left[2\\pi \\left(\\frac{x}{\\lambda} - \\frac{t}{T}\\right)\\right]$ So, when we move to the 2D wave, we could have function: $E(x, y, t) = E^0 \\sin\\left[2\\pi \\left(\\frac{\\sqrt{x^2 - y^2}}{\\lambda} - \\frac{t}{T}\\right)\\right]$ In order to calcualte the 2D wave from the different emission location, we need to introduce the initial point b=(bx, by) $E(x, y, b_x, b_y, t) = E^0 \\sin\\left[2\\pi \\left(\\frac{\\sqrt{(x-b_x)^2 - (y-b_y)^2}}{\\lambda} - \\frac{t}{T}\\right)\\right]$ Plot codes import matplotlib.pyplot as pltimport numpy as npimport pandas as pdfrom sklearn.neighbors import NearestNeighborsimport pyvista as pvdef waveFun(x, y, bx =0, by = 0, t = 0, lamb = 1, pi = np.pi, T = 1, E0 = 1): E = E0 * np.sin(2 * pi * ((np.sqrt((x-bx)**2+(y-by)**2))/lamb - t/T)) return E X = np.arange(100, step = .1)Y = np.arange(-50,50, step = .1)X, Y = np.meshgrid(X, Y)Points = waveFun(X,X)X = np.arange(-50, 50, step = .1)Y = np.arange(-50, 50, step = .1)X, Y = np.meshgrid(X, Y)Points += waveFun(X,Y, lamb = .7, T = .7)plt.imshow(Points)plt.show()for i in range(200): i = (i-100)/20 X = np.arange(100, step = .1) Y = np.arange(-50 + i,50 + i, step = .1) X, Y = np.meshgrid(X, Y) Points += waveFun(X,Y)#plt.scatter(points_array[:, 0], points_array[:, 1] + 0.5, c= points_array[:, 2], marker='o', cmap=plt.cm.coolwarm,)#plt.show()# Create a PyVista point cloudpoint_cloud = pv.PolyData(points_array)point_cloud['point_color'] = point_cloud.points[:, 2]point_cloud.plot(point_size=5,scalars='point_color', cmap=&quot;jet&quot;, show_bounds=True)Y = range(-100,100)X = range(0,200)Points = []for x in X: x /=10 for y in Y: y /=10 E = 0 for by in np.arange(-10,11, .1): E += waveFun(x, y, 0, by) Points += [[x, y, E] ]points_array = np.array(Points)#plt.scatter(points_array[:, 0], points_array[:, 1] + 0.5, c= points_array[:, 2], marker='o', cmap=plt.cm.coolwarm,)#plt.show()# Create a PyVista point cloudpoint_cloud = pv.PolyData(points_array)point_cloud['point_color'] = point_cloud.points[:, 2]point_cloud.plot(point_size=5,scalars='point_color', cmap=&quot;jet&quot;, show_bounds=True)point_cloud = pv.PolyData(Points)volume = point_cloud.delaunay_3d(alpha = 5)shell = volume.extract_geometry()shell.plot(show_edges=True)TB = pd.DataFrame(Points, columns = ['x', 'y', 'E'])fig, ax = plt.subplots(subplot_kw={&quot;projection&quot;: &quot;3d&quot;}, figsize=(6,6))P = ax.plot_trisurf(TB.x, TB.y, TB.E, vmin=TB.E.min() * 2, cmap=plt.cm.coolwarm)plt.show()from scipy.interpolate import griddatadf =TBx1 = np.linspace(df['x'].min(), df['x'].max(), len(df['x'].unique()))y1 = np.linspace(df['y'].min(), df['y'].max(), len(df['y'].unique()))&quot;&quot;&quot;x, y via meshgrid for vectorized evaluation of2 scalar/vector fields over 2-D grids, givenone-dimensional coordinate arrays x1, x2,..., xn.&quot;&quot;&quot;x2, y2 = np.meshgrid(x1, y1)# Interpolate unstructured D-dimensional data.z2 = griddata((df['x'], df['y']), df['E'], (x2, y2), method='cubic')# Ready to plotfig = plt.figure()ax = fig.subplots(subplot_kw = {&quot;projection&quot;:'3d'})surf = ax.plot_surface(x2, y2, z2, rstride=1, cstride=1, cmap=plt.cm.coolwarm, linewidth=0, antialiased=False)ax.set_zlim(-1.01, 1.01)ax.zaxis.set_major_locator(LinearLocator(10))ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))fig.colorbar(surf, shrink=0.5, aspect=5)plt.title('Meshgrid Created from 3 1D Arrays')plt.show()","link":"/2024/01/18/LearnNotes/light/"},{"title":"Bioinfr: mtGenome","text":"The complete mitochondrial genome of Taxus cuspidata (Taxaceae): eight proteincoding genes have transferred to the nuclear genome © Kan et al. 2020 cite: Kan, Sheng Long , et al. “The complete mitochondrial genome of Taxus cuspidata (Taxaceae): eight protein-coding genes have transferred to the nuclear genome.” Bmc Evolutionary Biology 20.1(2020). Paper: click here © wikipedia Abstract BG: there have lots of Gymnosperms species but only a few of species have sequenced mitochondrial genome. Result: Complete mitogenome of Taxus cuspidate; It lost many genes Multiple tRNA and introns also have been lost gene cluster could be less conserved Few RNA sites were identified and may responsible for fewer introns and frequent gene losses Background Compared to chloroplast, only few of mitochondria genomes are available. Previous study on mitogenome revealed that Cycans and Ginko are represent the ancestral type of seed plants. Size; substitution; numerous of genes; introns and RNA editing sites; genome structure; repeats; turnover rates, and foreign sequence ratios are the arguments for mtGenome Comparing. All other gymnosperms except Conifer II have mtGenome of represented species. There are some ambiguity in relationship between Conifer, Pianceae, and Gnetales. Our experiment and data are every valuable for the world. Methods Mitochodiral DNA isolation, total RNA extraction, sequencing and mitogenome assembly of Taxus cuspidata graph TD; st1(Yong leaves) Ch1[DNase I] op1(Density Gradient Centrifugation) Ch2(RNAplant Plus Reagent) st2(Yong seeds) et(RNA) lii(Illumina) Oxf(Oxford Nanopore) st1-->op1; Ch1 -->|Remove DNA|op1; Ch2 --> st2; Ch1 -->|Remove DNA|st2; op1 -->et st2 -->et et -->|sequencing|lii et -->|sequencing|Oxf Oxford Nanopore First, approximately two micrograms of mitochondrial DNA was sheared by using Megaruptor approximately one microgram of mitochondrial DNA was sonicated to ~ 500 bp using the Covaris M220 system The sonicated DNA was purified using a TIANgel Midi Purification Kit, and a sequencing library was constructed using the NEBNext® Ultra™ DNA Library Prep Kit for Illumina Megaruptor: The Megaruptor ® was designed to provide researchers with a simple, automated, and reproducible device for the fragmentation of DNA from 2 kb - 75 kb.Shearing performance is independent of the source, concentration, temperature, or salt content of a DNA sample. Illimina graph TD; R1((Raw Reads)) R2((H.Q. Reads)) Reads((Reads)) Con((Contigs)) Con2((Target Contigs)) Con3((Conf Contigs)) Con4((Contigs)) Con5((draft Contigs)) Con6((Contigs)) mt((mitogenome)) mt1((mitogenome)) mt2((mitogenome)) R1 --> |FastQC & Trimmomatic|R2 R2 -->|SPAdes|Con Con-->|blast against mt protein|Con2 Con2 --> | BLASR to mtDB| Con3 Con3 --> |Canu v1.7.1|Con4 R2 -->|Canu v1.7.1|Con6 Con4 --> |Pilon v1.22|Con5 Reads-->|bowtie2|MUMmer Reads-->|bowtie2|MUMmer2 Con4-->MUMmer Con5-->MUMmer Con5-->MUMmer2 Con6-->MUMmer2 MUMmer -->mt1 MUMmer2 -->mt2 mt1-->|MUMmer 3.0 and MAFFT v. 7|mt mt2-->|MUMmer 3.0 and MAFFT v. 7|mt mitogenome Annotation protein and rRNA: blast+ against Cycas taitungensis, Ginkgo biloba and Welwitschia mirabilis database. tRNA: tRNAscan-SE 2.0 introns: RNAweasel tool ORFs: ORF Finder ORFs-&gt; Blast2GO Visualization: OGDRAW RNA editing site identification identify: RES-Scanner predicting: PREP-Mt mt-genes to nuclear genome Depth of Sequencing Coverage: Bowtie2 v 2.2.9 &amp; SAMtools v 1.6 Realtime PCR: quantify the copy number of all protein coding genes (singlecopy nuclear gene LEAFY as an experimental control) Identification of repeats, tandem repeats, Bpu elements and foreign sequences Repeasts: ROUSFinder.py tandem repeats: Tandem Repeats Finder Plastid-derived mtDNA (MTPTs) &amp; Bpu-like elements: Guo et al. (span title here) MIPTs: blastn (against to genome and mitogenome) Bpu-like elements: blastn (using the Cycas Bpu consensus sequence as a query) nuclear-derived repetitive sequences: RepeatMasker web server Shared DNAs and gene cluster analyses (mtDNA shared between species) blastn with a word size of 7 and an e-value cutoff of 1 × 10− 6. Syntenic relationships were generated using Circos v. 0.69 Evolutionary rate heterogeneity test mitochondrial protein-coding genes Ran et al. : Sequence alignment; unreliable sequence alignment filtering; synonymous (dS); nonsynonymous length calculations (dN); absolute nonsynonymous(RN); synonymous rate (RS). Effects of C-to-U RNA editing: predicted editing sites were excluded Result Mitogenome size and gene and intron contents of Taxus cuspidata Category Size Size 468,924bp gene 46 protein 32 tRNA 10 rRNA 3 small subunit ribosomal protein 4 large subunit ribosomal protein 2 cytochrome C biogenesis 4 transport membrane protein 1 maturaserelated protein 1 Intron group I introns 0 group II introns 15 (cox2, nad1,nad2, nad4, nad5 and nad7 ) cis-spliced 4 trans-spliced 11 tRNA native tRNA 9 plastids tRNA 1 rRNA copies rrn5 &amp; rrn26 1 rrn18 2 Category Length genes 225 -4104bp exons 22 - 1224bp introns 804 - 2461bp nine, one, one, three, and five encoding mitochondrial respiratory chain complexes I, II, III, IV, and V, respectively. Variation in gene and intron Comparing groups: Taxus, Pinus, Welwitschia, Cycas and Ginkgo. Cycas Ginkgo Pinus Welwitschia Taxus mitogenome Size 414,903 346,544 1,191,054 978,846 468,924 GC% 46.9 50.4 47 53 50.39 tRNAs 27 23 12 8 10 rRNAs 3 3 6 3 4 Protein coding 41 41 41 29 32 ORF 3945 (414,858 bp) 3944 (323,967 bp) 10,587 (1,191,015 bp) 11,171 (978,799 bp) 3923 (468,857 bp) Introns 26 25 26 10 15 Predicted edit sites 1206 1306 1179 225 1102 Repeats (kb) 80 (19.2%) 32 (9.3%) 170 (14.2%) 50 (5.0%) 62 (13.2%) Tandem repeats (kb) 22 (5.3%) 3.6 (1.1%) 71 (6.0%) 24 (2.5%) 48 (10.2%) Plastid-derived (kb) 19 (4.6%) 0.3 (0.1%) 5.6 (0.5%) 7.9 (0.8%) 0 (0%) Nuclear-derived repetitive (kb) 3.4 (0.8%) 1.9 (0.6%) 5.3 (0.5%) 2.5 (0.3%) 3.5 (0.8%) Lost Genes 8+1 8+2 Homologous transcripts of eight of the nine lost mitochondrial genes (excluding rpl10) were found in the transcriptome of Taxus cuspidata © Kan et al. 2020 RNA editing site abundance and efficiency RES-Scanner efficiency: 0.05; 974 C-to-U 791 them are on protein-coding genes 730 were in coding regions 61 were in introns 1 in tRNA 2 in rRNA 180 in intergenic regions first and second codon positions have higher editing efficiencies nonsilent editing sites have higher editing efficiencies than silent sites PREP-Mt: only nonsilent RNA editing sites in proteincoding genes could be predicted cutoff score: 0.2 1102 C-to-U editing sites only 474 were identical … © Kan et al. 2020 Structural and gene cluster dynamics DNA shared by Cycas and Ginkgo up to 200 bp (about 1/2) Shared by Cycas and other three are short. (30 ~ 50) Repeats, tandem repeats, and foreign DNA sequences Cycas and Pinus mitogenomes contain more dispersed repeats In addition, most repeats had more than two copies in the Cycas and Pinus Plastid-derived sequence (&gt; 100bp) not found in Taxus. nuclear-derived repetitive sequences found in five species. … Variation in nucleotide substitution rates although eight putatively transferred genes in Taxus and Welwitschia were still found in the mitogenomes of Cycas, Ginkgo and Pinus, their synonymous and nonsynonymous substitution rates were higher than those of other mitochondrial genes Discussion Separate losses of multiple mitochondrial protein-coding genes in Taxus and Welwitschia Only two genes were lost in the first approximately 300 myr of land plant evolution if maturase is not considered parallel gene losses documented in hornworts, lycophytes, and ferns also happened in more recent times In angiosperms, a large number of protein-coding genes have been lost in some lineages, … Separate losses of multiple mitochondrial tRNA genes in Pinaceae, Taxus and Welwitschia all gymnosperms have three rRNA genes in their mitogenomes. the number of tRNAs differs greatly Frequent losses and cis- to trans-splicing of introns in the mitogenomes of gymnosperms Both the ancestral angiosperm and gymnosperm mitogenomes contain 26 group II introns. Cycas and Ginkgo, have 26 and 25 introns, whereas only ten introns are found in Welwitschia. Mechanisms for intron loss: genomic deletion exonization gene conversion EGT: rpl2i846 and rps10i235 retroprocessing (a reverse transcriptase-mediated model) Gene clusters could be less conserved in gymnosperms, and transposable elements and specific repeats are rare in the Taxus and Welwitschia mitogenomes … The number of RNA editing sites is not correlated with the GC content of mitochondrial genes Taxus cuspidata: results showed that all editing sites are C-to-U conversions … Size variation in gymnosperm mitogenomes is still a mystery …","link":"/2020/06/23/LearnNotes/mtGenome/"},{"title":"Basic Mathematics Calculating","text":"Sum The sum symbol, represented by the Greek letter sigma (Σ), is widely used in mathematics to denote the summation of a sequence of numbers or expressions. When you see this symbol, it means you should add up a series of numbers according to the specified rule. Here’s a breakdown of how it’s typically used: Basic Structure The summation symbol is written as: $$ \\sum_{i=a}^{b} f(i) $$ where: $i$ is the index of summation, which takes on each integer value from $a$ to $b$, inclusive. $a$ is the lower limit of summation, the starting value of $i$. $b$ is the upper limit of summation, the ending value of $i$. $f(i)$ is the function of $i$ to be summed over the range from $a$ to $b$. Examples Sum of the first 5 natural numbers: $$ \\sum_{i=1}^{5} i = 1 + 2 + 3 + 4 + 5 = 15 $$ Here, $f(i) = i$, and you sum the values of $i$ from 1 to 5. Sum of the squares of the first 3 positive integers: $$ \\sum_{i=1}^{3} i^2 = 1^2 + 2^2 + 3^2 = 1 + 4 + 9 = 14 $$ In this example, $f(i) = i^2$, so you square each $i$ from 1 to 3 and then add them together. Sum of a constant over a range: Suppose you want to add the number 4, five times. The expression would be: $$ \\sum_{i=1}^{5} 4 = 4 + 4 + 4 + 4 + 4 = 20 $$ Here, $f(i) = 4$, which doesn’t depend on $i$. You’re essentially multiplying 4 by the number of terms (5 in this case). Two sums $$ \\sum_{i=1}^ {5}\\sum_{j=2}^ {6} ij $$ For this, you sum over $j$ from 2 to 6 for each value of $i$ from 1 to 5, and then sum those results. It’s like computing a series within another series. The operation proceeds as follows: First, fix $i$ at its starting value, 1. Then, for $i = 1$, sum over $j$ from 2 to 6, calculating $1 \\cdot j$ for each $j$ and adding them together. Repeat this process for each value of $i$ up to 5. Finally, sum all the results from the inner summations together. Let’s compute this step-by-step to see the result. The result of the double summation $\\sum_{i=1}^ {5}\\sum_{j=2}^ {6} ij$ is 300. This means that when you sum the product of $i$ and $j$ for each $i$ from 1 to 5 and each $j$ from 2 to 6, the total sum is 300. PS: in python: N= 0for i in range(1,6): for j in range(2,7): N += i*j How to Use Identify the sequence you need to sum. This could be a series of numbers, functions of an index, or even a constant value repeated several times. Determine the starting and ending indices ($a$ and $b$, respectively) for your summation. Write down the function or value to be summed as $f(i)$ for each $i$ in the range from $a$ to $b$. Compute each term in the series and add them together to find the total sum. Summation notation is a powerful tool in mathematics, especially for dealing with sequences and series, and it’s widely used in various fields such as statistics, physics, and finance. Product Notation Similarly, we have product notation, too. The product symbol is represented by the Greek letter pi (Π), not to be confused with the mathematical constant $\\pi$ (pi) used for the ratio of a circle’s circumference to its diameter. The product symbol is used to denote the multiplication of a sequence of numbers or expressions, just like the sum symbol is used for addition. $$ \\prod_{i=a}^{b} f(i) $$ where: $i$ is the index of multiplication, taking on each integer value from $a$ to $b$, inclusive. $a$ is the lower limit of the product, the starting value of $i$. $b$ is the upper limit of the product, the ending value of $i$. $f(i)$ is the function of $i$ to be multiplied over the range from $a$ to $b$. Examples Product of the first 5 natural numbers (also known as $5!$, factorial of 5): $$ \\prod_{i=1}^{5} i = 1 \\times 2 \\times 3 \\times 4 \\times 5 = 120 $$ This multiplies the values of $i$ from 1 to 5. In mathematics and particularly in machine learning, besides the summation (Σ) and product (Π) notations, another frequently used notation is the integral symbol (∫). While the summation and product notations deal with discrete sequences, the integral symbol is used for continuous functions and is fundamental in calculus. Integrals play a crucial role in various aspects of machine learning, especially in optimization, probability distributions, and understanding the area under curves (such as ROC curves). Integral Notation The basic structure of an integral is: $$ \\int_{a}^{b} f(x) , dx $$ where: $a$ and $b$ are the lower and upper limits of integration, respectively, defining the interval over which the function $f(x)$ is integrated. $f(x)$ is the function to be integrated over $x$. $dx$ represents an infinitesimally small increment of $x$, indicating that the integration is performed with respect to $x$. Importance in Machine Learning Optimization: Many machine learning models involve optimization problems where the goal is to minimize or maximize some function (e.g., a loss function in neural networks or a cost function in logistic regression). Integrals are essential in solving continuous optimization problems, especially when calculating gradients or understanding the behavior of functions over continuous intervals. Probability Distributions: In the context of probabilistic models and statistics, integrals are used to calculate probabilities, expected values, and variances of continuous random variables. For example, the area under the probability density function (PDF) of a continuous random variable over an interval gives the probability of the variable falling within that interval. Feature Extraction and Signal Processing: In machine learning applications involving signal processing or feature extraction from continuous data, integrals are used to calculate various features and transform signals into more useful forms. Kernel Methods: In machine learning, kernel methods (e.g., support vector machines) utilize integrals in the formulation of kernel functions, which are essential in mapping input data into higher-dimensional spaces for classification or regression tasks. Deep Learning: In the training of deep neural networks, integrals may not be explicitly visible but are conceptually present in the form of continuous optimization and in the calculation of gradients during backpropagation. Example Consider the problem of finding the area under a curve, which is a fundamental concept in machine learning for evaluating model performance (e.g., calculating the area under the ROC curve (AUC) for classification problems). If $f(x)$ represents the curve, the area under $f(x)$ from $a$ to $b$ can be computed by the integral: $$ \\text{Area} = \\int_{a}^{b} f(x) , dx $$ Other Frequently Used Notations This integral computes the total area under $f(x)$ between $a$ and $b$, providing a measure of the model’s performance over that interval. Integrals, along with summation and product notations, form the backbone of many mathematical operations in machine learning, from theoretical underpinnings to practical applications in data analysis, model evaluation, and optimization strategies. Beyond summation (Σ), product (Π), and integral (∫) notations, there are several other mathematical symbols and concepts that are frequently used in machine learning and statistics. These include: Gradient (∇) The gradient is a vector operation that represents the direction and rate of the fastest increase of a scalar function. In machine learning, the gradient is crucial for optimization algorithms like gradient descent, which is used to minimize loss functions. The gradient of a function $f(x_1, x_2, \\ldots, x_n)$ with respect to its variables is denoted by: $$ \\nabla f = \\left( \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}, \\ldots, \\frac{\\partial f}{\\partial x_n} \\right) $$ Partial Derivative (∂) The partial derivative represents the rate of change of a function of multiple variables with respect to one of those variables, keeping the others constant. It’s denoted by the symbol ∂. Partial derivatives are essential in the calculation of gradients and in the optimization of machine learning models. Expectation (E) The expectation or expected value of a random variable is a fundamental concept in probability and statistics, denoted by $E[X]$ for a random variable $X$. It represents the average or mean value that $X$ takes over its probability distribution and is crucial in understanding the behavior of models, especially in probabilistic settings. Variance (Var) and Standard Deviation (σ) Variance measures the spread of a random variable’s values and is denoted by $Var(X)$ or $\\sigma^2$ for a random variable $X$. The standard deviation, $\\sigma$, is the square root of the variance and provides a measure of the dispersion of data points around their mean value. These concepts are vital in assessing the reliability and performance of models. Covariance and Correlation Covariance and correlation measure the relationship between two random variables. Covariance indicates the direction of the linear relationship between variables, while correlation measures both the strength and direction of this linear relationship. Understanding these relationships is essential in features selection and in modeling the interactions between variables. Big O Notation (O) Big O notation is used to describe the computational complexity of algorithms, which is crucial in machine learning for understanding the scalability and efficiency of models and algorithms. For example, an algorithm with a complexity of $O(n^2)$ means its execution time or space requirements increase quadratically as the input size $n$ increases. Matrix Notations and Operations Matrices and vectors are fundamental in machine learning for representing and manipulating data. Operations such as matrix multiplication, transpose, and inversion are essential for linear algebra, which underpins many machine learning algorithms, including neural networks, PCA (Principal Component Analysis), and SVMs (Support Vector Machines). Each of these mathematical concepts plays a crucial role in the formulation, analysis, and implementation of machine learning algorithms. They provide the theoretical foundation for understanding model behavior, optimizing performance, and evaluating outcomes in a wide range of applications. Matrix Calculating Matrix multiplication is a fundamental operation in linear algebra with extensive applications in mathematics, physics, engineering, computer science, and particularly in machine learning and data analysis. The way matrix multiplication is defined—by taking the dot product of rows and columns—might seem arbitrary at first, but it’s designed to capture several important mathematical and practical concepts. Understanding how to perform basic operations with matrices—addition, subtraction, multiplication, and division (in a sense)—is crucial in linear algebra, which is foundational for many areas of mathematics, physics, engineering, and especially machine learning. Here’s a brief overview of each operation: $$ \\begin{pmatrix} a_{11} &amp; \\cdots &amp; a_{1j} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{i1} &amp; \\cdots &amp; a_{ij} \\end{pmatrix} $$ Each element within the matrix is a pair $(i,j)$, where $i$ is the row index and $j$ is the column index. Matrix Addition and Subtraction Matrix addition and subtraction are straightforward operations that are performed element-wise. This means you add or subtract the corresponding elements of the matrices. For these operations to be defined, the matrices must be of the same dimensions. Addition: If $A$ and $B$ are matrices of the same size, their sum $C = A + B$ is a matrix where each element $c_{ij}$ is the sum of $a_{ij} + b_{ij}$. Subtraction: Similarly, the difference $C = A - B$ is a matrix where each element $c_{ij}$ is the difference $a_{ij} - b_{ij}$. Example: If $A = \\begin{pmatrix} 1 &amp; 2 \\\\ 3 &amp; 4 \\end{pmatrix}$ and $B = \\begin{pmatrix} 5 &amp; 6 \\\\ 7 &amp; 8 \\end{pmatrix}$, then $A + B = \\begin{pmatrix} 1+5 &amp; 2+6 \\\\ 3+7 &amp; 4+8 \\end{pmatrix} = \\begin{pmatrix} 6 &amp; 8 \\\\ 10 &amp; 12 \\end{pmatrix}$ $A - B = \\begin{pmatrix} 1-5 &amp; 2-6 \\\\ 3-7 &amp; 4-8 \\end{pmatrix} = \\begin{pmatrix} -4 &amp; -4 \\\\ -4 &amp; -4 \\end{pmatrix}$ Matrix Multiplication Matrix multiplication is more complex and involves a dot product of rows and columns. For two matrices $A$ and $B$ to be multiplied, the number of columns in $A$ must equal the number of rows in $B$. If $A$ is an $m \\times n$ matrix and $B$ is an $n \\times p$ matrix, the resulting matrix $C = AB$ will be an $m \\times p$ matrix where each element $c_{ij}$ is computed as the dot product of the $i$th row of $A$ and the $j$th column of $B$. Example: If $A = \\begin{pmatrix} 1 &amp; 2 \\\\ 3 &amp; 4 \\end{pmatrix}$ and $B = \\begin{pmatrix} 5 &amp; 6 \\\\ 7 &amp; 8 \\end{pmatrix}$, then $AB = \\begin{pmatrix} (1× 5 + 2× 7) &amp; (1× 6 + 2× 8) \\\\ (3× 5 + 4× 7) &amp; (3× 6 + 4× 8) \\end{pmatrix} = \\begin{pmatrix} 19 &amp; 22 \\\\ 43 &amp; 50 \\end{pmatrix}$ Matrix Division Matrix division as such doesn’t exist in the way we think of division for real numbers. Instead, we talk about the inverse of a matrix. For matrix $A$ to “divide” another matrix $B$, you would multiply $B$ by the inverse of $A$, denoted as $A^{-1}$. This operation is only defined for square matrices (same number of rows and columns), and not all square matrices have an inverse. Multiplying by the Inverse: If you want to solve for $X$ in $AX = B$, you can multiply both sides by $A^{-1}$, assuming $A^{-1}$ exists, to get $X = A^{-1}B$. Example: If $A = \\begin{pmatrix} 1 &amp; 2 \\\\ 3 &amp; 4 \\end{pmatrix}$, and its inverse $A^{-1} = \\begin{pmatrix} -2 &amp; 1 \\\\ 1.5 &amp; -0.5 \\end{pmatrix}$, and you want to “divide” $B = \\begin{pmatrix} 5 &amp; 6 \\\\ 7 &amp; 8 \\end{pmatrix}$ by $A$, you would compute $A^{-1}B$. Key Points Addition/Subtraction: Element-wise operation requiring matrices of the same dimensions. Multiplication: Involves the dot product of rows and columns, requiring the number of columns in the first matrix to equal the number of rows in the second. Division: Not directly defined, but involves multiplying by the inverse of a matrix. pre { background-color:#38393d; color: #5fd381; }","link":"/2024/02/11/LearnNotes/math-cal/"},{"title":"NMF: Non-negtive matrix factorization","text":"NMF: Non-negtive matrix factorization video instroctrions: Non-Negative Matrix Factorization (NMF) | Multiplicative Update Rules By Lee And Seung; 2020; Youtube Non-negative Matrix Factorization (NMF) Implementation; 2020; Youtube Blog and Papers: Github codes: ahmadvh; 2019 QColeman97; 2019 Bacground non-negtive matrix factorization (NMF) is an unsupervised machine learning technique created by Lee &amp; Seung in 1999. It is a verstile algorithm Makes a parts-based-representation ofits input data Non-nectivity of input data allows this Uses Dimensionality reduction Data compression and approximation Audio source separation Text topic extraction All input data should be positive numbers Nonnegative Matrix Factorization: An Analytical and Interpretive Tool in Computational Biology[1] This paper reviewed the principle algorithm of the NMF and both its advantage and disadvantage in the biology data. Molecular pattern discovery In cell level: In the gene and protein expresion profile → expressoin pattern find functional biological groups gene level A group of functional gene: functional cell group Sequence level: Sequence pattern among proteins. Cancer type clustering, subclustering searching. genomic hybridization data: patient subgroup Class comprision and prediction Supevised learning framewaork Identify differential expression gene with ANOVA. Classification methods or protein folding recognision. Cross-Platform and Cross-Species Characterization reduce noise capturing invariant biological features use of prior knowledge basd on existing datasets and generate new data Biomedical Information NPL PS: NPL: Topic modelling using NMF[2] Functional Characterization of Genes find the homogeneous functional group by the Gene ontology batabase This methodology is implemented in the program called GENERATOR (GENElist Aimed Theme- discovery execuTOR). Devarajan, Karthik. “Nonnegative matrix factorization: an analytical and interpretive tool in computational biology.” PLoS computational biology 4.7 (2008): e1000029. ↩︎ CHIRA GOYAL; Part 15: Step by Step Guide to Master NLP – Topic Modelling using NMF; 2021(https://www.analyticsvidhya.com/blog/2021/06/part-15-step-by-step-guide-to-master-nlp-topic-modelling-using-nmf/) ↩︎","link":"/2021/11/07/LearnNotes/nmf/"},{"title":"Negative Binomial Distribution | Introduction and examples","text":"Negative Binomial Experiment The experiment consists of x repeated trials. Each trial can result in just two possible outcomes. We call one of these outcomes a success and the other, a failure. The probability of success, denoted by P, is the same on every trial. The trials are independent; that is, the outcome on one trial does not affect the outcome on other trials. The experiment continues until r successes are observed, where r is specified in advance. Consider the following statistical experiment. You flip a coin repeatedly and count the number of times the coin lands on heads. You continue flipping the coin until it has landed 5 times on heads. This is a negative binomial experiment because: The experiment consists of repeated trials. We flip a coin repeatedly until it has landed 5 times on heads. Each trial can result in just two possible outcomes - heads or tails. The probability of success is constant - 0.5 on every trial. The trials are independent; that is, getting heads on one trial does not affect whether we get heads on other trials. The experiment continues until a fixed number of successes have occurred; in this case, 5 heads. Cite: Stat Trek[1] Geometric distribution is a special case of the negative binomial distribution. $$ b(x; r, P) = C_{x-1}^{r-1} \\times P^r \\times (1 - P)^{x - r} $$ $x$: The number of trials required to produce r successes in a negative binomial experiment. $r$: The number of successes in the negative binomial experiment. $P$: The probability of success on an individual trial. $Q$: The probability of failure on an individual trial. (This is equal to 1 - P.) $b(x; r, P)$: Negative binomial probability - the probability that an x-trial negative binomial experiment results in the rth success on the xth trial, when the probability of success on an individual trial is P. $C_n^r$: The number of combinations of n things, taken r at a time. The Mean of the Negative Binomial Distribution $μ = r / P$ $μ$ is the mean number of trials $r$ is the number of successes $P$ is the probability of a success on any given trial. Alternative Views of the Negative Binomial Distribution $μ_ R = kP/Q$ $R$: The negative binomial random variable $k$: the number of successes before the binomial experiment results in k failures $μK = rQ/P$ $K$: The negative binomial random variable $r$: the number of failures before the binomial experiment results in r successes Geometric Distribution The geometric distribution is a special case of the negative binomial distribution. It deals with the number of trials required for a single success. Thus, the geometric distribution is negative binomial distribution where the number of successes ® is equal to 1. Cite: Stat Trek[1:1] $ b(x; r, P) = C_{x-1}^{r-1} \\times P^r \\times (1 - P)^{x - r} $ $b(x; 1, P) = C_{x-1}^{0} \\times P^1 \\times (1 - P)^{x - 1}$ $b(x; 1, P) = P^1 (1 - P)^{x - 1}$ $b(x; 1, P) = P Q^{x - 1}$ Geometric Probability Formula. Suppose a negative binomial experiment consists of x trials and results in one success. If the probability of success on an individual trial is P, then the geometric probability is: $$ g(x; P) = P Q^ {x - 1} $$ Example Bob is a high school basketball player. He is a 70% free throw shooter. That means his probability of making a free throw is 0.70. During the season, what is the probability that Bob makes his third free throw on his fifth shot?[1:2] From the example, we can know: $P = 0.7$ $x = 4$ $r = 3$ So, we can have: $b(5; 3, .7) = C_{4}^{2} \\times P^3 \\times (1 - P)^{5-3}$ $b(5; 3, .7) = C_{4}^{2} \\times 0.7^3 \\times 0.3^2$ $b(5; 3, .7) = 6 \\times 0.7^3 \\times 0.3^2 $ $b(5; 3, .7) = 18.522 % $ Stat Trek: Negative Binomial Distribution ↩︎ ↩︎ ↩︎","link":"/2021/04/11/LearnNotes/negbinomial/"},{"title":"Obesity and Aging in the Drosophila Model","text":"Cite: Christoph Heier, Svitlana Klishch, Olha Stilbytska, Uliana Semaniuk, Oleh Lushchak, The Drosophila model to interrogate triacylglycerol biology, Biochimica et Biophysica Acta (BBA) - Molecular and Cell Biology of Lipids, Volume 1866, Issue 6, 2021, 158924, ISSN 1388-1981, https://doi.org/10.1016/j.bbalip.2021.158924. Abstract Researches of the relation between obesity and aging. Obesity types: high-fat diet high-sugar diet Energy Homeostasis in Drosophila nad Humans Circulating and Stored Sources of Energy Trehalose is the predominant sugar in flies (like the glycemia in human). Open circulation system: In human, hyperglycemia leades vascular related diseases. But drosophila has open circulation system, which means it’s vascular would not affected by hyperglycemia. Glycogen and lipid: Like mammals, extral energy material was stored in this way. Fat body consist of: polyploid multinucleate cells Regulation of the Energy Balance by the Insulin-Like and Glucagon-Like Pathways Eight insulin-like peptides (Ilp1–8) Insulin-like receptor, InR. glycemia control: Ilp2,3,5 which from median neurosecretory cells of the brain Regulation Pathway in Different Age: median neurosecretory cells: In laver: unable to sense circulating sugars regulated indirectly via the glucagon-like adipokinetic hormone (AKH), and several other hormones In adult: It sense circulating glucose directly, via a mechanism similar to mammalian pancreatic β cells Fat body Fat body-specific manipulations of the InR indicate that analogously to human insulin, the fly IIS is a positive regulator of fat storage. $InR\\uparrow \\ \\to fat\\ content\\uparrow$ $IIS\\downarrow \\ \\to fat\\ content\\uparrow$ IIS is responsible to glycogen storage. IIS positively regulates glycogen synthesis. An additional IIS-independent factor that promotes glycogen synthesis: ablation of the insulin-producing cells in the brain [32] or Ilp2-3,5 deficiency [33] lead to increased glycogen storage AKH $\\to$ hyperglycemic functions Corpora cardiaca is an endocrine organ which could produce AKH Laval: it was in ring gland. Adult: migrate towards the thorax, and attaches to the esophagus, and sends axon-like projections toward the brain and crop AKH: Mutatans: obeses. Over expression: lean phenotype. AKH does not induce catabolism of glycogen Glycogen levels rise upon Akh overexpression AKH is a hyperglycemic hormone (above two) Lifespan in Different Types of Fly Obesity HIhg Sugar Diet (HSD)-Induced Obesity HSD diet: 1. 30% sugar; 2. 50–150% increased fat. HSD effects: delays larval development reduces fecundity increases the age-independent mortality Galenza, et al.[1]: Increased early mortality of flies Lifespan extension by 31% Tânia Reis[2]: Early mortality has a bimodal distribution Lifespan was mildly increased HSD increased the expression of the Ilp2,3, and 5 but InR are not response to it due to the increased levels of te Ilp-binding protein, lipocalin neural Lazarillo. HSD-fed laval even resistance recombinant insulin. Adult: IIS independently of insulin resistance causing decreased expression of Ilp2, 3, and 5 the periphery remains insulin sensitive HSD-fed damage is simmilar to the Ilp2-3,5 triple mutants. HSD leads to dysfunction of pericardial nephrocytes (cells that simmilar like human kideny) which responsible to a shorter lifespan consequence. pharmacological inhibition of the hexosamine pathway extends the lifespan on HSD Reduction of fly fitness: short-term exposure to HSD: causes a long-lasting reprogramming of the signaling in the fat body Sugar overload: numerous fat body-unrelated processes Increases endoplasmic reticulum stereoisomerism Decreases immunity, disrupts gut homeostasis, and reduces commensal bacteria HSD: causes heart disorders such as fibrillations, asystolic periods, and arrhythmias, leading to progressive heart failure Heart: hexosamine flux nad the cardiac-specific reduction of this pathway fully protects the heart from the HSD-induced pathologies HSD without additional water access: hyperosmolarity or hypovolemia; reduced body water content; Dietary Restriction (DR) and the Paradox of Carbohydrate-Rich Diet DR: intermittent fasting leads to increased, compensatory feeding protein leverage hypothesis: reduction of proteins increases appetite. restriction of certain nutrients food dilution. Results: protein restriction increases both lifespan and fat reserves high carbohydrate/low protein diet extends lifespan, whereas the caloric restriction itself does not DR reduces IIS activity Lifespan extension in flies is mediated by the target of rapamycin (TOR) signaling pharmacological inhibition of the TOR pathway by rapamycin not only extends lifespan, but also increases fat reserves The HFD-Induced Obesity HFD: 20% to 30% coconut oil, or 15% lard. Leads to: obesity, hyperglycemia reduced cardiac contractility, ectopic accumulation of fat in the heart other pathologies reminiscent of the diabetic cardiomyopathy associated with lifespan reduction Increases TGF-β signaling: responsible for the development of insulin resistance genetically enhanced lipolysis targeted to the heart is sufficient to prevent the HFD-triggered cardiac dysfunctions overactivation of immune responses Obesity and Longevity in the Flies with Abrogated Reproduction Reduced reproduction is associated with increased fat accumulation and longevity… numerous treatments that result in longevity and excessive fat storage decrease fertility. some case: reduced reproduction correlates with obesity, but not with lifespan extension lifespan-extension associated with inhibition of breeding sometimes correlates with reduced fat reserves ecdysteroids the only steroid hormones in Drosophila, which could mediate the trade-offs between reproduction and lifespan reduced ecdysteroid levels or mild RNAi against the Ecdysone receptor (EcR) extends lifespan in males regulate maturation; reproduction; EcR acts as a negative regulator of fat accumulation in larvae. Genetic Links between Fat Storage and Lifespan attenuation of the IIS and TOR signaling—also result in obesity… long-lived Methuselah (Mth) mutants have increased starvation resistance Drosophila lines selected for longevity have increased resistance to starvation, suggesting higher energy reserves… increased starvation resistance resulted in increased fat storage, suggesting that longevity and obesity are determined by the same genetic variants… Nevertheless, there are also longevity selection lines without increased resistance to starvation Lifespan in Other Genetic Models of Obesity severe obesity can be triggered via inhibition of either lipolytic pathway: lipase Brummer: doubling of the fat, in a mild reduction of lifespan. AKH hormone signaling: fat is increased by around 75–100%; lifespan is reduced only moderately obesity associated with euglycemia can be triggered by manipulations of calcium signaling via Stim RNAi Pathways and Tissues Linking Lipid Metabolism and Lifespan The IIS and AKH Endocrine Systems HSD and HFD increase expression of the fly homolog of leptin, unpaired2 (upd2). typical models of fly obesity also have reduced insulin-like signaling. HSD in adult flies reduces expression of all three brain-produced Ilps, while the periphery remains insulin-sensitive. HFD leads to reduced peripheral IIS, and to insulin resistance HSD in flies leads to increased signaling via the analogous AKH hormone. HSD in adult flies reduces expression of all three brain-produced Ilps, while the periphery remains insulin-sensitive. The Fat Body The expression of hh(Hedgehog) increases upon starvation, when the Hh pathway promotes mobilization of lipid reserves in the fat body The Heart Under HFD, the apolipoproteins derived from cardiomyocytes, and not those produced by the fat body, are the predominate regulators of lipid metabolism The Immune Cells HFD: enhanced production of the macrophage-derived cytokine Upd3, HFD shortens lifespan solely via the Upd3-dependent inflammatory response, and not via the increase in fat storage. The Pericardial Nephrocytes HSD in flies leads to damage of the pericardial nephrocytes, which is a condition reminiscent of the diabetic nephropathy The Gut The JNK pathway promotes further overproliferation of intestinal stem cells, which is directly responsible for lifespan shortening. Experimental inhibition of the JNK pathway, or overexpression of Mag in the intestine increases fat reserves in old flies Moderate inhibition of the JNK pathway also extends lifespan Galenza, A.; Hutchinson, J.; Campbell, S.D.; Hazes, B.; Foley, E. Glucose modulates Drosophila longevity and immunity independent of the microbiota. Biol. Open 2016, 5, 165–173. [CrossRef] [PubMed] ↩︎ Reis, T. Effects of Synthetic Diets Enriched in Specific Nutrients on Drosophila Development, Body Fat, and Lifespan. PLoS ONE 2016, 11, e0146758. [CrossRef] [PubMed] ↩︎","link":"/2021/09/08/LearnNotes/ob-ag-fly/"},{"title":"CR9114","text":"Pan fluenza family CR9114 from VH1-69[1]: This antibody, derived from the VH1-69 gene segment, is known for its broad reactivity against both group 1 and group 2 influenza A viruses. CR9114 binds to a highly conserved epitope in the HA stem region. This region is involved in the fusion of the viral and host cell membranes, a critical step in the viral infection process. By binding to this region, CR9114 can block the conformational changes required for membrane fusion, thereby inhibiting viral entry into host cells. CR6261 from VH1-69[1:1]: Also originating from the VH1-69 gene segment, CR6261 specifically targets group 1 influenza A viruses. Like CR9114, CR6261 binds to the stem region of HA, but its binding is more restricted to group 1 viruses. This antibody stabilizes the pre-fusion form of HA, preventing the structural rearrangements necessary for the virus to fuse with the host cell membrane. FI6v3 from VH3-30[1:2]: Derived from the VH3-30 gene segment, FI6v3 is notable for its broad neutralizing activity against all known subtypes of influenza A viruses. This broad reactivity is achieved through its binding to a conserved epitope in the HA stem region, similar to CR9114 and CR6261. However, the precise mode of binding and the epitope details might differ, contributing to its unique broad-spectrum activity. CR8020[1:3]: CR8020’s mode of binding is distinct from the others. It targets a specific epitope in the HA stem region that is predominantly present in group 2 influenza A viruses. By binding to this site, CR8020 can inhibit the necessary conformational changes in the HA protein during the virus’s entry into the host cell, thereby neutralizing the virus. Five important hydrophobic pockets. © Wu, 2020[1:4] CR9114 Light Chain The CR9114 light chain contains a specific sequence motif in its CDR L3 region that is important for binding to the HA stem of the influenza A virus. The motif consists of two aromatic amino acids, Trp91 and Trp96, which are positioned toward the heavy chain with limited space in between. These aromatic residues participate in π-π stacking interactions with the HA protein, specifically with the tryptophan residue at position 91, which is located in the CDR L3 region.[2] Importance of CR9114 light-chain residues 91 and 96[2:1] Trp91: This tryptophan residue is located in the CDR L3 region of CR9114 and has been identified as a key residue for HA binding. It forms a π-π stacking interaction with the tryptophan residues in the HA stem, which is stabilized by hydrogen bonds between the amide and carbonyl groups. Small amino acid Ala at VL residue 96, which points toward the heavy chain with limited space in between The binding activity of CR9114 to the HA stem was found to be abolished when the non-aromatic amino acids threonine (T), arginine ®, or alanine (A) were substituted for the aromatic residue tryptophan at position 91. Similarly, substitution with aromatic amino acids tyrosine (Y) or phenylalanine (F) did not disrupt binding activity. This suggests that the presence of an aromatic residue at position 91 is essential for CR9114 binding to the HA stem.[2:2] Heavy Chain Y98, Y99, Y100, and Y100a in CDR H3 (heavy chain)[2:3] H95 and N97: the side chains of both VH H95 and VH N97 are not interacting with the HA stem epitope. Instead, both VH H95 and VH N97 form intramolecular interactions to stabilize the CDR H3 conformation. H95 H-bonds with VH S100b and VH S35 as well as interacts with VH Y100 via T-shaped p-p stacking N97 H-bonds with VH Y99 and VH S100b[2:4] Most CDR H3 variants are incompatible with CR9114 for HA stem binding[2:5] H95 and VH N97 stabilize the CDR H3 conformation[2:6] light chain 91, 96, and 98 insert into the hydrophobic pocket[2:7] Structure of CR9114, indicating the 16 AAs that differ between the germline and the somatic variant. Mutated residues (53) (16 positions) are shown in orange sticks. Residues IDs as labelled in orange are converted to the somatic sequence as in the PDB structure (table). Mutated residues required (53) for gaining affinity for H1, H3, and B HA are indicated in the table (+ required mutation, *mutation improves binding). Some key residues, such as F54 (HCDR2) and a quadruplet “YYYY” in HCDR3, are additionally displayed in magenta sticks. The heavy and light chains are shown in magenta and yellow, respectively.[3] CR9114 and CR6261 CDR1: CR9114: The I73 in the FR3 loop allows CR9114 to ﬂip into the hydrophobic groove of inﬂuenza H5 (Figure 3C) and H3 CR6261: D73: Its side chain has a different conformation and ﬂips out of the hydrophobic groove of H5. R30—D73 form a stable and preferable internal H-bond D73(FR3)—R30 (HCDR1) —Y32 (HCDR1) and A33(HCDR1)—G97 (HCDR3): expanded HCDR1 loop brings F29 into the groove nearby for interacting with the hydrophobic pocket of H5 CDR2: CR9114: polar S52 internal H-bond with Y98 (HCRD3) which can induce enlargement of the HCDR2 loop HCDR2 loop of CR9114 can block a larger space at the binding groove of HAs, and several residues at this loop can interact with H3 HA F54-W21(H3), CR6261: hydrophobic I52 backbone atoms of I52-G55/T56 and P52A-F54 pair form H-bonds → small and rigid HCDR2 loop of CR6261 CDR3: CR9114: 96GNYYYYSG100C It establishes crucial H-bonds with H5 HA (Y98-Q42, Y98/Y100A-D19) and H3 HA (Y98-T41/Q42, Y100A-D19) A short distance between Y99 (CR9114) to the backbone atom of V18 can induce a strong charge-charge interaction between CR9114 and HAs CR6261: 96MGYQVRET100C only Y98 can form an H-bond with a residue Longer distances between CR6261 residues and HA residues V18 and D19 result in very weak interactions: 7-8 Å for Q99–V18 and 11 Å for R100A-D19 Binding preference between CR9114 and CR6261 Anna L. Beukenhorst; 2022[3:1] W62 and W65 in the heavy-chain framework region 2 pre { background-color: #38393d; color: #5fd381; } ai { color: #3572A8; } Wu N C, Wilson I A. Influenza hemagglutinin structures and antibody recognition[J]. Cold Spring Harbor perspectives in medicine, 2020, 10(8): a038778. ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ Teo Q W, Wang Y, Lv H, et al. Stringent and complex sequence constraints of an IGHV1-69 broadly neutralizing antibody to influenza HA stem[J]. Cell Reports, 2023, 42(11). ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ Beukenhorst A L, Frallicciardi J, Koch C M, et al. The influenza hemagglutinin stem antibody CR9114: Evidence for a narrow evolutionary path towards universal protection[J]. Frontiers in Virology, 2022, 2: 1049134. ↩︎ ↩︎","link":"/2023/11/22/LearnNotes/panHA/"},{"title":"Cell-programmed nutrient partitioning in the tumour microenvironment.","text":"Cell-programmed nutrient partitioning in the tumour microenvironment. Cite: Reinfeld, Bradley I., et al. “Cell-programmed nutrient partitioning in the tumour microenvironment.” Nature 593.7858 (2021): 282-288. Abstract PET could use for toumor image. Cacncer Cell Marker: Glucose intacke; Lactate generated (Warburg metabolism) So as the umour-infltrating immune cells. As a result, the immune cell was restricted and evaluated. Thesis: immune cells dysregulated: cell-intrinsic programs or by competition? Our Solution: PET: tracers to measure the access to and uptake of glucose and glutamine Result: Intratumoral glucose: myeloid cells &gt; T cells &gt; Cancer cells cancer cells Cancer Cell &gt; all other cells Hypothesis: Metabolism in Result was: Programmed in cell-intrinsic manner through mTORC1 and related genes. Variation: tumour-resident cell: glutamine↓ → glucose↑ glutamine metabolism → glucose uptake↑ Conclusion: cell-intrinsic programs drive the preferential acquisition of glucose and glutamine by immune and cancer cells, respectively. Cell-selective partitioning of these nutrients could be exploited to develop therapies and imaging strategies to enhance or monitor the metabolic programs and activities of specifc cell populations in the TME. Intro Cancer cell; Rapidly proliferating cell, and activated immune cells: convert glucose to lactate very quickly. FDG PET imaging to detect cancer Resutl Figures Illustration A, B human renal cell carcinoma (RCC) and mouse subcutaneous MC38 tumours the mass spectrometry resutl C, D FDG PET on mouse E CD45⁺: Immune Cells CD45¯ in Tumour Cells F High FDG signle in Tumor cells. FDG in immune cell: CD45⁺ &gt; CD45¯ G, H CD45⁺ immune cells have No spatial distribution favouring I, J Same result shows in in mouse subcutaneous CT26 and renal carcinoma (Renca) tumours K orthotopic Renca tumours: FDG↑ in immune cells as compared to CD45¯ tumour cells I mouse model (GEMM) of breast cance has similar result Myeloid cells take up the most glucose Figures Illustration A, B FDG: TME T cells &gt; splenic T cells; TME T cells ≈ cancer cell suggesting that these cells are not deprived of glucose C, D myeloid cells (non-T cell CD45⁺ cells; CD11B⁺ selection) were isolated FDG: CD11B⁺ myeloid cells &gt; immune cells in MC38 tumors &gt; cancer cells E Two domain, LY6G−LY6Chi cells, from CD45⁺ CD11B⁺ MC38 tumour F Isolated F4/80hi cells had a histiocytic morpholog G, H high FDG avidity: M-MDSCs by microbeads(GR1⁺) TAMs by microbeads(F4/80⁺) I-K extracellular flux assays; ECAR; OCR TAMs and M-MDSCs consume the most glucose per cell in the TME and maintain robust glucose metabolism. mTORC1 programs metabolism in the TME mTORC1: supports anabolic metabolism and nutrient uptake pS6: monitor the mTORC1 pathway activity in tumour myeloid cells CD11B+ myeloid cells Cell type: Other CD45⁺ Cell: T cell CD45+ c :: To characterize the non-T cell CD45⁺ cells, myeloid CD11B⁺ (microbeads). CD3⁺: CD3⁺ T cells CD4⁺: CD4⁺ T cells) CD8⁺: CD8⁺ T cells CD11B⁺/CD45⁺: Myeloid: CD14; CA9 The hypothesis is mTORC1 which supports anabolic metabolism and nutrient uptake. pS6 is a protein which under the upstream of the mTOR signal pathway. Rapamycin can suppress the pS6 without affect the tumor’s weight, concentrations of glucose, glutamine; lactate in the TME; but led to significant decreases in pS6 levels, T cell infiltration, Ki67 levels in cancer cells and T cells, and the cell size of TAMs (Fig. 3d). Treatment with rapamycin also resulted in significant decreases in FDG uptake in myeloid and cancer cells. f, g, h show that Rapa led to a in myeloid cell metabolism ex vivo, whereas cancer cells and T cells remained unchanged decrease in myeloid cell metabolism ex vivo, whereas cancer cells and T cells remained unchanged Hk1 was broadly expresse, Hk2, the hexokinase isoforms 2, rate-limiting step of glycolysis was highly expressed in myeloid cells. iron transporter CD71 and the amino acid transporter CD98 This has implications for metabolism-directed agents as well as therapies that target myeloid cells, with the potential to either enhance or impair tumour-related inflammation. TME-resident cells have the capacity to increase glucose uptake like upreguate the mTOR singal pathway. Veh? : spleen vehicle; rapamycin- and the vehicle-treated samples; 8 mice for CD4+/CD8+ vehicle; glutamine plasma and TIF vehicle(5% Tween‐80, 5% PEG‐40??), Figures Illustration A FMO, PBMC, and ccRCC Ridgelines Different pS6 PE expression level in different group of cells. B C mouse MC38 tumours D mice bearing MC38 tumours: rapamycin (4 days) → measured FDG uptake Rapamycin did not affect: weight; concentrations of glucose, glutamine; lactate in the TME but pS6↓ significant, T cell infiltration↓, Ki67 levels↓ in cancer cells and T cells, and the cell size↓ of TAMs E MC38 tumour; Rapamycin: myeloid and cancer cells’s FDG uptake↓ (significant) F - H MC38 tumours Rapamycin: myeloid cell metabolism ex vivo↓ cancer cells and T cells remained unchanged I Untreated tumours: CPA and unbiased clustering based only on (metabolism-related transcripts) grouped samples by cell identity (RNA-Seq) J, K Rapamycin: (flow cytometry) HK1↓ across tumour cell populations HK2↓ specifically in TAMs potentially underlying the differences between tumour cell types in glucose uptake L, M Rapamycin: GLUT1: unchanged; protein levels of the iron transporter CD71 and the amino acid transporter CD98 ↓","link":"/2021/10/07/LearnNotes/paper-cancer-mi/"},{"title":"Integrins Form an Expanding Diffusional Barrier that Coordinates Phagocytosis","text":"Integrins Form an Expanding Diffusional Barrier that Coordinates Phagocytosis cite: Freeman, Spencer A., et al. “Integrins form an expanding diffusional barrier that coordinates phagocytosis.” Cell 164.1-2 (2016): 128-140. Brief To create the large zone of Src-family kinase (SFK) phosphorylation required for phagocytosis, a cascade of integrin activation, emanating from antigen contact sites, generates an expanding actin-based diffusion barrier that restricts the access of the bulky phosphatase molecules that target SFK. Highlights Tyrosine phosphatases are excluded from sites of phagocytosis An expanding diffusion barrier prevents phosphatase access to sites of phagocytosis Integrins activated by phagocytic receptors generate the diffusion barrier Activated integrins bridge sparse phagocytic receptors and coordinate phagocytosis Summary © Spencer A Freeman, et al. Phagocytosis activate Phagocytosis is initiated by lateral clustering of receptors, which in turn activates Src-family kinases (SFKs). Activation of SFKs requires depletion of tyrosine phosphatases from the area of particle engagement. Fcg The mobility of CD45 increased markedly upon engagement of Fcg receptors. While individual CD45 molecules moved randomly, they were displaced from the advancing phagocytic cup by an expanding diffusional barrier. By micropatterning IgG, the ligand of Fcg receptors, we found that the barrier extended well beyond the perimeter of the receptor-ligand engagement zone. Second messengers generated by Fcg receptors activated integrins, which formed an actin-tethered diffusion barrier that excluded CD45. The expanding integrin wave facilitates the zippering of Fcg receptors onto the target and integrates the information from sparse receptor-ligand complexes, coordinating the progression and ultimate closure of the phagocytic cup. Introduction Phagocytosis is initiated by a clustering of receptors. Fcg receptor could recognize the Fc portion of IgG in phagocytic response. The Multiplicity of IgG stimulate the Src-family kinase (SFKs) CD45 and CD148 on phagocytes are tyrosine phosphatases. SFKs activation needs the remove of phosphatases. Upon binding ligand, B/T cell receptors to form a central supermolecular activation center (cSMAC) phosphatases are displaced to the periphery exofacial domain of Fcg receptors is notably shorter (z6 nm) than phosphatases. So, how they excluded CD45 and CD148? integrins as progressive diffusional barriers that serve to integrate the signals emanating from immobile Fcg receptor microclusters. Result Activation of Fcg Receptors Increases the Mobility of CD45 (A) Human macrophages incubated with polystyrene beads opsonized with 0.5 mg IgG/107 particles. Cells were fixed after 45 s and stained for CD45 (green), pY (red), and IgG (cyan, inset). Scale bar, 10 μm. (B–F) Single CD45 particles were visualized in macrophages using anti-CD45 Fab fragments labeled with Qdots (B, inset). (B) Macrophages were seeded onto either BSA-coated or IgG-coated coverslips and particles tracked for 20 s at 33 Hz. CD45 trajectories were analyzed by MSS; the motion type for each trajectory is color coded as follows: blue, confined; cyan, free; and red, linear. Scale bar, 5 μm. (C–E) CD45 motion type ©, median confinement diameter (D), and median diffusion coefficient (E) for cells seeded on BSA (20 min), IgG (20 min), or BSA + LatA (15 + 5 min) were determined from 10-s recordings. Horizontal lines are means of ≥17 cells from three independent experiments; &gt;1,000 trajectories were analyzed per condition. (F) Three trajectories from (B) shown with color-coded time course. Depletion zones drawn in (B) and (F) delineate the area depleted of CD45. They were drawn to approximate the contour of the F-actin ring. (A) shows that the CD45 was depleted from the phagocytic site. But the pY was recruited. As a result, they formed a phagocytic cup which had py in the center which was circled by CD45 (B) shows the migration of the CD45 during the phagocytosis. Resting: When the cell didn’t perform phagocytosis 2/5/10 min: 2/5/10 min after the cell perform phagocytosis Contrary to the predictions made by the model of Yamauchi et al. (2012), fewer than 3% of the CD45 molecules moved linearly either at rest or during phagocytosis (Figures 1B and 1C). Yamauchi et al. (2012) proposed that myosin II facilitates the redistribution of CD45 during phagocytosis. © The different diffusion types of the CD45 contour with different particles. engaging Fcg receptors increased the fraction of CD45 undergoing free diffusion from 47% ± 14% to 70% ± 11% (means ± SD) at the expense of confined molecules, which decreased proportionately (D) the mean diameter of the remaining confinement zones increased. CD45 Is Progressively Displaced by a Diffusion Barrier MMS: diffusing freely Video evidence: CD45 bounce off the edge of the zone of depletion Play/Download: IgG dots on the slice: printed IgG onto glass coverslips The Area of Depletion of CD45 Extends beyond Regions of Microclustered Fcg Receptors This is a fine day. Fcg : Fcγ","link":"/2021/09/26/LearnNotes/paper-immune-integrins/"},{"title":"WGCNA: an R package for weighted correlation network analysis","text":"WGCNA: an R package for weighted correlation network analysis Peter Langfelder1 and Steve Horvath*2 Abstract Weighted gene co-expression network analysis is a method for describing the correlation patterns among genes across samples. WGCNA can find clusters (modules) of high correlated genes. Those gene clusters are called as module eigengene or intramodular hub gene. And WGCNA can masure the correlation of modules to one another or external traits. It can be used to identify candidate biomarkers or therapeutic targets. Background Functions of WGCNA: Cluster co-expression genes Correlation of modules to traits identification Significant modules identification Module annotation Define the network neighborhood Screen of nodes Contract network Results Overview of typical analysis steps and the rational behind them: © Peter Langfelder 2008 co-expression Using dynamic tree cut to idnetify modules. Correlation with traits: Clinical data, SNPs, proteomics ontology, functional enrichment find biology interest modules Module relationships Find the Key drivers in interesting modules 1. Gene Cluster Question: Soft Threadhold power??? 2. Module Detection 2.1 Algorithm Modules are defined as clusters of densely interconnected genes. hierarhical cluster is used to cluster the genes. Short Coming of this algorithm: Difficult determines how many clusters present in the data set. About how to determines the numbers of cluster [1] 2.2 Biological Meaning It could reflect: Biological signal Noise So, gene ontology information can be used. Algorithms of Modules detection Fuzzy measure of module membership Automatic block-wise module detection Consensus module detection 3. Module and Gene Selection ummmm… = = 4. Topological Properties To study about network concept. Whole Network Connectivity (degree) Intramodular Connectivity Topological Overlap Clustering Coefficient …Skip Mouse Data Application For computational reason, only 3600 most related genes are selected. 18 modules… © Peter Langfelder 2008 As is how in Graph D above, weight is mostly correlated to brown, red, and salmon. By GO enrichment result, we can find that brown is significantly enriched in categories “glycoprotein” and “signal”, red is enriched in “cell cycle”, and “salmon” is enriched in “chromosome”. Overall, it is biological meaningful. Figure E shows body weight between genes significant… 1. Dudoit S, Fridlyand J: A prediction-based resampling method for estimating the number of clusters in a dataset. Genome Biol 2002, 3(7):RESEARCH0036.","link":"/2020/07/07/LearnNotes/paper_WGCNA/"},{"title":"Impact of Fishmeal Replacement in Diets for Gilthead Sea Bream (Sparus aurata) on the Gastrointestinal Microbiota Determined by Pyrosequencing the 16S rRNA Gene","text":"Impact of Fishmeal Replacement in Diets for Gilthead Sea Bream (Sparus aurata) on the Gastrointestinal Microbiota Determined by Pyrosequencing the 16S rRNA Gene cite: Estruch, Guillem, et al. “Impact of fishmeal replacement in diets for gilthead sea bream (Sparus aurata) on the gastrointestinal microbiota determined by pyrosequencing the 16S rRNA gene.” PloS one 10.8 (2015): e0136389. © seamaxglobal.com Abstract Microbiota data was collected from stomach, foregut, midgut, and hindgut. Results: Reduce the survival ratio: 88% to 60% Microbiota of the water was also analysed inorder to study the mutual impact of the system. Alpha diversity has no significant different between diet switch groups. Photobacterium and Streptococcus which were highly represented in the AA0 and FM100 diets Proteobacteria was more related to wheatmeal, while Firmicutes were more abundant in fishmeal Aquaculture environment Flavobacteriaceae, Rhodobacteraceae, and Saprospiraceae are pretty common in Aquaculture environment. In this study, Rhodobacteraceae was found in higher percentages in wheatmeal group. This shows that food could affect the colonization of GIT by bacteria present in the surrounding water Diet switch Contributed the low survival ratio to anti-nutrition factors, tannins, for example. Enterobacteriaceae was abundant in wheatmeal in responsible to the digestion of polysaccharide. Corynebacterium, Propionibacterium, and Clostridium were abundant in fishmeal gut. Diversity and Richness were not significantly changed Higher percentage of Proteobacteria (Which related to high efficiency of nutrition absorption) variate in individuals? … a { position: relative; } a:active::after{ content: attr(title); white-space: nowrap; round: 90; position: absolute; top: 100%; background-color: #000000; color: #fff; border-radius: 5px; opacity:0.6; }","link":"/2020/12/29/LearnNotes/paper_dit_s_micro_1/"},{"title":"A Tissue-Mapped Axolotl De Novo Transcriptome Enables Identification of Limb Regeneration Factors","text":"A Tissue-Mapped Axolotl De Novo Transcriptome Enables Identification of Limb Regeneration Factors cite: Bryant, Donald M., et al. “A tissue-mapped axolotl de novo transcriptome enables identification of limb regeneration factors.” Cell reports 18.3 (2017): 762-776. Abstract cirbp and kazald1 as highly expressed and enriched in blastemas. cirbp palys and cytoprotective role in limb regeneration. It also verified the function of cirbp and kazald1 by modify their expression. Discussion cirbp is similar to RBM3 both cirbp and RBM3 are response to specific stressors (cold shock, hypoxia, UV…). cirbp prevent progenitor cell from death. cirbp are also detected in ealry and later stage, which may serves relatively undifferentiated and will be eliminated as the regenerating digits are sculpted. fus mRNA may regulated by the cirbp Kazald1 reducing the expression of kazald1 result deformed arm It’s a marker of the cancer cell","link":"/2021/01/17/LearnNotes/paper_regener_limb_salamender/"},{"title":"A partially self-regeneration synthetic cell","text":"A partially self-regeneration synthetic cell cite: Lavickova, Barbora, Nadanai Laohakunakorn, and Sebastian J. Maerkl. “A partially self-regenerating synthetic cell.” Nature communications 11.1 (2020): 1-11. An experiment of self-regeneration in synthetic cell which could sustain synthetic activities over a day by regenerating the important building blocks(protein components). Fundamental Theory: Self-replication: a set of instruction; external building blocks; energy – Von Neuman, 1940 Challenge of transcription-translation system: protein synthetic rate must be sufficient to regenerate necessary components; compounds should be functional synthesized; allows continuous and sustained regeneration PURE (protein synthesis using recombinant elements) system It could synthesize 70% of all E. coli protein co-expression of multiple PURE components in single batch Challenge: can’t tell which protein is functional or not Resolution: employ the experiments of transcription-translation reaction operating inside microfluidic reactor to demonstrate self-regeneration of essential components. Results Design © nature.com 8 independent 15 nL chamber reactor, (b); replacing 20% of of the reactor volume per 15min; replacing ration: energy:protein/ribosome:DNA = 2:2:1; 34℃ reaction environment; expressed a fluorescent protein(eGFP) three steps: kick-start -&gt; self-regeneration -&gt; washout aaRSs regeneration © nature.com","link":"/2020/12/15/LearnNotes/paper_synthetic_cell_regener_1/"},{"title":"Insect meal as renewable source of food for animal feeding: a review","text":"Insect meal as renewable source of food for animal feeding: a review cite: Sánchez-Muros, María-José, Fernando G. Barroso, and Francisco Manzano-Agugliaro. “Insect meal as renewable source of food for animal feeding: a review.” Journal of Cleaner Production 65 (2014): 16-27. Introduction Shortcoming of the soy protein: imbalances between essential and nonessential amino acids anti-nutrition factors high proportion fiber non-starch polysaccharides low palatability Nutrition Values protein Some of insect spices are higher methionine or leucine but not lysine than fish Fatty Acid Chitin increasing the activity of the immune system[1] and macrophage[2] increasing the growth rate and assimilation efficiency[3] increasing the growth performance through enhancement in bi-dobacterium[4]. Species feeding diets containing insects Poultry data show that replacing the fish meal with insect is applicable and sensible. the palatability is reduced may due to the crude fibre in the exo-skeleton Pigs[5] digestibility was decreased unfavorable Fish Fish Insect Increase Decrease Notes Clarias gariepinus Zonocerus variegatus 25%:- growth rate - nutrition utilisation- final mean body weight- FCR, SGR, PER Up to 50%:- negtive in growth performance- reduced digestibility of proteins and lipids [6] African catfish(C. gariepinus) 20%:growth and nutritive index similar to above [7] catla-rohu hybrids(Catlacatla x Labeo rohita) silkworm pupae similar to above [8] Cyprinus carpio silkworm pupae similar to above [8:1] channel catfish andtilapia (Oreochromis sp.) H. illucens (L.) No differences in the body weight and total length[9] rainbow trout(O. mykiss) H. illucens pre-pupae no effect on 25% of fishmeal and 38% of fish oil[10] rainbow trout(O. mykiss) H. illucens Normal H. illucens deit:growth enriched switch:no significant differences[11] a { position: relative; } a:active::after{ content: attr(title); white-space: nowrap; round: 90; position: absolute; top: 100%; background-color: #000000; color: #fff; border-radius: 5px; opacity:0.6; } Esteban, M.A., Cuesta, A.J., Ortuna, J., Mesegue, J., 2001. Immunomodulatory effects of dietary intake of chitin on gilthead seabream (Sparus aurata L.) innate immune system. Fish Shellfish Immunol. 11, 303e315. ↩︎ Sakai, M., Kamiya, R., Ishii, S., Atsuta, S., Kobayashi, M., 1992. The immunostimulating effects of chitin in rainbow trout Oncorhynchus mykiss. In: Shariff, M., Subasinghe, R.P., Arthur, J.P. (Eds.), Diseases in Asian Aquaculture. Asian Fisheries Society, Manila, Philippines, pp. 413e417. ↩︎ Kono, M., Matsui, T., Shimizu, C., 1987. Effect of chitin, chitosan, and cellulose as diet supplements on the growth of cultured fish. Nippon Suisan Gakkaishi 53, 125-12953. ↩︎ Spreen, K.A., Zikakis, J.A., Austin, P.R., 1984. The effect of chitinous materials on the intestinal microflora and the utilization of whey in monogastric animals. In: Zikakis, J.P. (Ed.), Chitin, Chitosan and Related Enzymes. Academic Press, Orlando, FL, USA, pp. 57e75 ↩︎ Newton, G.L., Booram, C.V., Barker, R.W., Hale, O.M., 1977. Dried Hermetia illucens larvae meal as a supplement for swine. J. Anim. Sci. 44, 395e400. ↩︎ Alegbeleye, W.O., Obasa, S.O., Olude, O.O., Otubu, K., Jimoh, W., 2012. Preliminary evaluation of the nutritive value of the variegated grasshopper (Zonocerus variegatus L.) for African catfish Clarias gariepinus (Burchell. 1822) fingerlings. Aquacult. Res. 43, 412e420. ↩︎ Ng, W.K., Liew, F.L., Ang, L.P., Wong, K.W., 2001. Potential of mealworm (Tenebrio molitor) as an alternative protein source in practical diets for African catfish, Clarias gariepinus. Aquacult. Res. 32, 273e280 ↩︎ Nandeesha, M.C., Srikanth, G.K., Varghese, T.J., Keshavanath, P., Shetty, H.P.C., 1988. Influence of silkworm pupa based diets on growth, organoleptic quality and biochemical composition of catlaerohu hybrid. In: Huisman, E.A., Zonneveld, N., Bouwmans, A.H.M. (Eds.), Aquaculture Research in Asia: Management Techniques and Nutrition. Proceedings of the Asian Seminar on Aquaculture. International Foundation for Science, Malang, Indonesia, pp. 211e221. ↩︎ ↩︎ Bondari, K., Sheppard, D.C., 1981. Soldier fly larvae as feed in commercial fish production. Aquaculture 24, 103e109. ↩︎ St-Hilaire, S., Sheppard, C., Tomberlin, J.K., Irving, S., Newton, L., McGuire, M.A., Mosley, E.E., Hardy, R.W., Sealey, W., 2007. Fly prepupae as a feedstuff for rainbow trout, Oncorhynchus mykiss. J. World Aquacult. Soc. 38, 59e67. ↩︎ Sealey, W.M., Gaylord, T.G., Barrows, F.T., Tomberlin, J.K., McGuire, M.A., Ross, C., StHilaire, S., 2011. Sensory analysis of rainbow trout, Oncorhynchus mykiss, fedenriched black soldier fly prepupae, Hermetia illucens. J. World Aquacult. Soc. 42, 34e45 ↩︎","link":"/2020/12/28/LearnNotes/paper_review_insectmeal/"},{"title":"PARTICLE-WAVE DUALITY","text":"Failure of Classical Mechanics Black Body Radiation Experiment: measure the radiation intensity as a function of frequency of the radiation emitted from a black body (a physical body that absorbs all incident electromagnetic radiation) at thermal equilibrium Model: Emitted radiation is classically due to oscillating electric dipoles within the material, acting like broadcast antennas. Classical expectation: higher temperature should result in a large increase in the radiation emitted at high frequencies (fast oscillation at high T) Gustav Kirchhoff The blackbody is an idealized physical body that absorbs all incident electromagnetic radiation (such as light), regardless of frequency or angle of incidence. A black body can also emit black-body radiation, which is solely determined by its temperature. Black-body Radiation Spectrum: Intensity vs. Wavelength Notic: the “Cold” object also emit “light” as long as its above the absolute zero (-273.15 °C). And it would appear “blakc” because the peak wavelength is in infrared range, which human eye cannot recognize. According to this theory, we could astimate the temperature of stars based on its color. webbtelescope astronomy.com Wien’s Displacement Law $ \\lambda _{max} = \\frac{W}{T} $ $ \\lambda _{max} $: Peak wavelength W: Wien’s constant = 2.9 e-3 m Kelvin T: Surfave temperature Exp: When λmax = 500nm: $T = \\frac{W}{\\lambda_ {max}} = \\frac{2.9 e^ {-3} mK}{500e^ {-9}m } = 5800K$ Rayleigh-Jeans law (Classical description of light) Predict the spectral irradiance (or spectral density) of a black body radiation as a function of wavelength or frequency for a fixed temperature. Spectrum Density (ν, T) = $\\frac{8\\pi\\nu^2}{ c^3 }k_BT$ c: speed of light kB = Boltzmann constant = 1.380649 × 10-23 J/K T: temperature ν: frequency Spectral density Density = radiance The power of radiation (W) passing a unit area (m2) within a unit solid angle (sr), within a unit time (s). It has the unit of W/(m2 × sr × s) Spectral density = Spectral radiance The radiance per unit wavelength (um) or per unit frequency (Hz), depending on if the power is measured over wavelength or frequency. Therefore, spectral density has the unit of W/(m2 × sr × s × um) or W/(m2 × sr × s × Hz). Unexpected Black Body Radiation: UV Catastrophe Conflict between observation and expectation Observation : Spectral density does not monotonically increase as the frequency increases. Classical expectation: According to the Rayleigh-Jean law, spectral density should increase as the frequency increases Reason: The classic oscillating field from electromagnetic radiation drives the motion of a spring - faster oscillation → higher frequency → higher energy For fix this conflict, a propportional model was given: E = nhν (Max Planck) n = 1, 2, 3… Planck’s constant (h) = 6.626×10−34 Js $$ \\rho (\\nu, T) = \\frac{8\\pi\\nu^2 h \\nu}{ c^3 } \\frac{1}{e^{\\frac{hv}{k_ BT}} - 1 } $$ Explained: - energy of photon (with frequent ν): hν - weight if photon population (ν): g(ν) = $\\frac{8\\pi \\nu ^2 }{c^ 3}$ - averagy number of photon (ν): n(#, T) = $\\frac{1}{exp(\\frac{h\\nu}{k_BT})-1}$ - ρ (νT)dν = hν × g(ν) × n(#, T) = $h\\nu × \\frac{8\\pi \\nu ^2 }{c^ 3} × \\frac{1}{exp(\\frac{h\\nu}{k_BT})-1}$ = $\\frac{8\\pi h \\nu^3}{ c^3 } \\frac{1}{e^{\\frac{hv}{k_ BT}} - 1 }$ In Planck Low, it show either high temperature or low frequency would case the “Ultralviolet catastrophe”: From the left to the right: $\\frac{8\\pi \\nu ^2 }{c^ 3}$ $\\frac{1}{exp(\\frac{h\\nu}{k_BT})-1}$ $\\frac{8\\pi h \\nu^3}{ c^3 } \\frac{1}{e^{\\frac{hv}{k_ BT}} - 1 }$ Plot Codes import numpy as npimport matplotlib.pyplot as pltdef Rayleigh_Jeans(v, T): kB = 1.380649 * 10**(0-23) c = 3 * 10**8 return (v**2) * 8 * np.pi * kB * T / (c**3)def Planck(v, T): h = 6.626*10**(0-34) kB = 1.380649 * 10**(0-23) return 1 /( np.e ** (h*v / (kB * T) ) - 1 )def Merged(v, T): h = 6.626e-34 kB = 1.380649e-23 c = 3 * 10 **8 return 8 * np.pi * h * v**3 / c**3 / np.e**(h *v /(kB * T))# Constantsh = 6.62607015e-34 # Planck's constant (m^2 kg / s)c = 299792458 # Speed of light in vacuum (m / s)k_B = 1.380649e-23 # Boltzmann constant (J / K)# Planck's law functiondef planck_law(frequency, temperature): &quot;&quot;&quot; Calculate the spectral radiance of a black body at thermal equilibrium. Parameters: frequency (float): frequency of the electromagnetic radiation (Hz) temperature (float): absolute temperature of the body (K) Returns: float: spectral radiance (W / (m^2 * sr * Hz)) &quot;&quot;&quot; exponent = (h * frequency) / (k_B * temperature) spectral_radiance = (8 * np.pi * h * frequency**3) / (c**3) * (1 / (np.exp(exponent) - 1)) return spectral_radiance# Example usage: Calculate the spectral radiance for a frequency of 1e14 Hz at 5000 Kfrequency_example = 1e14 # Hztemperature_example = 5000 # Kradiance_example = planck_law(frequency_example, temperature_example)# Plot the graphs aboveX = [i /10 for i in range(1,100)]fig, axs = plt.subplots(1, 3)axs[0].plot(X, [Planck(i * 1e14, 3000) for i in X])axs[1].plot(X, [Rayleigh_Jeans(i * 1e14, 3000) for i in X])axs[2].plot(X, [h *(i *1e14)* Rayleigh_Jeans(i*1e14, 3000) * Planck(i*1e14, 3000) for i in X])plt.tight_layout()plt.show()# plot the mergerd functionplt.plot(X, [Merged(i*1e14/10, 3000) for i in X])plt.show() So, both Rayleigh-Jean law and Planck law agree with the observation very well in very low frequency. But only Plank law could fit the decreasing of the intensity in high frequency situation. Light is Particle Einstein’s Contribution: Photoelectric Effect $$ E = nhν $$ By using the light to eject electrons from a copper, they found the kinetic energy of ejected electrons depends on light frequency $$ E_{light} = \\beta\\nu_{light} $$ The Photoelectric Effect Conservation of energy …?unknow $$ E_{elec} + \\Phi= \\beta \\nu $$ Eelec: (Measured) Electron kinetic energy &amp;\\Phi; Work to remove electron from target (independently determined) ν: Determine the value of &amp;\\beta; Einstein concluded that light must be behaving like a particle in this experiment: PHOTON E = hν Duality in partical with mass Electron diffraction: This is a typical diffraction pattern of a beam of electrons diffracted by a crystalline solid from Planck’s equation to Einstein’s equestion: E = h&amp;nu → E = mc2 $v = h\\nu$ $mv = P = m\\lambda\\nu$ $v = \\frac{P}{m\\lambda}$ $E = h\\nu = \\frac(hP){m\\lambda} → E = \\frac{p^2 }{m}$ De Broglie Equation: $\\lambda = \\frac{h}{p} = \\frac{h}{m\\nu}$ About Weight Terms in Spectral Density $g(\\nu) = \\frac{N(E)}{V} = \\frac{Number of States (E)}{Volumne}$ pre { background-color:#38393d; color: #5fd381; }","link":"/2024/01/23/LearnNotes/par-wave-dual/"},{"title":"Riboviria, Something you&#39;d like to know","text":"Riboviria Riboviria is a realm of viruses that includes all viruses that use a homologous RNA-dependent polymerase for replication. It includes: RNA viruses that encode an RNA-dependent RNA polymerase(RdRp). Reverse-transcribing viruses (with either RNA or DNA genomes) that encode an RNA-dependent DNA polymerase(RdDp). RdRp and RdDp enzymes are essential for replicating the viral genome and transcribing viral genes into messenger RNA (mRNA) for translation of viral proteins. Riboviria likely descended from non-viral elements that encode reverse transcriptase. It has few prokaryotic viruses, and includes most eukaryotic viruses. Well known species are included: coronaviruses, ebola virus, HIV, influenza viruses, rabies virus, and Tobacco mosaic virus. Characteristics RdRp: Based on the Baltimore classification system: positive sense single-stranded RNA (+ssRNA) viruses negative sense single-stranded RNA (-ssRNA) viruses double-stranded RNA viruses (dsRNA) Viral mRNA is translated by the host cell’s ribosomes to produce viral proteins. In order to produce more viruses, viral RNA-dependent polymerases use copies of the viral genome as templates to replicate the viral genome. For +ssRNA viruses, an intermediate dsRNA genome is created from which +ssRNA is synthesized from the negative strand. For -ssRNA viruses, genomes are synthesized from complementary positive sense strands. dsRNA viruses replicate their genomes from mRNA by synthesizing a complementary negative sense strand to form genomic dsRNA. For dsDNA-RT viruses, pregenomic RNA created from the cccDNA is retrotranscribed into new dsDNA genomes. For +ssRNA-RT viruses, the genome is replicated from the integrated genome. After replication and translation, the genome and the viral proteins are assembled into complete virions, which then leave the host cell. Some virus photos © Mazen S. Habayeb, 2006 Characterization of Nora virus in Rosiphila. pre { background-color:#38393d; color: #5fd381; }","link":"/2022/09/22/LearnNotes/riboviria/"},{"title":"Regulatory RNA","text":"Regulatory RNA miRNA, piRNA, siRNA, lncRNA miRNA A kind of small RNA. Short RNA which pair with mRNA regions and target them for degradation. siRNAs A kind of small RNA. piRNA A kind of small RNA. Similar to miRNA. LncRNA lncRNA associated with X chromosome inactivation. Some other lncRNA have been found associated with regulation of stem cell pluripotency and cell division. Enhancer RNA transcribed from enhancers which could up-regulate teh transcription of the genes prokaryotes RNA sRNA circulating RNA ? Small RNA Saml RNA are short (~18-30nt), non-coding RNA molecules which can regulate gene expression. They can interfering the expression (RNAi) or increase the expression (RNAa). There are three main classes of small RNAs: microRNAs (miRNAs), siRNAs and Piwi-interacting RNAs (piRNAs). Samll RNA like miRNA may directly regulate 30% of genes in human[1]. A review from 2009 elaborately talked the funciton of miRNA plaied important roles in gene regulation, cell differentiation, proliferation, migration, apoptosis, metabolism, defense, development, and disease[2]. miRNA MicroRNAs (miRNAs) are a class of short(~22-nt), endogenously-initiated non-coding RNAs that post-transcriptionally control gene expression via either translational repression or mRNA degradation. Meanwhile, miRNA itself is coordinatively modulated by multifarious effectors when carrying out basic functions, such as SNP, miRNA editing, methylation and circadian clock. it constitute nearly 1% of all predicted genes in nematodes, flies and mammals 1. most of the known miRNAs are encoded as polycistronic transcripts 2. considerable number of miRNAs are highly conserved in sequences among different organisms 3. miRNAs tend to target and regulate a set of mRNAs instead of a specific mRNA substrate 4. miRNA pathway is an ancient regulatory mechanism evolved before the divergence of multicellular and unicellular organisms[3] 5. viral miRNAs do not seem to share significant homology Cite: Cai, Y. 2009[4]. © Cai, Y. 2009 pre { background-color:#38393d; color: #5fd381; } Lewis B P, Burge C B, Bartel D P. Conserved seed pairing, often flanked by adenosines, indicates that thousands of human genes are microRNA targets[J]. cell, 2005, 120(1): 15-20. ↩︎ Zhang C. Novel functions for small RNA molecules. Curr Opin Mol Ther. 2009;11(6):641-651. ↩︎ Zhao, Tao, et al. “A complex system of small RNAs in the unicellular green alga Chlamydomonas reinhardtii.” Genes &amp; development 21.10 (2007): 1190-1203. ↩︎ Cai, Y., Yu, X., Hu, S., &amp; Yu, J. (2009). A Brief Review on the Mechanisms of miRNA Regulation. Genomics, Proteomics &amp; Bioinformatics, 7(4), 147-154. https://doi.org/10.1016/S1672-0229(08)60044-3 ↩︎","link":"/2022/09/29/LearnNotes/rnas/"},{"title":"Daily Paper Reading 1","text":"papperhead { font-size:1.5em; font-weight: 700; } 2021/04/28: Endothelin-1 impairs the mind Disrupted metabolic connectivity in dopaminergic and cholinergic networks at diferent stages of dementia from 18F‑FDG PET brain persistent homology network cite: Hsu TW, Fuh JL, Wang DW, et al. Disrupted metabolic connectivity in dopaminergic and cholinergic networks at different stages of dementia from 18F-FDG PET brain persistent homology network. Scientific Reports. 2021 Mar;11(1):5396. DOI: 10.1038/s41598-021-84722-8. Abstract Dementia is related to the cellular accumulation of β‑amyloid plaques tau aggregates α‑synuclein aggregates neurotransmitter defciencies in the dopaminergic and cholinergic pathways Cause: Cellular and neurochemical changes Challenge: the role of dopaminergic and cholinergic networks in metabolic connectivity at diferent stages of dementia remains unclear Methods: 18F‑fuorodeoxyglucose positron emission tomography (18F‑FDG PET) imaging data to construct dopaminergic and cholinergic metabolism network and used PHN analysis to track the evolution of these networks in patients with diferent stages of dementia. Result: The sums of the network distances in the Alzheimer’s disease and mild cognitive impairment cohorts is diferences Conclusion: A larger distance between brain regions can indicate poorer efciency in the integration of information. PHN analysis revealed the structural properties of and changes in the dopaminergic and cholinergic metabolism networks in patients with diferent stages of dementia at a range of thresholds. This method was able to identify dysregulation of dopaminergic and cholinergic networks in the pathology of dementia. Introduction Dementia Dementia is a neurodegenerative disease[1]: a progressive and chronic loss of function in cognitive motor sensory Caused by: β-amyloid plaques tau aggregates α-synuclein aggregates neurotransmitter deficiencies in the dopaminergic and cholinergic systems. Cholinergic circuity affects attention and cognition, memory and reward dysfunction, Else: Dopamine, α-synuclein werer related. 18F-FDG PET Advantage: The main advantage of 18F-FDG PET is its high sensitivity in detecting pathologies at the molecular level, due to the transportation of 18F-fluorodeoxyglucose into the intracellular space by glucose-1 transporters and its subsequent phosphorylation through the hexokinase reaction… Each brain region can be assumed to exchange information directly or indirectly with other parts of the network through synchronized fluctuations in glucose uptake… Using the 18F-FDG PET metabolic network, local neural activity, disconnection, and neuropathology effects can be observed. Result striatocortical pathways in Dopaminergic The SLD (single linkage distance) represents the functional distance between two brain regions SLD is higher in the AD and MCI groups compared with the SCD and HC groups. When λ increased, the dendrogram indicated that modularity occurred from the dorsal striatum to the prefrontal and sensorimotor cortices and that the supplementary motor regions had large delays in connectivity in patients with AD and MCI, but most markedly for MCI. When λ increased, the clustering of brain connections occurred more slowly and at a longer distance (less efficiency in the network): MCI &gt; AD &gt; SCD &gt; HC. The CPL and SIP AUC values is variety among all groups. mesolimbic pathways in Dopaminergic 2021/04/20: Endothelin-1 impairs the mind Endothelin-1 mediated vasoconstriction leads to memory impairment and synaptic dysfunction cite: Diwakar, L., Gowaikar, R., Chithanathan, K. et al. Endothelin-1 mediated vasoconstriction leads to memory impairment and synaptic dysfunction. Sci Rep 11, 4868 (2021). https://doi.org/10.1038/s41598-021-84258-x Abstract Cerebrovascular lesions are seen as white matter hyperintensity in MRI. It could be caused by micro-infracts and micro-bleeds and changing the blood flow to impair the cognitive deficits. We developed a model to study related impact by injecting ET-1 into C57 mice. The impediment in cerebral blood flow decreased CD31 expression around the hippocampal region, leading to memory deficits after 7 days. AKT-mTOR signaling cascade was downregulated but reversed after 30 days. activities depending on protein translation in the hippocampus were decreased. Introduction Dementia covers Alzheimer’s Disease (AD), Lewy body dementia, and Vascular Dementia (VD). The diagnosis of those diseases is relied on neuroimaging, neuropsychological, and pathological confirmation. Vasoconstriction over time contributes to VD, and cerebral small vessel disease (SVD) is being recognized as a major factor leading to cognitive impairment. We developed a mouse model of vasoconstriction predominantly in small vessels by intracerebroventricular (ICV) injection of ET-1 into lateral ventricles, bilaterally, which allowing ET-1 to spread through cerebrospinal fluid. Result Decreased expression of CD31 after 3 days injection Vasoconstriction leads to learning and memory deficits 7 days after injection Activation of microglia and increase in Iba1 expression after injection Activity-dependent protein translation is curtailed in synaptoneurosomes from the hippocampus of mice injected with ET-1 Akt‑1 and GSK phosphorylation are downregulated during the transient ischemia caused by ET‑1 injection. Memory impairment and synaptic function caused by a single dose of ET‑1 were reversed in 30 days. Discussion The model is successful and it led to significant effects on the mouse. ET-1 injection (2 µg) produces irreversible, focal lesion in locomotion and or memory depending on site of injection[2][3][4], low doses of ET-1 (0.5–1 μg) produces infarct induced lesion that is largely resolved by 3 days[5]. A higher dose (4 µg/ mouse) into the cortex results in mortality[6] CSF (cerebrospinal fluid) subsequently flows through the ventricular system of the brain, which consists of the two lateral ventricles and the third ventricle, which finally connects to the subarachnoid space… It has been shown that active transport can be bi-directional over the epithelial cells of the choroid plexus[7]. The direction of flow, the anatomical structures involved, and the driving forces that are involved in interstitial fluid and CSF flow are controversial[8][9]… Thus, the model was able to deliver a sufficient dose of ET-1. Synaptic plasticity is an important attribute for learning and memory and activity-dependent protein translation at the synapse is essential for synaptic plasticity… S35 methionine incorporation increased significantly in vehicle injected mice upon stimulation with KCl this was not observed in ET-1 treated mice indicating that activity dependent protein translation was non-existent following ET-1 treatment. Our results indicate for the first time the commonality between vasoconstriction in brain and early AD in downstream pathways that drive the behavioral abnormalities. Downregulated: Akt1 (Ser473 and Tr308)*, pmTOR, pS6k and p4EBP1 The loss of Akt1 kinase leads to downregulation in Akt-mTOR pathway which finally repressed activities dependent on protein translation[10]. ET-1 effects reversed after 30 days, much like that in patients with transient ischemic insults. Epstein FH, Martin JB. Molecular basis of the neurodegenerative disorders. New Engl. J. Med. 1999;340:1970–1980. doi: 10.1056/NEJM199902043400522. ↩︎ Sheng, T. et al. Endothelin-1-induced mini-stroke in the dorsal hippocampus or lateral amygdala results in deficits in learning and memory. J. Biomed. Res. 29, 362–369 (2015). ↩︎ Tennant, K. A. &amp; Jones, T. A. Sensorimotor behavioral effects of endothelin-1 induced small cortical infarcts in C57BL/6 mice. J. Neurosci. Methods 181, 18–26 (2009). ↩︎ Windle, V. et al. An analysis of four different methods of producing focal cerebral ischemia with endothelin-1 in the rat. Exp. Neurol. 201, 324–334 (2006). ↩︎ Wang, Y., Jin, K. &amp; Greenberg, D. A. Neurogenesis associated with endothelin-induced cortical infarction in the mouse. Brain Res. 1167, 118–122 (2007). ↩︎ Horie, N. et al. Mouse model of focal cerebral ischemia using endothelin 1. J. Neurosci. Methods 173, 286–290 (2008). ↩︎ de Lange, E. C. Potential role of ABC transporters as a detoxifcation system at the blood-CSF barrier. Adv Drug Deliv. Rev. 56, 1793–1809 (2004). ↩︎ Strazielle, N. &amp; Ghersi-Egea, J. F. Choroid plexus in the central nervous system: biology and physiopathology. J. Neuropathol. Exp. Neurol. 59, 561–574 (2000). ↩︎ Bedussi, B. et al. Clearance from the mouse brain by convection of interstitial fluid towards the ventricular system. Fluids Barriers CNS 12, 23 (2015). ↩︎ Ahmad, F. et al. Reactive oxygen species-mediated loss of synaptic Akt1 signaling leads to deficient activity-dependent protein translation early in Alzheimer’s disease. Antioxidants Redox Signal. 27, 1269–1280 (2017). ↩︎","link":"/2021/04/20/LearnNotes/readdaily1/"},{"title":"Statistic for Data Scientists 1| | Reading Notes","text":"Estimates of Location Mean; Weighter mean, Median, Weighted median, Trimmed mean, Robust, Outlier. Mean $\\overline{x} = \\frac{\\sum_ i^ n x_ i}{n}$ Trimmed mean $ \\overline{x} = \\frac{\\sum_ {i=p+1} ^{n-p} x_ {(i)}}{n-2p}$ Weighted mean $\\overline{x}_ w = \\frac{\\sum_ {i=1} ^ n w_ i x_ i}{\\sum_ i ^ n w_ i }$ Estimates of Variability Term Synonyms Description Deviations errors, residuals The difference between the observed values and the estimate of location Varuance mean-squared-error THe sum of squared deviations from the mean divided by $n - 1$ where n is the number of data values Standard deviation l2-norm, Eucliden norm The square root of the variance. Mean absolute deviation l1-norm, Manhattan norm The mean of the absolute value of the deviations from the mean. Median absolute deviation from the median The median of the absolute value of the deviations from the median Range The difference between the largest and the smallest value in a data set. Order statistics Ranks Metrics based on the date values sorted from smallest to biggest. Precentile quantile The value such that P percent of the values take on this value or less ad (100-P) percent take on this value or more. Interquartile range IQR The differentce between the 75th percentile and the 25th percentile. Deviation Mean absolution deviation $\\frac{\\sum ^ n _ {i=1} | x_ i - \\overline{x}|}{n}$ Variance $s^ 2 = \\frac{\\sum (x - \\overline{x})^ 2}{n-1}$ Standard deviation $s = \\sqrt{s^ 2}$ For Mean absolution deviation: List &lt;- c(1,2,3,4,5)MAD &lt;- function(List){ Tmp = 0 for( num in List){ Tmp = Tmp + abs(num - mean(List)) } Result = Tmp/length(List) return(Result)}'''in R mad()Instated of Tmp/length(List), in function mad(),it using Tmp/(length(List)-1)''' For Variance: List &lt;- c(1,2,3,4,5)VAR &lt;- function(List){ Tmp = 0 for( num in List){ Tmp = Tmp + (num - mean(List))^2 } Result = Tmp/(length(List)-1) return(Result)}# var() in R For Standard Deviation List &lt;- c(1,2,3,4,5)SD &lt;- function(List){ Tmp = 0 for( num in List){ Tmp = Tmp + (num - mean(List))^2 } Result = Tmp/(length(List)-1) Result = sqrt(Result) return(Result)}# sd() in R Why n - 1 In the intuitive denominator of n in the variance formulation, it would underestimate the true variance and the standard deviation. This is referred to as a biased estimate. If you divided by $n-1$, the standard deviation becomes an unbiased estimate. Test: function SD() and sd() SD() is using $n$, which is biased estimate, sd() is the base function of R, which use unbiased estimate. SD &lt;- function(List){ Tmp = 0 for( num in List){ Tmp = Tmp + (num - mean(List))^2 } Result = Tmp/length(List) Result = sqrt(Result) return(Result)} Test &lt;- function(List, i){ A = SD(List) B = sd(List) C = mad(List) D = var(List) Result = &quot;|&quot; List_str = &quot;$c(1,2,3,4,5,6,7,8,9,10)&quot; List_str_tmp = paste(List_str, &quot;^ {&quot;,(1+ i/10),&quot;}$&quot;,sep=&quot;&quot;) Result = paste(Result, List_str_tmp, sep = &quot;&quot;) Result = paste(Result, &quot;|&quot;,A,&quot;|&quot;,B,&quot;|&quot;, C,&quot;|&quot;, D, &quot;|&quot;,sep = &quot;&quot;) print(C) #print(Result) return(data.frame(A, B,C,D))}TB = data.frame()for(i in c(0:10)){ List &lt;- c(1,2,3,4,5,6,7,8,9,10) List &lt;- List ^(1+ i/10) TB = rbind(TB, Test(List, i))} List SD sd mad var $c(1,2,3,4,5,6,7,8,9,10)^ {1}$ 2.87228132326901 3.02765035409749 3.7065 9.16666666666667 $c(1,2,3,4,5,6,7,8,9,10)^ {1.1}$ 3.71464847156818 3.91558329233956 4.81903250216669 15.3317925192487 $c(1,2,3,4,5,6,7,8,9,10)^ {1.2}$ 4.77822834483576 5.03669491668582 6.21842448942231 25.3682956837688 $c(1,2,3,4,5,6,7,8,9,10)^ {1.3}$ 6.1203589266995 6.45142476870465 7.97443123015422 41.6208815462559 $c(1,2,3,4,5,6,7,8,9,10)^ {1.4}$ 7.81312940963156 8.23576152936081 10.1733320771185 67.8277679684995 $c(1,2,3,4,5,6,7,8,9,10)^ {1.5}$ 9.94716631430172 10.4852339392319 12.9217964296424 109.940130760421 $c(1,2,3,4,5,6,7,8,9,10)^ {1.6}$ 12.6363910464884 13.3199257038206 16.2215684620237 177.420420755302 $c(1,2,3,4,5,6,7,8,9,10)^ {1.7}$ 16.0239981545644 16.8907771302528 19.8184284109695 285.298352063871 $c(1,2,3,4,5,6,7,8,9,10)^ {1.8}$ 20.289967545938 21.3875036986871 24.1444312624589 457.425314461353 $c(1,2,3,4,5,6,7,8,9,10)^ {1.9}$ 25.6605043589986 27.0485465610381 29.3423269903854 731.623871064649 $c(1,2,3,4,5,6,7,8,9,10)^ {2}$ 32.4199012953463 34.1735765370459 35.5824 1167.83333333333 (Click the tag “var” below to dismiss the line “var”) // 基于准备好的dom，初始化echarts实例 var myChart = echarts.init(document.getElementById('echarts236')); // 指定图表的配置项和数据 var option = option = { tooltip : { trigger: 'axis', axisPointer : { // 坐标轴指示器，坐标轴触发有效 type : 'shadow' // 默认为直线，可选为：'line' | 'shadow' } }, xAxis: { type: 'category', data: [0, 1,2, 3,4, 5,6,7,8,9,10,] }, yAxis: { type: 'value' }, legend: { data:['sd', 'SD', \"mad\", \"var\"] }, series: [{ data: [2.872281,3.714648,4.778228,6.120359,7.813129,9.947166,12.63639,16.024,20.28997,25.6605,32.4199], type: 'line', smooth: true, name : \"SD\" }, { data: [3.02765,3.915583,5.036695,6.451425,8.235762,10.48523,13.31993,16.89078,21.3875,27.04855,34.17358], type: 'line', smooth: true, name : \"sd\" }, { data: [3.7065,4.819033,6.218424,7.974431,10.17333,12.9218,16.22157,19.81843,24.14443,29.34233,35.5824], type: 'line', smooth: true, name : \"mad\" }, { data: [9.166667,15.33179,25.3683,41.62088,67.82777,109.9401,177.4204,285.2984,457.4253,731.6239,1167.833], type: 'line', smooth: true, name : \"var\" } ] }; // 使用刚指定的配置项和数据显示图表。 myChart.setOption(option); Percentile Percentile was widely used in boxplot (interquartile range or IQR). It was more sensitive to the outliers, and the massive calculation also restricted its applicability since it needs sorting the data set though there are a machine learning algorithms to get an approximate percentile very quickly[1]. When the data (n is even): $$ 100 \\frac{j}{n} \\le P &lt; 100\\frac{j+1}{n} $$ Formally, the percentile is the weighted average: $$ P = (1 - w) x _ {(j)} + wx_ {j + 1} $$ IQR in R: $$ IQR(x) = quantile(x, 3/4) - quantile(x, 1/4) $$ RIQR(c(1,2,3,4,5,6,7,8,9,10)) [1] 4.5 Variation illustration Rlibrary(ggplot2)library(patchwork)P1 &lt;- ggplot(chickwts, aes(feed, weight, fill = feed, group = feed)) + geom_point() + geom_boxplot( alpha = 0.4) + theme_bw()+ labs( title= &quot;Boxplot&quot;)P2 &lt;- ggplot(chickwts, aes(weight, fill = feed, group = feed)) + geom_density(alpha = 0.4) + theme_bw() + labs( title= &quot;Density Plot&quot;)P3 &lt;- ggplot(chickwts, aes(weight, fill = feed, group = feed)) + geom_histogram( alpha = 0.4)+ theme_bw()+ labs( title= &quot;Histogram Plot&quot;)(P1|P3) /P2 @ Karobben Qi Zhang and Wei Wang. 2007. A Fast Algorithm for Approximate Quantiles in High Speed Data Streams. In Proceedings of the 19th International Conference on Scientific and Statistical Database Management (SSDBM '07). IEEE Computer Society, USA, 29. DOI:https://doi.org/10.1109/SSDBM.2007.27 ↩︎","link":"/2021/04/13/LearnNotes/statistics-ds-1/"},{"title":"Schrodinger Function","text":"Energy Momentum Relation $E^2 = (m_ 0 C ^2) ^2 + (pc)^ 2$ For Energy with rest mess: $E = m_0c^2$ For Energy with no rest mess: $E = pc$ Introducing Bacground: Light is a ruler; molecules are objects to be measured. Visible light is a coarse ruler (300 nm resolution) Molecules, on the other hand, are fine objects (0.1 nm) How can we measure such a fine object with a coarse ruler? Use a finer ruler (electron microscopy) Use indirect evidence to infer the information (today’s focus) How to infer? What indirect evidence? Use a language to describe the matter (molecule). Find information that is related to the size of a molecule. Hopefully that information can be obtained by measurement (using light). Infer the information about the molecule to be studied. Here is one way to do this: Use the Schrödinger equation to describe the system (molecule, atoms, electrons). Find out that energy of electrons is related to the size of the molecule. Measure the energy of the system using light. Infer the size of the molecule by interpreting the energy information. Use the Schrödinger Equation to Describe the System $$ -\\frac{\\hbar}{2m} \\frac{d^2 \\Psi (x)}{dx^ 2} + V(x)\\Psi(x) = E\\Psi(x) $$ V(x): Potential energy provides the constraints E: Solve for Energy(also called eigenvalues) $\\Psi(x)$: Solve for wavefunctions (also called eigenvectors or eigenfunctions) We will end up with a series of wavefunctions with associated energies: $$\\Psi(x) \\leftrightarrow E_ n $$ The Schrödinger Equation is a fundamental equation in quantum mechanics that describes how the quantum state of a physical system changes over time. It was formulated by Erwin Schrödinger in 1925. There are two forms of the Schrödinger Equation: the time-dependent and the time-independent forms. The Meaning of Φ(x) $$ P(x_0, t_0)dx = \\Psi^ * (x_0, t_0)\\Psi(x_0, t_0)dx = |\\Psi (x_0, t_0)|^2 dx $$ P(x0, t0): Probability* of finding the particle (e.g. electron) within an interval of dx of position x0 at time t0 Properties of Φ(x); $$ \\int_{-\\infty}^{\\infty} \\Psi^* (x, t) \\Psi (x, t)dx = 1 $$ Average value of f(x) over all space $$ \\left \\langle f(x) \\right \\rangle = \\frac{ \\int_{-\\infty}^{\\infty} \\Psi^* (x) \\Psi (x)f(x)dx }{\\int_{-\\infty}^{\\infty} \\Psi^* (x) \\Psi (x)dx} $$ Find Out That Energy of Electrons Is Related to the Size of the Molecule. 1-d particle in a box Here Particle = electrons in a molecule Layman language: Potential energy outside the box is infinite. Mathematical language: Boundary condition V(x) = 0 for L &gt; x &gt; 0 V(x) = ∞ for x ≥ L, x ≤ 0 $$ \\frac{d^ 2 \\Psi(x)}{dx^ 2} = \\frac{2m} {\\hbar^ 2} [V(x)-E]\\Psi(x) $$ Since V(x) is infinite outside the box, Ψ(x) must be zero outside the box (otherwise $\\frac{d^2 Ψ(x)}{dx^2}$ would be infinite: not allowed) Since Ψ(x) must be continous, Ψ(x) inside the box must connect smoothly to Ψ(x) outside the box Hence, $Ψ(0)= Ψ(L) = 0$ $$ \\Psi_ n (x) = \\sqrt{\\frac{2}{L}} sin(\\frac{n\\pi x}{L}) $$ $ E_ n= \\frac{h^2 n ^2}{8ma ^ 2} $ $ where n = 1, 2, 3, 4… $ Energy of the electron (E) is related to the size of the molecule (L). With this theory, we could measure the energy of the system using light Pi-electrons behave as a “particle in a box: Molecules has different absorb peak when they as different number of conjugation bounds. The electrons and its orbitals 4 pi electrons =&gt; 2 orbitals 8 pi electrons =&gt; 4 orbitals Estimate bond length from the transition energy $$ \\Delta E = \\frac{(n_ 3 ^ 2 - n_ 2^ 2) h^ 2 }{8mL^ 2} $$ For this compound, There are 4 pi electrons. Two each in the n=1 and n=2 orbitals. (This is due to electron spin, which we will see later). The absorption is due to promoting an electron from the n=2 to the n=3 orbital. Infinite potential: infinite number of solutions Finite potential: A finite number of solutions (5 in this example) Wavefunctions are not zero at the boundary of the box The wavefunctions have finite amplitude outside the box. Finite chance the particle can be outside the box even though E&lt;V0 TUNNELING effect in Quantum Mechanics © ntmdt-si a particle can go &quot;through&quot; an energy barrier instead of needing to have sufficient energy to go over the barrier When the wave go through the energy barrier, the exponential decay occurred inside of the energy barrier. Predict the Energy and Optical Property If we know the structure of the molecule, can we predict the energy and optical property of the molecule? Take the hydrogen atom as example. $V( r ) = \\frac{e^ 2}{4\\pi \\epsilon_ 0 r}$ e = electron charge ε0 = permittivity of free space Predicted the Energy Here we only need 3 quantum number: n, l, and ml the principal quantum number: n = 1, 2, 3, 4… the angular momentum quantum number: l = 0, 1, 2, … (n -1) the magnetic quantum number: ml = 0, ±1, ±2, … ± l As you can see, the energy only depends on n: $E_ n = - \\frac{m_ e e^ 4}{8 \\epsilon_ 0^ 2 h^2 n^ 2} = - \\frac{2.179 × 10 ^ {-18}}{n^ 2}Joule = -\\frac{13.6}{n^ 2}eV\\ \\ \\ n = 1, 2, 3… $ © Atkins, The Elements of Physical Chemistry Cheat Sheet Energy: kcal/mol, kJ/mol Wavelength: nm Frequency: Hz $E = h\\nu = \\frac{hc}{\\lambda}$ Planck constant (h) = 6.62607015 × 10-34 J∙s Speed of light (c) = 299 792 458 m/s ~ 3 × 108 m/s Calculate the energy of one photon of green light (532 nm) $ E = h\\nu = \\frac{hc}{\\lambda} = \\frac{hc}{532 × 10^ {-9}m} = 3.823×10^ {-19}J$ Convert J to Hz $ \\nu = \\frac{E}{h} = \\frac{3.823×10^ {-19}J}{h} = 5.8 × 10^ {14} Hz$ Convert kJ/mol and kcal/mol $E_ {total} = N_ A × E = 6.02 × 10^ {23} \\frac{1}{mol} × 3.823 × 10^ {-19} J$ $= 230226 J/mol ~ 230 kJ/mol $ $= 55 kcal/mol$ Extra Reading Time-Dependent Schrödinger Equation: $$ i\\hbar\\frac{\\partial}{\\partial t}\\Psi(\\mathbf{r}, t) = \\hat{H}\\Psi(\\mathbf{r}, t) $$ Here, $\\Psi(\\mathbf{r}, t)$ is the wave function of the system, $i$ is the imaginary unit, $\\hbar$ is the reduced Planck constant, $t$ represents time, $\\mathbf{r}$ is the position vector, and $\\hat{H}$ is the Hamiltonian operator which represents the total energy of the system. Time-Independent Schrödinger Equation: $$ \\hat{H}\\psi(\\mathbf{r}) = E\\psi(\\mathbf{r}) $$ In this form, $\\psi(\\mathbf{r})$ is the time-independent wave function, $E$ represents the energy of the system, and other symbols have the same meaning as in the time-dependent equation. The Schrödinger Equation is a cornerstone of quantum mechanics, providing a mathematical framework for understanding and predicting the behavior of quantum systems. It’s important to note that these equations are usually accompanied by specific boundary conditions or potentials, depending on the physical situation being modeled. pre { background-color:#38393d; color: #5fd381; }","link":"/2024/01/25/LearnNotes/schrodinger/"},{"title":"t-sne","text":"t-SNE Blog: Cory Maklin: t-SNE Python Example; 2019 Python codes Reference: Cory Maklin: t-SNE Python Example; 2019 import numpy as npfrom sklearn.datasets import load_digitsfrom scipy.spatial.distance import pdistfrom sklearn.manifold._t_sne import _joint_probabilitiesfrom scipy import linalgfrom sklearn.metrics import pairwise_distancesfrom scipy.spatial.distance import squareformfrom sklearn.manifold import TSNEfrom matplotlib import pyplot as pltimport seaborn as snssns.set(rc={'figure.figsize':(11.7,8.27)})palette = sns.color_palette(&quot;bright&quot;, 10)X, y = load_digits(return_X_y=True)MACHINE_EPSILON = np.finfo(np.double).epsn_components = 2perplexity = 30def fit(X): n_samples = X.shape[0] # Compute euclidean distance distances = pairwise_distances(X, metric='euclidean', squared=True) # Compute joint probabilities p_ij from distances. P = _joint_probabilities(distances=distances, desired_perplexity=perplexity, verbose=False) # The embedding is initialized with iid samples from Gaussians with standard deviation 1e-4. X_embedded = 1e-4 * np.random.mtrand._rand.randn(n_samples, n_components).astype(np.float32) # degrees_of_freedom = n_components - 1 comes from # &quot;Learning a Parametric Embedding by Preserving Local Structure&quot; # Laurens van der Maaten, 2009. degrees_of_freedom = max(n_components - 1, 1) return _tsne(P, degrees_of_freedom, n_samples, X_embedded=X_embedded)def _tsne(P, degrees_of_freedom, n_samples, X_embedded):params = X_embedded.ravel() obj_func = _kl_divergence params = _gradient_descent(obj_func, params, [P, degrees_of_freedom, n_samples, n_components]) X_embedded = params.reshape(n_samples, n_components) return X_embeddedx = np.array([[1, 2, 3], [4, 5, 6]])np.ravel(x)def _kl_divergence(params, P, degrees_of_freedom, n_samples, n_components): X_embedded = params.reshape(n_samples, n_components) dist = pdist(X_embedded, &quot;sqeuclidean&quot;) dist /= degrees_of_freedom dist += 1. dist **= (degrees_of_freedom + 1.0) / -2.0 Q = np.maximum(dist / (2.0 * np.sum(dist)), MACHINE_EPSILON) # Kullback-Leibler divergence of P and Q kl_divergence = 2.0 * np.dot(P, np.log(np.maximum(P, MACHINE_EPSILON) / Q)) # Gradient: dC/dY grad = np.ndarray((n_samples, n_components), dtype=params.dtype) PQd = squareform((P - Q) * dist) for i in range(n_samples): grad[i] = np.dot(np.ravel(PQd[i], order='K'), X_embedded[i] - X_embedded) grad = grad.ravel() c = 2.0 * (degrees_of_freedom + 1.0) / degrees_of_freedom grad *= c return kl_divergence, graddef _gradient_descent(obj_func, p0, args, it=0, n_iter=1000, n_iter_check=1, n_iter_without_progress=300, momentum=0.8, learning_rate=200.0, min_gain=0.01, min_grad_norm=1e-7): p = p0.copy().ravel() update = np.zeros_like(p) gains = np.ones_like(p) error = np.finfo(np.float).max best_error = np.finfo(np.float).max best_iter = i = it for i in range(it, n_iter):error, grad = obj_func(p, *args)grad_norm = linalg.norm(grad)inc = update * grad &lt; 0.0 dec = np.invert(inc) gains[inc] += 0.2 gains[dec] *= 0.8 np.clip(gains, min_gain, np.inf, out=gains) grad *= gains update = momentum * update - learning_rate * grad p += updateprint(&quot;[t-SNE] Iteration %d: error = %.7f,&quot; &quot; gradient norm = %.7f&quot; % (i + 1, error, grad_norm)) if error &lt; best_error: best_error = error best_iter = i elif i - best_iter &gt; n_iter_without_progress: break if grad_norm &lt;= min_grad_norm: break return pX_embedded = fit(X)sns.scatterplot(X_embedded[:,0], X_embedded[:,1], hue=y, legend='full', palette=palette) In sklearn: tsne = TSNE()X_embedded = tsne.fit_transform(X)sns.scatterplot(X_embedded[:,0], X_embedded[:,1], hue=y, legend='full', palette=palette)","link":"/2021/11/06/LearnNotes/tsne/"},{"title":"stocking density effects on fish | review","text":"Introduction growth and performance of some salmonids [1] [2][3] decreased food consumption[4] social interaction[5][4:1] altered water quality[6][7] growth-regulating role of hormones in fish held at high stocking density [8][2:1] chronic stress; water quality, adverse social interactions or over-crowding, negative physiological and biochemical changes [3:1][9] Reducing Lysozyme[10][11] Salvelinus fontinalis[12] © Wikimedia Brook charr Fish Date Effects Paper Salvelinus fontinalis 1990 energy metabolism of brook charr M.M.Vijayan[12:1] Brook charr: reared for 30 days Lower Higher No effect - final body weight- reduced food consumption- plasma T4 concentration was lowered- Lower Plasma glucose levels- Lower liver glycogen content- Lower hepatosomatic index- Hepatic hexokinase- glucose-6-phosphate dehydrogenase activities - fructose biphosphatase- 3-hydroxyacyl CoA dehydrogenase- glycerol kinase- glycerol-3-phosphate dehydrogenase - T3 concentrations- plasma protein- free fatty acid (FFA) levels- pyruvate kinase- glucose-6-phosphatase- phosphoenolpyruvate carboxykinase- glutamate dehydrogenase- glutamate pyruvate transaminase- glutamate oxaloacetate transaminase- plasma cortisol These results suggest that high stocking density has the effect of mobilizing triglyceride sources, promoting gluconeogenesis from glycerol, but has little effect on protein metabolism. VE[13] 18 weeks diets supplemented with 450 mg of vitamin E showed an increase (P!0.05) in the accumulation of macrophages foreign body giant cells and Langhans type cells. not show a similar difference in plasma cortisol concentrations related to stocking density Silver perch[14] © goodfish.org Densities of 12, 25, 50, 100 or 200 fish/m3 in cages (1 m3) in an aerated Cultured for 210 days There was aggression between fish in cages stocked at 25 or 50 fish/m3 survival (50% and 64.5%, respectively) was significantly lower (P &lt; 0.01) than at the other densities (87.5%, 98.5% and 97.4%). Stocking density did not affect final weight (454.6–471.1 g), specific growth rate (0.65–0.70%/day) or absolute growth rate (1.6–1.7 g/fish/day) feed conversion ratios (FCR) of fish stocked at 25 or 50 fish/m3 (4.4 and 3.7) were significantly higher (P &lt; 0.01) than FCRs (range, 2.3–2.5) at other densities. Coefficients of variation in weight (CV) at 25 or 50 fish/m3 (24.4% and 28.3%) were significantly higher (P &lt; 0.01) than at other densities and the lowest CV of 16.1% was at 200 fish/m3. Production was significantly affected (P &lt; 0.01) by stocking density, with the highest mean rate of 88.5 kg/m3 in cages stocked with 200 fish/m3. One infestation of the ectoparasitic ciliate, Chilodonella hexasticha, and two infestations of the monogenean gill fluke, Lepidotrema bidyana, were each treated successfully with an application of 30 mg/l formalin. The high survival, relatively fast growth, low variation in weight and high production rates of silver perch stocked at 100 or 200 fish/m3 demonstrate that cages are a viable alternative to ponds for the commercial production of silver perch. 12 25 50 100 200 Survival(%) 87.5(7.2)a 50.0(6.4)b 64.5(7.6)b 98.5(1.5)c 97.4(1.4)c Weight(g) 455.1(20.5) 454.6(32.4) 469.7(12.4) 471.1(15.7) 460.2(16.1) CV(%) 20.1(2.5)a 24.4(2.8)b 28.3(3.2)b 18.9(2.1)a,c 16.1(0.9)c SGR(%/day) 0.68(0.02) 0.65(0.03) 0.69(0.02) 0.70(0.03) 0.68(0.03) AGR(g/day) 1.6(0.1) 1.6(0.1) 1.7(0.1) 1.7(0.1) 1.7(0.1) Production(kg/m3) 4.8(0.4)a 5.8(1.8)a 11.9(5.3)b 46.4(1.8)c 88.5(2.0)d FCR 2.5(0.3)a 4.4(0.3)b 3.7(0.4)b 2.3(0.2)a 2.4(0.2)a Survival, final weight, coefficient of variation of weight (CV), specific growth rate (SGR), absolute growth rate (AGR), production and feed conversion ratio (FCR) of silver perch (initial mean weights, 109.3-115.4g) cultured for 210 days at five stocking densities in cages Feeding Behavior Fish in cages stocked at 100 or 200 fish/m3 always fed strongly at and near the surface, Feeding behavior in cages stocked at 25 or 50 fish/m3 was intermediate, with fish mostly feeding mid-water, but at times feeding strongly near the surface. fish stocked at 12 fish/m3 usually fed mid-water and were rarely seen feeding near the surface throughout the experiment Aggression Behavior observed daily in at 25 or 50 fish/m3, eroded fins no obvious signs of aggression in cages stocked at 12, 100 or 200 fish/m3 Which interested me Variation in weight More related to Stocking density Intestinal Microbiota (Pig)[15] Intestinal Microbiota (Duck)[16] Deposition and transport of trace mineral elements (Pig)[17] Schreck, C.B., Patino, R., Pring, C.K., Winton, J.R. and Holway, J.E., 1985. Effects of rearing density on indices of smoltification and performance of coho salmon, Oncorhynchus kisutch. Aquaculture, 45: 345-358. ↩︎ Vijayan, M.M. and Leatherland, J.F., 1988. Effect of stocking density on the growth and stressresponse in brook chat-r, Salvelinus fontinalis. Aquaculture, 75: 159-l 70. ↩︎ ↩︎ Bolasina, S., Tagawa, M., Yamashita, Y., Tanaka, M., 2006. Effect of stocking density on growth, digestive enzyme activity and cortisol level in larvae and juveniles of Japanese flounder, Paralichthys olivaceus. Aquaculture 259, 432–443. ↩︎ ↩︎ Refstie, T. and Kittelsen, A., 1976. Effect of density on growth and survival of artificially reared Atlantic salmon. Aquaculture, 8: 3 19-326. ↩︎ ↩︎ Fenderson, O.C. and Carpenter, M.R., 197 1. Effects of crowding on the behaviour of juvenile hatchery and wild landlocked Atlantic salmon (Satmo saiur L. ). Anim. Behav., 19: 439-447. ↩︎ Pickering, A.D. and Stewart, A., 1984. Acclimation of the interrenal tissue of the brown trout, Salmo trutta L., to chronic crowding stress. J. Fish Biol., 24: 131-740. ↩︎ Pickering, A.D. and Pottinger, T.G., 1987a. Poor water quality suppresses the cortisol response of salmonid fish to handling and confinement. J. Fish. Biol., 30: 363-374. ↩︎ Leatherland, J.F. and Cho, C.Y., 1985. Effect of rearing density on thyroid and interrenal gland. activity and plasma and hepatic metabolite levels in rainbow trout, Salmo gairdneri Richardson. J. Fish Biol., 27: 583-592 ↩︎ Montero, D., Izquierdo, M., Tort, L., Robaina, L., Vergara, J., 1999. High stocking density produces crowding stress altering some physiological and biochemical parameters in gilthead seabream, Sparus aurata, juveniles. Fish Physiol. Biochem. 20, 53–60. ↩︎ Costas, B., Aragão, C., Dias, J., Afonso, A., Conceição, L.E., 2013. Interactive effects of a highquality protein diet and high stocking density on the stress response and some innate immune parameters of Senegalese sole Solea senegalensis. Fish Physiol. Biochem. 39, 1141–1151. ↩︎ Liu, Baoliang, et al. “Effects of stocking density on antioxidant status, metabolism and immune response in juvenile turbot (Scophthalmus maximus).” Comparative Biochemistry and Physiology C-toxicology &amp; Pharmacology (2016): 1-8. ↩︎ Vijayan, M. M., J. S. Ballantyne, and J. F. Leatherland. “High stocking density alters the energy metabolism of brook charr, Salvelinus fontinalis.” Aquaculture 88.3-4 (1990): 371-381. ↩︎ ↩︎ Belo, Marco Antonio de Andrade, et al. “Effect of dietary supplementation with vitamin E and stocking density on macrophage recruitment and giant cell formation in the teleost fish, Piaractus mesopotamicus.” Journal of Comparative Pathology 133.2-3 (2005): 146-154. ↩︎ Rowland, Stuart J., et al. “Effects of stocking density on the performance of the Australian freshwater silver perch (Bidyanus bidyanus) in cages.” Aquaculture 253.1-4 (2006): 301-308. ↩︎ Li, Lan, et al. “Intestinal microbiota in growing pigs: effects of stocking density.” Food and Agricultural Immunology 29.1 (2018): 524-535. ↩︎ Wu, Yuqin, et al. “Proteome and microbiota analysis reveals alterations of liver-gut axis under different stocking density of Peking ducks.” PLOS ONE 13.10 (2018). ↩︎ Wu, Xin, et al. “Deposition and transport of trace mineral elements were affected by stocking density in fattening pigs.” Journal of Trace Elements in Medicine and Biology (2018): 566-571. ↩︎","link":"/2020/08/19/LearnNotes/stockingdensity_fish/"},{"title":"Glycolysis &amp; the TCA (citric acid) cycle 11| Tulane","text":"1623 21","link":"/2021/10/21/LearnNotes/tulane-biochem-11/"},{"title":"Enzymatic Catalysis, Catalytic Mechanisms 10| Tulane","text":"Enzymatic Catalysis, Catalytic Mechanisms 1.General Properties of Enzymes 2.Activation Energy and the Reaction Coordinate 3.Catalytic Mechanisms4.Serine Proteases (pp. 342-347) Give examples of various levels of substrate specificity, and explain specificity differences exhibited by serine proteases Give examples of reactions that utilize coenzymes NAD, FAD, Coenzyme A, and lipoic acid (metabolism lectures), and specify the role of the coenzyme Describe catalysis in terms of a reaction-coordinate energy diagram Classify enzymes by type of reaction Explain catalysis by enzymes in terms of chemical mechanisms Elaborate the catalytic mechanism of a chymotrypsin Explain divergent and convergent evolution Discuss the similarity of primary structure vs. tertiary structure in proteins as evidence supporting the existence of homology Enzymes differ from chemical catalysts rates↑; Reaction specifity↑ Mider reaction conditions Capacity for regulation How Enzymes Work trhough the foramtion of weak bonds between the enzyem and the substrate. help arrange the substrate in a position favorable for reaction Catalysis by Transition-state Stabilization CH_3_ than H, rate increased 315 times: transition-state stabilization Carbon -&gt; Aceessi for the hydroxyl group; L-Proline → [Planar transition stte] → D-Proline L-Proline : 109.5°; transition state: 20° I have no chemical background, so go on hell I am so tird. Thats increadible. Let’s keep type so I do fall into sleep. alkane → ahlcohole → aldchyl → Exrebexyl R-CH₃ → R - CH₂OH → R-CH=O → R-C=C=H Substrate Specificity Lock Key model: Hexokinase: 6C sugure, glucose, very specifics. Founder: Fisher (Projection) Enzyme distinguish different sugar model Something like Ahlcohole Dehydrase methanol, Ethanol Methanol → Carboxyl acid (toxity) Drinking Ethanol to inhibitor Methanol metabolism Example of “high” specificity (stereospecificity) Citrate ←(Aconitase)→ Isocitrate Enzyme is so large to interacte with the complex. If you rotated the molecue, Example of “low” specificity (geometric) Chymotrypsin: Peptide: RCO::NHR' + H₂O → RCOO¯ + H₃N⁺R' Ester: RCO::OR' + H₂O → RCOO¯ + HOR' + H¯ Trypsin; Elastase Example of enzyme that uses a coenzyme/cosubstrate Ethano ←(ADH)→ Acetaldehyde Adenosine: Oxidized Form ←→ Reduced Form NAD⁺ \\ NADP⁺ VB, whichi needs by Mitochondria: nicotinamide riboside As aging, the VB gets low, supply in precouser to aging mouse, mitochondria could, In humane: hearing lost in loud noise rescue. Acid-base Catatlysis Keto → Transition state → Enol Form 1 Form 2 + Acide Form 3 + Base Different forms has difference entropy. © Britannica Covalent Catatlysis © smu.edu Metal Ion Catalysis Zn Coordinate with His to do complex things. Catalysis by Proximity and Orientation Catalytic triad of chymotrypsin and other serine proteases Serine protease mechanism (Exam) Imtermider: not transition state, it is physical, detactable, and exist.S © Maya Topf and W. Graham Richards 🐶 🐔 .","link":"/2021/10/08/LearnNotes/tulane-biochem-10/"},{"title":"Water, thermodynamic|Graduate Biochemistry 1| Tulane","text":"Co-Author: Haoyang liang Structure of Water What makes water unique Dipole oxygen is tetrahedral (sp3 hybridization) 4 orbitals 4 pairs of electrons 2 of them bind to protons 2 of them are just orbitals orbital is not completely random Electrons spend more time around positively charged protons. which cause the water dipole In a right distance and right angle, they’ll form a hydrogen bond In the water, there are lots of polar, dipole interactions which not form hydrogen bonds. Hydrogen bond was much dominant in the water interaction with other biomolecules. Small Size small size and so, you have extrema abundant of a polar group. Hydrogen bond How it formed: Require hydrogen donor (δ+) and hydrogen acceptor (δ-) groups A hydrogen acceptor has a free electron pair Hydrogen is shared between the groups Separation and geometry are conserved Common Atoms you know Oxygen has 2 bonds and 2 free electron pairs (only accept) Nitrogen often has three bonds and 1 free electron pair and sometimes 4 bonds and no free electron pairs (accept other protons) Carbon has four bonds and NO free electron pairs and does not form hydrogen bonds Double bonds make the atoms in a co-plane. Other things about water The number of hydrogen bonds Liquid water: ~3 hydrogen bonds/molecule. Ice: 4 Hydrogen bonds/molecule. Quantity: The molar concentration of water is ~55M. The concentration of Hydrogen bonding groups in water is 220 M. Which makes water is extremely polar This character drives the most unique properties of the water Common Chmeical Group Remember them all in slides - - Thinking about hydrogen bonding. DNA pairs © ATbio Ionic Interaction © wps.prenhall.com All polar molecular has dipoles. This property makes them can interact with a hydrogen bond. The water automatically circles the dipole molecules by ion interaction. charge-charge (can over distance) Dipole-dipole (weak than c-c) charge-dipole interactions Exp: water circle the charged particles to form a water shield. it limited the charge-charge interaction At the surface of the protein, not surrounded by water, the interaction of molecules here could become much stronger. (Con contain? ion, not shield by water) Dielectric constant of the medium (weaker in more polar solvents) Ionic strength of the solution (weaker as ion concentration increases) Hydrophobic Interaction The measure of the non-favorite interaction of nonpolar molecules A non-polar molecule or group is “Hydrophobic” doesn’t solve into water Being nonpolar, not really interact with water. surface tension water molecules can’t H bond with nonpolar solutes so they H-bond with each other, forming a “cage” this ordering (entropy) is unfavorable the hydrophobic effect is proportional to the nonpolar surface area that is exposed to water Exp: a bottle of water, take non-polar (CH4) into the water, happens nonthing remove water-water interaction: lost some classic phenomenal summary of interaction energies Covalent Ionic Hydrophobic Thermol dynamic favorable. Hydrogen Bond Dipole-Dipole Induced dipole (Van Der Waals) Ionization of Water $H_ 2O \\longleftrightarrow H^ + + HO ^ -$ $$ k = {\\frac{[H^ +][OH^ -]}{[H_2 O]} } = 1.82 \\times 10^ {-16}\\ Molar $$ Since H2O is constant (55.3 M), we can write $$ K^ * = k[H_2 O] = [H^ +][OH^ -] = 1.01 \\times 10^{-14} $$ which usually rounded into 10-14 $$ pH = -log([H+]) $$ Ionization Equilibria low Ph -&gt; proton concentration is high in water high Ph -&gt; low proton concentration $$ pK_ A = -log(K_ A) = -log(\\frac{[H^ +][A]}{[AH]}) $$ $$ pK_ A = -log([H^ +])-log(\\frac{[A]}{[AH]}) $$ Henderson-Hasselbach Equation $$ pK_ A = pH - log(\\frac{[A]}{[AH]}) $$ Middle of the curve is pKa: point tow portion equally abounded Thermodynamic and Energetics Spontaneity of chemical reactions Chemical Potential, Equilibrium, standard states Equilibrium constants &amp; Free Energy Coupled reactions High energy compounds Metabolic pathways - glycolysis Second Law of Thermodynamic In biology, we focus in: constant pressure, constant temperature $\\Delta H - T \\Delta S &lt; 0 $ is the energy we can use $- \\Delta G$ is spontaneous, is a thermodynamically favorable reaction $aA + bB \\longleftrightarrow cC + dD$ $$ \\Delta G = \\Delta G^ {\\circ} + RT\\ ln[\\frac{C^ c D^ d}{A^a B^b}] $$ The rate of a chemical reaction is INDEPENDENT of $\\Delta G,\\ \\Delta G^ {\\circ}$ $$ \\Delta G ^ {\\circ} = - RT\\ ln[K_ {eq}] $$ Enzymes CAN NOT change the equilibrium concentrations in a reaction Enzymes can ONLY allow reaction to proceed towards equilibrium Metabolic pathways often operate far from equilibrium are steady state pathways are irreversible because at least one step has large negative $\\Delta G ^ {\\circ}$ The forward pathway is highly favorable (the sum of all the ΔGo is negative) Flow through the pathways is from A to J (the sum of all the ΔG is negative) Reactions 2,6,7 and 8 are near equilibrium Reaction 4 (D→E) is highly unfavorable Reactions 1,3, 6 and 9 are highly favorable Reactions 1,3 and 9 are far from equilibrium","link":"/2021/08/25/LearnNotes/tulane-biochem-1/"},{"title":"Oxidative phosphorylation &amp; ATP synthesis 12| Tulane","text":"Oxidative phosphorylation &amp; ATP synthesis 12 Invest 1st ATP Aldose to ketose Position carbonyl for aldolase (step 4) to split molecule into two 3-carbon fragments Invest 2nd ATP Allosteric regulation, e.g., feedback inhibition by ATP Split 6-carbon into two 3-cabon compounds Schiff base intermediate Funnel DHAP through GAP into 2nd half of pathway Catalytically “perfect” enzyme Form high-energy intermediate Thermodynamically unfavorable reaction Generate NADH 1st energy payoff Substrate level phosphorylation (phosphate transfer from carbohydrate to ADP) Setup for next formation of high-energy intermediate Slide 20: Some 2,3-BPG falls off, binds Hb, favors O2 release Slide 21: Dehydration forms high-energy intermediate Slide 22: Substrate-level phosphorylation Cori Cycle In the Cori cycle, Lactate from skeletal muscle is transferred to the liver Converted to pyruvate then glucose This glucose can be returned to the muscle Glycogen Regulate at PFK Adenylate kinase salvages high-energy bond of ADP generates AMP, a sensitive metabolic indicator Keq= 1 Low ATP or a small increase in AMP relieves PFK inhibition xczx rm package*rm -r themesrm -rf t*rm _config.* 123 Untitled.ipynb config node_modules profile.jsx test.md tmp.log 25663File.md _config.icarus.yml link_list.md package-lock.json public test.md.md webGL README.en.md _config.landscape.yml live2dDemo package.json scaffolds themes README.md _config.yml live2d_models paper.md source tmp","link":"/2021/10/20/LearnNotes/tulane-biochem-12/"},{"title":"Nuclear","text":"The central Dogma of Molecular Biology DAN Puring; Pyrimidine © Zac Pursell Nucleotides Biosynthesis of the DNA &amp; RAN purines Exam: Nucleotide synthesis OverView © Zac Pursell Adenine and guanine nucleotides originate from inosinic acid (IMP), which derives its atoms from phosphoribosyl pyrophosphate (==PRPP=), amino acids, formate and CO2 © wikipedia © wikipedia Click to see from PRPP to IMP AMP synthesis requires GTP hydrolysis and aspartate== GPM syntehsis requries ATP and glutamine © Biochemistry; Garrett &amp; Grisham Biosynthesis of the RNA Purine Ribonucleotides $$ AMP+ATP \\overset{NMK}{\\leftrightharpoons} 2 ADP + 2NTP \\overset{NDK}{\\leftrightharpoons} 2ATP + 2NDP $$ $$ GMP+GTP \\overset{NMK}{\\leftrightharpoons} 2 GDP + 2NTP \\overset{NDK}{\\leftrightharpoons} 2GTP + 2NDP $$ NMK: Nuclioside Monophosphate Kinase NDK: Nuclioside Diphosphate Kinase Regulation of the Nucleotide Synthesis Nucleotide Synthesis is Highly Regulated: Through Feedback Inhibition, Feedforward Activation and Coordinate Regulation © Fundamentals of Biochemistry, 3rd edition © Biochemistry; Garrett &amp; Grisham Activity-determining effector (Hexomerization site) Ribonucleotide reductase is a Allosteric enzyme. Schematic diagram of the quaternary structure. The enzyme consists of two identical pairs of subunits, R12 and R22. Each R2 subunit contains a binuclear Fe(III) complex that generates a phenoxy radical at Tyr 122. The R1 subunits each contain three different allosteric effector sites and five catalytically important Cys residues. The enzyme’s two active sites occur at the interface between the R1 and R2 subunits. Ribonucleotide Reductases Reduce NDPs to dNDPs $$ CDP &amp; UDP \\underset{dTTP}{\\overset{ATP}{\\longrightarrow}} dCDP &amp; dUDP $$ $$ GDP \\overset{dTTP}{\\longrightarrow} dGDP $$ $$ NDP \\overset{dATP}{\\longrightarrow} dNDP $$ dTMP Is Synthesized from dUMP Not TDP → dTDP reduction $UDP \\overset{RNR}{\\longrightarrow} dUDP \\overset{NDP\\ kinase}{\\longrightarrow} dUTP \\overset{dUTPase}{\\longrightarrow} dUMP \\overset{thymidylate\\ synthesis}{\\longrightarrow} dTMP → dTTP$ $dUMP + THF \\overset{thymidylate\\ synthase}{\\longrightarrow} dTMP + DHF$ dUTP intermediates are quickly broken down into dUMP to avoid mutagenic dUTP incorporation. The concentration of DHF was quickly rescued by DHFR: $DHF \\overset{DHFR}{\\longrightarrow} THF$ FdU and Methotrexate are anticancer compounds thath disrupt dTMP Biosynthehsis Cancer require large amount of dTTP than do normal cells. © wikipedia © wikipedia 5-Fluorodeoxyuridylate(FdUMP): locks dTMP synthesis by binding and irreversibly inhibiting thymidylate synthase Methotrexate: DHF analog; binds tightly and inhibits DHFR Purines Salvage Unlike de novo purine syntehsis, purine salvage is NOT conserved across species. Mammal: $Adenosine + PRPP \\overset{APRT}{\\longrightarrow} AMP + PP_i$ $Hypoxanthine/Guanine + PRPP\\overset{HPRT}{\\longrightarrow} AMP + PP_i$ Animal purin catabolism © Fundamentals of Biochemistry, 3rd edition DNA structures and metabolism The B-DNA Molecule © Sagar Aryal, 2019 Right Handed; 20 Å in diameter with two grooves. The distance between the bases (rise) is 3.4 Å, 10 bp Major groove is ~1.2nm wide, 0.6~0.8nm deep. minor groove is ~0.7nm Wide. B-form by far most common dsDNA under dehydrating conditions can exist as A-form Metabolic Instability of RNA © Gail Mitchell Emilsson, et al; 2003 RNA is intrinsically unstable in aqueous media and undergoes self-hydrolysis due to nucleophylic attack of the 2 ’OH on the adjacent phosphodiester linkage. This instability increases at alkaline pH. Base pairing © William Brown Syn- and anti-configurations: the basis for Z-DNA formation © Fundamentals of Biochemistry, 3rd edition Purine nucleotides, particularly guanine nucleotides, have a a tendency to exist in the “syn” configuration. A repeats of GC sequence causes a distortion in the double helix with the phosphates zig-zagging in the backbone. Sugar-base configurations that affect the conformation of DNA and RNA molecules © wikipedia C-2’ endo (South): Distance of phosphates: 7.0 Å; Favored in B-Form DNA C-3’ endo (North): Distance of phosphates: 5.9 Å; Favored in RNA and some DNA forms helical conformations Polynucleotides have a natural tendency to form helical conformations due to stacking interactions between the adjacent hydrophobic bases of the polymer Hydrophobic forces on planar bases drive stacking interactions Random coils (unstacked polymers) are favored in alkaline solution, in some organic solvents and at high temperatures Base Pair Geometry © Zac Pursell Metabolic roles of cellular RNA © Zac Pursell Structure of the RNA RNA double-helices exist in a variety of shapes base-pairing, stacking interactions, covalently modified bases, 3 base hydrogen bonding all contribute to compact and complex structure Ribosomal RNAs high degree of base pairing large numbers of “stems” and “loops” unpaired bases can interact with ribosomal proteins or RNA bases from other RNAs base-paired segments are mostly α-helical Some RNAs Capable of Carrying Out Catalysis self-splicing and self-cleavage reactions in vivo engineered catalysis in vitro Genomes dsDNA, linear, e.g., eukaryotic nuclear DNA, many viruses. dsDNA, circular, e.g., bacterial chromosomes, mitochondrial DNA, plasmids, some viruses. ssDNA, circular or linear e.g., the genomes of some bacterial, plant and animal viruses. ssRNA, e.g., the genomes of many viruses. dsRNA, e.g., the genomes of many viruses. Size of Genome © M. D. Golubovsky, Kenneth Manton; 2005","link":"/2021/10/22/LearnNotes/tulane-biochem-13/"},{"title":"Chromosome Structure","text":"DNA fiber and its packaging Introduction: E.coli, is 4.6 million base pairs (approximately 1.1 mm, if cut and stretched out (0.5 uM in width and 2 uM in length) Each human cells contains several meters of DNA (3.2 x 10 9 nucleosides ) if stretched end-to-end, the nucleus of a human cell, which contains the DNA, is only about 6 μm in diameter. This is geometrically equivalent to packing 40 km (24 miles) of extremely fine thread into a tennis ball! In bacteria, DNA gyrase aids in DNA packaging by causing an accumulation of negatively supercoiled (underwound) DNA. Some proteins are known to be involved in the supercoiling; other proteins and enzymes such as DNA gyrase (Topoisomerase)help in maintaining the supercoiled structure. © Xindan Wang, 2013 Supercoiled DNA Winding © psu.edu Supercoiled DNA can acquire different conformations or shapes (topologies). Excessively unwound DNA molecules exist as topological isomers with negatively supercoiled (plectonemic or solenoidal) forms. Unwinding Unwinding a DNA molecule without allowing it to rotate creates supercoils topoisomerase I Type I topos cleave single strand through use of covalent Tyr-DNA intermediate Type IA: relax negative supercoil; Tyr-5’-P-DNA (free 3’-OH) Type IB: relax pos. or neg. supercoil; Tyr-3’-DNA (free 5’-OH) © PDB, Topoisomerase I © PDB, Topoisomerase II Type I topos cleave single strand through use of covalent Tyr-DNA intermediate Type IA: relax negative supercoil; Tyr-5’-P-DNA (free 3’-OH)Type IB: relax pos. or neg. supercoil; Tyr-3’-DNA (free 5’-OH) All Type II topos can relax pos. and neg. supercoils and cleave double strand: DNA gyrase (prokaryotic) is the only enzyme that can introduce neg. supercoils © Ivan Laponogov, 2018 Topoisomerase Inhibitors Topoisomerase Inhibitors are Useful Anti-biotic &amp; -cancer Therapeutics Unknow Source Eukaryotic Chromosome © Ronald Hancock, 2012 © lumenlearning © microbenotes, 2021 Compositions: DNA Histones: H1, H2A, H2B, H3 and H4 Topoisomerase II Histon Genes © Izabela Makalowska, 1999 Histones Genes: No introns Multigene compound clusters Genes are duplicated (H2A, H2b, H3, H4) Highly conserved evolutionarily (except H1) Histone variants (CENP-A and H2AZ, etc.) Histone Core and the Nucleosome Nucleosome: Nucleosome Histone Octamer Core: H2A, H2B, H3, H4 DNA:Protein complex: 8 histone core proteins ~146 bp of wrapped DNA (twice) spacer region (~90 bp) Forms 11 nm nucleosome chromatin fiber “beads on a string” (~6-7X compaction of DNA). Stabilized through electrostatic interactions: DNA phosphate (-) charge Histones (+) charge (Arg, Lys) DNA wrapped around histones © Anthony T. Annunziato, 2008 Chromatin Structure 30 nm Chromatin Fiber Histone 1 (H1) bind DNA as it wraps nucleosome core. Six nucleosomes per helical turn. Nucleosomes stacked on top of one another in a zigzag forming (~100X compaction). Inactive chromatin in 30 nm fiber (or higher order). Higher Order Structure 30 nm fiber begins to loop. Forms a rosette arrangement constructed upon nuclear scaffold proteins. A coil forms of repeated rosettes. Each chromatid consists of numerous coils. However, more evidence suggests a lack of the existence of 30-nm chromatin. Fussner, E. et al. Open and closed domains in the mouse genome are configured as 10-nm chromatin fibres. EMBO Rep. 13, 992–996 (2012). Nishino, Y. et al. Human mitotic chromosomes consist predominantly of irregularly folded nucleosome fibres without a 30-nm chromatin structure. EMBO J. 31, 1644–1653 (2012). Hansen, J. C. et al. The 10-nm chromatin fiber and its relationship to interphase chromosome organization. Biochem. Soc. Trans. 46, 67–76 (2018). Instead, 11-nm fibers form DNA-loops © harvard.edu Interphase Chromatin © David Saintillan, 2018 Euchromatin (lightly staining) 11 nm active chromatin. Gene expression “on”. DNA replication of S phase. Heterochromatin (darkly staining) Condensed, inactive chromatin. Gene expression “off” Q&amp;A Q: How to read genetic information from highly packed chromatin? A: Basic principle: Loosen packed chromatin Post-translational modification on histone tails (enzymes) Chromatin remodeling (chromatin remodeling complex) Histone Tails Modifications © Jochen Erler, 2014 Occur on exposed histone tails (dashed lines). 3 Types of Modifications : Acetylation: decondensation. Methylation: condensation → prevents acetylation. Phosphorylation: decondensation → creates (-) charge. Oddly H3Ser10 phos. → condensation. Acetylation: Neutralizes histone (+) charge and electrostatic attraction to DNA. Opens chromatin → beads on string. HATs – Histone acetyltransferases on lysines e- amino groups (H3lys9). Deacetylation: Maintains (+) charge and electrostatic attraction to DNA. Closes chromatin – 30 nm fiber HDACs – Histone deacetylases Constituitively assoc. with silent genes Chromatin less sensitive to DNAse. Regulation: Chromatin Unwinding/Winding Unknow Source Activators (SWI/SNF) and repressors (H1) promote unwinding or winding. SWI/SNF complex binds enhancers and begin unwinding. Attracts HATs to acetylate histone tails. Further action continues to open chromatin. Equilibrium balance between HATs and HDACs to maintain unwinding/winding. Centromere and Telomere Telomere: TTAGGG Minisatellite Centromere: Various satellite components Hypervariable: ministatellites Structures see previous picture 0.1-20 kb of 6-64 bp repeated units. Several MB in length of tandemly repeated 5-170 bp sequences. &lt;100 bp repeats dispersed in chromosomes. Also Megasatellite: 100s of 3-5 kb repeats at different locations of some chromosomes. Genome-Wide Repeat Sequences: Transposons Lehninger, Fig 24-8 Retrotransposons: replicative (or copy) transposition. LINEs, SINEs and LTRs. DNA transposons: Conservative transposition. Cut and paste mechanism. Autonomous vs. nonautonomous transposition. Telomeres and The End Replication Problem Problem? Lagging strand end will shorten by ~ 1 primer length every genome duplication Solution? Telomerase! Ribonucleoprotein Complex That Catalyzes 3’ Telomere Extension Source Unknow Telomere functions, cancer and aging The primary role of telomeres is to protect chromosome ends from recombination, fusion, and from being recognized as damaged DNA. Maintaining Telomere length by telomerase is crucial for the survival of cancer cells in the vast majority of tumors. (Highly expressing telomerase can immortalize normal cells) Telomere length shortens with age. Progressive shortening of telomeres leads to senescence and apoptosis, affecting the health and lifespan of an individual. Centromeres across species Source Unknow Functions of centromeres and kinetochores during mitosis: chromosome segregation Genomic Instability and Cancer © myeloma.uams.edu","link":"/2021/11/26/LearnNotes/tulane-biochem-14/"},{"title":"Amino Acid|Graduate Biochemistry 2| Tulane","text":"Overview Protein Structure Proteins are polymers of amino acids Native proteins are folded into a unique three dimensional structure The three dimensional structure is responsible for specificity and biological activity The structure is determined entirely by the primary sequence of amino acids through the physical &amp; chemical properties of the amino acids Amino Acid Properties Chemical Structure R group is variable 20 amino acids are found in proteins Amino acids are chiral (optically active) Amino acids in proteins always have the L configuration (Equivalent to the configuration of glyceraldehyde that rotates polarized light to the left) Levorotatory – Leftward rotation of light Dextrorotatory – Rightward rotation L amino acids are not all Levorotatory 20 AA Remember the abb. and name and groups of all amino acids Gly G Glycine Glycine is in the β turn Ala A Alanine Every where -&gt; hydrophobic but not really strong Val V Valine hydrophobic, strictly in shape Leu L Leucine … Ile I Isolucine β branched Met M Methionine containing sulfate, hydrophobic Pro P Proline tight turn Phe F Phenylalanine Tyr Y Tyrosine Phenylalanine-(OH) Trp W Tryptophan largest hydrophobic group Asp D Aspartate β Carboxyl Glu E Glutamate γ Carbocyl Lys K Lysine ε Amino Group Arg R Arginine γ Guanidino Group His H Histidine β Imidazole Group Ser S Serine &amp;beta hydroxyl Thr T Threonine hydroxyl gorup Asn N Asparagine Amide Group; Can not accept proton Glu Q Glutamine Amide Group; Can not accept proton Cys C Cysteine Properties: Aliphatic (hydrophobic) Secondary Structured Aromatic (hydrophobic) Charged Polar, uncharged Ionization Properties of Amino Acids AA Function Group pKa Asp -CH2-COO- 3.9 Glu -CH2-CH2-COO- 4.3 Lys -CH2-CH2-CH2-CH2-NH3+ 10.8 Arg -CH2-CH2-CH2NH-C(-NH2)=NH2+ 12.5 His -CH2-Imidazole 6.5 primary structure Direction: N -&gt; C Average molecule weight of per amino acid is ~110. Properties of the Peptide Bond Electronic resonance gives the central -C(=O)N(H)- atoms some double-bond character Double bond character gives these bonds a generally planar (not tetrahedral) shape and rigidity Coplanarity severely limits the number of accessible conformations Cis-trans isomerization Trans peptide bonds are energetically preferred Cis peptide bonds are rare: 0.05% of all non-proline peptide bonds are cis 6.5 % of all X-Pro peptide bonds are cis Rate of conversion between cis and trans is slow Trans: opposite Cis: same side Conformational Properties of Polypeptides Protein backbone conformation can be described with 2 torsion angles Phi (Φ) and Psi (Ψ) around Cα Steric clashes make only some combinations of Φ and Ψ permissible The requirement for hydrogen bonding between backbone groups in folded proteins further limits the observed values for Φ and Ψ $\\phi$ $\\psi$ Ramachandran Plot © HarvardX © Sepp Hochreiter Secondary Structure of Polypeptides Hydrogen Bonds are weak noncovalent interactions between polar groups. In a folded protein, backbone groups are always involved in hydrogen bonds. Hydrogen bonding along with the allowed φ , ψ torsion angles determine the possible types of secondary structure Secondary structure is the local conformation the backbone Secondary structure is defined by Hydrogen bonding patterns and Φ , Ψ torsion angles α helix © PDB ID=1SI4 Right handed helix Interactions are local Defined by Hydrogen-bonding pattern (ith) C=0 - - - NH (i+4)th Accounts for well more than half of all protein structure Pitch: 3.6 residues per turn Rise: 1.5 Å per residue (5.4Å/turn) 13 atoms in the hydrogen bonded loop Hemoglobin - an all α helical protein Close packing in an α-helix Helices are very tightly packed structures The C=O::HN hydrogen bonds are partially buried within the core of the helical structure Because of steric constraints and hydrophobic interactions between side chains, the amino acids have very different propensities for being in an α-helix. The β-pleated sheet © PDB ID=2QLE Chains are extended Interactions are nonlocal Can be parallel or antiparallel Antiparallel is preferred Can contain from 2 to 25+ strands Accounts for most non-helical protein structure Length: 3.3 Å per residue Influenza Neuraminidase an all β-sheet protein Reverse Turn Short 180º turn of ~ 4 residues Connects elements of secondary structure Interactions are local Often occur at surface of protein Many types are defined by hydrogen-bonding patterns The hairpin motif others 3-10 helix Uncommon right-handed helix Hydrogen-bonding pattern: C=0 (i) - - - NH (i+3) Often found at the ends of α-helices π helix Rare right-handed helix Hydrogen-bonding pattern: C=0 (i)- - - NH (i+5) Ω loop Found at the surfaces of proteins Base of loop is part of a proteins secondary structure, while the loop is disordered as in the letter omega (Ω ) Random coil No regular secondary structure Highly flexible Portein Folding collapse; Mostly drived by hydrophobic hydrogen binding group are fold in the core of the protein Visual Schematic; Ribbon diagram; Cα trace; CPK space-filling; Solvent-accessible surface Structure of protein Secondary; Tertiary; Quaternary Anfinsen-Merrifield experiments Evolution in sequence protein motif β-sandwich coiled-coil EF hand Domain structure of large proteins Quanternary structure of protein Protein Folding Levels of Structure Exp: Ribonuclease A; 124 residues; 4 disulfide bonds; Unfolded with denaturants (1. urea or guanidine; 2. Oxidase/reduce the disulfide bound.) Structure motif $\\beta \\alpha \\beta$ $\\alpha \\alpha \\alpha$ $\\beta \\beta$ … Tim-brrel: ($\\beta \\alpha \\beta \\alpha$)4","link":"/2021/08/27/LearnNotes/tulane-biochem-2/"},{"title":"DNA Transcription,  Transcription Factor Binding","text":"RNA polymerases (RNAPs) Transcription of DNA to RNA RNA is composed of nucleotides containing ribose sugar and four bases uracil, adenine, guanine and cytosine Bacteria: One enzyme for all of RNA synthesis Eukaryotes: At least three major enzymes (RNAP-I,-II,-III) RNA Strand Terminology These terms describe the same strand… Template strand – used by RNA pol II to create RNA. Has complementary antiparallel sequence from RNA. Non-coding strand – This strand doesn’t code for protein. The complementary antiparallel strand would. Antisense strand – This strand is the opposite of the coding strand and thus is antisense. The RNA message must make sense. Replace T with U. The eleongation of the RNA is from 5’ → 3’, as the result, the reading direaction is from 3’ → 5’ Bacterial Promoter Consensus Sequences Expression controlled by interactions of promoter elements with RNA polymerase and specific repressors/activators. Bacterial Promoter Elements: UP element (-40 to -60; A-T rich) strongly stimulates transcription. TATAAT (-10) and TTGACAT (-35) regions. Help define transcription start and strand usage. Bacterial Transcription Initiation © archive.cnx.org Bacterial RNAP © Jookyung Lee Holoenzyme versus core enzyme. Core subunits: α2ββ’ω (400 kDa). Holoenzyme: core subunits plus σ factors A shape of crab claw formed by the β and β’ subunits RNAP structure from Thermus aquaticus Different σ factors of E. coli RNAP Five σ(Sigma) factors in E. coli gene expression σ 70: Most genes σ 32: Heat shock proteins σ 28: Flagellar operon σ 38: Stress-response genes σ 54: Nitrogen metabolism genes Regulating the transcription of coordinately expressed groups of special-purpose genes Bacterial Transcription Elongation During elongation, the prokaryotic RNA polymerase tracks along the DNA template, synthesizes mRNA in the 5’ to 3’ direction, and unwinds and rewinds the DNA as it is read. © archive.cnx.org RNA synthesis proceeds in the 5’ -&gt; 3’ direction. Transcription elongation causing DNA supercoiling, relaxed by topoisomerases RNAP following the template strand, the transcript being wrapped around the helix every 10bp (no strain and no supercoiling of the DNA). Instead, DNA rotates avoiding transcript entanglement. Bacterial Transcription Termination Intrinsic termination Transcription termination sites in E. coli A series of 4-10 A-T base pairs with A’s on the template strand, transcribed into a poly-U tail at the 3’ end of RNA. A G-C rich region with a palindromic sequence that immediately precedes the A-T’s, allowing self-complementary “hairpin” structure formation for the RNA transcript. Key factors for proper chain termination Structural stability of RNA transcript due to G-C rich hairpin Weak base pairing of oligo(U) to template DNA Rho factor-dependent © Daniel L.Kaplan, et al The amino-terminal domain of Rho factor (blue) binds to the RNA sequence of Rho utilization site (rut). (Step 1) The carboxy-terminal domain of Rho (orange) binds the mRNA downstream from rut, and the Rho hexameric ring closes. (Step2) Ring closure propels Rho moving close to RNAP (Step 3). Rho dis-engages RNA and RNAP from DNA. (Step 4). Eukaryotic Transcription Three types of nuclear RNAPs Subunit compositions of nuclear RNAPs All three yeast RNAPs have five core subunits, similar to those of E. coli RNAP. α-like subunits different between RNAP-II and RNAP-I, -III Four other subunits are shared Eukaryotic Transcription – RNAP II © Karim-Jean Armache Yeast RNAP II structure resembling bacterial RNAPs A crab claw-like shape Positions and core folds of homologous subunits Negatively charged surface except for the DNA-binding cleft Eukaryotic Transcription RNA biosynthesis: The “clamp” of the Rpb1 subunit moves down to trap DNA between the two claw Unwind DNA at the active site The “wall” of Rpb2 kinks the template by 90° out of the active site One base of the template points at the active site (magnesium) This base is paired with the ribonucleotide base of RNA above a “pore” at the end of a “funnel” to the protein exterior (NTP entrance) A rudder loop of the clamp separates the RNA-DNA hybrid helix, allowing the dsDNA to reform. RNA translocation: The “bridge” helix of Rpb1 contacts the DNA base at the active site The bridge helix switches between straight and bent conformation Bridge helix bending pushes away the DNA-RNA bases at the active site The straight conformation yield an empty pocket for entry of the new NTP Transcription Inhibition as a Therapeutic Target for Cancer mRNAs of many oncogenes, as well as regulators of other key processes such as cell proliferation, angiogenesis, and apoptosis, typically have shorter half-lives. Transformed and non-transformed cells exhibit the differential sensitivity to RNA-directed agents. Inhibiting transcription Source Unknow α-amanitin © Srivindhya Kolluru, 2019 © David A. Bushnell, 2002 Eukaryotic Transcription promoters Source Unknow Mammalian Gene and Proximal Promoter (class II) Proximal Promoter: Within 200 bp of transcription start. TATA Box (TATAAA) -30 upstream of start +1); fixed position. Recruits TATA Binding Protein (TBP) complex to promoter. Major assembly point for Transcription Preinitiation Complex (PIC). Initiator Region (Inr): Sequence where DNA is unwound. +1 usually within or near. Other activation elements: Critical for docking basal transcription apparatus. Tissue-specific elements. Eukaryotic Promoter with Activator Proteins &amp; Repressor Activator Proteins Transcriptional Repression © Lehninger, Fig 28-29 © Lehninger, Fig 28-29 1. Transcriptional Activators: DNA binding (green) and activation (pink) domains. Bind enhancers and UAS at varying distances. 2. Activator functions: A. Chromatin remodeling (methylation-HMT/ acetylation-HAT). B: Mediator facilitates PIC assembly. Repressors bind UAS/enhancers → displace activators.Prevents mediator → No PIC formation. Attracts HDACs and HMTs → heterochromatin How is PIC Assembled? © Lehninger, Fig 28-30 1. Mediator facilitates TBP and TFIIB binding promoter (TATA box).2. Other basal TFs and Pol II bind.3. Phosphorylation of the carboxyl-terminal domain (CTD) of Pol II by TFIIH → transcription initiation. Six transcription factors (TFs) for class II promoters Equivalent of a bacterial σ factor Highly conserved from yeast to human Required for the synthesis of all mRNAs Allow a low (basal) level of transcription, which can be increased by the gene-specific activators Phospho-code on RNAP II CTD © Sylvain Egloff, 2008 Non-canonical functions of transcription CENP-A defines centromeric chromatin RNAP II transcription facilitates the deposition of CENP-A into centromeric chromatin © F. Lyn Chan, 2012 ChIP-Seq: determine protein distribution on chromatins RNA-Seq: determine the expression patterns of genes and other DNA sequences Inhibitors of DNA synthesis and their specificities AZT and DDI: reverse transcriptase, chain terminate nuceoside analogues of guanosine: phosphorylated by a viral kinase Polymerase processivity Enhanced by a Clamp β clamp in bacteria PCNA in eukayotes loaded onto dsDNA on calmp Clamp loader couples ATP Hydrolysis to Clamp Loading Sliding clamp + ATP: open and bind DNA; ATP → ADP, DNA releases Biological advantages of DNA Provides stable, yet mutable storage of genetic information. Metabolic stability and availability of repair mechanisms ensure long-term survival under a variety of physiological conditions. Serves as a template for accurate and adaptable replication of genomes. This biological role ensures the transmission of important physiological functions for multiple generations. Serves as a template for the expression and regulation of genetic information. This biological role facilitates adaptation of genomes to changing physiological environments. Amenable to diversification (i.e., can evolve). Mutation and genetic recombination (DNA rearrangements) are the two major driving forces in the evolution of genomic diversity and adaptation in nature. DNA ligases Eukaryotic DAN ligase use ATP rather than NADP initiation od DNA replication in E. coli origin region (OriC) ~245bp Duplex unwinding by DNA helicase Exposed ssDNA allows SSB and helic … Initiation: OriC-DnaA intercation → Entry of SSB and DnaB (hexlicase) → ENtry of promase → RNA primers are synthesized and the elongation complexes for 2 DNA replication forks are assembled Elongation: Prokaryotic DNA replication A typical DNA replicsome synthesis of leading strand are coupled with lagging strand by clamploader complex. The e.coli Pol III holoenzyme … Pols enyzme subunit factors Eukaryotic DNA replication: Pro: no cell cycle and start every time Eu: onece anc only once in S phase; highly regulated G1: Preparing Checkpoint: end of the S phase Time is variatd Eukaryotic chromaomse have multiple origins… Pro: single initial site Euk: multiple initial site Eukaryotic replication initiation is hihgly oreder… well regulated and complex… Helicase (Mcm2-7) Sld2/3 phosphorylated by CDK Super Current Biochemical Reconstitution of Regulated replication origin firing Termination in prokaryotes Ter sites, 2 converging new ds circular DNA molecules separated from each other by recombination and with assistance of Cell are constantly exposed to agents that can cause damage to their genome Repair, tolerant, destroy the cell Types of mutation Transition: AT → G/C Transversion: A/T → C/G Frameshift: GGGGGG → GGGGG Base alteration Oxidation: 8-oxodG(antl)-dC(antf) 8-oxodG(synl)-dA(antf) The rotation of the bound which cause the shift of the side chain and attribute difference hydrogen bonds. 3 to 2, C to A Alkylation; Cross-links Exogenous Damage: Exposure to ultraviolet radiation Absorbed by adjacent pyrimidine bind and form double bond and cause mutation or lethal during replication/transcription Repair Base Excision Repair Single Nucleotide Nucleotide Excision Repair oligonucleotide Mismatch Excision Repair mismatched base Base Excision Repair how recognize AP site Donw string/ leading string doesn’t matter ligates involved Nucleotide excission repair (NER) recognize Enzymes (XPC) recruit other factors unwinding, mutation is exposed Some protein was recruited and mistake was cut / rescued. Recognition → resynthesis Xeroderma pigmentosum (XP) Accelerated skin cancer; mortality likely due to metastatic melanoma or squamous cell carcinoma MMR pathway - E. Coli MutS, MutL, MutH, ATP MutH: cut the strand (down/leading) methelation is critical here RNA polymerases Transcription using DNA to RAN Bacterial: ON enzyme for all of RNA synthesis Eukaryotic: At leased Three I II III Strangs 1: Template; Non-coding; Anti-sense: Completed strand Strands 2: Sense strand: coding strange of the DNA Non-completed strand Bacterial promoter consensus sequences UP Element; -35; -10; RNA stra +1 -35; -10: promoters (similar to regulatories in Eukaryotic.) Expression controlled by interactions of promoter elements with RNA polymerase and specific repressor/Activators Bacterial RNAP Holoenyme versis core enzyme Core subunits: α₂ββ’ω (400kDa) Holoenzyme: core subunits plus factors … Five σ factirs in E. coli gene expression Exp: (not important) σ 70: Most genes σ 32: Heat schock proteins Trascription Elongation RANP trancks along the DNA template, synthesizes mRNA in te 5’ to 3’ direction and unwinds and rewinds the DNA as it reads. Transcription elongation causing DNA supercoiling, relaxed by topisomerases Termination Transcription Terminattion A series of 4 - 10 base Sequence depended: CGGCGCTTTTTT (CG rich region; AT rich region) ρ factor-dependent The amino-termina domain of ρ factor binds to hte RNA sequence of ρ utilization site the carboxy-terminal domain of ρ hexameric ring closes Ring closure propels ρ moving close to RNAP ρ dis-engages RNA and RNAP from DNA Eukaryotic Transcriotion Three types of Nuclears RNAPs I: rRNA (28S, 18S) II: mRNA; snRNAs; miRNAs III: tRNAs; 5S rRNA; snRNA U6 7S RNA; other stable short RNAs Transcription Subunit compositions of nueclear RNAPs β’; β; αI; αII; ω All yeast RNAP has five subunits similar to Bacteria RNAP II Yeast RNAP II strcture resembling bacterial RNAPs A vrab claw-like strcuture RNA biosynthesis The clamp of the Rpb1 subunit moves down to trap DAN between the two claw Unwind DNA at the active site Wall of Rpb2 kinks the template by 90° out of the active site One vase of the template points at the active site This base is paired with the ribonucleotide RNA translocation Transcription promoters Class I, II, II to RAN poly I, II, III Mammalian Gene and proximal promoter (Class II) Proximal region (-200 ~ -30), within 200 bp of transcription start; similar to the -10; -35 in the bacteria’s TATA Box (TATAAA) Recruits TATA binding protein … Initiator region (Inr) Other activation elements EPromoter and Activator proteins Transcriptional Activators: DNA binding domain; activation domain; Activator functions: Chromatin remodeling (acetylation-HAT); Mediator facilitates PIC assembly Repressor Bind UAS.enhancers → displace activators Prevent mediator → no PIC formation Attracts HDACs and HMTs → heterochromatin PIC Assmbled mediator facilitates TBP and TFIIB binding promoter Other basal TFs and Pol II bind phosphorylation of the CTD of Pol II by TFIIH → Transcription initiation Six transcription factors for clas II promoters (Not important) ==Phospho-code on RNAP II CTD TFIH: Phosphate the Ser5 would initiated the transcription activity P-TEFb: phospholate Ser2 to maintain the elongation state Non-canonical functions of transcription CENP-A defines centromeric chromatin RNA… ChiP-Seq: Determine protein distributed on chromatins RNA-Seq: Expression profiles Transcription inhibition as a therapeutic target for cancer mRANs of many oncogenes Transformed → RNA-directed agents: different sensitivity. Alpha-amanitin: from mushroom directed binding to RNAP, adn block the bridge to repress the conformation change Bacterial Transcription Eukaryotic transcription RNAP II CTD phospho-code Non-canonical functions of transcription Assays to study transcription posttranscriptional Modification of Eukaryotic RNAs Role of 5’ cap Ribosomal recogintion during translation Cap structure 7-methylguanosin (m⁷G) joined to the mRNA first nucleotide Via a 5’-5’ tri-P brifge Involved Enzymes RNA riphosphatase removing the γ-P of the mRNA’s 5’ site mRNA guanlyltransferase (a capping enzyme) adding GMP. (Take GMP to the site) Guanine-7-methyltranserase (second capping enzyme) methylating guanine Capping enzymes bind to RNAP-II, which will switch RAN synthesis initiation to elongation () posttransicriptional Modification of Eukaryotic RANs Poly A tails; ~250 nt Cleavage and polyadenylation specificity factor (CPASF), cleaving up to 35 nt past the AAUAAA sequence Poly A polymerase generate poly A tail using ATP. (termination signals given to RNA-polymerase) CPSF binds to RNAP-II, coupling polyadenylation to transcription termination. Poly A tail binds to poly-binding protein, protecting from degradation, increasing mRNA stability. Exons and Introns Precurso mRANs (pre-mRNAs) are processsed by the excision of introns and the splicing (joing) of exons. Exon splicing in Two-Stage Reactions Invariant Sequences for splice junction GU at the intron’s 5’ AG at teh intron’s 3 (graph), the number under the NT means the ration you are supposed to see them on the Intron A branch point near the 3’ splice site Free G, not paire to the intron… A2’-5’ P-diester bind between the tinron A (OH²’) and the intron at teh 5’ splice site, forming a “lariat” structure. The Exon 1 OH³’ group at the 5’ splice site from a 3’-5’ P-diester bind with the Exon 2’ at the 3’ splice site, releasing the intron with the free OH³’ group. The intron keeps the lariat structure. Note: Splicing proceeds w/o free energy lose, Cleavage of one P-diseter bond and formation of a new bond. Spliceosome-aided RNA splicing Splicing could be focilited by the protein Splicesome.60S spliceosome particle containing five small nuclear RNAs + Ribonucleoproteins (U 1~6, no 3) U1 recognizes the 5’ splice junction U2 recognizes the branch point (intron A) The binding of U4-U5-U6 forms spliceosome. RAN cleavage at the 5’ splice site RNA cleavage at the 3’ splice site Intron … Self-Splicing RNA Group II Intron Exson 1 and Exon II aligned together the giant rondant was splicesd by themselves Group I intron: not Intron A to initiated the reaction G , GTP, GDP, GMP… as the starting site The 3’-OH of … Summary of spliceosome-aided Splicing and Self-Splicing In goup I introns, aguanosine cofactor (G) tat is not part of the RNA chain associates with the active site. The 3’-hydroxyl group of this G attacks the 5’ splice sit; The reaction is similar to those involving the 2 hydroxyl groups of branch sites as in group II introns and RNA inrons spliced in spliceosomes. The subsequent trans-e… Interactions of RNAP-II with capping enzyme, splicing and CPSF Figure 16-5 Aminoacyl-tRAN Synthetase Attach amino acids to tRNAs Two step reactions Amino acid activation by the reaction with ATP (Aminoacyl-tRNA syntheiase) Formation of an aminoacyl-tRNA Aminoacyl-tRAN SYnthetases The synthetase enzymes have an elongated shape. Binding the anticodon of tRNA near the one end of the enzyme. Binding the A.a. acceptor stem of tRNA near th other end Proofreading by Aminoacyl-tRAN Synthetase Binding to the amino acid substrate pocket of tRNA Synthetase that consists of the zinc ion.L-Group: Megan, Ryan, Ka Threonine binds at this pocket b/c it can coordinate Zn2+ using it NH2 and OH groups tRNAthr is tRNA for threonin. Attaching ThR to tRNAthr makes Thr-tRNAthr (tRNA is correctly charged) Attaching Ser to tRNAthr makes Ser-tRNAthr (tRAN is mischarged) Acetylation definition histone modification Acetylation by HATs Recognition by bromodomains Deacetylation by lysine deacytelases (HDACs adn Sirtuins) cofactors: Zinx, NAD Methylation by histone methyltransefrases (HMTs) The donor: S-adenosylmethionine (SAM) SET domains in SAM Recognition by chromodomains and plant homeodomain (PHD) fingers Aromatci cage: to recognize Chroodomain-containing heterochromatin protein 1 (HP1) function: regulated transcription Demethylation Lysine-specific histone demethylases (LSD1 and LSD2)-FAD-dependent Jumonji C-domain (JMJC) family members - F2a and α-ketoglutarate-dependent Chromatin structure Chrmosome → chromatin fiber → Beads on a string DNA wound on nucleosomes → Histones + Doble helix Heteochromatin: Highly condensed nonexpressing DNA. (PS: Canot be transcripted because transcript machinary can’t recognize and bind) Euchromatin: Less condensed, Transcriptionally active DAN H2A, H2B, H3, H4 Histone Modification Histone was circled in the center of the DNA, but with tail out of the stracture and cann’t be visualized by cristal structure. But they are the key site for the Methylating or Acetylating acKL acetyl lysine meR: meK: PS: phosphoryl serine … Histone Code Histone modification is the signals of transcription on/off. Histone Acetyltraseferases (HATs) Histone + Me-CoA → CoA + Me-Histone Structure of the HAT domain from Tetrahymena thermophila The enzyme is deeply clefted The histone H3 peptide KSTGGK14APRK! and coenzyme A are bound at the deep cleft. Catalysis appears to involve water-mediated proton extraction from the substrate lysine by a glutamic acid general base. Acetylated Lys recognition by Bromodomains Bromodomains specifically bind acetylated lysine residues on histones. A deep hydrophobic pocket (hole) accommodates the acetyl-Lys side chain (PS, the hole recognize the acetyl-Lys specificity) TAF1: has two brpmodomains and dipart from each with ~25Å, seperated by 7 ~8 residues. A subunit of transcription factor TFIID (PDBid=1eqf) … … Role of TAF1 double Bromodomain TAF1 double bromodomain targets TFIID to promoters A refined proposal for transcription initiation A AHT-cotaining coactivator binds to upstream DAN binding protein (An activator) The HAT acetylates nearby histone tails TFIID is recruited to the site via the binding of the TAF1 double bromodomain to the acetyl-Lys residues of histones. followed by recruitment of other initiation factors and RNAP-II for transcription initiation. Histone Deacetylases (HDACs) 18 HDAC enzymes that deacetylate acetyl lysine substrates including histones. Histone deacetylase … … Reaction mechanism: - Bound Zn2+ mediates the nucleophilic attack of water on acetylated lysine, forming a tetrahedral oxyanion intermidiate - The carbon-… Situins NAD⁺-dependent reaction nucleophilic addition to form a C1’-O-alkylamidate intermediate and free nicotinamide. Teh 2’hydroxy group of the NAD⁺ ribose attacks the C1’-O-alkylamidate to form the 1’,2’cyclic intermediate The formation of deacetylasted lysine and 2’-O-acetyl-ADP ribose. Thus, nicotinamide, a deacetylated lysine-containing histone, and 2’-O-acetyl-ADP Histone Methylation Methylation at Lys and Arg of H3 and H4 tends to silence the genes, inducing heterochromatin formation However, trimetheylated Lys4 of H3 is associated with active genes (methylation can add one to 3 methyl in a time) (give a exampel) Histone methyltransferases (HMTs) use S-adenosylmethionine (SAM) as a methy donor The HMT enzymes have a SET domain containing the catalytic site for methylation. Structure of SET7/9 (PDB=1o9s) SET7/9 mono-methylates Lys4 of H3 SAM (SAH) adn the Lys4-containing peptide bind to oppsite sites of the protein The lys4 side chain is inserted through a narrow channel and positioned for methylation by SAM. Methylated Histone Recognition Chromodomains and plant homeodomain (PHD) fingers bind to mono, di- or tri-methylated Lys by an aromatic cage. Fits in the shape, lots of electron to nutralize the positive charge of the methyl group??? Consequence of Methylated hisone Recognition The chromodomain heterochromatin protein 1 (HP1) bidns to methylated H3 Ly9, contributing to gene silencing, Bound HP1 recruitsthe HMT Suv39h, methylating nearby histone lysines (H3K9), thereby recruiting more HP1 and forming HP1 complexes. This mechanism explains how heterochromatin spread to silence neighboring genes. HP1 clust prefer to form a tide complex and so, silence the DNA transcription. Histone Demethylases LSD1 &amp; LSD2 demethylases Flacin adenine dinucleotide (FAD)- dependent amine oxidation Demethylate mono- and dimethylated substrates The JMJC family Dioxygenases dependent on Fe2+ and α-ketoglutarate Demethylates mono-, di- and trimethylated substrates Focuse on the Chemical reaction Understanding the demethylation reaction from the LSD1 Structure The LSD1 is bound to a 21 amino acid H2 peptide with a mutation of Lys4 to Met. Modeling predicts that methylated Lys3 binds in a solvent inaccessible area in front of the FAD cofactor (electron extraction). Understanding … JMJD3 structure THe JMJD3 is bound to a H3 pep with a trimetrhylated Lys27 The cofactor analog N-oxylayglycine NOG not α-ketoglutarate and nickel not iron are used to prevetn teh reaction The methylated Lys27 side chain insertes deep into the catalytic pocked, close to the cofactor analog and nickel for demethylation reaction. Chromatin Writers, Readers and Erases brif adn = = Recombination homologous reconbination, need small similar sequnces Site-specific reconbination, nees specific DNA sequence ranspositions, no Specific DNA Non-homologous DNA end-joining (), specific proteins that repair dsDNA breaks Homologous reconbination Required for accurate chomosome segregation repairing and tolerating DNA damage Recovery of stalled or broken replication forks Defects in recombination can contribute to genome instability and cancer predispositions Biological roles Genetic reassortments in gametogenesis Repair of DNA damages Repair replication forks laterl DNA transfer between ceels therOther, deletions, inversions, translocations, etc. How HR produces deletions, insertions and inversions Incersion: DNA fold in a revised direction, The DNA form a arch bridge and at the foot of the bridge connected Deletion and insertion DNA fold in a same direction. A circle formed and the cross point was connected together and the circle was deleted. (Insertion happens the similar way.) Translocation that casue cancers Chronic myeloid leukemia BCR/ABL mRNA p210 fusion protein ABL are concertive hyregulated RTK, BRC is a higly active promoter which drive the high expression of the ABL which resbonsible to growth and differentiation. Holliday Model of Recombination Nicking → Strand Exchange → Branch Migration → Resoltion → Recombination molecules SOS response: Mutagenic Survival Pathway of Last Resort DNA Damges → ssDNA or dsDNA break → No Transcription Normal LaxA turning of LexA-Regulated gene Auto-cleavage of LaxA recruitment lots of RecA. RacA: Pre-synapsis → Synapsis → ppost-synapsis RacA complex driving homology search and alignment of complementary sequences. Site-specific reconbination: intergration of lambda phage DNA into the E.coli Chromosome","link":"/2021/11/27/LearnNotes/tulane-biochem-15/"},{"title":"Catalytic RNAs: Splicing and Translation","text":"Posttranscriptional Modification of Eukaryotic RNAs Role of the 5’ cap Ribosomal recognition during translation Cap structure 7-methylguanosine (m7G) Joined to the mRNA first nucleotide Via a 5’-5’ tri-P bridge Involved enzymes RNA triphosphatase removing the γ-P of the mRNA’s 5’ site mRNA guanylyltransferase (a capping enzyme) adding GMP Guanine-7-methyltransferase (a capping enzyme) methylating guanine Capping enzymes bind to RNAP-II, which will switch RNA synthesis initiation to elongation Poly(A) tails ~250 nt (~80 nt in yeast) Cleavage and polyadenylation specificity factor (CPSF), cleaving up to 35 nt past the AAUAAA sequence Poly(A) polymerase generate poly(A) tail using ATP. CPSF binds to RNAP-II, coupling polyadenylation to transcription termination. Poly(A) tail binds to poly(A)-binding protein, protecting from degradation, increasing mRNA stability. Exons and Introns Precursor mRNAs (pre-mRNAs) are processed by the excision of introns and the splicing (joining) of exons Exon Splicing in Two-Stage Reactions © Zhichao Tang, 2021 Invariant sequences for splice junction: GU at the intron’s 5’ AG at the intron’s 3’ A branch point (Intron A) near the 3’ splice site Free guanosine, GMP, GDP, or GTP not part of the intron A 2’-5’ P-diester bond between the intron A (OH2’) and the intron at the 5’ splice site, forming a “lariat” structure. The Exon 1 OH3’ group at the 5’ splice site form a 3’-5’ P- diester bond with the Exon 2 at the 3’ splice site, releasing the intron with the free OH3’ group. The intron keeps the lariat structure. Note: Splicing proceeds w/o free energy lose. Cleavage of one P-diester bond and formation of a new bond. Note: Splicing proceeds w/o free energy lose. Cleavage of one P-diester bond and formation of a new bond. Spliceosome-aided RNA splicing 60S spliceosome particle containing five small nuclear RNAs + ribonucleoproteins (U1, U2, U4, U5 and U6) 1. U1 recognizes the 5’ splice junction 2. U2 recognizes the branch point (intron A)3. The binding of U4-U5-U6 forms spliceosome.4. RNA cleavage at the 5’ splice site5. RNA cleavage at the 3’ splice site6. Intron degregradation © utexas.edu Self-Splicing RNA © Chen Zhao, 2017 Group II intron A bulged adenosine in Domain 6 attacks the 5’ splice site, forming a lariat intermediate (a 2’-5’ linkage) The 5’ and 3’ exons are ligated and the lariat intron is released © Chang HoLee, 2018 Group I intron: In the presence of guanosine, GMP, GDP, or GTP, the pre-rRNA is self- splicing. The 3’-OH of guanosine attacks the 5’ splice site, forming a P-diester bond with the intron. The 3’-OH of the exon 1’s 5’ end attacks the 3’ splice site of exon 2, joining the two exons. The 3’-OH of the intron attacks the nucleotide 15 residues from the intron’s 5’ end, yielding a cyclic form. Summary of Spliceosome- aided Splicing and Self-Splicing In group I introns, a guanosine cofactor (G) that is not part of the RNA chain associates with the active site. The 3’-hydroxyl group of this G attacks the 5’ splice site; the reaction is similar to those involving the 2’ hydroxyl groups of branch sites as in group II introns and RNA introns spliced in spliceosomes. The subsequent trans-esterification that links the 5’ and 3’ exons is similar in all three splicing mechanisms. Interactions of RNAP-II with Capping enzyme, splicing and CPSF Aminoacyl-tRNA Synthetases © Bioforums Attach amino acids to tRNAs Two step reactions Amino acid activation by the reaction with ATP Formation of an aminoacyl-tRNA The synthetase enzymes have an elongated shape. Binding the anticodon of tRNA near the one end of the enzyme. Binding the a.a. acceptor stem of tRNA near the other end. The bases of the anticodon are unstacked and splay outward, binding in separate recognition pockets of the Synthetase. Proofreading by Aminoacyl-tRNA Synthetase (tRNAthr Synthetase) © Justin C. Morse Binding to the amino acid substrate pocket of tRNAthr Synthetase that consists of the zinc ion Threonine (attached at the 3’ of tRNA) binds at this pocket b/c it can coordinate Zn2+ using its NH2 and OH groups Serine binds b/c it can coordinate Zn2+ using its NH2 and OH groups!! But valine cannot bind b/c it lacks the OH group. tRNAthr is tRNA for threonine. Attaching Thr to tRNAthr makes Thr-tRNAthr (tRNA is correctly charged) Attaching Ser to tRNAthr makes Ser-tRNAthr (tRNA is mischarged!) Ser-tRNAthr incubates with Thr-tRNA synthetase------&gt; Rapid breakdown: Ser and free tRNAthr !! Thr- tRNAthr incubates with Thr-tRNA synthetase------&gt; No breakdown! The flexible aa acceptor stem of tRNAthr can move the attached serine residue between the activation/catalytic site and the editing site. Since serine fits well at the editing site, the residue is removed from tRNAthr . Threonine is too large to fit at the editing site, the residue remains on tRNAthr . Ribosomes Prokaryotic 70S Eukaryotic (80S) 30S subunit: 16S rRNA, 21 proteins ( bond mRNA (red)) 40S subunit: 18S rRNA, 33 proteins 50S subunit: 5S and 23S rRNAs and 31 proteins [bound to three sites: exit (E), peptidyl §, and aminoacyl (A)] 60S subunit: 5S, 5.8S and 28S rRNAs and 49 proteins Summary of the Composition and Mass of Ribosomes in Bacteria and Eukaryotes Translation (Protein biosynthesis) Translation (Protein biosynthesis) Protein synthesis proceeds from N-term to C-term by a peptidyl transferase activity Chain elongation occurs by linking the growing peptide to the incoming tRNA’s aa. The growing peptide is transferred from the P site to the incoming aa-tRNA in the A site, resulting in the formation of a peptidyl-tRNA with one more aa residue in the A site. The peptidyl-tRNA is translocated to the P site to have an empty A site for a new aa-tRNA. The uncharged tRNA in the P site moves to the E site (not shown) for exiting. © 1970 American Association for the Advancement of Science. Miller, O. L. et al. Visualization of bacterial genes in action. Science 169, 392–395 (1970). Ribosomes read mRNA in the 5’ → 3’ direction. Active translation occurs on polysomes Multiple ribosomes can bind to a single mRNA transcript Initiation Initiation codon(AUG) in mRNA, N-formylmethionyl-tRNA, 30S rRNA, 50S rRNA, Initiation factors (IF-1, IF-2, IF-3) GTP, Mg Elongation Functional 70S ribosome (initiation complex), aminoacyl-tRNAs specified by codons, elongation factors (EF-Tu, EF-Ts, EF-G), GTP, Mg Peptidyl transferase activity not by rProtein, but by rRNA Termination and release Termination codon in mRNA, polypeptide release factors (RF1, RF2, RF3), GTP Translation - Initiation Almost half of E. coli proteins begin with the uncommon N-formylated Met (fMet). The fMet has an amide bond, which can grow only to the C-term side. fMet is removed by deformylation, followed by the removal of resulting Met sometimes. Selectivity for the Translation Initiation Site In E. coli, base pairing interactions of an mRNA Shine-Dalgarno sequence with the 16S rRNA allows ribosome to select the proper initiation codon. Prokaryotic Translation - Initiation © Gaurab Karki, 2017 IF-3 binds to the 30S subunit to dissociate the inactive 70S ribosome into 30S &amp; 50S mRNA and IF-2 forms a complex with GTP and fMet- tRNAfmet along with IF-1 bind to the 30S subunit. IF-1 and IF-3 are released and the 50S subunit binds to the complex, stimulating GTP hydrolysis by IF-2. It is followed by IF-2 release. “fMet-tRNA bound at the P site of 50S in the 70S initiation complex.” Prokaryotic Translation - Elongation © Gaurab Karki, 2017 Decoding: Ribosome binds an aa-tRNA, whose anticodon is complementary to the mRNA codon in the A site. Peptide bond formation: The peptidyl group in the P site is transferred to the aminoacyl group in the A site Translocation: EF-GGTP binding to A translocates tRNAs from “P and A” to “E and P”, releasing the free tRNA at E. GTP hydrolysis releases EF-GGDP Prokaryotic Translation – Termination © Gaurab Karki, 2017 In E. coli, the stop codons (UAA, UGA, UAG) have no corresponding tRNAs, recognized by release factors. RF-1 recognizes UAA and UAG. RF-2 recognizes UAA and UGA. RF-1 (or RF-2) recognize corresponding codons at the A site. (1) The peptidyl group of tRNA at the P site is transferred to water, releasing the polypeptide. (2) RF-3GTP binds to ribosome. GTP hydrolysis releases RF-1 (or RF-2). RF-3GDP is replaced by ribosome recycling factor (RRF), followed by EF-GGTP Upon GTP hydrolysis, RRF, EF-GGDP, mRNA and tRNA at the P site dissociate, yielding an inactive 70S ribosome. Inhibitors of DNA synthesis and their specificities AZT and DDI: reverse transcriptase, chain terminate nuceoside analogues of guanosine: phosphorylated by a viral kinase Polymerase processivity Enhanced by a Clamp β clamp in bacteria PCNA in eukayotes loaded onto dsDNA on calmp Clamp loader couples ATP Hydrolysis to Clamp Loading Sliding clamp + ATP: open and bind DNA; ATP → ADP, DNA releases Biological advantages of DNA Provides stable, yet mutable storage of genetic information. Metabolic stability and availability of repair mechanisms ensure long-term survival under a variety of physiological conditions. Serves as a template for accurate and adaptable replication of genomes. This biological role ensures the transmission of important physiological functions for multiple generations. Serves as a template for the expression and regulation of genetic information. This biological role facilitates adaptation of genomes to changing physiological environments. Amenable to diversification (i.e., can evolve). Mutation and genetic recombination (DNA rearrangements) are the two major driving forces in the evolution of genomic diversity and adaptation in nature. DNA ligases Eukaryotic DAN ligase use ATP rather than NADP initiation od DNA replication in E. coli origin region (OriC) ~245bp Duplex unwinding by DNA helicase Exposed ssDNA allows SSB and helic … Initiation: OriC-DnaA intercation → Entry of SSB and DnaB (hexlicase) → ENtry of promase → RNA primers are synthesized and the elongation complexes for 2 DNA replication forks are assembled Elongation: Prokaryotic DNA replication A typical DNA replicsome synthesis of leading strand are coupled with lagging strand by clamploader complex. The e.coli Pol III holoenzyme … Pols enyzme subunit factors Eukaryotic DNA replication: Pro: no cell cycle and start every time Eu: onece anc only once in S phase; highly regulated G1: Preparing Checkpoint: end of the S phase Time is variatd Eukaryotic chromaomse have multiple origins… Pro: single initial site Euk: multiple initial site Eukaryotic replication initiation is hihgly oreder… well regulated and complex… Helicase (Mcm2-7) Sld2/3 phosphorylated by CDK Super Current Biochemical Reconstitution of Regulated replication origin firing Termination in prokaryotes Ter sites, 2 converging new ds circular DNA molecules separated from each other by recombination and with assistance of Cell are constantly exposed to agents that can cause damage to their genome Repair, tolerant, destroy the cell Types of mutation Transition: AT → G/C Transversion: A/T → C/G Frameshift: GGGGGG → GGGGG Base alteration Oxidation: 8-oxodG(antl)-dC(antf) 8-oxodG(synl)-dA(antf) The rotation of the bound which cause the shift of the side chain and attribute difference hydrogen bonds. 3 to 2, C to A Alkylation; Cross-links Exogenous Damage: Exposure to ultraviolet radiation Absorbed by adjacent pyrimidine bind and form double bond and cause mutation or lethal during replication/transcription Repair Base Excision Repair Single Nucleotide Nucleotide Excision Repair oligonucleotide Mismatch Excision Repair mismatched base Base Excision Repair how recognize AP site Donw string/ leading string doesn’t matter ligates involved Nucleotide excission repair (NER) recognize Enzymes (XPC) recruit other factors unwinding, mutation is exposed Some protein was recruited and mistake was cut / rescued. Recognition → resynthesis Xeroderma pigmentosum (XP) Accelerated skin cancer; mortality likely due to metastatic melanoma or squamous cell carcinoma MMR pathway - E. Coli MutS, MutL, MutH, ATP MutH: cut the strand (down/leading) methelation is critical here RNA polymerases Transcription using DNA to RAN Bacterial: ON enzyme for all of RNA synthesis Eukaryotic: At leased Three I II III Strangs 1: Template; Non-coding; Anti-sense: Completed strand Strands 2: Sense strand: coding strange of the DNA Non-completed strand Bacterial promoter consensus sequences UP Element; -35; -10; RNA stra +1 -35; -10: promoters (similar to regulatories in Eukaryotic.) Expression controlled by interactions of promoter elements with RNA polymerase and specific repressor/Activators Bacterial RNAP Holoenyme versis core enzyme Core subunits: α₂ββ’ω (400kDa) Holoenzyme: core subunits plus factors … Five σ factirs in E. coli gene expression Exp: (not important) σ 70: Most genes σ 32: Heat schock proteins Trascription Elongation RANP trancks along the DNA template, synthesizes mRNA in te 5’ to 3’ direction and unwinds and rewinds the DNA as it reads. Transcription elongation causing DNA supercoiling, relaxed by topisomerases Termination Transcription Terminattion A series of 4 - 10 base Sequence depended: CGGCGCTTTTTT (CG rich region; AT rich region) ρ factor-dependent The amino-termina domain of ρ factor binds to hte RNA sequence of ρ utilization site the carboxy-terminal domain of ρ hexameric ring closes Ring closure propels ρ moving close to RNAP ρ dis-engages RNA and RNAP from DNA Eukaryotic Transcriotion Three types of Nuclears RNAPs I: rRNA (28S, 18S) II: mRNA; snRNAs; miRNAs III: tRNAs; 5S rRNA; snRNA U6 7S RNA; other stable short RNAs Transcription Subunit compositions of nueclear RNAPs β’; β; αI; αII; ω All yeast RNAP has five subunits similar to Bacteria RNAP II Yeast RNAP II strcture resembling bacterial RNAPs A vrab claw-like strcuture RNA biosynthesis The clamp of the Rpb1 subunit moves down to trap DAN between the two claw Unwind DNA at the active site Wall of Rpb2 kinks the template by 90° out of the active site One vase of the template points at the active site This base is paired with the ribonucleotide RNA translocation Transcription promoters Class I, II, II to RAN poly I, II, III Mammalian Gene and proximal promoter (Class II) Proximal region (-200 ~ -30), within 200 bp of transcription start; similar to the -10; -35 in the bacteria’s TATA Box (TATAAA) Recruits TATA binding protein … Initiator region (Inr) Other activation elements EPromoter and Activator proteins Transcriptional Activators: DNA binding domain; activation domain; Activator functions: Chromatin remodeling (acetylation-HAT); Mediator facilitates PIC assembly Repressor Bind UAS.enhancers → displace activators Prevent mediator → no PIC formation Attracts HDACs and HMTs → heterochromatin PIC Assmbled mediator facilitates TBP and TFIIB binding promoter Other basal TFs and Pol II bind phosphorylation of the CTD of Pol II by TFIIH → Transcription initiation Six transcription factors for clas II promoters (Not important) ==Phospho-code on RNAP II CTD TFIH: Phosphate the Ser5 would initiated the transcription activity P-TEFb: phospholate Ser2 to maintain the elongation state Non-canonical functions of transcription CENP-A defines centromeric chromatin RNA… ChiP-Seq: Determine protein distributed on chromatins RNA-Seq: Expression profiles Transcription inhibition as a therapeutic target for cancer mRANs of many oncogenes Transformed → RNA-directed agents: different sensitivity. Alpha-amanitin: from mushroom directed binding to RNAP, adn block the bridge to repress the conformation change Bacterial Transcription Eukaryotic transcription RNAP II CTD phospho-code Non-canonical functions of transcription Assays to study transcription posttranscriptional Modification of Eukaryotic RNAs Role of 5’ cap Ribosomal recogintion during translation Cap structure 7-methylguanosin (m⁷G) joined to the mRNA first nucleotide Via a 5’-5’ tri-P brifge Involved Enzymes RNA riphosphatase removing the γ-P of the mRNA’s 5’ site mRNA guanlyltransferase (a capping enzyme) adding GMP. (Take GMP to the site) Guanine-7-methyltranserase (second capping enzyme) methylating guanine Capping enzymes bind to RNAP-II, which will switch RAN synthesis initiation to elongation () posttransicriptional Modification of Eukaryotic RANs Poly A tails; ~250 nt Cleavage and polyadenylation specificity factor (CPASF), cleaving up to 35 nt past the AAUAAA sequence Poly A polymerase generate poly A tail using ATP. (termination signals given to RNA-polymerase) CPSF binds to RNAP-II, coupling polyadenylation to transcription termination. Poly A tail binds to poly-binding protein, protecting from degradation, increasing mRNA stability. Exons and Introns Precurso mRANs (pre-mRNAs) are processsed by the excision of introns and the splicing (joing) of exons. Exon splicing in Two-Stage Reactions Invariant Sequences for splice junction GU at the intron’s 5’ AG at teh intron’s 3 (graph), the number under the NT means the ration you are supposed to see them on the Intron A branch point near the 3’ splice site Free G, not paire to the intron… A2’-5’ P-diester bind between the tinron A (OH²’) and the intron at teh 5’ splice site, forming a “lariat” structure. The Exon 1 OH³’ group at the 5’ splice site from a 3’-5’ P-diester bind with the Exon 2’ at the 3’ splice site, releasing the intron with the free OH³’ group. The intron keeps the lariat structure. Note: Splicing proceeds w/o free energy lose, Cleavage of one P-diseter bond and formation of a new bond. Spliceosome-aided RNA splicing Splicing could be focilited by the protein Splicesome.60S spliceosome particle containing five small nuclear RNAs + Ribonucleoproteins (U 1~6, no 3) U1 recognizes the 5’ splice junction U2 recognizes the branch point (intron A) The binding of U4-U5-U6 forms spliceosome. RAN cleavage at the 5’ splice site RNA cleavage at the 3’ splice site Intron … Self-Splicing RNA Group II Intron Exson 1 and Exon II aligned together the giant rondant was splicesd by themselves Group I intron: not Intron A to initiated the reaction G , GTP, GDP, GMP… as the starting site The 3’-OH of … Summary of spliceosome-aided Splicing and Self-Splicing In goup I introns, aguanosine cofactor (G) tat is not part of the RNA chain associates with the active site. The 3’-hydroxyl group of this G attacks the 5’ splice sit; The reaction is similar to those involving the 2 hydroxyl groups of branch sites as in group II introns and RNA inrons spliced in spliceosomes. The subsequent trans-e… Interactions of RNAP-II with capping enzyme, splicing and CPSF Figure 16-5 Aminoacyl-tRAN Synthetase Attach amino acids to tRNAs Two step reactions Amino acid activation by the reaction with ATP (Aminoacyl-tRNA syntheiase) Formation of an aminoacyl-tRNA Aminoacyl-tRAN SYnthetases The synthetase enzymes have an elongated shape. Binding the anticodon of tRNA near the one end of the enzyme. Binding the A.a. acceptor stem of tRNA near th other end Proofreading by Aminoacyl-tRAN Synthetase Binding to the amino acid substrate pocket of tRNA Synthetase that consists of the zinc ion.L-Group: Megan, Ryan, Ka Threonine binds at this pocket b/c it can coordinate Zn2+ using it NH2 and OH groups tRNAthr is tRNA for threonin. Attaching ThR to tRNAthr makes Thr-tRNAthr (tRNA is correctly charged) Attaching Ser to tRNAthr makes Ser-tRNAthr (tRAN is mischarged) Acetylation definition histone modification Acetylation by HATs Recognition by bromodomains Deacetylation by lysine deacytelases (HDACs adn Sirtuins) cofactors: Zinx, NAD Methylation by histone methyltransefrases (HMTs) The donor: S-adenosylmethionine (SAM) SET domains in SAM Recognition by chromodomains and plant homeodomain (PHD) fingers Aromatci cage: to recognize Chroodomain-containing heterochromatin protein 1 (HP1) function: regulated transcription Demethylation Lysine-specific histone demethylases (LSD1 and LSD2)-FAD-dependent Jumonji C-domain (JMJC) family members - F2a and α-ketoglutarate-dependent Chromatin structure Chrmosome → chromatin fiber → Beads on a string DNA wound on nucleosomes → Histones + Doble helix Heteochromatin: Highly condensed nonexpressing DNA. (PS: Canot be transcripted because transcript machinary can’t recognize and bind) Euchromatin: Less condensed, Transcriptionally active DAN H2A, H2B, H3, H4 Histone Modification Histone was circled in the center of the DNA, but with tail out of the stracture and cann’t be visualized by cristal structure. But they are the key site for the Methylating or Acetylating acKL acetyl lysine meR: meK: PS: phosphoryl serine … Histone Code Histone modification is the signals of transcription on/off. Histone Acetyltraseferases (HATs) Histone + Me-CoA → CoA + Me-Histone Structure of the HAT domain from Tetrahymena thermophila The enzyme is deeply clefted The histone H3 peptide KSTGGK14APRK! and coenzyme A are bound at the deep cleft. Catalysis appears to involve water-mediated proton extraction from the substrate lysine by a glutamic acid general base. Acetylated Lys recognition by Bromodomains Bromodomains specifically bind acetylated lysine residues on histones. A deep hydrophobic pocket (hole) accommodates the acetyl-Lys side chain (PS, the hole recognize the acetyl-Lys specificity) TAF1: has two brpmodomains and dipart from each with ~25Å, seperated by 7 ~8 residues. A subunit of transcription factor TFIID (PDBid=1eqf) … … Role of TAF1 double Bromodomain TAF1 double bromodomain targets TFIID to promoters A refined proposal for transcription initiation A AHT-cotaining coactivator binds to upstream DAN binding protein (An activator) The HAT acetylates nearby histone tails TFIID is recruited to the site via the binding of the TAF1 double bromodomain to the acetyl-Lys residues of histones. followed by recruitment of other initiation factors and RNAP-II for transcription initiation. Histone Deacetylases (HDACs) 18 HDAC enzymes that deacetylate acetyl lysine substrates including histones. Histone deacetylase … … Reaction mechanism: - Bound Zn2+ mediates the nucleophilic attack of water on acetylated lysine, forming a tetrahedral oxyanion intermidiate - The carbon-… Situins NAD⁺-dependent reaction nucleophilic addition to form a C1’-O-alkylamidate intermediate and free nicotinamide. Teh 2’hydroxy group of the NAD⁺ ribose attacks the C1’-O-alkylamidate to form the 1’,2’cyclic intermediate The formation of deacetylasted lysine and 2’-O-acetyl-ADP ribose. Thus, nicotinamide, a deacetylated lysine-containing histone, and 2’-O-acetyl-ADP Histone Methylation Methylation at Lys and Arg of H3 and H4 tends to silence the genes, inducing heterochromatin formation However, trimetheylated Lys4 of H3 is associated with active genes (methylation can add one to 3 methyl in a time) (give a exampel) Histone methyltransferases (HMTs) use S-adenosylmethionine (SAM) as a methy donor The HMT enzymes have a SET domain containing the catalytic site for methylation. Structure of SET7/9 (PDB=1o9s) SET7/9 mono-methylates Lys4 of H3 SAM (SAH) adn the Lys4-containing peptide bind to oppsite sites of the protein The lys4 side chain is inserted through a narrow channel and positioned for methylation by SAM. Methylated Histone Recognition Chromodomains and plant homeodomain (PHD) fingers bind to mono, di- or tri-methylated Lys by an aromatic cage. Fits in the shape, lots of electron to nutralize the positive charge of the methyl group??? Consequence of Methylated hisone Recognition The chromodomain heterochromatin protein 1 (HP1) bidns to methylated H3 Ly9, contributing to gene silencing, Bound HP1 recruitsthe HMT Suv39h, methylating nearby histone lysines (H3K9), thereby recruiting more HP1 and forming HP1 complexes. This mechanism explains how heterochromatin spread to silence neighboring genes. HP1 clust prefer to form a tide complex and so, silence the DNA transcription. Histone Demethylases LSD1 &amp; LSD2 demethylases Flacin adenine dinucleotide (FAD)- dependent amine oxidation Demethylate mono- and dimethylated substrates The JMJC family Dioxygenases dependent on Fe2+ and α-ketoglutarate Demethylates mono-, di- and trimethylated substrates Focuse on the Chemical reaction Understanding the demethylation reaction from the LSD1 Structure The LSD1 is bound to a 21 amino acid H2 peptide with a mutation of Lys4 to Met. Modeling predicts that methylated Lys3 binds in a solvent inaccessible area in front of the FAD cofactor (electron extraction). Understanding … JMJD3 structure THe JMJD3 is bound to a H3 pep with a trimetrhylated Lys27 The cofactor analog N-oxylayglycine NOG not α-ketoglutarate and nickel not iron are used to prevetn teh reaction The methylated Lys27 side chain insertes deep into the catalytic pocked, close to the cofactor analog and nickel for demethylation reaction. Chromatin Writers, Readers and Erases brif adn = = Recombination homologous reconbination, need small similar sequnces Site-specific reconbination, nees specific DNA sequence ranspositions, no Specific DNA Non-homologous DNA end-joining (), specific proteins that repair dsDNA breaks Homologous reconbination Required for accurate chomosome segregation repairing and tolerating DNA damage Recovery of stalled or broken replication forks Defects in recombination can contribute to genome instability and cancer predispositions Biological roles Genetic reassortments in gametogenesis Repair of DNA damages Repair replication forks laterl DNA transfer between ceels therOther, deletions, inversions, translocations, etc. How HR produces deletions, insertions and inversions Incersion: DNA fold in a revised direction, The DNA form a arch bridge and at the foot of the bridge connected Deletion and insertion DNA fold in a same direction. A circle formed and the cross point was connected together and the circle was deleted. (Insertion happens the similar way.) Translocation that casue cancers Chronic myeloid leukemia BCR/ABL mRNA p210 fusion protein ABL are concertive hyregulated RTK, BRC is a higly active promoter which drive the high expression of the ABL which resbonsible to growth and differentiation. Holliday Model of Recombination Nicking → Strand Exchange → Branch Migration → Resoltion → Recombination molecules SOS response: Mutagenic Survival Pathway of Last Resort DNA Damges → ssDNA or dsDNA break → No Transcription Normal LaxA turning of LexA-Regulated gene Auto-cleavage of LaxA recruitment lots of RecA. RacA: Pre-synapsis → Synapsis → ppost-synapsis RacA complex driving homology search and alignment of complementary sequences. Site-specific reconbination: intergration of lambda phage DNA into the E.coli Chromosome","link":"/2021/11/27/LearnNotes/tulane-biochem-16/"},{"title":"Histone Modifications in Transcriptional Regulation","text":"ChromatinStructure Chromatins Heterochromatin: Highly condensed nonexpressing DNA Euchromatin: Less condensed, transcriptionally active DNA Histone Modifications © Geoffrey P. Dann, 2017 This model depicts the lengths of the histone tails (dotted lines),which are not visible on the crystal structure of a nucleosome. acK: acetyl lysine meR: methyl arginine meK: methyl lysine PS: phosphoryl serine uK: ubiquitinated lysine Histone Code “Specific modifications of histones evoke certain chromatin-based functions, and these modifications act sequentially or in combination to generate unique biological outcomes.” Wikipedia – Gene transcription is regulated by chemical modification to histone proteins. Histone Acetyltransferases (HATs) HATs acetylase histone lysine side chains. Histone deacetylases (HDACs) catalyze the removal of acetyl groups from lysine residues in histones. Zinc is involved (not shown) Structure of the HAT Domain from Tetrahymena thermophila © PDBID=1QSN The enzyme is deeply clefted. The histone H3 peptide KSTGGK14APRKQ (yellow) and coenzyme A (pink) are bound at the deep cleft. Catalysis appears to involve water-mediated proton extraction from the substrate lysine by a glutamic acid general base. Acetylated Lys Recognition by Bromodomains © PDBID=1EQF Bromodomains specifically bind acetylated lysine residues on histones. Structure of double bromodomain of human TAF1, a subunit of transcription factor TFIID (PDB code 1eqf) Two binding sites are separated by ~25Å, ideal for two acetyl-Lys residues separated by 7-8 residues. Histone H4 has Lys at positions 5, 8, 12, 16 Fully acetylated H4 binds tighter to double than single bromodomains (5/12 or 8/16 pairs). Role of TAF1 Double Bromodomain TAF1 double bromodomain targets TFIID to promoters A refined proposal for transcription initiation A HAT-containing coactivator binds to upstream DNA- binding protein (an activator) The HAT acetylates nearby histone tails TFIID is recruited to the site via the binding of the TAF1 double bromodomain to the acetyl-Lys residues of histones. Followed by recruitment of other initiation factors and RNAP-II for transcription initiation. Histone Deacetylases (HDACs) 18 HDAC enzymes that deacetylate acetyl lysine substrates including histones. Histone deacetylase family (zinc-dependent) Sirtuin family (NAD-dependent) Reaction mechanism: Bound Zn mediates the nucleophilic attack of water on acetylated lysine, forming a tetrahedral oxyanion intermediate. The carbon–nitrogen bond of the intermediate is then broken and the nitrogen accepts a proton from His-Asp. The acetate and lysine products are formed. Sirtuins © William Giblin, 2016 NAD+-dependent reaction Nucleophilic addition to form a C1′- O-alkylamidate intermediate and free nicotinamide. The 2′-hydroxy group of the NAD+ ribose attacks the C1′-O- alkylamidate to form the 1′,2′-cyclic intermediate. The formation of deacetylated lysine and 2′-O-acetyl-ADP ribose. Thus, nicotinamide, a deacetylated lysine-containing histone, and 2′- O-acetyl-ADP ribose are the final reaction products. Histone Methylation Methylation at Lys and Arg of H3 and H4 tends to silence the genes, inducing heterochromatin formation However, trimethylated Lys4 of H3 is associated with active genes!!! Histone methyltransferases (HMTs) use S- adenosylmethionine (SAM) as a methyl donor The HMT enzymes have a SET domain containing the catalytic site for methylation. Structure of SET7/9 (PDB code 1o9s) © Hao-Bo Guo, 2007 SET7/9 mono-methylates Lys4 of H3. SAM (SAH) and the Lys4-containing peptide bind to opposite sites of the protein. The Lys4 side chain is inserted through a narrow channel and positioned for methylation by SAM. Methylated Histone Recognition © Kuo, 2012 Chromodomains and plant homeodomain (PHD) fingers bind to mono-, di- or tri-methylated Lys by an aromatic cage. Extral Reading: Epigenetic Regulation Mediated by Histone Marks Consequence of Methylated Histone Recognition • The chromodomain of heterochromatin protein 1 (HP1) binds to methylated H3 Lys9, contributing to gene silencing. • Bound HP1 recruits the HMT Suv39h, methylating nearby histone lysines (H3K9), thereby recruiting more HP1 and forming HP1 complexes. • This mechanism explains how heterochromatin spread to silence neighboring genes. Histone Demethylases © Susanne Marije Kooistra, 2012 LSD1 &amp; LSD2 demethylases • Flavin adenine dinucleotide (FAD)-dependent amine oxidation • Demethylate mono- and dimethylated substrates The JMJC family • Dioxygenases dependent on Fe(II) and α-ketoglutarate • Demethylates mono-, di- and trimethylated substrates The reaction lose two protons, one from the carbon and another from the (+) nitrogen, requiring the protonated nitrogen. Understanding the demethylation reaction from the LSD1 Structure © Sang-AhKim, 2020 The LSD1 is bound to a 21 amino acid H3 peptide with a mutation of Lys4 to Met (green). Modeling predicts that methylated Lys4 binds in a solvent inaccessible area in front of the FAD cofactor (electron extraction). Understanding the demethylation reaction from the JMJD3 Structure © SanchariBasu Mallik, 2016 The JMJD3 is bound to a H3 peptide with a trimethylated Lys27 (yellow). The cofactor analog N-oxalylglycine NOG (not α-ketoglutarate) and nickel (not iron) are used to prevent the reaction. The methylated Lys27 side chain inserts deep into the catalytic pocket, close to the cofactor analog (pink) and nickel (green) for demethylation reaction. Chromatin Writers, Readers and Erasers Source Unknow Inhibitors of DNA synthesis and their specificities AZT and DDI: reverse transcriptase, chain terminate nuceoside analogues of guanosine: phosphorylated by a viral kinase Polymerase processivity Enhanced by a Clamp β clamp in bacteria PCNA in eukayotes loaded onto dsDNA on calmp Clamp loader couples ATP Hydrolysis to Clamp Loading Sliding clamp + ATP: open and bind DNA; ATP → ADP, DNA releases Biological advantages of DNA Provides stable, yet mutable storage of genetic information. Metabolic stability and availability of repair mechanisms ensure long-term survival under a variety of physiological conditions. Serves as a template for accurate and adaptable replication of genomes. This biological role ensures the transmission of important physiological functions for multiple generations. Serves as a template for the expression and regulation of genetic information. This biological role facilitates adaptation of genomes to changing physiological environments. Amenable to diversification (i.e., can evolve). Mutation and genetic recombination (DNA rearrangements) are the two major driving forces in the evolution of genomic diversity and adaptation in nature. DNA ligases Eukaryotic DAN ligase use ATP rather than NADP initiation od DNA replication in E. coli origin region (OriC) ~245bp Duplex unwinding by DNA helicase Exposed ssDNA allows SSB and helic … Initiation: OriC-DnaA intercation → Entry of SSB and DnaB (hexlicase) → ENtry of promase → RNA primers are synthesized and the elongation complexes for 2 DNA replication forks are assembled Elongation: Prokaryotic DNA replication A typical DNA replicsome synthesis of leading strand are coupled with lagging strand by clamploader complex. The e.coli Pol III holoenzyme … Pols enyzme subunit factors Eukaryotic DNA replication: Pro: no cell cycle and start every time Eu: onece anc only once in S phase; highly regulated G1: Preparing Checkpoint: end of the S phase Time is variatd Eukaryotic chromaomse have multiple origins… Pro: single initial site Euk: multiple initial site Eukaryotic replication initiation is hihgly oreder… well regulated and complex… Helicase (Mcm2-7) Sld2/3 phosphorylated by CDK Super Current Biochemical Reconstitution of Regulated replication origin firing Termination in prokaryotes Ter sites, 2 converging new ds circular DNA molecules separated from each other by recombination and with assistance of Cell are constantly exposed to agents that can cause damage to their genome Repair, tolerant, destroy the cell Types of mutation Transition: AT → G/C Transversion: A/T → C/G Frameshift: GGGGGG → GGGGG Base alteration Oxidation: 8-oxodG(antl)-dC(antf) 8-oxodG(synl)-dA(antf) The rotation of the bound which cause the shift of the side chain and attribute difference hydrogen bonds. 3 to 2, C to A Alkylation; Cross-links Exogenous Damage: Exposure to ultraviolet radiation Absorbed by adjacent pyrimidine bind and form double bond and cause mutation or lethal during replication/transcription Repair Base Excision Repair Single Nucleotide Nucleotide Excision Repair oligonucleotide Mismatch Excision Repair mismatched base Base Excision Repair how recognize AP site Donw string/ leading string doesn’t matter ligates involved Nucleotide excission repair (NER) recognize Enzymes (XPC) recruit other factors unwinding, mutation is exposed Some protein was recruited and mistake was cut / rescued. Recognition → resynthesis Xeroderma pigmentosum (XP) Accelerated skin cancer; mortality likely due to metastatic melanoma or squamous cell carcinoma MMR pathway - E. Coli MutS, MutL, MutH, ATP MutH: cut the strand (down/leading) methelation is critical here RNA polymerases Transcription using DNA to RAN Bacterial: ON enzyme for all of RNA synthesis Eukaryotic: At leased Three I II III Strangs 1: Template; Non-coding; Anti-sense: Completed strand Strands 2: Sense strand: coding strange of the DNA Non-completed strand Bacterial promoter consensus sequences UP Element; -35; -10; RNA stra +1 -35; -10: promoters (similar to regulatories in Eukaryotic.) Expression controlled by interactions of promoter elements with RNA polymerase and specific repressor/Activators Bacterial RNAP Holoenyme versis core enzyme Core subunits: α₂ββ’ω (400kDa) Holoenzyme: core subunits plus factors … Five σ factirs in E. coli gene expression Exp: (not important) σ 70: Most genes σ 32: Heat schock proteins Trascription Elongation RANP trancks along the DNA template, synthesizes mRNA in te 5’ to 3’ direction and unwinds and rewinds the DNA as it reads. Transcription elongation causing DNA supercoiling, relaxed by topisomerases Termination Transcription Terminattion A series of 4 - 10 base Sequence depended: CGGCGCTTTTTT (CG rich region; AT rich region) ρ factor-dependent The amino-termina domain of ρ factor binds to hte RNA sequence of ρ utilization site the carboxy-terminal domain of ρ hexameric ring closes Ring closure propels ρ moving close to RNAP ρ dis-engages RNA and RNAP from DNA Eukaryotic Transcriotion Three types of Nuclears RNAPs I: rRNA (28S, 18S) II: mRNA; snRNAs; miRNAs III: tRNAs; 5S rRNA; snRNA U6 7S RNA; other stable short RNAs Transcription Subunit compositions of nueclear RNAPs β’; β; αI; αII; ω All yeast RNAP has five subunits similar to Bacteria RNAP II Yeast RNAP II strcture resembling bacterial RNAPs A vrab claw-like strcuture RNA biosynthesis The clamp of the Rpb1 subunit moves down to trap DAN between the two claw Unwind DNA at the active site Wall of Rpb2 kinks the template by 90° out of the active site One vase of the template points at the active site This base is paired with the ribonucleotide RNA translocation Transcription promoters Class I, II, II to RAN poly I, II, III Mammalian Gene and proximal promoter (Class II) Proximal region (-200 ~ -30), within 200 bp of transcription start; similar to the -10; -35 in the bacteria’s TATA Box (TATAAA) Recruits TATA binding protein … Initiator region (Inr) Other activation elements EPromoter and Activator proteins Transcriptional Activators: DNA binding domain; activation domain; Activator functions: Chromatin remodeling (acetylation-HAT); Mediator facilitates PIC assembly Repressor Bind UAS.enhancers → displace activators Prevent mediator → no PIC formation Attracts HDACs and HMTs → heterochromatin PIC Assmbled mediator facilitates TBP and TFIIB binding promoter Other basal TFs and Pol II bind phosphorylation of the CTD of Pol II by TFIIH → Transcription initiation Six transcription factors for clas II promoters (Not important) ==Phospho-code on RNAP II CTD TFIH: Phosphate the Ser5 would initiated the transcription activity P-TEFb: phospholate Ser2 to maintain the elongation state Non-canonical functions of transcription CENP-A defines centromeric chromatin RNA… ChiP-Seq: Determine protein distributed on chromatins RNA-Seq: Expression profiles Transcription inhibition as a therapeutic target for cancer mRANs of many oncogenes Transformed → RNA-directed agents: different sensitivity. Alpha-amanitin: from mushroom directed binding to RNAP, adn block the bridge to repress the conformation change Bacterial Transcription Eukaryotic transcription RNAP II CTD phospho-code Non-canonical functions of transcription Assays to study transcription posttranscriptional Modification of Eukaryotic RNAs Role of 5’ cap Ribosomal recogintion during translation Cap structure 7-methylguanosin (m⁷G) joined to the mRNA first nucleotide Via a 5’-5’ tri-P brifge Involved Enzymes RNA riphosphatase removing the γ-P of the mRNA’s 5’ site mRNA guanlyltransferase (a capping enzyme) adding GMP. (Take GMP to the site) Guanine-7-methyltranserase (second capping enzyme) methylating guanine Capping enzymes bind to RNAP-II, which will switch RAN synthesis initiation to elongation () posttransicriptional Modification of Eukaryotic RANs Poly A tails; ~250 nt Cleavage and polyadenylation specificity factor (CPASF), cleaving up to 35 nt past the AAUAAA sequence Poly A polymerase generate poly A tail using ATP. (termination signals given to RNA-polymerase) CPSF binds to RNAP-II, coupling polyadenylation to transcription termination. Poly A tail binds to poly-binding protein, protecting from degradation, increasing mRNA stability. Exons and Introns Precurso mRANs (pre-mRNAs) are processsed by the excision of introns and the splicing (joing) of exons. Exon splicing in Two-Stage Reactions Invariant Sequences for splice junction GU at the intron’s 5’ AG at teh intron’s 3 (graph), the number under the NT means the ration you are supposed to see them on the Intron A branch point near the 3’ splice site Free G, not paire to the intron… A2’-5’ P-diester bind between the tinron A (OH²’) and the intron at teh 5’ splice site, forming a “lariat” structure. The Exon 1 OH³’ group at the 5’ splice site from a 3’-5’ P-diester bind with the Exon 2’ at the 3’ splice site, releasing the intron with the free OH³’ group. The intron keeps the lariat structure. Note: Splicing proceeds w/o free energy lose, Cleavage of one P-diseter bond and formation of a new bond. Spliceosome-aided RNA splicing Splicing could be focilited by the protein Splicesome.60S spliceosome particle containing five small nuclear RNAs + Ribonucleoproteins (U 1~6, no 3) U1 recognizes the 5’ splice junction U2 recognizes the branch point (intron A) The binding of U4-U5-U6 forms spliceosome. RAN cleavage at the 5’ splice site RNA cleavage at the 3’ splice site Intron … Self-Splicing RNA Group II Intron Exson 1 and Exon II aligned together the giant rondant was splicesd by themselves Group I intron: not Intron A to initiated the reaction G , GTP, GDP, GMP… as the starting site The 3’-OH of … Summary of spliceosome-aided Splicing and Self-Splicing In goup I introns, aguanosine cofactor (G) tat is not part of the RNA chain associates with the active site. The 3’-hydroxyl group of this G attacks the 5’ splice sit; The reaction is similar to those involving the 2 hydroxyl groups of branch sites as in group II introns and RNA inrons spliced in spliceosomes. The subsequent trans-e… Interactions of RNAP-II with capping enzyme, splicing and CPSF Figure 16-5 Aminoacyl-tRAN Synthetase Attach amino acids to tRNAs Two step reactions Amino acid activation by the reaction with ATP (Aminoacyl-tRNA syntheiase) Formation of an aminoacyl-tRNA Aminoacyl-tRAN SYnthetases The synthetase enzymes have an elongated shape. Binding the anticodon of tRNA near the one end of the enzyme. Binding the A.a. acceptor stem of tRNA near th other end Proofreading by Aminoacyl-tRAN Synthetase Binding to the amino acid substrate pocket of tRNA Synthetase that consists of the zinc ion.L-Group: Megan, Ryan, Ka Threonine binds at this pocket b/c it can coordinate Zn2+ using it NH2 and OH groups tRNAthr is tRNA for threonin. Attaching ThR to tRNAthr makes Thr-tRNAthr (tRNA is correctly charged) Attaching Ser to tRNAthr makes Ser-tRNAthr (tRAN is mischarged) Acetylation definition histone modification Acetylation by HATs Recognition by bromodomains Deacetylation by lysine deacytelases (HDACs adn Sirtuins) cofactors: Zinx, NAD Methylation by histone methyltransefrases (HMTs) The donor: S-adenosylmethionine (SAM) SET domains in SAM Recognition by chromodomains and plant homeodomain (PHD) fingers Aromatci cage: to recognize Chroodomain-containing heterochromatin protein 1 (HP1) function: regulated transcription Demethylation Lysine-specific histone demethylases (LSD1 and LSD2)-FAD-dependent Jumonji C-domain (JMJC) family members - F2a and α-ketoglutarate-dependent Chromatin structure Chrmosome → chromatin fiber → Beads on a string DNA wound on nucleosomes → Histones + Doble helix Heteochromatin: Highly condensed nonexpressing DNA. (PS: Canot be transcripted because transcript machinary can’t recognize and bind) Euchromatin: Less condensed, Transcriptionally active DAN H2A, H2B, H3, H4 Histone Modification Histone was circled in the center of the DNA, but with tail out of the stracture and cann’t be visualized by cristal structure. But they are the key site for the Methylating or Acetylating acKL acetyl lysine meR: meK: PS: phosphoryl serine … Histone Code Histone modification is the signals of transcription on/off. Histone Acetyltraseferases (HATs) Histone + Me-CoA → CoA + Me-Histone Structure of the HAT domain from Tetrahymena thermophila The enzyme is deeply clefted The histone H3 peptide KSTGGK14APRK! and coenzyme A are bound at the deep cleft. Catalysis appears to involve water-mediated proton extraction from the substrate lysine by a glutamic acid general base. Acetylated Lys recognition by Bromodomains Bromodomains specifically bind acetylated lysine residues on histones. A deep hydrophobic pocket (hole) accommodates the acetyl-Lys side chain (PS, the hole recognize the acetyl-Lys specificity) TAF1: has two brpmodomains and dipart from each with ~25Å, seperated by 7 ~8 residues. A subunit of transcription factor TFIID (PDBid=1eqf) … … Role of TAF1 double Bromodomain TAF1 double bromodomain targets TFIID to promoters A refined proposal for transcription initiation A AHT-cotaining coactivator binds to upstream DAN binding protein (An activator) The HAT acetylates nearby histone tails TFIID is recruited to the site via the binding of the TAF1 double bromodomain to the acetyl-Lys residues of histones. followed by recruitment of other initiation factors and RNAP-II for transcription initiation. Histone Deacetylases (HDACs) 18 HDAC enzymes that deacetylate acetyl lysine substrates including histones. Histone deacetylase … … Reaction mechanism: - Bound Zn2+ mediates the nucleophilic attack of water on acetylated lysine, forming a tetrahedral oxyanion intermidiate - The carbon-… Situins NAD⁺-dependent reaction nucleophilic addition to form a C1’-O-alkylamidate intermediate and free nicotinamide. Teh 2’hydroxy group of the NAD⁺ ribose attacks the C1’-O-alkylamidate to form the 1’,2’cyclic intermediate The formation of deacetylasted lysine and 2’-O-acetyl-ADP ribose. Thus, nicotinamide, a deacetylated lysine-containing histone, and 2’-O-acetyl-ADP Histone Methylation Methylation at Lys and Arg of H3 and H4 tends to silence the genes, inducing heterochromatin formation However, trimetheylated Lys4 of H3 is associated with active genes (methylation can add one to 3 methyl in a time) (give a exampel) Histone methyltransferases (HMTs) use S-adenosylmethionine (SAM) as a methy donor The HMT enzymes have a SET domain containing the catalytic site for methylation. Structure of SET7/9 (PDB=1o9s) SET7/9 mono-methylates Lys4 of H3 SAM (SAH) adn the Lys4-containing peptide bind to oppsite sites of the protein The lys4 side chain is inserted through a narrow channel and positioned for methylation by SAM. Methylated Histone Recognition Chromodomains and plant homeodomain (PHD) fingers bind to mono, di- or tri-methylated Lys by an aromatic cage. Fits in the shape, lots of electron to nutralize the positive charge of the methyl group??? Consequence of Methylated hisone Recognition The chromodomain heterochromatin protein 1 (HP1) bidns to methylated H3 Ly9, contributing to gene silencing, Bound HP1 recruitsthe HMT Suv39h, methylating nearby histone lysines (H3K9), thereby recruiting more HP1 and forming HP1 complexes. This mechanism explains how heterochromatin spread to silence neighboring genes. HP1 clust prefer to form a tide complex and so, silence the DNA transcription. Histone Demethylases LSD1 &amp; LSD2 demethylases Flacin adenine dinucleotide (FAD)- dependent amine oxidation Demethylate mono- and dimethylated substrates The JMJC family Dioxygenases dependent on Fe2+ and α-ketoglutarate Demethylates mono-, di- and trimethylated substrates Focuse on the Chemical reaction Understanding the demethylation reaction from the LSD1 Structure The LSD1 is bound to a 21 amino acid H2 peptide with a mutation of Lys4 to Met. Modeling predicts that methylated Lys3 binds in a solvent inaccessible area in front of the FAD cofactor (electron extraction). Understanding … JMJD3 structure THe JMJD3 is bound to a H3 pep with a trimetrhylated Lys27 The cofactor analog N-oxylayglycine NOG not α-ketoglutarate and nickel not iron are used to prevetn teh reaction The methylated Lys27 side chain insertes deep into the catalytic pocked, close to the cofactor analog and nickel for demethylation reaction. Chromatin Writers, Readers and Erases brif adn = = Recombination homologous reconbination, need small similar sequnces Site-specific reconbination, nees specific DNA sequence ranspositions, no Specific DNA Non-homologous DNA end-joining (), specific proteins that repair dsDNA breaks Homologous reconbination Required for accurate chomosome segregation repairing and tolerating DNA damage Recovery of stalled or broken replication forks Defects in recombination can contribute to genome instability and cancer predispositions Biological roles Genetic reassortments in gametogenesis Repair of DNA damages Repair replication forks laterl DNA transfer between ceels therOther, deletions, inversions, translocations, etc. How HR produces deletions, insertions and inversions Incersion: DNA fold in a revised direction, The DNA form a arch bridge and at the foot of the bridge connected Deletion and insertion DNA fold in a same direction. A circle formed and the cross point was connected together and the circle was deleted. (Insertion happens the similar way.) Translocation that casue cancers Chronic myeloid leukemia BCR/ABL mRNA p210 fusion protein ABL are concertive hyregulated RTK, BRC is a higly active promoter which drive the high expression of the ABL which resbonsible to growth and differentiation. Holliday Model of Recombination Nicking → Strand Exchange → Branch Migration → Resoltion → Recombination molecules SOS response: Mutagenic Survival Pathway of Last Resort DNA Damges → ssDNA or dsDNA break → No Transcription Normal LaxA turning of LexA-Regulated gene Auto-cleavage of LaxA recruitment lots of RecA. RacA: Pre-synapsis → Synapsis → ppost-synapsis RacA complex driving homology search and alignment of complementary sequences. Site-specific reconbination: intergration of lambda phage DNA into the E.coli Chromosome","link":"/2021/11/27/LearnNotes/tulane-biochem-17/"},{"title":"Protein Structure|Graduate Biochemistry 3| Tulane","text":"Overview What is a protein? Folding is chain collapse Visualizing structures Primary, secondary, tertiary, quaternary structure Anfinsen-Merrifield experiments Evolution and sequence conservation Protein structural motifs The Greek Key and β-sandwich The coiled-coil The EF hand Domain structure of large proteins Quaternary structure of proteins Protein Structure-Chain Collapse A protein of 400 amino acids Unfolded ~500 Å mean diameter fexible polymer chain Folded ~40 Å diameter; Density ~1.3 g/ml PS: organic liquids: 0.8-1.0 g/ml organic solids: 1.0-1.4 g/ml Properties of folded proteins Folded proteins are as tightly packed as crystals of amino acids Secondary structure is an unavoidable consequence of packing Most hydrogen bonding groups inside are hydrogen bonded Visualization of Protein Structure © asu.edu a: NA; b: CPK space-filling; c: Cα trace; d: Ribbon diagram; Schematic is not show here. Protein Folding - Levels of Structure Primary -&gt; Secondary -&gt; Tertiary -&gt; Quaternary Globular Protein: typically have a fixed (small to moderate) number of subunits, ratio of length to width is small. Fibrous proteins: large polymeric, ratio of length to width is large Protein Folding - Levels of Structure Ribonuclease A: 124 residues 4 disulfide bonds Unfolded with denaturants (urea or guanidine) The Anfinsen/Merrifield Experiments More details above: Karobben, Biochemistry_4 Christian Anfinsen and Robert B. Merrifield The hypothesis: All of the information needed to determine the structure of a protein is contained within its amino acid sequence The experiment: Ribonuclease in an enzyme with 4 Cys-Cys disulfide bonds The correct linkage is essential for enzymatic activity Anfinsen purified ribonuclease from cow pancreas, and then reduced the disulfide bonds with mercaptoethanol and unfolded the protein with 8 Molar urea (It was completely inactive) The reduced and denatured protein was put into a solution that favored oxidation of disulfide bonds. The observations: There are 105 different arrangements of the S-S bonds but only the single native arrangement gives active enzyme Ribonuclease reoxidized in the presence of 8M Urea gave 1% activity Ribonuclease oxidized in the absence of Urea gave ~100% activity The conclusion: All of the information needed to determine the structure of a protein is contained within its amino acid sequence The confirmation Robert Merrifield synthesized ribonuclease chemically and got active enzyme. This experiment demonstrated that no cellular machinery or structural “memory” was involved. Cytochrome c Sequence Alignments © Gulnaz Afzal, et al. Sequence conservation in a small, critically important Protein cytochrome c Substitutions of amino acids can be: Conservative (similar physical properties. charge etc) Non conservative (dissimilar physical properties)Phylogenetic Tree of The degree of sequence relatedness is correlated with the degree of evolutionary relatedness. A protein with a conserved sequence will have a conserved structure. Protein Folding – Structure Motifs The atomic level 3-dimensional structure is known for ~19,000 proteins A few hundred folding motifs are adequate to describe most structures A structural “motif” is a unit of secondary structure topology Examples of secondary structure motifs a) βαβ b) β-hairpins c) αα d) β-barrel e) β-barrel f) α/β-barrel Examples of structural motifs TIM-barrel of triosephosphate isomerase Motif: (βαβα)4 Small β-sheet motifs A “Greek Key” pattern The two Greek key topologies For a 4 stranded β-sheet Topology of a 4 stranded β-meander What 4-stranded β-sheet topologies are found in proteins? 24 possible topologies exist only 8 have been observed the 2 Greek keys and β-meander (above) account for almost 70% of the observed topologies β sandwich motif A β-sandwich motif has two beta sheets (often Greek keys) packed face to face. It’s a small common folding motif. Hydrophobic α-helix core was been enveloped in the center of the protein. © Molview; The crystal structure of APRIL bound to BCMA; PDBID=1XU2; hemoglobin Coiled Coils – α-helical bundles Dimeric helical pairs have a heptad (7 amino acid) repeat of interacting amino acids. Coiled coils form the basis for many long fibrous proteins Heptad repeat pattern of dimeric Coiled-coils: Residues d and a are hydrophobic Residues g and e form charge pairs Residues c, b and f are variable A coiled-coil protein can have from several to hundreds of homologous heptad repeats. When the ‘d’ resides are leucine/isoleucine the motif is called a “leucine zipper” Protein Folding – Metal Binding Motif EF-hand or Helix-loop-Helix motif © Paul T Wilder, et al. EF-hand Sequence: ------------------------------------Helix Loop Helix------------------------------------ VkkAFaiID qDkSGfIEedE LklFLqnF (Parvalbumin β) lower case – variable UPPER CASE – conserved Underlined – involved hydrophobic interaction between helices Bold – involved in calcium binding Essential loop Glycine Target: Calcium atom [Helix] - [Loop] - [Helix] lower case – variable UPPER CASE – conserved Underlined – involved hydrophobic interaction between helices Bold – involved in calcium binding Protein Architecture - Independent Domains Proteins longer than about 200 residues tend to form globular domains Domains tend to fold independently and have conserved activities A few domain types can make many proteins Number of domain types appears limited to a few hundred An Example of Domains Proteases in the blood coagulation cascade are good examples of complex multi-domain proteins Calcium binding domain Kringle domain Has a specific pattern of cysteine residues in a span of ~85 residues Domains that resemble the epidermal growth factor EGFL domain Serine protease domain Quaternary Protein Structure Many proteins are multimeric: Containing more than one polypeptide chain, generally held together by noncovalent interactions Homomultimers – composed of copies of the same polypeptide chain Heteromultimers – composed of more than one polypeptide chain The interactions that drive quaternary structure are the same as those that drive folding interaction strengths can range from weak and transient to strong and essential for structure Aspartate Transcarbamoylase: 6 catalytic (C3)2 and 6 regulatory (R2)3 subunits digraph F { rankdir = UD; subgraph A { rank = same; RNAse [label = \"RNAse A\", color = \"#FF0000\" ]; } subgraph B { rank = same; Urea [color = blue ]; ME1 [label = \"b-mercaptoethanol\" color = blue ] } subgraph cluster_1 { rank = same; label = \"Result\"; Result1 [label = \"100 %\", shape=box ; color = \"#FF0000\" ] Result2 [label = \"0 %\", shape=box ; color = \"#FF0000\" ] Result3 [label = \"100 %\", shape=box ; color = \"#FF0000\" ] Result4 [label = \"90 %\", shape=box ; color = \"#FF0000\" ] Result5 [label = \"1 %\", shape=box ; color = \"#FF0000\" ] Result6 [label = \"90 %\", shape=box ; color = \"#FF0000\" ] } subgraph cluster_1 { style=filled; color=lightgrey; node [style=filled,color=white]; label = \"Results\"; } RNAse -> Result1 [label=\"No treatment\"] RNAse -> Mix1 -> Result2 Urea -> Mix1 Urea -> Mix2 Mix2 -> Result3 [label = \"dialysis\"] Urea -> Mix3 ME1 -> Mix3 Mix3 -> Result4 [label = \"1. dialysis\\n2. oxidizing\"] Urea -> Mix4 ME1 -> Mix4 Mix4 -> Result5 [label = \"1. oxidizing \\n 2. dialysis\"] Result5 -> Mix5 -> Result6 ME1 -> Mix5 [label = \"a little\"] } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });","link":"/2021/09/16/LearnNotes/tulane-biochem-3/"},{"title":"Protein Function|Graduate Biochemistry 4| Tulane","text":"Protein Database Bank (PDB) © Molview; PDBID=1bkv; Collagen Structure and Function of Collagen extracellular proteins that provide rigidity and strength to many tissues Large bundles of triple helices Gly-X-Y Alanine - Glycine substitute: A is hydrophobically contributed to α-helix composed. Hydroxyproline… stabilized by cross-helix backbone hydrogen bonds large bundles of triple helices: A right-handed trimer of left-handed helices. Gly-X-Y Pattern: X is mostly proline and many of the Y is hydroxyproline (Gly-Pro-Hyp) Glycine: No side chain: Closer the α-helix Hydrophobic: Folding to the center of the helix by hydrophobic effect Alanine (replacing to Glycine): larger than Glycine but could still work similarly to Glycine Prolein $ Hydroxyproline: pull out of the strand hydroxyproline work with water Proline hydrolyzation was carried by Proline hydroxylase and required Vc as co-factor. $$ Proline + 2-Oxoglutarate + O_ 2 + Fe^ {2+}\\overset{Proline hydroxylase}{\\longrightarrow} Hydroxyproline + Succinate + CO_ 2 + Fe^ {3+} $$ $$ V_ c + Fe^ {3+} \\to Dehydroascorbate + Fe^ {2+} $$ Collagen is stabilized by cross-helix backbone hydrogen bonds Gly-NH::O=C-Pro PS: Proline is often disturbing the structure of the α-helix. But why is proline’s favorite in the triple α-helix? (3-D structure) Globin Heme the oxygen binding cofactor Contains a reduced (ferrous, Fe2+) Iron atom. The porphyrin ring contains 4 pyrrole groups (A-D) Fe2+ has 6 coordination sites. 4 pyrrole nitrogens The proximal histidine that transmits ligand binding-induced conformational changes to the protein. The sixth coordination site that binds various ligands O2, CO, CO2, CN A “distal” histidine hydrogen-bonds to the heme-bound O2 Structure and function of myoglobin muscle protein that binds O2 First protein to have its 3D structure determined contains a single heme group © Molview; PDBID=1MBN; myoglobin First protein to have its 3D structure determined (by John Kendrew, 1956) 153 residues long 75% α-helical. No β-sheets. There are 8 helices designated A-H © Molview; PDBID=4hhb; hemoglobin α2β2 tetramer. Human: α, β, γ, δ Consist to α2X2(X= β, γ or δ) β in adult; and γ in fetal. © Cambridge University Myoglobin (Mb) versus hemoglobin (Hb) © Jay F Storz, 2002 Hb: sigmoidal (26 torr). Mb: hyperbolic (2.8 torr). Mb has a greater affinity than Hb for oxygen at all oxygen pressures. In the lungs, Hb is saturated In tissues, oxygen is released from Hb and transferred to Mb . © HarvardX More information about Oxygen Transport: Karobben, Principal of Biochemistry The Bohr (pH) Effect Hemoglobin’s oxygen affinity decreases with decreasing pH and increasing CO2, causing the release of oxygen in tissues PS: Bohr Effect is based on pH effect; pH Changes the conformation of the Myoglobin and Hemoglobin. (R state (oxy-form) to T state (deoxy-form)) Protonatable His146 of the β subunit is the key of Bohr effect. In the tissues (a low pH), His146 forms a salt-bridge with Asp94 and its backbone with Lys40 of the, stabilizing the T state in tissues (Deoxy-form). In the lungs (a high pH), the salt-bridge is disrupted, promoting the T to R transition (Oxy-form). H146 of β interactions in T and R states α2Lys40::β1His146::β1Asp94 © http://biomodel.uah.es BPG effect: © Molview; PDBID=1B86; BPG and Hemoglobin 2,3-bisphosphoglycerate (BPG) binds to hemoglobin (T state) and decreases oxygen affinity. BPG is produced within erythrocytes BPG is involved in high altitude adaptation BPG binds at the interface of β1 and β2 chains stabilized by numerous ionic and hydrogen bonding interactions Fetal hemoglobin (γ) doesn’t bind BPG b/c His143 -&gt; Ser mutation at the BPG binding site © www3.nd.edu Structure and Function of Antibody Antibodies function by interacting with foreign (antigen) molecules The antigen binding sites are produced by the variable domains from heavy and light chains. Several “hypervariable” loops are at the end of the variable domain. The two light chains and the two heavy chains are identical: the two antigen-binding sites are identical. Antibodies have H2L2 stoichiometry H is a “heavy” chain and L is a “light” chain Each chain has one variable domain All domains (4 in each heavy chain and 2 in each light chains) have the same “immunoglobulin fold” α β-sandwich with α 4-stranded and α 3-stranded sheet connected by a disulfide bond. © nthu.edu Antibody Peptide Interactions Strong and highly specific binding requires numerous favorable interactions between antibody and antigen. Involving hydrophobic, ionic and hydrogen bonding interactions. Video illustration Myosin © PDB; PDBID=1m8q; Myosin Sliding filament mechanism of muscle contraction: During contraction, the thin and thick filaments move with respect to one another Two heavy chains and several light chains Heavy chains are rod-like molecules The coiled coil tail domain The ATPase head domain Arranged with tails overlapping and heads directed toward either end Type Images Copyright More Actin © PDB, ID=4pkg - Long filamentous polymer consisting of two strands of globular monomers Tropomyosin © PDB, ID=1ic2 - A long, thin two-stranded α-helical rod- In relaxed muscle (low calcium), tropomyosin prevents myosin head from binding to actin Troponin (three subunits) © PDB, ID=1j1d - Tn-I inhibits the actin-myosin interaction- Tn-T binds to tropomyosin- Tn-C binds calcium ions Myosin Conformational Changes © Takashi, et al. Structural states of myosin during the contractile cycle. Without bound nucleotide, myosin is strongly bound to actin (rigor state). ATP binding to myosin dissociates the actin-myosin complex. ATP is then hydrolyzed in ADP+Pi. There is a swing of the lever arm (green arrow). Myosin can rebind to actin Release its hydrolysis products and produce its force (green arrow) and again strongly bound to actin without nucleotide bound (power stroke, red arrow)","link":"/2021/09/17/LearnNotes/tulane-biochem-4/"},{"title":"Protein Folding|Graduate Biochemistry 5| Tulane","text":"Protein Stability and Folding Overview Post translational modifications The interactions that drive protein folding The interactions that drive protein unfolding The net stability of folded proteins Free energies of protein folding Mutation studies The Levinthal paradox Folding pathways Molecular Chaperones Degradation of proteins Reading: All of Chapter 6 Proteolysis segments-cleave signal peptide cleaved in Membrane/secreted proteins proproteins: hormones; enzyems The final hormone is cleaved Some proteases are synthesized as zymogens which are activated by cleavage of a segment from the protein Significant: Table (half life), soluable Exp: Insulin PS: Some maturation of proteins are involved with pro-peptides cleavage. Insulin is an classical example. Insulin has not much of structure amino acid, lack of an hydrophobic core. 6 Cystines and form 3 pair of disulfide bonds. Insulin’s primary structure has not enough information to drive it to the native structure. As a result, people believe that insulin has a memory of each processes to fold. © PDB ID=2hiu Amino Acid Modulation Modulation Type Added Group Location / targets Reversible / Not General Features Glycosylation carbohydrates -N-linkage (on N-R) (More common)-O-linked (on S, T) Variety; long; branched; Charged; Ionized; Large Hydroxylation Carboxyl L &amp; P are hydroxylated on —CH₂ groupsRequires Ascorbate (VC) mainly in collagens(Gly-X-Y) P - 3 or 4 hydroxy proline Irreversible Lack of VC, cell depart Methylation Methyl K and H are methylated on –NH₃, NH₂ groups;K can also be trimethylated (3 Methyl groups) Reversible Doesn’t loose it’s charge. the Amine group still keep charge.Spatial Increased and effect the interactions with other atoms. DNA binding proteins (K phosphate the DNA) Acetylation/Acylation R-Carboxyl (myristate) Amino group of the R chain to for a peptide bondK; H; Terminal AA R Chain are reversible;Terminal are usually not reversible Charge is removed.More hydrophobic Increase the interact with cell membrane.Reversible; Highly Controlled Carboxylation Carboxyl The γ-carbon of E can be carboxylated The E have two carboxyl groups.Mainly blood coagulation enzymes. Requires VK Sulfation Sulfate the hydroxyl of T Permenent more polar, give hydrogen bondslarge polar ionic sulfate group Prenylation Isoprenyl chains C-terminal of C residue through a thioether (C-S-C) linkage. Promoting interact with membranes Signal transduction proteins are prenylated Amidation Amnie group C-terminal carboxyl group polar but not ionizable. Phosphorylation Phosphate groups The hydroxyl group in the R chain. T; S; YH Could be also be phosphorylated in some case Reversible Large polar group © Raimund Nagel, et al © Wiki Protein Folding Interactions The forces that stabilize folded proteins The hydrophobic effect Hydrogen bonding Ionic interactions van der Waals interactions (London dispersion force) Disulfide crosslinks cite: Kauzmann, W. (1959) “Some factors in the interpretation of protein unfolding” Adv. In Proteins Chemistry. 14:1. The hydrophobic effect The unfavorable interaction between hydrophobic sidechains and water is reduced when a protein folds into its native structure Up to 75% of hydrophobic residues are buried in folded proteins Its contribution greatly favors folded state Hydrogen bonding Every residue in a protein has at least one H-bond donor and at least one H-bond acceptor (the peptide bond) Concentration of H-bonding groups in a protein is ~25M Most potential H-bonding groups are, in fact, H-bonded in the interior of folded proteins H-bonds define secondary structure geometry The forces that stabilize folded protein The hydrophobic effect Hydrogen bonding Ionic interactions van der Waals interactions (London dispersion force) Disulfide crosslinks Ionic interactions Salt bridges form between acidic and basic residues Majority of salt bridges are on surface Buried salt bridges are conserved van der Waals Interaction Contribution is from tight packing of protein core Protein density is ~1.3 g/ml (H20=1.0 g/ml Ethanol=0.8 g/ml) Disulfide Crosslinking Covalent crosslinks between the sulfurs of cysteine residues Generally nonlocal Significant (but not dominant) contribution to stability The forces that destabilize folded protein Conformational entropy Hydrogen bonds to water Electrostatic repulsion Conformational Entropy Backbone of folded protein has only one (or a few) conformations. The backbone of an unfolded protein has 32n conformations (because there are 3 low energy φ and ψ torsion angles for each Cα) The backbone entropy change favoring unfolding: ΔS = Rln(32n/1) = 2nRln(3) = 1.4 kcal/mol/residue (5.4 kJ/mol/residue) Hydrogen bonds to water Every amino acid has at least two hydrogen-bonding groups The concentration of bulk water is ~55 Molar and each water molecule has 4 hydrogen bonding groups. Therefore the favorable energetic contribution of hydrogen bonds to folding may be small However, the unfavorable cost of unmade hydrogen bonds in the interior of the protein is still high Hydrophobic amino acids are buried Residue Exposed Burued Interm ediate S 0.70 0.20 0.10 T 0.71 0.16 0.13 A 0.48 0.35 0.17 G 0.51 0.36 0.13 P 0.78 0.13 0.09 C 0.32 0.54 0.14 D 0.81 0.09 0.10 E 0.93 0.04 0.03 Q 0.81 0.10 0.09 N 0.82 0.10 0.08 L 0.41 0.49 0.10 I 0.39 0.47 0.14 V 0.40 0.50 0.10 M 0.44 0.20 0.36 F 0.42 0.42 0.16 Y 0.67 0.20 0.13 W 0.49 0.44 0.07 K 0.93 0.02 0.05 R 0.84 0.05 0.11 H 0.66 0.19 0.15 C: Buried Residues V; L; I; F; W; C 0.01: Exposed Residues D; E; N; Q; K; R Protein Unfolding An unfolded protein has lost its tertiary/quaternary structure and its biological activity Depending on the experimental conditions an unfolded protein may be stable or it may aggregate/precipitate Treatments that unfold proteins: High temperature: many proteins unfold at 50-90 º C pH: some proteins will unfold when they gain a large net charge Denaturants: proteins unfold in detergents like sodium dodecyl sulfate (SDS) or in denaturants like urea and guanidine Unfolding curves are sigmoidal © Agnishwar Girigoswami Net Stability Most proteins have a net stability of ~10 kcal/mol/protein Compare this to the individual contributions: Hydrophobic effect ~ 1-2 kcal/mol/amino acid residue Conformational Entropy ~1-2 kcal/mol/amino acid residue For a 200 residue protein these contributions can be 400 kcal/mol each but the overall stability will always be ~10 kcal/mol Mutational Studies of Protein Stability © Lydia Chang Most mutations are destabilizing The ability to precisely predict the change in folding energy (ΔG) is not very good Buried residues have a bigger effect than exposed residues [图] Predicting changes in the stability of proteins and protein complexes: a study of more than 1000 mutations. J Mol Biol. 2002 Jul 5;320(2):369-87. The Levinthal Paradox Does a protein find its native configuration by a random search? Carbon-carbon bonds reorient each ~ 10-13 sec For a protein of n residues there are 32n conformations If n = 100, then 32n ~ 1095 If 1013 conformations were sampled every second it would take 1082 seconds to sample them all… …but the age of the universe is only about 1017 sec! It is now known that proteins fold on time scales from milliseconds to minutes Proteins fold via conserved, hierarchical pathways (This may explain the prevalence of the Greek Key motif) PS: why 32n: 2: there are two tortion angles: φ and ψ n: n peptides 3: If each of these bond angles can be in one of three stable conformations[1] Diseases of protein misfolding Cystic Fibrosis: Alzheimer’s disease Mad Cow Disease: Retinitus pigmentosa Molecular Chaperones © Alexandra Richardson, 1998 “Heat shock proteins” Molecular Chaperones Chaperonins Chaperones assist protein folding in the cell They bind unfolded chains They use energy from ATP to bind and release protein chains in a repeating cycle ATP turnover rate is slow 1 sec-1 The GroEL/GroES chaperone form E. Coli is well understood Other Proteins Protein Disulfide Isomerase Peptidyl proline cis-trans isomerase Protein Degradation in the Cell There are two main pathways for protein degradation in eukaryotic cells Lysosomal Degradation The lysosome is a membrane-encapsulated organelle It contains ~50 hydrolytic enzymes Lysosomes have acidic pH Has both selective and non-selective degradation processes Proteasomal Degradation The proteasome is a large protein machine (MW = 2x106) It degrades proteins that have the small protein ubiquitin attached to them Ubiquitination rate (degradation rate) is determined by the N-terminal residue Ubiquitin (76 residues) is the most highly conserved protein known Wikipedia: Levinthal’s paradox ↩︎","link":"/2021/09/22/LearnNotes/tulane-biochem-5/"},{"title":"Carbohydrate Biochemistry 8| Tulane","text":"Carbohydrate Biochemistry Glycated hemoglobin (HbA1C) Lactose intolerance Glycoprotein synthesis INfluenza virus Infection Heparin &amp; heparan sulfate Peptidoglycans of bacterial wall Glycate hemoglobin (HbA1C) HbA1c is a consequence of high blood sugar (Glc) caused by diabetes Normal Haemoglobin Fractions Haemoglobin HbA (a2/b2): 95-98% HbA2 (a2/d2): 1.5-3.5% HbF (a2/g2): &lt;2% Several minor hemoglobins migrate more rapidly than HbA in an electric field called HbA1. HbA1 is made up of HbA1a + HbA1b + HbA1C. What is HbA1C Suger Terminal HbA1a1 fructose-1,6 diphosphate β - N-terminal HbA1a2 glucose-6-phosphate β - N-terminal HbA1b pyruvic acid α- amino terminus HbA1C glucose attached β - N-terminal • HbA1C makes up &gt;90% of HbA1. • Normally less than 6% of Hb is HbA1C How is HbAiC is formed 2 Glc residues -&gt; Pre-HbA1C -&gt; HbA1C Note: Glucose is attache … to produce HbA1C molecules. How can we detect Hb subspecies? cation-exchange chromatography Why is A1C clinically important? Disease marker for Diabetes Lactose Intolerance Lactose intolerance Inability to digest lactose. Lactose Milk sugar, galactose - Glc Galactose (Gal) C-4-epimer of Glc chemically link in Lactose β-1,4-galactosidic linkage Cause of the lactose intolerance Lack/deficiency of lactase(β-galactosidase) Biosynthesis α-lactalbumin Glycoproteins Biosynthesis of O-glycans does not require dolichol phosphate. Biosynthesis of N-glycans requires dolichol phosphate. Synthesis Sialic aicd Hemagglutinin Neuraminidase Three Major Type A: mammal and birds B &amp; C: Human and not categorized into subtypes Influenza Virus Infection Type of Influenza viruses Treatment of Influenza Virus Infection Tamiflu and Relenza Heparin and heparan sulfate Fondaparinux","link":"/2021/10/01/LearnNotes/tulane-biochem-8/"},{"title":"Protein Analysis|Graduate Biochemistry 6| Tulane","text":"Purification and Analysis Overview Methods of protein separation and purification Protein solubility Isoelectric focusing Principles of chromatography Polyacrylamide gel electrophoresis Gel filtration Ion exchange/Hydrophobic interaction Affinity Chromatography Ultracentrifugation Methods of protein analysis Summary of primary information Protein sequencing by Edman degradation Mass spectrometry Methods of determining protein three dimensional structure Methods of Macromolecule Separation Method of Separation Physical Basis sensitivity Specifity Precipitation Solubility (charge, isoelectric point) μg - kg Very low Mass Spectrometry Molecular Mass fg - ug Very High Nondenaturing PAGE Charge/mass, shape μg - mg High SDS PAGE Molecular Weight μg - mg High Isoelectric focusing Isoelectric point μg - mg Moderate Capillary Electrophoresis Charge/mass ng - μg High Gel Filtration Size and shape ng - mg High Ion Exchange Net charge ng - mg Moderate High Hydrophobic interaction Chromatography Hydrophobicity ng - mg High Affinity Chromatography Specific molecular interactoin ng - mg Very High Density Gradient Ultracentrifugation Molecular weight, density and shape μg - g Moderate Equlibrium Density Ultracentrifugation Density μg - g Moderate Legend: Electrophoresis techniques Chromatography techniques Ultracentrifugation techniques Protein Solubility in Salt Salting in Increase in solubility with increasing salt at low ionic strength Proteins unfold at low ionic strength and irreversibly aggregate Salting out Protein precipitation at high ionic strength driven by ionic charge shielding and solvent effects Solubility is minimum at isoelectric point (ionic effect) Effectiveness of salting out in Hoffmeister series (solvent effect): Anions: SO4&gt;H2PO4&gt;CH3COO&gt;Br&gt;I&gt;ClO4&gt;SCN Cations: NH4,Cs,K,Na&gt;Li&gt;Mg&gt;Ca&gt;Ba PS: Increase the salt, you shield the charge surface of the protein © Michel Awkal 2020 © Richard R Burgess 2009 Solting in: The unsaturated ions on the surface of the protein can interacted with other ions to increase the soluability of the protein. Isoelectric focusing © Blake C Meyers 2007 Isoelectric point (pI) is the pH at which positive and negative charges are equally abundant on a molecule. pI for the G is ~6; pI for D is ~3.5 pI for K is ~ 9.5 Isoelectric focusing is equilibrium electrophoresis Ampholytes - Mixtures of buffer molecules covering a range of pKa values stabilize the pH gradient in an electric field Charged molecules, including the ampholytes, will move toward the location where their net charge is zero. This is the isoelectric point, or pI. Chromatography Principle of Chromatography Molecules in a mobile medium move through a stationary phase with which they can interact. Differential interactions with the stationary phase are the basis for physical separation of molecules Some stationary phases Paper (paper Chromatography) Bare silica (Thin layer chromatography) Functionalized Silica (Column Chromatography) Various polymers (acrylamide, dextran, agarose, and others) Mobile phase is usually liquid SDS PAGE Sodium Dodecyl Sulfate Polyacrylamide Gel Electrophoresis Acrylamide gel: Polymerized acrylamide Macromolecule movement is hindered Movement driven by electric field Mobility is determined by charge, size and shape SDS: A detergent that denatures proteins with/withough reducing agent: breaking the disulfide bond Proteins denatured in SDS: 3 SDS bound per amino acid Constant charge/mass Mobility α ln(mass) SDS can also solubilize hydrophobic AA Useful but may lots some information. Gel Filtration Chromatography © Marcell Wolf, 2015 © Rufika Shari Abidin Vo = Void Volume, Excluded Volume Vi = Included Volume VT (Total solvent volume) = Vo+Vi For each mocromolecule Vp = Penetrable volume Ve (Protein Elution Volume) = Vo+Vp σ (fractional retention) = Vp/Vi Vp/Vi = (Ve - Vo)/(VT - Vo) Polymer pours beets. separated the protein by its size You can’t tell the protein is monomor, dimer or etc. small proteins randomly filtered inside of the beets and causing transfer delay. Ion Exchange Chromatography Retention is due to ionic interactions with fixed charges on stationary phase Counterions compete for binding sites Three phases: binding, elution, regeneration Binding: Cation exchange: fixed anions Anion exchange: fixed cations Typical Ionic groups Diaminoethylamino (DEAE) Carboxymethyl (caboxylate) Sulfoethyl/Sulfobenzyl (sulfate) The material is charged: Same charge: not interacted opposite Charge: Reacted Hydrophobic Interaction Chromatography Binding to stationary phase is hydrophobic Elution is with organic solvents (Acetonitrile, methanol, isopropanol, hexane) Often used in High Pressure Liquid Chromatography (HPLC). Affinity Chromatography Retention is due to specific interaction Typical affinity molecules: Antibody Ligand/substrate/inhibitor Lectin (carbohydrates) Nickel-Nitrilotriacetate or Ni-NTA Binds to engineered poly Histidine PS: Some specific interact between the protein and the ?agent Example of Enzyme Purification Purification Step Total Acitivity % recovery Specific Activity Crude Extract 31800 100 1 Acid Precipitate 59900 189 10.1 Amm. Sulfate Precipitate 57200 175 27.2 GTP ( affinity) 37300 117 3962 Mono Q (ion exchange) 14300 45 6304 Gel filtration 11000 35 11620 // 基于准备好的dom，初始化echarts实例 var myChart = echarts.init(document.getElementById('echarts8469')); // 指定图表的配置项和数据 var option = option = { tooltip: { trigger: 'axis', axisPointer: { type: 'shadow' } }, legend: { data:['Total Acitivity', '% recovery', 'Specific Activity'] }, grid: { left: '3%', right: '4%', bottom: '3%', containLabel: true }, xAxis: [ { type: 'category', data: ['Crude Extract', 'Acid Precipitate', 'Amm. Sulfate Precipitate ', 'GTP ( affinity)', 'Mono Q (ion exchange)', 'Gel filtration'], axisLabel: { interval: 0, rotate: 15 }, } ], yAxis: [ { type: 'value' } ], series: [ { name: 'Total Acitivity', type: 'bar', label: { show: true, rotate: 90, align: 'left', verticalAlign: 'middle', position: 'insideBottom', formatter: '{c} | {a}', distance: 15 }, emphasis: { focus: 'series' }, data: [31800 , 59900, 57200, 37300 , 14300 , 11000] }, { name: '% recovery', type: 'bar', label: { show: true, rotate: 90, align: 'left', verticalAlign: 'middle', position: 'insideBottom', formatter: '{c} | {a}', distance: 15 }, emphasis: { focus: 'series' }, data: [100 , 189 , 175 , 117, 45 , 35] }, { name: 'Specific Activity', type: 'bar', label: { show: true, formatter: '{c} | {a}', }, emphasis: { focus: 'series' }, data: [1,10.1, 27.2, 3962, 6304, 11620] }, ] }; // 使用刚指定的配置项和数据显示图表。 myChart.setOption(option); Ultracentrifugation Bouyant force depends on: Density Difference between molecule and solvent Frictional force depends on: Molecular shape Solvent viscosity Centrifugal force depends on: Molecular weight Rotation speed Distance from center Ultracentrifugation Can be used to obtain information on molecular weight, molecular shape and intermolecular interactions Sedimentation velocity (S=Svedbergs) Sedimentation equilibrium Density Gradient Ultracentrifugation Sucrose gradient: Gradient is man-made and impermanent Sample applied at top Separation is by sedimentation velocity CsCl density Gradient: Gradient is formed by centrifugal force Equilibrium position of macromolecule determined by its density Protein Sequence Determination Primary Information Number of chains Dansyl Chloride reaction (Voet, Voet &amp; Pratt pg 109) One cycle of Edman degradation SDS PAGE (under reducing conditions) Primary Sequence Fragmentation, purification of fragments and Edman sequencing or mass spectroscopy Requires overlapping fragments Common fragmentation methods: Cyanogen Bromide (cleaves C-term side of Met) Trypsin (cleaves C-term side of Arg, Lys) Chymotrypsin (cleaves C-term side of Trp, Phe, Tyr) Disulfide linkages SDS PAGE (reduced and non-reduced) Fragmentation, purification and partial sequencing with disulfide bonds oxidized/reduced Protein Sequencing Principles of Edman degradation: Cyclic, sequential removal and identification of N-terminal amino acids Identification is done by High Pressure Liquid Chromatography (HPLC) Can sequence 50-100 residues Sequence determination requires overlapping fragments Derivitization: Phenylisothiocyanate (PITC) Acid cleavage: PTC polypeptide terminal remove Acid reduction: Polypeptide like of residue Separation and Identification (Back to 1.) cite: Voet, Voet &amp; Pratt pg 113 Mass Spectrometry Principle of Mass Spectrometry Acceleration of a molecule in an electric field depends on the mass/charge ratio Protein Mass Spectrometry MALDI TOF - Matrix assisted laser desorption - Time of flight ESI - Electrospray ionization Both methods can be used to determine the molecular weight of proteins up to ~ 105 Daltons Molecular weight determination is unambiguous Proteomics - by mass spectrometry Genomics: The study of the an organism’s genetic information. Proteomics: The study of large scale protein expression pattern in a cell type or tissue. Genomic information is fixed. Proteomic information depends on life cycle, environment, cell type etc. Below: Two-dimensional gel electrophoresis of an E. coli whole cell extract. Modern MALDI/SELDI mass spectrometers can identify these proteins Often done by cutting out spots, digesting proteins with trypsin and getting the mass of the fragments by mass spec. Determination of Protein Structure Two methods are used to determine protein structure: X-ray crystallography Two-dimensional Nuclear Magnetic Resonance (NMR) spectroscopy X-ray crystallography purify protein grow crystals collect X-ray diffraction patterns determine electron density in three dimensions solve protein structure Advantages: Can solve very large proteins/complexes Gives atomic-level resolution Disadvantages: crystallization is often difficult or impossible crystal contacts can distort structure Determination of Protein Structure 2D NMR Spectroscopy purify protein collect multidimensional NMR spectra in solution assign peaks and crosspeaks to specific residues calculate distances between residues from the strength of the crosspeaks solve structure using distance constraints Advantages: no crystallization required structure is a solution structure Disadvantages: Only small proteins (&lt;200 residues) can be solved Resolution is not at atomic level","link":"/2021/09/24/LearnNotes/tulane-biochem-6/"},{"title":"Lipids, Membranes and Membrane Proteins|Graduate Biochemistry 7| Tulane","text":"Overview A cell is a membrane-rich environment Classes of lipids Structure of lipids Polymorphic phase behavior of lipids The lipid bilayer membrane The fluid mosaic model of biological membranes Classes and functions of membrane proteins Folding and structure of membrane proteins Hydropathy plots A cell is a membrane-rich environment Classes of Lipids Fatty acid (e.g. palmitate, oleate) Energy storage metabolite Building block of other lipids Triacylglycerols (fat) Energy storage Glycerophospholipids Form lipid bilayer membrane Signal transduction Sphingolipids Form lipid bilayer membranes Signal transduction Steroids Rigidify membranes (Cholesterol) Membrane-crossing hormones (e.g. Estrogen) Fatty Acids - structure and nomenclature Fatty acid rules of nomenclature Carbon numbering start at carboxyl carbon Double bonds are numbered at the first carbon cis configuration is normal (trans is specified) Syntax for nomenclature length:#double bonds (list of double bond locations) 16:0 = palmitic acid 18:1(9) = oleic acid (sometimes written 18:1(Δ9)) 20:4(5,8,11,14) = arachidonic acid palmitic acid oleic acid arachidonic acid © PubChem ID= 985, 445639, 444899 Typical eukaryotic fatty acid structure Even number of carbons Non-conjugated double bonds (double bonds are separated by at least one CH2) Double bonds are normally cis If a double bond is trans it is specified in the name PS: Even number: Synthesis and degraded of the fatty acid are occur two carbons at a time. Conjugated double bounds: Conjugated double bounds could make fluorescence. Exp: Retinol, or vitamin A, has five conjugated double bonds and absorbs the violet part of the spectrum, thus appearing as yellow.[1] Cis: As the picture above, the hydrogen atoms are on the same side. Palmitic acid Oleic acid Classes of diacyl lipids The two backbone molecules in diacyl lipids: Glycerol (Glycerophospholipids) Serine (Sphingolipids) Diacyl lipids are the main structural component of bilayers and are the ONLY component that will form bilayers in pure form. Be able to draw the base of this two lipids. Glycerol Serine Two fatty acids connect to two hydroxyl groups independently, the rest hydroxyl group connect to the phosphate acid which could connect the variety head. Two fatty acids connect to Amino group and carboxyl group. R chain connect variety heads © PubChem Variety of Glycerophospholipid (head) Phosphatidic acid Phosphatidylethanolamine Phosphatidylcholine Phosphatidylglycerol Phosphatidylserine Phosphatidylinositol © PmdChem second messenger molecule Often phosphorylated on one o several hydroxyls No head © PubChem ID=6026790 A signaling molecule Phosphatidic acid: is rare in memebrane but it’s intermediate of the metabolic. Phosphatidylcholine: Most abundant glycerophospholipid found in eukaryotic membrane. Innert, not strong interaction with others. (Outside of the membrane) Phosphatidylethanolamine: Charge and much activity than Phosphatidylcholine, inside the cell. Phosphatidylglycerol: also abundant in prokaryotic cell. Phosphatidylserine: active, inside the cell. Common in eukaryotic cell. It’s not a sugar group, it is a sample carbon base ring. Phosphatidylinositol: Negative Charged, signaling molecule. Second messenger. Sphingolipid Headgroups Sphingomyelin Sphingomyelin Phosphocholine group Cerebrosides Simple sugars Galactose, lactose, glucose (uncharged) Gangliosides More complex carbohydrates (anionic) Found in brain Fatty acid melting points The longer the chain, the higher the melting point. The more double bounds, the lower the melting point. © PubChem ID= 3018404 Melting point:82-95 °C. © PubChem ID= 5280450 Melting point:-9 °C. PS: Cells control the fluid of the membrane by change the type of lipid (melting point) to achieve specific biology purpose. Four common fatty acid you should remember Symbol Common name Systematic name Structure mp (°C) 14:0 Myristic Acid Tetradecanoic acid CH₃(CH₂)₁₂COOH 52 16:0 Palmitic acid Hexadecanoic acid CH₃(CH₂)₁₄COOH 63.1 20:0 Arachidic acid Eicosanoic acid CH₃(CH₂)₁₈COOH 75.4 24:0 Lignoceric acid Tetracosanoic acid CH₃(CH₂)₂₂COOH 84.2 Phospholipases and cyclooxygenases © Konstantin Balashev Phospholipases A1, A2, B, C, and D. Most phospholipids was cleaved by Phospholipase A2 cyclooxygenases © NV Chandrasekharan Cyclooxygenases (COXs) catalyze the rate-limiting step in the production of prostaglandins, which is an signal molecule and both soluble in water and lipids. Cholesterol and other steroids © PubChem ID= 5997 Cholesterol is a component of biological membranes Up to 50% of a membrane’s lipid can be cholesterol It rigidifies or stiffens bilayers Cholesterol is converted to bile acids (used in digestion) and steroid hormones (used for signaling) Steroid hormones freely cross membranes and act directly on nuclear receptors The hydroxyl group of the cholesterol makes it float on the cell membrane. In the RBC, the cholesterol in cytomembrane could up to 50% and which makes the membrane very rigidity. (try to keep it’s shape when it through the catepillars) Lake of most membrane proteins. As a contrast, the mitochondria’s membrane does not have cholesterol and has very high fluidity which needs to go constant conformation change. One of the fluidity membrane we know are rod and cone cell which are light recept cells. They need to interact quickly. As a result, they are made highly portion of the saturated fatty acids and very little of cholesterol. Steroid Hormones © PubChem These hormones are both soluble in water and lipids. So they can pass membrane easily. Polymorphic Phase Behavior of Lipids All lipids spontaneously separate from water The form of the lipid phase depends on the molecular “shape” of the molecule Head group end Molecular shap hypothesis: Lipid Type Composition Types in below Fatty acid Other detergents micelle Type 1 Diacyl Lipid bilayer Type 0 Diacyl Glycerol inverse micelle Type 2 Core of the membrane is the most hydrophobic environment we can find. In the core of folded protein, the hydrophobic core coudl have a few polar groups. But not poler group in Membrane core. Which gaves the membrane a barrier property © Chandrashekhar V. Kulkarni “Fluid Mosaic” model of biological membranes © Veronika Novotná, et al. Living cells actively maintain a certain membrane fluidity by adjusting the composition of the lipids in their membranes. The lipids are the solvents, the proteins are solutes. This drawing is wrong. The membrane can pack more protein than it. Exp: Mitochondria. Secondary Structure Types in Membranes © Guangshun Wang Header One Header Two Water Interface 15 Å Core 30 Å Interface 15 Å Water Membrane-spanning proteins have very few polar groups groups, such as the peptide back bone exposed to the core of the bilayer. Membrane Protein α-helix 19-25 residues to span the membraneSelf hydrogen-bondingMostly hydrophobic along the membrane-spanning segmentAbout 25% of ALL proteins are helical membrane proteins β-barrel 8-12 residues are required to span membraneNot self Hydrogen bondingDyad repeat motif (alternating hydrophobic/hydrophilic)Found in the outer membranes of some bacteria and in mitochondria Membrane integral protein challenges: Residues: Hydrophobic residues on the menbrane core area Carbon back-bond: Form hydrogen bond with itself. Typically, the surface of the proteins interacted with membrane are even more hydroponically than the core of folded protein. 30Å membrane core takes about 20 residues of α-helix. β-barrel only find in gram-negative bacterial, mitochondrial and chloroplasts. (Human, about 50 β-barrel gene and only on mitochondria genome. 2% of gene is β-barrel in E. coli) Structure of Bovine Rhodopsin A protin in eye cell membrane. Salt bridges and hydrogen bonds are rare in membrane protein. © Molview, PDBID=1f88 Rhodopsin Dimer Structure of Rhodopsin Spacefilling Side View Top View Structural features of membrane proteins Exterior is very hydrophobic over ~30 Å slab of the membrane Interior has amino acid composition like that of a soluble protein Helices are close-packed Salt-bridges and helix-helix hydrogen bonds are rare ionizable residues are nearly always salt bridged. Helix-helix interactions are mainly driven by van der Waals packing © Yi Xia The human erythrocyte protein Glycophorin A has a single membrane-spanning α-helix Hydropathy Analysis © Yair Benita, et al. Take the 19 amino acids in a box from the chain and calculate the hydrophobicity, and them you slid it one by one to make the Sliding Window Hydropathy Plot. Glut1 © Molview, PDBID= 4pyp Rhodopsin Dimer © MobeenRaja, et al. A Brief Discussion on Color; umass.edu ↩︎","link":"/2021/09/29/LearnNotes/tulane-biochem-7/"},{"title":"Enzymatic Catalysis, Catalytic Mechanisms 9| Tulane","text":"Enzymatic Catalysis, Catalytic Mechanisms General Properties of Enzymes Activation Energy and the Reaction Coordinate Catalytic Mechanisms Serine Proteases (pp. 342-347) Learning Goals Give examples of various levels of substrate specificity, and explain specificity differences exhibited by serine proteases Give examples of reactions that utilize coenzymes NAD, FAD, Coenzyme A, and lipoic acid (metabolism lectures), and specify the role of the coenzyme Describe catalysis in terms of a reaction-coordinate energy diagram Classify enzymes by type of reaction Explain catalysis by enzymes in terms of chemical mechanisms Elaborate the catalytic mechanism of a chymotrypsin Explain divergent and convergent evolution Discuss the similarity of primary structure vs. tertiary structure in proteins as evidence supporting the existence of homology Enzymes differ from chemical catalysts Higher reaction rates Milder reaction conditions Greater reaction specificity Capacity for regulation How Do Enzymes Work? Enzymes accelerate reaction rates through the formation of weak bonds (hydrogen bonds, hydrophobic bonds, ionic bonds, van der Waals interactions) between the enzyme and the substrate. Enzymes use the energy from the formation of these weak bonds help arrange the substrate in a position favorable for a chemical reaction. Catalysis by Transition- state Stabilization Rate 315 times faster when R=CH3 than when R=H Specific Geomitric complementarity and electronic complementarity contribute the specific of the enzyme. Stereospecific: target into one kind of chiral only. Geometric Specificity: identities of the chemical groups on their substrates. Transition State Analogues The transition state is a “fleeting molecular moment” where events such as bond breakage, bond formation, and charge development have proceeded to a point at which decay to either substrate or product is equally likely. Stable molecules designed to resemble this transition state are called transition state analogues. They often bind to enzymes more tightly than either the substrate or the product. This principal has been used to increase the effectiveness of pharmaceuticals. Most of the HIV protease inhibitors used to treat AIDS are transition state analogues. Transition-state Analogs The properties of enzymes control the fate of most cellular metabolites The ~ 500 reactions that comprise human metabolism are all catalyzed by enzymes. Lehninger, Figure 15-1 Enzymes can be classified according to the reactions they catalyze Oxidation states of biological carbon molecules Oxidation states of biological carbon molecules Oxidation states of biological sulfur Biological oxidation-reduction reactions utilize mobile or protein-bound electron carriers Oxidized Forms NAD+ NADP+ FAD FMN Reduced Forms NADH NADPH FADH2 FMNH2 NAD+ Nicotinamide Adenine Dinucleotide NADP+ Nicotinamide Adenine Dinucleotide Phosphate FAD Flavin Adenine Dinucleotide FMN Flavin Mononucleotide Electrons on NADH and FADH2 are used primarily to generate ATP via electron transport and oxidative phosphorylation. Electrons on NADPH are used to provide reducing equivalents during synthetic reactions. Oxidoreductases catalyze redox reactions Lactate dehydrogenase (LDH) is a glycolytic enzyme present in a number of different tissues. LDH isozymes (enzymes with different structures that catalyze the same reaction) are sometimes measured in serum as an indicator of cell damage. Transferases catalyze the transfer of a functional group from one molecule to another Hexokinase is an transferase that transfer a phosphate from ATP to a hexoses (six-carbon sugars), forming hexose-6-phosphate. In most organisms, glucose is the most important substrate and of hexokinases, and glucose-6-phosphate is the most important product. Hydrolyases catalyze the transfer of a donor group to water. Water is added and 2 molecules are formed from 1. Glucose 6-phosphatase is a hydrolase in the gluconeogenic pathway that removes a phosphate group from the C-6 hydroxyl group of glucose to form glucose and inorganic phosphate. Lyases add or remove elements of carbon dioxide, ammonia or water (without making two molecules from one). Fumerase is an lyase enzyme in the Tricarboxylic Acid Cycle. Note that water is added, but this enzyme does not make 2 molecules from one. Isomerases are enzymes that catalyze intramolecular rearrangements. All the atoms in the substrate are also present in the product, just in a different configuration. Phosphoglucomutase is an isomerase that interconverts glucose 6-phosphate and glucose 1- phosphate. This enzyme is required for the synthesis of glycogen and complex carbohydrates. Ligases catalyze synthetic reactions where 2 molecules are joined at the expense of a “high energy phosphate bond” , usually ATP or GTP. No part of the ATP or GTP ends up in the product. Pyruvate carboxylase is a ligase important in the gluconeogenesis. It is also used to replenish intermediates in the Tricarboxylic Acid Cycle Substrate Specificity Lock-and-key model refers to complementarity between enzymes and substrates Induced fit refers to conformational change upon substrate binding – accommodation of multiple substrates Example of “high” specificity (stereospecificity) 3-point- attachment results in stereospecific product Example of “low” specificity (geometric) Example of enzyme that uses a coenzyme/cosubstrate MECHANISMS OF CATALYSIS Acid-base Catalysis Covalent Catalysis Metal Ion Catalysis Catalysis by Transition- state Stabilization Rate 315 times faster when R=CH3 than when R=H Catalysis by Proximity and Orientation Catalytic triad of chymotrypsin and other serine proteases ES complex Serine protease mechanism ES complex Tetrahedral intermediate","link":"/2021/10/05/LearnNotes/tulane-biochem-9/"},{"title":"Deep Learning (Classes notes)","text":"1 Lecture 18: Neural Networks 🐶 ANN, also called “artificial neural net” or “neural net”, represents one of the most popular and promising areas of artificial intelligence (AI) research. An ANN is an abstract computational model, inspired by the structure of central nervous systems Network structures: An ANN may have either a recurrent or nonrecurrent structure Parallel processing ability: Each neuron in the ANN is a processing element interconnections between neurons have a parallel structure Distributed memory: The network does not store information in a central memory. The values in the weights (the connections) form a long-term memory Fault tolerance ability: The network’s parallel processing ability and distributed memory make it relatively fault tolerant Collective solution: A conventional computer processes programmed instructions sequentially and one at a time Learning ability: An ANN, especially the nonrecurrent one, is capable of applying learning rules to develop models of processes while adapting the network to the changing environment and discovering useful knowledge implicit in received data Development Source: thinkautomation: Milestones in artificial intelligence 1943: The first ANN → 1948: First autonomous robots → 1955: Official term and academic recognition → 1964: The first chatbot → 1969: Backpropagation → 1970: First ‘intelligent’ robot → 1978: Voice-activated technology → 1981: Commercialised AI → 1989: Chess victories: defeating masters → 1996: Chess victories: defeating the world champion → 1998: Widespread introduction: Furby and machine learning → 2001: A.I. Artificial Intelligence → 2010: Jeopardy! win → 2011: Voice assistant → 2016: Winning at Go (ANN) Learning Major Types Supervised Learning: the desired outputs for a set of training examples with class labels are provided to the neural network; thus, it learns by learning from training examples in the train set Unsupervised learning: no training examples are provided, and therefore, no evaluation of performance provided to the network Reinforcement learning: a hybrid method, the neural network is given a scalar evaluation signal instead of being told the desired output, and evaluations can be made intermittently © Matthew E. Dilsizian; 2018 © Rosangela Cintra © Cornell College More infor: Cornell College: Cheat Sheets for AI, Neural Networks, Machine Learning, Deep Learning &amp; Big Data, click to download FFNN and FBNN © AnhTuan Hoang; 2021 Perceptron A perceptron, coined by Frank Rosenblatt in 1958, is originally defined as a single artificial processing neuron with an activation threshold, adjustable weights and bias [1] A perceptron refers to a single node in a neural network, such that in an input layer, these nodes (i.e., perceptrons) receive input values (also called input signals) that quantify the characteristics of each data object, and these input values are multiplied by the respective weights assigned to them to produce a summed value, which is evaluated according to a threshold value obtained from the activation function to determine the output value[2] In a single-layer perceptron, this output value is the prediction value. In a multi-layer perceptron, it is used as the input value for another perceptron layer[2:1] Multi-Layer Perceptron (MLP) A multi-layer perceptron (MLP) with backpropagation (BP) learning algorithm, also called multi-layer FFNN. An MLP comprises 3 layers: input, hidden, and output All neurons from one layer are fully connected to neurons in the adjacent layer. These connections are represented as weights. The weights play an important role in propagation of the signal in a neural network. The propagation which can be either single or multiple The learning algorithm of an MLP involves a forward feed (also called forward-propagation) step followed by a backpropagation (BP; also called backward-propagation) step, such that the input first is propagated through the neural network and the output computed. Then the error between the computer output and the correct output, in the form of a cost function, is propagated backward from the output to the input to adjust the weights (i.e., connection intensities). There are several methods that can be applied for backpropagation (BP), and among them, gradient descent method is the most popular Major Activation Functions in ANN What is Activation function: An Activation Function decides whether a neuron should be activated or not. This means that it will decide whether the neuron’s input to the network is important or not in the process of prediction using simpler mathematical operations. © V7 labs The steps of the ANN: input → weighted → Transform (Function) → Active (Function) Table: TizianoZarra; 2018 Activation Function Formula Strength/s Weakness/es Range Reference/s Logistic Sigmoid (LS) $f(x)=\\frac{1}{1+e^ {-x}}$ • smooth • continuously differentiable possibility to get stuck in the training• slow convergence (0, 1) Rojas, 1996, Chen et al., 2015 Hyperbolic Tangent $f(x)=\\frac{1-e^ {-2x}}{1+e^ {-2x}}$ the derivative is more steep that LS (i.e., scaled LS) Differentiable at all points vanishing gradient issues and low gradient (−1, 1) Pushpa and Manimala, 2014, Theodoridis, 2015 Radial basis function or Gaussian Function $f(x)= exp(-\\frac{(x-c)^ 2}{r^ 2})$ • good when finer control is required over the activation range • computational time consuming due to the calculation of Euclidean distance (0, 1) Sibi et al., 2013; Faqih et al, 2017 Rectified Linear Unit Function (ReLU) $f(x)=0\\ for\\ x&lt;0;x\\ for\\ x ≥0$ • good estimator• can combine with other functions• can activate all neurons at the same time • non-differentiable at zero and unbounded.• it can create dead neurons because gradients for negative input are zero. (0, ∞) Xu et al., 2015; Kessler and Mach, 2017 Maxout Function or Leaky ReLU $max(w_ 1 ^T x + b_ 1, w_ 2 ^ Tx + b_ 2)$ • speeds up the training• no dying ReLU units (i.e., 0 output” • become saturated for large negative values (−∞, ∞) Xu et al., 2015 Swish Function $f(x)=x×sigmoid(x)$ • smooth and non-monotonic function which outperformed ReLU on deep networks • computationally expensive (−∞, ∞) Nwankpa et al., 2018 © SAGAR SHARMA; 2017 Forward Feed back and Backpropagation Forward Feed Step Backpropagation (BP) Step Source: © Han SH; 2018 Gradient Descent © primo.ai The gradient descent identifies the lowest point, i.e., the global cost minimum, of a cost function by taking iterative steps to adjust the weights starting from an arbitrarily chosen initial weight[3]. The gradient descent shall take many “epochs” (i.e., training cycles) to find the global cost minimum, rather than a local cost minimum, starting from an arbitrarily chosen initial weight[4]. Advantages and Disadvantages Advantages ANNs do not rely on data to be normally distributed, an assumption of classical parametric analysis methods ANNs are able to process data containing complex (non-linear) relationships and interactions that are often too difficult or complex to interpret by conventional linear methods ANNs are fault tolerant, i.e., they have the ability of handling noisy or fuzzy information, whilst also being able to endure data which is incomplete or contains missing values ANNs are capable of generalization, so they can interpret information which is different to that of the training data, thus representing a ‘real-world’ solution to a given problem by their ability to predict future cases or trends based on what they have previously seen. Disadvantages The ANN model obtained could be difficult to interpret Training of ANNs can potentially be time-consuming, depending on the complexity of the data being modelled As the # of hidden layers required to capture the features of the data increases, so does the time taken for training to complete. As such, only one or two hidden layers are commonly used. Overfitting may be a problem, which is a memorization of the training examples causing the ANN to perform poorly on future examples It is not always apparent how an ANN reaches a solution, and because of this, an ANN model has been referred to as a “black box” approach the quality of an ANN model ouput is highly dependent upon the quality of the input data Lecutre 19: Deep Learning Outliers Advanced Concepts in Neural Networks Cost Functions Activation Functions Learning Rates and Overfitting Stochastic Gradient Descent (SGD) and Parallelization Convolutional Neural Networks Recurrent Neural Networks What is Deep learning: Deep learning is a NN with &gt;1 hidden layer Loss Functions Which measures how well the model goes. Binary Cross Entropy Loss Mean Squared Error Loss Activation Functions Go back to looking above. ReLUs VS Sigmoid Activation Functions ReLUs replace everything below the bias threshold to zero and don’t remap coordinates to (-1 to 1) Sigmoids have a problem of vanishing gradients where higher absolute input values no longer increment output values Sparser representation - high proportion of neurons output a 0 ReLUs converge much faster Multiple Sigmoids are Incompatible with Deep Learning Derivative of sigmoid function is always «1, therefore product of gradients drops close to zero for multiple layers Learning Rate and Overfitting © efxa.org Lots of local minima that gradient-descent can get stuck in. Solution: Setting the learning rate. Memorization and Early Stopping © Dr. Saptarsi Goswami; 2020 Goal is to have predictor that generalizes beyond the training set Early stopping prevents loss of generalization due to memorization of the training set Regularization I: Dropout During training, randomly set some activations to 0 Typically “drop” 50% of activations in layer Forces network to not rely on any I node Weight Decay Regularization Adds an additional error, proportional to: Sum of weights (L1 norm) Squared magnitude (L2 norm) of weight vector Elastic net regularization does both L1 and L2 Penalizing large weights simplifies the model Stochastic Gradient Descent (SGD) When you run backpropagation to readjust the weights and biases, should you go through the training set at each iteration? No! You can take randomly-sampled mini-batches of the data and compute weight adjustments in parallel across many processors Momentum and SGD for learning rate © datascience.stackexchange.com Faster convergence towards local optimum Reduced oscillation around steep slopes CNN © Sumit Saha; 2018 CNN Limitations Corner cases that occur in real life aren’t found in training sets upturned chair crumpled t-shirt lying on a bed ImageNet has idealized versions of objects in perfect lighting Generalization in CNNs occurs in a totally different way than we generalize CNNs do not have explicit internal representations of entities and their relationships Capsule Networks are being developed to solve ”Picasso problem” for higher-order feature hierarchies Recurrent Neural Networks Very friendly for time serious data A sequence Modeling Problem: Predict the Next Word Fixed window doesn’t work well because long term dependencies need to be modeled Vector of word counts doesn’t work well because counts don’t preserve order Apply a recurrence relation at every time step to prcess a sequence: $h_ t = f_ 2 (h_ {t-1}, x_ t)$ Recurrent Neural Networks Summary: Useful for language modeling and time-series data long short-term memory (LTSM) Multiple copies of the network – internal state is passed between these copies Signals can propagate through a layer more than once, potentially infinitely Data can flow in any direction Deep Learning in Biomedical Research L20: Deep Learning ==== Reinforcement Learning © Daniel Johnson © Hongbign Wang Introductions for Matlab Reinforcement learning is a machine learning training method based on rewarding desired behaviors and/or punishing undesired ones. In general, a reinforcement learning agent is able to perceive and interpret its environment, take actions and learn through trial and errorJoseph M. Carew,. Reinforcement learning, also called neuro-dynamic programming and approximate dynamic programming [5][6], a goal-oriented algorithm, refers to a class of techniques for training a computational agent (also called controller, robot, or player) to successfully interact with the environment to attain specifically defined goals. As an agent takes actions within its environment, an iterative feedback looping of reward and state trains the agent during time to better accomplish the goals Reinforcement learning learns how to attain a complex objective or maximize along a particular dimension during many time steps. The key feature is that the agent operates in a delayed return (i.e., reward) environment, such that it is not obvious to understand which action leads to which result during many time steps. Thus, reinforcement learning aims at correlating immediate actions with the delayed returns produced by such actions General Reinforcement Learning Workflow In reinforcement learning (RL), the RL agent solves a sequential decision-making problem by learning new experiences through a trial-and-error approach. An RL agent is trained by its actions interacting with the environment to maximize the cumulative reward resulting from the interactions. Generally, An RL algorithm is modeled and solved based on the Markov decision process (MDP) theory [6:1], there is an R packege MDPtoolbox that can be applied to implement MDP The learning of an agent is a sequential process, where interactions with the environment occur at discrete time steps t = 0, 1, 2, …, such that in a typical RL iteration at time step t, the agent receives the environment’s state (i.e., st) and selects an action (at) to interact. The environment responds to the action at and progresses to a new state st+1 at next iteration at time step t+1 The reward rt+1 that the agent receives for the selected action at associated with the transition (st, at, st+1) is also determined [6:2]. Accordingly, after each RL iteration, the agent updates (state-)value function V(st) and action-value function Q(st, at) based on a control policy π, which is a function that maps st ∈ S to at ∈ A, i.e., π: S → A ⇒ at = π(st) [7] The objective of the RL agent is to iteratively learn (i.e., attain) an optimal control policy π* that maximizes the expected umulative reward (i.e., expected return) received Deep Reinforcement Learning © Luis Campos; 2018 Zafeiris D, Rutella S, Ball GR. An Artificial Neural Network Integrated Pipeline for Biomarker Discovery Using Alzheimer’s Disease as a Case Study. Comput Struct Biotechnol J. 2018;16:77-87. ↩︎ Lee D-G, Jang Y, Seo YS. Intelligent Image Synthesis for Accurate Retinal Diagnosis. Electronics 2020;9:767. ↩︎ ↩︎ Han SH, Kim KW, Kim S, Youn YC. Artificial Neural Network: Understanding the Basic Concepts without Mathematics. Dement Neurocogn Disord. 2018;17:83-89. ↩︎ Burney SMA, Jilani TA, Ardil C. A comparison of first and second order training algorithms for artificial neural networks. Int. J. Comput. Intelligence, 2004;1:176-184. ↩︎ Bertsekas DP, Tsitsiklis JN. Neuro-dynamic programming. Athena Scientific, 1996. ↩︎ Sutton RS, Barto AG. Reinforcement learning: An introduction. MIT Press, 1998. ↩︎ ↩︎ ↩︎ Kaelbling P, Littman ML, Moore AW. Reinforcement learning: A survey. J Arti. Intell Res., 1996;4:237-285. ↩︎","link":"/2022/03/24/LearnNotes/tulane-bioinf-18/"},{"title":"BioStatistics with R&#x2F;Python: Block 1","text":"Biomedical Statistics and Data Analysis pre { background-color:#38393d; color: #5fd381; } Normal Distribution (PS: If you don’t have any other information, or have too few data points to test the assumption, it is acceptable to assume a Gaussian distribution.) $$ Pr(X = x|\\mu, σ^ 2) = p ( x | \\mu , σ^ 2) = \\frac{A}{\\sigma \\sqrt{ 2 \\pi}} e^{- \\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^ 2} $$ A = Area under curve μ = mean σ = standard deviation Normal distribution codes for python © R CODER In R, there are few functions for calculate normal distribution related values. Let’s say, the μ = 0, σ = 1, (as the plot above) than, we have: the probability of x is dnorm, the Z is pnorm. The size of blue area qnorm: inverse cdf function (Confidence Intervals, CI), the reversed value of the pnorm dnorm(0, mean=0, sd=1)pnorm(0, mean=0, sd=1)qnorm(0.5, mean=0, sd=1) [1] 0.5 [1] 0.3989423 [1] 0 CI calculate ® CI &lt;- function(A, alpha){ alpha = 1- alpha sample.mean &lt;- mean(A) sample.n &lt;- length(A) sample.sd &lt;- sd(A) sample.se &lt;- sample.sd/sqrt(sample.n) print(sample.se) degrees.freedom = sample.n - 1 t.score = qt(p=alpha/2, df=degrees.freedom,lower.tail=F) print(t.score) margin.error &lt;- t.score * sample.se lower.bound &lt;- sample.mean - margin.error upper.bound &lt;- sample.mean + margin.error print(c(lower.bound,upper.bound))}A &lt;- c(12, 3, 4, 2, 42, 4, 42, 524, 5)CI(A, 0.90)CI(A, 0.95)CI(A, 0.99) rnorm() function for data simulation from scipy import statsimport numpy as nprng = np.random.default_rng()pts = 1000a = rng.normal(0, 1, size=pts)b = rng.normal(2, 1, size=pts)x = np.concatenate((a, b))k2, p = stats.normaltest(x)alpha = 1e-3print(&quot;p = {:g}&quot;.format(p))p = 8.4713e-19if p &lt; alpha: # null hypothesis: x comes from a normal distribution print(&quot;The null hypothesis can be rejected&quot;)else: print(&quot;The null hypothesis cannot be rejected&quot;)The null hypothesis can be rejected codes for python, 2 Shapiro-Wilk Test # Shapiro-Wilk Testfrom numpy.random import seedfrom numpy.random import randnfrom scipy.stats import shapiro# seed the random number generatorseed(1)# generate univariate observationsdata = 5 * randn(100) + 50# normality teststat, p = shapiro(data)print('Statistics=%.3f, p=%.3f' % (stat, p))# interpretalpha = 0.05if p &gt; alpha: print('Sample looks Gaussian (fail to reject H0)')else: print('Sample does not look Gaussian (reject H0)') Shapiro in R shapiro.test(my_data$len) Shapiro-Wilk normality test data: my_data$len W = 0.96743, p-value = 0.1091 noteFrom the output, the p-value &gt; 0.05 implying that the distribution of the data are not significantly different from normal distribution. In other words, we can assume the normality. D’Agostino’s K² Test (most widely and used by GraphPad) # D'Agostino and Pearson's Testfrom numpy.random import seedfrom numpy.random import randnfrom scipy.stats import normaltest# seed the random number generatorseed(1)# generate univariate observationsdata = 5 * randn(100) + 50# normality teststat, p = normaltest(data)# Stat is k^2print('Statistics=%.3f, p=%.3f' % (stat, p))# interpretalpha = 0.05if p &gt; alpha: print('Sample looks Gaussian (fail to reject H0)')else: print('Sample does not look Gaussian (reject H0)') Anderson-Darling Test # Anderson-Darling Testfrom numpy.random import seedfrom numpy.random import randnfrom scipy.stats import anderson# seed the random number generatorseed(1)# generate univariate observationsdata = 5 * randn(100) + 50# normality testresult = anderson(data)print('Statistic: %.3f' % result.statistic)p = 0for i in range(len(result.critical_values)): sl, cv = result.significance_level[i], result.critical_values[i] if result.statistic &lt; result.critical_values[i]: print('%.3f: %.3f, data looks normal (fail to reject H0)' % (sl, cv)) else: print('%.3f: %.3f, data does not look normal (reject H0)' % (sl, cv)) PS: 10 Normality Tests in Python (Step-By-Step Guide 2020) SD and SEM $$ σ = \\sqrt{ \\frac {\\sum_ N (X_ i - μ)^ 2} { N -1 } } $$ $$ sem = \\frac{σ}{\\sqrt{N}} $$ SD Describes the width of the parent population as estimated from the scatter in the sample measurements. (For example, when the width of the parent population reflects actual variation of the measured quantity more than in reflects experimental uncertainty) Does not decrease with more measurements Should be used when the width of the parent distribution is important to your audience. SEM Describes the uncertainty in the measured value of the mean Decreases with more measurements Should be used when the accuracy in the measured mean is more important to your audience that the width of the parent population. (For example, when most of the width of the parent population is due to experimental uncertainties) Always give the sample size so your reader can convert Rules for expressing means and uncertainties Express your data with the last significant digit equal to the precision of your measurement. Plot a histogram to see the distribution. Also test whether your data are distributed in a Gaussian manner. Present uncertainties as standard deviations if the width of the parent population is important or standard errors if the precision of the measured mean is important. Always define error (SD, SEM) and provide sample number so readers can convert. Keep in mind that experiments with small sample sizes are much more variable and have higher uncertainties. Lecture 3 The t-table The t distribution is a probability distribution that we can use to express confidence intervals of a mean. $$ t_ i = \\frac{\\overline{X_ i} - \\mu_ {parent}}{σ/\\sqrt{N}} $$ Interpretation: The deviation of sample mean and parent mean divided by SEM T Distributuin For analyze statistical data from small sample. When measure the small sample Normal distribution, you didn’t get the Gaussine distribution, you get t distribution. © tdistributiontable.com dt(x, df, ncp, log = FALSE)pt(q, df, ncp, lower.tail = TRUE, log.p = FALSE)qt(p, df, ncp, lower.tail = TRUE, log.p = FALSE)rt(n, df, ncp)# two tailed T to P:T = 2.085963N = 20pt(T, df=N-1, lower.tail=FALSE)*2# Two tailed P to T:X= 0.05N = 20qt(X/2, df=N-1, lower.tail=FALSE) How to use the T table In the t table, the index is the degrees of freedom, which is N - 1 (N is the sample size). For retrieve the rows of the T table: Rows = N -1!!! That’s means, when your sample size is 4, you should looking into row 3! T table related examples: dummies.com Confidence Interval (CI) = ±t × SEM The Confidence Interval (CI) is the range of possible means over which there is a specified probability of observing a similarly measured value. CI is another way of expressing the uncertainty in a mean. To calculate a confidence interval (CI): Choose what confidence level you want (95% is typical) p is the probability. Equals 1-confidence level. 95% mean p=0.05 Determine the t-value (t*) from a t-table using dF and p Calculate CI using the equation above When you express a CI, make sure the readers knows probability and N Example: You measured 8.72 ± 1.21 (SD, N=7) . What is the 99% CI? Calculate $SE = SD/\\sqrt7$ = 0.46 Determine t (for p=0.01 and dF=6) t= 3.71 (t-table) in r: X= 0.01; N = 7qt(X/2, df = N-1, lower.tail = F)[1] 3.707428 Calculate CI = t*SE = 3.17*0.48 = 1.78 One sided (one tailed) versus two-sided confidence intervals © Sunil Ray; 2015 Two tailed probabilities are almost always better than one-tailed probabilities because they are more conservative (less likely to lead you to mistakenly claim a positive correlation) and because they do not require any assumption about the sign of the deviation between the actual and measured value. For symmetrical distributions (Gaussian, t-distribution, etc) the two-tailed probability is twice the one-tailed probability. Divide probability in a t-table by 2 to convert two-tailed to one-tailed. Multiple probability by 2 to covert one-tailed to two-tailed. The p-value The null hypothesis (Ho) is a hypothetical value of the mean of the parent population. Typically it is the value you would expect to observe if the parameter or conditions of interest have no effect on your measured parameter. Statistical tests are used to support or disprove the null hypothesis. The p-value is the probability that you have obtained a difference between your results and the null hypothesis as large as you did observe strictly by chance. In other words, it is the probability of obtaining obtained your results if the null hypothesis was true. Confidence Intervals and p-values are connected α is the cutoff that we chose for statistical significance. The ends of the 1-α CI define the values of the null hypothesis that fall exactly at p=α. A CI defines the range of hypothetical values that have probabilities larger than α, and thus are not significant. Values outside the confidence interval have p-values smaller than α and thus are significant. $t = \\frac{|(H_0 - μ)|}{SE}$ $t = |(H_ 0 -μ)|\\sqrt{N}/ sd$ $sd = |(H_ 0 -μ)|\\sqrt{N}/t $ $sd = |(0 - )|$ Examples: Mesurement: 1.235, 2.1254, 3.8926, 1.0022, 0.9880, 2.9876, 1.4350 Your null hypothesis is that the enzyme expression is 1.0. Do your data disprove the Null hypothesis (H0)? A &lt;- c(1.235, 2.1254, 3.8926, 1.0022, 0.9880, 2.9876, 1.4350)# Step 1: Test the Gaussian?shapiro.test(A) # p = 0.1528# Step 2: Calculate mean, SD, SEmean(A); sd(A); sd(A)/sqrt(length(A))1.952257 1.116636 0.4220488# Step 3: Calculate a t-value for the difference between the measured mean and the null hypothesis.# t = |(H~0~ - μ)/SE| = (1 – 1.9923)/0.422 = 2.35# Step 4: Look up p-value in a table corresponding to t=2.35 and dF = 6.# Interpolating between values in the Table above, you get p = 0.062.# Instat gives p=0.065 for a hypothetical mean of 1.0T = abs((1-mean(A))/ (sd(A)/sqrt(length(A))))N = 7pt(T, df=N-1, lower.tail=FALSE)*2# p = 0.06487952# Or, One step with R:t.test(A, mu=1) # p = 0.06488 At a standard confidence level of 95% (minimum p-value of 5% or 0.05), your data DO NOT disprove the Null hypothesis. Your measurement is not significantly different from the null hypothesis. Assumptions before t-test: The parent population has a normal (Gaussian) distribution Your sample is a random sampling of the population Lecture 4: The p-value The p-value is the probability that you have obtained a difference between your results and the null hypothesis as large as you did observe strictly by chance. In other words, due to random sampling. The p-value is the probability of obtaining your results if the null hypothesis was true. The One Sample t-test The simplest (and most useful) statistical test is the one-sample t-test which compares a mean from set of measurements to a hypothetical value (the null hypothesis). The one sample t-test calculates a probability (p-value) that the null hypothesis is true, and that you measured a value as far away from it as yours simply by chance. Example data: 7,11,3,5,12,3,0,8 μ = 6.25; σ = 4.0; N = 8; 95% CI = 2.9 to 9.6 Null Hypothesis is that the value = 0 Our statistical test: Two tailed p-value = 0.0029 (very significant). If the parent mean is 0, there is a 0.29% chance of measuring a mean of 6.25 ± 4.0 (SD, N=8). The sample you measured probably does not have a parent mean of 0. The null hypothesis is disproved. Now assume that the Null Hypothesis be that the value = 3 Our statistical test: Two tailed p-value = 0.053 (Not significant at the 95% level) If the parent mean is 3, there is a 5.3% chance of measuring a mean of 6.25 ± 4.0 by chance. You have no reason to conclude that the parent mean is not 3. The null hypothesis is NOT disproved. Exp in R: Ps, I tried running the codes but keep get a sliter different result. The main reason is the mean and sd not match the example data. So, I dicided to change the 0 to 1. R codes for one sample T test Null Hypothesis is that the value = 0 A &lt;- c(7,11,3,5,12,3,1,8)t.test(A) One Sample t-test data: A t = 4.4696, df = 7, p-value = 0.002902 alternative hypothesis: true mean is not equal to 0 95 percent confidence interval: 2.943449 9.556551 sample estimates: mean of x 6.25 Null Hypothesis is that the value = 3 t.test(A, mu=3) One Sample t-test data: A t = 2.3242, df = 7, p-value = 0.05307 alternative hypothesis: true mean is not equal to 3 95 percent confidence interval: 2.943449 9.556551 sample estimates: mean of x 6.25 Null Hypothesis is that the value = 6 t.test(A, mu = 6) One Sample t-test data: A t = 0.17878, df = 7, p-value = 0.8632 alternative hypothesis: true mean is not equal to 6 95 percent confidence interval: 2.943449 9.556551 sample estimates: mean of x 6.25 Two sample t-test: unpaired A unpaired experiment is one in which there are no connections between the individual samples measured in the experiments. A “before and after” experiment is unpaired if the identity of the individual samples is not maintained or if both sets of measurements are independent samplings of a parent population. Example datas and result in R A &lt;- c(34, 33, 34, 46, 36, 37, 37, 32, 33, 33)B &lt;- c(50, 52, 64, 50, 46, 62, 54, 52, 54, 68)t.test(A, B) Welch Two Sample t-test data: A and B t = -7.6291, df = 14.418, p-value = 1.971e-06 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: -25.22324 -14.17676 sample estimates: mean of x mean of y 35.5 55.2 As we can see, the null hypothesis is accepted. The difference is dromatic. According to the result above, μA = 35.5, μB = 55.2. In R, we can also using this test to test that the B is larget than A: Codes P value t.test(A,B, mu= 0, alternative = &quot;greater&quot;) 1 t.test(A,B, mu= -10, alternative = &quot;greater&quot;) 0.999 t.test(A,B, mu= -20, alternative = &quot;greater&quot;) 0.4546 t.test(A,B, mu= -21, alternative = &quot;greater&quot;) 0.3111 t.test(A,B, mu= -23, alternative = &quot;greater&quot;) 0.1107 t.test(A,B, mu= -24, alternative = &quot;greater&quot;) 0.05872 t.test(A,B, mu= -25, alternative = &quot;greater&quot;) 0.02937 According to the result above, we can “safly” say that B is greater A than 24. Two sample t-test: paired A paired experiment is one in which there are multiple measurements of the same sample/subject or on matched (unique) samples/subjects. This can be a “before and after” experiment, or an experiments on manually selected matched samples (experiment and control). Paired sample experiments are more sensitive that unpaired experiments. Paired experiments DO NOT require that the samples be Gaussian as long as the differences (pairwise) are Gaussian. We still using the data A, B above t.test(A, B, paired = T) Paired t-test data: A and B t = -6.9072, df = 9, p-value = 7.01e-05 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: -26.15189 -13.24811 sample estimates: mean of the differences -19.7 Compare the results from one sample t test: t.test(A-B) One Sample t-test data: A - B t = -6.9072, df = 9, p-value = 7.01e-05 alternative hypothesis: true mean is not equal to 0 95 percent confidence interval: -26.15189 -13.24811 sample estimates: mean of x -19.7 We can find that: The Paired T test is actually running one sample t test with the difference of paired lists T test from statistic results function tsum.test from BSDA: tsum.test( mean.x, s.x = NULL, n.x = NULL, mean.y = NULL, s.y = NULL, n.y = NULL, alternative = \"two.sided\", mu = 0, var.equal = FALSE, conf.level = 0.95 ) Instead of give two lists, we given the Mean, Sd, and N (sample size) to do the t-test. (Ps, meam.x; s.x; n.x is for the first sample, mean.y; s.y; n.y are for the second sample) Codes for R A B Mean 0.03 0.02 Sd 0.05 0.001 N 18 3 library(BSDA)# one sample t-testtsum.test( 0.03, 0.05, 18)# two sample t-test for A and Btsum.test( 0.03, 0.05, 18, 0.02, 0.001, 3) Non-parametric tests for calculating confidence intervals and p-values A non-parametric test is one that does not depend on the assumption that the data have a particular distribution. This makes a non-parametric test weaker than a t-test, because the information contained in the shape of the distribution is not used in a non- Parametric test. But, if the data are strongly non-Gaussian and you can not transform The data to make it Gaussian, then you may not have a choice. one sample versus a null hypothesis Sign Test A sign test is used to decide whether a binomial distribution has the equal chance of success and failure. For number of successes = 5, number of trials = 18, : binom.test(5, 18) [1] Mann Whitney test. Two data samples are independent if they come from distinct populations and the samples do not affect each other. Using the Mann-Whitney-Wilcoxon Test, we can decide whether the population distributions are identical without assuming them to follow the normal distribution. wilcox.test(mpg ~ am, data=mtcars)[2] Pythonfrom scipy.stats import mannwhitneyumales = [19, 22, 16, 29, 24]females = [20, 11, 17, 12]U1, p = mannwhitneyu(males, females)print(p) 0.055673443266570206 For unpaired data: Randomization test (See the codes below) It is a test used to analyze the distribution of a set of data to see if it can be described as random (patternless)(wikipedia) Mann Whitney test (See the codes above) For paired data: Wilcoxon (signed rank) test The Wilcoxon signed-rank test tests the null hypothesis that two related paired samples come from the same distribution. In particular, it tests whether the distribution of the differences x - y is symmetric about zero. It is a non-parametric version of the paired T-test.from scipy.stats import wilcoxond = [6, 8, 14, 16, 23, 24, 28, 29, 41, -48, 49, 56, 60, -67, 75]w, p = wilcoxon(d)w, p (24.0, 0.041259765625) There are MANY non-parametric tests. These above use nothing more than the actual data collected. The data are scrambled between columns randomly and all the possible outcomes are generated. The p-value is calculated from the probability of an outcome as large or larger than the one observed. The randomization test uses the actual values. Mann Whitney and Wilcoxon use only the rank of each value (highest, lowest etc) and thus are not sensitive to extreme values. Randomization test[3] # assumes the two samples are in 'x' and 'y' and x[i] and y[i] are paired# set up:B &lt;- 99999d &lt;- x-ym0 &lt;- mean(d)# perform a one-sample randomization test on d# for the null hypothesis H0: mu_d = 0 vs H1 mu_d != 0 (i.e. two tailed)# here the test statistic is the meanrndmdist &lt;- replicate(B,mean((rbinom(length(d),1,.5)*2-1)*d))# two tailed p-value:sum( abs(rndmdist) &gt;= abs(m0))/length(rndmdist) T test in python from scipy import statsstats.ttest_ind(set1, set2) Lecture 5 Independence and rejection of data Application of Chauvenet’s Criterion PS: you shold really try with the online calculater from mathcracker! According to this website, we need two parameter to find the outliers. One is Dmax, the second is Z-score. $Pr(Z&gt;D_ {max}) = \\frac{1}{4n}$ which in r is: qnorm(1/4/N), N is the sample size. So, we can easily define a function like this: chauvenet_test &lt;- function(A){ Dmax = abs(qnorm(1/4/length(A))) Outer = A[abs(scale(A))&gt;= abs(Dmax)] Z_out = abs(scale(A))[abs(scale(A))&gt;= abs(Dmax)] P_val = 1- pnorm(abs(scale(A)), lower.tail = T) print(paste(&quot;Dmax:&quot;, Dmax)) print(paste(&quot;Outliners:&quot;,Outer)) print(paste(&quot;Zscore:&quot;, Z_out)) print(paste(&quot;P value:&quot;, P_val)) return(Outer)} We measure 17, 23, 41, 19, 29, 34, 99 in a new type of experiment. You are suspicious of the measurement of 99. You want to know if you can reject any points. 37.43 ± 28.44(SD, N=7) 99 is 2.17 standard deviations from the mean (Z-scores) The p-value is 0.0152, and 0.0152×7=0.1064 As we calculated below, μ = 37.43, σ = 28.44, Z = 2.17. The probability of Z according from the Z table is 0.015, which means if the cut threshold is 0.05 or 0.03, 99 should be rejected. When the cut threshold is 0.01, then, 99 should be accepted. On the other hand, the P value of 17 is 0.76, which is acceptable. A &lt;- c(17, 23, 41, 19, 29, 34, 99)Dmax = abs(qnorm(1/4/length(A)))TB = data.frame(Raw= A)TB$Mean &lt;- mean(A)TB$SD &lt;- sd(A)TB$Z_score = scale(A)TB$P_value &lt;- 1- pnorm(q= scale(A), lower.tail=TRUE)print(TB$Raw[abs(TB$Z_score)&gt;=Dmax]) RawMeanSDZ_scoreP_value 1737.4285728.43623-0.71839950.76374450 2337.4285728.43623-0.50740100.69406327 4137.4285728.43623 0.12559430.45002653 1937.4285728.43623-0.64806670.74152909 2937.4285728.43623-0.29640260.61653867 3437.4285728.43623-0.12057050.54798440 9937.4285728.43623 2.16524600.01518443 Another Example when the triple experiments of the result is 1, 1, 1000000, then similarly, we can have the table below. It might out of your expectation, but the value 1000000 is actually acceptable. RawMeanSDZ_scoreP_value 1333334577349.7-0.57735030.7181486 1333334577349.7-0.57735030.7181486 1e+06333334577349.7 1.15470050.1241065 Lecture 6: Propagation of errors Weighted averages $$ \\mu_ {weighted} = \\frac{\\sum(\\frac{\\mu_ i}{\\sigma_ i^2})}{\\sum(\\frac{1}{\\sigma_ i^2})} $$ $$ \\sigma_ {weighted} = \\sqrt{ \\frac{1}{\\sum(\\frac{1}{\\sigma_ i^2})} } $$ TB = data.frame(Mean = c(121, 110, 131), Sd = c(21, 9, 19), N = c(9, 13, 11))Wei_Mean &lt;- function(TB){ W_mean_t1 = 0 W_mean_t2 = 0 W_sd = 0 for(i in c(1: nrow(TB))){ Mean = TB[i,1] Sd = TB[i,2] W_mean_t1 = W_mean_t1 + Mean/(Sd^2) W_mean_t2 = W_mean_t2 + 1/(Sd^2) W_sd = 1/(Sd^2) } WM = W_mean_t1/W_mean_t2 WS = sqrt(1/W_mean_t2) DF = sum(TB[3]) - nrow(TB) SE = WS/sqrt(sum(TB[3])) print(paste(&quot;Weighted Mean:&quot;, WM)) print(paste(&quot;Weighted Sd:&quot;, WS)) print(paste(&quot;df:&quot;, DF)) print(paste(&quot;SE:&quot;, SE))} [1] \"Weighted Mean: 122.067278328693\" [1] \"Weighted Sd: 7.79700223506481\" [1] \"df: 30\" [1] \"SE: 4.50160133928678\" Propagation of Errors If the calculated number x is a function of measured parameters u and V then the uncertainty in x is given by $σ^2_x = σ^2_u(\\frac{\\partial x}{\\partial u})^2 + σ^2_v(\\frac{\\partial x}{\\partial u})^2 + 2σ^2_{uV} (\\frac{\\partial x}{\\partial u}) (\\frac{\\partial x}{\\partial V})$ $\\frac{\\partial x}{\\partial u}$is the derivative of x with respect to u. In other words, dx/du is a measure of how much x changes when u changes. This equation can be applied to any equation in which x is a function of U and v. The last term in the equation above is the covariance which becomes significant only if the uncertainties in the parameters are correlated. Most of the time, the covariance can be ignored. Covariance; youtube $$ σ^2_{uV} = \\frac{\\sum(u_i - u_{mean})(V_ i - V_ {mean})}{N} $$ For uncorrelated (random) samples the covariance is zero. Propagation of Errors; GlacierFilm, LLC. 2013 Exp: 13.2m/s ± 0.2m/s measured velocity: v=13.2 m/s absolute uncertainty in v: $δv= ± 0.2m/s$ relative uncertainty in v: $\\frac{δv}{v}$ Powers $x = αμ^n $ $σ_ x = nx\\frac{σ_ μ}{μ}$ Logarithm $x = α log(μ)$ $σ_ x = α\\frac{σ_ μ}{μ}$ Propagation of Errors: Calcumation X: is the new number obtained by doing math on measurement (s) U and V: are the measured parameters (with uncertainties) Addition and Subtraction $x=u±V$ $σ_ x = \\sqrt{σ_ u ^2 + σ_ V ^2 ± 2σ_ {uV} ^2}$ Ignoring covariance: $σ_ x = \\sqrt{σ_ u ^2 + σ_ V ^2}$ Multiplication: $x = uV$ $\\frac{σ_ x}{x} = \\sqrt{ \\frac{σ_ u}{u}^ 2+ \\frac{σ_ V}{V}^ 2 }$ Division: $x = \\frac{u}{V}$ $\\frac{σ_ x}{x} = \\sqrt{ \\frac{σ_ u}{u}^ 2+ \\frac{σ_ V}{V}^ 2 }$ Degrees of freedom and calculation of standard errors for a propagated error. Propagation of errors is always done using standard deviations. If N is the same for each of the experiments in your propagated result, then dF for the propagated value is N-1. If your two variables have different N, use the dF for the smallest N. EXP: u= 20.34 ± 0.51 (SD, N=10, dF = 9) V = 17.81 ± 1.45 (SD, N=10, dF = 9) When you propagate errors you have $x = u × V = 20.34 × 17.81 = 362.26$ $σ_ x = x\\sqrt{ \\frac{σ_ u}{u}^ 2+ \\frac{σ_ V}{V}^ 2 }$ $σ_ x = 362.26 × \\sqrt{ \\frac{0.51}{20.34}^ 2+ \\frac{1.45}{17.81}^ 2 }$ $σ_ x= 30.86$ u×V = 362.26 ± 30.86 (SD, N=10, dF = 9) SE = SD/N = 9.7589 = 9.8 (proper sig figs) With proper sig figs the result is 362.3 ± 9.8 (SE, dF = 9) For the purpose of calculating confidence intervals, p-values etc the result can now be treated as a Mean ± SE with dF =9. Code in R: library(propagate)x &lt;- c(20.34, 0.51)y &lt;- c(17.81, 1.45 )EXPR1 &lt;- expression(x*y)DF1 &lt;- cbind(x,y)propagate(expr = EXPR1, data = DF1) Results from uncertainty propagation: Mean.1 Mean.2 sd.1 sd.2 2.5% 97.5% 362.25540 362.25540 30.86000 30.86886 301.75348 422.75732 Results from Monte Carlo simulation: Mean sd Median MAD 2.5% 97.5% 362.28108 30.89162 362.04746 30.85789 302.25524 423.44032 Sign Test; R Tutorial ↩︎ Mann-Whitney-Wilcoxon Test; R Tutorial ↩︎ Glen_b; 2013 ↩︎","link":"/2022/01/24/LearnNotes/tulane-biostat-1/"},{"title":"BioStatistics with R&#x2F;Python: Block 2","text":"Biomedical Statistics and Data Analysis: Block 2 pre { background-color:#38393d; color: #5fd381; } L8: Counted Variables and Their Asymmetric Distributions What is Sample count? Count Variable For an event to be counted it has to occur AND it has to be observed. Counted variables are treated differently than measured variables because their distributions are asymmetric (not Gaussian). (use binomial statistics) To be able to apply the statistical treatments that we will use, the counted events must follow the following rules: Each event has a probability of occurring or a random probability of being observed (or both). Occurrence or observation (or both) is a random event. The probability of occurrence/observation is independent of whether other occurrences/observations have been made. If both the occurrence of an event and its observation are non random or known with certainty then the statistical principles related to counted variables do not apply. Examples Examples of counted variables where the occurrence is random but the observation is certain: Proportion of planes that crash Number of cars that drive past a certain intersection Number of patients that die when treated with a drug Examples of counted variables where the occurrence is certain but the observation is random: Number of turtles counted in a lake Radioisotope concentration Examples of counted variables where both occurrence and observation is random: Number of people with the flu Number of cells that are transfected Examples of counted variables where neither the occurrence nor the observation is random: The number of turtles in a bathtub The number of toes on your left foot The number of presidents with wives named “Barbara” Question: Are you categorizing or just counting events (or categorizing)? If you are categorizing events (yes/no, live/dead, success/failure, democrat/republican) use binomial statistics. INSTAT does not deal with single proportions very well. OS4 and SSP will use do calculations for proportions. SSP uses the word “probability” to denote proportions. If you are counting events Car crashes, weddings in July, deaths from lung cancer, radioactive counts) use Poisson statistics. Binomial DIstribution $$ P_ {x:n} = \\frac{n!}{x!(n-x)!} p^x (1-p)^{n-x} $$ $\\frac{n!}{x!(n-x)!}$: Of combinations (how many different ways are there of doing an experiment) $p^x$: Probability of x Successes in one experiment. $(1-p)^{n-x}$: Probability of n-x failures in one experiment (n trials). # Do it yourselfBi_cal &lt;- function(x, n, p){ R = ncol(combn(n,x)) * (p^x) * ((1-p)^(n-x)) return (R)}# From R default functionsdbinom(4, size=12, prob=0.2) Exp: Probability of getting 2 heads when flipping 3 coins = 3 x 0.25 x 0.5 = 0.375 in r: dbinom(2, size=3, prob=0.5) Codes for the Graphic library(ggplot2)library(reshape2)x= c(1:32)Pro = data.frame(x=x, H1 = dbinom(1, size=x, prob=0.5), H2 = dbinom(2, size=x, prob=0.5), H4 = dbinom(4, size=x, prob=0.5), H8 = dbinom(8, size=x, prob=0.5), H16 = dbinom(16, size=x, prob=0.5), H32 = dbinom(32, size=x, prob=0.5))Pro_TB = melt(Pro, id.vars = 'x')ggplot(Pro_TB, aes(x= x, y =value, group = variable, color=variable)) + geom_line(size= 2)+ theme_minimal()+ scale_color_brewer(palette = &quot;Set2&quot;) The H1 means the chase for get 1 head in times of rolled at x. So as the H2, 4, 8, 16, and 32 The binomial distribution is used to describe small numbers of discreet events, or proportions of small numbers. Becomes a Gaussian distribution as n gets large. Mean and standard deviation of the parent distribution can be calculated. $μ= np$ μ is the mean number of “successes”, n is the number of trials p is the probability of success in each trial $σ_ μ = \\sqrt{np(1-p)}$ The standard deviation in μ (# successes) If p is not known it must be estimated from the data. p is successes divided by total i.e. (μ/n) Data that would use a Binomial Distribution Example: You know that normally 1 person in 8 has a negative reaction to a particular drug. 1. How many negative reactions would you expect to have in a sample of 21 people? In this questions, we can know that the p = 1/8 So, we can have $\\mu = np= 21\\times (1/8) = 2.63$ We supposed have 2.63 people is negative And then: $\\sigma = \\sqrt{np(1-p)}= \\sqrt{21 × (1/8)(7/8)} = 1.52$ The SD is 1.52 2. What is the probability of observing zero negative reactions in 21 patients? dbinom(0, 21, 1/8) [1] 0.06055766 Example: You conducted a random phone poll of 900 people and found that 45% favored candidate A and 55% favored candidate B. What is the uncertainty of the result (What is the standard deviation?). This question is actually calling for the relative uncertainty. which is μ/σ $µ=np=900×.45= 405$ $\\sigma = \\sqrt{np(1-p)}=\\sqrt{900×0.45(1-0.45)}=14.92481$ Relative uncertainty = μ/σ = 3.7% The Poisson Distribution When p « 1 or when n » x the binomial distribution simplifies to the Poisson distribution. The Poisson distribution also applies when you are counting discreet events (presumably from a very large population of possible observations) but not categorizing them as successes/failures or left/right or alive/dead or sick/not sick. $$ p = \\frac{\\mu^ x}{x!}e^{-\\mu} $$ $\\mu=np=x$ $\\sigma = \\sqrt{np(1-p)}$; When the p « 1, we then have: $σ = \\sqrt{np}= \\sqrt{x}$ The standard deviation of a counted variable is the square root of the # of counts. Ex: Political polls, radioactive counts, cell counts etc Special case: If the probability of seeing an event is 1/n and you try n times, the probability of seeing the event once is only 37%. This is exactly the same as the probability of not seeing the event at all. There is a 63% chance is seeing it at least once. Binomial versus Poisson Statistics: Which do we use? Finally: The binomial equation is used when counting ratios or proportions of small numbers ( i.e. n/m where n&lt; 100, n&lt;m and m&lt;100). If we were counting the number cars that drive up to an intersection, that would be described with a Poisson distribution. While counting the number that turn left relative to the total would normally be described with a binomial distribution. The binomial equation is used when categorizing. In other words, when your data are ratios or proportions of counted variables. The Poisson equation is used when counting only and not categorizing. When the numerator of a ratio is very large, the binomial and Poission descriptions become equivalent. Examples: If we were counting the number cars that pass a certain intersection, that would be described with a Poisson distribution, because it is a simple count. If we are counting the number of cars that hat turn left and the number that turn right, that would be described with a binomial distribution because it is a categorization. Assume you are doing yeast genetic studies and are counting the number of transformed colonies. If the transformation is frequent, you can plate a small number of colonies (&lt;1000), count transformed and normal colonies, and analyze the statistics using proportions (binomial). If the transformation is rare, you can plate thousands of colonies, count only the transformed colonies and analkyze the statistics using simple counts (Poisson). L9: Confidence intervals for proportions and counts How to determine statistical significance of one proportion versus a null hypothesis: Determine the upper and lower bounds of the confidence interval. Use 1-α for probability. 95% CI for α=0.05. Compare H0 to the CI. If Ho is inside the CI, the difference is not significant. If H0 is outside the CI, the difference IS significant. How to calculate the 95% confidence Intervals. R codes: Wayne W. LaMorte, MD, PhD, MPH prop.test(10,20,p=.5) 1-sample proportions test without continuity correction data: 10 out of 20, null probability 0.5 X-squared = 0, df = 1, p-value = 1 alternative hypothesis: true p is not equal to 0.5 95 percent confidence interval: 0.299298 0.700702 sample estimates: p 0.5 library(Hmisc)#calculate 95% confidence intervalbinconf(x=10, n=20, alpha=.05) PointEst Lower Upper 0.5 0.299298 0.700702 Results from Exact Binomial and Poisson Confidence Intervals : Special case for a proportion: How do you determine p-value when the Null hypothesis is 0 or 1? There is a problem we have to solve: The exact two-sided CI (by definition) can never include a proportion of 0 or 1 (because we are forcing it to have equal area on each side). Yet, in some cases the probability of observing a proportion of exactly zero 0 or 1 will be greater than 0.025 (half of the 95% CI) and thus should not be considered significant. How do we decide if a null hypothesis proportion of 0 or 1 is really statistically different from a experimentally derived proportion? There are two approaches. Exact Solution: Go to a binomial probability calculator and calculate the probability for x=0 (or x=n) for your proportion. If p&gt;0.025 then the limit (proportion = 0 or 1) should be considered WITHIN the CI and not significantly different. Approximate solution (works well for trials &gt; 10): Determine the 2 sided CI of your proportion. If the 1/n is within the CI, then a proportion of 0 is NOT statistically significant. If (x-1)/x is within the CI then a proportion of 1 is NOT statistically significant. HINT: For any experiment with at least 12 trials, if the successes = 3 or less, it will not be statistically different from a proportion of zero. Similarly, if the number of trials is 12 or more and trials-successes = 3 or less, it will never be significantly different from a proportion of 1. Example: You measured a proportion of 3/15. Is there a statistically significant difference from a Null hypothesis proportion = 0? Using the statpages site or table above the CI of the proportion 3/15 is 0.043 – 0.481. Exact method: Using a binomial calculator (above) with N=15 and prop = 0.2 (3/15), the probability of x=0 is 0.0352. Since this is larger than the one-tailed probability of 0.025 (for =0.05) it is NOT significant. Approximate Method: The value 1/n or 1/15 is 0.067. Since this value falls within the CI 0.043-0.481, a proportion of 0 is NOT significantly different from your measured 3/15. So, after interpretation from above, we now know that we’d like to know the difference between 3/15 and 0/15. So, the code in R could be: prop.test(0,15, p = 3/15) 1-sample proportions test with continuity correction data: 0 out of 15, null probability 3/15 X-squared = 2.6042, df = 1, p-value = 0.1066 alternative hypothesis: true p is not equal to 0.2 95 percent confidence interval: 0.0000000 0.2534679 sample estimates: p 0 p-value = 0.1066, which means is not significantly different. The null hypothesis is accepted and 3/15 has no difference from 0/15. Confidence Interval of a Poisson distributed (counted) value How do you determine statistical significance for the null hypothesis that a proportion equals a certain value? A 95% CI is equal to p- value of 0.05. Calculate a CI for the proportion using one of the methods we just discussed. If CI includes the null hypothesis, then p is larger than your cutoff (thus not significant). If the CI does not include the null hypothesis p is smaller and is significant. Example: Suppose you observed 5 mice out of 30 transgenic mouse offspring were male. You wanted to know if there was a gender specific mortality effect. Your null hypothesis is 0.5 (half male, half female). Observed Ratio = 0.17 95% CI = 0.056-0.347 (From Table) Since the 95% CI does not include Null hypothesis, p is smaller than 0.05 and is significant. In r, We know that the observe is 5, sample size is 30, and expectation is 0.5. So, we can have: prop.test(5,30,.5) 1-sample proportions test with continuity correction data: 5 out of 30, null probability 0.5 X-squared = 12.033, df = 1, p-value = 0.0005226 alternative hypothesis: true p is not equal to 0.5 95 percent confidence interval: 0.06303555 0.35451084 sample estimates: p 0.1666667 We can see that the p = 0.0005226, which means the result is significant. Example: Poisson Confidence Intervals A newspaper headline proclaims that the roads in Southern Louisiana have become less safe in 2004 because the 138 fatal accidents that year was 11% higher than the long term average number of 124 per year. Use statistics to analyze this conclusion. Are the roads more dangerous? Since 124 is a long term average we use it in this simple example as a null hypothesis without uncertainty. In r, we just need use: poisson.test(138) Exact Poisson test data: 138 time base: 1 number of events = 138, time base = 1, p-value < 2.2e-16 alternative hypothesis: true event rate is not equal to 1 95 percent confidence interval: 115.9369 163.0397 sample estimates: event rate 138 We can see that the confidence interval is from 115.9369 to 163.0397. And 115.9369 &lt; 124 &lt; 163.0397. So, the result is not significant difference. More examples for understanding Example 1: If your data are the proportion of dead cells on a plate and you measured in each of four fields: 31/120; 18/56; 40/103; 44/121 You recalculate your total proportion as (31+18+40+44) / (120+56+103+121) or 133/400. We use 1-sample proportions: prop.test(133, 400) the CI: 0.2869229 0.3813495 the proportion of 4 experiments are: 0.2583333, 0.3214286, 0.3883495, 0.3636364. The first experiment is significantly different from others. Example 2: Your Geiger counter reports counts in 1 minute intervals: 12,15,8,17,12,11,9 and 13 Your confidence interval is based on total counts = 97 (12.1 cpm) poisson.test(97) tell us that the CI is: 78.66047 118.33177, which means it’s 9.832558 14.791472 per minute. We can find that the 8 and 9 is the outlier. L10: Contingency Tables It is used in statistics to summarize the relationship between several categorical variables. A contingency table is a special type of frequency distribution table, where two variables are shown simultaneously. Instruction in Excel Clinical studies sometimes use a binary (yes/no) decision to assess disease or outcome. So clinical studies are often analyzed as a proportion of a counted variable. There are four main types of clinical studies: Retrospective (case-control): Start with outcome (e.g. disease) and look back to see the cause with cases (disease) and controls (no disease). Prospective: Start with exposure and follow cases to see if disease develops. Also uses cases (exposed or hypothetical risk factor) and controls (not exposed, or no hypothetical risk factor). Cross-sectional: Start with a set of randomly selected subjects that are NOT selected based disease or exposure. Divide into two groups and assess the correlation between disease and hypothetical risk factor. Experimental: Randomly selected subjects, Split into two groups, subject one groups to a treatment, the other to a control treatment such as a placebo. Find the correlated with the diseases. Exp1: How you compare multiple proportions with one another? Imagine a small scale experimental cancer drug trial. You recruit 40 patients with end-stage cancer. 20 get drug and 8 of them survive 5 years. Another 20 get placebo and 2 of them survive 5 years. contingency table Survival Not Survival Treated 8 12 Not Treated 2 18 Codes for R: December 19, 2020 by George Pipis in R bloggers TB2 &lt;- data.frame( Survival = c(8, 2), Dead=c(12, 18), row.names = c(&quot;Treated&quot;, &quot;Placebo&quot;))prop.table(TB2)chisq.test(TB2)fisher.test(TB2) Survival Dead Treated 0.20 0.30 Placebo 0.05 0.45 Pearson's Chi-squared test with Yates' continuity correction data: TB2 X-squared = 3.3333, df = 1, p-value = 0.06789 Fisher's Exact Test for Count Data data: TB2 p-value = 0.06483 alternative hypothesis: true odds ratio is not equal to 1 95 percent confidence interval: 0.9222194 64.6794654 sample estimates: odds ratio 5.735024 We can see that P value from both Chi-squared test and Fisher’s Exact test are larger than 0.05, which means the null hypothesis is accepted and they have no significant difference. Exp 2: An example of a clinical trial with a single outcome Suppose you are performing an experimental study to determine if AZT improves the outcome of HIV-infected patients. All patients are infected with HIV, some are treated with AZT some with placebo. You determine which patients develop clinical symptoms of AIDS and which do not. Disease developed in 28% of placebo-treated cases (129/461) and in 16% of AZT treated cases (76/475). AIDS No AIDS Total ATZ 76(TD) 399(TN) 475(Tx) Placebo 129(ND) 332(NN) 461(Nx) Total 205(xD) 731(xN) 936 TB &lt;- data.frame( AIDS = c(76, 399), N_AIDS=c(129, 332), row.names = c(&quot;AZT&quot;, &quot;Placebo&quot;))prop.table(TB)chisq.test(TB)fisher.test(TB) AIDS N_AIDS AZT 0.08119658 0.1378205 Placebo 0.42628205 0.3547009 Pearson's Chi-squared test with Yates' continuity correction data: TB X-squared = 18.944, df = 1, p-value = 1.346e-05 Fisher's Exact Test for Count Data data: TB p-value = 9.24e-06 alternative hypothesis: true odds ratio is not equal to 1 95 percent confidence interval: 0.3512693 0.6818650 sample estimates: odds ratio 0.4905877 P value is signifcant and so, the H0 hypothesis is rejected and the drug works. Explained: If you want to measure the confidence interval for the difference between the proportions. You can do it with a Gaussian approximation if none of the entries are smaller than 5 and none of the same-row values are within 5 of each other. (In other words, if neither proportion is close to zero or close to 1.0). $$ CI = (p_ 1 - p_ 2) ± z × \\sqrt{\\frac{p_ 1 (1-p_ 1)}{n_ 1} + \\frac{p_ 2 (1-p_ 2)}{n_ 2}} $$ Other ways of expressing proportional results: Relative risk(RR) $$ RR = \\frac{p_ 1}{p_ 2} $$ Relative risk is sometimes called relative rate or relative probability, especially in non-clinical studies. Pay attention to which outcome is in the numerator (on top). In the AZT study, the relative risk is 0.57. AZT patients were 57% as likely as placebo patients to have disease progression. If we switched places of the two treatments (which would be perfectly valid) we would be saying that placebo patients were 1.75 time as likely to have disease progression. Number Needed to Treat $$ NNT = \\frac{1}{(p_ 2 - p_ 1)} $$ Odds ratio (OR) $$ OR = (\\frac{Odds_ 1}{Odds_ 2}= \\frac{TD/TN}{ND/NN}) $$ Exp 3 Cat scratch fever is a mild disease that is transmitted by cats. A case-control study assessed whether there is an connection between fleas and the disease in humans. (That is fleas on the cats and disease in the humans). Disease No Disease Total Fleas 32(TD) 4(TN) 36(Tx) No Fleas 24(ND) 52(NN) 76(Nx) Total 56(xD) 56(xN) 112 TB &lt;- data.frame( Disease = c(32, 4), N_Disease=c(24, 52), row.names = c(&quot;Fleas&quot;, &quot;N_Fleas&quot;))prop.table(TB)chisq.test(TB)fisher.test(TB) Disease N_Disease Fleas 0.28571429 0.2142857 N_Fleas 0.03571429 0.4642857 Pearson's Chi-squared test with Yates' continuity correction data: TB X-squared = 29.842, df = 1, p-value = 4.687e-08 Fisher's Exact Test for Count Data data: TB p-value = 1.201e-08 alternative hypothesis: true odds ratio is not equal to 1 95 percent confidence interval: 5.171911 72.958931 sample estimates: odds ratio 16.84407 According to Fisher’s Extrac test, the CI is 5.171911 to 72.958931, which means that cat owners with fleas (cat owners whose cats have fleas) are between 5 and 73 times more likely to get cat scratch fever as cat owners whose cats do not have fleas. Contingency table in R Exp1: Łukasz Deryło, 2018 # Practice 1library(MASS)#check the observes by yourselves#Cars93$Typetable(Cars93$Type)prop.table(table(Cars93$Type))# Practice 2table(Cars93$Origin)prop.table(table(Cars93$Origin))# How to make a contingency tabletable(Cars93$Type, Cars93$Origin) Practice 1: Compact Large Midsize Small Sporty Van 16 11 22 21 14 9 Compact Large Midsize Small Sporty Van 0.17204301 0.11827957 0.23655914 0.22580645 0.15053763 0.09677419 Practice 2: USA non-USA 48 45 USA non-USA 0.516129 0.483871 How to make a contingency table USA non-USA Compact 7 9 Large 11 0 Midsize 10 12 Small 7 14 Sporty 8 6 Van 5 4 After probability Fisher’s exact test fisher.test(Cars93$Type, Cars93$Origin) Fisher's Exact Test for Count Data # data: Cars93$Type and Cars93$Origin p-value = 0.007248 alternative hypothesis: two.sided G-test library(DescTools)GTest(Cars93$Type, Cars93$Origin) Log likelihood ratio (G-test) test of independence without correction # data: Cars93$Type and Cars93$Origin G = 18.362, X-squared df = 5, p-value = 0.002526 Yates’ correction chisq.test(table(Cars93$Man.trans.avail, Cars93$Origin)) Pearson's Chi-squared test with Yates' continuity correction # data: table(Cars93$Man.trans.avail, Cars93$Origin) X-squared = 15.397, df = 1, p-value = 8.712e-05 3 (or more) dimensional table table(Cars93$Man.trans.avail, Cars93$Origin, Cars93$Type) L12: Survival Curve Targets for Survival Curve Plot Kaplan-Meier Curve P-value: Log-rank (Mantel-Cox) test and Gehan-Breslow-Wilcoxon test (which has more weight to early events) Hazard Ratio: Mental-Haenszel and logrank Kaplan-Meier Curve Plots percent survival of each cohort relative to non-censored totals. A tic mark indicates a censoring event. © Ruben Van Paemel; 2019 Online Calculator: evanmiller.org R in action Quick start with survival package More detailed examples and codes: bioconnector The most informative and detailed posts: Emily C. Zabor Practive Data: library(survival)?lung inst: Institution code time: Survival time in days status: censoring status 1=censored, 2=dead age: Age in years sex: Male=1 Female=2 ph.ecog: ECOG performance score as rated by the physician. 0=asymptomatic, 1= symptomatic but completely ambulatory, 2= in bed 50% of the day but not bedbound, 4 = bedbound ph.karno: Karnofsky performance score (bad=0-good=100) rated by physician pat.karno: Karnofsky performance score as rated by patient meal.cal: Calories consumed at meals wt.loss: Weight loss in last six months The data we need is in time, Survival time in days, and status, Censored or dead library(survival)library(survminer)sfit &lt;- survfit(Surv(time, status)~sex, data=lung)ggsurvplot(sfit, conf.int=TRUE, pval=TRUE, risk.table=TRUE, legend.labs=c(&quot;Male&quot;, &quot;Female&quot;), legend.title=&quot;Sex&quot;, palette=&quot;Set1&quot;, title=&quot;Kaplan-Meier Curve for Lung Cancer Survival&quot;, risk.table.height=.25)fit &lt;- coxph(Surv(time, status)~sex, data=lung)fit Call: coxph(formula = Surv(time, status) ~ sex, data = lung) coef exp(coef) se(coef) z p sex -0.5310 0.5880 0.1672 -3.176 0.00149 Likelihood ratio test=10.63 on 1 df, p=0.001111 n= 228, number of events= 165 L13: Power and Sample Size The function power.t.test from R has the same result from Java applets for power and sample size, which is different from some others. Example: You have measured 2.3±5.0 (SD, n=26) and determined that p=0.027 for Ho=0. What is the power of your experiment? Mean=2.3, H0= 0, as a result, delta = 2.3-0 =2.3. Because the null hypothesis is 0, we only need the lesser side. So, we should use one.sample t test. In R, we can have: power.t.test(n = 40, delta = 2.3, sd = 5, type=&quot;one.sample&quot;, alternative = &quot;two.sided&quot;) One-sample t test power calculation n = 40 delta = 2.3 sd = 5 sig.level = 0.05 power = 0.8097611 alternative = two.sided We can tell that the power is 0.81, which means you got 80.98% of chance to have the significant result. With the same data, if we’d like to improve the changes to 95%, than, we can have: power.t.test(power = .95, delta = 2.3, sd = 5, type=&quot;one.sample&quot;, alternativ = &quot;two.sided&quot;) One-sample t test power calculation n = 63.36733 delta = 2.3 sd = 5 sig.level = 0.05 power = 0.95 alternative = two.sided Now, we can know that we need at least 64 tests to get a significant result with the chance of 95% in success. Example 1: In a preliminary experiment you measure 12±4 (SD). You want to estimate sample size required to detect a difference of ±0.5 (Ho – mean) with a power of 90%. The confidence level you will use is 95% (α=0.05) Two-sample t test power calculation n = 1345.911 delta = 0.5 sd = 4 sig.level = 0.05 power = 0.9 alternative = two.sided Example 2: If around 10% of the population suffers from migraine headaches. How many people would you have to enroll in an experimental clinical study to determine if prophylactic daily aspirin use will reduce the number of people who have migraines to 8%. Your desired confidence level is 95% and the desired power is 50%. power.prop.test(p1=.1, p2 = .08, power = .5) Two-sample comparison of proportions power calculation n = 1573.077 p1 = 0.1 p2 = 0.08 sig.level = 0.05 power = 0.5 alternative = two.sided We know that with the power of 0.5, we need to at least have 1574 sample for each. So, for a test with control, we’d like to have at least 1574*2=3148 for the experiment.","link":"/2022/03/30/LearnNotes/tulane-biostat-2/"},{"title":"BioStatistics with R&#x2F;Python: Block 3","text":"Biomedical Statistics and Data Analysis: Block 3 pre { background-color:#38393d; color: #5fd381; } For more codes and example, please go to view this page Anova In python from bioinfokit.analys import stat# perform multiple pairwise comparison (Tukey's HSD)# unequal sample size data, tukey_hsd uses Tukey-Kramer testfor i in ['Nst_dist', 'length', 'B_angle', 'M_angle', 'Move', 'mm_s', 'Motion', 'Sing', 'Grooming', 'Chasing', 'Hold', ]: res = stat() res.tukey_hsd(df=Sample, res_var=i, xfac_var='Group', anova_model=i+' ~ C(Group)') print(i) print(res.tukey_summary) In R All detailed for codes including one-way, two-way, or repeated ANOVA test with examples and citation links could be see: Karobben, ANOVA in R, 2022 summary table example Reference: anova_summary: Create Nice Summary Tables of ANOVA Results library(rstatix)anova_summary() Lecture 16: Biomedical Statistics and Data Analysis Linear regression is a technique to find the best line that passes through an X-Y data set. The criteria for “best” linear fit is the line that gives the minimum sum of errors squared: $$ SSE = \\sum{(Y_ i - Pred_ i)^ 2} $$ Where Yi is the y-value of the Xi,Yi pair and Predi is the predicted value of the line at Xi. Linear Regression I In Linear Regression, you assume that there is a Independent variable (X) that you control, or select and a Dependent variable that you measures. They are related by the equation=mX +b where m is the slope of the line and b is the y-intercept at (X=0) You assume that all of the uncertainty (scatter) is in Y (not X). Types of Uncertainties: Equal uncertainties (assumed by most programs) Proportional uncertainties Counted uncertainties Individual uncertainties Uncertainties in Y and X Linear regression is based on a Chi-squared calculation that finds the “best fit” line which minimizes the sum of the squared differences between the observed and expected values of Y for each value of X. Because the expected differences depend on the uncertainties in Y, we must first define the uncertainties (or weighting factors) si for each Y There are several possibilities: Uncertainties in Y are all equal. This is the default assumption of most linear regression calculators,websites etc. Generally valid if each point is a single measurement using a technique that gives a constant absolute uncertainty. In this case, you can estimate s and use it as the weighting factor, or get it from the regression analysis. In the case of equal uncertainties, the important results of the linear regression analysis will not change if you enter the actual values. So you can ignore the actual uncertainties if they are equal. Uncertainties are a constant proportion of the Y-value. In this case multiply Y by the relative uncertainty to get uncertainty in Y. Y is a counted variable or a proportion of counted variables Count: $σ=\\sqrt{x}$ x = number of events Proportion: $σ=\\sqrt{np(1-p)}$ $n=total\\ event$ $p=\\frac{x}{n}$ Uncertainties in Y are unique for each value. Each Y may be an average with a mean and uncertainty of its own. Or different measurement methods may have been used for different sets of points. In this case use the appropriate uncertainty for each point. If your uncertainties are not constant, you must use curve fitting (non-linear regression) to fit an equation for a line to your data. When using curve-fitting you can weight each point by its SD. Linear Regression Function $$ Y = mX +b $$ $slop=\\frac{\\sum{\\frac{x_ i^ 2}{σ_ i^ 2}} \\sum{\\frac{y_ i}{σ_ i^ 2}} - \\sum{\\frac{x_ i}{σ_ i^ 2}} \\sum{\\frac{y_ i x_ i}{σ_ i^ 2}} }{ \\sum{\\frac{x_ i^ 2}{σ_ i^ 2}} \\sum{\\frac{1}{σ_ i^ 2}} - (\\sum{\\frac{x_ i}{σ_ i^ 2}})^ 2 }$ $intercept=\\frac{\\sum{\\frac{1}{σ_ i^ 2}} \\sum{\\frac{y_ i x_ i}{σ_ i^ 2}} - \\sum{\\frac{x_ i}{σ_ i^ 2}} \\sum{\\frac{y_ i}{σ_ i^ 2}} }{ \\sum{\\frac{x_ i^ 2}{σ_ i^ 2}} \\sum{\\frac{1}{σ_ i^ 2}} - (\\sum{\\frac{x_ i}{σ_ i^ 2}})^ 2 }$ Calculating p-values from Linear Regression The Null hypothesis for Linear Regression is that X and Y are not correlated. In other words: A change in X will not produce a predictable change in Y. The observed changes in Y are due to random error. p-values are calculated using the Chi Squared test. “Observed” is the measured value of Y at a particular X “Expected” is the value of the line at a particular X $$ χ^ 2 = \\sum{\\frac{expected - observed}{σ^ 2}}^ 2 $$ $$ df = N - 2 $$ Also individual p-values for the slope and intercept (compared to a null hypothesis, usually zero) can be calculated using a one sample t-test with the value of the slope or intercept and its standard error. Use N-2 as the degrees of freedom. Once we have the χ2, we can have the p-value by pchisq(x, df=2, lower.tail=FALSE), which x is the χ2. What else can you say about a linear regression analysis? Errors If your estimate of the uncertainties is too large, and you use them to do Linear Regression then the χ2 will be too small and the p-value will be close to 1.0. The calculated S value will be smaller that your estimates of SD in the data points. Correct uncertainties will follow the Z-distribution around the line. In other words roughly 67% of the ± 1 SD error bars on each Y value will include the best fit line, 33% will not include the line. This is because 1 SD is essentially a 67% Confidence interval. Residuals The distribution of residual errors is an indication of the goodness of fit. They should be randomly distributed. Correlation Coefficient $$ r^ 2 = \\frac{total\\ variance\\ in\\ Y - variance\\ in\\ Y\\ from\\ regression }{ total\\ variance } $$ $$ r^ 2 = \\frac{\\sum{(y_ i - y_ {mean})^ 2} - \\sum{(y_ i - y_ {expected})^ 2} }{ \\sum{(y_ i - y_ {mean})^ 2} } $$ r2 = 1 means perfect correlation. r2 = 0 mean there is no correlation. Note that some programs give r (not r2) which can range from –1 to +1 Extrapolation You can use regression parameters to calculate a new value of Y for any value of X. But beyond the range of the actual data, the calculated values can become very uncertain. Below: 95% confidence interval from Instat. Assumptions of linear regression Linear regression assumes that the X and Y numbers are independent measurements. Y can depend on X, but it can not contain the same data as X. If the values of X and Y are both used to calculate one or the other, then the observed correlation will be false. In the example above blood pressure in patients before and after a treatment are plotted. These are independent measurements, until you decide to see if there is a correlation between the change in blood pressure and the value before treatment. The change is really X – Y, so the Y axis values on the right are calculated using X. Since the numerical value of X is part of the Y axis AND the X axis, you can get a false correlation between X and Y. L17: Biomedical Statistics and Data Analysis Runs test The Wald–Wolfowitz runs test (or simply runs test), named after statisticians Abraham Wald and Jacob Wolfowitz is a non-parametric statistical test that checks a randomness hypothesis for a two-valued data sequence. More precisely, it can be used to test the hypothesis that the elements of the sequence are mutually independent. wikipedia Reference: Runs-test The runs test made by Prism is it assign the elements into two groups and calculate only the “lesser” part of the result. There are three packages we can do runs test: DescTools, snpar, and randtests. Only the DescTools has the same result like Prism by code below. TMP is the vector which contain the re-assign result as we talked above. For this package, you can assign the different group either to number or Character. More detailed codes you can find at: Karobben: Linear Regression in R PS: alternative=&quot;less&quot; cannot be ignored. library(DescTools)TMP = c(&quot;H&quot;,&quot;H&quot;,&quot;H&quot;,&quot;T&quot;,&quot;T&quot;,&quot;H&quot;,&quot;H&quot;,&quot;T&quot;,&quot;T&quot;,&quot;H&quot;,&quot;H&quot;,&quot;T&quot;)RunsTest(TMP, alternative = &quot;less&quot;) Runs Test for Randomness data: TMP runs = 6, m = 7, n = 5, p-value = 0.4242 alternative hypothesis: true number of runs is less than expected Rejection of data in linear regression","link":"/2022/04/02/LearnNotes/tulane-biostat-3/"},{"title":"Introduction of Bioinformatics","text":"Introduction of Bioinformatics Data units: © Quora 5V of Big Data Volume Velocity Variety Veracity Value Difinition of Bioinformatic Bioinformatics is the use of computer databases and computer algorithms to analyze proteins, genes, and the complete collection of deoxyribonucleic acid (DNA) that comprises an organism (the genome). – Bioinformatics and Functional Genomics (BFG) Book, 3rd Edition (2015): Bioinformatics refers to “research, development, or application of computational tools and approaches for expand- ing the use of biological, medical, behavioral, or health data, including those to acquire, store, organize, analyze, or visualize such data.” – National Institutes of Health (NIH) GeneCards.org (Human) Genome.ucsc.edu (Genome browser) For tolls for this classes HUGO gene names Uniport RCSB protein structure databases (PDB) Human protein Atlas cBioPortal for cancer genomics Frequency of the gene mutated in cancers Immune epotope database Antibody Antigen Homolog Analog: Convergent evelution Structure Alignment Sequence Alignment ClsutalW Muscle TCoffee Markov Models for Multisequence Alignment Wiki: Hiddne Markov Model Profile Hiden Markove Models are simoly a way to represent the features of these aligned sequences from the same family using a statistic model. Parts of the protein is important to this specific family. HMMs can make a profile to each protein family. We can take this profile for familiy specific and align the same protein family. PS: The HMMs could build profiles for families. We can using the profile of the pritein family and align our sequence. So we can have a better weighted alignment result by the families feature implied in HMMs profils (pre-bild model) Markove Chains: Sequences of random varibales in which the futrue variable is detemined by the present variable stochasitic/probabilistic process. First Order Markov model: the current event only depends on the immediatetly preceding event. Second order models uss the two preceding evetns, THird order models use three, etc. s Learn all the insert and the deleted probabilistic from the aligned sequence database and build the model. Then we can evaluate the this family of the Aligned Sequence for build the Markove Model Who do we get a proprate aligned sequence? What is the golden standard of the apropriate aligned squence? How to buidl Remvove low occupancy columns (&gt; 50%) Assign match states, delete states, insert states from MSA Get the path of each sequence Count the amino acid freqencies emitted from match or insert states, which are converted into probabilities for each state Count… Tran model using a given multiple sequence alignment Baum-Welch Algorithm odes the training/parameter estmation for HMM Baum-Welch is an ecpetation-Maximization (EM) algorithm - iterative Converges on a set of probabilities for the model that best fir the multiple alignment you gaie it Only finds a local maxima - good to try different intial conditions Baum-Welch can also perfom an MSA to from a set of unaligned sequences faster and more fitable than PIS-blast Classification: wihch fimaily of protein belongs. Meloular Phyligenies Describ, Meaning, Access Confidence. NGS Sanger Sequencing reciprocal translocation: long reads align © C.V.Beechey A.G.Searle Genome Sequencing Sequencing and Diseases Sample workflow DNA → Library → capture based selection → Sequencing DNA → PCR based selection→ Library → Sequencing Exp Severe combined immunodeficiency syndrome Il-2/4/7/9/15/21 → X-SCID (γ domain) γ domain mutate failed to active jak3 → Jak3-SCID Newborn sscreening Amino acid disorder PKU; MSUD Fatty acid disorder MCAD; VLCAD Organic acid disorders pH disorder Card screen Hemoglobinopathies Sickle cell, SC, S-β-thalassemia MSUD Galactosemia CF; CF links SCID - recommended by HRSA, detects T cell receptro excision circles (TRECs) T cell recombination. TREC screening False positive False negatives Zap70 deficiency MHC Class II deficiency NF-κb essential modulator late-onset ADA Positive: Genes tsted: ADA CD3D; CD3E… FOXN1: required for the development of Thymus WES, WGS Can detect novel variants Often uses trios or unaffected sibs Can be used in CMC-STAT3 gof, IL-17R mutations CF Screening -immunoreactive trypsinogen Typically measured by fluoroimmunoassay False postive Perinatal asphyxia, infection CF carrier (heterozygote) False negatives - rare Lab or specimen error pseudo-Bartter’s syndrome Positive: Sweat test high salting in sweat; less salting concentration among patients dehydrate Genetic testing Bordeline sweat test Targeted sequence of CFTR Challenges of WGS, WES Each individual harbors 2.7-4.2m SNV NGS and cancer Can compare somatic to germline mutation Exmaple AML Micro-dissected tumor Circulating tumor RNA Cancer Early Casses Lukas Whartman Dx All 2003 Treatede with sibling related … Sequenced the cancer genome for actionable mutations No mutations detected RNAseq found iverexpression in FLT3 Remitted with FLT3 inhibitor(Sutent) 2nd stem cell transplatnt after remission Suffers from GVHD Panels Sequences regions of interest Hybridization or PCR based Often disease specific Eg Breast , lung, colon CA Sequence coverage is high (up to 80x) GeneDx Panel data -positive yield 9.7% for breast 13.4% for ovarian 14.8% for colon/stomacj pathogenic or likely pathogenic mutation in over 8%-15% ofr … Between 70%-92% of the patients remains mutation-negative or undiagnosed … Mutations in PALB2 and ATM in pancreatic CA XRCC2, FANCC and BLM in HBOC Germline RNA-splice mutations using RNA-seq Germline splice variants in BRCA1/BRCA2 … NF1 NGS and cancer - Clinical utility Diagnosis Survival prediction GNAS &amp; KRAS Up to 20% of NGS tests were actionable Another 50% were actionable if you include mutations that could be targeted by the use of a FDA approved drug for off-label use Can identify candidates for anti-EGFR therapies Re-classification of tumors. Troditional: look unde the microscopy Pathology Diagnosis Useful in small smaples -FNAs Thyroseq panel for thyroid cancer Survival prediction Liquid Biopsy Rationable -Has been used for liquid and solid tumors May be useful in lieu of biospy… Pharmacogenomics Ratoionale Exampel Dihydropyrimidine dehydrogenase:D{D Mutations associated with greate toxicity of 5-fluorouracil, capecitiabine and… Futrue Directions for CA Epigenome CHIP-seq (Bulk cell) ATAC-seq (More advance; nano scale cells.) -RANseq Transcriptomes including non-coding RNA - - TPM: normalized by the size of the library Different tissues has different expression profile and the size of the profile is different. Transcripts is different, too. Small RNA Non coding RNA Long non-codong RNAs siRAN, piRNA, snRAN, snoRNAs biogenesis and functions of miRNA qRT-PCR, Microarrary Deep Sequencing structure features of snRANs and snoRNAs role of miRNAs ine cancer IncRNA XIST in X chrmosome Coding RNAs vs Non-coding RNAs Major type of small RNA tRAN Ribosomal RNA Smal neclear RNA (snRNA) Small nucleolar RNAs (snoRNAs) MicroRNAs (miRNAs) Small interfering RNAs (siRNAs) Piwi-interacting RNAs (piRNAs) Long 18/28S rRNAs Long intergenic non-coding rNASs or long intronic non-coding RANS Telomere-associated lncRNAS Long non-coding RNA &gt; 200nt 56,018 and 46,475 of long non coding RNA genes for human and mouse LncRNAs represent the largest category of ncRNAs XIST and H19 represetn the most extensicely studied lncRNAs X-inactive-specific trancripts (XIST): inactivation inactive X chromosome . miRNA: Perfect complemetnatrity/Non-perfect complemetnatrity piRNA: Silencing of trasnposable elements in the germline siRNA: Perfect match Evolutionary caonservation of has-miR-140-5p This miRNA is concertive amone vertibirets. (Human; Orangutan; zabera fish) 1993: C-elegans 2002: Biomarker; First version of the miRNA DB (V1) 2004: miRNA Microarray; RNAhybrid; V3,4,5 2006: miRNA-Seq; TarBase(MC) V8,9 Tools Dyana Scan; d Cluster What is cluster A cluster refers to “a group that includes objects with similar attributes” (e.g., Pirim et al., 2012) (1) a set of data objects that are similar to each other, while data objects in different clusters are different from one another (2) a set of data objects such that the distance between an object in a cluster and the centroid of the cluster is less than the distance between this object to centroids of any other clusters (3) a set of data objects such that the distance between any two objects in a cluster is less than the distance between any object in the cluster and any object not in it (4) a continuous region of data objects with a relatively high density, which is separated from other such dense regions by low-density regions Object: Finding groups of data objects such that those data objects grouped in the same cluster will be similar (or related) to one another, and different from (or unrelated to) the data objects grouped in the other clusters Exp: © Gergely Tholt, et al, 2018 How Clustering is Different from Classification Clustering does not use a subset of data objects with known class labels (called “train set”, which is commonly used in classification) to learn a classification model (i.e., “supervised learning”) Clustering is deemed as a form of an unsupervised task, which computes similarities (based on a distance) between data objects, without having any information on their correct distributions (also known as ground truth) Due to its unsupervised nature, clustering is known to be one of the most challenging tasks. The different clustering algorithms developed during the years by the researchers, lead to different clusters to the same dataset, even for the same algorithm, the selection of different parameters or the presentation order of data objects may greatly affect the eventual clustering partitions How it works Confirm data is metric Scale the data Select Segmentation Variables Define similarity measure Visualize Pair-wise Distances Method and Number of Segments Profile and interpret the segments Robustness Analysis Cite: T. Evgeniou[1] Major Types of Clustering Algorithms © Adil Fahad; 2014 Commonly Used Types of Clustering Algorithms in Biomedical Research The 3 commonly used types of clustering algorithms are: Hierarchical-based clustering considers grouping data objects with a sequence of nested partitions, and attempts to build a tree-like, nested, hierarchical structure that partitions a dataset Partitioning-based clustering partitions a dataset into a particular # of clusters denoted by K, no hierarchical structure, and therefore attempts to seek a K-partition of a dataset Model-based clustering [e.g., mclust, Expectation-Maximization (EM), COBWEB, and Self-Organizing Map (SOM)] applies predefined mathematical models for fitting the dataset and then, tries to optimizes them. The basic assumption is that the dataset is a mixture (i.e., hybrid) of several probability distributions. Such algorithms can determine the # of clusters based on standard statistical approaches (e.g., maximum likelihood), which could be robust to outliers and noise These commonly used types of clustering algorithms serve well to fulfill the objective of biomedical research to extract knowledge from big data, and their applications in biomedical research are ubiquitous in the prevention, treatment, and prognosis of human diseases! Partitioning library klaR library(klaR)library(ggplot2)library(reshape2)library(psych)set.seed(1)x &lt;- rbind(matrix(rbinom(250, 2, 0.25), ncol = 5), matrix(rbinom(250, 2, 0.75), ncol = 5))colnames(x) &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;)## run algorithm on x:cl &lt;- kmodes(x, 2)cl2 &lt;- kmeans(x, 2)# plot the resultx &lt;- data.frame(x)PC &lt;- principal(x[1:5], nfactors=2, rotate =&quot;none&quot;)pc &lt;- data.frame(PC$scores)C_map &lt;- cl$clusterC_map[which(cl$cluster!= cl2$cluster)] =100C_map &lt;- as.character(C_map)ggplot(pc, aes(x=PC1, y=PC2, color = C_map)) + geom_point(size=4,alpha=0.5)+ theme_bw() The color blue is the different results from two clusters. As we can see here, it doesn’t matter which group they blong since they are on the intersect region of two group. But when the K-mean increase to 3, they had a good agreement on group 1 and 3, but have misaggrement on group 2. © Karobben; 2022 Hierarchical Clustering Algorithms Hierarchical clusters are built on a cluster hierarchy also known as a tree of clusters called a dendrogram. These algorithms allow us to explore the dataset at different granularity levels, which are also called connectivity-based algorithms that build clusters gradually. Agglomerative hierarchical clustering, also called bottom-up approach, starts from bottom with each data object placed individually in a separate group (i.e., n clusters). Then, it successively merges data objects or groups that are close to (i.e., similar to) one another. This repeats till all the groups are eventually merged into a single hierarchical cluster, which is the topmost level of the hierarchical tree. This merging process will continue until a certain stopping condition is valid Divisive hierarchical clustering, also called as top-down approach, begins from topmost level by placing all data objects in a single cluster, and every successive iteration will split a cluster into smaller clusters (i.e., subsets). This dividing process happens until eventually each data object is placed as a single cluster (i.e., n clusters at the bottommost level), or a certain stopping condition is valid Distance Measures (also called Dissimilairty Measures) in Hierarchical Clustering © Rui Xu, et al. 2010 Major Linkage Methods of Agglomerative Hierarchical Clustering Single Linkage (also called Minimum Linkage) Complete Linkage (also called Maximum Linkage) Average Linkage [also called Unweighted Pair Group Method with Arithmetic Mean (UPGMA)] Centroid Linkage [also called Unweighted Pair Group Method with Centroid (UPGMC)] Ward’s Linkage (also called Minimum Variance) McQuitty Linkage [also called Weighted Pair Group Method with Arithmetic Mean (WPGMA)] © Shaik Irfana Sultana; 2020[2] Advantages and Disadvantages of Agglomerative Hierarchical Clustering and Divisive Hierarchical Clustering Agglomerative hierarchical clustering (A “bottom-up” approach) starts with n clusters, each of which includes exactly one data object. By comparison, divisive hierarchical clustering would start with considering 2(n-1) - 1 possible two-subset divisions for a cluster (a dataset) with data objects, which is very computationally intensive. Therefore, Agglomerative hierarchical clustering is a often preferred and more widely used approach Divisive hierarchical clustering (A “top-down” approach) provides clearer insights into the main structure of a dataset, because the larger clusters are generated at the early stage of the clustering process, and are less likely to suffer from the accumulated erroneous decisions, which can not be corrected by the successive process Advantages They provide embedded flexibility regarding the level of granularity It is easier for them to handle a variety of distance measures They are applicable to any attribute types Disadvantages The stopping criteria can be very vague to determine (i.e., the # of clusters can be difficult to determine) Many hierarchical algorithms do not revisit the intermediate clusters once constructed, which hampers the purpose of their improvement PS: after calss challenges İzzet Tunç; 2021. Time serious data Clustring tslearn; Time Series Clusterin paper:NbClust: An R Package for Determining the Relevant Number of Clusters in a Data Set NbClust package provides 30 indices for determining the number of clusters and proposes to user the best clustering scheme from the different results obtained by varying all combinations of number of clusters, distance measures, and clustering methods. L10 NbClust: NbClust Package for determining the best number of clusters L11 Partitional clustering Partitional clustering (also called partitioning-based clustering) algorithms identify the best K centers to partition the data objects into K clusters where the centers are either centroids (means), called K-means, or medoids, called K- medoids In contrast to hierarchical clustering, which yields a successive level of clusters by conducting either fusions or divisions, partitional clustering assigns a set of data objects into clusters with no hierarchical structure. The # of clusters, i.e., K, needs to be prespecified, and the choice of K is usually influenced by either prior knowledge regarding the nature of the data, or by using clustering validity measures. The K-means clustering algorithm is the best-known squared error-based clustering algorithm that has led to its applications in a variety of fields, e.g., psychology, marketing research, biology, and medicine K-Means Clustering First proposed by Steinhaus (1956) [Others suggest Forgy (1965)] [Steinhaus H. Sur la division des corp materiels en parties. Bull Acad Polon Sci. 1956; IV (C1.III), 801-804 has been cited 1,312 as of 02/22/2022, according to Google scholar; Forgy EW. Cluster analysis of multivariate data: efficiency versus interpretability of classifications. Biometrics 1965;21:768-9 has been cited 2,991 as of 02/22/2022, according to Google scholar] The K-means algorithm (also called kmeans algorithm) finds the centroids (i.e., centers) to minimize the sum of the squares of the Euclidean distance between each data point (i.e., each data object) and its closest centroid (i.e., center) In general, the K-means iterative clustering method is implemented as follows: Step 1: Choose a K value. Based on this value, randomly choose an initial set of K centroids Step 2: Assign each data object to the cluster with the nearest centroid Step 3: Determine the new set of K centroids for the K clusters, by computing the mean value of the cluster members - Step 4: Repeat Steps 2 and 3 until there is no change in the criterion function (i.e., sum of squared error function) after an iteration (i.e., the algorithm converges) The K-means algorithm is relatively scalable and efficient for processing (i.e., clustering) large datasets. However, K-means can converge to a local optimum (rather than a global optimum) in a small # of iterations Iteration K-means clustering is a good place to start exploring an unlabeled dataset. The K in K-Means denotes the number of clusters. This algorithm is bound to converge to a solution after some iterations. It has 4 basic steps: Initialize Cluster Centroids (Choose those 3 books to start with) Assign datapoints to Clusters (Place remaining the books one by one) Update Cluster centroids (Start over with 3 different books) Repeat step 2–3 until the stopping condition is met. You don’t have to start with 3 clusters initially, but 2–3 is generally a good place to start, and update later on. © Azika Amelia; 2018; K-Means Clustering: From A to Z © Azika Amelia; 2018 Limitation It is sensitive to the densities, the size of the cluster. Advantages Is simple and can be easily implemented in solving many practical problems Can work very well for compact and hyperspherical clusters Can be used to cluster large datasets Disadvantages There is no efficient and universal method for identifying the initial partitions and the # of clusters, i.e., K. The convergence centroids vary with different initial points. A general strategy for the problem is to run the algorithm several times with random initial partitions The iterative optimization procedure of K-means cannot guarantee convergence to a global optimum. The stochastic optimization techniques, e.g., simulated annealing (SA) and genetic algorithm (GA) can find the global optimum, but these tehniques are computationally intensive The K-means is sensitive to outliers and noise. E.g., even if a particular data object is quite far away from the cluster centroid, it is grouped into a cluster and, thus, could distort the cluster’s shape The definition of means limits the application only to numerical variables Example of the K-means cluster © Marcilio CP de Souto, et al. Advantages and Disadvantages of PAM Clustering Advantages PAM is more general than K-means [that typically require attributes (i.e., features) to be continuous], which can handle all types of attributes and all types of distance metrics (i.e., distance measures) Medoids (rather than centroids) are applied as the cluster “centers”, which are more robust and less sensitive to outliers and noise PAM can assist a user to determine the optimal # of clusters, i.e., K, because it provides a silhouette plot showing the silhouette widths for the K clusters Disadvantages The # of clusters, i.e., K, needs to be pre-specified, and the eventual clustering results are dependent on the initial selection of a random set of K data objects as K medoids The iterative optimization procedure of PAM cannot guarantee convergence to a global optimum PAM could be computationally intensive, which could work effectively for small datasets, but does not scale well for large datasets. To handle large datasets, a sampling-based method, called CLARA (Clustering LARge Applications), can be applied t-SNE t-distributed Stochastic Neighbor Embedding The t-distributed Stochastic Neighbor Embedding (t-SNE) (van der Maaten, 2008) is a state-of-the-art nonlinear dimensionality reduction algorithm, that has emerged as a popular and powerful technique for the analysis of single-cell data generated by a wide variety of experimental platforms (e.g., Camp et al., 2017; See et al., 2017; Lavin et al., 2017) The t-SNE focuses on preserving the local structure while de-emphasizing the global structure of high-dimensional data, resulting in similar data points clustering together in an unsupervised manner. Because t-SNE allows the user to define the # of dimensions for analysis, cell populations can be unbiasedly shown in 2 or 3 dimensions For a high-dimensional dataset, t-SNE creates a low-dimensional distribution, or a ‘map’. Conspicuous groupings of data points, also called ‘islands’, correspond to observations that are similar in the original high-dimensional space, which help to visualize the general structure and heterogeneity of a dataset Exp: © Paul A. Reyfman, etl al. Code in R # Data simulationset.seed(627)Bluegill.length &lt;- sample(seq(15, 22.5, by=0.5), 50, replace=T)Bluegill.weight &lt;- sample(seq(0.2, 0.8, by=0.05), 50, replace=T)Bowfin.length &lt;- sample(seq(46, 61, by=0.5), 50, replace=T)Bowfin.weight &lt;- sample(seq(1.36, 3.2, by=0.5), 50, replace=T)Carp.length &lt;- sample(seq(30, 75, by=1), 50, replace=T)Carp.weight &lt;- sample(seq(0.2, 3.5, by=0.1), 50, replace=T)Goldeye.length &lt;- sample(seq(25, 38, by=0.5), 50, replace=T)Goldeye.weight &lt;- sample(seq(0.4, 0.54, by=0.01), 50, replace=T)Largemouth_Bass.length &lt;- sample(seq(22, 55, by=0.5), 50, replace=T)Largemouth_Bass.weight &lt;- sample(seq(0.68, 1.8, by=0.01), 50, replace=T)weight &lt;-c(Bluegill.weight, Bowfin.weight, Carp.weight, Goldeye.weight,Largemouth_Bass.weight)length &lt;-c(Bluegill.length, Bowfin.length, Carp.length, Goldeye.length,Largemouth_Bass.length)set.seed(627)speed &lt;- rnorm(50*5, 7.2, sd=1.8)fish &lt;- c(rep(&quot;Bluegill&quot;, 50), rep(&quot;Bowfin&quot;, 50), rep(&quot;Carp&quot;, 50),rep(&quot;Goldeye&quot;, 50), rep(&quot;Largemouth_Bass&quot;, 50))fish.data &lt;- data.frame(length, weight, speed, fish)str(fish.data)# K-means clustering# Apply kmeans() function to perform K-means clustering# Apply the set.seed() function to make the results of kmeans() function repeatableset.seed(627) # the random for the random start of the centroidfish_data_kmeans &lt;- kmeans(fish.data[,1:3], centers = 5, nstart=1)str(fish_data_kmeans)fish.data$cluster &lt;- as.factor(fish_data_kmeans$cluster)# The following R code is equivalent to table(fish.data$cluster, fish.data$fish)with(fish.data, table(cluster, fish)) cluster Bluegill Bowfin Carp Goldeye Largemouth_Bass 1 50 0 0 3 4 2 0 7 17 0 0 3 0 0 13 47 18 4 0 13 14 0 21 5 0 30 6 0 7 # Compute clustering accuracycluster_fish &lt;- as.matrix(table(fish.data$cluster, fish.data$fish))cluster_fishsum(diag(cluster_fish))/sum(cluster_fish)# [1] 0.308# Partitioning Around Medoids (PAM) clusteringlibrary(cluster)set.seed(627)fish.data_pam &lt;- pam(fish.data[,1:3], k=5)str(fish.data_pam)fish.data_pam$clustering[1:10]fish.data_pam$clustering[241:250]# Create a 1x2 grid for plottingpar(mfrow=c(1,2))# Create a graphical display of PAM clusters and a silhouette plot by applying plot() functionplot(fish.data_pam, main=&quot;PAM&quot;)# Reset to a 1x1 grid for plottingpar(mfrow=c(1,1))fish.data$pam_cluster &lt;- as.factor(fish.data_pam$clustering)# The following R code is equivalent to table(fish.data$pam_cluster, fish.data$fish)with(fish.data, table(pam_cluster, fish))# Compute clustering accuracypam_cluster_fish &lt;- as.matrix(table(fish.data$pam_cluster, fish.data$fish))pam_cluster_fishsum(diag(pam_cluster_fish))/sum(pam_cluster_fish)# [1] 0.536# t-Distributed Stochastic Neighbor Embedding (t-SNE) Clustering# R code for t-SNE clustering#setwd(&quot;C:\\\\Users\\\\Tianhua Niu\\\\Desktop&quot;)#data_tsne &lt;- read.delim(&quot;data_1.txt&quot;, header = T, stringsAsFactors = F, sep = &quot;\\t&quot;)str(data_tsne)library(caret)library(Rtsne)# Apply the set.seed() function to make the results of Rtsne() function repeatableset.seed(627)tsne_model_1 &lt;- Rtsne(as.matrix(data_tsne), check_duplicates=FALSE, pca=TRUE, perplexity=30, theta=0.5, dims=2)# Create a data frame based on tsne_model_1d_tsne_1 &lt;- as.data.frame(tsne_model_1$Y)str(d_tsne_1)library(ggplot2)# Plotting the t-SNE result by applying ggplot() function# plotting the results as a scatter plot without clusteringggplot(d_tsne_1, aes(x=V1, y=V2)) + geom_point(size=0.25) + guides(colour=guide_legend(override.aes=list(size=6))) + xlab(&quot;tSNE_1&quot;) + ylab(&quot;tSNE_2&quot;) + ggtitle(&quot;A 2-Dimensional t-SNE Plot&quot;) + theme_light(base_size=12) + theme(axis.text.x=element_blank(), axis.text.y=element_blank(), plot.title = element_text(hjust = 0.5)) + scale_colour_brewer(palette = &quot;Set2&quot;)# Save the original dataset d_tsne_1 into a data frame called d_tsne_1_originald_tsne_1_original &lt;- d_tsne_1# Create a hierarchical clustering model using complete linkage method, and save the output into an R object called fit_cluster_hclustdist_euclid &lt;- dist(scale(d_tsne_1), method = &quot;euclidean&quot;)fit_cluster_hclust &lt;- hclust(dist_euclid, method = &quot;complete&quot;)# setting k=3 clusters as output for hierarchical clustering modeld_tsne_1_original$cl_hclust &lt;- factor(cutree(fit_cluster_hclust, k=3))# Create a K-Means clustering model, and save the output into an R object called fit_cluster_kmeans# Apply kmeans() function to perform K-means clustering# Apply the set.seed() function to make the results of kmeans() function repeatableset.seed(627)fit_cluster_kmeans &lt;- kmeans(scale(d_tsne_1), centers = 3, nstart=1)d_tsne_1_original$cl_kmeans &lt;- factor(fit_cluster_kmeans$cluster)# Create a plot_cluster() functionplot_cluster &lt;- function(data, var_cluster, palette){ ggplot(data, aes_string(x=&quot;V1&quot;, y=&quot;V2&quot;, color=var_cluster)) + geom_point(size=0.25) + guides(colour=guide_legend(override.aes=list(size=6))) + xlab(&quot;&quot;) + ylab(&quot;&quot;) + ggtitle(&quot;&quot;) + theme_light(base_size=12) + theme(axis.text.x=element_blank(), axis.text.y=element_blank(), legend.direction = &quot;horizontal&quot;, legend.position = &quot;bottom&quot;, legend.text = element_text(size = 12), legend.box = &quot;horizontal&quot;) + scale_colour_brewer(palette = palette)}# Apply plot_cluster() functionplot_hclust &lt;- plot_cluster(d_tsne_1_original, &quot;cl_hclust&quot;, &quot;Set1&quot;)plot_kmeans &lt;- plot_cluster(d_tsne_1_original, &quot;cl_kmeans&quot;, &quot;Accent&quot;)# Put these 2 plots side by side by applying R package gridExtralibrary(gridExtra)grid.arrange(plot_hclust, plot_kmeans, ncol=2) L16 Random Forest © Jesse Johnson Bagging: Bootstrap Aggregating Bagging algorithm, an ensemble learner, is a type of ensemble learning (also called committee- based learning) methods inspired from real life phenomena like democratic process, expert teams, and others, to combine individual machine learning methods into one predictive model in order to decrease the variance of the predictive model, and each individual machine learning method is called a base learner In Bagging algorithm, each base learner (i.e., individual learner) is constructed independently from a “bootstrap sample” (“bootstrap” refers to “resampling with replacement”) of the original train set, such that multiple base learners are trained by the same machine learning method on different base learner-specific train sets (i.e., different &quot;bootstrap samples“). During iteration, the successive base learners do not depend on earlier base learners (i.e., all are built independently),. Eventually, either a majority voting of predictions (for classification) or an averaging of predictions (for regression) is taken. Therefore, the diversity of individual learners is emphasized in Bagging algorithm, which has been increased implicitly for this ensemble learner Omics Cluster Analysis and Segmentation ↩︎ Shaik Irfana Sultana, 2020, How the Hierarchical Clustering Algorithm Works; Dataaspirant ↩︎","link":"/2021/08/24/LearnNotes/tulane-bioinf-1/"},{"title":"1 Methods in Biology|Advanced Cell Biology|Tulane","text":"Co-Author: Haoyang liang Cell Biology Methods Comment Methods: Immunohistochemistry-immunofluorescence Western blotting Immunoprecipitation Southern blotting Northern blotting in suit hybridization allele-specific oligonucleotides DNA microarray Polymerase chain reaction (PCR) DNA sequencing Immunohistochemistry-immunofluorescence Fixation:(antigen denaturation) Formalin: kill and cell fixation Paraffin: paraffin-embedded tissue section Antigen retrieval Antigen retrieval is an effective method of unmasking antigenic epitopes on the surface of formalin-fixed paraffin-embedded (FFPE) tissue sections. The antigen retrieval technique breaks the methylene bridges between epitopes and unrelated proteins to expose antigenic sites for antibody binding (1) Permeabilization Exp: Non-ion detergent so the antibody could enter the cell Blocking Incubation Unspecific binding by using blocking buffer exp: milk, BSA (Bovine Serum Albumin), gelatin, or casein blocking agents. For the secondary Ab specific binding to primary Ab Primary antibody high stringency (exp: mouse) if 1st Abgoat, then 2nd Anti-goat Second antibody large quantity (Donkey) Counterstain Image the histology structures Mounting adhere a coverslip to a tissue section or cell smear Control: nonspecific antibody? Common Dyes: 5-ethynyl-2′-deoxyuridine (EdU) Click Reaction © Kai Li, et al. Western Fractionation of proteins by gel electrophoresis in polyacrylamide gels followed by transfer to solid support. After blocking the residual binding capacity of the membrane, the filter is probed with a specific antibody. The bound antibody is detected with a secondary reagent that is labeled. Gel containing separated proteins Transfer of entire protein pattern by electrophoresis. Membrane with blotted proteins Blocking of residual binding sites and incubation with the first antibody Membrane with the first antibody bound Incubation with secondary enzyme-linked antibody and substrate Developed immunoblot Why protein migrated by its weight: Denatured: DTT: DL-Dithiothreitol; disruption of protein and (DNA) disulfide bonds SDS: sodium dodecyl sulfate Ionic detergent; Amphipathic surfactant Function: Denatures &amp; binds to proteins to make them uniformly negatively charged, aiming to be separated by mass Technically, protein is negatively charged. Positive Control: Protein from housekeeping genes like ribosome protein Immunoprecipitation © avantor; Classic IP kit Two important steps: Spin: remove the beads. Wash: remove the Unspecific bindings. Protein A/G has a high affinity for the antibody Two “A” factors Abundance of antigen solution Affinity of the antibody to antigen Co-immunoprecipitation protein interacting with antigen (interactiveprotein + Antigen) (Boiled) denatured and separated by electrophoresis. DNA/RNA Probe: A nucleic acid that is radiolabeled or tagged with another detectable tracer that is used to identify complementary sequences by hybridization Hybridization: The process of pairing two complementary single-stranded nucleic acids. Hydrogen bonds are formed between the bases to become a single double-stranded molecule DNA denature: Heating and high pH(11.3) formamide: a 42$^{\\circ} C$ Maintains RNA denaturing stats Lower the Tm of DNA Tm: GC% Length % Homology Salt concentration The hybridization stringency is adjusted to take these factors into account. Southern &amp; Northern blot N -&gt; RNA S -&gt; DNA RNA should be treated with denaturing detergent (Formamide/paraformaldehyde) to remove the secondary structure. Exp: Hairpin, etc. DNA doesn’t need this move after being digested (restriction nucleases). Digestion: smaller linear fragments. Denaturation: NaOH (sodium hydroxide) PCR Polymerase Chain Reaction Uses thermostable polymerase to synthesize a region of target DNA defined at each end by specific primers. Denaturation at high temperature; annealing at lower temperature; extension at moderate temperature; Repeat for many cycles. Primer: A short nucleic acid that is paired to another nucleic acid template. The primer provides a free 3’-OH that can be extended by polymerases along the template. $\\uparrow$ salt $\\to \\ \\downarrow$stringency $\\downarrow$ low salt $\\to \\ \\uparrow$ stringency RFLP Restriction Fragment Length Polymorphism - RFLP Based on: Linkage of the genetic disease with the RFLP Polymorphic distribution of restriction enzyme sites The normal variation in DNA sequence between two unrelated individuals is about one base out of 400. This variation can create or destroy restriction enzyme sites. Structural alteration in the gene or flanking sequences Linkage Clues to the location of a gene can come from comparing the inheritance of a mutant gene with the inheritance of markers of a known chromosomal location within a family Coinheritance, or genetic linkage, of a disease gene and a marker suggests that they are physically close together on the chromosome Linkage is determined by analyzing the pattern of inheritance of a gene and a marker in suitable families Because the RFLP is inherited just like a gene the individual chromosomes can be followed as they pass from generation to generation by tracing the inheritance of the marker fragments Variable Number of Tandem Repeats A hypervariable locus that consists of a variable number of identical sequences joined together in tandem. There are many VNTR loci in the genome; therefore, the pattern of fragments from the VNTR loci in one individual is essentially unique for that individual. When DNA is digested with a restriction endonuclease that cuts the sequence flanking a VNTR locus, the lengths of the DNA fragments produced in different individuals depend on the number of repeats at the locus - a DNA fingerprint DNA Fingerprinting Analyses of a set of polymorphic loci that are chosen so that the probability that two individual DNA samples with identical haplotypes could by chance have come from two different individuals is low. The most useful polymorphisms for this purpose occur at hypervariable loci. Allele Specific Oligonucleotide Hybridization Oligonucleotide probes are used that hybridize selectively to the normal or the mutant allele. These allele-specific probes can be used for any disorder where the nucleotide sequence of the mutant and normal alleles are known. Example: cystic fibrosis The ASO hybridization method exploits selective hybridization to distinguish between the normal and mutant alleles DNA Chip Technology Miniaturized silicone chips with densely packed arrays of oligonucleotides have been developed. The chips can be hybridized to a fluorescently labeled sample. Laser scanning of the chip can detect localized areas of fluorescence. DNA Microarray: The Genome Project made available cDNA clones and DNA sequences representing the entire genome Robotics allows precise immobilization of DNA onto microarrays Well-developed knowledge of nucleic acid hybridization Computer-based bioinformatics to analyze massive amount of data. In most instances cluster analyses of microarrays confirms pathological classification and staging, but new tumor entities have also been revealed. Response to chemotherapy has been predicted by the expression profile. Matrix-assisted laser desorption ionization (MALDI) mass spetrometry is a complementary means to analyze the proteome. Target amplified nucleic acid-based techniques couple hybridization with target nucleic acid and signal amplification techniques. The assays require exacting assay conditions (i.e. control for molecular contamination of reactions by amplified products leading to false positive results and using quality assurance measures and experimental controls that are carefully designed and executed) and careful interpretation.","link":"/2021/08/24/LearnNotes/tulane-cellbio-1/"},{"title":"11 RTK&#x2F;RAS&#x2F;MAP kinase pathway|Tulane","text":"overview Receptor Tyrosine Kinase: structure mechanism of activation Adaptor proteins/RAS: mechanism of activation MAP Kinase pathway: Signaling cascade mechanism of activation Kinase Kinase: Phosphorylate protein to active/inactive cell signal pathways. Phosphorylate: Ser, Thr and/or Tyr residues Kinase: conserved and has 11 subdomains. Conserved K to γ phosphate from ATP, can not be substitute by Arg. Conserved kinase catalytic domain: 11 subdomains Piedaldism Piebaldism is a rare autosomal dominant disorder of melanocyte development characterized by a congenital white forelock and multiple symmetrical hypopigmented or depigmented skin. KIT heterozygous mutation An autosomal dominant disorder of melanolcyte development characterized by a congenital white foreloc k and multiple symmetrical hypopigmented or depigmented skin. KIT heterozygous mutation. Similar mutation induced into mouse could cause similar symptom. Several common cell-surface receptors and signal transduction pathways Overview of signal transduction pathways triggered by receptors that activate protein tyrosine kinases. Structure and dimerization of RTK Dimerization could either happend in cis and trans. Different modes of ligand-mediated dimerization Dimerization of FGF family receptors is aided by heparan sulfate (polysaccharide) Dimerization of Receptor Tyrosine Kinases When not activated, RTKs are monomeric (almost all). Binding of ligand to the extracellular domain causes dimerization (also called cross-linking) of two RTK molecules. This can be accomplished by: The ligand is a monomer and causes a conformational change in the receptor that exposes a binding domain in the RTK that promotes its dimerization (EGF). The ligand is a homo- or heterodimer that thus automatically dimerizes the receptor (PDGF, NGF). The receptor already exists as a dimer (insulin). The ligand is clustered together by binding to extracellular sulfate proteoglycans (FGFs). The RTK undergoes cis or trans autophosphorylation on tyrosine residues. This further stimulates the kinase activity of the RTK. Dimerization of EGF family receptors (HER) Different mode of dimerization of EGF family receptors In 25% of breast cancers, HER2 gene is amplified and cancer cells overexpress HER2. What might be the effects of HER2 overexpression? Increase in HER2 expression on the cell surface will make the cell more sensitive to signaling by EGF family ligands. Why? Do the ligands activate same cellular response? Different ligands induce different biological responses via inducing phosphorylations on different Tyr residues Membrane-bound ligand and bidirectional signaling Ephrins are “repulsive” signals that stop neurons from growing into the incorrect areas of the brain. Ephrins are unusual ligands in that many of them are transmembrane proteins. Even though ephrins are monomeric, they are clustered in the plasma membrane of the cell that presents them. This allows for the cross-linking of their receptors, the Eph receptors. Ephrins and Eph receptors carry out bidirectional signaling: when ephrin binds to the Eph receptor, the ephrin undergoes conformational changes that promotes a signal into the cell that presented the ephrin. Monomeric RTK kinase domain is in an inactive state Activation of EGF receptor by EGF results in the formation of an asymmetric kinase domain dimer. Different mode of activation of EGF family receptors Different ways to inhibit RTK Dominant negative Receptor Tyrosine Kinase RTK signaling is downregulated by endocytosis The PDGF Receptor Signaling Complex The PDGF Receptor Signaling Complex The PDGF receptor is phosphorylated on several tyrosines (5 are shown here) Different phosphorylated tyrosine residues activate different signaling pathways Adaptor proteins and RAS Switch The compound eye of Drosophila melanogaster. Sevenless mutants fail to produce R7 receptors Sevenless encodes a receptor tyrosine kinase Genetic studies reveal that activation of Ras induces development of R7 photoreceptors in the Drosophila eye. Receptor tyrosine kinases (RTKs) Two different classes of proteins associate with phosphotyrosine residues in RTKs. Adapter or Docking proteins: These proteins couple the activated receptor to other signaling molecules but have no intrinsic signaling properties themselves. Enzymes involved in signaling pathways, GEFs and GAPs Adaptor proteins provide additional docking sites for downstream signaling molecules Surface model of an SH2 domain bound to a phosphotyrosine-containing peptide. Activation of Ras following ligand binding to receptor tyrosine kinases (RTKs) or cytokine receptors. RAS is a GTPase that can be turned on and off Ras promotes proliferation and differentiation pathways activated by RTKs. Dominant-negative forms of Ras block these two pathways. Conversely, hyperactive forms of Ras promote proliferation without any extracellular signal. Ras is a major mediator of cancer. ~30% of human cancers have hyperactive forms of Ras. Structures of Ras bound to GDP, Sos protein, and GTP. There are 3 different RAS proteins H-RAS, K-RAS and N-RAS They are all oncogenes MAP kinase pathway RTK (inactive) → bind → RTK dimer → GRB2 SOS → RAS(Inactivate) → RAS(activate) → RAF(MAPKK) → MEK(MAPKK) → MARK (ERK) → Activation of Transcription Active RAS activates the MAP kinase pathway Induction of gene transcription by MAP kinase Outline of the yeast MAP kinase pathways, illustrating similarities and difference in architecture Different scaffold proteins activate different MAP kinases RTK activates other signaling pathways Recruitment and activation of protein kinase B (PKB) in PI-3 kinase pathways Signaling Networks Signal diversity: most receptors activate multiple intracellular signaling pathways. This is one mechanism that allows a single receptor to have multiple effects on a cell. Cross-talk: most signaling pathways contain points where they can be regulated by other signaling pathways. This enables one signaling pathway to “branch out” and affect other target proteins. Redundancy: many pathways are activated by more than one receptor. Thus, different signal molecules can have similar effects on a cell. Signal amplification: multiple steps in an intracellular signaling pathway allows for the signal to be amplified along the way. Thus, very small amounts of a ligand can have dramatic effects. Kinases identified or implicated as the driver of cancer Pancreas: Insulin and regulation of glucose Pancreas is made up of exocrine and endocrine cells Insulin and regulation of glucose Insulin stimulates glucose uptake via small GTPases, and PI3K and AKT signaling pathway Multiple signal transduction pathways interact to regulate adipocyte differentiation","link":"/2021/10/26/LearnNotes/tulane-cellbio-11/"},{"title":"10 Cell Signaling|Advanced Cell Biology|Tulane","text":"Cell’s social network No cell lives in isolation; life requires that all cells sense chemical and physical stimuli in their environment and respond which changes that can affect their function os development. – Molecule Cell Biology, 3ed Inner signals Toxic signals Physical signals Responding to other biologies Growth factors Hormones Neurotransmitters Morphogens Odors Pheromones Ions Pharmacological agents Chemicals Heavy Metals Light Temperature Pressure Radiation Viruses Bacteria Responding of the cell signaling: differentiation proliferation exocytosis migration apoptosis adhesion senescence Receptors: Three domains: Extracellular domain plasma-membrane-spanning domain intracellular domain Acts like a ligand Many signaling proteins are belongs to signal transduction proteins Transmembrane signaling: only a few mechanisms Ligand-gated ion channel (iontropic receptros) G-protein-coupled receptors (metabotropic) Kinases-linked receptors Nuclear receptors Signal Transduction Snthesis → Release → Transport → Detection → Initiation → Functional Change → Deactivation → Removal Synthesis of the signal Release of the signaling molecule by the signaling cell: exocytosis, diffusion, cell-cell contact Transport of the signal to the target cell Detection of the signal by a specific receptor protein Initiation of one or more intracellular signaltransduction pathways A change in cellular metabolism, function or development triggered by the receptor-signal complex Deactivation of receptor Removal of the signal (downregulation) Signaling events are ordered both spatially and temporally Cellular Tools for information transmission Ligands transmit signals Receptors receive information in form of a ligand transmits signal across membrane Transducers pass information enzymatically active may be signal integrators Adapters no catalytic activity modulate proximity of transducers Scaffolds provide architecture allow energetically unfavorable events Effectors perform an end function Ligands (structure) Chamical structure, small molecules: • Small molecules (e.g. amino acid or lipid derivatives, acetylcholine) • Peptides (e.g. ACTH, vasopressin) • Steroids • Retinoids • Thyroxine • Proteins (usually large &amp; hydrophilic, bind to cell-surface receptors) (hydrophobic, bind intracellular receptors) Major classes • Hormones • Growth factors, cytokines, chemokines • Neurotransmitters • Pheromones • Can also be changes in metabolite concentration, e.g. oxygen or nutrients or physical stimuli such as light and heat Models of Cell Signaling ENDOCRINE SIGNALING Example: release of insulin by cells in the pancreas, travels in the blood stream and acts on distal liver, muscle and fat cells PARACRINE SIGNALING Examples: Growth factors and cytokines that signal to neighboring or surrounding cells AUTOCRINE SIGNALING Example: PDGF binds to PDGFproducing and secreting cells to stimulate cell growth SIGNALING BY MEMBRANEATTACHED PROTEINS Example: Delta-Notch signaling Not every ligand that binds to a receptor also activates the receptor Agonists are able to activate the receptor and result in a maximal biological response. The natural endogenous ligand with the greatest efficacy for a given receptor is by definition a full agonist (100% efficacy). Partial agonists do not activate receptors thoroughly, causing responses which are partial compared to those of full agonists. Antagonists bind to receptors but do not activate them. This results in receptor blockage, inhibiting the binding of agonists and inverse agonists. Inverse agonists reduce the activity of receptors by inhibiting their constitutive activity. What determines the cellular specificity of responses to ligands? The presence or absence of receptors The internal signal transduction or response machinery of individual cell types Ligands induce specific cellular response One type of ligand could trigger different type of respons in diffrent cell types. Exp: Acetylcholine could initiate: Pancreatic Acinar cell: Digestive enzymes Pancreatic β cell: Insuline Smooth Muscle: contraction Parotid gland (saliavary): amylase enzyme Receptors They work as a gateway to the cell. As a result, they are crucial … to regulate almost every known physiological process.” (Robert Lefkowitz) Intracellular (Nuclear) Receptors • Can be located in the cytoplasm or the nucleus • Bind to hydrophobic ligands that can diffuse across the plasma membrane • Contain DNA-binding domains and act as ligand-regulated transcriptional activators or suppressors • Characteristic lag period between ligand binding and cellular response of 30 minutes to several hours • Effects of NR agonists can persist for hours or days after plasma concentration is zero Cell-surface receptors Hydrophilic ligands bind to cell-surface receptors • Integral membrane proteins • Domain structure - Extracellular - Transmembrane - Intracellular • Exhibit ligand binding specificity • Ligand binding induces conformational change that exerts an effect intracellularly • Effector specificity Seven Major Classes of Cell-Surface Receptors © Molecular Cell Biology, Edt3 Experimental Figure 15.3 Ligand Growth hormone binds to its receptor through molecular complementary. Binding Specificity Ligands binding to different types of receptors lead to different physiological responses Sensitivity of a cell to an external signal is determined by the number of surface receptors Maximal cellular response does not require binding of all receptors 50% of maximal response when only 18% of receptors bound with ligand 80% of maximal response is induced when 50% of the receptors are occupied Transducers pass information; enzymatically active; may be signal integrators Protein kinases and phosphatases are employed in virtually all signaling pathways Regulation of protein activity by a kinase/phosphatase switch. A simple signal transduction pathway involving one kinase and one target protein. ~ 600 kinases and 100 different phosphatases in human genome Target residues are ‘phosphoacceptors’ - Ser, Thr or Tyr Assembled into the ‘KINOME’ Diversity encompasses transmembrane, simple and complex structures Post-translational modifications (PTM) Reversible addition of a small chemical group causes change in activity or location of a signaling protein PTMs require the action of both modifying and unmodifying enzymes (allowing the signal to be given and terminated) GTPase switch proteins cycle between active and inactive forms. Switching mechanism of G proteins. Second messengers amplify the signal Second messengers Short lived, diffusible intracellular signaling molecules Elevated concentration leads to rapid alteration in the activity of one or more cellular enzymes Removal or degradation terminates the cellular response Adapters and Scaffolds no catalytic activity modulate proximity of transducers provide architecture allow energetically unfavorable events Signaling induced by protein-protein interactions Cellular Tools for information transmission Adapter has no catalytic activity, modulate proximity of transducers Many signal-transduction pathways contain large multiprotein signaling complexes which are held together by adapter proteins These regulatory interactions are mediated by specific protein domains Signaling proteins are modular, consisting of groupings of highly conserved domains each with a specific function. When used in combination, these domains allow the construction of specialized molecules with multiple input and output points. Use of domains ensures function only in the correct conditions/context Adapter - Protein clustering Clustering of neurotransmitter receptors in the region of the postsynaptic plasma membrane adjacent to the presynaptic cell promotes rapid and efficient signal transmission PDZ domains are protein-protein interaction domains recognizing mainly the C-termini of their target proteins Src-homology 2 (SH2) domains bind to specific phospho-tyrosine containing peptide motifs. Src-homology 3 (SH3) domains bind to proline rich peptides Pleckstrin homology (PH) domain Bind to phosphoinositides, bg-subunits of G-proteins and PKC Scaffolding protein provide architecture and allow energetically unfavorable events Lipid Rafts Rafts, 10-50 nm, contain a max of 50 proteins along cholesterol, sphingolipids, and Glycosylphosphatidylinositol-anchored proteins Caveolae are a special type of lipid raft Coalesce with active signaling and might concentrate signaling proteins May provide a microenvironment for signaling and help GPI-linked proteins signal across membrane Caveolae are small (50 -100 nm) invaginations in plasma membrane containing Caveolin on the cytosolic leaflet of the plasma membrane Caveolin helps form the flask-shaped pits involved in endocytosis Caveolin interacts with cholesterol and may be play a role in transfer of cholesterol into lipid raft domains. Signal proteins that attach to the plasma membrane via lipid anchors tend to be concentrated in caveolae. Effectors perform an end function Cellular Tools for information transmission Many ligands bind to multiple types of receptors leading to different physiological responses Different Receptor ligand complexes can activate the SAME response: Example: Epinephrine or glucagon can activate glycogen breakdown and release of glucose into the blood Turning off or dampening signaling Signaling Pathways often cross-communicate Signaling Networks the same cellular response may be induced by multiple signaling pathways by distinct mechanisms Interaction of different signaling pathways permits fine-tuning of cellular activities Cell-Cell Adhesion and Communication- Integrating Cells into Tissues Cell adhesion molecules (CAMs) classes: cadherins – cell-cell adhesion; calcium dependent e.g, E-cadherin, P-cadherin Ig superfamily of CAMs – cell-cell adhesion; calcium-independent; some are found enriched on specific cell types – e.g. N-CAM, V-CAM Integrins – cell-matrix adhesion molecule e.g. a1 integrin, b1 integrin Signal Transduction The effects of activation of cell surface receptors are more complicated than a simple step-by-step cascade By no means is signaling a linear event Extensive networking and cross talk Key is integration Why so complicated? Amplification - Reliability - Redundance When signaling goes wrong Dysregulated signaling results in inappropriate responses to stimuli Over- and under-reaction are equally devastating All disease is the result of inappropriate, inadequate or over-enthusiastic signal transduction When the target ignores the Signal: Losing the Signal → Type I Diabetes When the target ignores the Signal → Type II diabetes Too much signal → Stroke Multiple breakdowns → Cancer When a signal doesn’t reach its target → Multiple Sclerosis Mutations of receptors may lead to constitutive activity Amplification or overexpression of Her2/neu is associated with aggressive breast cancers Suppression of pro-apoptotic genes will lead to transformation Some cancer-causing viruses encode an activated form of src 90% human tumors have activating Ras Mutations; Activating mutations of Ras, Rac, Rho or cdc42 are Enough to induce cellular transformation In the lab Oncogenic transformation Uncontrolled Proliferation Suppressed Apoptotic Downregulation of antigenic surface proteins Many signaling proteins are oncogenes: activating or inactivating mutations are sufficient to cause transformation Studying Cell-Surface Receptors and Signal Transduction Proteins Kd = dissociation constant measures the affinity of the receptor for the ligand Low Kd = high affinity of ligand for receptor High Kd = low affinity of ligand for receptor For high-affinity ligands, binding assays can determine the Kd and the number of receptors per cell Suspension of cells incubated for 1 h at 4oC with increasing conc. of 125I-labeled insulin Pellet cells and wash away unbound insulin Measure radioactivity = total binding Repeat binding assay in the presence of 100-fold excess unlabeled insulin = nonspecific binding Subtract nonspecific binding from total binding = specific binding Determine total number of receptors per cell Determine Kd Isolation of Membrane receptors A typical mammalian cell has between 1,000 and 50,000 copies of receptor Affinity labeling: crosslink radiolabeled ligand to receptor- follow radioactivity in purification Affinity chromatography: ligand is chemically linked to polystyrene beads - pass homogenate over column - receptor binds - release receptor by passing excess ligand through column Cloning of Receptors Allow identification of receptors that constitute small percentage of total cellular protein, and identification of receptors from small tissue source Expression cloning Homology cloning Expression Cloning of Receptors Make cDNA library from appropriate tissue Express library in cell line that does not express the receptor of interest Use ligand binding to identify clone that encodes receptor Functional Expression Assay Divide library into smaller pools to find clone that encodes receptor Provided cells express relevant signal-transduction proteins, transfected cells will now exhibit normal cellular response to ligand X if the cDNA encodes the functional receptor Homology Cloning find additional variants of receptor find novel receptors Degenerative PCR (odorant receptors) Or screen library at low stringency (glutamate receptors) Or database search (Taste receptors) Degenerative PCR Cloning • Design degenerate primers that match amino acid sequences in conserved region of receptor family members • Use these primers in all pairwise combinations to amplify related sequences in cDNA prepared from tissue suspected of expressing the new receptor • Clone and sequence DNAs from PCR • Examine sequence for hallmarks of receptor family • Use these DNAs as probes to screen cDNA library from tissue known to express receptor • Examine proteins encoded by positive cDNA clones The structures and actions of receptors may be studied by using biophysical methods such as X-ray crystallography, NMR, circular dichroism, and dual polarization interferometry. Computer simulations of the dynamic behavior of receptors has been used to gain understanding of their mechanism of action.","link":"/2021/10/21/LearnNotes/tulane-cellbio-10/"},{"title":"12 G Protein&#x2F;Wnt kinase pathway|Tulane","text":"Signaling at the cell surface Chapter 15, pages 687-712 Chapter 16, pages 752-757 GPCR-Related Researchers Awarded Nobel Prize 1967 Ragnar Granit, Haldan Keffer Hartline and George Waki – physiological and chemical visual processes in the eye. 1970 Bernard Katz, Ulf von Euler and Julius Axelrod – neurotransmitters in the nerve terminals and the mechanism for their storage, release and inactivation. 1971 Earl Wilbur Sutherland, Jr. – discovered cyclic AMP as the second messenger for mediating the action of hormones. 1988 James W. Black – discovery of propranolol and cimetidine, two clinical drugs that block the action of the b-adrenergic receptor and the H2 histamine receptor, respectively 1994 Alfred G. Gilman and Martin Rodbell – discovery of G-proteins and their role in signal transduction 2000 Arvid Carlsson - dopamine 2004 Richard Axel and Linda B. Buck – odorant receptors 2012 Robert J. Lefkowitz and Brian K. Kobilka - identification, purification, cloning and determining crystal structure of the adrenergic receptors General Elements of GPCR Systems Accepter Trimeric Gs protein Effector • contains 7 membrane-spanning domains • coupled trimeric G protein - functions as a switch (active/inactive) • A membrane bound effector protein • Most involve second messengers • Feedback regulation and desensitization of the signaling pathway Most receptors are G protein-coupled receptors (GPCRs) • Contains 7 membrane-spanning domains • A coupled trimeric G protein which functions as a switch • A membrane bound effector protein • Most involve second messengers • Feedback regulation and desensitization of the signaling pathway General structure of GPCRs The same orientation in the membrane 7 transmembrane α-helical regions 4 extracellular segment 4 cytosolic segments Rhodopsin structure β2-Adrenergic Receptor Dendrogram of human GPCR superfamily crystal structures solved by Nov 2012 A coupled trimeric G protein which functions as a switch G protein G Protein + GTP → Conformation changed G Protein + GDP + Pi G Protein: on/off state Heterotrimeric G proteins vary in composition 3 subunit: Gα, Gβ, Gγ • 23 a isoforms (39-46 kDa proteins) • contains the GTP/GDP binding site • is responsible for identity • membrane anchored through prenylation • 6 b isoforms (35 - 36 kDa proteins) and 12 g isoforms (8 kDa proteins) • are functionally identical or very similar, interchangeable in vitro; • most of them are ubiquitously expressed; • membrane anchored through prenylation of Gβ. A membrane bound effector protein One side is activate, another side has a inactivate proteins • Most involve second messengers • Feedback regulation and desensitization of the signaling pathway General Elements of GPCR Systems Operational model: Hormone bind to the Active receptor G protein bind to the Active receptor GDP released G Protein + GTP: α subunit sepratede with other two α subunit bind to the active effector, GTP → GDP Which of the following mutations to the Ga protein could render a G protein-coupled receptor signaling pathway constitutively active? A) Ga cannot bind Gbg B) Ga cannot hydrolyze GTP C) Ga protein cannot bind GDP D) Ga protein cannot release GDP E) Ga protein cannot bind GTP Which of the following mutations to the Ga protein could render a G protein-coupled receptor signaling pathway constitutively active? A) Ga cannot bind Gbg B) Ga cannot hydrolyze GTP C) Ga protein cannot bind GDP D) Ga protein cannot release GDP E) Ga protein cannot bind GTP A Ga subunit that cannot hydrolyze GTP would remain bound to its downstream effector, keeping it constitutively active. All of the other mutations would render the signaling pathway nonfunctional. Heterotrimeric G protein families (based on a subunit) GPCRs mediated Regulation of Ion Channels Accepter + G protein + Ion Channel After activated, β and γ bind to the ion channel Neurotransmitter receptors (Na and K channels)- Nerve impulses essential for sensory perception Acetylcholine receptors (K channel)- Hyperpolarizes membrane, reduces frequency of heart muscle contraction • Human retina contains 2 types of photoreceptors - cones and rods • Cone photoreceptors contain the GPCRs for color • Rod photoreceptor cells contain GPCR (rhodopsin) for non-color light • Rhodopsin is localized in the thousands of flattened membrane disks in the outer segment of rod cells The light-triggered step in vision. Rhodopsin = opsin (7 transmembrane protein) + 11-cis-retinal (light absorbing pigment) Light-activated rhodopsin pathway and the closing of ion channels in rod cells Ligand = photon (light) Transducer = Gat (transducin) Effector = cGMP phosphodiesterase, reduces cGMP in the cell *reduced cGMP causes cGMP-gated ion channel to close, membrane becomes hyperpolarized, less neurotransmitter released, brain sees this as ‘light’ Inhibition of rhodopsin signaling by rhodopsin kinase Light activated rhodopsin is substrate for rhodopsin kinase The extend of rhodopsin phosphorylation proportional to the amount of time each rhodopsin spend in the light Arreastin binds to completely phosphorylated Rhodopsin – no activation Mechanism for re-setting visual cycle Hydrolysis of GTP on α-subunit – accelerated by GAP Re-synthesis of cGMP by guanyl cyclase is stimulated by lower Ca++ levels Phosphorylation of cytoplasmic loop of rhodopsin (opsin) allowing β-arrestin to bind Phosphatases remove phosphates from cytoplasmic loop of rhodopsin resensitizes Most involve second messengers Secondary messenger cAMP cGMP DAG IP₃ GPCRs activate or inhibit adenylyl cyclase Binding of Gsa-GTP to adenylyl cyclase activates the enzyme, whereas binding of Gia -GTP inhibits adenylyl cyclase. The Gbg subunit in both stimulatory and inhibitory G proteins is identical; the Ga subunits and the receptors differ. • Gsa stimulates adenylyl cyclase to increase cAMP • Virtually all the diverse effects of cAMP are mediated through PKA • The resulting cellular response depends on the particular PKA isoform and the PKA substrates expressed by the cell PKA Links GPCRs to transcription CREB = CRE-binding protein, found in the nucleus, phosphorylated and activated by PKA CRE = cAMP responsive element Table 15-2 mAKAP anchors both PKA and PDE to the nuclear membrane, maintaining them in a negative feedback loop Basal PDE activity: Resting state Increased cAMP: PKA activation PDE phosphorylation and activation; reduction in cAMP level mAKAP - A kinase-associated protein kinase; anchoring PDE - cAMP phosphodiesterase PKA - protein kinase A Synthesis of 2nd messengers DAG and IP3 IP3/DAG pathway and the elevation of cytosolic Ca2+ Provides close local control of the cAMP level 30 cytosol membrane Actin remodeling Endocytosis Vesicle fusion 2nd messengers table 15-3 Feedback regulation and desensitization of the signaling pathway Inactivate receptor + G Protein + Inactive effector Mechanisms to attenuate signaling by GPCRs • Removal of stimulus - reuptake, degradation • Affinity of receptor for ligand decreases when GDP bound G- protein becomes replaced with GTP • GTP is quickly hydrolyzed, inactivating Ga (e.g. reversing the activation of adenylyl cyclase &amp; production of cAMP) • Removal of 2nd messenger (e.g. cAMP phosphodiesterase hydrolyzes cAMP to 5’-AMP, terminating the cellular response) • Receptor desensitization • Receptor endocytosis - recycling or degradation GPCR desensitization • Feedback suppression • Heterologous desensitization • Homologous desensitization Feedback suppression The end product of a pathway blocks an early step in the pathway Example: activation of receptor Leads to activation of PKA, PKA phosphorylates the same receptor, reducing its ability to activate adenylyl cyclase Homologous Desensitization • Agonist-dependent phosphorylation of receptors mediated by G protein-coupled receptor kinases (GRKs) • Receptor interaction with intracellular proteins called arrestins • Arrestin binding sterically precludes coupling between the receptor and heterotrimeric G proteins • Termination of signaling by effector G protein coupled receptor kinases (GRKs) N Catalytic Domain 0 50 100 amino acids amino-terminal domain (receptor-binding?) autophosphorylation region Variable region (membrane targeting) C • Rhodopsin kinase or visual (GRK1 and GRK7) • β-adrenergic receptor kinases (GRK2/GRK3) • GRK4 (GRK4, GRK5 and GRK6) Heterologous Desensitization Activation of one type of receptor can activate signal transduction leading to the desensitization of a different receptor (agonist-independent phosphorylation) Luttrell L M , and Lefkowitz R J J Cell Sci 2002;115:455-465 ©2002 by The Company of Biologists Ltd β-arrestins can act as adapters Receptor-bound b-arrestins also act as adapter proteins, binding to components of the clathrin endocytic machinery and other signaling molecules. β-arrestin-induced signaling RhoA-dependent stress fiber formation inhibition of nuclear factor κB (NF-κB)- targeted gene expression through IκB stabilization Protein phosphatase 2A (PP2A)- mediated dephosphorylation of Akt, which leads to the activation of glycogen synthase kinase 3 (GSK3) Extracellular signal-regulated kinase (ERK)-dependent induction of protein translation and antiapoptosis Phosphatidylinositol 3-kinase (PI3K)- mediated phospholipase A2 (PLA2) induction and increased vasodilation through GPR109A activation Kif3A-dependent relocalization and activation of the protein Smoothened (Smo) in the primary cilium (21). 44 Phosphorylated (desensitized) receptors are constantly being resensitized owing to dephosphorylation by constitutive phosphatases. All involve phosphorylation of GPCR GPCR desensitization • Feedback suppression • Heterologous desensitization • Homologous desensitization Which of the following steps in an intracellular signaling pathway amplifies the signal? A) binding of ligand to receptor B) synthesis of a secondary messenger C) activation of a protein kinase D) receptor desensitization E) receptor activation of a G protein In B, C, and E, each signaling molecule produces/activates more than one of the next signaling molecule. GPCR Signaling Diversity Oligomerization of GPCRs can confer unique pharmacological and functional profiles to a receptor, including affinity for specific peptide ligands and coupling to novel G proteins. Both homo- and hetero-oligomeric receptor complexes may have the ability to couple to more than one G protein, depending on their cellular environment, thereby conferring the ability to mediate different intracellular responses to the same ligand. Disruption of G protein signaling can cause disease Cholera • Cholera toxin catalyzes covalent modification of Gsa. ADP-ribose is transferred from NAD+ to an arginine residue at the GTPase active site of Gsa. • ADP-ribosylation prevents Gsa from hydrolyzing GTP. Thus G sa becomes permanently activated. • Resulting excessive rise in intracellular cAMP leads to loss of electrolytes and water into the intestinal lumen, producing watery diarrhea. Whooping Cough Disease Colonization of tracheal epithelial cells by Bordetella pertussis Pertussis toxin catalyzes ADP-ribosylation at a cysteine residue of Gia, making the inhibitory Ga incapable of exchanging GDP for GTP. Thus the inhibitory pathway is blocked Resulting increase in cAMP in epithelial cells of the airways promotes loss of fluids and electrolytes and mucus secretion. These toxins can be useful tools in the lab used to determine whether a particular agonist of a GPCR invokes activation of members of the Gia or Gsa family If the GPCR mediates its effects through Giawe should see an increase in activity (cAMP) when we apply the pertusis toxin compared to control. If the GPCR mediates its effects through Gsa we should see a significant increase in activity (cAMP) when we apply the cholera toxin. Many Human Viruses Encode GPCRs Wnt and Hedgehog signaling Nonconventional 7-TM Receptors Frizzled family receptors Schulte. Pharmacological Reviews. 2010; 62:633 Wnt Proteins • Large family of secreted molecules (350 to 400 aa) highly conserved across species • 2 members discovered: Drosophila Wingless Mouse int-1 • Three Wnt signaling pathways: canonical Wnt pathway (operates through b-catenin) noncanonical planar cell polarity pathway noncanonical Wnt/calcium pathway Control processes during development, stem cell maintenance and homeostasis Aberrant regulation has been linked to diseases in man including diabetes, neurodegeneration and cancer Canonical Wnt signaling Activation of b-catenin MacDonald et al. Developmental Cell 17, July 21, 2009 APC – adenomatosis polyposis coli CK – casein kinase GSK3 – glycogen synthase kinase 3b Gro – groucho Noncanonical Wnt signaling Niehrs. Nature Reviews. 2012; 13:767 60 MacDonald et al. Developmental Cell 17, July 21, 2009 61 Cancer Inflammatory bowel disease Parkinsons Diseases of bone Obesity Wnt related diseases Hedgehog signaling pathway • Discovered in Drosophila and is conserved in vertebrates (including humans) • Involved in cell growth and differentiation during embryonic development ensuring that tissues reach their correct size and location, maintaining tissue polarity and cellular content regulating hair follicle and sebaceous gland development In the skin • Germline mutations in of the results in a number of developmental abnormalities • Remains inactive in most adult tissues Hedgehog signaling Abnormal Hedgehog pathway signaling in the pathogenesis of certain types of cancers Two different mechanisms drive abnormal Hedgehog pathway signalling in different types of cancer: Ligand-independent signalling driven by mutations (e.g. BCC and medulloblastoma) Mutations in key pathway regulators (e.g. PTCH or SMO) cause SMO to be in a constitutively active state Ligand-dependent signalling driven by overexpression of Hh ligand by tumour cells (e.g. ovarian cancer, colorectal cancer, pancreatic cancer) Dorsam and Gutkind Nature Reviews Cancer 7, 79–94 (February 2007) | doi:10.1038/nrc2069 Please read Molecular Cell Biology Chapter 15, pages 687-712 Chapter 16, pages 752-757 Thank you 68 Operational model for ligand-induced activation of effector proteins associated with GPCRs http://www.youtube.com/watch?v=V_0EcUr_txk","link":"/2021/10/28/LearnNotes/tulane-cellbio-12/"},{"title":"13 Cytokine Receptors, JAK&#x2F;STAT, PI3K|Tulane","text":"Cytokine Receptors, JAK/STAT, PI3K and TGFb/SMAD signaling pathway Central themes in the activation of RTKs Ligands induce dimerization of receptors and activation of kinase by cis- or trans-phosphorylation of activation lip. Recruitment of adaptor proteins to p-Tyr (RTKs) via SH2 domain and activation of RAS through SOS Activation of MAP kinase pathway and activation of transcription via phosphorylation of transcription factors. Receptors-associated Kinases Receptors That Activate Protein Tyrosine Kinases RTK (receptor tyrosine kinase): Intrinsic kinase activity Cytokine Receptors (no intrinsic enzyme activity) Activate Tightly Bound JAK Protein Tyrosine Kinases that activate STATs. Receptor Ser/Thr Kinases and SMAD signaling Ser, Thr, Tyr phosphorylation and phosphomimetic aa Part I: Cytokine Receptors and the JAK- STAT pathway Cytokines Cytokines are a family of relatively small, secreted signaling molecules that control cell growth and differentiation, especially the cells in the immune system. interferons (IFNs) and interleukins (IL) Cytokines are critical for generation of all immune cells Erythropoietin and formation of red blood cells Low blood oxygen levels activates HIF1a (hypoxia inducible factor) in the kidney interstitial fibroblasts low blood oxygen levels → activates HIF1a (hypoxia inducible factor) in the kidney interstitial fibroblasts Blood doping in sports: Epo Dr. Francesco Conconi; University of Ferrara Lance Armstrong All cytokines and cytokine receptors have similar structures. Cytokine receptors have two subdomains comprised of seven conserved beta-strands (sheets) which are critical for cytokine- receptor interaction. Epo binds to two identical Epo receptors (homodimer). Cytokine receptors do not have intrinsic kinase activity. Cytokine Receptor Activation Cytokine receptors can form homodimers, heterodimers or oligomers with 3 or more subunits. Cytokine receptors have NO intrinsic enzymatic activity. Rather, the receptors are associated with cytoplasmic kinases called JAK kinase. JAK is tightly bound to the cytosolic domain of all cytokine receptors. In the absence of cytokines, the JAK kinases are not activated. JAK Protein Tyrosine Kinases The JAK (Just Another Kinase, Janus) family are cytoplasmic protein tyrosine kinases, which are physically associated with the intracellular domains of cytokine receptors. There are four JAK in mammalian cells: JAK1, JAK2, JAK3, TYK2 The domain structure of JAKs JH2, pesudo-kinase domain phospholate it’s self to cpntrol the JH1 kinase domain’s activity. JAK kinases have two kinase domains (JH1 and 2) and do not have SH2 or SH3 domains. There are seven well-conserved JAK homology domains (JH). JH1 is the kinase domain, which contains two tyrosines that can be phosphorylated after ligand stimulation. JH2 is considered catalytically inactive. However, a recent study showed that JH2 is a dual-specific kinase which keeps JAK inactive. The JH6 and JH7 domains mediate the binding of JAKs to receptors. There are four mammalian JAKs (JAK1, 2, 3, TYK2) that are associated with specific cytokine receptors. Cytokine Receptor Activation Activated cytokine receptors signal through JAK-family Kinases Binding of ligand triggers receptor dimerization and the activated receptor dimers interact through their intracellular domains which brings the associated-JAKs closer and allows rapid transphosphorylation and activation of the receptor- associated JAKs. Activated JAKs then phosphorylate critical tyrosine residues on the receptor, which leads to recruitment of specific STATs through their SH2 domains followed by single tyrosine phosphorylation of the bound STAT. SH2 domain is phospho-tyrosine-binding domain, which directly binds to phospho-tyrosine residues. The unique amino acid sequence of each SH2 domain determines the specific phospho- tyrosine residues it binds. STAT proteins (Signal Transducers and Activators of Transcription) STAT proteins, a family of latent cytoplasmic transcription factors, are the principal players of JAK-STAT pathway. There are seven mammalian STAT proteins (STAT 1, 2, 3, 4, 5A, 5B, 6) STAT1: INF response STAT2: Development STAT3: EGF and IL-6, Development STAT4: IL-12 STAT5s: prolactin, growth hormones and many ILs STAT6: IL-4 STAT proteins (Signal Transducers and Activators of Transcription) STAT2 STAT4 STAT6 STAT1 STAT3 STAT5a STAT5b Development of T cells IFNg signaling Expressed in different tissues Involved in IFN signaling Development of mammary gland Embryogenesis Control cell cycle and apoptosis (cancer) All STAT proteins share six structural regions: Interaction and dimerization JAKs structure: SH2 domain + DAN binding domain, Linker domain, phosphated Trannsactivation domain The tyrosine residue within the C terminus is phosphorylated when the molecule is activated. Tyr phosphorylation is critical for dimerization and nuclear localization. STAT Activation Recruitment of STAT by p-Tyr of receptors by activated JAK and 3. the formation of activated STAT dimers. Phosphorylated STAT dimers translocate into nucleus and activate transcription of specific genes. Specificity of JAK-STAT signaling STAT heterodimers, homodimers, dimers with coactivators/corepressors Conundrum: There are more than 50 different cytokines but only 4 JAKs and 7 STATs. How is the specificity to different cytokines achieved with only few JAKs and STATs? (e.g. IL6, a proinflammatory cytokine, that utilizes gp130, promotes activation of STAT3, while IL-10, an anti-inflammatory cytokine that does not utilize gp130, also activates STAT3.) Specificity of JAK-STAT signaling Heterodimerization of STAT proteins Potential Mechanisms by which STAT heterodimers function Specific interaction between STATs and cytokine receptors Tissue-specific STAT protein expression and STAT heterodimerization Tissue-specific epigenetic modification of chromatin Erythrocytes Mammary gland Epo Receptor Prolactin Receptor JAK activation JAK activation Milk genes STAT5 activation STAT5 activation BCL-XL Transcription of milk proteins BCL-XL Cell survival Production of milk Negative Regulation of JAK–STAT pathway Signaling from cytokine receptors is terminated by the phosphotyrosine phosphatase SHP1 and several SOCS and PIAS proteins. Phosphotyrosine phosphatases: PTPs and N-PTPs. SOCS (Suppressor Of Cytokine Signaling). PIAS (the protein inhibitor of activated STAT). Negative Regulation by Phosphotyrosine Phosphatases Protein tyrosine phosphatases (PTPs) in the cytoplasm (SH2- domain-containing PTP) , such as SHP1, SHP2, CD45, PTP1B, TC45 inactivate JAKs. Nuclear protein tyrosine phosphatases Nuclear protein tyrosine phosphatases (N-PTPs), such as SHP2, PTP1B, and TC45 dephosphorylate of STATs to complete the cycle of activation/inactivation. The unphosphorylated dimer associates with the nuclear export factor, chromosome region maintenance 1 (CRM1), for transport back to the cytoplasm where it can be reactivated. The STATs are stable throughout this cycle. Domain structure of SOCS proteins (Suppressors of Cytokine Signaling) SOCS proteins contain an SH2 domain that is flanked by a variable amino-terminal domain and a carboxy-terminal SOCS box. The SOCS box can bind to elongins B and C, which are known components of a ubiquitin E3 ligase complex. The SOCS family of proteins has eight members: cytokine-inducible SRC homology 2 (SH2) domain protein (CIS) and SOCS1–SOCS7. Negative Regulation by SOCS Proteins SOCS are the target genes of tyrosine phosphorylated STATs; which form a classical negative feedback loop that switches off the activity of JAKs. (1) Binding of SOCS to phosphotyrosine residues on activated receptor or JAK blocks binding of other signaling proteins (such as STATs). (2) The SOCS box can also target proteins such as JAK for degradation by the ubiquitin- proteasome pathway. The domain structure of PIAS proteins (Protein Inhibitor of Activated STAT) PIAS proteins are E3 Sumo-protein ligases and interact with STATs and many other transcription factors. Thus, PIAS proteins act as transcriptional co-regulators. There are four mammalian PIAS genes: PIAS1 PIAS2 PIAS3 PIAS4 Negative Regulation by PIAS Proteins a. PIAS1 and PIAS3 block the DNA- binding activity of STAT dimers. b. PIASX (PIAS2) and PIASY (PIAS4) might act as transcriptional co- repressors of STAT by recruiting other co-repressor proteins such as histone deacetylase (HDAC). c. PIAS proteins can promote the conjugation of small ubiquitin- related modifier (SUMO) to STAT1. JAK-STAT signaling JAK-STAT signaling regulates many cellular processes including: innate and adaptive immune function. Development. cell proliferation, differentiation and apoptosis. The JAK-dependent or –independent STAT tyrosine phosphorylation Tyrosine phosphorylation of STATs can also be stimulated by binding of growth factors to receptor tyrosine kinases (RTKs), such as epidermal growth factor receptor or platelet-derived growth factor receptor. This activation may be direct or indirect. The latter case involves the recruitment of nonreceptor tyrosine kinases (NRTKs) such as Src-family tyrosine kinases. Alternatively, the STATs can be tyrosine phosphorylated in a JAK-dependent manner after hormone- and chemokine- binding to G protein-coupled receptors (also known as seven-transmembrane receptors). Unphosphorylated STAT proteins Recent evidence shows that unphosphorylated STATs can enter the nucleus via importin-α-dependent (STAT2, STAT3) or carrier-independent transport (STAT 1, 3, 5). In unstimulated cells, unphosphorylated STATs (STAT 1, 2, 3, 5) constitutively shuttle between the nucleus and cytoplasm. Unphosphorylated STAT1 and STAT3 have been found to activate transcription by binding to other transcription factors (IRF1 and NF-κB, respectively). Part II: PI-3 kinase pathway Generation of phosphatidylinositol 3-phosphates important in cancers PI-3 kinase (Phosphatidylinositol-3 kinase) PLCg activates PKC via IP3 and DAG PI-3 kinase Class I phosphoinositide 3-kinases (PI3Ks) phosphorylate the 3-hydroxyl group of the inositol ring of phosphoinositide (4,5) bisphosphate (PtdIns(4,5)2) to generate the lipid second- messenger phosphoinositide (3,4,5) trisphosphate (PtdIns(3,4,5)3), which binds to PH (pleckstrin homology) domains of effector proteins, inducing their plasma membrane translocation and activation. PI3K is comprised of two subunits: Regulatory subunit Catalytic subunit Classification and domain structure of mammalian PI3Ks p85 Regulatory p85 Regulatory subunit binds to p-Tyr of RTKs, Cytokine receptors or adaptor proteins and activates the p110 catalytic subunit PI-3 kinase Receptor Tyrosine kinase Cytokine receptor Adaptor Proteins Recruitment and activation of protein kinase B (PKB/AKT) in PI-3 kinase pathways Activation of PI3K triggers diverse cellular responses The PI-3 Kinase Pathway Is Negatively Regulated by PTEN Phosphatase Signaling via the PI-3 kinase pathway is terminated by the PTEN phosphatase. The PTEN (phosphatase and tensin homolog deleted on chromosome 10) gene encodes a plasma membrane lipid phosphatase that is recurrently lost in various human cancers. PTEN phosphatase: the major function: its ability to remove the 3-phosphate from PI 3,4,5-trisphosphate. also it can remove phosphate groups attached to serine, threonine, and tyrosine residues in proteins. Phosphatidylinositol-3,4,5- trisphosphate generation PTEN Phosphatase The PTEN gene is deleted in multiple types of advanced human cancers. The resulting loss of PTEN protein contributes to the uncontrolled growth of cells. Part III: TGF-β receptors and the SMAD signaling pathway TGF-β Superfamily the multipotential cytokine TGF-β was first identified for its ability to induce a malignant phenotype(anchorage-independent growth) in several cultured early stage cancerous mammalian cell lines. Cancerous cells: Loss of contact inhibition of cell growth (cultured in vitro). Colony formation in soft agar(anchorage-independent growth). Tumor formation in vivo. In general, TGF- b signaling inhibits cell proliferation. From Roberts et al., Cancer Research 1981; 41:2842-48 TGF β Superfamily Transforming Growth Factor b (TGF b ) family comprises a large number of secreted and structurally related proteins with multiple roles in all major cell activities including developmental patterning, tissue differentiation and proliferation, and homeostasis. The TGF b family is divided into distinct classes, based on different biological functions: TGF- b (three human isoforms TGF- b 1, 2, and 3), known to potently prevent the proliferation of most normal (non-cancerous) mammalian cells; also to promote expression of cell-adhesion molecules and extracellular-matrix molecules, which play important roles in tissue organization. Bone morphogenetic proteins (BMPs), known to induce the formation of bone and cartilage. Many BMPs are critical for development of many tissues. Activins and inhibins are important for genital development. Mullerian-inhibiting substance (MIS). Structure of TGF β Superfamily TGF-β is produced by many different cells in the body and inhibits growth both of the secreting cell (autocrine signaling) and neighboring cells (paracrine signaling). TGF β Receptor Activation Signaling by all TGF β family members occurs via transmembrane serine/threonine kinases that upon ligand binding form a heteromeric complex of type II and type I receptors. In the canonical pathway, signaling to the transcriptional machinery is transduced by a unique family of intracellular signaling mediators called SMADs. TGF β Receptors I and II are Ser/Thr Kinases TGF-β binds either RII (intrinsic kinase activity) or RIII. Ligand bound receptor RII recruits and phosphorylates RI on Ser/Thr residues. The activated RI phosphorylates SMAD2 or 3. Phosphorylation of SMAD2 or 3 leads to NLS unmasking. Two phosphorylated SMAD2 or 3 proteins bind to SMAD4 with importin- b to form a large cytosolic complex. and After the entire complex translocates into nucleus, the importin dissociates by Ran-GTP protein. TFE3 (a nuclear transcription factor) then associates with Smad2/3/4 complex to form an activation complex which binds to the regulatory sequence of a target gene. This complex then recruits transcriptional co-activators and induces gene transcription. The dephosphorylation of Smad2/3 by a nuclear phosphatase. Smad2/3 recycles through a nuclear pore to the cytosol for the reactivation by another TGF b receptor complex. SMADs SMADs are intracellular proteins that transduce extracellular signals from TGF b ligands to the nucleus where they activate downstream gene transcription. There are three classes of SMAD: The receptor-regulated Smads (R-SMAD): SMAD1, SMAD2, SMAD3, SMAD5 and SMAD8/9. The common-mediator Smad (co-SMAD): only SMAD4 which interacts with R-SMADs to participate in signaling. The antagonistic or inhibitory Smads (I-SMAD): SMAD6 and SMAD7 which block the activation of R-SMADs and Co-SMADs. The SMADs, which form a trimer of two receptor-regulated SMADs and one co-SMAD, act as transcription factors that regulate the gene expression. The domain structure of SMADs and their interactions The C-terminal SSXS motif of receptor-regulated Smads is directly phosphorylated by specific type I receptors. This phosphorylation allows both the association of the receptor-regulated Smads with Smad4 and translocation into the nucleus. N-terminal MH1 domain contains the specific DNA- binding segment and the nuclear-localization signal (NLS).Three serine residues near the C-terminus of R- Smad are directly phosphorylated by activated type I receptors. This phosphorylation induces NLS unmasking and allows both the association of the receptor- regulated Smads with Smad4 through the phosphoserine-binding sites in the MH2 domain and translocation into the nucleus. Negative feedback regulation of TGF- b /Smad signaling pathway Ski and SnoN, inhibiting transcription mediated by the Smad2/3/Smad4 complex. (Ski and SnoN are oncogenes). I-Smad 7, inhibiting Smad activation. TGIF (Transforming growth interacting factor), a potential repressor of TGF b signaling. Model of Ski-mediated down-regulation of Smad transcription-activating function Ski directly binds to Smad4 and P-R-Smads. Binding of Ski disrupts the normal interactions between Smad3 and Smad4 necessary for transcriptional activation. Ski recruits N-CoR, which directly binds to mSin3A; in turn, mSin3A interacts with histone deacetylase (HDAC). HDAC-induced chromatin remodeling and transcription repression. TGF b causes rapid degradation of Ski and SnoN but after few hours, SnoN expression is induced by Smad2/Smad4 complex, which then inhibits the Smad complex. Negative feedback regulation of TGF- b /Smad signaling pathway Inhibitory Smad, Smad7, is a transcriptional target of Smad signaling, which acts in a negative feedback loop to inhibit Smad activation. Smad7 binds to the receptor and blocks the ability of activated type I receptors (RI) to phosphorylate R-Smad; and it also recruits the E3 ubiquitin ligases, Smurf 1/2 (Smad Ubiquitin Regulatory Factors 1/2), to mediate receptor degradation. I-Smads and Smurfs regulate receptor turnover Loss of TGF b signaling plays a key role in cancer development TGF- b signaling generally inhibits cell proliferation. Loss of various components of the signaling pathway contributes to abnormal cell proliferation and malignancy, for example, Inactivating mutations of either TGF b receptors or R-Smad or Smad4 proteins are resistant to growth inhibition by TGF b . Smad4, called DPC (deleted in pancreatic cancer). Mutations in Smad2 in several types of human tumors. loss of type I or type II TGF- b receptors in retinoblastoma, colon and gastric cancer, hepatoma, and some T- and B-cell malignancies. Overexpression of inhibitors of Smad signaling (e.g. Ski, SnoN).","link":"/2021/11/02/LearnNotes/tulane-cellbio-13/"},{"title":"14 Nuclear Receptors|Tulane","text":"Nuclear Receptors I. History of Nuclear Receptor Research II. The Nuclear Receptor Superfamily and Classification III. Structure of Nuclear Receptors IV. Mechanisms of Nuclear Receptor Signaling V. Nuclear Receptors in Health and DiseasesFather of 1966 Nobel Laureate30+ years of nuclear receptor research Evans RM and Mangelsdorf DJ. Cell 2014 157, 255-266Discovery of RXR: the Big Bang in NR research Evans RM and Mangelsdorf DJ. Cell 2014 157, 255-266 Nuclear receptor research: recent topics • Transcriptome and proteome analysis • Crosstalk of nuclear receptor with other signaling pathways: PI3k/AKT, STATs, mTOR, PKA, PKC • Epigenetic regulation of NRs: non-coding RNAs, histone modificication • Non-canonical NRs: mutants, splice variants • Non-genomics actions of nuclear receptors • Therapeutic targeting: SERMs, SARMs, etc Terminology • Ligand: the signaling molecule. It may be a hormone, a growth factor/cytokine, a steroid, a polypeptide, or other type of molecules. The ligand has no activity of its own, it must bind to a macromolecule which is known as a receptor. • Receptor: protein molecules that bind to ligand with high specificity. When activated by the ligand, the receptor induces changes in the target cells/tissues in which it is expressed. • Hormone response element (HRE): the specific motif on the DNA to which the receptor binds. • Dimerization: one protein molecule forms a complex with another, usually via non covalent bonds. The protein molecules can be the same (homodimer) or different (heterodimer). The mode of signaling is determined by the chemical nature of the ligand • Lipophilic or hydrophobic ligands such as steroids can pass through the cell membrane and thus use intracellular receptors. • Hydrophilic ligands such as peptides and growth factors cannot pass through the cell membrane and thus use cell surface receptors. Hormone signaling Nuclear Receptor: Classical Definition Nuclear receptors (NRs) are a family of structurally similar, ligand-activated transcription factors that reside within the cells. Upon binding to ligands, NRs exert their functions in the nucleus and regulate the expression of genes with a wide range of physiological functions, such as embryonic development, cell proliferation, differentiation, metabolism, cell death, etc. Type I Nuclear Receptor (Steroid Hormone Receptors) Including ER, PR, AR, GR, and MR Ligand-dependent transcription factors Unliganded receptors reside in the cytoplasm, form a complex with chaperones (heat shock proteins and immunophilins) After binding to ligands, translocate to the nucleus and bind to DNA as homodimers. Hormone response elements (HREs) are inverted repeats. Steroidogenesis Pathway Adrnal Cortex Aldosterone Stimulates renal reabsorption of Na⁺ and excretion of K⁺. Cortisol Increased Glucongenesis Anti-inflammatory Protein breakdown in muscle Ovary Estrogens Control menstrual cycle Promote development of female secondary sex characteristics. Progesterone Secretory phase of uterus and mammary glands. Implantation of maturation of fertilized ovum. Testes Testosterone Stimulate spermatogenesis Promotes development of male secondary sex characteristics Promotes anabolism Masculinization of the fetus Type II Nuclear Receptor (RXR heterodimers) including receptors for retinoid acid (RAR), vitamin D (VDR), thyroid hormone receptor (TR), and peroxisome proliferator-activated receptor (PPAR) Ligand-dependent transcription factors Unliganded receptors are in the nucleus, bound to DNA in the promoter of target genes, interact with co-repressors, and repress basal transcription bind to DNA as heterodimers with RXR in the presence of ligands, undergo conformational change, dissociate from co-repressors and recruit co-activators HREs are direct repeatsLigands for Type II Nuclear Receptors Ligands for Type II Nuclear Receptors Type I: ERl; AR; GR Type II: RAR; TR; VD thyroid hormones retinoids vitamin D Direct repeats of Type II HREs Same repeat patterns but different length in the insertion: VD3RE:3n RARE:5n Type III Nuclear Receptors (Orphan Receptors) including Rev-Erb, ROR, ERR, NGFI-B, SF-1 In general, are located in the nucleus, bound to DNA and repress basal transcription Activation through signaling pathways or unknown ligands Bind to DNA either as monomers, or homodimers, or heterodimers with RXR Dimeric orphan recptors and monomer orphan recptors Nuclear receptor classification summary Type I Type II Type II Ligands Known Kown Unknown or No Location w/o ligands Cytoplasm Nucleus Nucleus Nuclear translocation Y N N Dimerization Homodimer Heterodimer with RXR Homodimer, Monomer, or heterodimer with RXR HRE Inverted repeats Direct Repreats Direct repeat or half site Structure of Nuclear Receptors translocation Yes No No Dimerization Homodimer Heterodimer with RXR Homodimer, monomer, or heterodimer with RXR HRE Inverted repeats Direct repeats Direct repeat or half siteLecture Outline I. History of Nuclear Receptor Research II. The Nuclear Receptor Superfamily and Classification III. Structure of Nuclear Receptors IV. Mechanisms of Nuclear Receptor Signaling V. Nuclear Receptors in Health and Diseases Domain Organization of Nuclear Receptors A/B → C → D → E → F A/B: N-terinal domain C: DNA binding Domain (DBD) D: Hinge domain E: ligands bindg domain F: C-terminal Sequence homology of Nuclear Receptors DNA binding domain: most conserved one Degree of similarity: DBD &gt; LBD &gt; NTD N Terminal Domain (NTD) Highly variable among NRs. Unstructured or structurally diverse. Type I NRs have large NTDs (400-600 a.a.); Nonsteroid receptors have much shorter NTDs (VDR 24 a.a.) Contains Activation Function -1 (AF-1) domain, which is responsible for ligand-independent activation. AF-1 synergizes with AF-2 in the LBD. NTD is involved in co-regulator recruitment. AR has ~150 co-regulators interacting with AF-1. DNA Binding Domain (DBD) The most conserved domain among NRs. Contains two zinc- finger motifs. Responsible for binding to hormone response elements (HREs). Zinc Finger Motifs in DBD Evidence for role of zinc fingers in receptor function: Site-directed mutagenesis destroys DNA-binding Chelation of zinc in vitro destroys DNA-binding 1 st zinc finger has P-Box (Proximal Box), critical for sequence recognition and contacting the major groove of DNA. 2 nd zinc finger has D-Box (Distal Box), which is involved in dimerization Evans R M Molecular Endocrinology Where are the P-boxes and D-boxes? Hinge domain –K--------RK----RK– Between DBD and LBD, confers flexibility to NRs. Also contains Nuclear Localization Signal (NLS), which is critical for nuclear translocation of Type I NRs. NLS motifs are highly conserved in type I receptors. Ligand Binding Domain (LBD) Moderately conserved among in sequence, but highly conserved in secondary structure. There are 12 α-helices forming the ligand-binding pocket. H12 H3 ligand binding is not static, is dynamic. LBD contains the ligand-dependent activating function-2 (AF-2) domain, which is involved in recruiting coactivators. Positioning of H12 determines the activity of NR NCoA: nuclear receptor coactivator (LxxLL) NCoR: nuclear receptor corepressor (LxxIIxxxL) Ligand-induced conformation change in the LBD Ligand binding leads H12 movement H12 conformation change is used in drug design DES: diethylstilbestrol Fraydoon Rastinejad et al. J Mol Block the movement of the H12, hinder the contact between H12 and ligands. Drug design based on H12 conformation change Mechanisms of Nuclear Receptor Signaling SKey Steps in Type I NRs Signaling • Ligand binding • Receptor dimerization • nuclear translocation • DNA binding • Recruitment of co- regulators (coactivators and corepressors) Chaperones and Co-chaperones for Type I Receptors Stabilize the receptors, preventing degradation Maintain the proper conformation of the LBD to facilitate ligand binding. Play an important role in nuclear translocation of SRs Chaperones maintain the conformation of NRs for ligand-binding Transport of proteins across the nuclear membrane NLS: nuclear localization signal; NES: nuclear export signal LMB: leptomycin B, inhibitor of nuclear export Nucleocytoplasmic Shuttling of Type I Nuclear Receptors Type I NRs cannot diffuse through the nuclear pore complex due to their sizes (&gt; 40 KDa) Nuclear translocation is a tightly regulated process. Depending on the receptor and physiological settings, the nuclear translocation of Type I NRs can be ligand-dependent or –independent. The active transport of NRs always dependents on the presence of nuclear localization signals (NLSs). NLSs of Type I Receptors NTD • Bipartite structure: two clusters of basic amino acids separated by a spacer • The first cluster is in the DBD, the second in the hinge domain • NLS activity is also found in the LBD and NTD Two-step Model for Type II Receptor Activation Nuclear Receptor Co-regulators Chaperones and co-chaperones: Hsp90, Hsp70 Coactivators and corepressors Histone modifying enzymes: HATs, HDACs Recruiters of basal transcription machinery Histone Acetylation/deacetylation by Coregulators Nuclear Receptor Coactivators and Corepressors Steroid Receptor Coactivator Family (SRC-1, 2, 3) Not to be confused with Src kinase! Corepressors: Nuclear receptor CoRepressor (NCoR) Silencing Mediator for Retinoid or Thyroid-hormone receptors (SMRT) Complexity of Nuclear Receptors Signaling Genomic actions Ligand-dependent, HRE-dependent “classical mechanism” Ligand-dependent, HRE-independent “transcriptional crosstalk” Ligand-independent Non-genomic actions Non-genomic to genomic signaling Nuclear Receptors Signaling: multiple modes NUCLEUSRapid effects of hormones Ca 2+ influx and PKC activation: progesterone, aldosterone, VitD3 Vasodilation: estrogen Evidence for Non-genomic Actions of Nuclear Receptors These effects are too rapid (seconds to minutes) to be explained by transcription and protein synthesis These effects cannot be blocked by transcriptional inhibitors (actinomycin D) or protein synthesis inhibitors (cycloheximide) These effects can be elicited by nuclear receptors that lack or have inactive transcriptional activation domains Some effects can be reproduced by using steroid hormones coupled to membrane- impermeable molecules. Membrane associated Nuclear Receptors classical NRs are associated with the membrane in the following manners: tethered to the membrane by palmitoylation (ER, AR, PR) docked in membrane microdomains (caveolae or lipid rafts) in close association with specific G-protein couple receptors (GPCRs) Non-genomic Actions of Nuclear Receptors ERs have been found in caveolae and activate endothelial nitric oxide synthase (eNOS) by phosphorylation Non-genomic actions of ARConvergence of Genomic and Nongenomic actions Convergence of Genomic and Nongenomic actions Nuclear Receptors in Health and Diseases Physiology Roles of Nuclear Receptors Discovery of RXR: the Big Bang in NR research Sites of Androgen Receptor Action Androgen Receptor in Health and Disease Male Sex Development and Reproduction. Androgen Insensitivity Syndrome (AIS). Caused by mutations in AR, leading to truncated receptor or altered ligand affinity. Symptoms are male sexual development is deterred or absent. Kennedy’s Disease. a.k.a. spinal and bulbar muscular atrophy (SBMA), is caused by increased number of CAG repeats in exon 1 of AR. Affected individuals have progressive muscular weakness, cramps and witching in the limbs. Males have testicular atrophy, reduced fertility, and excessive development of the mammary glands. Females are usually carriers. Androgen Receptor in Health and Disease Cancer. Signaling through AR are critical for all stages of prostate cancer, including castration-resistant prostate cancer (CRPC). Mechanisms for AR activation in CRPC have been hot topics of investigation. Also play a role in cancers of the breast, liver, kidney, bladder Brain Development and Behavior. Widespread expression of AR is found in the mammalian brain, playing a role in brain development, e.g. white matter growth during adolescence, brain masculinization. Muscle Growth. Bone homeostasis and Osteoporosis. Immune Function. Maturation of B- and T- lymphocytes. Regulation of glucose metabolism and diabetes. Controls insulin secretion and sensitivity. Sites of Estrogen Receptor Action Estrogen Receptor in Health and Disease Female Development and Reproduction. Skeletal Homeostasis and Osteoporosis. ER regulates bone homeostasis in both male and female. Breast Cancer. Estrogen promotes the proliferation of mammary epithelial cells. Selective Estrogen Receptor Modulator (SERM) and aromatase inhibitors are used in the treatment of breast cancer. Ovarian and Endometrial Cancer. Neuroprotective Effects. Protection against neuro- degenerative diseases, such as stroke, Alzheimer’s Disease, Parkinson’s Disease. Expectations Domain structure of NR and function of each domain Types of NRs Diversity of NR signaling mechanisms Coregulators What type of nuclear receptor? Additional Readings Bain D. et al. Nuclear Receptor Structure: Implications for Function. Annu. Rev. Physiol. 2007, 69:201–20 Bjornstrom L. and Sjoberg M. Mechanisms of Estrogen Receptor Signaling: Convergence of Genomic and Nongenomic Actions on Target Cells. Molecular Endocrinology 2005, 19:833-842. Ronald M. Evans and David J. Mangelsdorf. Nuclear Receptors, RXR, and the Big Bang. Cell 2014, 157:255-266","link":"/2021/11/03/LearnNotes/tulane-cellbio-14/"},{"title":"15 Nuclear Receptors|Tulane","text":"Cell Cycle Cell cycle phases Determining Cell cycle position Synchronous cells Cell cycle: - Grow, replicate, segregate chromosomes; Divide Cycle Phases The fate of a single parental chromosome throughout the eukaryotic cell cycle. Mammalian cell expsaple: G1 = 9, S = 10; G2 = 4.5; M = 0.5 G1 cells monitor environment and dize G2 completion of DNA syntehsis G0 Uncommitted to the cell cycle The cell cycle in yeast takes about 90 min. M phase: Prophase – chromosomes condense, spindle forms, envelope breaks down. Metaphase – kinetochores attach to spindle, chromosomes align. Anaphase – chromosomes separate. Telophase – chromosomes reach spindle poles, decondense chromosomes, spindle breaks down and envelope forms. Monitoring cell cycle position Microscopy Count cell number Hemocytometer Cell counter Viability assay DNA labeling Tritiated thymidine, Br-dU, EdU DNA content Yeast morphology Cell cycle regulated protein and mRNAs Microscopy Microscopy Hemocytometer Whit the cover slip in place transfer a small amount of the cell suspension to the edge often cover slip and allow the chamber to fill by capillary action, Trypan blue (or, Eosin, Propidium) staining can distinguish live from dead cells. Cell Counter Viability assay Basically, viability means how many cells are living. But viability doesn’t tells more. So, there are more specific assays like, apoptosis assay, proliferation assay, and function assay. MTT Assay. Hemocytometer © Abishek Vembadi, et al Cell Counter © acmerevival Viability assay: MTT Assay Principle Water soluble yellow MTT Reduced to purple insoluble formazan by mitochondrial dehydrogenases Water insoluble formazan can be solubilized using isopropanol or other solvents The dissolved material is measered spectrophotometrically yielding absorbance as a function of concentration of converted dye. Mitochondrial Dehydrogenase catalize the Yellow MTT to purple insoluble form © wikipedia Video Protocol: Abnova: MTT Assay; 2010 Why MTT assay: Though dyes like Trypan blue could mark living cell based on the intact cell membrane, but can’t tell which cell are dying. MTT Tetrazolium Reduction Assay, which is a colorimetric assay. Cellular oxidoreductase enzymes reduce the terazolium dye MTT bromide to its insoluble form ozone which has a purple color, quantity was based on the changes in absorbance at 570nm using a spectrophotometer. As a result, it can be used to measure cytotoxicity loss of viable cells or cytostastic activity shift from proliferation to quiesence of potential medicinal agents and toxic materials. Advantage: Fewer steps, uses fewer materials, and does not carry the added burden of radioactive waste disposal. Disadvantages: Not suitable for suspending cells, Must be optimized for seeding amount and assay duration to obtain satisfactory results Precipitated protein and cellular debris present in the cell culture plate wells may interfere with the optical ratings Creative Bioarray[1] MTS: adding into culture media directly. (expensive) MTT, MTS, CCK-8, SRB Significance: Tetrazolium dye reduction is assumed to be dependnet on NAD§H-dependent oxidoreductase enzyme. The sensitivity of the cell group are different from each other. Proliferation cells shall more sensible then because of it’s high metabolic rate.[2] PS: alternative Assay: CCK-8 Not like MTT, which using organic solution and toxic to Cell, which effect the function, reproduction, and change the morphology of the cell, CCK-8 was more temperate.[3] [© Biocompare[3:1] Monitoring cell cycle position Microscopy Count cell number DNA labeling - tritiated thymidine, Br-dU, EdU [3H]thymidine ([3H]dT) © Alvaro Duque, al |© Anthony N. Karnezis, et al| © Alvaro Duque Monitoring cell cycle position Yeast Morphology change © Pierre Delobel, et al © Kathleen Scheffler, et al © Davide Tamborrini, et al Synchronizing cells for cell cycle studies Drugs - Aphidicolin (G1), hydronxyurea(S), nocodazole(M), serum starvation(G1), mimosine Mitotic shake-off Centrifugal elutriation Embryonic cells Yeast Drugs Aphidicolin (G1) hydronxyurea(S), nocodazole(M), serum starvation(G1), mimosine Header One Header Two Aphidicolin Aphidicolin is a tetracyclic diterpenoid first produced by the fungus Cephalosporium aphidicola. This antibiotic is a potent inhibitor of cellular DNA synthesis by targeting α, ε, and δ DNA polymerases in eukaryotic cells lines with little to no effect on β or γ DNA polymerases. Studies have shown that Aphidicolin specifically binds to α DNA polymerase, resulting in the formation of a pol α-DNA-aphidicolin ternary complex that blocks DNA replication. The uses for this compound include synchronized cells at the G1/S boundary and increased gene amplification.[4] Hydronxyurea The therapeutic effect is generally believed to be due to the suppression of ribonucleotide reductase (RNR), which slows DNA polymerase movement at replication forks and induces an S phase cell cycle arrest in proliferating cells.[5] Mitotic shake-off Adherent cells round up in mitosis © Lucy H. Swift, Roy M. GolsteynEmail Many cells round up during mitosis and are less firmly attached to the culture substratum, so that gentle shaking of the culture vessel will detach the mitotic cells. Centrifugal Elutriation © Fredrik B Thorén Synchronization of cells and nuclei is a powerful technique for the exact study of regulatory mechanisms and for understanding cell cycle events. Counterflow centrifugal elutriation is a biophysical cell separation technique in which cell size and sedimentation density differences of living cells are exploited to isolate subpopulations in various stages of cell cycle. This cell separation technique is available since 1948. Centrifugal elutriation offers the advantage that it does not perturb the cell cycle progression; it selects uniformly sized cells, as the cell size generally correlates with cell cycle stage. The major advantage of centrifugal elutriation is that it permits the selection of cells during the whole cell cycle. Among the disadvantages of elutriation, the moderate dispersion of synchrony could be mentioned in fractions collected at the end of the elutriation process, especially in the late S, G2 and M phases. Best synchrony with elutriation is achieved in G1 and in early and mid S phase. Nevertheless, this method is still regarded as one of the best ways of preparing ‘unperturbed’ synchronous yeast cultures for cell cycle studies. Analysis of the DNA distributions after centri- fugal elutriation confirmed that excellent synchrony was obtained with low dispersion throughout the cell cycle. Source: Gaspar Banfalvi What is the evidence for cell cycle control Fuse a mitotic cell with any other cell drives it into mitosis. Fuse a S phase cell with one in G1 – both are in S- incorporate labeled nucleotides. Fuse a G2 cell with one in S – S continues to replicate, but no DNA synthesis in G2 cell. Diffusable factors are the cell cycle engine, which is conserved from yeast to man. Fusing cell??? Oocyte Maturation The oocyte is 4C. What is the DNA content after each step? Step 1 requires protein synthesis How can you use the frog oocyte to assay for MPF??? MPF from yeast to man works in the oocyte injection assay MPF activity in frog development The embryonic cell cycle of xenopus laevis Cleavage without growth- 12 consecutive mitoses – no RNA synthesis Oocyte stockpiles materials for multicellular embryo The frog embryonic cycle is regulated by a biochemical oscillator • Fertilize frog eggs and they divide. • Block spindle assembly with nocodazole – fertilized egg still oscillates. • Block DNA synthesis with aphidicolin – still oscillates. • Inhibit protein synthesis with cycloheximide – embryos will not divide after fertilization. • Oscillation occurs in the absence of a nucleus. • Inhibit protein synthesis and inject MPF – embryos enter mitosis. Downstream events (chromosome decondensation and DNA synthesis) regulated by the destruction of MPF in embryonic cells. Fertilization leads to rapid inactivation of MPF. Identifying the oscillator Why does the cell cycle engine oscillate? Protein degraded at onset of anaphase. Tim Hunt showed that a subunit of MPF had this protein – cyclin B Xenopus egg extract Electrically activate xenopus eggs- prepare extract and add sperm nuclei. Replication occurs, chromosomes condense and nuclei form in cyclic fashion. Inhibit protein synthesis and extract stops cycling. Add antisense RNA to cyclin B – stop cycling. Non-degradable cyclin B mRNA lacks 90 a.a. from N-terminus. Cyclin accumulates before MPF is detected. Accumulate cyclin B to high levels and destroy. Yeast mitotic cycle Yeast must repondto size, food and sex-START. Somatci cells must grow and reach a certain size before division Cycles in 90 mins Grows in simple medium Well-defind genertics Size of bud r lenghth defines cell cycle position Schizosaccharomyces pombe – fission yeast; Saccharomyces cerevisiae – budding yeast. The G2 checkpoint is more prominent in pombe. The fission yeast G1: short S: Relativily short G2: Longest Conditional mutants product fails only under certain conditions. ts mutants unable to grow at restrictive temperature. 35-37 °C: restrictive; 20-23 °C: permissive cdc (cell division cycle) ~70 known arrest at a single point in the cell cycle at the non-permissive or restrictive temp. Discovered by Lee Hartwell. S. pombe grows only in length. Cdc-ts arrests in G2 at nonpermissive temperature. Transfect in library to restore temperature resistant growth. Cdc2 identified by complementation. Cdc13 also required for entry into mitosis. Cdc2 sequence reveals a protein kinase. Wild-type cell division cycle (CDC) genes can be isolated from a S. cerevisiae genomic library by functional complementation of cdc mutants. The budding yeast S. cerevisiae: Antibody to cdc2 immunoprecipitates MPF. MPF is a heterodimer of cdc2/cdc13 with protein kinase activity. Cdc13 has homology to cyclin B. Cerevisiae cdc-28 complements cdc2 mutants. Cdc28 vs Cdc2 Cdc28 mutant blocks cells before S phase-continue to grow, but • 1. Don’t replicate DNA. • 2. Don’t duplicate spindle poles. • 3. Don’t bud.- Defines a point in the cell cycle as START. • G1 checkpoint –nutrients; G2 checkpoint chromosomes. A single protein overcomes G1 and G2 checkpoints. S. pombe grows with a haploid DNA content – selective pressure for G2 arrest. Why? Creative Bioarray, Comparison of Different Methods to Measure Cell Viability, Youtube ↩︎ Wikipedia; MTT assay; 2021 ↩︎ Biocompare, Watch Animation: DOJINDO CCK-8 Assay vs. MTT Assay, 2011, Youtube ↩︎ ↩︎ Aphidicolin; cellsignal.com ↩︎ Xu, Yong-Jie et al. “Hydroxyurea Induces Cytokinesis Arrest in Cells Expressing a Mutated Sterol-14α-Demethylase in the Ergosterol Biosynthesis Pathway.” Genetics vol. 204,3 (2016): 959-973. doi:10.1534/genetics.116.191536 ↩︎","link":"/2021/11/15/LearnNotes/tulane-cellbio-15/"},{"title":"16 Nuclear Receptors|Tulane","text":"Synchronizing cells for cell cycle studies • Drugs – Aphidicolin, hydroxyurea, nocodazole, serum starvation, mimosine • Mitotic shake-off • Centrifugal elutriation • Embryonic cells • Yeast Yeast The yeast mitotic cycle Yeast must respond to size, food and sex-START. Somatic cells must grow and reach a certain size before division. yeast cycles in 90 minutes. Grows in simple medium. Well-defined genetics. Size of bud or length defines cell cycle position. Schizosaccharomyces pombe – fission yeast Saccharomyces cerevisiae – budding yeast. The G2 checkpoint is more prominent in pombe. The fission yeast S. pombe. https://www.youtube.com/watch?v=nhMFxqC89Ac Wild-type cell division cycle (CDC) genes can be isolated from a genomic library by functional complementation of cdc mutants Paul Nurse isolated cdc2 using complementation assays in S. Pombe Also cdc13 Cdc2 sequence reveals a protein kinase. Antibody to cdc2 immunoprecipitates MPF. Cdc13 has homology to cyclin B. MPF is a heterodimer of cdc2/cdc13 with protein kinase activity. ts mutant phenotypes: Wee1 sequence reveals a protein kinase, Cdc25 is a protein phosphatase Change in the amount of cdc2 or a change in the activity? Gene dosage in wild-type cells Genotype Size at mitosis 5 x cdc2 no effect 5 x cdc13 no effect Δwee1 small 3 x wee1 large 5 x cdc25 small Cdc2: Complex with Cycline B, phosphate on Y161. Activating Y14, deactivate CDK1 – human gene complements cdc2 mutant. 65% identical to pombe cdc2. All eucaryotes have a cdc2 gene. MPF required for mitosis – works in the absence of protein synthesis. Gene dosage experiments demonstrate that extra copies of cdc13 don’t control M. How is the activity of MPF controlled? Human cdc2/CDK1 Y-15 phosphorylation inhibits and T-161 phosphorylation activates. Also requires cyclin binding. Targets for MPF? • nuclear lamins A&amp;C (alternative splice products of a single gene) lamin B stays associated with nuclear membrane through isoprenylation. • SMC (structural maintenance of chromosomes) proteins, which form condensin, a multi-protein complex. Addition of an anti- SMC antibody to xenopus extracts prevents DNA condensation and association of sister chromatids. • SMC must be phosphorylated to wind DNA into supercoils. SMC is also a component of cohesin, which holds sister chromatids together at the centromere. Another component of cohesin is Scc1, a target for separase. The nuclear lamina and its regulation by phosphorylation Polo and aurora kinases Remove cohesins from arms Separation of chromosomes Cdk-cyclin B phosphorylation promotes APC/C-cdc20 interaction. In the transition from metaphase to anaphase the Scc1 (sister chromatid cohesion protein1) subunit of cohesin is degraded by separase, a caspase-like protease. Ubiquitination of securin, a separase inhibitor, is directed by cdc20-APC-starts onset of anaphase. Attachment of last kinetochore activates securin destruction. Exiting Mitosis Ubiquitin linked to cysteine on E2 transferred to lysine of target MPF must be inactivated for cells to exit mitosis. MPF activates ubiquitin conjugation of cyclin B. 9 a.a. destruction box. Cyclin B must be cdc2 associated to be degraded. Anaphase Promoting Complex (APC) activated by MPF-promotes APC-cdc20 interaction. Inactivated by G1 cyclin-CDK. Required for entry into anaphase and exit into G1 APC substrates stable in S, G2 and M. Unstable metaphase to anaphase and in G1. APC orders mitosis. How? Regulation of S phase and mitotic cyclin levels Cdh1-APC degrades cyclin to exit anaphase. Cdh1 inhibited by MPF. Describe Cdk1 activity during the phases of mitosis. Cdh1 is hct1 in pombe. After chromosomes segregate cdc14 is activated –released from sequestration by a GTP-binding protein. Cdc14 also induces transcription of SIC1. The embryonic cell cycle of xenopus laevis Cleavage without growth- 12 consecutive mitoses – no RNA synthesis Oocyte stockpiles materials for multicellular embryo What signal does cdc14 respond to? Chromosome separation in anaphase activates cdc14. Cdc14 is a phosphatase that targets cdh1 Ordering Mitosis APC/C 13 subunits in yeast. CyclinA-GFP fusion protein demonstrates it is the first substrate of APC/C. If cyclin A can’t be degraded, unable to initiate anaphase. APC/C-cdc20 ubiquitinates securin leading to its degradation and activation of separase which degrades Scc1 in the transition from metaphase to anaphase. Cdc14 activates APC/C-cdh1 to degrade cyclin Cdc20 is a substrate for APC/C-cdh1. How does this affect activity? Mitotick Checkpoint Cdc28 vs cdc2 Sic→↑↑↓ 17 let’s see what cat we record Page1 Markers of the CDK kinase domain Page2: Classify: A type cycline, D type cycline Page3: Predicted Cyclin-binding elements Page4: Cdk 7 and 8 involved in transcription Page5: Elaborate explained table Page6: Graph: mammalian cell, gg roal? CyclinD starte close serum Discrib the S phase by the information from previous table. CDK2 + Cyclin E and A resbonsible to the entry of the S phase. P7: ||Vertebrates |Budding yeast| Cyclin-cdk complex cyclin cdk Cyclin cdk G1-cdk D Cdk4 &amp; cdk6 Cln3 cdc-28 G1/S cdk E Cdk2 Cln1 &amp; cln2 cdc-28 S-cdk A Cdk2 Clb 5 &amp; clb 6 cdc-28 M-cdk B Cdk1 Clb1,2,3,4 cdc-28 P8: CAK → CDK7 → tf2b tf2h TF2A form complex to Wee1 Kinase → Inhibits CAK Cdc25 phosphatase Cdc25A (Virtbrates) Cdc25C (Virtbrates) ATM/ATR kinase Chk1/Chk2 kinase P15: IRES: internal ribosome entry site Oncogenic Viruses Viruses Simple obligate intracellular parasites of plants, animals, and bacteria. Target to the cell surface receptor. Consist essentially of a core of RNA or DNA surrounded by a protein coat. Either DNA or RNA, not both Attach, penetry, inject, replication, assembly, release Replication involves disassembly and reassembly Tumors Tumor: An abnormal benign or malignant new growth of tissue that possesses no physiological function and arises from uncontrolled usually rapid cellular proliferation. Classification: Aggression behaviors Benign tumor Malignant tumor (a.k.a. Cancer) Location of the tumor Carcinoma (epithelial origin) Sarcoma (mesenchymal origin/connective tissues) Others (lymphoma, leukemia, melanoma, and etc.) Oncogenic Virus (tumor virus): A virus capable of causing transformation of cells, inducing a neoplasia in its host or causally linked to human tumors. General criteria for oncogenic viruses The virus or part of its genome should be closely associated with the oncogenic disease (e.g., should be present in tumor tissues). The virus should persist throughout the disease. A prospective study should show that infection with the virus precedes disease. Prevention of virus infection (e.g., by vaccine) should prevent disease. Why has the study of oncogenic viruses been important? It’s estimated that ~20% of human cancers in the world are caused by infection, of which 10-15% are caused by oncogenic viruses. In the past, research on oncogenic viruses led to the discovery of key cellular tumor suppressor proteins (e.g. p53) and general pathways involved in tumor development. Studies of SV40 led to the discovery of tumor suppressor p53 DIscovery of p53 AgT → 53kDa protein interacted with AgT, which functoin as tumor suppressor. Why has the study of oncogenic viruses been important? It’s estimated that ~20% of human cancers in the world are caused by infection, of which 10-15% are caused by oncogenic viruses. In the past, research in oncogenic viruses led to the discovery of key cellular tumor suppressor proteins (e.g. p53) and general pathways involved in tumor development. It can help us to identify potential diagnostic/prognostic markers and therapeutic targets for virus-mediated tumors. Human oncogenic viruses DNA tumor viruses: Small DNA tumor viruses Human papillomavirus (HPV) Simian virus 40 (SV40) Merkel cell polyomavirus (MCV) Adenovirus Complex DNA tumor viruses Epstein-Barr virus (EBV) Kaposi’s sarcoma-associated herpesvirus (KSHV) Hepatitis B virus (HBV) RNA tumor viruses: Oncogenic retroviruses Human T-cell lymphotropic virus-1 (HTLV-1) Human T-cell lymphotropic virus-2 (HTLV-2) non-retroviruses Hepatitis C virus (HCV) Why and how do oncogenic viruses cause tumors Genetic basis of cancer Loss of growth control: Genes (i.e. oncogenes) that are stimulatory for growth are hyperactive. Genes (i.e. tumor suppressor genes) that inhibit cell growth are turned off. Generally, oncogenic viruses either carry a copy of oncogenes or can alter expression of the cell’s copy of these genes. Why do oncogenic viruses want to disrupt growth control? It’s viruses’ way to fight against the host defense system and to meet their needs for replication and continuation of their species. Oncogenic viruses might accidentally cause tumors, since killing your host is a poor way to ensure your survival even if he/she is trying to kill you. Human oncogenic viruses DNA tumor viruses: Small DNA tumor viruses: Human papillomavirus (HPV) Simian virus 40 (SV40) Merkel cell polyomavirus (MCV) Adenovirus Small DNA tumor viruses need to hijack the host DNA, RNA, and Protein synthesis systems. Complex DNA tumor viruses Epstein-Barr virus (EBV) Kaposi’s sarcoma-associated herpesvirus (KSHV) Hepatitis B virus (HBV) Human papillomavirus (HPV) More than 150 subtypes identified based on the genetic sequence of viral L1; can infect skin (~60 types) or mucosal surfaces (~40 types). HPV is the most common STI in U.S. 16 High-risk HPVs (HR-HPV) are detected in 99% of cervical cancers. HPV- 16 and -18 cause &gt;70% of cervical cancer cases. Associated with benign papillomas (warts) and carcinomas including cervival, vulvar, vaginal, anal, penile, and head &amp; neck squamous cell carcinoma. Vaccines: HPV4 (Gardasil) targets HPV6,11,16,18) for females/males. HPV2 (Cervarix) targets HPV16,18 for females. Circular, double-strand DNA virus, ~8Kb genome. Viral genes: E1, E2: early regulatory protein E5, E6, E7: early oncoprotein L1, L2: late structural capsid protein Human papillomavirus life cycle Effect Skin and … Four layer of the skin, baskm suprbasalm granular, cornifierd. HPV first infect the basal layer and then, transferred to other layer. DIfferenct layers express HPV gene differently because the transcription factors are different from layer to layer Human papillomavirus (HPV) Integration and abortive replication Abortive replication: when a virus infects a cell (or host), but cannot complete the full replication cycle, i.e. a non-productive infection. Some gene was deleted and the replication aborted. Mode of transformation: HPV E6 and E7 StepA: E7 prohebite RB, which free E2F1 and causing the proliferation StepB: E7 bind p27 which regulate the CDK2/CyclineE StepC: E7 bind to p21 Simian virus 40 (SV40) SV40 was first isolated as a contaminating virus in rhesus macaque monkey cells used to grow the early versions of the polio vaccine developed in the late 1950s. 30 millions of vaccine recipients in U.S. accidentally received vaccine doses with low to high titers of the SV40 between 1955 and 1963. SV40 can induce tumors including primary brain cancers, malignant mesotheliomas, bone tumors, and systemic lymphomas in test animals. Simian virus 40 in human malignant disease In 2002, the National Academy of Sciences Immunization Safety Review committee that stated, &quot;The committee concludes that the biological evidence is moderate that SV40 exposure could lead to cancer in humans under natural conditions.” In 2004, the National Cancer Institute announced that “substantial epidemiological evidence has accumulated to indicate that SV40 likely does not cause cancer in humans”. In 2006, new evidence indicated that SV40 is involved in the development of peritoneal and pleural mesothelioma in human. Simian virus 40 (SV40) Belongs to polyomavirus family. Nonenveloped, circular dsDNA genome, 5kb in size. Genome is divided into early and late regions. Oncogene: Large T (tumor) antigen. SV40 large T-antigen TAg bind to the pRb → Rb degnation TAg bind to p53 Paper Discussion Merkel cell polyomavirus (MCV) Feng H, Shuda M, Chang Y, Moore PS. Clonal integration of a polyomavirus in human Merkel cell carcinoma. Science. 2008 Feb 22;319(5866):1096-100. PubMed PMID: 18202256. Shuda M, Feng H, Kwun HJ, Rosen ST, Gjoerup O, Moore PS, Chang Y. T antigen mutations are a human tumor-specific signature for Merkel cell polyomavirus. Proc Natl Acad Sci U S A. 2008 Oct 21;105(42):16272-7. PubMed PMID: 18812503. Adenovirus Linear, non-segmented dsDNA genome. 7 groups, 57 serotypes in humans. Associated with respiratory disease, conjunctivitis, and gastroenteritis. Certain adenovirus subtypes can transform mammalian cells (e.g. adenovirus group c serotype 5). Adenovirus mediated oncogenesis Oncogenes: E1A E1B Oncogenesis mediated by small DNA tumor virus In benign lesions induced by the small DNA tumor viruses, viral genomes are typically maintained extrachromosomally. Malignant progression is often associated with viral integration into host cell chromatin. Integration usually leads to abnormal expression of early genes. Early genes promote cell cycle progression and prevent apoptosis. HPV - E7 (cell cycle) and E6 (apoptosis) SV40 - T Ag (cell cycle and apoptosis) Adenovirus - E1A (cell cycle) and E1B (apoptosis) Human oncogenic viruses DNA tumor viruses: Complex DNA tumor viruses Epstein-Barr virus (EBV) Kaposi’s sarcoma-associated herpesvirus (KSHV) Hepatitis B virus (HBV) Epstein-Barr virus (EBV) EBV belongs to human herpes virus family (a.k.a. HHV-4). Infect &gt;90% of the adult population in U.S (EveryBody’s Virus). Infect lymphocytes and epithelial cells. Transmitted by saliva. Generally, don’t need to integrate. Cause lymphoma in Marmosets and transform human B-lymphocytes in vitro. EBV in human diseases Malignant diseases: Burkitt’s lymphoma in the tropics, where it is more common in malaria-endemic regions. Nasopharyngeal carcinoma, particularly in China and southeast Asia, where certain diets may act as co-carcinogens. B cell lymphomas in immune suppressed individuals (such as in organ transplantation or HIV). Hodgkin’s lymphoma in which it has been detected in a high percentage of cases (about 40% of affected patients). Non-Malignant diseases: Infectious mononucleosis (a.k.a. kissing disease, glandular fever) Autoimmune diseases including dermatomyositis, systemic lupus erythematosus, rheumatoid arthritis, and multiple sclerosis. Epstein-Barr Virus (EBV) Enveloped, linear dsDNA genome in virions; circular dsDNA in host cells. ~171kb genome. Latency genes and lytic genes. EBV life cycle There are 2 stages in EBV’s life cycle: latency and lytic replication (reactivation). Latency: viral persistence. Lytic replication: production of new infectious virions. EBV Encodes its own polymerases and don’t need S-phase environment for replication. EBV latency programs EBV latent genes EBNA2 and LMP1 are absolutely required for EBV-mediated transformation of B cells. EBNA-LP, EBNA3A and EBNA3C play a critical role in the transformation process. EBV Nuclear Antigen 2 (EBNA2) First virus protein expressed after infection of B cells. Plays a pivotal role in B cell immortalization. Transcription factor, regulate the expression of viral LMP1 and LMP2 as well as cellular oncogene c-Myc. Latent Membrane Protein 1 (LMP1) Classical oncogene (transgenic mice expressing LMP1 alone in B cells develop lymphomas). Acts as constitutively activated tumor necrosis factor receptor (TNF-R) CD40. Inhibits apoptosis by upregulating BCL2 and A20. Activates NF-kB pathway and JAK/STAT pathway. EBV Nuclear Antigen 3C (EBNA3C) Essential for B-cell transformation in vitro. Cell cycle regulator. Kaposi’s sarcoma-associated herpesvirus (KSHV) Discovered in 1994, belongs to the herpes virus family (a.k.a. HHV-8). ~10% of the general population has been infected in U.S. Transmitted through sexual contact and organ transplantation. Causes Kaposi’s sarcoma, body cavity-based lymphoma, and Castleman’s disease. Enveloped dsDNA genome. Latency and lytic replication. Molecular piracy (molecular mimicry). Major latent genes: LNA-1, v-cyclin, and v- FLIP. Regulation of cell cycle by KSHV LNA-1 and v-Cyclin LNA1 → RB; p53; Ring3 Hepatitis B Virus (HBV) Belongs to Hepadnavirus family. Circular Partially dsDNA genome. Causes hepatitis B, cirrhosis, and hepatocellular carcinoma. HBV mediated oncogenesis Mechanism is not clear. Integration disrupts oncogene or tumor- suppressor genes. Hepatitis B virus X (HBx) protein. Targeted therapies for EBV-associated malignancies T-cell-based adoptive immunotherapeutics for EBV-associated malignancies","link":"/2021/11/30/LearnNotes/tulane-cellbio-16/"},{"title":"2 Membranes|Advanced Cell Biology|Tulane","text":"Proof Reading: Haoyang Liang Overview A cell is a membrane-rich environment Classes of lipids Structure of lipids Polymorphic phase behavior of lipids The lipid bilayer membrane The fluid mosaic model of biological membranes Classes and functions of membrane proteins Receptors Hydropathy plots Terminology phospholipid bilayers: amphipathic: hydrophobic tial and hydrophilic head micelles; liposomes; sheet-like phospholipid bilayers Function Selective Barrier Surround cells to hold enzymes and metabolites inside Cellular Compartmentation: surround organelles Contain Enzyme Systems–energy metabolism (oxidative phosphorylation, photosynthesis, etc.) Contain Transport Systems–bring food molecules inside and maintain ion concentrations Contain Specific Recognition Sites–for hormones, etc. PS: Reaction Facility: Enzyme Working on a 3 dimension, -&gt; with the membrane, bring things to 2 dimensions to facilities the interactions and reactions. protein helps to transport the materials. hydrophobic substrate; recognition: Glycolipids / Glucoportein Composition Lipids – lipid bilayer creates a hydrophobic barrier mostly phospholipids but also glycolipids (contain carbohydrate) and steroids (cholesterol). Lipid bilayers form a barrier to the diffusion of hydrophilic molecules. Proteins – confer specificity peripheral membrane proteins bound to bilayer surface integral membrane proteins – intrinsic structural parts with hydrophobic and hydrophilic domains ===&gt; amphipathic glycoproteins (integral) contain covalently bound CH2O which may be very complex ===&gt; cell surface receptors? e.g. glycophorin–MW 30,000 with 130 aa’s and 60% CH2O Exceptions: drugs which specifically designed to cross membrane to deliver the chemicals., hydrophilic for solving hydroponically for crossing the membrane The relative amounts of lipid and protein vary from one membrane type to the next, but the basic structures of all of these membranes are similar. Membrane Lipid Protein Myelin Sheath 80% 20% Plasma Membrane 50% 50% Mitochondrial Inner Membrane 25% 75% The ratio of the L/P of the membrane serves its function. Structural of lipid Phospholipids Hydrophilic head Hydrophobic tail Saturated tail/Unsaturated tail Unsaturated tail: Decreases the Van de Waal interaction by increasing the distance of the lipid tail. increases fluidity. Cholesterol Abundant in mammal’s cell but lack in prokaryotic cells. Maintain the fluidity and rigidity of the cell membrane[1] Modulating the physical property of the membrane. Large spacial molecular, decreasing fluid-ability increasing the order of the membrane Lipid Bilayers Free rotation and diffusion in 2-dimensions Micelle Vesicle Classes Fatty acid (e.g. palmitate, oleate) Energy storage metabolite Building block of other lipids Triacylglycerols (fat) Energy storage Glycerophospholipids Form lipid bilayer membrane Signal transduction Sphingolipids Form lipid bilayer membranes Signal transduction Steroids Rigidify membranes (Cholesterol) Membrane-crossing hormones (e.g. Estrogen) Non-pivotal: classification: head Tail “Fluid Mosaic” model of biological membranes © Veronika Novotná, et al. “The membrane (is) a two-dimensional liquid-like solution of protein dissolved in the lipid bilayer” Cite: Singer SJ, Nicolson GL The fluid mosaic model of the structure of cell membranes Science 1972; 175(23):720-3 Membrane Composition Asymmetry of the membrane composition in phospholipid, protein, and sterol. Integral Membrane Proteins α-spin in the interior of the bilayer, = = two known structural motifs in membrane $\\beta$-barrel Outer membrane Mitochondria membrane E. Coli Outer Membrane Protein A (OmpA) an 8-stranded β-barrel. Known variation: 8-22 strands. About 2-4% of genome of Gram negative bacteria. Less than 1% of mitochondrial proteins Helical Bundle rich in eukaryotic cells. Bacteriorhodopsin (mitochondrial), a 7-helix helical bundle protein. Known variation 1-22+ helices. About 25% of the proteins of ALL known genomes are helical membrane proteins. Classes of Helical Type I and II -&gt; opposite in direction I: Out -&gt; inner (N -&gt; C) II: Out -&gt; inner (C -&gt; N) Type III: single back-forward (snake-like) Type IV: a cluster of multiple bundles Type V: no-helix with lipids Type VI: helix + lipid(s) linkage FRAP FRAP - Fluorescence Recovery after Photobleaching A technique used to measure protein diffusion in membranes. FRAP uses a fluorescence microscope to measure the diffusion of molecules into a photobleached spot in a membrane. A membrane component can be freely diffusing, coralled or immobile Functional Classes Enzymes - catalyze reactions with lipid soluble substrates Channels/pores - Allow molecules to move across membranes Transporters - Pump molecules across membranes Toxins - Permeabilize membranes to kill cells Binding Proteins - Regulation, stabilization/destabilization, activation/deactivation, signal transduction Anchors - Attachment point for cell-surface carbohydrates or for cytoskeletal proteins Transporters Some types of protein mediated transport across membranes. Symporters and antiporters can pump one of the solutes against a concentration gradient Some uniporters use metabolic energy to pump solutes against a concentration gradient. Others only allow the flow of solutes down a concentration gradient. Receptors A membrane-spanning receptor transduces chemical signal across membranes Some broad classes: Channel receptors (Acetylcholine receptor) Tyrosine Kinase (Insulin, growth factor) G-protein coupled (adrenergic, rhodopsin) G-protein coupled receptors all belong to a widespread class called 7TM receptors because they have 7 membrane-spanning helices. The C2 Domain sterols provide structural support to membranes, preventing too close a packing of the phospholipids’ acyl chains to maintain a significant measure of membrane fluidity, and at the same time conferring the necessary rigidity required for mechanical support. 2. Cholesterol restricts the random movement of phospholipid head groups at the outer surfaces of the leaflets, but its effect on the movement of long phospholipid tails depends on its concentration. At the cholesterol concentrations normally present in the plasma membrane, the interaction of the steroid ring with the long hydrophobic tails of phospholipids tends to immobilize those lipids and thus decreases biomembrane fluidity. It is this property that can help organize the plasma membrane into discrete subdomains of unique lipid and protein composition. At lower cholesterol concentrations, however, the steroid ring separates and disperses phospholipid tails, causing the inner regions of the membrane to become slightly more fluid. [Molecular Cell Biology, 8th, Harvey Lodish, et al.] ↩︎","link":"/2021/08/26/LearnNotes/tulane-cellbio-2/"},{"title":"4 Cytoskeleton|Advanced Cell Biology|Tulane","text":"Cytoskeleton Type Intermediate filament; microtubule; Actin filament Geometry of the cell Fix the position of organelles Moves the compounds (cargos) Facilitate movement of the whole cells Cytoskeletal Element Diameter Composition Microfilament (MF) thin (6-7nm) Actin+ associated protein Microtubules (MT) tubular structures (25nm) tubline + associated proteins Intermediate filaments (IF) rope-like fibers (~10) No associated proteins Actin and Microfilaments G-actin Highly globular protein F-actin Polymerizes into microfilaments (exhibits polarity) Filaments stabilized by other proteins Polymerization Requires nucleation (activation) 3 actins Elongation primarily at “+” end (barbed end) ATP/ADP G-actin has bound ATP ADP-actin more likely to dissociate Actin-binding proteins monomer sequestration (profilin) trimeric G-proteins Celluar regulation hro family (ras-like G-proteins) trimeric G-proteins Drugs cytochalasins (prevent assembly) phalloidin (prevent disassembly) $$ G-actin \\to F-actin $$ Nucleation factors Initial dimer and trimer formation is energetically unfavorable. Assemble automatically is unfavorable Tandem monomer-binding nucleators bring together actin monomers through tandem G-actin-binding motifs to form an actin nucleus. Tandem: initial a pointed end (-) A formin FH2-domain dimer associates with the barbed end of an actin filament and the FH1 domains recruit and deliver profilin-bound actin to the barbed end. Formins helping elongate by binding the barbed ends Arp2/3 with NPF (WASp) nucleates a new filament from the side of an existing filament, causing branching at a 70°angle. Arp2/3 for forming a branch Examples of Actin-Binding Proteins Tight bundles Loose bundles 3-D Gels Dick shape fimbrin alpha actinin filamin Spectrin (Red blood cell) Actin Microfilament (MF) Bundles Tight bundles (e.g., microvilli) MFs having the same polarity (+) ends point toward the microvillus tip Fimbrin bundling proteins Two ABD of the monomer holding two MFs together Loose bundles (e.g., contractile ring); which could interacted with myosine MFs loosely spaced for myosin binding for contraction α-actinin bundling proteins Two ABD of the dimer holding two MFs together Actin Microfilament (MF) networks Filamin is a dimer Forming a flexible V-shaped molecule Crosslinking MFs into orthogonal networks Submembrane cortical MF in RBC RBC spectrin, a tetramer of α and β chains Two chains join laterally to form a dimer and head-to-head to form a tetramer ABDs of the β chain are separated by ~200 nm Spectrins associate with short MFs (yellow ball) to form the network. Protein 4.1 (pink) links MFs to PM-embedded glycophorin Ankyrin (green) links spectrins to PM-embedded Band 3 Stress Fibers at Focal Adhesions Focal adhesions: ECM attachment regions of the cell Stress fibers: α-actinin-linked contractile bundles of MFs Attached to the plasma membrane at focal adhesions via interactions with integrin. Mediated by talin and vinculin Talin and α-actinin bind to the cytoplasmic domains of integrins. (out cell) Talin also binds to vinculin, which in turn interacts with actin. (inner cell) MFs at Adherens Junctions Adherens junctions are regions of cell-cell contact. In epithelial cells, the AJs form a belt-like structure Contractile bundle of MFs is linked to the PM MFs associate with cytoplasmic α/β catenins (connect to Cadherins), which form a complex with PM-embedded cadherins Cadherins (membrane protein) mediate contact between cells Myosin and Force Generation (in loos connection) large family of proteins (16) actin-activated ATPase converts chemical energy into mechanical energy Cell Locomotion-1 Step 1: Movement begins with extension of one or more lamellipodia from the leading edge of the cell. Step 2: Some lamellipodia adhere to the substratum via focal adhesions. Step 3: Then the bulk of the cytoplasm in the cell body flows forward. Step 4: The trailing edge of the cell remains attached to the substratum until the tail eventually detaches and retracts into the cell body. Proline leading the actin assembly Cell Locomotion-2 What propels the membrane forward? The polymerization of actin filaments at the (+) end, stimulated by profilin located at the leading-edge membrane, pushes the membrane outward. Vasp (MF elongator) and Arp2/3 may participate in directing assembly. Myosin I links actin filaments to the leading-edge plasma membrane Arp2/3 and actin cross-linking proteins stabilize the actin filaments into networks and bundles. Cofilin induces the loss of subunits fromthe (−) ends of filaments. Microtubules (MT) © Linda A Amos Major Roles: Mechanical/Cell Shape in Cilia(lung)/Flagella(bone) Mitotic Spindle (divide) Tubulin: highly conserved heterodimer (α, β) in vivo MT assembly starting from MT organization center 13 β subunits on the top only. two subunits (one unit) added at a time Microtubule Organizing Center (MTOC) Centrioles of animal cell aka basal bodies of flagella Barrel-shaped (triplets of MT) Centrosome of plant cell Amorphous protein matrix + two centrioles Organizes cytoplasmic MT array Forms spindle poles during cell division in animal Spindle pole bodies of fungi Not contain centrioles Located on nuclear membrane Forms mitotic spindle in many lower eukaryotes γ-Tublin and MT Nucleation γ-Tublin: nucleation center MT nucleation in vivo requires γ-tubulin and associated proteins (γTu ring complex) Caps minus end Anchored near MTOC Tubulin α/β-dimers added to plus end Flagellar Movement-1 © Linda A Amos Axoneme cytoskeleton of cilia and flagella Nine outer doublets MTs A central pair of singlet MTs A and B tubules in each MT doublet 13 protofilaments in A tubule 10 protofilaments in B tubule Inner and outer dynein arms in A tubule Flagellar Movement-2 Sliding forces generated by dynein arms: The dynein arms on the A tubule of 1st doublet “walk” along the adjacent 2nd doublet’s B tubule toward its base, the (−) end, moving the 2nd doublet toward the (+) end. Flagellar Movement-3 Axonemal bending: Each doublet slides down only one of its two neighboring doublets, Active sliding in a portion of the axoneme produces bending toward one side Active sliding in the opposite portion produces bending toward the opposite side. Motor Proteins MF associated myosin MT associated dynein cilia/flagella cytoplasmic Kinesin © Jason Duncan Kinesins © Chapin Korosec Large superfamily of proteins (45) defined by ‘motor’ domain Tail regions are highly divergent (cargo binding function) Chemomechanical cycle similarities to myosin two motors needed (?) Structure: Moto Domain Stalk Region Tail region μT binding ATPase Coiled-coil accessory proteins specific functions Kinesins in Mitosis Reorganization of MT during mitosis disassembly of cytoplasmic MT assembly of spindle apparatus Duplication of centrosome to initiate spindle apparatus formation Several kinesins implicated separation of poles migration of chromosomes Intermediate Filaments © Douglas Fudge, et al. Rope-like fibers extending from nucleus periphery Extremely stable resistant to detergent extraction Only in metazoa Subunits are part of large multigene family related to nuclear lamins tissue specific expression GFAP: Glial fibrillary acidic protein Intermediate Filament Proteins α-helical rod domain C-terminus domain IF protein types distinguished by N- and C-termini Central region composed of heptad repeats Forms coiled-coil structure (a-helices that twist around each other) IF Proposed Structure Tetramer believed to be fundamental subunit Mechanism of assembly and disassembly not known Form stable structures $\\to$ mechanical support IF Role in Mechanical Support abundant in cells/structures under mechanical stress (e.g., epithelial, muscle) links to membranes and other cytoskeletal elements digraph F { rankdir = \"LR\" node [style=filled, font=Courier, color = \"salmon\", shape = \"box\"]; A [label=\"Lamellipodia\\nFormation\"] B [label=\"Focal Adhesion\\nDormation\"] C [label=\"Cytoplasm\\nTransportation\"] D [label=\"Old Focal\\nAdhesion Detach\"] A -> B -> C -> D } var viz = new Viz(); var code = document.getElementById(\"graphviz-0-code\").value; viz.renderSVGElement(code) .then(function(element) { document.getElementById(\"graphviz-0\").append(element) });","link":"/2021/09/16/LearnNotes/tulane-cellbio-4/"},{"title":"3 Extracellular Matrix Adhesion|Advanced Cell Biology|Tulane","text":"Cell-Cell and Cell–Extracellular Matrix Adhesion In introduction: Cells are actually living in an extracellular material which does not also supply an environment, but also signal contact the cell. cell-adhesion molecules (CAMs) Major types of CAMs cadherins immunoglobulin (Ig) superfamily integrins selectins Fibroblast; Tropoelastin; Ground Substance; Tropocollagen EMC Components Fibrous Proteins Collagens Elastins Keratins Hydrated Gel (highly sulfide, highly charged carbohydrate molecules) Hyaluronic acid Proteoglycans Multiadhesive Matrix Proteins (two binding sites: matrix components and cell-surface) Fibronectin (One site to the binding matrix, another side bonds to Cells.) Laminin Others Cells Fibroblasts and mast cells in loose connective tissue Epithelial and endothelial cells in basal lamina Specialized cells make specialized ECM (chondrocytes/cartilage; osteoblasts/bone; keratinocytes/skin) Ps: All ECMs are composed of hydrate gel either Hyaluronic acid/Proteoglycans, which are highly sulfate and Carbohydrates to create a highly charged environment and attract lots of water. It could also be attached by proteins. Functions of the extracellular matrix Scaffold for cells A barrier to migration (infection, metastasis) Reservoir for growth factors Signals to the cell interior during morphogenesis wound healing, and maintenance of the differentiated state Collagen © Molview; PDBID=1bkv; Collagen Structure Most abundant Gly-X-Y X: mostly was Proline Y: mostly was hydrophilic amino acid. Type I is called Tropocollagen long halve life Glycines are in the center of the 3 single right-handed α-helix strings coiled fiber. Structure disruption: Ala replacing Gly causing the deformation of the collagen and cause the “brittle bone”. Biosynthesis Collagen was synthesis in the cell but had additional post-translation modification outside of the cell. In cell Rough ER Rough ER translation Signal peptide cleavage Hydroxylation of selected prolyl and lysyl residues addition of N-linked oligosaccharides Golgi Glycosylation of hydroxylysine residues Chain alignment, formation of disulfide bonds Formation of triple helix procollagen Cytoplasm Transport vesicle Exocytosis It keeps the collagen aggregation outside of the cell Out of cell Removal of N- and C-terminal pro-sequences Lateral covalent cross-linking of tropocollagens aggregation of fibrils Structure of Collagen Genes A lot of post-translation splicing and modification leads to a lot of genetic diseases. Gly-X-Y pattern Whole fasta file: Collagen alpha-1(VII) chain 1260 bp ~ 2783 bp GEMGLRGQVGPPGDPGLPGRTGAPGPQGPPGSATAKGERGFPGADGRPGSPGRAGNPGTPG APGLKGSPGLPGPRGDPGERGPRGPKGEPGAPGQVIGGEGPGLPGRKGDPGPSGPPGPRG PLGDPGPRGPPGLPGTAMKGDKGDRGERGPPGPGEGGIAPGEPGLPGLPGSPGPQGPVGP PGKKGEKGDSEDGAPGLPGQPGSPGEQGPRGPPGAIGPKGDRGFPGPLGEAGEKGERGPP GPAGSRGLPGVAGRPGAKGPEGPPGPTGRQGEKGEPGRPGDPAVVGPAVAGPKGEKGDVG PAGPRGATGVQGERGPPGLVLPGDPGPKGDPGDRGPIGLTGRAGPPGDSGPPGEKGDPGR PGPPGPVGPRGRDGEVGEKGDEGPPGDPGLPGKAGERGLRGAPGVRGPVGEKGDQGDPGE DGRNGSPGSSGPKGDRGEPGPPGPPGRLVDTGPGAREKGEPGDRGQEGPRGPKGDPGLPG APGERGIEGFRGPPGPQGDPGVRGPAGEKGDRGPPGLDGRSGLDGKPGAAGPSGPNGAAG KAGDPGRDGLPGLRGEQGLPGPSGPPGLPGKPGEDGKPGLNGKNGEPGDPGEDGRKGEKG DSGASGREGRDGPKGERGAPGILGPQGPPGLPGPVGPPGQGFPGVPGGTGPKGDRGETGS KGEQGLPGERGLRGEPGSVPNVDRLLETAGIKASALREIVETWDESSGSFLPVPERRRGP KGDSGEQGPPGKEGPIGFPGERGLKGDRGDPGPQGPPGLALGERGPPGPSGLAGEPGKPG IPGLPGRAGGVGEAGRPGERGERGEKGERGEQGRDGPPGLPGTPGPPGPPGPKVSVDEPG PGLSGEQGPPGLKGAKGEPGSNGDQGPKGDRGVPGIKGDRGEPGPRGQDGNPGLPGERGM AGPEGKPGLQGPRGPPGPVGGHGDPGPPGAPGLAGPAGPQGPSGLKGEPGETGPPGRGLT GPTGAVGLPGPPGPSGLVGPQGSPGLPGQVGETGKPGAPGRDGASGKDGDRGSPGVPGSP GLPGPVGPKGEPGPTGAPGQAVVGLPGAKGEKGAPGGLAGDLVGEPGAKGDRGLPGPRGE KGEAGRAGEPGDPGEDGQKGAPGPKGFKGDPGVGVPGSPGPPGPPGVKGDLGLPGLPGAP GVVGFPGQTGPRGEMGQPGPSGERGLAGPPGREGIPGPLGPPGPPGSVGPPGASGLKGDK GDPGVGLPGPRGERGEPGIRGEDGRPGQEGPRGLTGPPGSRGERGEKGDVGSAGLKGDKG DSAVILGPPGPRGAKGDMGERGPRGLDGDKGPRGDNGDPGDKGSKGEPGDKGSAGLPGLR GLLGPQGQPGAAGIPGDPGSPGKDGVPGIRGEKGDVGFMGPRGLKGERGVKGACGLDGEK GDKGEAGPPGRPGLAGHKGEMGEPGVPGQSGAPGKEGLIGPKGDRGFDGQPGPKGDQGEK GERGTPGIGGFPGPSGNDGSAGPPGPPGSVGPRGPEGLQGQKGERGPPGERVVGAPGVPG APGERGEQGRPGPAGPRGEKGEA GEMGLRGQVGPPGDPGLPGRTGAPGPQGPPGSATAKGERGFPGADGRPGSPGRAGNPGTPG APGLKGSPGLPGPRGDPGERGPRGPKGEPGAPGQVIGGEGPGLPGRKGDPGPSGPPGPRG PLGDPGPRGPPGLPGTAMKGDKGDRGERGPPGPGEGGIAPGEPGLPGLPGSPGPQGPVGP PGKKGEKGDSEDGAPGLPGQPGSPGEQGPRGPPGAIGPKGDRGFPGPLGEAGEKGERGPP GPAGSRGLPGVAGRPGAKGPEGPPGPTGRQGEKGEPGRPGDPAVVGPAVAGPKGEKGDVG PAGPRGATGVQGERGPPGLVLPGDPGPKGDPGDRGPIGLTGRAGPPGDSGPPGEKGDPGR PGPPGPVGPRGRDGEVGEKGDEGPPGDPGLPGKAGERGLRGAPGVRGPVGEKGDQGDPGE DGRNGSPGSSGPKGDRGEPGPPGPPGRLVDTGPGAREKGEPGDRGQEGPRGPKGDPGLPG APGERGIEGFRGPPGPQGDPGVRGPAGEKGDRGPPGLDGRSGLDGKPGAAGPSGPNGAAG KAGDPGRDGLPGLRGEQGLPGPSGPPGLPGKPGEDGKPGLNGKNGEPGDPGEDGRKGEKG DSGASGREGRDGPKGERGAPGILGPQGPPGLPGPVGPPGQGFPGVPGGTGPKGDRGETGS KGEQGLPGERGLRGEPGSVPNVDRLLETAGIKASALREIVETWDESSGSFLPVPERRRGP KGDSGEQGPPGKEGPIGFPGERGLKGDRGDPGPQGPPGLALGERGPPGPSGLAGEPGKPG IPGLPGRAGGVGEAGRPGERGERGEKGERGEQGRDGPPGLPGTPGPPGPPGPKVSVDEPG PGLSGEQGPPGLKGAKGEPGSNGDQGPKGDRGVPGIKGDRGEPGPRGQDGNPGLPGERGM AGPEGKPGLQGPRGPPGPVGGHGDPGPPGAPGLAGPAGPQGPSGLKGEPGETGPPGRGLT GPTGAVGLPGPPGPSGLVGPQGSPGLPGQVGETGKPGAPGRDGASGKDGDRGSPGVPGSP GLPGPVGPKGEPGPTGAPGQAVVGLPGAKGEKGAPGGLAGDLVGEPGAKGDRGLPGPRGE KGEAGRAGEPGDPGEDGQKGAPGPKGFKGDPGVGVPGSPGPPGPPGVKGDLGLPGLPGAP GVVGFPGQTGPRGEMGQPGPSGERGLAGPPGREGIPGPLGPPGPPGSVGPPGASGLKGDK GDPGVGLPGPRGERGEPGIRGEDGRPGQEGPRGLTGPPGSRGERGEKGDVGSAGLKGDKG DSAVILGPPGPRGAKGDMGERGPRGLDGDKGPRGDNGDPGDKGSKGEPGDKGSAGLPGLR GLLGPQGQPGAAGIPGDPGSPGKDGVPGIRGEKGDVGFMGPRGLKGERGVKGACGLDGEK GDKGEAGPPGRPGLAGHKGEMGEPGVPGQSGAPGKEGLIGPKGDRGFDGQPGPKGDQGEK GERGTPGIGGFPGPSGNDGSAGPPGPPGSVGPRGPEGLQGQKGERGPPGERVVGAPGVPG APGERGEQGRPGPAGPRGEKGEA # 123 is the file which has the protein seq aboveStr = open(&quot;123&quot;,'r').read().replace(&quot;\\n&quot;,&quot;&quot;).replace(&quot; &quot;,&quot;&quot;)Split = Str.split(&quot;G&quot;)Split.remove(&quot;&quot;)while &quot;&quot; in Split: Num = Split.index(&quot;&quot;) print(str(Num), Split[Num+1]) Split[Num+1] = &quot;G&quot;+Split[Num+1] Split.remove(&quot;&quot;)Num = 0for i in range(len(Split)): if len(Split[i]) &gt; Num: Num = len(Split[i])for i in range(len(Split)): if len(Split[i]) &lt; Num: Split[i] = Split[i] + &quot; &quot;*(Num -len(Split[i]) ) Split[i] = list(Split[i])A = pd.DataFrame(Split) library(ggplot2)library(reshape2)A &lt;- read.table(&quot;TB&quot;, sep=&quot;,&quot;, header=T, row.names = 1)TB &lt;- melt(t(A))TT &lt;- table(TB$value,TB$Var1)[-1,]TP &lt;- melt(TT) Collagen classes and types: Fibrill-forming Type 1: Most abundant connective tissue, which is long rode triple collagen. (fiber-forming) Type 2: Cartilage and vitreous humor. (Most fiber forming collagen) Type 4: (Basal lamina) Chicken Wire shape, to reinforce the structure. Network-forming Type 7: Anchoring fibrill which holds the dermis and epidermis. Anchoring filament Type 8: Attachments of basal laminae to underlying connective tissue. (Butterfly Children: lack a particular collagen, gentle touch in the skin could cause blister) Elastin © Y.K. Lahir - A highly hydrophobic protein rich in glycine and proline.- Secondary structure is a random coil that can stretch and relax.- Unique crosslinks, desmosine and isodesmosine, formed from cross-linked lysines, return elastin to its original conformation after force on the tissue has been released. © Valentin Hagel, et al Keratin The major fibrous protein of hair, nails, and the enamal of teeth. These fibers are embedded in a ground substance that consistance of keratohyaline and proteoglycan.Keratin is high in cysteine (~14% in hair). It forms α-helix structure that further assemble into thick strands of “coiled coils” © PDB id=6EC0 Glycosaminoglycans core introduction: NCBI Books Glycosaminoglycans (GAGS) are unbranched polysaccharides composed of repeating disaccharides units. (mostly: uronic acid and amino sugar) Glycosaminoglycans are classifide primarily according to the amino sugar they contain. Because of their highly charge, GAGs are osmotically active and imbibe large quantities of water. GAGs form the porous hydrated gels that fill most of the extracellular space. Collagen and elastic fibers comprise the reinforcing fiber embedded in this “ground substance”. uronic acid and sulfide compounts contributed the negative charge of the Glycosaminoglycans Proteoglycans © Hussein Kaoud Most GAGs (with the exception of the hyaluronic acid) are covalently linked to a protein core. These covalent conjugages are called proteoglycans. Proteoglycans are normally given names when the protein core to which the GAG is attached has been cloned and sequenced. Formerly, the core proteins of the proteoglycans were thought to have a passive role of carry glycosaminoglycan GAG chains. It appears now, however, that, the core protein so of the some molecules are involved in mediating outside-in signals generated by the binding of ligands. Aggrecan Aggrecan is a type of Proteoglycans © Ameera Kamal Khaleel Electron micrograph and diagram of the structure of aggrecan, a proteoglycan aggregate found primarily in the specialized connective tissue, cartilage. PS: sulfate proteoglycan gives lots of charges which makes this structure work like a sponge. Proteoglycan Mol Wt of core protein Type of GAG chain Number of GAG Chain Location function Aggrecan 210,000 Chondroitin and Keratan sulfate ~130 Cartilage Mechanical support; forms large aggregates with hyaluronic acid, binds TGF-β Perlecan 600,000 Heparan sulfate 2-15 Basal lamina Structural and filtering function in basal lamina Syndecan-1,2,3 and 4 32,000 Chindroitin sulfate + heparan uslfate 1-3 Fibroblast, epithelial cell surface Cell adhesion, binding FGF; Signal Transduction Multiadhesive Matrix Proteins © Veli-Jukka Uitto Fibronection: The most abundant of the ECM adhesion protein; has binding site for type I collagen, fibrin, heparan sulfate proteoglycans, and membrane-intercolated receptors. Laminin: AN important component of the basal lamina synthesized by epithelial and endothelial cells. Laminin is the first ECM adhesion protein to appear during embryonic development and appears to be very important in the development of the nervous system. Thrombospondin: An important component in platelet aggregation. This cell is also involved in endothelial cell proliferation. Fibronectin Fibronectin consist of two nearly identical chains joined by two sulfide bonds near their carboxyl ends. RGD domain was recognized by fibronectin receptors Laminin-1 is synthesized by epithelial and endothelial cells and is the principal multi-adhesive matrix protein of the basal lamina. At least 8 different genes code for laminin-like proteins. Transmembrane Protein Family Ligands recognized stable cell junctions Selectins Carbohydrates No Integrins ECM Members of lg superfamily Focal adhesions and hemidesmosomesNo [Source: Don’t know = =] Disruption of this process decreases inflammation A humanized monoclonal antibody, Natalizumab, which binds to the α4 integrin subunit, disrupts the ability of leukocytes to move from the bloodstream to the tissues. This antibody has been shown to be effective in reducing the severity of symptoms in Multiple Sclerosis, most of which can be attributed to inflammation. A low molecular weight agonist (activator) of the αMβ2 integrin also prevents extravasation of the leukocytes and decreases inflammation. This drug is not yet in clinical trials. Modulating integrin action decreases inflammation Integrins Integrins are obligate heterodimers containing two distinct chains, called the α and β subunits. In mammals, 19 α and 8 β subunits have been characterized. There are many types of integrins, and many cells have multiple types on their surface. Integrin Structure. Both the alpha and beta subunits are attached to the cellular plasma membrane through a single transmembrane helix. The binding specificity of integrins depends upon the nature of the alpha and beta subunit. Most integrins recognized relatively short peptide motifs and in general require an acidic amino acid to be present. Integrin Function Many integrins are expressed on the surface of cells in an inactive state, where they do not bind ligands and do not signal. Integrins interact with the elements of the extracellular matrix and mediate various intracellular signals. They define cellular shape, mobility, and regulate the cell cycle. Integrin Signaling Integrins communicate biochemical and mechanical signals in a bidirectional manner across the plasma membrane. Intracellular signals switch integrins into a ligand-competent state as a result of conformational changes in the extracellular domain. Binding of extracellular ligands induces, in turn, structural changes that convey distinct signals to the cell interior. cell signaling Structural adaptors (e.g. talin, tensin,) link integrins directly to the cytoskeleton Scaffolding adaptors (e.g. paxillin, kindlin) forms bridges between focal adhesion proteins. Catalytic adaptors (e.g. focal adhesion kinase, integrin-linked kinase, Src) propagate signal transduction from adhesion sites. Phosphorylation state of cytoplasmic tail residues modulate the competition between adaptors for binding and hence the subsequent cytoskeletal interactions of integrins and response. Interactions between beta integrins and signaling proteins FAK, focal adhesion kinase p130Cas, an adaptor that promotes protein–protein interactions, leading to the formation of multiprotein complexes Crk, a family of signal transducing adaptor proteins that contain SRC homology domains and play a role in cytoskeletal reorganization. Abl, cytoplasmic and nuclear protein tyrosine kinase that has been implicated in processes of cell differentiation, cell division, cell adhesion, and stress response. Be able to name the proteins that integrins use for signal transduction. Integrins activate intracellular signaling pathways Which signaling pathway is initiated by integrin activation is based on the biological context, as well as the ligands bound (matrix components, growth factors). Depending on the combination of these factors, a variety of short-term and long-term responses may result. Substrate stiffness has also been shown to affect the type of adhesion structure formed following integrin activation. Integrin signals intersect growth- factor pathways at multiple points. PAK proteins are critical effectors that link Rho GTPases to cytoskeleton reorganization and nuclear signaling. They consist of a family of serine/threonine p21- activating kinases, serve as targets for the small GTP binding proteins Cdc42 and RAC and have been implicated in a wide range of biological activities. Key Points to Remember Components of the extracellular matrix Collagen structure (types I, II, IV and VII) and the importance of glycine in the triple helical region. Proteoglycan structures (especially Aggrecan) Transmembrane proteins that mediate cell adhesion and their specificity Steps in extravasation of leukocytes Integrin structure (activated and unactivated) and specificity Intracellular proteins involved with integrin signaling","link":"/2021/09/02/LearnNotes/tulane-cellbio-3/"},{"title":"5 Membrane Transport|Advanced Cell Biology|Tulane","text":"Objectives By the end of this session you should be able to: Compare and contrast the characteristics of passive diffusion facilitated diffusion primary active transport secondary active transport (cotransport). Compare and contrast the properties of the: four classes of ATP-powered pumps their effect on the intracellular environment Describe how: potassium channels can generate a hyperpolarized resting potential, common in most living cells. Explain how transporters &amp; Ion channels regulate insulin release in the pancreas General information Type of membrane transport depends on: Characteristics of the substance being transported Direction of transport Three main classes of membrane protein ATP-power pump (carrier, permease) couple with energy source for active transport binding of specific solute to transporter which undergo conformation change. Channel protein (ion channel) formation of hydrophilic allow passive movement of small inorganic molecule. Transporters: uniport (single) Symport (double) antiport (double &amp; anti one cis another trans gradient) © Mariafrancesca Scalise, et al. Two types of transport: © Maria Müller Passive transport (diffusion): NO metabolic energy is needed Active Transport: Metabolic energy is used Passive (simple) diffusion Small noncharged molecules or lipid soluble molecules pass between the phospholipids to enter or leave the cell Moving from areas of high concentration to areas of low concentration (they move down their concentration gradient) Example: Oxygen, carbon dioxide, and most lipids Osmosis A type of simple diffusion in which water molecules diffuse through a selectively permeable membrane from areas of high water concentration to areas of lower water concentration. Facilitated diffusion The substance is moving down its concentration gradient through a membrane protein (not between the phospholipids) Example: monosaccharide, glucose, water “Water &amp; oil don’t mix” - That’s why water was not considered as passive diffusion - Aquaporins increase water permeability - Too much mRNA injected into Frog Oocyte could make it absorbing too much water. © Rob Horsefield, et al. GLUT1 Mechanism (Facilitated Diffusion) © Dong Deng, et al. most commonly expressed glucose transporter reversible (depends on concentration gradient); glucose is commonly rapidly phosphorylated in cytoplasm ping pong mechanism (protein does not “flip”) Facilitated vs. Passive Diffusion © Florina Silvia Iliescu, et al. Exp: GLUT1 (erythrocytes) and GLUT2 (liver &amp; pancreas) saturable non-linear selective, fast &amp; constant rate at 5-10 mM uptake rate varies more (stimulates insulin release) Active transport PS: Energy; Against Concentration Move substances across membranes against their concentration gradient (from areas of low concentration to areas of high concentration) Energy is needed for this movement Primary vs Secondary active transport © Alberto Canarini, et al. Primary: simply against the concentration Secondary: send the intermediate molecule against the concentration and then, Symport the target molecules against the concentration. e.g.: Intestinal &amp; Kidney Utilize the free-energy for Na (down its concentration gradient) to move glucose (against its concentration gradient) SGLT-2 (Na-glucose co-transporter 2) Comparison of Different Transport Mechanisms Property PassiveDiffusion Facilitatediffusion ActiveTransport cotransport Protein Required - + + + Against Graident - - + + ATP Needed - - + - contransported ion down its gradient - - - + EXP O2, CO2, steroid hormones, may drugs Glucose and AA (uniporters), ions, water (channels) Ions, small hydrophilic molecules, lipids (ATP-powered pumps) Glucose and AA (symporters); Various ions and sucrose (antiporters) Saturable transport at high [solute] 4 Classes of ATP-powered transport proteins P class pump V class pump F Class Proton Pumps ABC (ATP Binding Cassette) Superfamily P Class pump (Proton pump) Plasma membrance of plants, fungi, bacteria (H+ pump) Plasma membrane of higher eukaryotes (Na+/K+ pump) Apical plasma membrane of mammalian stomach (H+/K+ pump) Plasam membrane of all eukaryotic cells (Ca+ pump) Sarcoplasmic reticulum membrane in muscle cells (Ca+ pump) Typical Intracellular and Extracellular Ion Concentrations Ion Cell(mM) Blood (mM) K+ 139 4 Na+ 12 145 Cl- 4 116 HCO3- 12 29 X- 138 9 Mg2+ 0.8 1.5 Ca2+ &lt;0.0002 1.8 Na/K ATPase © Susan Spiller, et al. Inhibited by ouabain &amp; digoxin F-Class Proton Pumps Location: Bacterial plasma membrane Inner mitochondrial membrane Thylakoid membrane of chloroplast Use H+ gradient to generate ATP (convert chemical energy to a different form) V-Class Proton Pumps Location: Vacuolar membranes in plants; yeats, other fungi Endosomal and lysosomal membranes in animal cells Plasma membrane of osteoclasts and some kidney tubule cells. Utilize ATP to generate a H+ gradient PS: Functional against F-Class V-Class H+ ATPase Lysosomes: degrade extracellular materials (e.g. bacteria, LDL particles) Synapse: V-class H+ pumps &amp; Synaptic Transmission Vesicles, Pumps &amp; Synaptic Transmission ATP Binding Cassette (ABC) Superfamily Bacterial plasma membrane (AA, sugar, and peptide transporters) Mammalian plasma membranes (Transporters of phospholipids, small lipophilic drugs, cholesterol, other small molecules) Pre-systemic drug clearance, blood-brain barrier, renal secretion of drugs, cancer cells Location: BBB (blood-brain barrier ); GI tract; Kidney; Liver; Cancer ABC Transporters &amp; Presystemic Clearance Mechanism of presystemic clearance. After drug enters the enterocyte, it can undergo metabolism, excretion into the intestinal lumen, or transport into the portal vein. Similarly, the hepatocyte may accomplish metabolism and biliary excretion prior to the entry of drug and metabolites to the systemic circulation. Ion Channel Four Subtypes of Ion Channels Types Example 1 Voltage-gate Na, Ca, K 2 Ligand-gated(extracellular ligand) GABAA, ACh, Nicotinic 3 Ligand-gated(intracellular ligand) βγ, Muscarinic, Adenosine 4 Stress-activated Stretch © Nilan Jacob Beta Cells of the Pancreas (How Transporters &amp; Ion Channels Regulate Insulin Release) © Suttira “Joy” Intapad, Ph.D Ion Channels &amp; Membrane Potential Membrane electric potential 59 mV; intracellular medium Membrane electric potential Patch Clamp Technique (Voltage Clamp) Transport across, but not through, membranes Endocytosis Exocytosis","link":"/2021/09/21/LearnNotes/tulane-cellbio-5/"},{"title":"6 Protein Folding and Degradation|Advanced Cell Biology|Tulane","text":"Protein Folding and Degradation • Lodish MCB, 8th ed., pages 81-105 and 622-631. • 3.2 Protein Folding • 3.3 Protein Binding and Enzyme Catalysis • 3.4 Regulating Protein Function • 13.6 Transport Into and Out of the Nucleus Protein Folding Principles of protein folding: AA Seq. → 3D Structure and Function. Assisted by: ATP-dependent chaperones and chaperonins Misfolded/denatured proteins → Diseasecan Exp: amyloid fibril: Alzheimer &amp; Parkinson. Factors that Affect Protein Folding/Structure Hypothetical protein folding pathway: Primary → Secondary → Tertiary Native conformation: lowest free energy Forces that govern folding Hydrophobic interaction (favors) Conformational entropy (disfavors) Steric hindrance limits dihedral angles off central α-carbon van der Waals contacts (packing) Hydrogen bonds Electrostatic interactions PS: Planar peptide bonds φ and ψ: steric clash PS: How AA Seq determing the high dimensions information For example, : Steric effect: a large side chain, such as that of (W), might sterically block one region of the chain from packing closely against another region Charge effect: a side chain with a positive charge (A) , might attract a segment of the polypeptide that has a complementary negatively charged side chain (e.g., D). Secondary structure: Example we have already discussed is the effect of the aliphatic side chains in heptad repeats in promoting the association of helices and the consequent formation of coiled coils. Thus a polypeptide’s primary structure determines its secondary, tertiary, and quaternary structures. Steric hindrance and secondary structure Values of dihedral angles φ and ψ are excluded by contact between bulky groups - steric hindrance (clash) “Allowed” regions of Ramachandran Plot correspond to major secondary structures Molecular Chaperone Families • stabilize unfolded or partly folded proteins and prevent aggregation during synthesis, membrane translocation, assembly, and degradation. • Molecular chaperones bind exposed segments and surfaces of unfolded proteins. • Hsp60-Hsp10 family chaperones (Mito and chlp) manage folding of enzymes and proteotoxic stress • Hsp70-Hsp40 family chaperones (in cyto, ER, nuc,mito, chlp) manage protein translocation across membranes and proteotoxic stress • Hsp90 family chaperones (cyto, nuc, ER, mito, chlp) regulate signaling and gene expression and manage proteotoxic stress • Hsp100 (AAA+) family chaperones (cyto, mito, chlp) unfold proteins for degradation and manage proteotoxic stress • Hsp25 family chaperones (in cyto) manage actin assembly and proteotoxic stress - do not utilize ATP Molecular Chaperones Chaperonins Small protein which bind to a short segment of a target and stabilize unfold or part folded protein. Large protein which form a folding chamber into which all or part of unfolded protein, give it time and an appropriate environment to fold properly. Hsp70; Hsp40; Hsp90; Hsp60; Hsp10 Functions: Preventing aggregation Fold newly made proteins disassmble ptentially toxic protein aggregates duet to … Chaperones: Hsp60-Hsp10 ATP cycle © Alexandra Richardsona, et al. Video: 3D Animation; 2014 Youtube Ibiology; 2014 Youtube Hsp60: Huge cylindrical supramolecular assemblies Two groups: Group I: The Prokaryotic Group GroEL/GroES Group II: The Eukaryotic Group TriC ATP + GroEL → ADP: unfolded protein in lid of GroES sealed ATP → ADP → protein fold ATP → ADP → GroES and peptide release Pepetide enter another chamber → Release/Repeats Chaperonins: Hsp70-Hsp40 ATP-cycle Hsp40-bound “client” protein binds to Hsp70 Hsp40 J-domain triggers ATP hydrolysis, Hsp70 closes, Hsp40 released Waiting/folding ADP/ATP exchange triggers opening of Hsp70 Release of client protein Hsp70 Monomeric Families of heat-shock protein Hsp70 homologs: Hsp70 in Mito; 2. Bip in ER, 3. DnaK in Heat-shock: large expressed after heat-shock in bacteria. +ATP → Open conformation → Expose Hydrophobic Region → Bond client. ATP → ADP → Close conformation → helping folding ADP Release → conformation change → Target release ATP bond → binds another target Check: appropriate folded → Cannot bind again inappropriate folded → bind again Hsp40 Four main families of nucleotide exchange factors: GrpE: bacteria BAG; HspBP; Hsp110 Hsp40 (co-chaperone) facilitate Hsp70 processes. Increasing the ATP hydrolysis. ×100 ~ ×1000 Hsp90 ATP cycle Hs70-bound “client” protein binds to Hsp90 ATP binding triggers closing of Hsp90 Waiting/folding ADP hydrolysis and release Release of client protein Hsp70-bound Hsp70 Dimer protein Usually recognizing partially folded protein, highly conserved among species. Four families: two in cytosol, one in Mito, and one in ER. Important: Helping miss folded protein under the stress, convert them into active form or held in a functional conformation. open conformation → Bind target +ATP → Closed conformation ATP → ADP → target release Else: Cooperate with Hsp70 Influenced by covalent modification Facilitate identification and degradation AAA+ Protein Family Aggregate disassembly Hsp100 of yeast ClpB of E. coli Vesicular transport complex disassembly NEM-sensitive factor for SNARE disassembly Vps4 for ESCRT disassembly DNA-binding protein assembly Clamp loader Export of mRNA from nucleus Dbp5 Protein translocation across membranes p97 for ER-associated degradation (ERAD) Protein degradation ClpA, ClpX of E. coli “Cap” of 26S proteasome (6 in 19S cap) Molecular motor Dynein for organellar transport along microtubules (ATPases associated with various cellular activities, homologous to hexameric nucleic-acid helicases) 3.4 Regulating Protein Function At the level of synthesis, degradation, or through noncovalent or covalent interactions. Proteins marked for destruction with a polyubiquitin tag by ubiquitin ligases are degraded in proteasomes. Allosteric mechanisms act as switches, reversibly turning protein activity on and off. Higher-order regulation includes the intracellular compartmentation of proteins. Proline cis/trans isomerizations. Alters structure of a protein SH2 domain. Can influence protein activity.??? Proline isomerase may act as switch to regulate protein activity. From Textbook: ALtering the rate of protein synthesis and degradation Change the intrinsic activity, Exp: active or in active conformation Change the location and the concentration within the cell. Ubiquitin- and Proteasome-Mediated Proteolysis © Lodish, Molecular Cell Biology, Eight Edition, p98 Proteasome Structures: ATPas: AAA+ family: Red Ubiquitin recepor: Yellow Deubiquitinase Enzyme: Green Ubiquitin and Formation Ubiquitin’s type Features Monoubiquitinylation Single Ubiquitin Multyubiquitinylation Multiple, single ubiquitin Polyubiquitinylation A polymeric chain of ubiquitin Degradation in Proteasome Actication: ATP + ubiquitin (Ub) → activate Enzyme E1 E1 - Ub Ttransfers Ub → E2 (step 2 ) E2 - Ub Formation: Ubiquitin ligase (E3) transfer Ub → Lysine–NH2 and forming an isopeptide bond UB - Peptide more Ub by repeating steps 1 – 3 n * (Ub) - Pepide polyubiquitinylatd targed → Ub receptors (19S cap) went into proteasome deubiquitinase enzyme (19S cap) → Ub remove a. +ATP → unfold → the 20S core ( b. coordinately with step 6: protein → short peptide → release (7c) Degradation: Proteosome recognition, 1. de-Ub protein, 2. unfolds protein; protein transferred to core proteolysis chamber, protein cleaved into short peptides (2-24 aa) and released for further degradation by soluble proteases. Determination of polyubiquitin function by the lysine used for inter-ubiquitin isopeptide bonds © Lodish, Molecular Cell Biology, Eight Edition, 104 Signaling: Lys-63; Proteasomes: Lys-48:Gly-76 isopeptide. T-lymphocyte control: Lys-33 Cell division: Lys-11 Misfolded Proteins can form Amyloid Aggregates © Lodish, Molecular Cell Biology, Eight Edition, p88 Amyloid aggregate plaques form inside or outside many cell types. Flat sheets form protofilaments, assemble into thicker fibrils, and into larger aggregates or macroscopic plaques. Cause neurodegenerative amyloidosis diseases, including Alzheimer’s disease, Parkinson’s disease, and transmissible spongiform encephalopathy (“mad cow” disease). Clinical Case: Alzheimer’s Disease © Lodish, Molecular Cell Biology, Eight Edition, p88 68 yo male seen in ER with apparent confusion, disorientation of where he is or the present date. • Most common form of dementia. • Affects 1 in 10 people over 65 and 50% of people over 85. • Plaques (Aβ peptide) and tangles (tau microtubule-associated protein) results in gradual and progressive loss of neurons and cognitive function over a period of 4-15 years (memory lapse, language impairment, loss of motor functions). Alzheimer’s Disease Fact Sheet; 2021 NCBI Prion Diseases &amp; Transmissible Spongiform Encephalopathies TSE - spongiform neurodegeneration, astrocytic gliosis. Prion - proteinaceous infectious agent, considered heretical concept for transmission. Lehninger Box 4-6 Transmissible Spongiform Encephalopathies Creutzfeldt-Jakob Disease (CJD) Gerstmann-Straussler-Scheinker syndrome (GSS) Fatal Familial Insomnia (FFI) Kuru: Fore tribe in New Guinea Wild Animals and Livestock (bovine, mink, feline, elk, sheep) The Prion Hypothesis for TSEs PrPSc + PrPc → 2PrPSc Synfrome Etiology Sporadic sCJD Spontaneous conversion of PrPc to PrPsc (usually not mutant) Acquired Kuru Ritualistic endocannabilism iCJD Exposure to contaminated growth hormone, gonadotrophins, dura mater, cornea or surgical instruments vCJD Ingestion of BSE-contaminated food products Familial fCJD Germline mutation in PRNP locus GSS; FFI From: Hilton (2006) J Pathol 208: 134, Table 1 Iatrogenic CJD 2004 Diseases involving Amyloid Formation: Know the normal and abnormal proteins, the disease, and specific mechanisms. Disease Type II Alzheimer’s disease Prion disease Huntington’s disease Parkinson’s disease ALS Spinal Cerebellar Ataxia Protein Amylin Amyloid Precursor Protein (APP) PrPc Huntingtin protein α-synuclein SOD ataxin Function Glycemic regulation with insulin ECM, migration during development Unk. Unclear, MAP, vesicle trafficking Unclear, MAP, vesicle trafficking Destroy oxygen radicals Unclear Abnormal protein n/a Aβ42(β-Amyloid) PrPsc mHTT, Trinucleotide repeats (polyQ) Lewy bodies n/a Trinucleotide repeats (polyQ), and nonPolyQ Effects Apoptosis of β islet cells Neuronal death Neuronal death Neuro-tramsmitter release, neuronal death Neuro-transmitter release, dopaminergic neuronal death Dementia neuronal atrophy Neuronal deat 13.6 Transport Into and Out of the Nucleus © Jeroen Vangindertael, et al; 2018 © Roderick Lim, et al; 2006 © Mario Tagliazucchi, et al; 2015 © Anita H Corbett, et al; 2004 • Unidirectional transport of a protein larger than 40 kDa through large, complex nuclear pore complexes requires a nuclear-localization or nuclear-export signal, nuclear transport receptors, Ran G-proteins, and localized Ran?GEFs and GAPs. • Other molecules, including mRNPs, are transported by a Ran-independent pathway. Nucleoporins: Structural nucleoporins (circule the memrain) Membrane nucleoporins (Y complex) FG nucleoporins (matrix on the pour center) Transport Into and Out of the Nucleus The Nu Env: NPCs, ×30 different nucleoporins. FG-nucleoporins: multiple repeats of a short hydrophobic sequence (FG-repeats), line the central transporter channel and play a role in the transporter. &gt;40 kDa: nuclear transport receptors interact nuclear-localization signal (NLS) or a nuclear-export signal (NES) on the proteins in/out. NLS: Nucleus-restricted proteins NLS+NES: proteins that shuttle between the nucleus and cytoplasm Each type of NESs/NLSs is thought to interact with a specific nuclear transport receptor. Transient interactions: Protein-[NES/NLS] + receptor. Transport receptors + FG-repeats: very rapid diffusion through the NPC, Ran: a monomeric G protein Localization of the Ran guanine (Ran-GEF) in the nucleus and of the Ran GTPase-activating protein (Ran-GAP) in the cytoplasm creates a gradient with high concentrations of Ran⋅GTP in the nucleoplasm and of Ran⋅GDP in the cytoplasm. The interaction of a cargo complex with Ran⋅GTP in the nucleoplasm causes dissociation of the complex, releasing the cargo into the nucleoplasm, whereas the assembly of an export cargo complex is stimulated by interaction with Ran⋅GTP in the nucleoplasm. Most mRNPs are exported from the nucleus by binding to a heterodimeric mRNP exporter. RNA helicase associated with the cytoplasmic filaments of the NPC that removes the heterodimeric mRNP exporter once the transport complex has reached the cytoplasm. Nuclear-Localization Signals (NLSs) Direct Proteins to Cell Nucleus © Kalderon D, et al; 1984 NLSs is a 7 residue sequence rich in the terminal of the protein, exp: PLLLRLV All nuclear proteins come from cytosol. They all have NLSs Experiment: (a) Pyruvate kinase: in the cytosol for glycolysis. (b) Chimeric pyruvate kinase containing SV40 NLS at its N-terminus: transported into the nucleus. Nuclear Import © Terence David Allen, et al. 2000 Ran &amp; nuclear transporter receptor was purified. In Cytosol: Importin + NLS-[Cargo]. Importin-NLS-Cargo passively diffuses. In nucleus: Ran-GEF: Ran-GDP + GTP → Ran-GTP + GDP Importin binds Ran-GTP → Cargo release. Importin-Ran-GTP diffuses through NPC. Back in cytosol. Ran-GTP reacts with Ran-GAP → part of cytoplasmic filament. GTP hydrolysis → low affinity for Importin → releases Importin. RanL a small monomeric G protein: GTP/GDP-bound conformation: supply the energy NTR binds to the NLSs: Recognition Monomeric G Proteins: The GTPase Switch © biologicmodels GTPase: GTP-bound: Active “on” conformation → interacts with target proteins to regulate their activities. GDP-bound: inactive “off” conformation → intrinsic GTPase activity → hydrolyzes GTP to GDP. GEF: Guanine nucleotide exchange factor, stimulates exchange of GDP-(off) to GTP-bound (on) forms. GAP: GTPase-activating protein, stimulates GTP (on) hydrolysis to GDP (off). Examples: Ras, Ran, Rho, ARF Ran-Dependent Export © Terence David Allen, et al. 2000 In Nucleus: [Ran-GTP]-[Exportin]-[Cargo] → passive diffusion. In Cytosol: Ran-GAP: [Ran-GTP]-[Exportin]-[Cargo] → Ran-GTP + Cargo + Exportin Passively diffuse: Ran-GDP &amp; Exportin → into Nucleus. Back in nucleus: 4. Ran-GEF: Ran-GDP + GTP → Ran-GTP + GDP Ran-Independent mRNA Nuclear Export NXF1: Nuclear Export Factor 1 NXT1: Nuclear Export Transport 1 mRNP: Messenger Ribonuclear Protein Complex Nucleoplasm: Passive diffusion： Heterodimeric NXF1/NXT1 + mRNPs. Cytosol Dissociation: RNA helicase (Dbp5) + ATP + [NXF1/NXT1]-[mRNP] → NXF1 + NXT1 + mRNA + ADP + Pi Recycling: Ran-dependent import recycles NXF1 and NXT1 Vesicular Traffic Class I Presentation to CO8⁺ T Cells [go to find the pic and make more notes.] Cross presentaiton P: 1110 Class II Presentation to CD4⁺ T Cells P: 1112 Lodish MCB, 8th ed., pages 631-659. Techniques for Studying the Secretory Pathway Protein Transport through the Secretory Pathway Secretory and Endocytic Pathways Sec Mutants Identify 5 Stages of Secretory Pathway Exam: Classes , what machine could be broken/mutant Coated Vesicles Involved in Protein Trafficking Coated Vesicles table, 1, 2, 4 Docking/Fusion of Vesicle w/Target Membrane Coil-Coil structure is really staby, not easty to recycle. KDEL Receptor Retrieval of ER-Resident Luminal Proteins from the Golgi slide difference pH between in cis and trans Golig: help the cargo binds and releaes (pH trigger). Dynamin Pinching Off of Clathrin-Coated Vesicles High energy state to close the bud neck 14.2 Molecular Mechanisms of Vesicle Budding and Fusion 14.3 Early Stages of the Secretory Pathway 14.4 Later Stages of the Secretory Pathway © Keith P. Delaune; Khalid Alsayouri. Exam: Draw cell component G protein regulation and fedality","link":"/2021/09/30/LearnNotes/tulane-cellbio-6/"},{"title":"7 Protein translocation|Advanced Cell Biology|Tulane","text":"Protein Translocation • Lodish MCB, 8th ed., pages 583-622. • 13.1 Targeting Proteins To and Across the ER Membrane • 13.2 Insertion of Membrane Proteins into the ER • 13.3 Protein Modifications, Folding, and Quality Control in the ER • 13.4 Targeting of Proteins to Mitochondria and Chloroplasts • 13.5 Targeting of Peroxisomal Proteins Protein translocation was also called protein sorting/protein targeting. Two types of protein sorting: single-based targeting Newly or completed transcriptions Leads insertion in the membrane, trans-membrane into organelles vesicle based trafficking. Secrete protein, Glogi, lysosome, and plasma membrane Targeting Proteins To and Across the ER Membrane © SCIENCE PHOTO LIBRARY All soluble protein are initially delevered into ER. Two main types of protein: Soluble protein and Integral protein. Synthesis of: secreted proteins integral plasma-membrane proteins proteins destined for the ER, Golgi complex, plasma membrane, or lysosome begins on cytosolic ribosomes. A signal sequence, SRP, and SRP receptor system docks the ribosome on an ER translocation and cotranslationally inserts the nascent protein into or through the ER membrane. Structure of the Rough ER Convoluted membranes continuous with nuclear membrane. sER: Cellular lipid synthesis (sER). rER: First step in secretory pathway – rough ER – with attached ribosomes. Synthesis and processing for plasma membrane and secreted proteins, and proteins functioning in the ER, Golgi complex and lysosomes. Protein synthesis on the ER: ER membrane-bound and free cytosolic ribosomes are identical. Membrane-bound ribosomes: recruited to the ER during synthesis of a polypeptide containing an ER signal sequence. Secretory Proteins Enter the ER Lumen © Daniel A. Nissley, et al. 2016 Pulse-chase experiments: secretory proteins are in ER lumen right after synthesis. before the synthesis of first 70 AAs. Pulse radiolabeled amino acids only newly synthesized proteins labeled. Cells homogenized: shears rough ER into small vesicles called microsomes. Purified microsomes treated with a protease: (–) Detergent: proteins in ER are protected from digestion. (+) Detergent: dissolves ER membrane; proteins not protected from digestion. Detergent: disrupt the membrane system to expose the secrete protein Conclusion: newly made proteins are inside the microsomes (lumen of the rough ER) after synthesis. Simultaneous Translation / Translocation © Lodish, Molecular Cell Biology, Eight Edition, p587 Hydrophobic N-terminal signal sequence targets secretory proteins to ER membrane during translation from free cytosolic ribosomes. Initiates translocation of the growing polypeptide across the ER membrane Signal sequences cleaved from most secretory proteins after translocation. Cell-free experiments demonstrate that translocation of secretory proteins into microsomes is coupled to translation – cotranslational insertion Cotranslational Translocation © Victor Van Puyenbroeck, et al. 2018 © Lodish, Molecular Cell Biology, Eight Edition, p589 SS transcription: N-terminal ER signal sequence (SS) emerges from the ribosome first. SRP recognition: Signal recognition particle (SRP) binds SS – arrests protein synthesis. SS, SPR, Ribosome; SRPr complex: SPR-ribosome complex binds SRP receptor in ER membrane; interaction strengthened by the binding of GTP to both the SRP and its receptor. SRP dissociates: Transfer of nascent polypeptide–ribosome to translocon; opens translocation channel. SRP and SRP receptor both hydrolyze bound GTP; dissociates SRP from ribosome and receptor; restarts protein synthesis. SS cleaved: Peptide passes thru translocon into ER lumen; signal sequence cleaved. extrudes: Growing peptide chain extrudes thru translocon into ER. Ribosome Dissociated: Translation finishes; ribosome is released Folded: Translocated protein folds into native conformation and translocon closes. Nucleoside hydrolysis reactions that regulate processes using a timer-like function GTP ATP Ef-tu in protein synthesis G-protein signaling Ran in nuclear import/export SRP and SRP receptor Tubulin dynamic instability Sar1 in vesicle budding Rabs in vesicle fusion Dynamin in bud neck closure Actin for assembly Hsp70 for client binding/release Glucokinase for positive cooperativity Post-translational Translocation © Lodish, Molecular Cell Biology, Eight Edition, p589 BiP: (Hsp70 family ATP-dependent molecular chaperone) BiP bind peptide could prevent it’s backward sliding. Direct interaction: SS + translocon. N-terminal segment of the protein enters the ER lumen; signal peptidase cleaves SS. BiP + Sec63 complex: provide driving force for unidirectional translocation across the ER membrane. Random inward sliding: exposes more nascent protein. BiP-ADP binding: ratchets nascent protein into ER. BiP ATP hydrolysis essentially powers protein translocation across membrane. Releases: ATP for ADP exchange releases BiP from nascent protein. Folding: Protein folds into native conformation. 13.2 Insertion of Membrane Proteins into the ER Topogenic sequences: N-terminal signal sequences Internal sequence internal stop-transfer anchor sequences internal signal-anchor sequences direct the insertion of nascent proteins into the ER membrane. Topogenic sequences can be predicted by computer by identify hydrophobic topogenic segments. GPI anchor: Initiate as Type I but cleaved and transferred into GPI molecue Classes of ER Membrane Proteins © Lodish, Molecular Cell Biology, Eight Edition, p594 Classified by Orientation Locations of N/C-termini the Types of targeting signals. α helices segments (20- 25 A, Hydrophobic) → Embed. Hydrophilic regions fold into conformations outside membrane. Type IV: n × α helices. GPI anchor: protein in membrane by phospholipid anchor. Type I Insertion/Orientation © Lodish, Molecular Cell Biology, Eight Edition, p595 Topology: ER Lumen Transmembrane Domain Cytosol N- Single -C Translocation initiation and Ss cleavage. Ppeptide elongates. Elongation until hydrophobic stop-transfer anchor sequence enters translocon → prevents further translocation. Stop-transfer anchor sequence (α-helix) moves laterally into membrane. Translocon closes. Newly synthesized AA remain in cytosol. Synthesis completes; ribosomal subunits are released. PS: cotraslation translocation Sec61α domain, plug peptide. Exp: HGH receptor Types II and III Insertion/Orientation © Lodish, Molecular Cell Biology, Eight Edition, p596 Have single internal hydrophobic signal-anchor sequence (SAS; serves as both ER signal sequence and membrane anchor). Category Type I Type II N-terminal Ss None None SAS Yes Yes Positive charges adjacent to SAS towards cytosol towards cytosol SRP binds internal SAS internal SAS Positively charged residues N C cytosol C N SAS functions both Ss &amp; SAS, which is recognition and anchor. Type II: Start as Type I but not be cleaved, as a result, the N terminal still on the cytosol side. Type III: N-terminal was anchored immediately since the SAS is so closes to N-terminal. As a result, rest of sequence can’t enter the lumen. Topology/Orientation of ER Membrane © Lodish, Molecular Cell Biology, Eight Edition, p598 Red: Topogenic Sequences Blue: Soluble, hydrophilic sequences The high dense charged residues adjacent to SA were in the cytosol side. GPI-Anchored Proteins © Lodish, Molecular Cell Biology, Eight Edition, p599 GPI anchor covalently attaches protein in extracellular plasma membrane. (a) GPI molecule: hydrophobic fatty acyl chains with polar phosphate groups and carbohydrate moieties. (b) GPI-anchor: 1. Type I protein was synthesized. Transmembrane domain was cleaved and transferred into GPI by Transamidase. Biological Functions: 1, Higher mobility; 2, Not cytosol side residues which might anchor to cytoskeleton; GPI: Amphipathic glycosylphosphatidylinositol; Amphipathic GPI Transamidase: remove the membrane span to the GPI-linked protein. Tag contacts with ER would transfer to the cell surface through body infusion. 13.3 Protein Modifications, Folding, and Quality Control in the ER Oligosaccharides, disulfide bonds, and prolyl isoform modification; Cleavage ER chaperones + Lectins: help &amp; accelerates correct folding, transport to the cytosol to ubiquitin. Hinder: Only good protein → Golgi complex in vesicles. N-Linked Oligosaccharide Precursor Biosynthesis © Lodish, Molecular Cell Biology, Eight Edition, p602 N-linked oligosaccharide → RER. Oligosaccharide precursor + dolichol phosphate. Sugar residues added sequentially as activated sugar-NDPs. Steps 1-3: Two N-acetylglucosamine (GlcNAc) and five mannose residues added on ER membrane cytosolic face. Step 4: intermediate is flipped to ER membrane luminal face. Steps 5-6: Additional sugar-NDPs flipped to the luminal face and transferred to the growing oligosaccharide precursor. Tunicamycin blocks step 1, inhibits all N-linked glycosylation. PS: Precursor contain 14 residues and very conservative among eukaryotic. Function: Glc₃Man₉(GlcNAc)₂ formation: Dolichol Phosphate -[pyrophosphate bond]- GlcNAc₂ (Core)→ Man₉ (Branches) → Glc₃ (Tag) Asn-X-Ser/Thr: Not all, Not predictable. Glycosidase: remove Glc₃ → Act as a signal that the oligosaccharide is complete and ready to be transferred to a protein. Mucose; extra cellular protein have abundant of glycosylated residues. Glucose is important: ER quality contra mechanisms for protein folding. Protein is maturing, Glucose are being kicked out. Protein has be sensed weather it is folded completely. The fate was determined by the glucose. N-Linked Glycosylation and Processing © Lodish, Molecular Cell Biology, Eight Edition, p603 Promotes protein folding, stability, adhesion, and recognition. Step 1: Oligo precursor transferred into N residues(Asn-X- Ser/Thr) Steps 2–4: Remove: Glucose and mannose residues (plays a role in the correct folding of many ER proteins). Transfer the protein from ER to Golgi. Misfolded proteins delocated into lumen into the cytosol for degradation. PS: Examples Leukocytes → Cell adhesion molecules ABO blood system Protein Disulfide Isomerase (PDI) © Bei Xiong, et al Disulfide bonds rearrangement. Active site contains two cysteines that can have reduced dithiol or oxidized disulfide forms. Functions: Formation: Forms disulfide with PDI. Substrate second thiol forms disulfide within substrate, releasing reduced PDI. Reduced PDI is oxidized by Ero1, reforming active site disulfide bond. Rearrangement: Reduced PDI reacts similarly to rearrange disulfide bond within substrate. Reaction is repeated until substrate is folded into thermodynamically most stable conformation. thiol group: sulfhydryl group. Lectins: carbohydrate binding protein calnexin (On the membrane) and calreticulin (in the lumen) bind selectively to certain N-linked oligosaccharides to help protein folding, reducing peptides aggregate. Only in the ER: for a disulfide bond, Is a mixed disulfide bond, using disulfide bond to connect. Correct disulfide bond in cell. Summary: Hemagglutinin (HA) Folding/Assembly © Lodish, Molecular Cell Biology, Eight Edition, p605 © Lodish, Molecular Cell Biology, Eight Edition, p605 1. BiP, and Calreticulin bind nascent protein to prevent premature folding into incorrect conformation. 2. PDI → disulfide bonds → Folding allows trimer formation 3. Complete influenza virion with HA₀ (HA₁ + HA₂) trimer spikes protruding from viral membrane surface. Peptidyl-Prolyl Isomerase (PPI) of X-pro peptide bonds Accelerates rotation about peptidyl-prolyl bonds in unfolded segments of a polypeptide Rate-limiting step in the folding of protein domains Ire1: The Unfolded Protein Response 1. [Bip]-[Ire1]: heterodimer: Ire1 homodimer was prevented 2. Unfolded protein↑ → Bip↓ : [Bip]-[Ire1] → Bip + Ire1 3. Ire1 + Ire1 → [Ire1]₂ homodimer → Unspliced Hac1 mRNA → Spliced Hac1 mRNA → Translation → Hac1 TF → Nuclear → Gene expression © Lodish, Molecular Cell Biology, Eight Edition, p606 13.4 Targeting of Proteins to Mitochondria and Chloroplasts States: Mitochondrial and chloroplast proteins encoded by nuclear genes are synthesized on cytosolic ribosomes, and maintained in an unfolded state by chaperones. Targeting Sequences: N-terminal targeting sequences direct post-translational transport of the unfolded proteins through translocons into the organelles. Direction: Multiple internal targeting sequences direct protein targeting inside the organelles to different membrane and lumen destinations. PS: Energy required, usually two system: one for targeting the organelles, one for sorting to the part of the organelle. Organelle targeting sequences are similar in their location and general function, but differ in sequence characteristics. © Lodish, Molecular Cell Biology, Eight Edition, p609 Import of Mitochondrial Proteins © bio protocol, 2021 N-terminal targeting sequence Variety: share common motif but different in sequence Composition: rich in hydrophobic (A, L), + charged, and hydroxlated (S, T). But lack of - charged (D, E). Property: Amphipathic α-helix → one side hydrophobic, one side opsitive charged. Required for uptake: Matrix-targeting sequence Respiring mitochondria (proton-motive force) ATP cytosolic chaperone proteins that maintain the precursor proteins in an unfolded conformation. Import into Mitochondrial Matrix © Lodish, Molecular Cell Biology, Eight Edition, p611 1. Cytosol: Protein + chaperones. (Hsp70, Hsp90) 2. Initiating: MTS + import receptor. 3. MTS → outer membrane translocon (Tom40, general import pore). 4. Protein → Tom → inner translocon (Tim). 5. Matrix Hsp70+Cargo: Import↑. 6. [Hsp70]-[Cargo] + ATP → ADP + Pi + Cargo; Targeting Sequence Cleaved 7. Folds (may use other chaperones). Matrix-targeting sequence (MTS) Three Pathways to Inner Mitochondrial Membrane © Lodish, Molecular Cell Biology, Eight Edition, p615](https://www.amazon.com/Molecular-Cell-Biology-Harvey-Lodish/dp/1464183392) Path Signal Receptor Insertion Path A N’ MTS Tom and Tim Stop-transfer anchor sequence: Tim block Transfer Path B N’ MTS Tom and Tim Oxa1: insert protein Path C Internal Sequence Tom Different Tim incorporates multiple hydrophobic segments Two Pathways to Mitochondria Intermembrane Space © Lodish, Molecular Cell Biology, Eight Edition, p616](https://www.amazon.com/Molecular-Cell-Biology-Harvey-Lodish/dp/1464183392) Path A Path B Signal Sequence MTS (removed in matrix) No MTS or Tim targeting sequences. Inner membrane Stop transfer sequence → releases from Tim Don’t involved Release Inner membrane protease Stay at here and form disulfide bonds to prevent reverse translocation Two Pathways to Chloroplasts Intermembrane Space © Lodish, Molecular Cell Biology, Eight Edition, p616](https://www.amazon.com/Molecular-Cell-Biology-Harvey-Lodish/dp/1464183392) Through Toc|Tic → Stromal import sequence cleavage → Thylakoid targeting sequence exposes. Path A: Thylakoid - targeting sequence binds SRP → SRP receptor and translocon. Translocation of protein into thylakoid lumen. Thylakoid- targeting sequence-removed. Path B: Twin arginine signal induces Tat (Twin-arginine translocation). pH gradient across thylakoid membrane drives translocation. (Bound metal Ion) Cleavage of Tat sequence. 13.5 Targeting of Peroxisomal Proteins © Lodish, Molecular Cell Biology, Eight Edition, p616](https://www.amazon.com/Molecular-Cell-Biology-Harvey-Lodish/dp/1464183392) Luminal proteins are from cytosolic ribosomes, contain a targeting sequence, and are incorporated into the peroxisome post-translationally. Folded luminal proteins are imported by a system involving a cytosolic receptor protein and translocation machinery on the peroxisomal membrane. Peroxisomal membrane proteins contain different targeting sequences than peroxisomal matrix proteins and are imported by a different pathway. Targeting sequence (PTS1): C-terminal peroxisomal recognized by Pex5 receptor Cytosolic Pex5 receptor Pex14: receptor/channel Peroxisome luminal proteins: Encoded by nuclear genes and synthesized on free ribosomes in the cytosol. Incorporated into preexisting or newly generated peroxisomes. PTS1 + Pex5 → [PTS1]-[Pex5] → [PTS1]-[Pex5]-[Pex14] → [Pex5]-[Pex14] → PTS1 + Lumen. Pex10: [Pex5]-[Pex14] + Ub → Pex14 + [Pex5]-[Ub]→ + ATP → ADP + Pex5 + Ub Can be PTS2/Pex7 instead of PTS1/Pex5.","link":"/2021/10/16/LearnNotes/tulane-cellbio-7/"},{"title":"8 Vesicular Traffic|Advanced Cell Biology|Tulane","text":"Vesicular Traffic Lodish MCB, 8th ed., pages 631-659. 14.1 Techniques for Studying the Secretory Pathway 14.2 Molecular Mechanisms of Vesicle Budding and Fusion 14.3 Early Stages of the Secretory Pathway 14.4 Later Stages of the Secretory Pathway 14.1 Studying the Secretory Pathway Various labels enable tracking protein movement through the secretory pathway to different destinations. Components required for intracellular protein trafficking have been identified by analysis of yeast temperature-sensitive secretory (sec) mutants. Cell-free assays for intercompartmental protein transport have defined individual steps of the secretory pathway. Protein Transport through the Secretory Pathway © Lodish, Molecular Cell Biology, Eight Edition, p635 GFP labeled viral membrane glycoproteins synthesized and transported to host cell membrane by the constitutive secretory pathway. Looked at time points to determine cell location. At 0 time point, VSV G-GFP retained in ER. At 40 min, most concentrated in the Golgi. At 180 min, most VSV G-GFP has integrated into and is diffusing within the plasma membrane. Secretory and Endocytic Pathways © Lodish, Molecular Cell Biology, Eight Edition, p633 Transport vesicles transport membrane and soluble proteins from one membrane-bound compartment to another. Transport vesicles collect cargo proteins in membrane budding from a donor compartment and deliver cargo by fusing with a target membrane. Secretory pathway distributes cargo proteins to final destinations (ER, Golgi, cell surface (including secretion) or lysosomes. Cargo buds from the ER, fuse together to form a new cis-Golgi cisternae → move by nonvesicular cisteral maturation, and retrograde vesicle transport. Regulated (aggregates) and constitutive secretion. Lysosomal proteins bud and fuse with late endosome. Endocytic vesicles bud from plasma membrane, delivered to lysosomes via late endosomes. Sec Mutants Identify 5 Stages of Secretory Pathway © Lodish, Molecular Cell Biology, Eight Edition, p637 Yeast temperature-sensitive mutants define 5 major stages and individual components involved in targeting and vesicular transport: Cytosol, Rough ER, Vesicles transporting proteins from the ER to the Golgi complex, Golgi cisternae, and constitutive secretory vesicles Mutations simultaneously in both class B and class D functions: proteins accumulate in rough ER, not in Golgi → defines order of steps ER to Golgi Transport and Processing © Lodish, Molecular Cell Biology, Eight Edition, p636 Yeast temperature-sensitive mutant: At 40°C is retained in ER, not processed in Golgi. At 32°C, transported to Golgi and processed. Shows that processing of glycosylation occurs in Golgi. EXPERIMENTAL FIGURE 14-3 Transport of a membrane glycoprotein from the ER to the Golgi can be assayed based on sensitivity to cleavage by endoglycosidase D. Detecting secretory protein carbohydrate modifications by compartment-specific enzymes elucidates trafficking through different compartments. Experiment: Temperature-sensitive VSV G protein – labeled with a pulse of radioactive amino acid during synthesis in cells Split cells into two groups – Group 1 – Control cells maintained at 40°C – misfolded protein retained in ER Group 2 – Experimental cells shifted to 32°C – protein moves through secretory pathway Time points – VSV G protein extracted and treated with endoglycosidase D (a) Protein movement to cis-Golgi and modification: Protein retained in the ER – not modified Protein moved from the ER to the cis-Golgi – core oligosaccharide Man8(GlcNAc)2 is trimmed to Man5(GlcNAc)2 by cis-Golgi resident enzymes Endoglycosidase D – cleaves the oligosaccharide chains from proteins processed in the cis-Golgi, but not from proteins retained in the ER (b) SDS-polyacrylamide gel electrophoresis of the digestion mixtures (Autoradiography only shows labeled VSV G protein in gel.): (ER) resistant – uncleaved (larger-slower-migrating) (cis-Golgi) sensitive – cleaved (smaller-faster-migrating) 5 min – most protein resistant to EndoD cleavage – not yet moved from ER to cis-Golgi ER 60 min – most protein cleaved by EndoD cleavage – moved to and modified in the cis-Golgi © Percentage of EndoD-sensitive VSV G protein over time: Derived from electrophoretic data 40°C – little increase n sensitive protein – misfolded proteins retained in ER 32°C – most protein moved from ER to cis-Golgi and modified by 30–40 min Protein Transport from One Golgi Cisternae to Another © Lodish, Molecular Cell Biology, Eight Edition, p637 Mutant in cis-Golgi. Cannot process from High mannose glycosylation. Wild type processes glycosylation in each of the Golgi cisternae. Mixing of Golgi shows cis-Golgi enzyme (N-acetylglucosamine transferase) moved from wild type medial Golgi to mutant cis-Golgi by retrograde vesicle transport during cisteral maturation process. EXPERIMENTAL FIGURE 14-5 A cell-free assay demonstrates protein transport from one Golgi cisterna to another. Cell-free transport assays – biochemical dissection of secretory pathway individual steps Experiment: VSV virus infection of cultured mutant cells lacking one of the Golgi enzymes that modify N-linked oligosaccharide chains –fate of the VSV G protein. (a) VSV G protein modification in Golgi of intact wild-type and mutant fibroblast cells Wild-type cells: medial-Golgi – N-acetylglucosamine transferase I adds one N-acetylglucosamine to N-linked oligosaccharides trans-Golgi – N-linked oligosaccharides further modified to more complex carbohydrate Mutant cells – lack medial-Golgi N-acetylglucosamine transferase I: medial-Golgi – no addition of N-acetylglucosamine trans-Golgi – no further modification to complex carbohydrate G protein reaches the cell surface with a simpler high-mannose oligosaccharide containing only two N-acetylglucosamine and five mannose residues. (b) Golgi isolated from VSV-infected mutant cells and noninfected wild-type cells: Mutant cell Golgi – contains VSV G protein Wild-type cell Golgi – no VSV G protein Golgi mixed together Result: Some VSV G protein modified by wild-type medial-Golgi N-acetylglucosamine transferase I Conclusion: N-acetylglucosamine transferase I – moved by transport vesicles from the wild-type medial-Golgi cisternae to the mutant cis-Golgi during cisternal maturation process. 14.2 Molecular Mechanisms of Vesicle Budding and Fusion Three types of coated vesicles mediate protein transport through different pathways. Small GTPase proteins direct coat protein polymerization on donor membranes to pinch off vesicles carrying different cargoes. Coat shedding exposes Rab and SNARE proteins that target vesicles for fusion with specific target membranes. Vesicle Budding and Fusion with a Target Membrane © Lodish, Molecular Cell Biology, Eight Edition, p640 Coat proteins bind membrane cargo cytosolic domain. Soluble cargo bind receptors, receptor also binds coat protein. Vesicle SNARES (v-SNARES) captured in budding vesicle. Coat evaginates donor membrane, pinches off coated vesicle. Monomeric GTP-binding protein also binds coat protein in GTPbound form. GTP hydrolysis → decoating. G protein also leaves. Decoating uncovers v-SNARES, interaction with target membrane t-SNARES for membrane fusion. Coated Vesicles Involved in Protein Trafficking Three major types of transport vesicles: each with a different type of protein coat and monomeric GTPase protein. Vesicle Type Transport Step Mediated Coat Proteins Associated GTPase COPII ER to cis-Golgi Sec23/Sec24 and Sec13/Sec31, Sec16 Sar1 COPI cis-Golgi to ER Later to earlier Golgi cisternae Coatomers containing seven different COP subunits ARF Clathrin and adapter proteins* trans-Golgi to endosome Clathrin + AP1 complexes ARF trans-Golgi to endosome Clathrin + GGA ARF Plasma membrane to endosome Clathrin + AP2 complexes ARF Golgi to lysosome, melanosome, or platelet vesicles AP3 complexes ARF Sar1 Role Assembly/Disassembly of COPII Coat © Lodish, Molecular Cell Biology, Eight Edition, p641 GEF function: Sar1-GDP → Sar1-GTP, membrane bound. Sar1-GTP recruits coat proteins, curvature forms bud w/ cargo. GTP hydrolysis, Sar1-GDP loses affinity for vesicle membrane. Sar1-GDP not membrane bound, promotes coat disassembly. Image: Coated vesicles accumulate during in vitro budding in presence of nonhydrolyzable GTP analog. Docking/Fusion of Vesicle w/Target Membrane © Lodish, Molecular Cell Biology, Eight Edition, p643 Vesicle Rab binds Rab effector on target membrane. v-SNARE forms stable coiled-coil interaction with t-SNAREs (syntaxin and SNAP-25); hold vesicle close to target membrane. Fusion of two membrane → drives dissociation of the SNARE complexes (4), freeing SNARE proteins (recycled by NSF – an AAA-family member). Not shown: Rab-GTP hydrolyzed to RabGDP – dissociates Rab from the Rab effector. Targeting Sequences on Cytosolic Regions of Cargo Proteins Bind to Specific Coat Proteins Signal Sequence* Signal-Bearing Protein Proteins with Signal Vesicles That Incorporate Signal Receptor LUMINAL SORTING SIGNALS Lys-Asp-Glu-Leu (KDEL) ER-resident soluble proteins KDEL receptor in cis-Golgi membrane COPI Mannose 6-phosphate (M6P) Soluble lysosomal enzymes after processing in cis-Golgi M6P receptor in trans-Golgi membrane Clathrin/AP1 CYTOPLASMIC SORTING SIGNALS Lys-Lys-X-X (KKXX) ER-resident membrane proteins COPI α and β subunits COPI Asn-Pro-X-Tyr (NPXY) LDL receptor in plasma membrane AP2 complex Clathrin/AP2 14.3 Early Stages of the Secretory Pathway COPII-coated vesicles transport newly synthesized proteins containing Golgi-targeting sequences in their cytosolic domain or bound to such proteins from the rough ER to the cis-Golgi (anterograde direction). COPI-coated vesicles transport vesicles carrying ER/Golgi-resident proteins in the retrograde direction, which supports Golgi cisternal maturation. Vesicle-Mediated ER and cis-Golgi Trafficking © Lodish, Molecular Cell Biology, Eight Edition, p644 Forward (anterograde) transport: COPII vesicles ER → cis-Golgi transport. Step 1: COPII coat assembles. Step 2: COPII coat disassembly. Step 3: Membrane fusion Reverse (retrograde) transport: COPI vesicle cis-Golgi to ER transport. Cargo: recycles membrane bilayer, v-SNAREs, and missorted ERresident proteins. Step 4: COPI coat assembles. Step 5: COPI coat disassembly. Step 6: Membrane fusion. KDEL Receptor Retrieval of ER-Resident Luminal Proteins from the Golgi © Lodish, Molecular Cell Biology, Eight Edition, p647 Soluble ER proteins contain KDEL (LysAsp-Glu-Leu) ER-targeting sequence. May become missorted to cis-Golgi: Nonspecifically incorporated into COPII vesicle fluid phase. cis-Golgi to ER retrieval mechanism: cis-Golgi acidic pH promotes receptorKDEL interactions. Higher pH of ER → dissociates ER resident KDEL protein from the KDEL receptor. Retrieval system prevents depletion of ER luminal proteins. Processing of N-linked Oligosaccharide within cis-, medial-, and trans-Golgi Cisternae © Lodish, Molecular Cell Biology, Eight Edition, p648 trans-Golgi: N-acetylneuraminic acids added (7). Galactoses added (6). medial-Golgi: Fucose added (5). Mannoses removed (3). N-acetylglucosamines (GlcNAc) added (2 and 4). cis-Golgi: Mannoses removed (1). Anterograde transport occurs by cisternal maturation. Golgi cisternae have different enzymes. 14.4 Later Stages of the Secretory Pathway The trans-Golgi network sorts proteins into vesicles targeted for different destinations. Lysosomal enzymes bear M6P residues that are recognized by M6P-receptors and delivered by a clathrin-coated vesicle pathway to lysosomes. Regulated secretory proteins are concentrated and stored until secretion is signaled; constitutively secreted proteins are continuously delivered to the plasma membrane. Some proteins are processed into mature form after leaving the trans-Golgi network. Vesicle Trafficking from trans-Golgi Network © Lodish, Molecular Cell Biology, Eight Edition, p651 (5) Regulated secretory vesicles (unknown coat). (4) Constitutive secretory vesicles (unknown coat). (3) Clathrin-coated (+AP2) vesicles transport to late endosomes. (2) AP complex vesicles transport directly to lysosomes. (1) COPI vesicles: retrograde to trans-Golgi (cisternal progression). Distal sorting trans-Golgi network: transport vesicles to plasma membrane, endosomes, and lysosomes. Dynamin Pinching Off of Clathrin-Coated Vesicles © Lodish, Molecular Cell Biology, Eight Edition, p652 Dynamin: Required for pinching off of clathrin-coated vesicles Polymerizes around vesicle neck Hydrolyzes GTP – conformational change coupled to membrane fusion and vesicle release from the donor membrane. GTP hydrolysis by dynamin is required for the pinching off of clathrin-coated vesicles (cells incubated with GTP-γ-S nonhydrolyzable analogue of GTP). Formation of Mannose 6-phosphate (M6P) to Target Soluble Enzymes to Lysosomes © Lodish, Molecular Cell Biology, Eight Edition, p653 M6P signal directs newly synthesized enzymes to lysosomes. Step 1: cis-Golgi-localized N-acetylglucosamine (GlcNAc) phosphotransferase transfers a phosphorylated GlcNAc group to carbon 6 of one or more mannose residues. Step 2: Phosphodiesterase removes the GlcNAc group, leaving a 6-phosphorylated mannose residue on the lysosomal enzyme. Trafficking of Lysosomal Enzymes from trans-Golgi Network and Cell Surface to Lysosomes © Lodish, Molecular Cell Biology, Eight Edition, p654 M6P receptors in trans-Golgi membrane recruit M6P-lysosomal enzymes into clathrin/AP1-coated vesicles (1). Clathrin coat disassembles (2). Coat proteins recycled (2a). Vesicle fuses with late endosome compartment (3). Acidic pH dissociates M6P-enzyme from receptor. Late endosome fuses with a lysosome (4). M6P receptors recycled (4a). Some receptors are delivered to the cell surface (5a). Plasma membrane M6P receptors (5) capture missorted M6P-enzymes into clathrin-coated vesicles in the receptor-mediate endocytosis pathway (6). Deliver enzyme to endosome/lysosome (7-8) I Cell Disease: Mistargeting of Lysosomal Enzymes to Extracellular Matrix Lack of N-acetylglucosamine phosphotransferase activity. Lysosomal enzymes lack M6P targeting signal → constitutively secreted (5a). Continued accumulation of undigested lysosomal contents → forms “inclusions bodies”, may eventually kill cells. Causes developmental, physiological, and neurological abnormalities. Referred to as Mucolipidosis. In vitro “cure” – M6P-enzymes added to I-cell fibroblasts – internalized by endocytosis pathway and function on arrival in lysosomes. VERY EXPENSIVE. Proteolytic Processing of Proproteins in Constitutive / Regulated Secretory Pathways © Lodish, Molecular Cell Biology, Eight Edition, p657 Proproteins matured after leaving trans-Golgi. (a) Proalbumin processing – typical of proteins in constitutive secretory pathway: Furin endoprotease cleaves peptide. (b) Insulin processing – typical of proteins in regulated secretory pathway: PC2 and PC3 endoproteases – cleave central region of insulin. C peptide secreted with insulin. High C peptide levels → kidney problems or insulinoma. Low C peptide → low insulin (T1 diabetes). Sorting Proteins Destined for Apical and Basolateral Membranes of Polarized Cells © Lodish, Molecular Cell Biology, Eight Edition, p658 VSV G protein only on the basolateral membrane (VSV viruses bud only from the basolateral membrane.) Serosal Mucosal Influenza HA glycoprotein only on the apical membrane (Influenza viruses bud from only from the apical membrane). Also GPI proteins in some cell types IgA internalized at basolateral membrane and sorted to apical membrane by transcytosis Some hepatocyte apical membrane proteins sorted initially to basolateral membrane, endocytosed and transcytosed through endosomes to the apical membrane.","link":"/2021/10/18/LearnNotes/tulane-cellbio-8/"},{"title":"9 Receptor-Mediated Endocytosis|Advanced Cell Biology|Tulane","text":"Receptor-Mediated Endocytosis Influenza Virus Infects by Viral Hemagglutinin Interaction with Host Cell Sialic Acid © Creative Biolabs Host Antigen: Sialic acid; Viral Antigens: Hemagglutinin (H), Neuraminidase (N) Neuraminidase cleaves host Sialic acid, enhances release of new viral particles. Antiviral Neuraminidase inhibitors: Tamiflu (Oseltamivir) and Relenza (Zanamivir). Viral subtypes derive from 18 H and 11 N possible antigens. Vaccine against common H and N antigens. Changes yearly due to antigenic drift. Endocytosis activate: [Hemagglutinin]-[Sialic] Lysosome Fuse: H⁺ release to change the pH → Hemagglutinin conformation changed Neuraminidase： Cleave Sialic → Enhance releases Antiviral Neuraminidase inhibitors: Tamiflu (Oseltamivir) and Relenza (Zanamivir). © Dr.G Bhanu Prakash Animated Medical Videos; 2019 youtube 14.5 Receptor-Mediated Endocytosis Clathrin-coated vesicles: [Ligands]::[AP2-targeting sequences]-[Receptors] Ligands delivers: Exp: LDL Dissociation: Receptor-ligand complexes dissociated in acid environment: receptor → cytoplasm → recycling ligand → lysosome → degradation Ttransferrin carrier: Iron endocytosis Fe3+ → endosome and recycle transferrin • Extracellular ligands bound to specific cell-surface receptors with cytoplasmic domain AP2-targeting sequences are internalized by clathrin-coated vesicles. • The endocytic pathway delivers some ligands (e.g., LDL particles) to lysosomes, where they are degraded. • The late endosome acidic environment dissociates most receptor-ligand complexes for receptor recycling to the plasma membrane and ligand degradation in lysosomes. • The iron endocytosis pathway releases Fe3+ in the late endosome but recycles the transferrin carrier proteins with the receptor to the plasma membrane. Initial Stages of RME of Low-Density Lipoprotein (LDL) Particles © Lodish, Molecular Cell Biology, Eight Edition, p661](https://www.amazon.com/Molecular-Cell-Biology-Harvey-Lodish/dp/1464183392) (a) LDL-LDL receptor complexes invaginated in AP2-clathrin-coated pit. (b) Pit closes. Dynamin associates with neck region. © AP2-Clathrin-coated vesicle containing free in cytoplasm (d) LDL-LDL receptor complexes in decoated endosome. © iotech Review; 2014 youtube RME: Receptor-mediated endocytosis LDL: low-density lipoprotein RME is used by cells to import specific macromolecules or complexes too large to be imported by membrane transporters Uptake specificity is receptor-dependent, in clathrin/AP2-coated vesicles. Experiment: LDL particles (contain cholesterol): labeled with electron-dense, iron-containing ferritin protein (visible with EM) Cultured fibroblasts incubated with LDL-ferretin at 4°: LDL binds to LDL-receptors; endocytosis process is inhibited Cells warmed to initiate endocytosis. RME receptors: Some types cluster in clathrin-coated pits by cytoplasmic domain association with AP2 even in absence of ligand. Others types diffuse freely in the plasma membrane until a ligand-induced conformational change associates them with AP2. Two or more types of receptor-bound ligands, such as LDL and transferrin, can be present in the same coated pit/vesicle. Cellular Uptake / Degradation of LDL by RME © Lodish, Molecular Cell Biology, Eight Edition, p661 • LDL-LDL receptor complexes completely bound at membrane surface in AP2-clathrincoated pit. • Internalization of LDL-LDL receptor receptor increases as binding at cell surface decreases. • Degradation begins within 10-15 minutes, as internalization reached its maximum. Pulse-chase experiment demonstrates precursor-product relations in cellular uptake of LDL. Experiment: LDL labeled with 125I Cultured normal human skin fibroblasts – incubated with 125I-LDL for 2 hours at 4°C (pulse) – LDL binds to surface LDL receptors; not endocytosed Unbound LDL – washed away Shift to 37°C – activates RME (chase) Results: 125I-LDL rapidly disappears from surface (binding) by RME. 125I-LDL in internal vesicles rises coincidently. After a 15 min lag – 125I-LDL degradation in lysosomes increases. Model of LDL Particle © Lodish, Molecular Cell Biology, Eight Edition, p661 • Cells take up lipids from the blood in the form of large, welldefined lipoprotein complexes (LDL, VLDL, HDL, Chylomicon). • All classes of lipoproteins have the same general structure. Model of LDL Receptor and LDL Binding • Shell composed of a phospholipid monolayer (not bilayer) containing cholesterol. Interacts with aqueous environment for transport in blood. • Apolipoprotein B (ApoB) is ligand for LDL receptor. • Hydrophobic core is mostly cholesteryl esters/triglycerides (minor neutral lipids [vitamins]). Model of LDL Receptor and LDL Binding © Lodish, Molecular Cell Biology, Eight Edition, p663 (a) LDL receptor at neutral pH (binding LDL at cell surface): - Ligand binding arm seven cysteine-rich repeats (R1–R7) – tightly bind LDL apoB-100 (R4 and R5 – most critical for LDL binding) - Note receptor NPXY AP2- targeting cytosolic domain. (b) LDL receptor at acidic pH (releasing LDL in endosome): - β-propeller domain histidine residues become protonated. - Positively charged propeller domain binds negatively charged ligand-binding domain → release of LDL particle. PS: (b, bottom) LDL receptor at pH 5.3 structure – extensive hydrophobic and ionic interactions between the β propeller and R4 and R5 repeats - Human disease – Familial Hypercholesterolemia - Excessive circulating LDL causes cardiovascular disease. - LDL receptor mutations cause too little LDL uptake/clearance into cells (liver cells). - Several LDL receptor mutations including a single amino acid mutation in NPXY targeting sequence causes inefficient LDL receptor RME – FH disease. LDL-LDL Receptor Mediated Endocytosis © Lodish, Molecular Cell Biology, Eight Edition, p662 Physiologic pH: LDL receptor has high affinity for LDL. Lysosomal pH: LDL receptor has low affinity for LDL. Receptor recycled Clinical Implications: Familial Hypercholesterolemia Excessive circulating LDL causes cardiovascular disease. a. Heterozygous – LDL ~2X elevated in blood b. Homozygous – LDL 4X-6X elevated c. Atherosclerotic plaques b. Premature heart attacks (as early as 20s) LDL receptor mutations cause too little LDL uptake or clearance into cells (liver cells). a. LDL receptors are absent b. Defective LDL binding sites c. Improper folding → premature receptor degradation d. NPXY mutation affects sorting to AP2 vesicles e. Mutation in ApoB ligand, ↓ affinity for LDL receptor Cells regulate their cholesterol by a. Inhibition of cholesterol synthesis b. Down-regulation of LDL receptor Transferrin Cycle © Lodish, Molecular Cell Biology, Eight Edition, p664 Transferrin Cycle: Ferrotransferrin binds transferrin receptor at cell surface pH 7.0 (1). Transferrin receptor forms AP2 clathrin-coated vesicle → RME to late endosome (2-4). Acidic pH dissociates Fe3+ → Apotransferrin recycled to cell surface. Extracellular neutral pH, receptor releases apotransferrin. Fe3+ reduced to Fe2+ for use. Transferrin protein comes in two forms, apotransferrin (not bound to Fe3+) and Ferrotransferrin (carries Fe3+ in blood). Transferrin binding to transferrin receptor is pH-dependent: Receptor binds Ferrotransferrin at physiologic pH (pH ~7.0). Receptor binds Apotransferrin at lysosomal pH (pH ~5.0). RME endocytic pathway delivers iron to cells without dissociation of the transferrin–transferrin receptor complex in endosomes. Transferrin protein: Apotransferrin – no bound Fe3+ Ferrotransferrin – carries Fe3+ in blood Binds to transferrin receptor Uptake mechanism: Ferrotransferrin dimer with two Fe3+ binds tightly to transferrin receptor at the cell surface – ~pH 7.0. Transferrin receptor cytoplasmic tail interaction with an AP2 adapter complex – incorporates receptor-ligand complex into endocytic clathrin-coated vesicles Clathrin disassembly uncoats vesicle. Vesicle fuses with late endosome – acidic pH – Dissociates Fe3+ from ferrotransferrin – Fe3+ reduced to Fe2+ by endosome reductase Transported from endosome to cytoplasm Maintains apotransferrin-receptor complex Recycling of receptor-apotransferrin complex to the plasma membrane Extracellular neutral pH destabilizes complex – releases apotransferrin from receptor 14.6 Directing Membrane Proteins and Cytosolic Materials to the Lysosome ESCRT (endosomal sorting complex required for transport) Endocytosed membrane proteins targeted for degradation in the lysosome are incorporated into vesicles that bud into the interior of the endosome. Cellular components (e.g., ESCRT) that mediate endosome membrane budding are used to pinch off enveloped viruses such as HIV from the plasma membrane of virus-infected cells. Autophagy envelopes a region of cytoplasm or an organelle into a double-membrane autophagosome for delivery to a lysosome. Delivery of Plasma-Membrane Proteins to Lysosome Interior for Degradation Membrane proteins for degradation → delivered to lysosome lumen © Lodish, Molecular Cell Biology, Eight Edition, p666 Mechanism: Vesicles carrying newly synthesized lysosomal membrane proteins (green) from the trans-Golgi network – fuse with the late endosome Endosomes carrying endocytosed plasma-membrane proteins (blue) targeted for degradation – fuse with the late endosome Late endosome: Plasma membrane proteins targeted for degradation – incorporated into vesicles that bud into the interior of the late endosome Forms a multivesicular endosome Multivesicular endosome fuses with a lysosome: Internal vesicles (containing targeted membrane proteins)– degraded Lysosomal membrane proteins – not degraded Formation of Multivesicular Endosomes © Lodish, Molecular Cell Biology, Eight Edition, p667 Proteins for multivesicular endosome degradation are tagged with ubiquitin at the plasma membrane, in the trans-Golgi network, or in the endosomal membrane (cargo proteins). Ubiquitinated Hrs protein on endosomal membrane direct loading of ubiquitinated membrane cargo proteins (blue) into multivesicular endosomes. Cytosolic ESCRT protein complexes and Hrs mediate pinching off of inwardly budding vesicles. Vps4 ATP hydrolysis drives disassembly and recycling of ESCRT complex proteins. HIV Budding from Plasma Membrane © Lodish, Molecular Cell Biology, Eight Edition, p668 • Retrovirus (HIV) budding from plasma membrane exploits ESCRT/Vps4 machinery for multivesicular endosomes. • Ubiquitinated viral Gag proteins function like Hrs protein → recruit ESCRT/Vps4 complexes to pinch off viral particle. The Autophagic Pathway • Autophagic pathway delivers cytosolic proteins and organelles to lysosomes for degradation. • ATG proteins induce formation of cup-shaped membrane structure around a portion of the cytosol (right) or an organelle (left) to create am autophagosome. • Autophagosome envelop contents in two complete membranes. • Fusion of autophagosome outer membrane with the lysosome membrane releases a singlemembrane vesicle and its contents into the lysosome interior for degradation. Mechanism: ATG proteins induce formation of cup-shaped membrane structure around (right) a portion of the cytosol (left) an organelle such as a mitochondrion Proteins involved include Atg 5, 8, 12, 16 – Atg 8 forms coat around autophagosome Step 1: Continued membrane addition and fusion forms autophagosome – envelops contents in two complete membranes Step 2: Fusion of the autophagosome outer membrane with the lysosome membrane – Releases a single-membrane vesicle and its contents into the lysosome interior Vesicle protein and lipid components – degraded by lysosomal hydrolases Amino acids – permease transport across the lysosomal membrane into the cytosol for use in protein synthesis","link":"/2021/10/18/LearnNotes/tulane-cellbio-9/"},{"title":"Notes for Genetics","text":"Who knows = = Extra DNA, why? transposon DAN transposon: cut &amp; paste Retrotransposon: copy &amp; paste DNA transposon: transpoase recognize the IR sequences and cut it out. Form a Pre-integration complex Jump into another site of DNA IR: inverted repeat TSD: target site duplication (direct repeat) exp: © The Tn3-family of Replicative Transposons © viralzone Retrotransposons Retrotransposons have shared similarity with retroviruses Reverse transcriptase Similar in life cycle, similar in gene structure. Consequence of transpositon Insertion of a sequence in a new site Cutting of DNA strands Generally: mutagenic processes, generally bad in excess Potential disadvantages: disruption of coding sequence deletion/rearrangements of the sequences non-allelic homologous recombination (based on similar seq contributed by transposons) alternative splicing Epigenetic alterations “transduction” of neighboring sequnces premature polyadenylation or other transcription defects Benefits: V(D)J recombination in vertebrates V(D)J recombination generates diversity in immune system The RAGI.RAG2 complex catalyses the programmed deletions during antibody rearrangement. Exp a dramatic example of active retrotransposition that is “put to use” by the hose - Drophila telomeres non-LTR retrotransposons replaces the function of the telomerase to extending the end of the linear chromosomes. P elements, more information need P elements are transposable elements that were discovered in Drosophila as the causative agents of genetic traits called hybrid dysgenesis. The transposon is responsible for the P trait of the P element and it is found only in wild flies. They are also found in many other eukaryotes.[1] Generate Mouse models Spontaeous mutant starins chemical-induced mutatgenesis models Transplatntation/Engraftment models Transgenic and gene targeting models PDX mouse models. PS: PDX can preserve the traits better than other for some reason. Spontaneously arising mutatnt strain lethal yellow Maturity-onset obesity Adipocytehypertrophy hypertriglyceridemia Hyperinsulinemia Diabetes Hypatic lipogenesis Increased caloric efficiency Chmical mutagensis mouse models Germline: N-ethyl-N-nitrosourea ENU (1/700 loci) (cause random mutations in sperm) Pancreas: Streptozotocin (destroys pancreatic β-cells), T1D Skin: 7,12-dimethylbenz[a]anthracene (DMBA) + TAP Lung: Nitrosamines Linve Bearst; Colon: Bladder Cheap, quick, and generate lots of mutatios Hard to figure out where, when, and how it cause the mutation. ENU-induced mutatgenesis generates random mutat strains Gene knockout → gene1 → Phenotype 1, 2, 3 Genome-wide mutatgenesis → lots of lots of genes → Lots of interested phynotypes Forward and reverse Genetic Screens Forward: Spontaneously arising Phynotype Screen Mutation phenotypes reveal gene functions Map the genes and identify the gen products Reverse genetic screen ENU - induced mutagenesis it oxidize the G and destroy the hydrogen bond of the G Forward genetic screen using ENU-induced mutagenesis Patient-dereived xenograft (PDX) Model Plant cancers from human to growth on mouse. HGPS HGPS Muscular dystrophy Cardiomyopathy Lipodystrophy Mutation from laminopathies, Laminin A Laminin A is a structural protein that forms nuclear lamina in inner nuclear membrane nuclear lamina is importatnt for maintatining interphase nuclear architecture heterozygous C to T substitution at 1824, G608G. Reducing LMNA gene dosage rescues Zmpste24 KO-induced progera syndrome phnetype Sketch for CH12 Target: How Regulated Variaty ways for regulation Chromatin in regulation Epigemetic Markers RNA regulation (miRNA, post-TGR) Difference between the eukaryotic cells and prokaryotic cells: One RNA pol in prokaryotic but 3 in Eu Intron and exon Majumdar, S; Rio, DC (April 2015). “P Transposable Elements in Drosophila and other Eukaryotic Organisms”. Microbiology Spectrum. 3 (2): MDNA3–0004–2014. doi:10.1128/microbiolspec.MDNA3-0004-2014. PMC 4399808. PMID 26104714. ↩︎","link":"/2022/01/24/LearnNotes/tulane-genetics-1/"},{"title":"Wnt signal pathways","text":"Canonical Wnt Signal Pathway © KEGG Resources: © Hussain Biology; youtube, 2018 © Catalyst University: youtube, 2019 Without the Wnt From the KEGG pathway map, we can know that a receptor complex is composed by LRP and frizzled. On the downside of the receptor, there is a degradation complex (grey arear on the map which name is scaffold) which mad by Axin, CKI, GSK3B, and the most important two proteins: $\\beta$-catenin and APC. CKI and GSK3B both phosphorylate the $\\beta$-catenin and then it was degradation by proteosome. On the other side, which is in the nuclear, protein TCF and LEF formed a complex and bind on the DNA which responsible for transcription of the genes. But groucho bind with TCF/LEF to prohibit the release of DNA. With the present of Wnt When the receptor complex activated by Wnt, Dishevelled protein (Dvl) and degradation complex are recruited by receptor complex. In this way, the $\\beta$-catenin is not ubiquinated and released into the nuclear. Then, $\\beta$-catenin releases the groucho and bind with TCF and started to bind the DNA. In this way, wnt signal pathway regulated genes are activated and expressed. Abnormal in Wnt Intestine stem cells is a group of fast poliferation cell because the intestine epithelial cells only last for 4 days. Lost of tha APC could cause the fail of $\\beta$-catenin phosphorylation and leading the constant of gene transcription (90% of human colon cancer). ?? over-expression of wild-type Wts has relatively little effect on wing growth in wild-type flies, but can suppress the over-growth phenotypes associated with mutation of upstream tumor suppressors that activate Yki[1]. pre { background-color:#38393d; color: #5fd381; } Sun, Gongping, and Kenneth D. Irvine. “Regulation of Hippo signaling by Jun kinase signaling during compensatory cell proliferation and regeneration, and in neoplastic tumors.” Developmental biology 350.1 (2011): 139-151. ↩︎","link":"/2023/03/12/LearnNotes/wnt/"},{"title":"Writing Advises from Online Friends","text":"Writing Advises Collection Writing Consistency Avoiding repeated words one-after-another Some vocabulary like “remain” should be avoid in a present tense Paste tense for Tailing a story Make sure the connection is strong between two sentences where you try to use “on the other hand” @ 远绍 from HelloTalk Vocabulary and clauses “add … to the center”. To the center suggestes a manipulation, and sounds more antural “While” clause works best when fully in a list or in a difference clause. Exp: His favoriate is Beef, while I often enjoy Pork. ‘Living in it’ is a weak-sounding construction. @ 远绍 from HelloTalk Expression Difference in Culture shock It’s somewhat unnatural to speak about an entire gender like: women are as beauty as moon. Singular form is better Sometimes, ‘where’ could replace the ‘which’: Yesterday I read a story which/where a couple fell in love. @ 远绍 from HelloTalk Posts and Corrections why China has so many Chinese characters I think it’s good to know the origin story of Chinese character before you learn it. Though, there are more than ten thousand, or even 100 thousand of Chinese character, they can all be classified into six types. Pictograms (象形), Simple ideograms (指事), Compound ideographs(会意), Rebus characters(假借), Phono-semantic compound characters (形声), and Derivative cognates(转注); Six days to know all types of Chinese character! Day 1: Pictograms Pictograms is the easiest one. As a pictograms, the character was looks like a photo draw by kids. 马(馬) is one of my favorite characters because it just looks like a horse. You can find the horse’s head, horsehair, four lags, and pony tail (If you can’t image that, please look the 1st photo). Other pictograms: 日月山川水火心牛羊鸟马犬虎彘象人田禾子女刀舌 Day 2: Simple ideograms Simple ideograms: They are a group of characters which were simply decorated pictograms. For example, “甘” is a dot or dash on the center of a tongue which means sweat. With the dot, the word had a new related meanings which became a new character. Similar character is “刃”, a dash on a knife, which means the edge of the knife. Other Simple ideograms: 一、二、三、四、末、亦 、本. Six days to know all types of Chinese characters! Day 3: Phono-semantic compound characters Phono-semantic compound characters (PCC, 形声字). PCC is a great invention because it greatly expended the variety of characters without complicating them. For example, “气” is gas. You can still guess that 氢, 氦, 氧, 氩 is some kind of gas because they looks like a gas. One of another key element is another part plays a role of phonetic symbol. 巠(jin) in 氢(qing), 亥(hai) in 氦(hai), 羊(yang) in 氧(yang), 亚(ya) in 氩(ya). As a result, you can figure out all the normal form of element in Periodic Table of Element. All characters with 气 is gas, characters with 金(钅, metal) is metal, characters with 石 (stone) is none-metal solid compound. For more examepels: 艹(草) for plants: 早(zao) in 草 (cao, grass, ), 化(hua) in 花 (hua, flower), 何 in 荷 (he, water lily) 木 for woods: 对(dui) in 树 (shui, tree), 象(xiang) in 橡(xiang, oak), 公(gong) in 松 (song, pine), 氵(水) for water: 可(ke) in 河(he,river),每(mei) in 海(hai, sea),胡(hu) in 湖 (hu, pound) 口 for sound: 啊(a), 嘎(ga), 咔(ka), 哈(ha), 啪(pa), 吧(ba), 嗒(ta), 哒(da) Six days to know all types of Chinese characters! Day 4: compound characters Like the Phono-semantic compound character, compound ideographs has more than two components, too. But not like phono-semantic compound characters, all elements in this word are directly contributed to the meaning of the character. For example, what a 人(man) 言(said) is 信 (worthy to be trusted), 人(people) line a 木(tree) is for 休(rest). two 木(trees) is 林(a small woods), three 木(trees) is 森(forest), two (人)men is 从 (follow), three (人)men is 众(lots of man). Six days to know all types of Chinese characters! Day 5: Rebus characters (RC) After you learned Phono-semantic compound characters (PCC) you can easily remember the pronunciation PCC words like 证(zheng), 抖(dou), and 城(cheng) if you know 正(zheng), 斗(dou), and 成(cheng). But that not means some characters like 说(shuo), 脱(tuo), 悦(yue) pronounce as 兑(tui). The origin of this group of characters is more complicated than the previous. The story goes like, sometimes you have to describe the thing out of your dictionary but you can’t create a character sine others would seem it as a mistake. As a result, you choose to use an existing word to represent it. Sometimes it is hard to distinguish RC from PCC and even a Chinese would make mistakes. For example, I was spell 谙(an) as 音(yin) for a while until I can’t find it when I want to type it. 2021/04/22: 行 S1: “A: 你行不行? B:不行! A:不行也要行!! B: 真不行！难道你行? A: 当然行! B: 真行? A:真行! B:你真行!那行吧！” S2: “人要是行干一行行一行一行行行行行要是不行干一行不行一行一行不行行行不行” Correction contributor: 远绍 from HelloTalk We have a complicated character for today, which is 行. The writing is easy, but the meanings are varied since it has so many pronunciations: háng, hàng, héng, xíng, xìng. Two main of them which frequently appear on the daily are xíng and háng. Again, it is a hieroglyph word. As you can see in the photo below, it was originally an illustration of a crossroad and its roads (noun). But 2,000 years ago, a man changed the shape of this word and made it not look like a crossroad anymore. With further illustration and evolution, it also played the role of a verb, which greatly complicated this character. Because the character was derived from roads, it could mean a lot that directly or indirectly relates to roads. For example: The most common vocabularies you can see: Click to Show Chinese Translation xíng: 1. 行: Ok; 2. 不行: NO; 3. 行不行: Is it ok? 4. 你真行: You did a great job! (ironically, most of the time) 5. 行医: Doing medicine jobs. 6. 行为: behaviors 7. 五行: 金, 木, 水, 火, 土, five basic elements which composed the universe. 8. 步行: by walk háng: 银行: bank (a place doing specific activities focused on money is bank) 多行: multiple lines; (量词) 行业: jobs, areas 行家: A master of something héng: 道行: abilities, kunfu, etc. 我们今天有一个复杂的汉字: 行。它写起来很容易，但因为它有很多的发音:háng, hàng, héng, xíng, xìng, 所以含义非常复杂。其中两个主要日常用的是xíng和háng。另外，它是一个象形文字。 正如你在下面的图片中所看到的，它原本是一个十字路模样的一个名词。但是2000年前，一个人改变了这个字的写法，使它看起来不再像一个十字路口。随着进一步的使用和演变，它又有了动词的功能，这使这个字变得更加的复杂了。 因为这个字来源于道路，所以它可以直接或间接的意味着很多和路相关的东西。例如: 最常见的词汇: Rewrite contributor: 远绍 from HelloTalk We have a complicated character today, which is 行. The writing is easy, but the meaning are varied since it has so many pronunciations: háng, hàng, héng, xíng, xìng.The two pronunciations that you find on the daily are xíng and háng. As you can see in the photo below, it was originally an illustration of a roads and its crossroads, but 2,000 years ago, a man changed the shape if the symbol to make it not look like a crossroad anymore. With further illustration and evolution, 行 also morphed into a verb, which greatly complicated its usage. Because the character was derived from a picture of roads, it often possesses meanings that directly or indirectly related to roads, walking, movement, and so on. For example: The most common vocabularies you can see are: 2021/04/20: 山 &lt;ATTENTION: THE CHINESE VERSION ON THE BACK IS REALLY TOUGH&gt; Correction contributor: 远绍 from HelloTalk 山 is a hieroglyph. As you can see, it has three heels or mountains. It is a very simple character and easy to remember or to write. In Chinese culture, we revere the mountains because, on the one hand, the mountain is huge and unshakable. On the other hand, ancient people believe that every creature and even plants have less or moresome kind of divine powers. Mountains play a role to nurture and habit all kinds of living things. As a result, mountains support a huge quantity of psychic power. Last but not least, our ancestors believe that the mountain is where the immortals and low-ranking divines live. They avoid the contaminated secular world and absorb the pure psychic power from the surroundings to helping them finally evolve into gods. The larger the mountain it is, the largerhigher chance you can meet one. Vocabulary related 山: 爬山: (Hiking on a mountain) Exp: 昨天我们去爬山了山庄: (A house or small village in the mountain) Exp: 这个小山庄还挺难找的病来如山倒: (crashed like a mountain when you get sick) Exp: 明明那么健硕的小伙子, 生了一场病后, 变得骨瘦如柴了. 真是病来如山倒呀! Click to Show Chinese Translation 山是一个象形文字. 如你所见, 他有三个小山丘. 这是一个非常简单且易记, 易书写的文字. 在中华文化中, 我们非常敬畏山. 因为山很大且不可撼动. 另外, 古人相信所有的生物, 包括植物都或多或少的有一些灵力. 正是大山养育并庇护了他们, 所以大山蕴藏着巨大的灵力. 最后, 我们的祖先相信很多小神或半仙隐居在山中. 他们避开被玷污的尘世, 在此汲取天地之精华, 来达到最终得道飞升的目的. 越大的山中, 你将越有可能偶遇他们. Rewrite contributor: 远绍 from HelloTalk This is the hieroglyph Shan: 山 As you can see, it has three little heels or mountains, which makes it a very easy character to write and remember. In Chinese culture, we revere mountain because one hand, they are huge and unshakable. On the other hand, mountains also possess a mystical element. Ancient people believed that all creatures and even plants had some kind of divine power. Because they nurture and give a home to all kinds of these natural creatures, mountains were believed to support an intense web of psychic and magical energy. Finally, our ancestors believed that the tops of mountains are where the immortals and low-ranking divines lived. These divine avoided the contaminated secular world and slowly absorbed the powers from their surroundings to aid in their goal of godhood. It is said that the larger the mountain, the higher chance you have of meeting a divine. 2021/04/19: 月 Correction contributor: 远绍 from HelloTalk 月 is the moon, a hieroglyph. Like the Ssun(日), there is a dash at the center of it. In myth, a diving three-feet frog was living in its surface (Why it’s three feet again? ). There is another romantic story about the moon, which /where was a couple that became the goddivine and ran away tointo the moon forever. The woman had a rabbit with her. Because the light of the moon is as gentle and cold as a jade, ancient people also called the moon as the jade-frog (玉蟾), Ice-frog (冰蟾), or the jade-rabbit (玉兔). It also has another romantic name, Chan Juan (婵娟), which means gorgeous (娟) beauty(婵). So, you can use it to compliment the beauty of a womanwomen(美若婵娟). On the other hand, the Chinese calendar is based on the phases of the sun and the moon. The phase of the moon from one new moon to the next is a month. That’s why we have a full moon on the 15th of each month. WeBecuase of that, we also call a month as ‘one moon’(一个月). Some vocabulary of the moon: 月亮: Moon, 今晚的月亮很大. The moon is large tonight. 月色: the scenery of moonlight, 今晚月色不错. The moonlight (scenery) of tonight is good. 满月: Full moon. 残月: waxing crescent/ waning crescent. Click to Show Chinese Translation 月是月亮, 一个象形文字. 像日字一样, 它中间有一横. 在神话中, 月亮中间住了一只三足金蟾 (为什么又是三条腿?). 除此之外, 我们还有一个浪漫的关于月亮的故事. 一对恩爱的情侣变成了神仙永远的奔向了月亮. 其中的女神仙带着一只兔子. 又因为月光入玉般的温润阴寒, 所以人们又称它, 玉蟾, 冰蟾, 或者玉兔. 此外, 它还有一个美丽的名称: 婵娟. 婵娟是漂亮的美女的意思. 因此, 你可以形容一个女生美若婵娟. 另外, 中国的日历是基于太阳和月亮的相对位置来计算的. 一个新月到下一个新月的时间为一个月. 所以每月15的时候, 月亮都很圆. 我们称一个月(month)为一个月(moon) 2021/04/16: 日 Correction contributor: 远绍 from HelloTalk 日 is a hieroglyph. In the beginning, it was a single circle. After that, people added a dot or a dash to it. There are a few theories and explanations about why people added a dot or a dash atto the center. Some people believe that they just wanted to distinguish it from the ring shape cause the sun is a global or plate. Others thought that they had done this to prevent a mixture with other similar characters like mouth, which was a circle, too. While mMy favorite theory is that people believed there was a god living and ruling the sun. Because traditional Chinese myth illustrated that the sun was settled by a dark crow with 3 feet. reference and picture: 2021/04/15: 龟 Correction contributor: 远绍 from HelloTalk 龟 is one of the most ancient characters. It is a classical hierographical character. It still remains potrays the features of the turtle: you can find a head, a turtle shell, and a tail in this characterpicture. Back in ancient times, people believed that turtles had some kind of mysterious power. So, instead of a Crystal GlobeBall, ancient Chinese shamans usding the bones of the turtle to make an augury. The events were also recorded and carved on the bone, which became one of the oldest (about 3000 years ago) evidenced written systems of China. Since turtles could hide on its shell to protect themselves, people will call men turtles if they feared to stand out and face problems or challenges. Any Words help, so, Please Correct me, Thx. Click to Show Chinese Translation &quot;龟&quot;是一最古老的文字之一. 它是一个典型的象形文字. 它任然保留着乌龟的特征: 你在这个字上, 找到头, 龟壳, 和尾巴. 很久以前, 人们认为乌龟有某种灵力. 所以古代的中国祭祀用龟甲而不是水晶球占卜. 占卜的事件会被镌刻记录在这个龟甲上. 这些文字, 是最早的可考系统性的书写系统之一. 因为乌龟可以躲在自己壳里来保护自己, 所以人们会称那些选择逃避而不是面对问题和挑战的人为(缩头)乌龟.","link":"/2021/04/20/LearnNotes/writing-advice/"},{"title":"Build BSgenome by youself","text":"Build a BSgenome by youself Reference: Tom Guest In this tutorial, I’ll show how to create a BSgenome library with Linux commands. The main steps for doing this are to prepare the fasta files and the configure files. Preparing the sequence files and configuring file We’d like to store each chromosome into an independent file and record them in a configuring file so the BSgenome can find them. Here I use awk to remove useless information in the name and seqkit to extract seqs. Prepare: Genome.fa and seqkit conda install -c bioconda seqkit mkdir BSgenome # make a new directorycd BSgenome # Enter the directoryawk '{print $1}' ../Genome.fa &gt; sample.fa # samplify the name of each sequencegrep &quot;&gt;&quot; sample.fa | sed 's/&gt;//'&gt; list.txt # Get the name sequencesfor i in $(cat list.txt)do echo -e $i&quot;\\n&quot;$i&quot;\\n&quot;$i&quot;\\n&quot;$i&quot;\\n&quot; &gt; tmp seqkit grep -n -f tmp sample.fa &gt; $i.fadonerm sample.fa list.txt tmpecho 'Package: BSgenome.dme.BDGP6.32Title: Full genome sequenceDescription: Full genome sequenceVersion: 1.0.0organism: drosophila melanogastercommon_name: fruit flyprovider: BDGPprovider_version: 6.32release_date: ?release_name: ?source_url: ?organism_biocview: ?BSgenomeObjname: dmeseqnames: c(&quot;2L&quot;, &quot;2R&quot;, &quot;3L&quot;, &quot;3R&quot;, &quot;4&quot;, &quot;EGFP&quot;, &quot;GAL4&quot;, &quot;mCD8GFP&quot;, &quot;mitochondrion_genome&quot;, &quot;test&quot;, &quot;X&quot;, &quot;Y&quot;)seqs_srcdir: /media/ken/BackUP/Drosophila/BSgenome' &gt; BSgenome.dme.BDGP6.32-seed R library(BSgenome)forgeBSgenomeDataPkg(&quot;BSgenome.dme.BDGP6.32-seed&quot;) If everything is right, you would see the codes below and a directory BSgenome.dme.BDGP6.32 was created. Now, we need to package it and install it. Creating package in ./BSgenome.dme.BDGP6.32 Loading '2L' sequence from FASTA file '/media/ken/BackUP/Drosophila/BSgenome/2L.fa' ... DONE Loading '2R' sequence from FASTA file '/media/ken/BackUP/Drosophila/BSgenome/2R.fa' ... DONE Loading '3L' sequence from FASTA file '/media/ken/BackUP/Drosophila/BSgenome/3L.fa' ... DONE Loading '3R' sequence from FASTA file '/media/ken/BackUP/Drosophila/BSgenome/3R.fa' ... DONE Loading '4' sequence from FASTA file '/media/ken/BackUP/Drosophila/BSgenome/4.fa' ... DONE Loading 'EGFP' sequence from FASTA file '/media/ken/BackUP/Drosophila/BSgenome/EGFP.fa' ... DONE Loading 'GAL4' sequence from FASTA file '/media/ken/BackUP/Drosophila/BSgenome/GAL4.fa' ... DONE Loading 'mCD8GFP' sequence from FASTA file '/media/ken/BackUP/Drosophila/BSgenome/mCD8GFP.fa' ... DONE Loading 'mitochondrion_genome' sequence from FASTA file '/media/ken/BackUP/Drosophila/BSgenome/mitochondrion_genome.fa' ... DONE Loading 'test' sequence from FASTA file '/media/ken/BackUP/Drosophila/BSgenome/test.fa' ... DONE Loading 'X' sequence from FASTA file '/media/ken/BackUP/Drosophila/BSgenome/X.fa' ... DONE Loading 'Y' sequence from FASTA file '/media/ken/BackUP/Drosophila/BSgenome/Y.fa' ... DONE Writing all sequences to './BSgenome.dme.BDGP6.32/inst/extdata/single_sequences.2bit' ... DONE R CMD build BSgenome.dme.BDGP6.32R CMD INSTALL BSgenome.dme.BDGP6.32_1.0.0.tar.gz Now, you can load your Genome","link":"/2022/07/23/R/BSgenome/"},{"title":"TOEFL Independent Writing","text":"TOEFL Independent Writing Solving Problem Along or Together Copy from: 新东方在线 Proofreader: Karobben Which one do you prefer, to solve problems on your own experience and knowledge, or to ask others for advice? As knowledge and experience serve as two towers in problem-solving, one is often presented with two major paths that pave the way for final fulfillment, either to wrack his brain, just like what happened to Neuton, sitting for many years under an apple tree and eventually figuring out one of the greatest universal rules that govern the whole globe, or to seek for other’s wisdom through their advice, just as in the case of Benjamin Franklin, gathering great minds under one roof and then establishing a most world-renown library. Both ways work. When a practical goal is involved, however, Benjamin Franklin may best be regarded as a role model in this respect, and asking people for advice often turns out to be the primer alternative. Experience and knowledge borrowed or learned from others’ advice contribute greatly to the effectiveness and efficiency of a goal-accomplishment. Not all experience and knowledge related to problem-solving can be obtained by personal effort alone due to the limitation of the mind and capabilities of each individual. A single thought in someone’s mind is, more often than not, far less shining compared with the group’s wisdom. That explains the famous old saying that one sees further when standing on the shoulders of past great giants; that explains why a great leader is always with greater minds; that also explains why teamwork in cooperation is highly emphasized in the 21st century. Brainstorm and exchange of ideas between different thoughts never fail to enhance the capabilities of each individual involved, a team, a company, an institution, a country, or even the entire global village. Asking other’s advice instead of getting everything done on one’s own promotes democracy and communication too. In terms of democracy, it is necessary to give others rights and chance to speak since the problem may concern them in different ways, and their saying in turn reflects our respect toward freedom of speech as well as their wisdom. In terms of communication, idea exchange sometimes focuses more than solutions, and hereby better mutual understanding about perspectives, principles, practicalities, and personalities of each other. Admittedly turning to others for help and suggestion by no means refers to absolute and irresponsible dependence. Consideration upon different thoughts and ideas broadens our mind, enlarges our vision, furthers understanding, enhances more effective and efficient brainstorm, and stresses mutual respect in groups and communities, which undoubtedly gives rise to better, if not the best solutions. As is paraphrased from John F Kennedy, brainstormed, there is litter we cannot do while divided, there is little we can do. Back Home or Leave After Graduation Copy from: 新东方在线 Proofreader: Karobben After they complete their university studies, some students live in their hometowns. Others live in different towns and cities. Which do you think is beterr? Give reasons for your answer. After they complete their university studies, some students prefer to live in their hometowns while others choose to live in different towns or cities. Everybody has his own hometowns or cities. Everybody has his own reason for his preference. After graduation, I will go back and live in my home city. I have made this decision because of the following reasons. Firstly, my home city is a big city that can offer a lot. There are plenty of opportunities for work, many big libraries for studies, several different museums for visit, and numerous cinemas, theaters, and centers for entertainment. When I go back there, I’ll have no difficulty in finding a job suitable for me and I can make use of all the facilities available there. Secondly, if I go back to my home city, I can look after my parents. I take this into consideration because I am their only child and they are now weak and getting on in age. If I live in the same city as them, I can visit them very often and help them whenever it is necessary. Thirdly, if I live in my home city, I will have a lot of friends, schoolmates, and relatives to visit and to turn to for help when I need it. Of course, I could get acquainted with many people and make many friends if I went to live in a strange place, but that takes time. If I go back to my home city, everybody will wait for me and I will be able to settle down comfortably without any trouble and waste of time. In short, my choice is based on careful consideration of my home city and my family. I think it’s a better and a sensible choice; in a certain sense, it is a must. Good Neighbor Copy from: 新东方在线 Proofreader: Karobben Neighbors are the people who live near us. In your opinion, what are the qualities of a good neighbor? Use specific details and examples in your answer. If you have a good neighbor, you are a lucky person. You have someone who cares about your needs and property, who is helpful in the little day-to-day situation that comes up, and who is supportive in times of crisis. A good neighbor is someone who, for instance, understands that your children may occasionally run across his lawn, even though you tell them not to. He’ll realize that children can be careless about things like that, and he won’t make a big fuss about it unless it becomes a regular thing. In the same vein, he knows that you’ll understand if some of the trash from his trash cans blows across into your yard. In other words, he is sensitive to the unintentional things that can happen. He doesn’t make a big deal about them. A good neighbor is also respectful of your property. For example, she asks your permission before doing anything that interferes with what’s yours. This means she wouldn’t plant a huge tree in between your house without asking how you felt about it. If she wanted to put up a fence, she would let you know first. She might work with you to decide where it should be placed. Maybe the two of you would even split the cost. A good neighbor would lend you some milk if you ran out. She’d give you a ride to work if your car was broken, and let your children stay at her house in the evening if you got stuck working overtime. You would do the same for her. Both of you would help make the other’s life easier. When something really awful happens to you, like a death in the family, a good neighbor will volunteer to help in any way he can. This could mean something small, like making some casseroles to put in your freezer to feed visiting relatives. Or it could mean something big, like helping you get through the sadness of the funeral. I think only someone who has experienced a bad neighbor can really appreciate a good one! A good neighbor can be a good friend. He or she can make all the difference in the world to your life. Eating Outside or at home Copy from: 新东方在线 Proofreader: Karobben Some people prefer to eat at food stands or restaurants. Other people prefer to prepare and eat food at home. Which do you prefer? Use specific reasons and esamples to support your answer. Some people like to eat out at food stands and restaurants, while others like to prepare food at home. Often, it depends on the kind of lifestyle people have. Those with very busy jobs outside the house don’t always have time to cook. They like the convenience of eating out. Overall, though, it is cheaper and healthier to eat at home. While eating in restaurants is fast, the money you spend can add up. When I have diner at a restaurant with friends, the bill is usually over twenty dollars. I can buy a lot of groceries with that much money. Even lunch at a fast-food stand usually costs five or six dollars for one person. THat’s enough to feed the whole family at home. If you cook food at home, you have more control over the ingredients. You can use margarine instead of butter on your potatoes, or not put so much cheese on top of your pizza. At home, you can control your portion size. You can serve yourself as little as you want. In a restaurant, you may eat a full plate of food “because you paid for it”. It’s true that eating out is convenient. You don’t have to stop, or cook, or clean up. But real home cooking doesn’t have to take up a lot of time. There are lots of simple meals that don’t take long to make. In fact, they’re faster than eating out, especially if you think of the time you spend driving to a restaurant, parking, waiting for a table, waiting for service, and driving home. Both eating at restaurants and cooking at home can be satisfying. Both can taste good and be enjoyed with family and friends. I prefer cooking at home because of money and health issues. but people will make the choice that fits their lifestyle best. Personally, I prefer cooking at home for several reasons. Most people believe that eating at stands or restaurants is a kind of time-saving since we need to pro-process the foodstuffs, flavor and cook them, and clean everything up if we eat at home. It seems time-consuming than eating out. But that’s not quite true. There are more choices compared with eating outside and a quick meal is such an answer. For example, we can boil some noodles, vegetables, and eggs and flavoring them with sauces. It just takes 3 min to boil water, and 5 min to finish the cook. On the other hand, if you not satisfied with this, you can prepare more then one meal for each time just as I always did. So, for the next meal, it just takes 2 mins to heat it by microwave-oven. Compared to eating outside, I need to take time to pick a restaurant, make a very hard order since there are so many choices on the menu, wait for the service, and finally, eat it. If we hit a traffic jam or a long waiting list, it takes more. Dancing plays an important role in a culture. Do you agree or disagree with the following statement? Dancing plays an important role in a culture. Use specific reasons and examples to support your answer. Copy from: 新东方在线 Proofreader: Karobben Around the world, people gather to explore their emotions through dance. The dances are created as part of celebrations, as religious services, as preparation for challenging hunts and warfare and to express sorrow (less often than the other situations). Indeed, dance does play an important role within a culture and reveals a wide range of information about the characteristics of a culture. Three of the most revealing aspect of dance are the nature of the culture’s symbols and art forms revealed in costumes and equipment, the body language (moves and gestures) which give information about social contact behaviors, and frequently the style of preferred music for the culture. Ethnic dances, and certainly popular dance, anywhere around the world have associated preference for costumes and special clothing. Through dancing, the participants are able to reveal and express their chosen role in the garments they choose; social roles in the dance show publically to the observers as well as other dancers. Frequently dancers utilize objects like swords or sticks or hoops or musical instruments to further reveal information about their role in the social story portrayed in the dance. Items such as special headwear and jewelry are further examples of the garments that in general express preferences and culturally significant details about the particular culture. Dancers, by the very nature of the activity, physically express beliefs and attitudes associated with their specific culture. In many dances, the participants are modeling typical activities of their culture and thus imparting instructions and historical information to the audience. In other dances, one can see the expression of deep emotion: love, worship, grief, strength, anger, etc. and thus obtain clues about the inner feelings of the culture’s individuals. Dance provides an opportunity for others to witness some of the special behaviors associated with activities in the culture. Also, dance is a (usually) public statement so that observers can see how members of the culture treat those who are older members of the opposite sex, more respected members, etc. The third aspect of dance that reveals much about a culture is the music or singing that is typically a part of the event. Observers can see evidence of the type of instruments, characteristics of the culture, and who plays the instruments as well as how they are used – instruments may be associated only with special events and thus transmit valuable cultural information. Frequently, singing is part of a dance program, and again an observer has an opportunity to observe who is singing and the nature of the voices. I found this aspect of dance particularly fascinating during a brief time I spent in a rural village in Zimbabwe a few years ago. Dancing is indeed a very important aspect of any culture. It provides a communal opportunity for members of the culture to artistically express emotions while acting out typical activities and concerns in their world. For outsider observers, many valuable details about the culture are revealed. Live in a City or Town Copy from: 新东方在线 Proofreader: Karobben Some people prefer to live in a small town. Others prefer to live in a big city. Which place would you prefer to live in? Use specific reasons and details to support your answer. The Advantages of City Life There are undeniable advantages to both lives in a big city and in a small town. The former offers more excitement and convenience while the latter offers a cleaner, quieter, and often friendly place to live. However, despite the advantages of small-town life, I prefer to live in a big city for several reasons. First, life in the city is more convenient. More goods are available and stores are open later. Also, there is better public transportation so it is easier to get around. I can find almost everything I want easily in the city. Second, there are more ways to spend leisure time in the city. There are many places I can go to meet friends and have fun. The city often attracts the best teachers and companies. There is also a wider choice of jobs so it is easier to move up the career ladder. For all of these reasons, I prefer to live in the city, Although I sometimes miss the fresh air and quiet life of a small town, nothing can make up for the opportunities that the city offers me. If one wants to be successful, I believe the best place to live in the city. Agree or not: Success has nothing to do with luck. Copy from: 新东方在线 Proofreader: Karobben When people succeed, it is because of hard work. Luck has nothing to do with success.&quot; Do you agree or disagree with the quotation above? Use specific reasons and examples to explain your position. The Role of Luck in Success “When people succeed, it is because of hard work. Luck has nothing to do with success.” Do you agree or disagree with the quotation above? Use specific reasons and examples to explain your position. The Role of Luck in Success It has been said that when people succeed, it is because of hard work and that has nothing to do with luck. Although I believe that hard work is very important and is the surest way to success for most people, I must disagree with this statement. It cannot be denied that luck plays an important role in success. For example, many important discoveries have been made by accident. There have many cases of researchers and inventors making major breakthroughs while they are trying to solve another problem or create a different device. Furthermore, there is something to be said for simply being in the right place at the right time-perhaps meeting someone by chance who can offer a good job or rare opportunity. And of course, there are rare examples of gamblers and lottery winners who beat the odds and achieve sudden and unexpected success. While the influence of luck can not be ignored, this is not to say that one should depend on it and ignore the value of hard work. If one is willing to work hard, I believe that success will eventually be achieved, with or without the added benefit of luck. Moreover, hard work is often an essential ingredient of luck because it enables one to take advantage of a lucky encounter. If the scientist has not worked hard to developed his knowledge and skills, he may not recognize that lucky breakthrough when it comes along. Therefore, my suggestion is not to count on luck to bring you success. Instead, work hard and keep your eyes open for that lucky opportunity. Construction a Factory Near Your Community Copy from: 新东方在线 Proofreader: Karobben A company has announced that it wishes to build a large factory near your community. discuss the advantages and disadvantages of this new influence on your community. do you support or oppose the factory? explain your position. Having a factory near where one lives brings with it both advantages and disadvantages. An obvious advantage is an increase in the number of jobs, and many people in the community might find employment in the new factory. The factory would bring money into the community in other ways as well. It would have to pay some taxes to the local government, and workers might go shopping or eat at restaurants in the area before or after their shits. However, the factory would bring some disadvantages, too. Depending on what kind of factory it is. It might pollute the environment and bring down property values. It would be sure to increase traffic in the area, causing congestion and making it unsafe for children to play outside. Finally, the neighborhood would become a noisy, busy place. For all of these reasons, I would be opposed to the construction of a new factory near my community. While the employment opportunities would help the community, I believe it would be better for residents to commute to work and preserve the peace of our neighborhood. Change one things in your hometown Copy from: 新东方在线 Proofreader: Karobben If you could change one important thing about your hometown, what would you change? use reasons and specific examples to support your answer. My hometown is a large city with a dense population. Because it is crow people and vehicles, the environment is not as clean as I would like it to be. Too many cars and buses polluted the air and also people created a lot of garbage that is not always disposed of properly. If I could change just one thing about my hometown, it would be the environment. I would make it a cleaner and less polluted place to live. I believe that such a change is important because a person’s living environment greatly affects both his physical and mental health. Bad air quality can contribute to many health problems such as asthma, and improperly discarded garbage can spread bacteria that are dangerous to health. In addition, the environment can greatly affect the way a person feels. When in clean, attractive surroundings we always feel optimistic. For these reasons, I think the people of my hometown should work together to make it a cleaner place to live. In order to accomplish this goal, we have to not only enact laws to limit pollution but also take personal responsibility for our own actions. Only when people realize the effect that the environment has on their well-bing will they such proposals seriously. Therefore, ew must first inform people of the dangers of a poor environment. Then I believe we can all live happier, healthier lives.","link":"/2020/11/07/LearnNotes/writing/"},{"title":"R base","text":"Install R Ubuntu source page: linuxize 2020 sudo apt install dirmngr gnupg apt-transport-https ca-certificates software-properties-commonsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9sudo add-apt-repository 'deb https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/'sudo apt install r-base Packages Install Install from CRAN install.packages(&quot;ggplot2&quot;,&quot;repos&quot; = c(CRAN=&quot;https://mirrors.tuna.tsinghua.edu.cn/CRAN/&quot;)) Install from local fille install.packages(\"/data/data/com.termux/files/home/ggradar\",repos = NULL) Mirrors options函数就是设置R运行过程中的一些选项设置 options(&quot;repos&quot; = c(CRAN=&quot;https://mirrors.tuna.tsinghua.edu.cn/CRAN/&quot;)) Bioconductor options(BioC_mirror=&quot;https://mirrors.tuna.tsinghua.edu.cn/bioconductor&quot;) Reading from Excel library(&quot;readxl&quot;)A &lt;- read_excel(&quot;Table.xlsx&quot;) library(tidyr)library(dplyr)df &lt;- data.frame(x = c(NA, &quot;a.b&quot;, &quot;a.d&quot;, &quot;b.c&quot;,&quot;a-b&quot;))df %&gt;% separate(x, c(&quot;A&quot;, &quot;B&quot;),'-') '''Base &lt;- data.frame(Nodes =c(&quot;P1&quot;, &quot;P1&quot;, &quot;P1&quot;, &quot;P2&quot;), Targets=c(&quot;P2&quot;,&quot;P3&quot;,&quot;P4&quot;,&quot;P1&quot;))List &lt;- c(&quot;P1&quot;, &quot;P2&quot;, &quot;P3&quot;)Base &lt;- read.table(&quot;DataBase/Mybase/AB_List&quot;)List &lt;- read.table(&quot;&quot;)[[1]]''''''Result without Annotation'''addPercent &lt;- function(x){percent &lt;- round(x * 100, digits = 1)result &lt;- paste(percent, &quot;%&quot;, sep = &quot;&quot;)return(result)}library(tidyr)library(dplyr)A &lt;- BaseA &lt;- A[which(match(A[[1]],List)!=&quot;NA&quot;),]A &lt;- A[which(match(A[[2]],List)!=&quot;NA&quot;),]AVBA = paste(A[[2]],&quot;_&quot;,A[[1]],sep='')List = c(AVBA)List = data.frame(X=List[duplicated(List)])List = List %&gt;% separate(X, c(&quot;A&quot;, &quot;B&quot;),'_')ListVBA = paste(List[[2]],&quot;_&quot;,List[[1]],sep='')remove Lift == rightList = List[-which(match(ListVBA)-c(1: nrow(List))==0),]List = List[match(ListVBA)-c(1: nrow(List))&gt;0,]A = A[-na.omit(match(ListVAB)),]write.table(data.frame(A[1:2]),&quot;Output&quot;,sep='\\t',quote=F,col.names=F,row.names=F)'''for delete duplicates and combind rest of colums'''RM_du &lt;-function(A){AVBA = paste(A[[2]],&quot;_&quot;,A[[1]],sep='')##Num=0Num= Num+1## Get the Duplicate listi = unique(AVAB == AVBA == AVAB)[-1]){Num= Num+1## Get the Duplicate listList1 = which(AVAB[1])List1 = c(List1,which(AVAB[1]))TMP = A[List1,]TMP_R = data.frame(TMP[1,1:2],V3 = paste(unique(as.character(TMP[,3])), collapse='|'))Result = rbind(Result,TMP_R)A = A[-List1,]print(Num)}return(Result)} install package from sourceinstall.packages(&quot;/data/data/com.termux/files/home/ggradar&quot;,repos = NULL)functionmyfunction &lt;- function(arg1, arg2, ... ){statementsreturn(object)}remove all variablerm(list = setdiff(ls(), lsf.str()))calculate &quot;spend&quot; by TypeA_radar = with(A[c(6,3)], tapply(spend, list(Type), sum))matchc('aa','ab','c') %in% c('aa','c')###system.time()I = 0system.time(for(i in (1:1000000000)){I = I + i})T1&lt;- Sys.time()ggplot() + geom_bar(aes(x=A,y=B),stat='identity')T2&lt;- Sys.time()T2 - T1Time_A = time.time()plt.bar(A, B)plt.show()Time = time.time() - Time_Aprint(Time)logarithmsexp(value)Split a columnlibrary(stringr)str_split_fixed(before$type, &quot;and&quot;, 2)Batter than cbind &amp; rbindhttps://www.jianshu.com/p/a3277f29ed46library(dplyr)dplyr::bind_rows(data1,data2)'''namea value nameb1 海波 一波 2 立波 接 3 秀波 一波 4 东去 柯震东5 又 刘强东6 东来 何盛东'''###weekdaysweekdays(as.Date('2018-3-1')) Function Shrink &lt;- function(Data, P){ Num = round(nrow(world)/P) Data = Data[c(1:Num)*P,]} world &lt;- map_data(&quot;world&quot;) Connect to Jupyter NoteBook 一窗星乱银河静1 2018 # dependents for IRkernelinstall.packages(c('repr', 'IRdisplay', 'evaluate', 'crayon', 'pbdZMQ', 'devtools', 'uuid', 'digest'))# Install IRkernel from githubdevtools::install_github('IRkernel/IRkernel')# Connect to Jupyter NotebookIRkernel::installspec()# 或者是在系统下安装IRkernel::installspec(user = FALSE) Errors Package ‘XXX’ was installed before R 4.0.0: please re-install it Solution: Amleto, 2020 check the lib path .libPaths() [1] \"/home/ken/R/x86_64-pc-linux-gnu-library/4.2\" \"/usr/local/lib/R/site-library\" [3] \"/usr/lib/R/site-library\" \"/usr/lib/R/library\" grab old packages names and remove old packages for(i in .libPaths()[2:4]){ old_packages &lt;- installed.packages(lib.loc = i ) old_packages &lt;- as.data.frame(old_packages) list.of.packages &lt;- unlist(old_packages$Package) remove.packages( installed.packages( priority = &quot;NA&quot; )[,1] )} Actually, it doesn’t work to me. Then, I just deleted /usr/local/lib/R/site-library. Everything is fine, now. cannot create ** byte-compile and prepare package for lazy loading Fatal error: cannot create 'R_TempDir' Two possibles: have no write right in /tmp file (not likely) Out of storage space.","link":"/2020/05/01/R/Base-and-tricks/"},{"title":"Biostrings","text":"Biostrings source(“http://bioconductor.org/biocLite.R”) ## InstallBiocManager::install('Biostrings') Quick Start test.txt library(Biostrings)s = readDNAStringSet(&quot;test.txt&quot;)length(s) #Numbers of seqnchar(s) #length of each seqreverse(s)translate(s)dna2rna(s)cDNA(dna2rna(s))tolower(s) # = = I don't knowletterFrequency(s, DNA_BASES) # Frq with A,T,G,CletterFrequency(s, DNA_ALPHABET) # Frq with A, C, G, T, M, R, W, S, Y, K, V, H, D, B, N, -, +, .letterFrequency(s, DNA_BASES, as.prob = TRUE) # Frq with A T G CletterFrequency(s, &quot;GC&quot;, as.prob = TRUE) # Frq with GC 1. Fasta Calculate library(Biostrings)## Reading a fasta fileA &lt;-readDNAStringSet('predict.coding.fa.transdecoder.pep.sel.fa')head(DNAStringSet(A)) width seq names [1] 604 ASSVASTASSAHHHASAASTGTV... TRINITY_DN100000_... [2] 616 MDYMDSGRYTKSDKDWDTNVASD... TRINITY_DN100001_... [3] 157 SRAKKVKKDSKKGGGGGGGGSSW... TRINITY_DN100002_... Get the Distance Matrix from the Tree Raw post library(TDbook) # example datalibrary(Biostrings)tree &lt;- tree_HPV58tl &lt;- tree$tip.labelacc &lt;- sub(&quot;\\\\w+\\\\|&quot;, &quot;&quot;, tl)names(tl) &lt;- acctipseq &lt;- ape::read.GenBank(acc) %&gt;% as.character %&gt;% lapply(., paste0, collapse = &quot;&quot;) %&gt;% unlist %&gt;% Biostrings::DNAStringSettipseq_aln &lt;- muscle::muscle(tipseq)tipseq_aln &lt;- DNAStringSet(tipseq_aln)tipseq_dist &lt;- stringDist(tipseq_aln, method = &quot;hamming&quot;)as.matrix(tipseq_dist)[1:5, 1:5] FJ385264 D90400 FJ385265 FJ385263 FJ385261 FJ385264 0 15 16 18 20 D90400 15 0 7 7 9 FJ385265 16 7 0 8 12 FJ385263 18 7 8 0 12 FJ385261 20 9 12 12 0 pre { background-color:#38393d; color: #5fd381; }","link":"/2020/05/01/R/Biostrings/"},{"title":"Correlation","text":"Correlation CORRELATION ELLIPSES library(ellipse)library(RColorBrewer)data=cor(mtcars)##Build a Pannel of 100 colors with Rcolor Brewermy_colors &lt;- brewer.pal(5, &quot;Spectral&quot;)my_colors=colorRampPalette(my_colors)(100)##Order the correlation matrixord &lt;- order(data[1, ])data_ord = data[ord, ord]plotcorr(data_ord , col=my_colors[data_ord*50+50] , mar=c(1,1,1,1)) BASIC SCATTERPLOT MATRIX data=mtcars[ , c(1,3:6)]##Make the plotplot(data , pch=20 , cex=1.5 , col=rgb(0.5, 0.8, 0.9, 0.7)) SCATTERPLOT MATRIX – CAR PACKAGE library(car)library(RColorBrewer)##Let's use the car dataset proposed by Rdata=mtcarsmy_colors &lt;- brewer.pal(nlevels(as.factor(data$cyl)), &quot;Set2&quot;)scatterplotMatrix(~mpg+disp+drat|cyl, data=data , reg.line=&quot;&quot; , smoother=&quot;&quot;, col=my_colors , smoother.args=list(col=&quot;grey&quot;) , cex=1.5 , pch=c(15,16,17) , main=&quot;Scatter plot with Three Cylinder Options&quot;) library(GGally)## Create datasample_data &lt;- data.frame( v1 = 1:100 + rnorm(100,sd=20), v2 = 1:100 + rnorm(100,sd=27), v3 = rep(1, 100) + rnorm(100, sd = 1))sample_data$v4 = sample_data$v1 ** 2sample_data$v5 = -(sample_data$v1 ** 2)## Check correlation between variablescor(sample_data)## Check correlations (as scatterplots), distribution and print corrleation coefficientggpairs(sample_data) # image leftggcorr(sample_data, method = c(&quot;everything&quot;, &quot;pearson&quot;)) # image right More","link":"/2020/06/28/R/Correlation/"},{"title":"Data cleaning","text":"Data cleaning Date as.Date(&quot;Aug_24_2019&quot;, &quot;%B_%d_%Y&quot;)as.Date(&quot;08_24_2019&quot;, &quot;%m_%d_%y&quot;)as.Date(&quot;08月24日2019年&quot;, &quot;%m月%d日%y年&quot;) Split column by str ## Split a columnlibrary(stringr)str_split_fixed(before$type, &quot;_and_&quot;, 2) r$&gt; print(TB) Date Words Words_Wrong MisRate MisRateT1 2020-08-24 525 165 1559.486 31.43%2 2020-08-25 449 138 1525.069 30.73%3 2020-08-27 338 96 1409.325 28.4%4 2020-08-28 446 131 1457.448 29.37%5 2020-08-29 423 102 1196.511 24.11%6 2020-08-30 368 104 1402.304 28.26%r$&gt; str_split_fixed(TB$Date, &quot;-&quot;, 2) [,1] [,2] [1,] &quot;2020&quot; &quot;08-24&quot;[2,] &quot;2020&quot; &quot;08-25&quot;[3,] &quot;2020&quot; &quot;08-27&quot;[4,] &quot;2020&quot; &quot;08-28&quot;[5,] &quot;2020&quot; &quot;08-29&quot;[6,] &quot;2020&quot; &quot;08-30&quot; reshape2 Raw matrix:head(longImage) Var1 Var2 Var3 value1 1 1 1 1.00000002 2 1 1 0.99215693 3 1 1 0.98823534 4 1 1 0.97254905 5 1 1 0.96862756 6 1 1 0.9803922 Reshape reshape(longImage, timevar='Var3',idvar=c('Var1','Var2'), direction='wide') Var1 Var2 value.1 value.2 value.31 1 1 1.0000000 0.9960784 1.00000002 2 1 0.9921569 0.9921569 1.00000003 3 1 0.9882353 1.0000000 1.00000004 4 1 0.9725490 0.9960784 0.99607845 5 1 0.9686275 1.0000000 1.00000006 6 1 0.9803922 1.0000000 1.0000000 R-dplyr library(tidyr)&lt;br /&gt;library(dplyr)df &lt;- data.frame(x = c(NA, &quot;a.b&quot;, &quot;a.d&quot;, &quot;b.c&quot;,&quot;a-b&quot;))&lt;br /&gt;df %&gt;% separate(x, c(&quot;A&quot;, &quot;B&quot;),'-') Expression matrix Centralize the matrix for heatmap This codes come from Trinity-rnaseq Exm_center &lt;- function(primary_data){ primary_data = as.matrix(primary_data) ##transformations data = log2(primary_data+1) data = as.matrix(data) # convert to matrix ## Centering rows data = data.frame(t(scale(t(data), scale=F))) return (data)} String remove numbers from str string_with_numbers &lt;- &quot;The quick brown fox 123 jumps over the lazy dog 456&quot;string_without_numbers &lt;- gsub(&quot;\\\\d+&quot;, &quot;&quot;, string_with_numbers)print(string_without_numbers) [1] \"The quick brown fox jumps over the lazy dog \" In this example, string_with_numbers is the original string that contains numbers. The \\d+ regular expression matches one or more digits, and the gsub() function replaces all matches with an empty string. The resulting string without numbers is stored in string_without_numbers. Who said this?","link":"/2020/05/01/R/Data-cleaning/"},{"title":"Data normalization","text":"Data normalization Normalization 1 Max-Min for(ii in 1:ncol(a)){a[,ii] &lt;- (a[,ii]-min(a[,ii]))/(max(a[,ii])-min(a[,ii]))} 2 z-score for(ii in 1:ncol(a)){a[,ii] &lt;- (a[,ii]-mean(a[,ii]))/sd(a[,ii])} 3 Soft-max_Normalization for(ii in 1:ncol(a)){a[,ii] &lt;- pnorm((a[,ii]-mean(a[,ii]))/sd(a[,ii]))} 4 Logistic/Softmax for(ii in 1:ncol(a)){a[,ii] &lt;- 1/(1+ exp(-a[,ii])) 5 模糊量化模式 for(ii in 1:ncol(a)){x&lt;- a[,ii]a[,ii] &lt;- x &lt;- 1/2 +1/2sin(pi/(max(x)-mean(x))(x-max(x)-mean(x)/2)) *x} 6 log for(ii in 1:ncol(a)){a[,ii][which(a[,ii]&gt;0)] &lt;- log(a[,ii][which(a[,ii]&gt;0)],10)/log(max(a[,ii]),10)a[,ii][which(a[,ii]&lt;0)] &lt;- log(a[,ii][which(a[,ii]&lt;0)](-1),10)(-1)/log(mean(a[,ii]) *(-1))} 7 atan for(ii in 1:ncol(a)){a[,ii][which(a[,ii]&gt;0)] &lt;- atan(a[,ii][which(a[,ii]&gt;0)])*2/pia[,ii][which(a[,ii]&lt;0)] &lt;- atan(a[,ii][which(a[,ii]&lt;0)])2/pi (-1)} 8 Logistic/Softmax ## Something wrong with this 1/2+ 1/2sim(pi/max())","link":"/2020/05/01/R/Data-normalization/"},{"title":"Density plot","text":"Density plot Quick start geom_density_2d library(ggplot2)world &lt;- map_data(&quot;world&quot;)ggplot(world,aes(long, lat)) +geom_density_2d(color='red') + theme_light() stat_density_2d ggplot(world,aes(long, lat)) + stat_density_2d(aes(fill = stat(level)), geom = &quot;polygon&quot;) + theme_map() ggplot(world,aes(long, lat)) + stat_density_2d(aes(fill = stat(level),colour = region), geom = &quot;polygon&quot;) + theme_map()+ theme(legend.position = 'none') geom_raster ggplot(faithfuld, aes(waiting, eruptions)) + geom_raster(aes(fill = density))+ theme_map() More","link":"/2020/08/13/R/Density-plot/"},{"title":"GG3D | ggplot extends","text":"1. 安装 install.packages('devtools')devtools::install_github(&quot;AckerDWM/gg3D&quot;) Quick Start 看图 library(gg3D)library(ggplot2)theta=1 #方位角的度数phi=50 # 渐近线ggplot(iris, aes(x=Petal.Width, y=Sepal.Width, z=Petal.Length, color=Species)) + axes_3D(theta=theta, phi=phi) + stat_3D(theta=theta, phi=phi) + axis_labs_3D(theta=theta, phi=phi, size=3, hjust=c(1,1,1.2,1.2,1.2,1.2), vjust=c(-.5,-.5,-.2,-.2,1.2,1.2)) + labs_3D(theta=theta, phi=phi, hjust=c(1,0,0), vjust=c(1.5,1,-.2),labs=c(&quot;Petal width&quot;, &quot;Sepal width&quot;, &quot;Petal length&quot;)) +theme_void() theta &amp; phi的关系 ## 查看thetafor(i in c(0:100)){theta=i #方位角的度数phi=1 # 渐近线p &lt;- ggplot(iris, aes(x=Petal.Width, y=Sepal.Width, z=Petal.Length, color=Species)) + axes_3D(theta=theta, phi=phi) + stat_3D(theta=theta, phi=phi) + axis_labs_3D(theta=theta, phi=phi, size=3, hjust=c(1,1,1.2,1.2,1.2,1.2), vjust=c(-.5,-.5,-.2,-.2,1.2,1.2)) + labs_3D(theta=theta, phi=phi, hjust=c(1,0,0), vjust=c(1.5,1,-.2),labs=c(&quot;Petal width&quot;, &quot;Sepal width&quot;, &quot;Petal length&quot;)) +theme_void()+ labs(title =paste(&quot;theta=&quot;,i))print(p)##ggsave(paste(i,'.png',sep=&quot;&quot;))}##convert $(ls *.png| sort -n) theta.gif##查看phifor(i in c(0:100)){theta=1 #方位角的度数phi=i # 渐近线p &lt;- ggplot(iris, aes(x=Petal.Width, y=Sepal.Width, z=Petal.Length, color=Species)) + axes_3D(theta=theta, phi=phi) + stat_3D(theta=theta, phi=phi) + axis_labs_3D(theta=theta, phi=phi, size=3, hjust=c(1,1,1.2,1.2,1.2,1.2), vjust=c(-.5,-.5,-.2,-.2,1.2,1.2)) + labs_3D(theta=theta, phi=phi, hjust=c(1,0,0), vjust=c(1.5,1,-.2),labs=c(&quot;Petal width&quot;, &quot;Sepal width&quot;, &quot;Petal length&quot;)) +theme_void()+ labs(title =paste(&quot;phi=&quot;,i))print(p)##ggsave(paste(i,'.png',sep=&quot;&quot;))}##convert $(ls *.png| sort -n) phi.gif Theta Phi More","link":"/2020/06/19/R/GG3D/"},{"title":"Go Ontology Bar Plot by ggplot","text":"Data Before running the codes, I’d like to have a brief introduces about my data. There are three tables in total and name as In_all.table, Li_all.table, Mu_all.table. It looks like: Name InCK_30 InCK_75 In30_75 Cate localization 114 149 94 Biological process single-organism process 285 357 225 Biological process metabolic process 375 413 261 Biological process multi-organism process 4 5 1 Biological process immune system process 15 13 9 Biological process multicellular organismal process 16 13 11 Biological process cellular process 411 473 296 Biological process reproduction 0 1 1 Biological process reproductive process 0 1 1 Biological process Quick Start library('ggplot2')library('reshape2')theme_go &lt;- theme(axis.text.x=element_text(angle=60,hjust=1), axis.title.x=element_text(hjust=0), plot.title = element_text(hjust = 0.5), panel.grid.major =element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), axis.line = element_line(colour = &quot;black&quot;))### Intestineall &lt;- read.table(&quot;In_all.table&quot;,sep='\\t',header=T)all_gg &lt;- melt(all)p1 &lt;- ggplot(data=all_gg)+ geom_bar(aes(x=Name,y=value,fill=variable),stat=&quot;identity&quot;)+ facet_grid(. ~ Cate,scales = &quot;free_x&quot;,space = &quot;free&quot;) + labs(title=&quot;Intestine&quot;, x = &quot;A&quot;, y=&quot;Countes&quot;)+ theme_go+ theme(axis.text.x = element_text(size=15))ggsave('GP_Q.png',wi=12,hei=7.4) It is definitely the best result of GO bar plot. But, thing gonna change when you want to align two or more others. Plot Three files library('ggplot2')library('reshape2')theme_go &lt;- theme(axis.text.x=element_text(angle=60,hjust=1,size=12), axis.title.x=element_text(hjust=0), plot.title = element_text(hjust = 0.5), panel.grid.major =element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), axis.line = element_line(colour = &quot;black&quot;))### Intestineall &lt;- read.table(&quot;In_all.table&quot;,sep='\\t',header=T)all_gg &lt;- melt(all)p1 &lt;- ggplot(data=all_gg)+ geom_bar(aes(x=Name,y=value,fill=variable),stat=&quot;identity&quot;)+ facet_grid(. ~ Cate,scales = &quot;free_x&quot;,space = &quot;free&quot;) + labs(title=&quot;Intestine&quot;, x = &quot;A&quot;, y=&quot;Countes&quot;)+ theme_go### Liverall &lt;- read.table(&quot;Li_all.table&quot;,sep='\\t',header=T)all_gg &lt;- melt(all)p2 &lt;- ggplot(data=all_gg)+ geom_bar(aes(x=Name,y=value,fill=variable),stat=&quot;identity&quot;)+ facet_grid(. ~ Cate,scales = &quot;free_x&quot;,space = &quot;free&quot;) + labs(title=&quot;Liver&quot;, x = &quot;B&quot;, y=&quot;Countes&quot;)+ theme_go### Muscleall &lt;- read.table(&quot;Mu_all.table&quot;,sep='\\t',header=T)all_gg &lt;- melt(all)p3 &lt;- ggplot(data=all_gg)+ geom_bar(aes(x=Name,y=value,fill=variable),stat=&quot;identity&quot;)+ facet_grid(. ~ Cate,scales = &quot;free_x&quot;,space = &quot;free&quot;) + labs(title=&quot;Muscle&quot;, x = &quot;C&quot;, y=&quot;Countes&quot;)+ theme_gop1/p2/p3ggsave(&quot;GO.png&quot;, wi=10,height = 15) Due to the name of categories are long and dense, it is hard to get an idea distribution of the chart. One resolution is to combine three tables and sharing one X axis. Another is to annotate the categories at the side of the chart. Combining X axis theme_go &lt;- theme(axis.text.x=element_text(angle=60,hjust=1,size=12), #axis.title.x=element_text(hjust=0), plot.title = element_text(hjust = 0.5), panel.grid.major =element_line(colour='grey'), #panel.grid.major =element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), axis.line = element_line(colour = &quot;black&quot;))File_list = c(&quot;In_all.table&quot;, &quot;Li_all.table&quot;, &quot;Mu_all.table&quot;)Samples_list = c(&quot;Intestine&quot;, &quot;Liver&quot;, &quot;Muscle&quot;)Degree_list = c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;)TB = data.frame()## Combining tablesfor(i in c(1:length(File_list))){ tmp = read.table(File_list[i],sep='\\t',header=T) tmp$Samples= Samples_list[i] colnames(tmp)[2:4]=c(&quot;CK vs 30&quot;, &quot;CK vs 75&quot;, &quot;30 vs 75&quot;) TB = rbind(TB,tmp)}TB_melt &lt;- melt(TB)p &lt;- ggplot(TB_melt)+ geom_bar(aes(x=Name,y=value,fill=variable),stat=&quot;identity&quot;)+ facet_grid(Samples ~ Cate,scales = &quot;free&quot;,space = &quot;free&quot;) + labs(title=&quot;Intestine&quot;, x = &quot;Categories&quot;, y=&quot;Countes&quot;) + theme_gop &lt;- p + theme( strip.background = element_rect(fill = '#f2f2f2'), strip.text = element_text(face = 'bold',size=15))## we using cowplot to extent the axislibrary(cowplot)ggdraw() + draw_plot(p,0.05,0,0.95)ggsave(&quot;GO_2.png&quot;,wi=12.7,hei = 10) You may also like using heatmap to display the difference of counts among samples. Heatmap library(pheatmap)library(ggplotify)library(ggplot2)library(reshape2)library(patchwork)## reading from dataall_In &lt;- read.table(&quot;In_all.table&quot;,sep='\\t',header=T)all_Li &lt;- read.table(&quot;Li_all.table&quot;,sep='\\t',header=T)all_Mu &lt;- read.table(&quot;Mu_all.table&quot;,sep='\\t',header=T)## MergeIn_Li = merge(x=all_In,y=all_Li,by=&quot;Name&quot;, all.x = T, all.y = T)In_Li_Mu = merge(x=In_Li,y=all_Mu,by=&quot;Name&quot;, all.x = T, all.y = T)## GroupIn_Li_Mu = In_Li_Mu[c(1,2,3,4,6,7,8,10,11,12,5,9,13)]In_Li_Mu[13][which(is.na(In_Li_Mu[13])==TRUE),]=In_Li_Mu[12][which(is.na(In_Li_Mu[13])==TRUE),]In_Li_Mu[13][which(is.na(In_Li_Mu[13])==TRUE),]=In_Li_Mu[11][which(is.na(In_Li_Mu[13])==TRUE),]In_Li_Mu = In_Li_Mu[c(1:10,13)]row.names(In_Li_Mu) = In_Li_Mu[[1]]## OrderIn_Li_Mu = In_Li_Mu[order(In_Li_Mu[[11]]),]## Using raw countsp1 &lt;- pheatmap(In_Li_Mu[c(2:10)], annotation_row =In_Li_Mu[11],cluster_rows = F, cluster_col=F, labels_row = &quot;&quot;, legend = F, annotation_legend = F)## Normalizing it with Log2(x+1)p2 &lt;- pheatmap(log(1+In_Li_Mu[c(2:10)]), annotation_row =In_Li_Mu[11],cluster_rows = F, cluster_col=F, labels_row = &quot;&quot;, legend = F, annotation_legend = F)## Centering the matrix after log themp3 &lt;- pheatmap( data.frame(t(scale(t(log2(1+In_Li_Mu[c(2:10)])), scale=F))), annotation_row =In_Li_Mu[11],cluster_rows = F, cluster_col=F, annotation_legend = F)g1 = as.ggplot(p1)g2 = as.ggplot(p2)g3 = as.ggplot(p3)(g1|g2)/g3##ggsave(&quot;GO_3.png&quot;,width = 6.54,height = 10.5) For have a better layout and easy to comparation, I tossed some legends. Dots plot library(ggplot2)library(cowplot)library(ggdendro)TB_tree &lt;- In_Li_Mu[2:10]TB_tree[is.na(TB_tree)]=0Tree &lt;- hclust(dist(TB_tree))dendr &lt;- dendro_data(Tree, type=&quot;rectangle&quot;)## plot the dendrogram; note use of color=cluster in geom_text(...)p1 &lt;- ggplot() + geom_segment(data=segment(dendr), aes(x=x, y=y, xend=xend, yend=yend)) + coord_flip() + labs(y=&quot;Distance&quot;)+ theme(axis.line.y=element_blank(), axis.ticks.y=element_blank(), axis.text.y=element_blank(), axis.title.y=element_blank(), axis.text.x=element_text(angle=45,hjust=1), panel.background=element_blank(), panel.grid=element_blank())TB &lt;- melt(In_Li_Mu)TB$Name = factor(TB$Name,levels = unique(TB$Name[order(TB$Cate)]))TB$SubG = &quot;Intest&quot;TB$SubG[grep( &quot;Mu&quot;, TB$variable)] = &quot;Muscle&quot;TB$SubG[grep( &quot;Li&quot;, TB$variable)] = &quot;Liver&quot;TB$Name = factor(TB$Name, levels= dendr$labels$label)p2 &lt;- ggplot(TB,aes(x=variable,y=Name)) + geom_point(aes(size=value,color=Cate))+ theme_light()+ facet_grid(~SubG, scales =&quot;free&quot;, space = 'free') + labs(x='Samples',y='Category',title = &quot;GO Anotation of DEGs&quot;)+ theme(axis.text.x = element_text(angle = 45,hjust=1), axis.text.y = element_text(size=12), strip.text.x = element_text(size=12, face='bold'), legend.position = 'left')ggdraw()+ draw_plot(p1,0.784,0.0,0.1,0.972) + draw_plot(p2,0,0.007,0.8)ggsave('GO_Dots222.png', width = 9.4, height = 8.07)","link":"/2020/06/19/R/GG_goplot/"},{"title":"GGcal | ggplot for Calendar","text":"Quick start: The graph show ahead. library(ggplot2)library(ggcal)mydate &lt;- seq(as.Date(&quot;2017-02-01&quot;), as.Date(&quot;2017-07-22&quot;), by=&quot;1 day&quot;)myfills &lt;- rnorm(length(mydate))print(ggcal(mydate, myfills)) Installation devtools::install_github(&quot;jayjacobs/ggcal&quot;) Favorite theme gg &lt;- ggcal(mydate, myfills) +scale_fill_gradient2(low=&quot;#4575b4&quot;, mid=&quot;#ffffbf&quot;, high=&quot;#d73027&quot;, midpoint=0)print(gg) More","link":"/2020/06/19/R/GGcal/"},{"title":"GGmap: geom_map | ggplot for maps","text":"Install install.packages('ggalt') 文件下载: CLIWOC15.csv https://raw.githubusercontent.com/ljtyduyu/DataWarehouse/master/File/CLIWOC15.csv (也许需要科学上网) library(ggplot2) #需安装最新的2.0.0版本library(dplyr) #你也可以用内置的subset函数来代替filter函数library(ggalt) #安装方法: devtools::install_github(&quot;hrbrmstr/ggalt&quot;)。需安装加载devtools包library(ggthemes)world &lt;- map_data(&quot;world&quot;)world &lt;- world[world$region != &quot;Antarctica&quot;,] # 剔除南极洲dat &lt;- read.csv(&quot;CLIWOC15.csv&quot;)dat &lt;- filter(dat, Nation != &quot;Sweden&quot;)ggplot()+ geom_map(data=world, map=world, aes(x=long, y=lat, map_id=region), fill=&quot;#00518E&quot;, color=&quot;white&quot;, fill=&quot;#7f7f7f&quot;, size=0.05, alpha=1/4)+ geom_point(data=dat,aes(x=Lon3, y=Lat3, color=Nation),size=0.15, alpha=1/100)+ scale_color_tableau()+ coord_proj(&quot;+proj=wintri&quot;)+ facet_wrap(~Nation)+ theme_map()+ theme(strip.background=element_blank())+ theme(legend.position=&quot;none&quot;)ggsave('map.png',w=500,h=450)## graph shows as in head library(map) library(ggplot2)library(maps)data(us.cities)big_citi &lt;- subset(us.cities,pop &gt; 500000) ##人口大于50万的城市##Quick plot (left)qplot(long,lat,data=big_citi) + borders(&quot;state&quot;,size=0.5)##ggsave('map2.png',w=4,h=2.6)##Quick plot (right)library(ggthemes)library(ggrepel)qplot(long,lat,data=big_citi) + borders(&quot;state&quot;,size=0.5) +theme_map()+ geom_label_repel(data=big_citi,aes(x=long,y=lat,label=name))##ggsave('map3.png',w=8,h=5.2) map2.png map3.png More","link":"/2020/08/13/R/GGmap/"},{"title":"GGmap: geom_polygon | ggplot examples","text":"主要参考: https://blog.csdn.net/kMD8d5R/article/details/86582019 install.packages('mapproj') 快速上手 library(ggplot2)library(ggthemes)## 世界地图，比较好的配色world &lt;- map_data(&quot;world&quot;)worldmap &lt;- ggplot(world, aes(x = long, y = lat, group = group)) + geom_polygon(fill = &quot;#00518E&quot;,color = &quot;#317DA4&quot;) + scale_y_continuous(breaks = (-2:2) * 30) + scale_x_continuous(breaks = (-4:4) * 45)## 正射投影worldmap + coord_map(&quot;ortho&quot;) # 默认北极为中心点。 ## 南极为中心点worldmap + coord_map(&quot;ortho&quot;, orientation = c(30, 100, 0))# 中国 中心worldmap + coord_map(&quot;ortho&quot;, orientation = c(-90, 0, 30)) # 顺时针旋转30度worldmap + coord_map(&quot;ortho&quot;, orientation = c(41, -74, 0)) # 随便取一点##下图worldmap + coord_map(&quot;ortho&quot;, orientation = c(30, 100, 0))+ theme_map() 原理 x=c(0,0,6,6)y=c(0,7,0,8)TB=data.frame(X=x,Y=y)gplot(TB,aes(X,Y)) + geom_polygon(aes(fill='red')) + geom_point() + theme_light() 动画 1. gganimate gganimate 只能画平面图的动画，不能画球状以后的动画gps.txt随便测试一下 library(gganimate)City = read.table('gps.txt')City$Group=1Num=nrow(City)for(i in c(2:10)){ tmp = City[1:Num,1:3] tmp$Group=i tmp[[3]]=tmp[[3]]+i-1 City =rbind(City,tmp)}ggplot(head(City,30))+ geom_polygon(data=world,aes(x = long, y = lat, group = group), fill = &quot;#00518E&quot;,color = &quot;#317DA4&quot;)+ geom_point(data=City,aes(x=V2,y=V3)) + geom_text(data=head(City,Num),aes(x=V2,y=V3,label=V1))+ coord_cartesian(xlim=c(70,150),ylim = c(10,65))+ transition_time(City$Group) + theme_map()## 简单示范 2.多 png 转 gif 先画出一系列的png，在叠加成gif ##旋转library(ggrepel)p &lt;- ggplot(head(City,15))+ geom_polygon(data=world,aes(x = long, y = lat, group = group),fill = &quot;#00518E&quot;,color = &quot;#317DA4&quot;)+ geom_point(data=City,aes(x=V2,y=V3)) + coord_map(&quot;ortho&quot;)+ geom_text(data=head(City,Num),aes(x=V2,y=V3,label=V1))+ theme_map()for(i in c(1:5)){ p = p + coord_map(&quot;ortho&quot;, orientation = c(30, 50+i*20, 0)) ggsave(paste(i,'_map.png',sep='')) }＃bash 下完成＃convert $(ls *_map.png| sort -n) map.gif 各种杂耍 加上经纬线 [经纬线函数链接](https://www.yuque.com/liuwenkan/bni63i/bwkcrz#rlfqy)/ ##杂技函数经纬线() +geom_polygon(data=world, aes(x = long, y = lat, group = group), fill = &quot;#00518E&quot;,color = &quot;#317DA4&quot;) + scale_y_continuous(breaks = (-2:2) * 30) + coord_map(&quot;ortho&quot;, orientation = c(30, 100, 0)) + scale_x_continuous(breaks = (-4:4) * 45)+ theme_map()+ 链接两点 这里用到Connet函数，详见“曲线链接两点” 创建地点 echo &quot;巴黎 2.294694 48.856958墨尔本 144.958832 -37.812164马德里 -3.677528 40.390197SD -117.071944 32.775554马塞卢 27.512883 -29.363468罗萨里奥 -60.62623 -32.949375东京 139.752725 35.68461&quot; &gt; 20City 北京= c(116.4167, 39.91667) City2=read.table('20City') 建立链接Num=0Result=data.frame()for(i in c(1:nrow(City2))){ Num=Num+1 tmp = Connet(北京,c(City2[i,][[2]],City2[i,][[3]]),Space=pi/10) tmp$Group=Num Result = rbind(Result,tmp)}经纬线() + geom_polygon(data=world, aes(x = long, y = lat, group = group), fill = &quot;#00518E&quot;,color = &quot;white&quot;,size=1.2)+ coord_map(&quot;ortho&quot;, orientation = c(30, 100, 0)) +theme_map()+ geom_polygon(data=world, aes(x = long, y = lat, group = group), fill = &quot;#00518E&quot;,color = &quot;#317DA4&quot;,alpha=0.25,size=0.5,linetype=6) + geom_point(data=Result,aes(x=X,y=Y)) More GGmap: geom_map geom_sf","link":"/2020/06/20/R/GGmap_polygon/"},{"title":"GGplot | A tutorials for beginner","text":"大量带图介绍: https://yutannihilation.github.io/allYourFigureAreBelongToUs/ggthemes/ 扩展包介绍: http://www.ggplot2-exts.org ggsave pre { background-color:#38393d; color: #5fd381; } ggsave(filename, plot = last_plot(), device = NULL, path = NULL, scale = 1, width = NA, height = NA, units = c(&quot;in&quot;, &quot;cm&quot;, &quot;mm&quot;), dpi = 300, limitsize = TRUE, ...)ggsave('plot.pdf', width=7,height=3)ggsave('plot.png', width=400,height=300)## 当pdf字体有问题时：ggsave('test.pdf', width=7,height=3, device = cairo_pdf, family = &quot;Song&quot;) Dot plot geom_point ggplot(mpg) +geom_point(mapping =aes( x =displ, y =hwy, color =class))ggplot(mpg) +geom_point(mapping =aes( x =V1, y =V2, color =V3, shape =V4, size=V5)) geom_dotplot ggplot(mtcars, aes(x = mpg)) + geom_dotplot() + theme_light() geom_jitter ggplot(mpg, aes(cyl, hwy))+ geom_point() +geom_jitter(aes(colour = class))+ theme_light() Line geom_line &amp; geom_path library(ggplot2)library(patchwork)TB = data.frame(X=c(1,23,4,2,3,4,1,1,2,3,4,1,1,5,2,3),Y=c(1:16))p1 &lt;- ggplot(TB) + geom_line(aes(X,Y)) + labs(title='geom_line()')+ theme_light()p2 &lt;- ggplot(TB) + geom_path(aes(X,Y)) + labs(title='geom_patch()')+ theme_light() geom_smooth ggplot(data = mpg) + geom_point(mapping = aes(x = V1, y = V2)) + geom_smooth(mapping= aes(x=V1, y=V2))######## stingggplot(mpg , aes(x = displ, y = hwy)) + geom_point() + geom_smooth(method = &quot;lm&quot;)++geom_smooth(data=Growth_p,aes(x=ID,y=log(value+20)/3,group=ALL,color='OD Curve'),se = FALSE,span=0.75) Extra Line aux2 &lt;- data.frame(cyl = c(4,6,8), x = c(2,3,4),y = c(10,10,10), xend = c(2,3,4), yend = c(35,35,35), x2 = c(3,4,5), xend2= c(3,4,5))ggplot(mtcars, aes(x = drat)) + geom_line(aes(y = mpg, colour = &quot;mpg&quot;)) + geom_line(aes(y = qsec, colour = &quot;qsec&quot;)) + geom_segment(aes(x = x, y = y, xend = xend, yend = yend, colour = &quot;xiaopang&quot;),data= aux2, lty = 2) + geom_segment(aes(x = x2, y = y, xend = xend2, yend = yend, colour = &quot;xiaomei&quot;),data= aux2, lty = 2) geom_boxplot ggplot(box,aes(x=box$variable,y=box$value)) +geom_boxplot() Bar geom_bar + geom_bar(stat= 'identity')### the number of the point+ geom_bar(aes(fill=group),stat=&quot;identity&quot;)### the mean of all point (stack togather)+ geom_bar(aes(fill=group),stat=&quot;summary&quot;,fun.y=&quot;mean&quot;,position = 'stack')### dont stact+ geom_bar(aes(fill=group),stat=&quot;summary&quot;,fun.y=&quot;mean&quot;,position = 'dodge') an easier way to draw bar plot df &lt;- data.frame(trt = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), outcome = c(2.3, 1.9, 3.2))ggplot(df, aes(trt, outcome)) + geom_col() + geom_point(color='red') Position for bar ### Positionposition = 'fill'position = 'identity'position = 'stack'position = 'dodge' More for Bar plot: Blog/语雀 from bar to pie you just need adding + coord_polar(&quot;y&quot;, start=0) at the end of your code More for pie: GitIO/语雀 Heatmap ggplot(A, aes(x=Diet,y=A$Time)) + xlab(&quot;samples&quot;) + ylab(NULL) + theme_bw()+theme(panel.grid.major = element_blank()) + theme(legend.key=element_blank())+geom_tile(aes(fill=weight)) + scale_fill_gradient2(low=&quot;steelblue2&quot;,mid=&quot;white&quot;,high=&quot;red&quot;,midpoint =150)+ scale_fill_gradient(low = &quot;white&quot;, high = &quot;red&quot;)ggplot(A, aes(x=Diet,y=A$Time)) + xlab(&quot;samples&quot;) + ylab(NULL) + theme_bw()+ theme(panel.grid.major = element_blank()) + theme(legend.key=element_blank())+ geom_tile(aes(fill=weight)) + scale_fill_gradient2(low=&quot;steelblue2&quot;,mid=&quot;white&quot;,high=&quot;red&quot;,midpoint =150)+ scale_fill_gradient(low = &quot;white&quot;, high = &quot;red&quot;) Best theme for heatmap ## Best color for heatmaplibrary(RColorBrewer)colorRampPalette(rev(brewer.pal(n = 7,name = &quot;RdYlBu&quot;))) -&gt; ccsimplot(d) + scale_fill_gradientn(colors=cc(100)) + theme() Fan plot ggplot() + geom_bar() + coord_polar(theta = 'y')## removing background+theme(panel.grid=element_blank(),panel.border=element_blank(),axis.ticks=element_blank(),axis.text=element_blank(),axis.title=element_blank(),, panel.background = element_blank())## orlibrary(ggthemes)+theme_map() geom_errorbar + geom_errorbar(aes(ymin=len-sd, ymax=len+sd), width=.2， position=position_dodge(.9)) Adding Equation reference: weixin_43948357 2020 eq &lt;- substitute(italic(y) == a + b %.% italic(x)~&quot;,&quot;~italic(R)^2~&quot;=&quot;~r2~&quot;,&quot;~italic(P)~&quot;=&quot;~p)p + geom_text(aes(x = 4, y = 50, label = as.character(as.expression(eq))), parse = TRUE) patchwork library(patchwork)p1 &lt;- ggplot(mtcars,aes(mpg)) + geom_histogram() + theme_light() + ggtitle('histogram')p2 &lt;- ggplot(mtcars,aes(mpg)) + geom_freqpoly() + theme_light() + ggtitle('freqpoly')p2/p1# order the legendP11/P33 + plot_layout(guides = &quot;collect&quot;) &amp; theme(legend.position = &quot;right&quot;) Axis reference: 九茶 2015 + scale_x_continuous(breaks=seq(0, 10, 5))## 0: start## 10: end## 5: breaks Switch Coordination ##switch X and Y+ coord_flip() Axis Limits + coord_cartesian(ylim = c(100,200), expand = F) # moving the panel+ coord_fixed(ratio =2) #ratio = axis.y/axis.x+ expand_limits(y=c(-12,18)) # similar like cartesian Polar Axis + coord_polar(theta =&quot;x&quot;, start = pi/3)+ coord_polar(theta =&quot;y&quot;, start = pi/3) Scale Axis ## https://www.cnblogs.com/wkslearner/p/5635184.html+scale_x_date(breaks=as.Date(c(&quot;2016-06-06&quot;,&quot;2016-06-13&quot;,&quot;2016-06-20&quot;,&quot;2016-06-27&quot;)), labels=c(&quot;06-06&quot;,&quot;06-13&quot;,&quot;06-20&quot;,&quot;06-27&quot;),date_labels=&quot;%y/%m/%d&quot;) Reverse axis + scale_x_reverse()+ scale_y_reverse() Legends Basic usage: + theme( legend.position='none') Position legend.position = 'none' # delete legendlegend.position = &quot;left&quot; # Position leftlegend.position = &quot;right&quot; # Position rightlegend.position = &quot;bottom&quot; # Position bottomlegend.position = &quot;top&quot; # Position Toplegend.position = c(0.9, 0.1) # relative postion in right-bottom. Legends’ name # alter in the given scalescale_color_gradient2(name = &quot;My title&quot;)# labs()labs(color = &quot;title for color&quot;, size = &quot;title for size&quot;, fill = &quot;title for fill&quot;) Texts labs + labs(title=&quot;MPO&quot;, x=&quot;Basket&quot;, y=&quot;U/g&quot;)+ theme(plot.title = element_text(hjust = 0.5)) geom_text &amp; geom_labels library(ggrepel)+geom_text_repel(aes(label=variable))+geom_text(data=A,aes(x=V1,y=valuable, label=row.names(A4), colour =row.names(A4)),nudge_x = 0.5) Annotate annotate(geom, x = NULL, y = NULL, xmin = NULL, xmax = NULL, ymin = NULL, ymax = NULL, xend = NULL, yend = NULL, ..., na.rm = FALSE)geom=&quot;text&quot; |&quot;rect&quot;| &quot;segment&quot; | &quot;pointrange&quot; + annotate(&quot;segment&quot;, x = 2, xend = 4, y = 15, yend = 25, colour = &quot;pink&quot;, size=3, alpha=0.6, arrow=arrow()) ggtitle ggtitle(&quot;AAA&quot;)theme(plot.title = element_text(hjust = 0.5)) Switch x labels (text.x) ## add the limits first and substitu...+ scale_x_discrete(name =&quot;Dose (mg)&quot;, limits=c(1:119),labels=as.character(A$X1)) Legends title # alter in the given scalescale_color_gradient2(name = &quot;My title&quot;)# labs()labs(color = &quot;title for color&quot;, size = &quot;title for size&quot;, fill = &quot;title for fill&quot;) Facet + facet_grid(Group ~ .)## Switch the side of the legen+ facet_grid(Group ~ . switch = 'y')## for GO enrichment+ facet_grid(. ~ Cate,scales = &quot;free_x&quot;,space = &quot;free&quot;)+ facet_wrap(~ V3, nrow = NULL, ncol = NULL, scales = &quot;free&quot;) Themes Background remove + theme(panel.grid.major =element_blank(), #栅格线1 panel.grid.minor = element_blank(), #栅格线2 panel.background = element_blank(), #滑板底层 axis.line = element_line(colour = &quot;black&quot;), #轴线 axis.ticks=element_blank(), #轴上点 axis.text.y=element_blank(), #y文字 axis.title.x =elemet_blank(), #y标题 legend.position='none') #删标注 background color panel.background = element_rect(fill = &quot;lightblue&quot;, colour = &quot;lightblue&quot;, size = 0.5, linetype = &quot;solid&quot;), Levels table$X=factor(table$X, levels=table[[1]]) theme() + theme(plot.title = element_text(hjust = 0.5),axis.text.x = element_text(angle = 45, hjust=1)) legend ##rm legend+theme(legend.position='none')##(&quot;none&quot;, &quot;left&quot;, &quot;right&quot;, &quot;bottom&quot;, &quot;top&quot;, or two-element numeric vect) Colors (scale_fill/scale_color) Default color palette for 4 samples: library(ggplot2)TB &lt;- ChickWeight[ChickWeight$Chick %in% c(1,30, 40,50),]summary(TB)P &lt;- ggplot(TB,aes(x=Time, y = weight, fill=Diet)) + geom_bar(stat = 'identity', position = 'dodge') + theme_bw()P weight Time Chick Diet Min. : 41.00 Min. : 0.00 1 :12 1:12 1st Qu.: 66.75 1st Qu.: 5.50 30 :12 2:12 Median :117.50 Median :11.00 40 :12 3:12 Mean :130.06 Mean :10.92 50 :12 4:12 3rd Qu.:172.00 3rd Qu.:16.50 18 : 0 Max. :321.00 Max. :21.00 16 : 0 (Other): 0 If we have only few group like less than 13, we can use the preset color palette from RColorBrewer by scale_color_brewer library(&quot;RColorBrewer&quot;)#P + scale_color_brewer(palette = &quot;RdYlBu&quot;) # this is for line nad outline of the barP + scale_fill_brewer(palette = &quot;RdYlBu&quot;) Palettes: - Diverging BrBG, PiYG, PRGn, PuOr, RdBu, RdGy, RdYlBu, RdYlGn, Spectral - Qualitative Accent, Dark2, Paired, Pastel1, Pastel2, Set1, Set2, Set3 - Sequential Blues, BuGn, BuPu, GnBu, Greens, Greys, Oranges, OrRd, PuBu, PuBuGn, PuRd, Purples, RdPu, Reds, YlGn, YlGnBu, YlOrBr, YlOrRd If we only interesting in few of the color from the palette, we can print the color value and assign them with scale_color_manual/scale_fill_manual Show the value of the colors: brewer.pal(n = 12, name = &quot;Paired&quot;) '#A6CEE3''#1F78B4''#B2DF8A''#33A02C''#FB9A99''#E31A1C''#FDBF6F''#FF7F00''#CAB2D6''#6A3D9A''#FFFF99''#B15928' ##Examplescale_fill_manual(values=c(&quot;#FB882C&quot;,&quot;#5B88A0&quot;)) If the group number is larger than 3 and we still want to using the color from palette, one resolution is combine multiple color palettes. Another Resolution is using colors from a palette or a list again and again. library(&quot;RColorBrewer&quot;)G_number = 100N = 12P + scale_fill_manual(values= head(rep(brewer.pal(n = N, name = &quot;Paired&quot;),round(G_number/N)+1), G_number)) library(&quot;ggthemes&quot;)## Gradientscale_fill_gradient() 允许分配一组双色连续渐变，low=&quot;white&quot;,high=&quot;red&quot;scale_fill_gradient2() 允许分配一组三色连续渐变，low=&quot;blue&quot;,mid=&quot;white&quot;,high=&quot;red&quot;## sed a group of colourscale_fill_manual(values=c(&quot;Linen&quot;,&quot;Peru&quot;,&quot;PeachPuff&quot;,&quot;SandyBrown&quot;,&quot;Chocolate&quot;))## apply the Set on ggthemes+ scale_colour_XXX() # Tab to see more+ scale_color_gradient(low = &quot;cyan&quot;,high = &quot;red&quot;) scale_color_gradient(low = &quot;cyan&quot;,high = &quot;red&quot;) scale_color_gradientn(values = seq(0,1,0.2),colours = c('cyan','blue','green','orange','red')) © 天使不设防 2019 © 天使不设防 2019 More for plot 1. Cow plot library(cowplot)+ draw_plot(p1,0,0.5,0.5,0.5)+draw_plot(p2,0.5,0.5,0.5)+draw_plot(pheat,0.5,0,0.5,0.5)+draw_plot_label(c(&quot;A&quot;, &quot;B&quot;), c(0,0.5), c(1, 1), size = 20)'''Xl,Xr,Yt,Yzoomdraw_plot(p1,Xl,Yb,Xzoom,Yzoom,Pzoom)''' 2. Patch Work reference: 尘世中一个迷途小书僮 library(patchwork)p1 &lt;- ggplot() + ...p2 &lt;- ggplot() + ...p1|p2p1/p2(p1|p2)|p2GGlay = 'AA##B'p1 +p2 +plot_layout(design = GGlay) 3. Map library(pacman)rladies &lt;- read_csv(url(&quot;https://raw.githubusercontent.com/d4tagirl/R-Ladies-growth-maps/master/rladies.csv&quot;))%&gt;% select(-1)p_load(tidyverse, gganimate, maps, ggthemes)ggplot()+borders(&quot;world&quot;, color=&quot;black&quot;, fill=&quot;steelblue4&quot;) + geom_point(data = rladies, aes(lon, lat, size=followers), color=&quot;firebrick3&quot;, alpha=0.6)+scale_size_continuous(range = c(2,8), breaks = c(250, 500, 750, 1000)) + labs(size=&quot;Followers&quot;, title=&quot;The development of R-Ladies'Twitter accounts&quot;, x=NULL,y=NULL)+theme(text = element_text(family = &quot;Times New Roman&quot;, color = &quot;deeppink&quot;),plot.title = element_text(size=40,color = &quot;#f9ba00&quot;), plot.subtitle = element_text(size=14),axis.ticks = element_blank(), axis.text = element_blank(),panel.grid = element_blank(), panel.background = element_rect(fill=&quot;skyblue&quot;), plot.background = element_rect(fill = &quot;#333333&quot;), legend.position = c(0.18,0.36),legend.background = element_blank(), legend.key = element_blank(),legend.text = element_text(size = 24), legend.title = element_text(size=28, color = &quot;orangered3&quot;)) More for maps, please go to see: GGplot Map Extra Details for theme ############################## Parameter of theme###########################line #all line elements (element_line)rect #all rectangular elements (element_rect)text #all text elements (element_text)title #all title elements: plot, axes, legends (element_text; inherits from text)aspect.ratio #aspect ratio of the panelaxis.title #label of axes (element_text; inherits from text)axis.title.x #x axis label (element_text; inherits from axis.title)axis.title.y #y axis label (element_text; inherits from axis.title)axis.tex #tick labels along axes (element_text; inherits from text)axis.text.x #x axis tick labels (element_text; inherits from axis.text)axis.text.y #y axis tick labels (element_text; inherits from axis.text)axis.ticks #tick marks along axes (element_line; inherits from line)axis.ticks.x #x axis tick marks (element_line; inherits from axis.ticks)axis.ticks.y #y axis tick marks (element_line; inherits from axis.ticks)axis.ticks.length #length of tick marks (unit)axis.line #lines along axes (element_line; inherits from line)axis.line.x #line along x axis (element_line; inherits from axis.line)axis.line.y #line along y axis (element_line; inherits from axis.line)legend.background #background of legend (element_rect; inherits from rect)legend.margin #extra space added around legend (unit)legend.key #background underneath legend keys (element_rect; inherits from rect)legend.key.size #size of legend keys (unit; inherits from legend.key.size)legend.key.height #key background height (unit; inherits from legend.key.size)legend.key.width #key background width (unit; inherits from legend.key.size)legend.text #legend item labels (element_text; inherits from text)legend.text.align #alignment of legend labels (number from 0 (left) to 1 (right))legend.title #title of legend (element_text; inherits from title)legend.title.align #alignment of legend title (number from 0 (left) to 1 (right))legend.position #the position of legends (&quot;none&quot;, &quot;left&quot;, &quot;right&quot;, &quot;bottom&quot;, &quot;top&quot;, or two-element numeric vector)legend.direction #layout of items in legends (&quot;horizontal&quot; or &quot;vertical&quot;)legend.justification #anchor point for positioning legend inside plot (&quot;center&quot; or two-element numeric vector)legend.box #arrangement of multiple legends (&quot;horizontal&quot; or &quot;vertical&quot;)legend.box.just #justification of each legend within the overall bounding box, when there are multiple legends (&quot;top&quot;, &quot;bottom&quot;, &quot;left&quot;, or &quot;right&quot;)panel.background #background of plotting area, drawn underneath plot (element_rect; inherits from rect)panel.border #border around plotting area, drawn on top of plot so that it covers tick marks and grid lines. This should be used with fill=NA(element_rect; inherits from rect)panel.margin #margin around facet panels (unit)panel.margin.x #horizontal margin around facet panels (unit; inherits from panel.margin)panel.margin.y #vertical margin around facet panels (unit; inherits from panel.margin)panel.grid #grid lines (element_line; inherits from line)panel.grid.major #major grid lines (element_line; inherits from panel.grid)panel.grid.minor #minor grid lines (element_line; inherits from panel.grid)panel.grid.major.x #vertical major grid lines (element_line; inherits from panel.grid.major)panel.grid.major.y #horizontal major grid lines (element_line; inherits from panel.grid.major)panel.grid.minor.x #vertical minor grid lines (element_line; inherits from panel.grid.minor)panel.grid.minor.y #horizontal minor grid lines (element_line; inherits from panel.grid.minor)panel.ontop #option to place the panel (background, gridlines) over the data layers. Usually used with a transparent or blankpanel.background. (logical)plot.background #background of the entire plot (element_rect; inherits from rect)plot.title #plot title (text appearance) (element_text; inherits from title)plot.margin #margin around entire plot (unit with the sizes of the top, right, bottom, and left margins)strip.background #background of facet labels (element_rect; inherits from rect)strip.text #facet labels (element_text; inherits from text)strip.text.x #facet labels along horizontal direction (element_text; inherits from strip.text)strip.text.y #facet labels along vertical direction (element_text; inherits from strip.text)strip.switch.pad.grid #space between strips and axes when strips are switched (unit)strip.switch.pad.wrap #space between strips and axes when strips are switched (unit) Details for element margin(t = 0, r = 0, b = 0, l = 0, unit = &quot;pt&quot;)element_blank()element_rect(fill = NULL, colour = NULL, size = NULL, linetype = NULL, color = NULL, inherit.blank = FALSE)element_line(colour = NULL, size = NULL, linetype = NULL, lineend = NULL, color = NULL, arrow = NULL, inherit.blank = FALSE)element_text(family = NULL, face = NULL, colour = NULL, size = NULL, hjust = NULL, vjust = NULL, angle = NULL, lineheight = NULL, color = NULL, margin = NULL, debug = NULL, inherit.blank = FALSE)rel(x)","link":"/2020/06/12/R/GGplot/"},{"title":"GGplot 杂耍","text":"1.点 2.线 曲线链接两点 library(ggplot2)##先从横线线入手## r*sin(theta/2)=d/2##2.随机圈上圆点## r^2 = (x+a)^2 + (y+b)^2## D -&gt; centerD0##1.两点距离Distent &lt;- function(P1,P2){ R = sqrt((P1[1]-P2[1])^2 + (P1[2]-P2[2])^2) return(R)}##2.映射到平行Trans &lt;- function(P1,P2){ D_s = Distent(P1,P2) P2=c(P1[1]+D_s,P1[2]) return(P2)}##画弧Cir_D &lt;-function(P1,P2,D=c(0,0),r=1,Space=pi/7){ X = seq(P1[1],P2[1],by=Space) Y = sqrt(r^2-(X-D[1])^2)+D[2] S=data.frame(X,Y)return(S)}##整合Connet &lt;- function(P1,P2,Space=pi/7,theta=pi/2){ P3 = Trans(P1,P2) D=(P1+P3)/2 #中点 d=sqrt((P1-P3)[1]^2 + (P1-P3)[2]^2) #得长 r=(d/2)/sin(theta/2) l=(d/2)/tan(theta/2) Cen_x =D[1] Cen_y = D[2]-l D=c(Cen_x,Cen_y) S=Cir_D(P1,P3,D,r,Space=Space) if(P1[1] -P2[1] &gt; 0){ S$Y = (-1)*S$Y } #List = Turn_back(P1,P3,P2) Sin=(P2-P1)[2]/sqrt(sum((P2-P1)^2)) Cos=(P2-P1)[1]/sqrt(sum((P2-P1)^2)) X = S$X*Cos-S$Y*Sin Y = S$X*Sin+S$Y*Cos Line = data.frame(X=X-(X[1]-P1[1]),Y=Y-(Y[1]-P1[2]))## p &lt;- ggplot(S)+geom_point(aes(X,Y))+ ## geom_label(aes(x=P1[1],y=P1[2],label=&quot;P1&quot;,color=&quot;P1&quot;))+ ## geom_point(aes(x=P3[1],y=P3[2],color=&quot;P3&quot;))+ ## geom_point(aes(x=D[1],y=D[2],color=&quot;center&quot;))+ ## geom_label(aes(x=P2[1],y=P2[2],size=2,label=&quot;P2&quot;))+ ## geom_point(data=Line,aes(X,Y),color='red')## print(p)## p &lt;- geom_point(data=Line,aes(X,Y,group=1),color='red') return(Line)}P1 = c(0,0)P2 = c(6,0)Connet(P1,P2)ggplot(Connet(P1,P2,pi/15),aes(X,Y))+geom_path() 原理： 1.转成平行，方便找圆心 2.画弧(黑色) 3.旋转(红色) Combine The Whole function ##There is a funning thing I found.##When I try to name it as geom_curve, I cheked the original geom function and find## THIS FUNCTION EXIST ALREADY!! So, why should I waste so much of time to write this function = =geom_curve_C &lt;- function(P1,P2,Space=pi/20,theta=pi/2){ P3 = Trans(P1,P2) D=(P1+P3)/2 #中点 d=sqrt((P1-P3)[1]^2 + (P1-P3)[2]^2) #得长 r=(d/2)/sin(theta/2) l=(d/2)/tan(theta/2) Cen_x =D[1] Cen_y = D[2]-l D=c(Cen_x,Cen_y) S=Cir_D(P1,P3,D,r,Space=Space) if(P1[1] -P2[1] &gt; 0){ S$Y = (-1)*S$Y } #List = Turn_back(P1,P3,P2) Sin=(P2-P1)[2]/sqrt(sum((P2-P1)^2)) Cos=(P2-P1)[1]/sqrt(sum((P2-P1)^2)) X = S$X*Cos-S$Y*Sin Y = S$X*Sin+S$Y*Cos Line = data.frame(X=X-(X[1]-P1[1]),Y=Y-(Y[1]-P1[2])) p &lt;- geom_path(data=Connet(P1,P2,pi/20),aes(x=X,y=Y)) return(p)}P1 = c(0,0)P2 = c(6,0)ggplot + geom_curve_C(P1,P2) 荧光经纬线 经纬线 &lt;- function(底色='grey',边色=&quot;#E9FEFF&quot;,Space=30){ p &lt;- ggplot() + #geom_vline(aes(xintercept=seq(-180,+180,by=Space)),color=颜色,size=1.3,alpha=0.5)+ geom_vline(aes(xintercept=seq(-180,+180,by=Space)),color=边色,size=2,alpha=0.7)+ geom_vline(aes(xintercept=seq(-180,+180,by=Space)),color=底色,linetype=&quot;dashed&quot;)+ #geom_hline(aes(yintercept=seq(-80,+80,by=Space)),color=颜色,size=1.3,alpha=0.5)+ geom_hline(aes(yintercept=seq(-80,+80,by=Space)),color=边色,size=2,alpha=0.7)+ geom_hline(aes(yintercept=seq(-80,+80,by=Space)),color=底色,linetype=&quot;dashed&quot;)+ theme_map() return(p)}经纬线() 3. theme 文字 theme_text &lt;- function(){ theme(axis.text.x=element_text(angle=45, hjust=1))} More","link":"/2020/08/13/R/GGplot_tricks/"},{"title":"Machine Learning (out of date)","text":"Machine Learning (out of date) library(tidyverse)library(rpart)library(randomForest)a &lt;- read_csv(&quot;../input/melb_data.csv&quot;)## train a decision tree based on our datasetfit &lt;- rpart(Price ~ Rooms + Bathroom + Landsize + BuildingArea + YearBuilt + Lattitude + Longtitude, data = a)plot(fit, uniform=TRUE) +text(fit, cex=1.6)print(head(melbourne_data))print(predict(fit, head(melbourne_data)))print(head(melbourne_data$Price))##### Train and Testlibrary(modelr)mae(model = fit, data = a)splitData &lt;- resample_partition(a, c(test = 0.3, train = 0.7))lapply(splitData, dim)fit2 &lt;- rpart(Price ~ Rooms + Bathroom + Landsize + BuildingArea + YearBuilt + Lattitude + Longtitude, data = splitData$train)mae(model = fit2, data = splitData$test)#####Built functionget_mae &lt;- function(maxdepth, target, predictors, training_data, testing_data){predictors &lt;- paste(predictors, collapse=&quot;+&quot;)formula &lt;- as.formula(paste(target,&quot;~&quot;,predictors,sep = &quot;&quot;))model &lt;- rpart(formula, data = training_data,control = rpart.control(maxdepth = maxdepth))mae &lt;- mae(model, testing_data)return(mae)}target &lt;- &quot;Price&quot;predictors &lt;- c(&quot;Rooms&quot;,&quot;Bathroom&quot;,&quot;Landsize&quot;,&quot;BuildingArea&quot;,&quot;YearBuilt&quot;,&quot;Lattitude&quot;,&quot;Longtitude&quot;)for(i in 1:10){ mae &lt;- get_mae(maxdepth = i, target = target, predictors = predictors, training_data = splitData$train, testing_data = splitData$test) print(glue::glue(&quot;Maxdepth: &quot;,i,&quot;\\t MAE: &quot;,mae))}#####MODEL with training and repairmodel &lt;- rpart(formula, data = splitData$train ,control = rpart.control(maxdepth = 5))","link":"/2020/08/20/R/Machine_Learning/"},{"title":"GGradar | ggplot example","text":"Project: ricardo-bion 2019 Quick Start remotes::install_github('ricardo-bion/ggradar')library(ggplot2)library(ggradar)mydata&lt;-matrix(runif(40,0,1),5,8)rownames(mydata) &lt;- LETTERS[1:5]colnames(mydata) &lt;- c(&quot;Apple&quot;,&quot;Google&quot;,&quot;Facebook&quot;,&quot;Amozon&quot;,&quot;Tencent&quot;,&quot;Alibaba&quot;,&quot;Baidu&quot;,&quot;Twitter&quot;)mynewdata&lt;-data.frame(mydata)Name&lt;-c(&quot;USA&quot;,&quot;CHN&quot;,&quot;UK&quot;,&quot;RUS&quot;,&quot;JP&quot;)mynewdata&lt;-data.frame(Name,mynewdata)ggradar(mynewdata)ggradar(mynewdata) + theme(legend.position = 'none') ##Data structure'''Name Apple Google Facebook Amozon Tencent Alibaba BaiduA USA 0.6028703 0.9975856 0.4771023 0.8630967 0.21543389 0.78643566 0.7611366B CHN 0.3853622 0.7067794 0.4991334 0.8006687 0.47394478 0.68875340 0.1547279C UK 0.2634778 0.3165925 0.8032880 0.5479650 0.87007110 0.01701491 0.3585789D RUS 0.9749844 0.6391640 0.0542372 0.2777984 0.04970435 0.38795458 0.4374871E JP 0.3928207 0.5548013 0.5891342 0.5367423 0.69436110 0.48937538 0.1104125''' Arguments ggradar(data,axis.label.size = 4,grid.label.size =7,group.line.width = 1,group.point.size = 3,plot.title = '这啥？') fmsb library(fmsb)set.seed(99)data=as.data.frame(matrix( sample( 0:20, 15, replace=F) , ncol=5))colnames(data)=c(&quot;math&quot;, &quot;english&quot;, &quot;biology&quot;, &quot;music&quot;, &quot;R-coding&quot;)rownames(data)=paste(&quot;mister&quot;, letters[1:3] , sep=&quot;-&quot;)## 用于生成雷达图的最大最小值data=rbind(rep(20,5) , rep(0,5) , data)colors_border=c( rgb(0.2,0.5,0.5,0.9), rgb(0.8,0.2,0.5,0.9) , rgb(0.7,0.5,0.1,0.9))colors_in=c( rgb(0.2,0.5,0.5,0.4), rgb(0.8,0.2,0.5,0.4) , rgb(0.7,0.5,0.1,0.4))radarchart( data, axistype=1, pcol=colors_border , pfcol=colors_in , plwd=4, plty=1, cglcol=&quot;grey&quot;, cglty=1, axislabcol=&quot;grey&quot;, caxislabels=seq(0,20,5), cglwd=0.8, vlcex=0.8)legend(x=0.7, y=1, legend = rownames(data[-c(1,2),]), bty = &quot;n&quot;, pch=20, col=colors_in , text.col = &quot;grey&quot;, cex=1.2, pt.cex=3) More","link":"/2020/08/13/R/GGradar/"},{"title":"NetWorkPlot","text":"pre { background-color:#38393d; color: #5fd381; } NetWorkPlot Igraph Document library(igraph)##Create dataset.seed(1)data=matrix(sample(0:1, 100, replace=TRUE, prob=c(0.8,0.2)), nc=10)network=graph_from_adjacency_matrix(data , mode='undirected', diag=F )##Default networkpar(mar=c(0,0,0,0))plot(network) Tricks for Igraph nodes-distance; name of the nodes The trickiest way to achieve this goal is decreasing the size of nodes. library(igraph)##Create dataset.seed(1)data=matrix(sample(0:1, 100, replace=TRUE, prob=c(0.8,0.2)), nc=10)network=graph_from_adjacency_matrix(data , mode='undirected', diag=F )V(network)$name &lt;- paste(&quot;dot&quot;, c(1:10))##Default networkpar(mar=c(0,0,0,0))plot(network, vertex.size = 5) More examples plot(network,vertex.color = rgb(0.8,0.2,0.2,0.9), # Node colorvertex.frame.color = &quot;Forestgreen&quot;, # Node border colorvertex.shape=c(&quot;circle&quot;,&quot;square&quot;), # One of “none”, “circle”, “square”, “csquare”, “rectangle” “crectangle”, “vrectangle”, “pie”, “raster”, or “sphere”vertex.size=c(15:24), # Size of the node (default is 15)vertex.size2=NA, # The second size of the node (e.g. for a rectangle)edge.curved=0.8) node shape names(igraph:::.igraph.shapes) [1] \"circle\" \"square\" \"csquare\" \"rectangle\" \"crectangle\" [6] \"vrectangle\" \"none\" ## color palettelibrary(RColorBrewer)coul = brewer.pal(nlevels(as.factor(mtcars$cyl)), &quot;Set2&quot;)## Map the color to cylindersmy_color=coul[as.numeric(as.factor(mtcars$cyl))]## plotpar(bg=&quot;grey13&quot;, mar=c(0,0,0,0))set.seed(4)plot(network, vertex.size=12, vertex.color=my_color, vertex.label.cex=0.7, vertex.label.color=&quot;white&quot;, vertex.frame.color=&quot;transparent&quot; )text(0,0,&quot;The network chart of the mtcars dataset&quot;,col=&quot;white&quot;)text(0.2,-0.1,&quot; - by the R graph gallery&quot;,col=&quot;white&quot;)legend(x=-0.6, y=-0.12, legend=paste( levels(as.factor(mtcars$cyl)), &quot; cylinders&quot;, sep=&quot;&quot;), col = coul , bty = &quot;n&quot;, pch=20 , pt.cex = 2, cex = 1, text.col=&quot;white&quot; , horiz = T) More instructions: Katherine Ognyanova, 2016 Group-1, Åsa Björklund; Group-2, Antoine; 2015 NetworkD3 dave it as html library(htmlwidgets)saveWidget(P,&quot;_bar.html&quot;, selfcontained = F) library(networkD3)# options(browser = 'firefox')## Load datadata(MisLinks)data(MisNodes)forceNetwork(Links=MisLinks, #读入基因之间的关系列表，基因以数字为编号，从0开始；value可用来设置基因间连线的宽度 Nodes=MisNodes, #基因信息，以对应编号的大小排序 Source=&quot;source&quot;, #指定Links文件中的源节点 Target=&quot;target&quot;, #指定Links文件中的靶节点 Value=&quot;value&quot;, #设定基因间连线的宽度 NodeID=&quot;name&quot;, #指定节点显示的标签 fontSize=20, #设定节点标签的字号，单位为像素 Group=&quot;group&quot;, #对节点进行分组，这里可根据基因的功能进行分组，配置不同颜色 opacity=0.8, #指定图像的不透明度 zoom=TRUE, #是否允许图像缩放 arrows=TRUE, #连线是否添加箭头，显示方向 opacityNoHover=0.7, #鼠标悬停前，节点标签的不透明度 legend=TRUE, #是否显示图例 height=600, #设置图像高度 width=600 #设置图像宽度 #Nodesize = &quot;Freq_l&quot; #radiusCalculation = &quot;d.nodesize&quot; ) Those Code Doesn’t Works without the data set forceNetwork(Links=genelinks, #读入基因之间的关系列表，基因以数字为编号，从0开始；value可用来设置基因间连线的宽度 Nodes=genenodes, #基因信息，以对应编号的大小排序 Source=&quot;source&quot;, #library(RColorBrewer)coul = brewer.pal(nlevels(as.factor(mtcars$cyl)), &quot;Set2&quot;)指定Links文件中的源节点 Target=&quot;target&quot;, #指定Links文件中的靶节点 linkColour=genelinks$col, #指定连线的颜色，默认为单一颜色，这里用红、绿色分别表示某一基因对靶基因的正、负调控关系 Value=&quot;value&quot;, #设定基因间连线的宽度 NodeID=&quot;name&quot;, #指定节点显示的标签 fontSize=20, #设定节点标签的字号，单位为像素 Group=&quot;group&quot;, #对节点进行分组，这里可根据基因的功能进行分组，配置不同颜色 opacity=0.8, #指定图像的不透明度 zoom=TRUE, #是否允许图像缩放 arrows=TRUE, #连线是否添加箭头，显示方向 opacityNoHover=0.7, #鼠标悬停前，节点标签的不透明度 legend=TRUE, #是否显示图例 height=600, #设置图像高度 width=600 #设置图像宽度 #Nodesize = &quot;Freq_l&quot; #radiusCalculation = &quot;d.nodesize&quot; )MyClickScript &lt;- 'r = confirm(d.name+&quot;\\\\n\\\\nIf you\\'d like to know more about &quot;+d.name+&quot;, Please Click \\'OK\\'&quot;); if (r == true){ window.open(&quot;https://www.uniprot.org/uniprot/&quot;+d.name+&quot;_HUMAN&quot;);};'forceNetwork( Links=GeneLinks, Nodes=GeneNodes, Source=&quot;source&quot;, Target=&quot;target&quot;, linkColour=&quot;#99FFCC&quot;, Value=&quot;value&quot;, NodeID=&quot;name&quot;, Nodesize = &quot;Freq_l&quot;, fontSize=20, Group=&quot;group&quot;, opacity=0.98, zoom=TRUE, arrows=F, opacityNoHover=0.7, legend=TRUE, clickAction = MyClickScript) matrix to network data Data: X and Y don’t share the items in raw_tb 屋 沃 烛 觉 歌 0 0 0 0 戈 2 0 0 0 豪 12 6 0 3 肴 2 0 0 18 MT_Network &lt;- function(raw_tb, direction=&quot;wide&quot;){ if(direction==&quot;wide&quot;){ raw_tb$ID = row.names(raw_tb) raw_tb &lt;- melt(raw_tb) } if(direction==&quot;long&quot;){ colnames(raw_tb) &lt;- c(&quot;ID&quot;, &quot;variable&quot;, &quot;value&quot;) } ID = unique(c(raw_tb$ID, as.character(raw_tb$variable))) ID = data.frame(ID, NO=c(1:length(ID))) MisLinks = raw_tb MisLinks$ID = ID$NO[match(raw_tb$ID, ID$ID)]-1 MisLinks$variable = ID$NO[match(raw_tb$variable, ID$ID)]-1 colnames(MisLinks) = c(&quot;source&quot;, &quot;target&quot;, &quot;value&quot;) MisLinks = MisLinks[which(MisLinks$value!=0),] MisLinks = MisLinks[order(MisLinks$source),] MisNodes = ID colnames(MisNodes) = c(&quot;name&quot;, &quot;group&quot;) MisNodes$size = 1 return(list(MisLinks,MisNodes))} TB &lt;- data.frame(A=c(0,2,1), B= c(0,0,1), C=c(1,0,5))row.names(TB) = c(&quot;A&quot;, &quot;C&quot;, &quot;D&quot;)print(TB)Result &lt;- MT_Network(TB)Links &lt;- Result[[1]]Nodes &lt;- Result[[2]]forceNetwork( Links=Links, Nodes=Nodes, Source=&quot;source&quot;, Target=&quot;target&quot;, linkColour=&quot;#99FFCC&quot;, Value=&quot;value&quot;, NodeID=&quot;name&quot;, fontSize=20, Group=&quot;group&quot;, opacity=0.98, zoom=TRUE, arrows=T, opacityNoHover=0.7, legend=TRUE) A B C A 0 0 1 C 2 0 0 D 1 1 5 Sankey Diagram library(networkD3)# Load energy projection dataURL &lt;- &quot;https://cdn.rawgit.com/christophergandrud/networkD3/master/JSONdata/energy.json&quot;Energy &lt;- jsonlite::fromJSON(URL)head(Energy$links)head(Energy$nodes)# Thus we can plot itp &lt;- sankeyNetwork(Links = Energy$links, Nodes = Energy$nodes, Source = &quot;source&quot;, Target = &quot;target&quot;, Value = &quot;value&quot;, NodeID = &quot;name&quot;, units = &quot;TWh&quot;, fontSize = 12, nodeWidth = 30)p source target value 1 0 1 124.729 2 1 2 0.597 3 1 3 26.862 4 1 4 280.322 5 1 5 81.144 6 6 2 35.000 name 1 Agricultural 'waste' 2 Bio-conversion 3 Liquid 4 Losses 5 Solid 6 Gas","link":"/2020/08/13/R/NetWorkPlot/"},{"title":"Other Tutories for R","text":"Other Tutories 知乎 杜雨: 那些年倒腾的R语言学习笔记，全都在这里了~","link":"/2020/08/13/R/Other-Tutories/"},{"title":"PCA and PCoA","text":"PCA PCA 1 prcomp ## install ggbioplot## remotes::install_github(&quot;vqv/ggbiplot&quot;)## install.packages('plyr')library(plyr)library(ggbiplot)data(wine)wine.pca &lt;- prcomp(wine, scale. = TRUE)## bioplotggbiplot(wine.pca, obs.scale = 1, var.scale = 1, groups = wine.class, ellipse = TRUE, circle = TRUE) + scale_color_discrete(name = '') + theme_light()+ theme(axis.title = element_text(size=10))# var.axis = F to remove the varible axis on the center. 1.1 Arguments ggbiplot(pcobj, choices = 1:2, scale = 1, pc.biplot =TRUE, obs.scale = 1 - scale, var.scale = scale, groups =NULL, ellipse = FALSE, ellipse.prob = 0.68, labels =NULL, labels.size = 3, alpha = 1, var.axes = TRUE, circle= FALSE, circle.prob = 0.69, varname.size = 3,varname.adjust = 1.5, varname.abbrev = FALSE, ...)pcobj # prcomp()或princomp()返回结果choices # 选择轴，默认1：2scale # covariance biplot (scale = 1), form biplot (scale = 0). When scale = 1, the inner product between the variables approximates the covariance and the distance between the points approximates the Mahalanobis distance.obs.scale # 标准化观测值var.scale # 标准化变异pc.biplot # 兼容 biplot.princomp()groups # 组信息，并按组上色ellipse # 添加组椭圆ellipse.prob # 置信区间labels #向量名称labels.size #名称大小alpha #点透明度 (0 = TRUEransparent, 1 = opaque)circle #绘制相关环(only applies when prcomp was called with scale = TRUE and when var.scale = 1)var.axes #绘制变量线-菌相关varname.size #变量名大小varname.adjust #标签与箭头距离 &gt;= 1 means farther from the arrowvarname.abbrev # 标签是否缩写 2 Psych library(psych)library(ggplot2)# calculate PCAPC &lt;- principal(wine, nfactors=2, rotate =&quot;none&quot;)pc &lt;- data.frame(PC$scores)# calculate the location of labelsLabel_pos &lt;- aggregate(cbind(PC1, PC2) ~ wine.class, data=pc, FUN=median)# Plot the PCA scatter graphggplot(pc, aes(x=PC1, y=PC2,color=wine.class )) + geom_point(size=4,alpha=0.5)+ theme_light() + geom_label(data = Label_pos, aes(label = wine.class), alpha = .3)+ stat_ellipse(lwd=1,level = 0.95, alpha= .8, linetype = 4) 3 qplot library(ggplot2)qplot(x=PC1,y=PC2, data=pc,colour=factor(wine.class))+theme(legend.position=&quot;none&quot;)+stat_ellipse(lwd=1,level = 0.8) More library(ggbiplot)library(ggthemes)library(patchwork)data(wine)wine.pca &lt;- prcomp(wine, scale. = TRUE)## bioplotTB= data.frame(wine.pca$x)TB$class = wine.classp0 &lt;- ggbiplot(wine.pca, obs.scale = 1, var.scale = 1, groups = wine.class, ellipse = TRUE, circle = TRUE) + scale_color_discrete(name = '') + theme_light()+theme(legend.position = 'none', axis.title=element_blank())p1 &lt;- ggplot() + geom_density(data=TB, aes(x=PC1,fill=class),alpha=0.5) + theme_map() + theme(legend.position = 'none')p2 &lt;- ggplot() + geom_density(data=TB, aes(x=PC2,fill=class),alpha=0.5) + theme_map() +theme(legend.position = 'none') + coord_flip() + scale_y_reverse()p3 &lt;- ggplot(TB, aes(x=class,y=PC1)) + geom_tufteboxplot(aes(color=class),median.type = &quot;line&quot;, hoffset = 0, width = 3) + coord_flip()+ theme_map()+ theme(legend.position = 'none')p4 &lt;- ggplot(TB, aes(x=class,y=PC2)) + geom_tufteboxplot(aes(color=class),median.type = &quot;line&quot;, hoffset = 0, width = 3) + theme_map()+ theme(legend.position = 'none')TB= data.frame(wine.pca$x)TB$class = wine.classGGlay &lt;-&quot;#BBBBBB#CAAAAAAECAAAAAAECAAAAAAECAAAAAAECAAAAAAECAAAAAAE##DDDDDD#&quot;p0+p1+p2+p3+p4 +plot_layout(design = GGlay) PCoA What's different between PCA and PCoA? Principal Component Analysis (PCA) and Principal Coordinates Analysis (PCoA, also known as Multidimensional Scaling, MDS) are both techniques used for dimensionality reduction, which is the process of reducing the number of random variables under consideration by obtaining a set of principal variables. However, they are used in different contexts and have different underlying methodologies. PCA is a technique that is used when you have a multivariate data set and you want to identify new variables that will represent the variability of your entire data set as much as possible. The new variables, or principal components, are linear combinations of the original variables. PCA operates on a covariance (or correlation) matrix, which implies that it is a parametric method. On the other hand, PCoA is a method used in ecology and biology to transform a matrix of distances (or dissimilarities) between samples into a new set of orthogonal axes, the most important of which can be plotted against each other. PCoA can be applied to any symmetric distance or dissimilarity matrix. Unlike PCA, PCoA is non-parametric and makes no assumptions about the distribution of the original variables. So, the main difference lies in the type of data they work with: PCA works with the actual data matrix and is used when you have a set of observations and measurements, while PCoA works with a matrix of pairwise distances and is used when you have a set of pairwise dissimilarities (like geographical distances between cities or genetic distances between individuals or species). © ChatGPT4 Interesting PCA in Python Main PCA research and Plot import pandas as pdfrom sklearn.decomposition import PCAfrom sklearn.preprocessing import StandardScalerfrom sklearn.datasets import load_wineimport matplotlib.pyplot as plt# Step 1: Load the wine datasetwine_data = load_wine()df = pd.DataFrame(data=wine_data.data, columns=wine_data.feature_names)# Step 2: Standardize the data (optional but recommended)scaler = StandardScaler()scaled_data = scaler.fit_transform(df)# Run the PCA with 3 componentspca = PCA(n_components=2) # Reduce to 2 dimensions for visualizationprincipal_components = pca.fit_transform(scaled_data)pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])pca_df['target'] = wine_data.target# Create a scatter plot with color based on the target classscatter = plt.scatter(pca_df['PC1'], pca_df['PC2'], c=pca_df['target'], cmap='viridis', edgecolor='k', alpha=0.7)# Adding labels and titleplt.xlabel('Principal Component 1')plt.ylabel('Principal Component 2')plt.title('PCA of Wine Dataset')# Add a color bar to indicate the different classesplt.colorbar(scatter, ticks=[0, 1, 2], label='Wine Class')# Optionally, add a legend (if your target classes are categorical)# legend = plt.legend(*scatter.legend_elements(), title=&quot;Classes&quot;)# plt.gca().add_artist(legend)# Show the plotplt.grid(True)plt.show() By checking the raw data, each column is feature, row is element. Index Alcohol Malic Acid … OD280/OD315 of Diluted Wines Proline 0 14.23 1.71 … 3.92 1065.0 1 13.20 1.78 … 3.40 1050.0 2 13.16 2.36 … 3.17 1185.0 3 14.37 1.95 … 3.45 1480.0 4 13.24 2.59 … 2.93 735.0 … … … … … … 173 13.71 5.65 … 1.74 740.0 174 13.40 3.91 … 1.56 750.0 175 13.27 4.28 … 1.56 835.0 176 13.17 2.59 … 1.62 840.0 177 14.13 4.10 … 1.60 560.0 Explained Variance Ratio # Step 3: Perform PCApca = PCA() # By default, PCA will consider all componentspca.fit(scaled_data)# Step 4: Get the explained variance ratio for each componentexplained_variance_ratio = pca.explained_variance_ratio_# Step 5: Create a DataFrame to store component contributionscomponent_contributions = pd.DataFrame({ 'Principal Component': [f'PC{i+1}' for i in range(len(explained_variance_ratio))], 'Explained Variance Ratio': explained_variance_ratio})# Step 6: Sort the components by their contribution (explained variance ratio)component_contributions_sorted = component_contributions.sort_values(by='Explained Variance Ratio', ascending=False)# Display the sorted componentsprint(component_contributions_sorted)# Step 7: Optionally, you can plot the explained variance ratio to visualizeplt.figure(figsize=(8, 6))plt.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, alpha=0.7, align='center', label='individual explained variance')plt.step(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio.cumsum(), where='mid', label='cumulative explained variance')plt.ylabel('Explained variance ratio')plt.xlabel('Principal components')plt.legend(loc='best')plt.tight_layout()plt.show() Index Principal Component Explained Variance Ratio 0 PC1 0.361988 1 PC2 0.192075 2 PC3 0.111236 3 PC4 0.070690 4 PC5 0.065633 5 PC6 0.049358 6 PC7 0.042387 7 PC8 0.026807 8 PC9 0.022222 9 PC10 0.019300 10 PC11 0.017368 11 PC12 0.012982 12 PC13 0.007952 Contribution of Each Features import numpy as np# adding a new column for test.df2 = df.copy()df2['test'] = 0# Perform PCApca = PCA()pca.fit(df2)# Get the loadings (components)loadings = pca.components_.T# Calculate the contribution of each featurefeature_contributions = np.sum(np.abs(loadings), axis=1)# Create a DataFrame to rank featuresfeature_importance_df = pd.DataFrame({ 'Feature': wine_data.feature_names + ['test'], 'Contribution': feature_contributions})feature_importance_df = feature_importance_df.sort_values(by='Contribution', ascending=False).reset_index(drop=True)# Rank features by their contribution We can find the this contribution results, the text column doesn’t has any of contribution in variation since all values are equals to 1. Feature Contribution 0 flavanoids 2.640230 1 od280/od315_of_diluted_wines 2.066036 2 total_phenols 2.050567 3 malic_acid 1.991115 4 proanthocyanins 1.981272 5 color_intensity 1.867953 6 alcohol 1.849138 7 hue 1.807356 8 magnesium 1.707784 9 ash 1.558561 10 alcalinity_of_ash 1.551888 11 nonflavanoid_phenols 1.430382 12 malic_acid 1.204709 13 test 1.000000","link":"/2020/06/23/R/PCA/"},{"title":"Ploty","text":"Ploty Quick Start install.packages(&quot;plotly&quot;)library(plotly)library(ggplot2)p &lt;- ggplot(df) + geom_point(ase(x=X,y=Y))P &lt;- ggplotly(p) Save library(htmlwidgets)saveWidget(P,&quot;1.html&quot;,selfcontained = F) More","link":"/2020/06/20/R/Ploty/"},{"title":"GGplot in Github","text":"GGplot in Github Update by: 2020/1/20Sort by stars tidyverse/ggplot2 4.2k(stars) thomasp85/gganimate 1.4k jrnold/ggthemes 1k thomasp85/ggraph 694 slowkow/ggrepel 694 rstudio/ggvis 661 cttobin/ggthemr 597 dkahle/ggmap 564 kassambara/ggpubr 532 thomasp85/ggforce 493 hrbrmstr/ggalt 483 sinhrks/ggfortify 415 YuLab-SMU/ggtree 381 davidgohel/ggiraph 360 ggobi/ggally 320 calligross/ggthemeassist 316 yutannihilation/gghighlight 313 nanxstats/ggsci 310 eclarke/ggbeeswarm 301 clauswilke/ggjoy 299 EmilHvitfeldt/ggpage 290 wilkelab/ggridges 288 daattali/ggExtra 255 gadenbuie/ggpomological 252 malcolmbarrett/ggdag 237 echen/ggplot2-tutorial 236 ricardo-bion/ggtech 236 vqv/ggbiplot 229 strengejacke/ggeffects 220 jespermaag/gganatogram 213 const-ae/ggsignif 210 paleolimbot/ggspatial 202 corybrunson/ggalluvial 199 jennybc/ggplot2-tutorial 198 LKremer/ggpointdensity 187 AtherEnergy/ggTimeSeries 183 lionel-/ggstance 182 ricardo-bion/ggradar 180 dill/emoGG 170 wilkox/ggfittext 169 briatte/ggnet 167 AliciaSchep/gglabeller 150 oswaldosantos/ggsn 133 wilkox/gggenes 124 eliocamp/ggnewscale 124 erocoar/gghalves 122 lepennec/ggwordcloud 118 omarwagih/ggseqlogo 116 RobWHickman/ggparliament 116 clauswilke/ggtextures 112 ehrlinger/ggRandomForests 108 martin-borkovec/ggparty 105 const-ae/ggupset 104 VPetukhov/ggrastr 102 gertstulp/ggplotgui 99 GuangchuangYu/ggimage 95 cosname/ggplot2-translation 92 kassambara/ggcorrplot 89 briatte/ggnetwork 88 xfim/ggmcmc 82","link":"/2020/01/22/R/R-gitgg/"},{"title":"R-riverplot","text":"pre { background-color:#38393d; color: #5fd381; } R-riverplot install.packages(&quot;riverplot&quot;)library(riverplot) ##1. 画一个6级能量流动图/桑基图 构造连接节点(边)的数据框，采用runif生成模拟数据 实验中每个节点间的连续情况是己知的 #1. 生成一个组1-5与组2-6对应的值数据框:edges = data.frame(N1 = paste0(rep(LETTERS[1:4], each = 4), rep(1:5, each = 16)), N2 = paste0(rep(LETTERS[1:4], 4), rep(2:6, each = 16)), Value = runif(80, min = 2, max = 5) * rep(c(1, 0.8, 0.6, 0.4, 0.3), each = 16), stringsAsFactors = F)# 2. 筛选80%的记录，以免每个点都对应到4个点(可选)edges = edges[sample(c(TRUE, FALSE), nrow(edges), replace = TRUE, prob = c(0.8, 0.2)),]head(edges) N1 N2 Value 1 A1 A2 3.308538 2 A1 B2 4.642646 3 A1 C2 4.339417 5 B1 A2 3.413252 6 B1 B2 3.028736 7 B1 C2 2.722511 # 3. 获得非冗余结点nodesnodes = data.frame(ID = unique(c(edges$N1, edges$N2)), stringsAsFactors = FALSE)## 添加x: X为组编号，即列位置nodes$x = as.integer(substr(nodes$ID, 2, 2))## Y为组类型字符，转换为ASCII编号，减65，即为A/B/C/D转换为0/1/2/3数值，即行位置nodes$y = as.integer(sapply(substr(nodes$ID, 1, 1), charToRaw)) - 65rownames(nodes) = nodes$IDhead(nodes)## 添加颜色library(RColorBrewer)## brewer.pal生成柔合色，后面加调淡颜色palette = paste0(brewer.pal(4, &quot;Set1&quot;), &quot;60&quot;)## 对每个节点生成相应的列表格式，颜色col，线条类型lty，文字颜色textcolstyles = lapply(nodes$y, function(n) { list(col = palette[n+1], lty = 0, textcol = &quot;black&quot;) }) names(styles) = nodes$ID## 将点、单和样式合并为List，构建riverplot对象rp &lt;- list(nodes = nodes, edges = edges, styles = styles)## 添加对你属性包括riverplotclass(rp) &lt;- c(class(rp), &quot;riverplot&quot;)plot(rp, plot_area = 0.95, yscale=0.06) Riverplot for change of the Genes Quick Build A Sankey Diagram from Different list Let’s say, we have 3 group of data: Group A: A-M Group B: A-N; But G-J is missing Group C: A-N; But I-Ois missing A &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;, &quot;F&quot;, &quot;G&quot;, &quot;H&quot;, &quot;I&quot;, &quot;J&quot;, &quot;K&quot;, &quot;L&quot;, &quot;M&quot;)B &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;, &quot;F&quot;, &quot;K&quot;, &quot;L&quot;, &quot;M&quot;, &quot;N&quot;)C &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;, &quot;F&quot;, &quot;G&quot;, &quot;H&quot;, &quot;N&quot;,&quot;O&quot;)TB = data.frame(row.names = sort(unique(c(A,B,C))))Num = 0for(Col in list(A,B,C)){ Num = Num + 1 TB[paste(&quot;Group&quot;,Num, sep=&quot;_&quot;)] = 0 TB[paste(&quot;Group&quot;,Num, sep=&quot;_&quot;)][row.names(TB) %in% Col,] = 1}print(TB) Group_1 Group_2 Group_3 A 1 1 1 B 1 1 1 C 1 1 1 D 1 1 1 E 1 1 1 F 1 1 1 G 1 0 1 H 1 0 1 I 1 0 0 J 1 0 0 K 1 1 0 L 1 1 0 M 1 1 0 N 0 1 1 O 0 0 1 Plot Function library(stringr)library(ggplot2)library(reshape2)library(RColorBrewer)Kaboom_Flow &lt;- function(TB){ coul = brewer.pal(12, &quot;Set3&quot;) # Melt data Group = c() for(i in c(1:nrow(TB))){ Group= c(Group, paste(TB[i,],collapse = &quot;_&quot;)) } Group_TB_gene = data.frame(Group,row.names = row.names(TB)) Group = as.data.frame(table(Group)) Group = Group[order(Group$Group, decreasing = F),] Group_N = data.frame(str_split_fixed(Group[[1]], &quot;_&quot;, ncol(TB)), stringsAsFactors =F) for(i in c(1:ncol(Group_N))){ Group_N[[i]] = as.numeric(Group_N[[i]]) } Group_N &lt;- Group_N * Group$Freq colnames(Group_N) = colnames(TB) Increasing_list = Group_N for(i in c((nrow(Increasing_list)-1):1)) { Increasing_list[i,] = Increasing_list[i+1,] + Increasing_list[i,] } Increasing_TB &lt;- rbind(Increasing_list, rep(0, ncol(Increasing_list),)) Group_N$Group &lt;- Group$Group Group_TB &lt;- melt(Group_N) Mutation_flow&lt;- function(TB, Bar_w= 0.2){ P &lt;- ggplot() + geom_bar(data=Group_TB, aes(x=variable, y=value, fill = Group), stat = 'identity', position = 'stack', width = Bar_w) + theme_bw() return(P) } Connect &lt;- function(TMP_TB, Bar_w = 0.2, C_alp = .1, Color=&quot;grey&quot;){ Indent_ = Bar_w/2 #C_alp = (1-Bar_w) * C_alp + Indent_ C_alp = (max(TMP_TB$X)- min(TMP_TB$X) -Bar_w) * C_alp + Indent_ TMP_TB2 &lt;- TMP_TB TMP_TB3 &lt;- TMP_TB TMP_TB2$X &lt;- TMP_TB2$X + Indent_ TMP_TB3$X &lt;- TMP_TB3$X - Indent_ TMP_ind &lt;- rbind(TMP_TB2, TMP_TB3) TMP_ind &lt;- TMP_ind[which(TMP_ind$X %in% c(max(TMP_ind$X), min(TMP_ind$X))==FALSE),] TMP_TB2$X &lt;- TMP_TB2$X + C_alp TMP_TB3$X &lt;- TMP_TB3$X - C_alp TMP_alp &lt;- rbind(TMP_TB2, TMP_TB3) TMP_alp &lt;- TMP_alp[which(TMP_alp$X %in% c(max(TMP_alp$X), min(TMP_alp$X))==FALSE),] Area_TB = rbind(TMP_ind, TMP_alp) g1 &lt;- ggplot() + geom_smooth(data=Area_TB[Area_TB$line==&quot;UP&quot;,], aes(x=X, y = value))+ geom_smooth(data=Area_TB[Area_TB$line==&quot;DOWN&quot;,], aes(x=X, y = value)) # build plot object for rendering gg1 &lt;- ggplot_build(g1) # extract data for the loess lines from the 'data' slot df2 &lt;- data.frame(x = gg1$data[[1]]$x, ymin = gg1$data[[1]]$y, ymax = gg1$data[[2]]$y) # use the loess data to add the 'ribbon' to plot p &lt;- geom_ribbon(data = df2, aes(x = x, ymin = ymin, ymax = ymax), fill = Color, alpha = 0.4) return(p) } # Get the Index Index_ = c() for(Row in c(1:nrow(Group_N))){ TMP &lt;- Group_N[Row,1:(ncol(Group_N)-1)] # clean the duplicate 0 # remove 0 Result = TMP[which(TMP!=0)] # Chech of the end tmp_id = which(colnames(TMP)==colnames(Result)[ncol(Result)]) if(tmp_id != ncol(TMP)){ Result[colnames(TMP)[tmp_id+1]] = 0 } # Chech of the head tmp_id = which(colnames(TMP)==colnames(Result)[1]) if(tmp_id != 1){ Result[colnames(TMP)[tmp_id-1]] = 0 } # sort by raw data Result = Result[as.character(sort(factor(colnames(Result), levels = colnames(TMP))))] row.names(Result) = Row Index_ = c(Index_, list(Result)) } P &lt;- Mutation_flow(TB) for(i in c(1:length(Index_))){ TMP = Index_[[i]] Row = as.numeric(rownames(TMP)) TMP = Increasing_TB[Row:(Row+1),colnames(TMP)] TMP$line=c(&quot;UP&quot;,&quot;DOWN&quot;) for(col_i in c(1:(ncol(TMP)-2))){ TMP_TB = melt(TMP[c(col_i,col_i+1, ncol(TMP))]) TMP_TB$X = as.numeric(factor(TMP_TB$variable , levels=colnames(Increasing_TB ))) P &lt;- P + Connect(TMP_TB,.2, .1, coul[1+(i%%12)]) } } print(P) return(list(P,Group_TB_gene))} Reference Packaged function remotes::install_github(&quot;karobben/ggkaboom&quot;)library(ggkaboom)Kaboom_flow(TB)","link":"/2020/01/22/R/R-riverplot/"},{"title":"R 语言报错集","text":"R 语言报错集 写R包 打包错误 R CMD build hello* checking for file ‘hello/DESCRIPTION’ ... OK* preparing ‘hello’:* checking DESCRIPTION meta-information ... OK* installing the package to process help pages -----------------------------------* installing *source* package ‘hello’ ...** using staged installation** R** byte-compile and prepare package for lazy loading** helpWarning: /tmp/Rtmp9IseJR/Rbuild799a14248b2f/hello/man/hello-package.Rd:26: All text must be in a section*** installing help indicesError in Rd_info(db[[i]]) : missing/empty \\title field in '/tmp/Rtmp9IseJR/Rbuild799a14248b2f/hello/man/hello.Rd'Rd files must have a non-empty \\title.See chapter 'Writing R documentation' in manual 'Writing R Extensions'.* removing ‘/tmp/Rtmp9IseJR/Rinst799a2d1feb80/hello’ -----------------------------------ERROR: package installation failed 错原： “missing/empty \\title fiel”， 没有改title解决： sed -i ‘s/%% ~~function to do … ~~/喵喵喵？/’ hello/man/hello.Rd 上传至github后安装报错 devtools::install_github(&quot;Karobben/Test&quot;)Downloading GitHub repo Karobben/Test@master✔ checking for file ‘/tmp/Rtmp3HTrN3/remotes225241f0c918/Karobben-Test-252c791/DESCRIPTION’ ...─ preparing ‘hello’:✔ checking DESCRIPTION meta-information─ installing the package to process help pages─ saving partial Rd database (688ms)─ checking for LF line-endings in source and make files and shell scripts─ checking for empty or unneeded directories─ building ‘hello_1.0.tar.gz’Installing package into ‘/home/ken/R/x86_64-pc-linux-gnu-library/3.6’(as ‘lib’ is unspecified)* installing *source* package ‘hello’ ...** using staged installation** R** byte-compile and prepare package for lazy loading** helpError : (converted from warning) /tmp/RtmpixBxlB/Rbuild2ccc35a25d23/hello/man/hello-package.Rd:26: All text must be in a sectionERROR: installing Rd objects failed for package ‘hello’* removing ‘/home/ken/R/x86_64-pc-linux-gnu-library/3.6/hello’ 错原：Error : (converted from warning) /tmp/RtmpixBxlB/Rbuild2ccc35a25d23/hello/man/hello-package.Rd:26: All text must be in a section解决： 删除 man/hello-package.Rd 的 第 26 行","link":"/2020/06/20/R/R_errors/"},{"title":"Response Surface Methodology in R","text":"Response Surface Methodology in R (rsm) Introduction of RSM and rsm pacakge Response-surface methodology comprises a body of methods for exploring for optimum operating conditions through experimental methods. The rsm package for R (R Development Core Team 2009[1]) provides several functions to facilitate classical response-surface methods. Commercial Software for rsm: Design-Expert JMP Statgraphics rsm covers only the most standard first-and second order designs and methods for one response variable. desirability package (Kuhn 2009) may be used in conjunction with predictions obtained using the rsm package Install install.packages('rsm') Started With library(&quot;rsm&quot;)ChemReact Table ChemReact: Time Temp Block Yield1 80.00 170.00 B1 80.52 80.00 180.00 B1 81.53 90.00 170.00 B1 82.04 90.00 180.00 B1 83.55 85.00 175.00 B1 83.96 85.00 175.00 B1 84.37 85.00 175.00 B1 84.08 85.00 175.00 B2 79.79 85.00 175.00 B2 79.810 85.00 175.00 B2 79.511 92.07 175.00 B2 78.412 77.93 175.00 B2 75.613 85.00 182.07 B2 78.514 85.00 167.93 B2 77.0 coded.date The first block, ChemReact1, uses factor settings of Time = 85 ± 5 and Temp = 175 ± 5, with three center points. Thus, the coded variables are x1 = (Time − 85)=5 and x1 = (Temp − 175)=5. CR1 &lt;- coded.data(ChemReact1, x1 ~ (Time - 85)/5, x2 ~ (Temp - 175)/5)CR1 Time Temp Yield1 80 170 80.52 80 180 81.53 90 170 82.04 90 180 83.55 85 175 83.96 85 175 84.37 85 175 84.0Data are stored in coded form using these coding formulas ...x1 ~ (Time - 85)/5x2 ~ (Temp - 175)/5 ## data frame was used to plotas.data.frame(CR1) des1 &lt;- ccd (y1 + y2 ~ A + B + C + D, generators = E ~ - A * B * C * D, n0 = c(6, 1))des10 &lt;- ccd( ~ A + B + C + D + E, blocks = Blk ~ c(A * B * C, C * D * E), n0 = c(2, 4))par(mfrow=c(1,2))varfcn(des10, ~ Blk + SO(A,B,C,D,E), dist = seq(0, 3, by=.1))varfcn(des10, ~ Blk + SO(A,B,C,D,E), dist = seq(0, 3, by=.1), contour = TRUE) ccd(2, n0 = c(1,1), inscribed=TRUE, randomize=FALSE) run.order std.order x1.as.is x2.as.is Block1 1 1 -0.7071068 -0.7071068 12 2 2 0.7071068 -0.7071068 13 3 3 -0.7071068 0.7071068 14 4 4 0.7071068 0.7071068 15 5 5 0.0000000 0.0000000 16 1 1 -1.0000000 0.0000000 27 2 2 1.0000000 0.0000000 28 3 3 0.0000000 -1.0000000 29 4 4 0.0000000 1.0000000 210 5 5 0.0000000 0.0000000 2Data are stored in coded form using these coding formulas ...x1 ~ x1.as.isx2 ~ x2.as.is CR1.rsm &lt;- rsm(Yield ~ FO(x1, x2), data = CR1)summary(CR1.rsm) CCD (Central-Composite Design) One of the most popular response-surface designs is the central-composite design (CCD), due to Box and Wilson (1951)[2]. it works as the codes show below, but I didn’t figure out how exactly why = = Fitting a Response-Surface Model library(rsm)CR1 &lt;- coded.data(ChemReact1, x1 ~ (Time - 85)/5, x2 ~ (Temp - 175)/5)CR1.rsm &lt;- rsm(Yield ~ FO(x1, x2), data = CR1)CR1.rsmi &lt;- update(CR1.rsm, . ~ . + TWI(x1, x2))CR2 &lt;- djoin(CR1, ChemReact2)CR2.rsm &lt;- rsm(Yield ~ Block + SO(x1, x2), data = CR2)png('image.png',w=450, h= 1000)par(mfrow=c(3,1))image(CR1.rsm, x1~ x2)image(CR1.rsmi, x1~ x2)image(CR2.rsm, x1~ x2)dev.off()png('persp.png',w=450, h= 1000)par(mfrow=c(3,1))persp(CR1.rsm, x1~ x2, col='blue', contours = list(z='top',col='orange'))persp(CR1.rsmi, x1~ x2, col='blue', contours = list(z='top',col='orange'))persp(CR2.rsm, x1~ x2, col='blue', contours = list(z='top',col='orange')) dev.off() Images: image(CR1.rsm, x1~ x2)image(CR1.rsmi, x1~ x2)image(CR2.rsm, x1~ x2) persp(CR1.rsm, x1~ x2, col=‘blue’, contours = list(z=‘top’,col=‘orange’))persp(CR1.rsmi, x1~ x2, col=‘blue’, contours = list(z=‘top’,col=‘orange’))persp(CR2.rsm, x1~ x2, col=‘blue’, contours = list(z=‘top’,col=‘orange’)) More about this codes: Video tutorial: Chris Mack 2016 Codes: Chris Mack 2016 Click to see the explanation of codes #--------------------------------------##--- Response Surface Modeling in R ---##--------------------------------------##First, install and load the &quot;rsm&quot; package# install.packages(&quot;rsm&quot;)library(rsm)# Example generating a Box-Behnken design with three factors and two center points (no)bbd(3, n0 = 2, coding = list(x1 ~ (Force - 20)/3, x2 ~ (Rate - 50)/10, x3 ~ Polish - 4))# Example data setdata = ChemReactplot(data)# The data set was collected in two blocks.# Block1 is a 2-level, two-factor factorial design with three repeated center points.# Block 2 is the Central Composite Design (circomscribed) with 3 center points.# The variables are Time = 85 +/- 5 and Temp = 175 +/- 5,# Thus, the coded variables are x1 = (Time-85)/5 and x2 = (Temp-175)/5CR &lt;- coded.data(ChemReact, x1 ~ (Time - 85)/5, x2 ~ (Temp - 175)/5)CR[1:7,]# Note: If the data are already coded, use as.coded.data() to convert to the proper coded data object# Let's work as though the first block (full factorial) has been finished,# and we'll fit a linear model, first order (FO), to it (Yield is the response)CR.rsm1 &lt;- rsm(Yield ~ FO(x1, x2), data = CR, subset = (Block == &quot;B1&quot;))summary(CR.rsm1)#The fit is not very good. Let's include the interaction term (TWI) and update the model, or start over with a new model (these two lines do the same thing)CR.rsm1.5 &lt;- update(CR.rsm1, . ~ . + TWI(x1, x2))CR.rsm1.5 &lt;- rsm(Yield ~ FO(x1, x2)+TWI(x1, x2), data = CR, subset = (Block == &quot;B1&quot;))summary(CR.rsm1.5)#This is no better! The reason is the strong quadratic response, with the peak near the center.# Now let's assume the second block has been collected. We use the SO (second order) function, which includes FO and TWICR.rsm2 &lt;- rsm(Yield ~ Block + SO(x1, x2), data = CR)summary(CR.rsm2)# The secondary point is a maximum (both eigenvalues are negative) and within the experimental design range (no extrapolation)# Also note that the block is significant, meaning that the processes shifted between the first set of data and the second. This is not good. The coefficient is -4.5, meaning the yield shifted down by 4.5% between the two blocks - a more significant effect than either temperatue or time! This is most easily seen by looking at the repeat center points.# We can plot the fitted response as a contour plot.contour(CR.rsm2, ~ x1 + x2, at = summary(CR.rsm2)$canonical$xs) On the other hand: An other algorithm to plot the surface by lm which explained by Resseel V. Lenth 2010[3] A.lm &lt;- lm( Yield ~ poly(Time, Temp, degree =2),data=ChemReact1)image(A.lm, Time~ Temp)contour(A.lm, Time~ Temp)persp(A.lm, Time~ Temp, col='blue', contours = list(z='top',col='orange')) It’s clearly different from the result above. st=>start: Table sp1=>operation: coded.date:>#step1 e=>end: End:>http://www.google.com op1=>operation: My Operation|past op2=>operation: Stuff|current sub1=>subroutine: 这啥啊|invalid cond=>condition: Yes or No?|approved:>http://www.google.com c2=>condition: Good idea|rejected io=>inputoutput: catch something...|request st->sp1(right) cond(yes, right)->c2 cond(no)->sub1(left)->op1 c2(yes)->io->e c2(no)->op2(right)->op1{\"theme\":\"simple\",\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"flowchart-0-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"flowchart-0-options\").value)); var diagram = flowchart.parse(code); diagram.drawSVG(\"flowchart-0\", options); R Development Core Team (2009). R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing, Vienna, Austria. ISBN 3-900051-07-0, URL http://www.R-project.org/. ↩︎ Box GEP, Wilson KB (1951). “On the Experimental Attainment of Optimum Conditions.” Journal of the Royal Statistical Society B, 13, 1-45. ↩︎ Surface Plots in the rsm Package ↩︎","link":"/2020/08/02/R/R-rsm/"},{"title":"3分钟写一个R包","text":"3分钟写一个R包 主要参考：https://blog.csdn.net/jiyang_1/article/details/53283504 3分钟写个R包 1. 新建目录，快速写一个函数 mkdir R_packageecho 'hello &lt;- function() { print(paste(&quot;Hellow World&quot;))}' &gt; hello.R##这里的 hello.R 就是所有的需要放在包里面的函数了 2. 在R中创建骨架 ##该目录打开Rpackage.skeleton(name=&quot;hello&quot;,code_files=&quot;hello.R&quot;) 3. 根据需要添加相关相关信息 为了赶上3min，我只改了两个必须改的地方。 ## 在title 下面加一行，不然本地安装报错sed -i 's/%% ~~function to do ... ~~/喵喵喵？/' hello/man/hello.Rd##删除此行，不然github远程安装的时候报错sed -i '/~~ Optionally other standard keywords, one per line, from file KEYWORDS in the R documentation directory ~~/d' hello/man/hello-package.RdR CMD build hello##R CMD check hello_1.0.tar.gz##可以不check 应为有错误也能安装，一般只要能打包##但是上Cran就一定要check了 不run第3部分第二行代码的结果（改title） 4. 开始安装 进入R安装。注意路径。 install.packages(&quot;hello_1.0.tar.gz&quot;, type=&quot;source&quot;, repos=NULL) 成果！ 撒花 5. 运行测试 library(hello) hello()##输出结果##Hellow World?hello#查看函数信息packageDescription('hello') # 查看信息和安装地址##最后删除我们的包remove.packages('hello' ) Details: Indexofhelptopics: ### 6. 完成！ 接下来可以认真的写一个自己的包啦！可以和大众分享，也可以是储存几个自己习惯的函数看看表，有没有超过3min！ ![NJkUAI.md.png](https://s1.ax1x.com/2020/06/22/NJkUAI.md.png) 最后 上传到github吧 Github 新建目录后，直接吧hello下的文件，全部上传即可，安装 devtools::install_github(&quot;Karobben/Test&quot;) 不进行第3部分第5航代码的结果： 统统上传～～","link":"/2020/06/22/R/Rin3min/"},{"title":"How to Start With R","text":"How to Started With R R语言新手快速入门起步 实验楼 國內網站， 所以全是中文， 並且速度快。 新手超級友好！缺點： 免費課程較少（5個，鏈接列在後面了）不過， 免費的， 對與新手入門來說， 還是夠了。！（反正都是， 從入門，到放棄 23333）並且基礎的， 機器學習入門，也有。所以還是蠻OK的，首推 界面 實驗樓界面比較簡潔。左邊是介紹， 和練習用的代碼右邊是一個完全的， linux 圖形虛擬桌面。好處就是， 他是一個完全的linux圖形界面系統壞處就是， 應爲是基於瀏覽器，所以是有些快捷鍵無法使用。此外，就是比較浪費，網絡， 計算機的性能， 反應較慢。並且無法檢測代碼對錯進行打分評價。不過因此， 看見太簡單的教程也可以直接跳過，避免冗餘的重複練習。 免费课程列表： R 语言基础入门 R 语言高级数据管理 R 语言英国房屋价格建模预测 R 语言序列数据挖掘 R 语言进行商业问卷分析 DataCampe 虽然是英文界面， 国外服务器， 但是速度还是挺快的。 比之后测试的 CodaAcademy 要好很多。 而且输入界面，更像Rstudio 首页 练习界面 分区如下图所示， 输入代码后， 按输入区的submit 提交即可下一题 下一题 code academy Website: CodeAcademy 主页 第一页 学习界面 12+3 网速略慢。 swirl Learn R in R install.packages(&quot;swirl&quot;)library(swirl)swirl() | Welcome to swirl! Please sign in. If you've been here before, use the same| name as you did then. If you are new, call yourself something unique.What shall I call you? 我很皮的输入papa /滑稽 | Thanks, papa. Let's cover a couple of quick housekeeping items before we| begin our first lesson. First of all, you should know that when you see| '...', that means you should press Enter when you are done reading and ready| to continue.... &lt;-- That's your cue to press Enter to continue 更具指引， 你將開始下一個課程， 然後選擇他： 開始學習！ #### 一大波文字說明即將到來， 2333 | | 0%| The simplest and most common data structure in R is the vector.... |== | 3%| Vectors come in two different flavors: atomic vectors and lists. An atomic| vector contains exactly one data type, whereas a list may contain multiple| data types. We'll explore atomic vectors further before we get to lists.... |==== | 5%| In previous lessons, we dealt entirely with numeric vectors, which are one| type of atomic vector. Other types of atomic vectors include logical,| character, integer, and complex. In this lesson, we'll take a closer look at| logical and character vectors. 終於開始了，2333 | First, create a numeric vector num_vect that contains the values 0.5, 55,| -10, and 6. 輸入 0.5 [1] 0.5| You almost had it, but not quite. Try again. Or, type info() for more| options.| Recall that the c() function is used for creating a vector. If you forget how| to use it, use ?c to access the help file. Don't forget to assign the result| to a new variable called num_vect.&gt; ummm， 我覺得相對於來學R， 這個更適合用來學英語， 哈哈哈哈哈","link":"/2020/06/03/R/Start/"},{"title":"WGCNA - 實戰","text":"WGCNA - 實戰 0. 數據結構 0.1 Expression matrix Trinity script TPM result ID1 ID2 Liver_CK Intest_CK Muscle_CK Liver_30 Intest_30 Muscle_30 Liver_75 Intest_75 Muscle_75 TRINITY_DN100000_c1_g1 TRINITY_DN100000_c1_g1_i1 2.1 4.3 1.32 1.04 4.49 2.85 3.59 4.27 1.7 TRINITY_DN100001_c0_g1 TRINITY_DN100001_c0_g1_i1 0.45 21.0 0.02 0.15 8.85 4.33 0.18 14.76 0.0 TRINITY_DN100002_c0_g1 TRINITY_DN100002_c0_g1_i1 8.39 2.01 1.08 11.32 3.2 1.1 7.83 6.23 2.91 0.2 Traits ID Group Organ Weight Liver_CK CK Liver 33.32 Intest_CK CK Intest 33.32 Muscle_CK CK Muscle 33.32 Liver_30 SPC30 Liver 31.3 Intest_30 SPC30 Intest 31.3 … … … … 1. Data Clean 1.1 Load and Filter library(WGCNA)A &lt;- read.csv(&quot;All_isoform.TPM.matrix.anno.xls&quot;,sep='\\t')## rownames:sample; colnames: Transcriptsrow.names(A) = A[[2]]A = A[-(1:2)]datExpr0 = t(A)## Data filtergsg = goodSamplesGenes(datExpr0, verbose = 3);gsg$allOKif (!gsg$allOK){ # Optionally, print the gene and sample names that were removed: if (sum(!gsg$goodGenes)&gt;0) printFlush(paste(&quot;Removing genes:&quot;, paste(names(datExpr0)[!gsg$goodGenes], collapse = &quot;, &quot;))); if (sum(!gsg$goodSamples)&gt;0) printFlush(paste(&quot;Removing samples:&quot;, paste(rownames(datExpr0)[!gsg$goodSamples], collapse = &quot;, &quot;))); # Remove the offending genes and samples from the data: datExpr0 = datExpr0[gsg$goodSamples, gsg$goodGenes]} 1.2 Clust sampleTree = hclust(dist(datExpr0), method = &quot;average&quot;);##png(file = &quot;sampleClustering_T45.png&quot;,wi=300, he=300)par(cex = 0.6);par(mar = c(0,4,2,0))plot(sampleTree, main = &quot;Sample clustering to detect outliers&quot;, sub=&quot;&quot;, xlab=&quot;&quot;, cex.lab = 1.5, cex.axis = 1.5, cex.main = 2)##dev.off() 相對來說， Liver30 異質性有點大， 不過， 根據實驗來說， 應該是正常現象，因此跳過刪除異質性項。 datExpr = datExpr0nGenes = ncol(datExpr)nSamples = nrow(datExpr) 1.3 Loading Traits traitData = read.csv(&quot;traits.csv&quot;)allTraits = traitData[-c(2,3)]Samples = rownames(datExpr);traitRows = match(Samples, allTraits$ID);datTraits = allTraits[traitRows, -1];rownames(datTraits) = allTraits[traitRows, 1];collectGarbage()## Re-cluster samplessampleTree2 = hclust(dist(datExpr), method = &quot;average&quot;)## Convert traits to a color representation: white means low, red means high, grey means missing entrytraitColors = numbers2colors(datTraits, signed = FALSE);## Plot the sample dendrogram and the colors underneath.## png(&quot;traits_heatmap.png&quot;)plotDendroAndColors(sampleTree2, traitColors, groupLabels = names(datTraits), main = &quot;Sample dendrogram and trait heatmap&quot;) ummm, 並不能看出什麼來。只是個普通的熱圖加樹衛而已 2. Network construction and module detection 2.1 Pick soft-thresdholding power powers = c(c(1:10), seq(from = 12, to=20, by=2))## Call the network topology analysis functionsft = pickSoftThreshold(datExpr, powerVector = powers, verbose = 5)## Plot the results:sizeGrWindow(9, 5)##png(&quot;sorft_Thread.png&quot;,wi=630,he=350)## Scale-free topology fit index as a function of the soft-thresholding power## png(&quot;T45_Soft_th.png&quot;,width=500,height=300)cex1 = 0.9;par(mfrow = c(1,2));plot(sft$fitIndices[,1], -sign(sft$fitIndices[,3])*sft$fitIndices[,2], xlab=&quot;Soft Threshold (power)&quot;,ylab=&quot;Scale Free Topology Model Fit,signed R^2&quot;,type=&quot;n&quot;, main = paste(&quot;Scale independence&quot;));text(sft$fitIndices[,1], -sign(sft$fitIndices[,3])*sft$fitIndices[,2], labels=powers,cex=cex1,col=&quot;red&quot;);## this line corresponds to using an R^2 cut-off of habline(h=0.90,col=&quot;red&quot;)## Mean connectivity as a function of the soft-thresholding powerplot(sft$fitIndices[,1], sft$fitIndices[,5], xlab=&quot;Soft Threshold (power)&quot;,ylab=&quot;Mean Connectivity&quot;, type=&quot;n&quot;, main = paste(&quot;Mean connectivity&quot;))text(sft$fitIndices[,1], sft$fitIndices[,5], labels=powers, cex=cex1,col=&quot;red&quot;)##dev.off() ummm… 等了半天，就這。。。這種垃圾數據的話， 還是放棄把。 3. 刪除不必要reads，再來做一遍 想法： 刪除低hit的reads， 減少計算量，減少垃圾數據的污染 Counts &lt;- read.csv(&quot;/media/ken/Data/Yan/RNA-seq/report/4.exprs//All_isoform.COUNT.matrix.anno.xls&quot;,sep='\\t')Counts$Sum = rowSums(Counts[-c(1:2)])Counts_sub = Counts[which(Counts$Sum&gt;10),]paste(round((nrow(Counts_sub)/nrow(Counts))*100,2),&quot;%&quot;,sep=&quot;&quot;)A_sub &lt;- A[match(Counts_sub[[2]],rownames(A)),] 然後， 重複上面步驟, 從1.1 datExpr0 = t(A)替換成datExpr0 = t(A_sub)開始 鐺鐺鐺鐺鐺! 這次結果就好看多了把！雖然沒有 Tutorial 那樣標緻，但是，至少給了我繼續下去的勇氣。數據不好，就調高閾值把， 更具這條線，大概是要選9了 4. One-step NetWork net = blockwiseModules(datExpr, power = 9, TOMType = &quot;unsigned&quot;, minModuleSize = 30, reassignThreshold = 0, mergeCutHeight = 0.25, numericLabels = TRUE, pamRespectsDendro = FALSE, saveTOMs = TRUE, saveTOMFileBase = &quot;femaleMouseTOM&quot;, verbose = 3) 這一步等待時間和你電腦計算能力，基因數量成正相關 moduleLabels = net$colorsmoduleColors = labels2colors(net$colors)MEs = net$MEs;geneTree = net$dendrograms[[1]]## open a graphics windowsizeGrWindow(12, 9)## png('modules_tree.png',width=480, height=320)## Convert labels to colors for plottingmergedColors = labels2colors(net$colors)## Plot the dendrogram and the module colors underneathplotDendroAndColors(net$dendrograms[[1]], mergedColors[net$blockGenes[[1]]], &quot;Module colors&quot;, dendroLabels = FALSE, hang = 0.03, addGuide = TRUE, guideHang = 0.05)##dev.off() ummmm… 模塊似乎有點寬， 分的不均勻- - 感覺很爛的樣子。 要不再， 篩一下？ Modules 統計 library(ggplot2)library(reshape2)Color_TB = melt(table(labels2colors(net$colors)))Color_TB$Var1 = factor(Color_TB$Var1, levels = Color_TB$Var1[order(Color_TB$value,decreasing = T)])ggplot(Color_TB) + geom_bar(aes(x=Var1,y=value), stat = 'identity',fill=Color_TB$Var1)+ theme_light() +theme(axis.text.x = element_text(angle = 90,hjust=1)) 5. Traits nGenes = ncol(datExpr);nSamples = nrow(datExpr);## Recalculate MEs with color labelsMEs0 = moduleEigengenes(datExpr, moduleColors)$eigengenesMEs = orderMEs(MEs0)moduleTraitCor = cor(MEs, datTraits, use = &quot;p&quot;);moduleTraitPvalue = corPvalueStudent(moduleTraitCor, nSamples);sizeGrWindow(10,6)## Will display correlations and their p-values## png(&quot;T45_traits_heatmap.png&quot;,width=1000,height=600)textMatrix = paste(signif(moduleTraitCor, 2), &quot;\\n(&quot;, signif(moduleTraitPvalue, 1), &quot;)&quot;, sep = &quot;&quot;);dim(textMatrix) = dim(moduleTraitCor)par(mar = c(6, 8.5, 3, 3));## Display the correlation values within a heatmap plotlabeledHeatmap(Matrix = moduleTraitCor, xLabels = names(datTraits), yLabels = names(MEs), ySymbols = names(MEs), colorLabels = FALSE, colors = greenWhiteRed(50), textMatrix = textMatrix, setStdMargins = FALSE, cex.text = 0.5, zlim = c(-1,1), main = paste(&quot;Module-trait relationships&quot;)) ummm, 能看個大概就好2333.還是有點意思的 6. Focus on Weight weight = as.data.frame(datTraits$Weight)modNames = substring(names(MEs), 3)geneModuleMembership = as.data.frame(cor(datExpr, MEs, use = &quot;p&quot;));MMPvalue = as.data.frame(corPvalueStudent(as.matrix(geneModuleMembership), nSamples));names(geneModuleMembership) = paste(&quot;MM&quot;, modNames, sep=&quot;&quot;);names(MMPvalue) = paste(&quot;p.MM&quot;, modNames, sep=&quot;&quot;);geneTraitSignificance = as.data.frame(cor(datExpr, weight, use = &quot;p&quot;));GSPvalue = as.data.frame(corPvalueStudent(as.matrix(geneTraitSignificance), nSamples));names(geneTraitSignificance) = paste(&quot;GS.&quot;, names(weight), sep=&quot;&quot;);names(GSPvalue) = paste(&quot;p.GS.&quot;, names(weight), sep=&quot;&quot;);module = &quot;grey&quot;column = match(module, modNames);moduleGenes = moduleColors==module;sizeGrWindow(7, 7);## png(&quot;grey_weight.png&quot;)par(mfrow = c(1,1));verboseScatterplot(abs(geneModuleMembership[moduleGenes, column]), abs(geneTraitSignificance[moduleGenes, 1]), xlab = paste(&quot;Module Membership in&quot;, module, &quot;module&quot;), ylab = &quot;Gene significance for body weight&quot;, main = paste(&quot;Module membership vs. gene significance\\n&quot;), cex.main = 1.2, cex.lab = 1.2, cex.axis = 1.2, col = module) ummmm… 有點少， 哈哈哈， 才18個，數了一下。和tutorial 差好多呀 因爲是非模式物種，所以無法直接用tutorial給的方法做註釋。直接調到後面的可視化把。 7. NetWork Visualizing nGenes = ncol(datExpr)nSamples = nrow(datExpr)## Calculate topological overlap anew: this could be done more efficiently by saving the TOM## calculated during module detection, but let us do it again here.dissTOM = 1-TOMsimilarityFromExpr(datExpr, power = 9);## Transform dissTOM with a power to make moderately strong connections more visible in the heatmapplotTOM = dissTOM^7;## Set diagonal to NA for a nicer plotdiag(plotTOM) = NA;## Call the plot functionsizeGrWindow(9,9)TOMplot(plotTOM, geneTree, moduleColors, main = &quot;Network heatmap plot, all genes&quot;)nSelect = 400## For reproducibility, we set the random seedset.seed(10);select = sample(nGenes, size = nSelect);selectTOM = dissTOM[select, select];## There's no simple way of restricting a clustering tree to a subset of genes, so we must re-cluster.selectTree = hclust(as.dist(selectTOM), method = &quot;average&quot;)selectColors = moduleColors[select];## Open a graphical windowsizeGrWindow(9,9)## Taking the dissimilarity to a power, say 10, makes the plot more informative by effectively changing## the color palette; setting the diagonal to NA also improves the clarity of the plot##png('123.png')plotDiss = selectTOM^7;diag(plotDiss) = NA;TOMplot(plotDiss, selectTree, selectColors, main = &quot;Network heatmap plot, selected genes&quot;) ummm… 好像是內存爆了，直接退出。 試試不用radian看看失敗了- -放棄， 跳過把參考圖： MEs = moduleEigengenes(datExpr, moduleColors)$eigengenes## Isolate weight from the clinical traitsweight = as.data.frame(datTraits$Weight);names(weight) = &quot;weight&quot;## Add the weight to existing module eigengenesMET = orderMEs(cbind(MEs, weight))## Plot the relationships among the eigengenes and the traitsizeGrWindow(5,7.5);##png('T45_Tree_weight_module.png',width=400,height=600)par(cex = 0.9)plotEigengeneNetworks(MET, &quot;&quot;, marDendro = c(0,4,1,2), marHeatmap = c(3,4,1,2), cex.lab = 0.8, xLabelsAngle = 90) 這個圖還是可以畫的 8. 數據導出 modules = c(&quot;darkorange2&quot;, &quot;grey&quot;,&quot;lightcyan&quot;);inModule = is.finite(match(moduleColors, modules));for(color in modules){ write.table(colnames(t(net$colors[moduleColors==color])),paste(&quot;module_&quot;,color,'.list',sep=&quot;&quot;) ,row.names=F,quote=F,col.names=F)}probes = names(datExpr)## Recalculate topological overlap if neededTOM = TOMsimilarityFromExpr(datExpr, power = 9);## Read in the annotation fileannot = read.csv(file = &quot;GeneAnnotation.csv&quot;);## Select modules## Select module probesmodProbes = probes[inModule];modGenes = annot$gene_symbol[match(modProbes, annot$substanceBXH)];## Select the corresponding Topological OverlapmodTOM = TOM[inModule, inModule];dimnames(modTOM) = list(modProbes, modProbes)## Export the network into edge and node list files Cytoscape can readcyt = exportNetworkToCytoscape(modTOM, edgeFile = paste(&quot;CytoscapeInput-edges-&quot;, paste(modules, collapse=&quot;-&quot;), &quot;.txt&quot;, sep=&quot;&quot;), nodeFile = paste(&quot;CytoscapeInput-nodes-&quot;, paste(modules, collapse=&quot;-&quot;), &quot;.txt&quot;, sep=&quot;&quot;), weighted = TRUE, threshold = 0.02, nodeNames = modProbes, altNodeNames = modGenes, nodeAttr = moduleColors[inModule]); 9. 如果 softThread 還是取6 Modules 分佈 library(ggplot2)library(reshape2)library(patchwork)Color_TB = melt(table(labels2colors(net$colors)))Color_TB$Var1 = factor(Color_TB$Var1, levels = Color_TB$Var1[order(Color_TB$value,decreasing = T)])p&lt;- ggplot(Color_TB) + geom_bar(aes(x=Var1,y=value), stat = 'identity',fill=Color_TB$Var1)+ theme_light() +theme(axis.text.x = element_text(angle = 90,hjust=1))SplitBar(p,8500,10000,27000,0,c(1,4)) 畫圖函點擊SplitBar Optimal A1. Reduce Input Transcripts 這裏， 我們把閾值設定在 45(9*5) library(WGCNA)A &lt;- read.csv(&quot;All_isoform.TPM.matrix.anno.xls&quot;,sep='\\t')## rownames:sample; colnames: Transcriptsrow.names(A) = A[[2]]A = A[-(1:2)]Counts &lt;- read.csv(&quot;/media/ken/Data/Yan/RNA-seq/report/4.exprs//All_isoform.COUNT.matrix.anno.xls&quot;,sep='\\t')Counts$Sum = rowSums(Counts[-c(1:2)])Counts_sub = Counts[which(Counts$Sum&gt;45),]paste(round((nrow(Counts_sub)/nrow(Counts))*100,2),&quot;%&quot;,sep=&quot;&quot;)A_sub &lt;- A[match(Counts_sub[[2]],rownames(A)),]datExpr0 = t(A_sub)## Data filtergsg = goodSamplesGenes(datExpr0, verbose = 3);gsg$allOKif (!gsg$allOK){ # Optionally, print the gene and sample names that were removed: if (sum(!gsg$goodGenes)&gt;0) printFlush(paste(&quot;Removing genes:&quot;, paste(names(datExpr0)[!gsg$goodGenes], collapse = &quot;, &quot;))); if (sum(!gsg$goodSamples)&gt;0) printFlush(paste(&quot;Removing samples:&quot;, paste(rownames(datExpr0)[!gsg$goodSamples], collapse = &quot;, &quot;))); # Remove the offending genes and samples from the data: datExpr0 = datExpr0[gsg$goodSamples, gsg$goodGenes]} 剩下了&quot;32.96%&quot;的 Transcripts 接下來退回到1.2 ummmm, 好像還沒之前的好看了- -， 還是取9把，soft modules 29 個。 traits聚類： Cluster1 Cluster2 最亮的沒有上次那麼亮，= =相關係數有點低， 不高 modules 分佈情況: B. Remove low-hits &amp; Non-DEGs library(WGCNA)A &lt;- read.csv(&quot;All_isoform.TPM.matrix.anno.xls&quot;,sep='\\t')## rownames:sample; colnames: Transcriptsrow.names(A) = A[[2]]A = A[-(1:2)]Counts &lt;- read.csv(&quot;/media/ken/Data/Yan/RNA-seq/report/4.exprs//All_isoform.COUNT.matrix.anno.xls&quot;,sep='\\t')Counts$Sum = rowSums(Counts[-c(1:2)])Counts_sub = Counts[which(Counts$Sum&gt;9),]paste(round((nrow(Counts_sub)/nrow(Counts))*100,2),&quot;%&quot;,sep=&quot;&quot;)A_sub &lt;- A[match(Counts_sub[[2]],rownames(A)),]DEG1 &lt;- read.table(&quot;../edgeR_Intest/diffExpr.P1e-3_C2.matrix&quot;,head=T)DEG2 &lt;- read.table(&quot;../edgeR_Liver/diffExpr.P1e-3_C2.matrix&quot;,head=T)DEG3 &lt;- read.table(&quot;../edgeR_Muscle/diffExpr.P1e-3_C2.matrix&quot;,head=T)List = as.character(unique(DEG1[[1]], DEG2[[1]], DEG3[[1]]))A_DEG = na.omit(A_sub[match(row.names(A_sub), List),])datExpr0 = t(A_DEG)## Data filtergsg = goodSamplesGenes(datExpr0, verbose = 3);gsg$allOKif (!gsg$allOK){ # Optionally, print the gene and sample names that were removed: if (sum(!gsg$goodGenes)&gt;0) printFlush(paste(&quot;Removing genes:&quot;, paste(names(datExpr0)[!gsg$goodGenes], collapse = &quot;, &quot;))); if (sum(!gsg$goodSamples)&gt;0) printFlush(paste(&quot;Removing samples:&quot;, paste(rownames(datExpr0)[!gsg$goodSamples], collapse = &quot;, &quot;))); # Remove the offending genes and samples from the data: datExpr0 = datExpr0[gsg$goodSamples, gsg$goodGenes]} 跳回 1.2 ummmm, 這麼篩完以後， 剩下了1105個Transcripts 。。。 聚類 Soft圖 這次聚類結果，就很不一樣了 不過sortpower這個圖，基本還是和前文一樣沒怎麼變。取0.9以上的話， 又得取10了 還是去9吧。 1000個，秒算完。先看看分組頻率 和樹圖這個圖，我就覺得，看着舒服多了- -唉 聚類 Soft圖 第一次畫出Tomplot，激動 這個聚類，相關性都不太高呀 相關性確實是太低了。 我們看一下這1000基因的表達趨勢把。 library(ggplotify)A_DEG$Module = labels2colors(net$colors)A_DEG$ID = row.names(A_DEG)TB = melt(A_DEG,id.vars = c(&quot;ID&quot;,&quot;Module&quot;))TB$variable = factor(TB$variable,levels=sort(as.character(unique((TB$variable)))))TB$ID = factor(TB$ID, levels = row.names(A_DEG)[order(A_DEG$Module)])p2 &lt;- ggplot( TB, aes( variable, ID)) + theme(panel.grid.major = element_blank())+ theme(legend.key=element_blank(), axis.text.y = element_blank(), axis.title=element_blank(),axis.ticks.y=element_blank(), axis.text.x=element_text(angle=90,hjust=1))+ geom_tile(aes(fill=log(1+value)))+ scale_fill_gradient2(low=&quot;steelblue&quot;,mid=&quot;white&quot;,high=&quot;red&quot;,midpoint =1)A_DEG$ID = factor(A_DEG$ID, levels = row.names(A_DEG)[order(A_DEG$Module)])p1 &lt;-ggplot(A_DEG[10:11], aes( x=&quot;Module&quot;, y=ID)) + theme(panel.grid.major = element_blank())+ theme(axis.text.y = element_blank(), legend.position = 'left', axis.title=element_blank(),axis.ticks.y=element_blank(), axis.text.x=element_text(angle=90,hjust=1))+ geom_tile(fill=A_DEG$Module)p1+p2 + plot_layout(design = 'ABBBBBBBBBB') 熱圖還是，可以的，就是配色有點麻煩- - 只管來看， 聚類效果還是OK的把。不過correlation值太低了 = = 有什麼之後再去深究把。 添加樹打包兩個函數 PLOT2 &lt;- function(dendr){ ggplot() + geom_segment(data=segment(dendr), aes(x=x, y=y, xend=xend, yend=yend)) + geom_text(data=label(dendr), aes(x, y, label=label, hjust=0), size=3) + coord_flip() + scale_y_reverse(expand=c(0.2, 0)) + theme(axis.line.y=element_blank(), axis.ticks.y=element_blank(), axis.text.y=element_blank(), axis.title.y=element_blank(), panel.background=element_rect(fill=&quot;white&quot;), panel.grid=element_blank())}LS_judg&lt;- function(TB){ if (TB['x'] == TB['xend']){ R = 'v' }else{ R = 'h' } return(R)}TreePlot &lt;- function(dendr, Width_tree){ dendr$labels$x = Width_tree[dendr$labels$x] dendr$segments = dendr$segments[order(dendr$segments$x),] # 做個list List = c() for(i in c(1:length(Width_tree))){ List = c(List, which(dendr$segments$x==i)) } # 調整豎線 for( i in c(1:length(dendr$labels$label))){ Dif_tmp = Width_tree[i]- dendr$segments$x[List[i]] dendr$segments$x[List[i]:nrow(dendr$segments)] = dendr$segments$x[List[i]:nrow(dendr$segments)]+Dif_tmp dendr$segments$xend[List[i]:nrow(dendr$segments)] = dendr$segments$xend[List[i]:nrow(dendr$segments)]+Dif_tmp } # 刪除添加新的橫線 dendr$segments = dendr$segments[dendr$segments$x == dendr$segments$xend,] Y_list = dendr$segments$y[duplicated(dendr$segments$y)] for(i in Y_list){ tmp = (dendr$segments$x[dendr$segments$y == i]) dendr$segments = rbind(dendr$segments, data.frame(x=tmp[1],y=i,xend=tmp[2],yend=i)) } Seg = dendr$segments for( i in c(nrow(dendr$segments):1)){ if(LS_judg(dendr$segments[i,]) == 'h'){ tmpy = dendr$segments[i,]$y tmpTB = Seg[Seg$yend== tmpy,] for( ii in c(1:nrow(tmpTB))){ if(LS_judg(tmpTB[ii,]) == 'v'){ Num = rownames(tmpTB[1,]) dendr$segments[match(Num, row.names(dendr$segments)),][c(1,3)] = sum(Seg[i,c('x','xend')])/2 } } } } # 重画横线： dendr$segments = dendr$segments[dendr$segments$x == dendr$segments$xend,] Y_list = dendr$segments$y[duplicated(dendr$segments$y)] for(i in Y_list){ tmp = (dendr$segments$x[dendr$segments$y == i]) dendr$segments = rbind(dendr$segments, data.frame(x=tmp[1],y=i,xend=tmp[2],yend=i)) } return(dendr)} 画图 library(ggplot2)library(ggdendro)library(reshape2)library(patchwork)library(RColorBrewer)colorRampPalette(rev(brewer.pal(n = 7,name = &quot;RdYlBu&quot;))) -&gt; ccTB_color = (data.frame(net$colors,color=labels2colors(net$colors)))A_DEG$ID = row.names(A_DEG)A_DEG$Module = TB_color$color[match(row.names(A_DEG), row.names(TB_color))]## Samples dendrogramhc &lt;- hclust(dist(t(A_DEG[1:9])))dendr_head &lt;- dendro_data(hc, type=&quot;rectangle&quot;) # convert for ggplot## Module dendrogramhc &lt;- hclust(dist(t(MEs)))dendr &lt;- dendro_data(hc, type=&quot;rectangle&quot;) # convert for ggplot### 1. order and listModule_list = as.character(dendr$labels$label[order(dendr$labels$x)])Module_or = c()for( i in strsplit(Module_list,'ME')){ Module_or = c(Module_or, i[2])}### 2. Axis locationTB_mbar = data.frame(table(A_DEG$Module))TB_mbar = TB_mbar = data.frame(table(A_DEG$Module))TB_mbar$hei = TB_mbar$Freq[1]/2for(i in c(2:nrow(TB_mbar))){ TB_mbar$hei[i] =sum(TB_mbar$Freq[1:i-1])+ (TB_mbar$Freq[i]/2)}Width_tree = TB_mbar$heiAA &lt;- TreePlot(dendr, Width_tree)## Module Bar### acquiring module list## order moduleA_DEG$Module = factor(A_DEG$Module, levels = Module_or)## order IDA_DEG$ID = factor(A_DEG$ID, levels = row.names(A_DEG)[order(A_DEG$Module)])## Transcripts Heatmapprimary_data = as.matrix(A_DEG[1:9])##transformationsdata = log2(primary_data+1)data = as.matrix(data) # convert to matrix## Centering rowsdata = data.frame(t(scale(t(data), scale=F)))TB = melt(cbind(data,A_DEG[c(&quot;ID&quot;,&quot;Module&quot;)]),id.vars = c(&quot;ID&quot;,&quot;Module&quot;))TB$ID = factor(TB$ID, levels = row.names(A_DEG)[order(A_DEG$Module)])TB$variable = factor(TB$variable, levels =levels(dendr_head$labels$label))p0 &lt;- ggplot() + geom_segment(data=segment(AA), aes(x=x, y=y, xend=xend, yend=yend)) + geom_text(data=label(AA), aes(x, y, label=label, hjust=0), size=3) + coord_flip() + scale_y_reverse(expand=c(0.7, 0)) + theme(axis.line.y=element_blank(), axis.ticks.y=element_blank(), axis.text.y=element_blank(), axis.title =element_blank(), panel.background=element_rect(fill=&quot;white&quot;), panel.grid=element_blank())p1 &lt;-ggplot(A_DEG[10:11], aes( x=&quot;Module&quot;, y=ID)) + theme(panel.grid.major = element_blank())+ theme(axis.text.y = element_blank(), legend.position = 'left', axis.title=element_blank(), axis.ticks=element_blank(), panel.background=element_rect(fill=&quot;white&quot;), axis.text.x=element_text(angle=90,hjust=1))+ geom_tile(fill=A_DEG$Module)p2 &lt;- ggplot( TB, aes( variable, ID)) + theme(panel.grid.major = element_blank())+ theme(legend.key=element_blank(), axis.text.y = element_blank(), axis.title=element_blank(),axis.ticks.y=element_blank(), axis.text.x=element_text(angle=90,hjust=1))+ geom_tile(aes(fill=value))+ scale_fill_gradientn(colors=cc(100))p4 &lt;- ggplot() + geom_segment(data=segment(dendr_head), aes(x=x, y=y, xend=xend, yend=yend)) + scale_y_reverse(expand=c(0, 0)) + theme(axis.line.y=element_blank(), axis.ticks.x=element_blank(), axis.text.x=element_blank(), axis.title=element_blank(), panel.background=element_rect(fill=&quot;white&quot;), panel.grid=element_blank())layout_P &lt;- &quot; AAAABCCCCCC AAAABCCCCCC AAAABCCCCCC AAAABCCCCCC AAAABCCCCCC AAAABCCCCCC #####DDDDDD &quot;p0 + p1 + p2 + p4 + plot_layout(design = layout_P)","link":"/2020/06/10/R/WGCNA/"},{"title":"XGBoost (out of date)","text":"XGBoost (out of date) library(xgboost)library(tidyverse)library(modelr) a &lt;- read_csv(&quot;melb_data.csv&quot;) a &lt;- na.omit(a)### Dataa &lt;- select(TR,-starts_with(&quot;Address&quot;))Suburb &lt;- model.matrix(~Suburb-1,a)Type &lt;- model.matrix(~Type-1,a)Method &lt;- model.matrix(~Method-1,a)SellerG &lt;- model.matrix(~SellerG-1,a)CouncilArea &lt;- model.matrix(~CouncilArea-1,a)Regionname &lt;- model.matrix(~Regionname-1,a)aa &lt;- data.frame(a,Suburb=Suburb, Type=Type,Method=Method,SellerG=SellerG, CouncilArea=CouncilArea,Regionname=Regionname)### Split data to tow groupssplitData &lt;- resample_partition(aa, c(test = 0.3, train = 0.7)) TR &lt;- data.frame(splitData$train) TT &lt;- data.frame(splitData$test)##orset.seed(1234)diseaseInfo &lt;- diseaseInfo[sample(1:nrow(diseaseInfo)), ]##random arrage the data and grep apart of it to different groups### RM predict target and build target list TR_Labels &lt;- TR$Price TT_Labels &lt;- TT$Price TR &lt;- select(TR,-starts_with(&quot;Price&quot;)) TT &lt;- select(TT,-starts_with(&quot;Price&quot;)) TR &lt;- data.matrix(TR) TT &lt;- data.matrix(TT)dtrain &lt;- xgb.DMatrix(data = TR, label= TR_Labels)dtest &lt;- xgb.DMatrix(data = TT, label= TT_Labels)TB &lt;- data.frame( mean=m)model &lt;- xgboost(data = dtrain,nround = 3000) pred &lt;- predict(model, dtest) mean &lt;- (pred-TT_Labels)/TT_Labels mean[which(mean&lt;0)] &lt;- mean[which(mean&lt;0)]*(-1) m &lt;- mean(mean)mean(as.numeric(pred &gt; 0.5) != TT_Labels)predict(model,dtest)##for(i in 1){## model &lt;- xgboost(data = dtrain,nround = i)## pred &lt;- predict(model, dtest)## mean &lt;- (pred-TT_Labels)/TT_Labels## mean[which(mean&lt;0)] &lt;- mean[which(mean&lt;0)]*(-1)## m &lt;- mean(mean)## TB &lt;- rbind(TB,m)## }library(xgboost)library(tidyverse)diseaseInfo &lt;- read_csv(&quot;Outbreak_240817.csv&quot;)set.seed(1234)diseaseInfo &lt;- diseaseInfo[sample(1:nrow(diseaseInfo)), ]head(diseaseInfo)diseaseInfo_humansRemoved &lt;- diseaseInfo %&gt;% select(-starts_with(&quot;human&quot;))diseaseLabels &lt;- diseaseInfo %&gt;% select(humansAffected) %&gt;% # get the column with the # of humans affected is.na() %&gt;% # is it NA? magrittr::not() # switch TRUE and FALSE (using function from the magrittr package)## check out the first few lineshead(diseaseLabels) # of our target variablehead(diseaseInfo$humansAffected) # of the original columndiseaseInfo_numeric &lt;- diseaseInfo_humansRemoved %&gt;% select(-Id) %&gt;% # the case id shouldn't contain useful information select(-c(longitude, latitude)) %&gt;% # location data is also in country data select_if(is.numeric) # select remaining numeric columns## make sure that our dataframe is all numericstr(diseaseInfo_numeric)model.matrix(~country-1,head(diseaseInfo))region &lt;- model.matrix(~country-1,diseaseInfo)head(diseaseInfo$speciesDescription)diseaseInfo_numeric$is_domestic &lt;- str_detect(diseaseInfo$speciesDescription, &quot;domestic&quot;)speciesList &lt;- diseaseInfo$speciesDescription %&gt;% str_replace(&quot;[[:punct:]]&quot;, &quot;&quot;) %&gt;% # remove punctuation (some rows have parentheses) str_extract(&quot;[a-z]*$&quot;) # extract the least word in each row## convert our list into a dataframe...speciesList &lt;- tibble(species = speciesList)## and convert to a matrix using 1 hot encodingoptions(na.action='na.pass') # don't drop NA values!species &lt;- model.matrix(~species-1,speciesList)diseaseInfo_numeric &lt;- cbind(diseaseInfo_numeric, region, species)diseaseInfo_matrix &lt;- data.matrix(diseaseInfo_numeric)## get the numb 70/30 training test splitnumberOfTrainingSamples &lt;- round(length(diseaseLabels) * .7)## training datatrain_data &lt;- diseaseInfo_matrix[1:numberOfTrainingSamples,]train_labels &lt;- diseaseLabels[1:numberOfTrainingSamples]## testing datatest_data &lt;- diseaseInfo_matrix[-(1:numberOfTrainingSamples),]test_labels &lt;- diseaseLabels[-(1:numberOfTrainingSamples)]dtrain &lt;- xgb.DMatrix(data = train_data, label= train_labels)dtest &lt;- xgb.DMatrix(data = test_data, label= test_labels)model &lt;- xgboost(data = dtrain, # the data nround = 2, # max number of boosting iterations objective = &quot;binary:logistic&quot;) # the objective functionpred &lt;- predict(model, dtest)## get &amp; print the classification errorerr &lt;- mean(as.numeric(pred &gt; 0.5) != test_labels)print(paste(&quot;test-error=&quot;, err))model_tuned &lt;- xgboost(data = dtrain, # the data max.depth = 3, # the maximum depth of each decision tree nround = 2, # max number of boosting iterations objective = &quot;binary:logistic&quot;) # the objective function## generate predictions for our held-out testing datapred &lt;- predict(model_tuned, dtest)## get &amp; print the classification errorerr &lt;- mean(as.numeric(pred &gt; 0.5) != test_labels)print(paste(&quot;test-error=&quot;, err))## get the number of negative &amp; positive cases in our datanegative_cases &lt;- sum(train_labels == FALSE)postive_cases &lt;- sum(train_labels == TRUE)## train a model using our training datamodel_tuned &lt;- xgboost(data = dtrain, # the data max.depth = 3, # the maximum depth of each decision tree nround = 10, # number of boosting rounds early_stopping_rounds = 3, # if we dont see an improvement in this many rounds, stop objective = &quot;binary:logistic&quot;, # the objective function scale_pos_weight = negative_cases/postive_cases) # control for imbalanced classes## generate predictions for our held-out testing datapred &lt;- predict(model_tuned, dtest)## get &amp; print the classification errorerr &lt;- mean(as.numeric(pred &gt; 0.5) != test_labels)print(paste(&quot;test-error=&quot;, err))## train a model using our training datamodel_tuned &lt;- xgboost(data = dtrain, # the data max.depth = 3, # the maximum depth of each decision tree nround = 10, # number of boosting rounds early_stopping_rounds = 3, # if we dont see an improvement in this many rounds, stop objective = &quot;binary:logistic&quot;, # the objective function scale_pos_weight = negative_cases/postive_cases, # control for imbalanced classes gamma = 1) # add a regularization term## generate predictions for our held-out testing datapred &lt;- predict(model_tuned, dtest)## get &amp; print the classification errorerr &lt;- mean(as.numeric(pred &gt; 0.5) != test_labels)print(paste(&quot;test-error=&quot;, err))xgb.plot.multi.trees(feature_names = names(diseaseInfo_matrix), model = model)","link":"/2020/01/22/R/XGBoost/"},{"title":"WGCNA Tutorial 1","text":"WGCNA Tutorial 1 raw tutorial: Peter Data: Female data Male data 1. Data Cleaning ## Load the WGCNA packagelibrary(WGCNA);## The following setting is important, do not omit.options(stringsAsFactors = FALSE);##Read in the female liver data setfemData = read.csv(&quot;LiverFemale3600.csv&quot;);datExpr0 = as.data.frame(t(femData[, -c(1:8)]));names(datExpr0) = femData$substanceBXH;rownames(datExpr0) = names(femData)[-c(1:8)]; 1.1 Checking data Checking data for excessive missing values and identification of outlier microarray samples gsg = goodSamplesGenes(datExpr0, verbose = 3);gsg$allOKif (!gsg$allOK){ # Optionally, print the gene and sample names that were removed: if (sum(!gsg$goodGenes)&gt;0) printFlush(paste(&quot;Removing genes:&quot;, paste(names(datExpr0)[!gsg$goodGenes], collapse = &quot;, &quot;))); if (sum(!gsg$goodSamples)&gt;0) printFlush(paste(&quot;Removing samples:&quot;, paste(rownames(datExpr0)[!gsg$goodSamples], collapse = &quot;, &quot;))); # Remove the offending genes and samples from the data: datExpr0 = datExpr0[gsg$goodSamples, gsg$goodGenes]} 1.2 Cluster the samples sampleTree = hclust(dist(datExpr0), method = &quot;average&quot;);## Plot the sample tree: Open a graphic output window of size 12 by 9 inches## The user should change the dimensions if the window is too large or too small.sizeGrWindow(12,9)##png(file = &quot;sampleClustering.png&quot;)par(cex = 0.6);par(mar = c(0,4,2,0))plot(sampleTree, main = &quot;Sample clustering to detect outliers&quot;, sub=&quot;&quot;, xlab=&quot;&quot;, cex.lab = 1.5, cex.axis = 1.5, cex.main = 2)## Plot a line to show the cutabline(h = 15, col = &quot;red&quot;) It appears there is one outlier (sample F2_221, see Fig. 1). One can remove it by hand, or use an automatic approach. Choose a height cut that will remove the offending sample, say 15 (the red line in the plot), and use a branch cut at that height. 1.3 Remove the abnormal sample ## Determine cluster under the lineclust = cutreeStatic(sampleTree, cutHeight = 15, minSize = 10)table(clust)## clust 1 contains the samples we want to keep.keepSamples = (clust==1)datExpr = datExpr0[keepSamples, ]nGenes = ncol(datExpr)nSamples = nrow(datExpr) 1.4 Loading Clinical Data traitData = read.csv(&quot;ClinicalTraits.csv&quot;);dim(traitData)names(traitData)## remove columns that hold information we do not need.allTraits = traitData[, -c(31, 16)];allTraits = allTraits[, c(2, 11:36) ];dim(allTraits)names(allTraits)## Form a data frame analogous to expression data that will hold the clinical traits.femaleSamples = rownames(datExpr);traitRows = match(femaleSamples, allTraits$Mice);datTraits = allTraits[traitRows, -1];rownames(datTraits) = allTraits[traitRows, 1];collectGarbage()## Re-cluster samplessampleTree2 = hclust(dist(datExpr), method = &quot;average&quot;)## Convert traits to a color representation: white means low, red means high, grey means missing entrytraitColors = numbers2colors(datTraits, signed = FALSE);## Plot the sample dendrogram and the colors underneath.## png(&quot;traits_heatmap.png&quot;)plotDendroAndColors(sampleTree2, traitColors, groupLabels = names(datTraits), main = &quot;Sample dendrogram and trait heatmap&quot;) 2. Network construction and module detection Automatic one-step detection 2.1 Pick soft-thresdholding power ## Choose a set of soft-thresholding powerspowers = c(c(1:10), seq(from = 12, to=20, by=2))## Call the network topology analysis functionsft = pickSoftThreshold(datExpr, powerVector = powers, verbose = 5)## Plot the results:sizeGrWindow(9, 5)## Scale-free topology fit index as a function of the soft-thresholding power## png(&quot;Soft_th.png&quot;,width=500,height=300)cex1 = 0.9;par(mfrow = c(1,2));plot(sft$fitIndices[,1], -sign(sft$fitIndices[,3])*sft$fitIndices[,2], xlab=&quot;Soft Threshold (power)&quot;,ylab=&quot;Scale Free Topology Model Fit,signed R^2&quot;,type=&quot;n&quot;, main = paste(&quot;Scale independence&quot;));text(sft$fitIndices[,1], -sign(sft$fitIndices[,3])*sft$fitIndices[,2], labels=powers,cex=cex1,col=&quot;red&quot;);## this line corresponds to using an R^2 cut-off of habline(h=0.90,col=&quot;red&quot;)## Mean connectivity as a function of the soft-thresholding powerplot(sft$fitIndices[,1], sft$fitIndices[,5], xlab=&quot;Soft Threshold (power)&quot;,ylab=&quot;Mean Connectivity&quot;, type=&quot;n&quot;, main = paste(&quot;Mean connectivity&quot;))text(sft$fitIndices[,1], sft$fitIndices[,5], labels=powers, cex=cex1,col=&quot;red&quot;) 2.2 One-step network construction and module detection net = blockwiseModules(datExpr, power = 6, TOMType = &quot;unsigned&quot;, minModuleSize = 30, reassignThreshold = 0, mergeCutHeight = 0.25, numericLabels = TRUE, pamRespectsDendro = FALSE, saveTOMs = TRUE, saveTOMFileBase = &quot;femaleMouseTOM&quot;, verbose = 3)## View modules## table(net$colors)moduleLabels = net$colorsmoduleColors = labels2colors(net$colors)MEs = net$MEs;geneTree = net$dendrograms[[1]]## open a graphics windowsizeGrWindow(12, 9)## png('123.png',width=480, height=320)## Convert labels to colors for plottingmergedColors = labels2colors(net$colors)## Plot the dendrogram and the module colors underneathplotDendroAndColors(net$dendrograms[[1]], mergedColors[net$blockGenes[[1]]], &quot;Module colors&quot;, dendroLabels = FALSE, hang = 0.03, addGuide = TRUE, guideHang = 0.05) 3. Relating modules to external information and identifying important genes 3.1 Clinical Traits ## Define numbers of genes and samplesnGenes = ncol(datExpr);nSamples = nrow(datExpr);## Recalculate MEs with color labelsMEs0 = moduleEigengenes(datExpr, moduleColors)$eigengenesMEs = orderMEs(MEs0)moduleTraitCor = cor(MEs, datTraits, use = &quot;p&quot;);moduleTraitPvalue = corPvalueStudent(moduleTraitCor, nSamples);sizeGrWindow(10,6)## Will display correlations and their p-values## png(&quot;1234.png&quot;,width=1000,height=600)textMatrix = paste(signif(moduleTraitCor, 2), &quot;\\n(&quot;, signif(moduleTraitPvalue, 1), &quot;)&quot;, sep = &quot;&quot;);dim(textMatrix) = dim(moduleTraitCor)par(mar = c(6, 8.5, 3, 3));## Display the correlation values within a heatmap plotlabeledHeatmap(Matrix = moduleTraitCor, xLabels = names(datTraits), yLabels = names(MEs), ySymbols = names(MEs), colorLabels = FALSE, colors = greenWhiteRed(50), textMatrix = textMatrix, setStdMargins = FALSE, cex.text = 0.5, zlim = c(-1,1), main = paste(&quot;Module-trait relationships&quot;)) 3.2 Genes and Trait ## Define variable weight containing the weight column of datTraitweight = as.data.frame(datTraits$weight_g);names(weight) = &quot;weight&quot;## names (colors) of the modulesmodNames = substring(names(MEs), 3)geneModuleMembership = as.data.frame(cor(datExpr, MEs, use = &quot;p&quot;));MMPvalue = as.data.frame(corPvalueStudent(as.matrix(geneModuleMembership), nSamples));names(geneModuleMembership) = paste(&quot;MM&quot;, modNames, sep=&quot;&quot;);names(MMPvalue) = paste(&quot;p.MM&quot;, modNames, sep=&quot;&quot;);geneTraitSignificance = as.data.frame(cor(datExpr, weight, use = &quot;p&quot;));GSPvalue = as.data.frame(corPvalueStudent(as.matrix(geneTraitSignificance), nSamples));names(geneTraitSignificance) = paste(&quot;GS.&quot;, names(weight), sep=&quot;&quot;);names(GSPvalue) = paste(&quot;p.GS.&quot;, names(weight), sep=&quot;&quot;);module = &quot;brown&quot;column = match(module, modNames);moduleGenes = moduleColors==module;sizeGrWindow(7, 7);## png(&quot;1234.png&quot;)par(mfrow = c(1,1));verboseScatterplot(abs(geneModuleMembership[moduleGenes, column]), abs(geneTraitSignificance[moduleGenes, 1]), xlab = paste(&quot;Module Membership in&quot;, module, &quot;module&quot;), ylab = &quot;Gene significance for body weight&quot;, main = paste(&quot;Module membership vs. gene significance\\n&quot;), cex.main = 1.2, cex.lab = 1.2, cex.axis = 1.2, col = module) annot = read.csv(file = &quot;GeneAnnotation.csv&quot;);dim(annot)names(annot)probes = names(datExpr)probes2annot = match(probes, annot$substanceBXH)## The following is the number or probes without annotation:sum(is.na(probes2annot))## Should return 0.## Create the starting data framegeneInfo0 = data.frame(substanceBXH = probes, geneSymbol = annot$gene_symbol[probes2annot], LocusLinkID = annot$LocusLinkID[probes2annot], moduleColor = moduleColors, geneTraitSignificance, GSPvalue)## Order modules by their significance for weightmodOrder = order(-abs(cor(MEs, weight, use = &quot;p&quot;)));## Add module membership information in the chosen orderfor (mod in 1:ncol(geneModuleMembership)){ oldNames = names(geneInfo0) geneInfo0 = data.frame(geneInfo0, geneModuleMembership[, modOrder[mod]], MMPvalue[, modOrder[mod]]); names(geneInfo0) = c(oldNames, paste(&quot;MM.&quot;, modNames[modOrder[mod]], sep=&quot;&quot;), paste(&quot;p.MM.&quot;, modNames[modOrder[mod]], sep=&quot;&quot;))}## Order the genes in the geneInfo variable first by module color, then by geneTraitSignificancegeneOrder = order(geneInfo0$moduleColor, -abs(geneInfo0$GS.weight));geneInfo = geneInfo0[geneOrder, ] 4. GO Enrichment of Modules ## Read in the probe annotationannot = read.csv(file = &quot;GeneAnnotation.csv&quot;);## Match probes in the data set to the probe IDs in the annotation fileprobes = names(datExpr)probes2annot = match(probes, annot$substanceBXH)## Get the corresponding Locuis Link IDsallLLIDs = annot$LocusLinkID[probes2annot];## $ Choose interesting modulesintModules = c(&quot;brown&quot;, &quot;red&quot;, &quot;salmon&quot;)for (module in intModules){ # Select module probes modGenes = (moduleColors==module) # Get their entrez ID codes modLLIDs = allLLIDs[modGenes]; # Write them into a file fileName = paste(&quot;LocusLinkIDs-&quot;, module, &quot;.txt&quot;, sep=&quot;&quot;); write.table(as.data.frame(modLLIDs), file = fileName, row.names = FALSE, col.names = FALSE)}## As background in the enrichment analysis, we will use all probes in the analysis.fileName = paste(&quot;LocusLinkIDs-all.txt&quot;, sep=&quot;&quot;);write.table(as.data.frame(allLLIDs), file = fileName, row.names = FALSE, col.names = FALSE)GOenr = GOenrichmentAnalysis(moduleColors, allLLIDs, organism = &quot;mouse&quot;, nBestP = 10);tab = GOenr$bestPTerms[[4]]$enrichmentwrite.table(tab, file = &quot;GOEnrichmentTable.csv&quot;, sep = &quot;,&quot;, quote = TRUE, row.names = FALSE)keepCols = c(1, 2, 5, 6, 7, 12, 13);screenTab = tab[, keepCols];## Round the numeric columns to 2 decimal places:numCols = c(3, 4);screenTab[, numCols] = signif(apply(screenTab[, numCols], 2, as.numeric), 2)## Truncate the the term name to at most 40 charactersscreenTab[, 7] = substring(screenTab[, 7], 1, 40)## Shorten the column names:colnames(screenTab) = c(&quot;module&quot;, &quot;size&quot;, &quot;p-val&quot;, &quot;Bonf&quot;, &quot;nInTerm&quot;, &quot;ont&quot;, &quot;term name&quot;);rownames(screenTab) = NULL;## Set the width of R's output. The reader should play with this number to obtain satisfactory output.options(width=95)## Finally, display the enrichment table:screenTab module size p-val Bonf nInTerm ont term name1 black 166 3.9e-04 1.0e+00 4 BP dopamine transport2 black 166 6.5e-04 1.0e+00 5 BP mRNA transport3 black 166 8.0e-04 1.0e+00 6 BP RNA transport4 black 166 8.0e-04 1.0e+00 13 MF receptor ligand activity... 5. Visualization 5.1 NetWork Visualization nGenes = ncol(datExpr)nSamples = nrow(datExpr)## Calculate topological overlap anew: this could be done more efficiently by saving the TOM## calculated during module detection, but let us do it again here.dissTOM = 1-TOMsimilarityFromExpr(datExpr, power = 6);## Transform dissTOM with a power to make moderately strong connections more visible in the heatmapplotTOM = dissTOM^7;## Set diagonal to NA for a nicer plotdiag(plotTOM) = NA;## Call the plot functionsizeGrWindow(9,9)TOMplot(plotTOM, geneTree, moduleColors, main = &quot;Network heatmap plot, all genes&quot;)nSelect = 400## For reproducibility, we set the random seedset.seed(10);select = sample(nGenes, size = nSelect);selectTOM = dissTOM[select, select];## There's no simple way of restricting a clustering tree to a subset of genes, so we must re-cluster.selectTree = hclust(as.dist(selectTOM), method = &quot;average&quot;)selectColors = moduleColors[select];## Open a graphical windowsizeGrWindow(9,9)## Taking the dissimilarity to a power, say 10, makes the plot more informative by effectively changing## the color palette; setting the diagonal to NA also improves the clarity of the plot##png('123.png')plotDiss = selectTOM^7;diag(plotDiss) = NA;TOMplot(plotDiss, selectTree, selectColors, main = &quot;Network heatmap plot, selected genes&quot;) 5.2 Visualizing the network of eigengenes ## Recalculate module eigengenesMEs = moduleEigengenes(datExpr, moduleColors)$eigengenes## Isolate weight from the clinical traitsweight = as.data.frame(datTraits$weight_g);names(weight) = &quot;weight&quot;## Add the weight to existing module eigengenesMET = orderMEs(cbind(MEs, weight))## Plot the relationships among the eigengenes and the traitsizeGrWindow(5,7.5);##png('123.png',width=400,height=600)par(cex = 0.9)plotEigengeneNetworks(MET, &quot;&quot;, marDendro = c(0,4,1,2), marHeatmap = c(3,4,1,2), cex.lab = 0.8, xLabelsAngle= 90)## Plot the dendrogram##sizeGrWindow(6,6);##par(cex = 1.0)##plotEigengeneNetworks(MET, &quot;Eigengene dendrogram&quot;, marDendro = c(0,4,2,0),## plotHeatmaps = FALSE)## Plot the heatmap matrix (note: this plot will overwrite the dendrogram plot)##par(cex = 1.0)##plotEigengeneNetworks(MET, &quot;Eigengene adjacency heatmap&quot;, marHeatmap = c(3,4,2,2),## plotDendrograms = FALSE, xLabelsAngle = 90) 6. Export of networks 6.1 Exporting to VisANT ## Recalculate topological overlapTOM = TOMsimilarityFromExpr(datExpr, power = 6);## Read in the annotation fileannot = read.csv(file = &quot;GeneAnnotation.csv&quot;);## Select modulemodule = &quot;brown&quot;;## Select module probesprobes = names(datExpr)inModule = (moduleColors==module);modProbes = probes[inModule];## Select the corresponding Topological OverlapmodTOM = TOM[inModule, inModule];dimnames(modTOM) = list(modProbes, modProbes)## Export the network into an edge list file VisANT can readvis = exportNetworkToVisANT(modTOM, file = paste(&quot;VisANTInput-&quot;, module, &quot;.txt&quot;, sep=&quot;&quot;), weighted = TRUE, threshold = 0, probeToGene = data.frame(annot$substanceBXH, annot$gene_symbol) )nTop = 30;IMConn = softConnectivity(datExpr[, modProbes]);top = (rank(-IMConn) &lt;= nTop)vis = exportNetworkToVisANT(modTOM[top, top], file = paste(&quot;VisANTInput-&quot;, module, &quot;-top30.txt&quot;, sep=&quot;&quot;), weighted = TRUE, threshold = 0, probeToGene = data.frame(annot$substanceBXH, annot$gene_symbol) ) 6.2 Exporting to Cytoscape ## Recalculate topological overlap if neededTOM = TOMsimilarityFromExpr(datExpr, power = 6);## Read in the annotation fileannot = read.csv(file = &quot;GeneAnnotation.csv&quot;);## Select modulesmodules = c(&quot;brown&quot;, &quot;red&quot;);## Select module probesprobes = names(datExpr)inModule = is.finite(match(moduleColors, modules));modProbes = probes[inModule];modGenes = annot$gene_symbol[match(modProbes, annot$substanceBXH)];## Select the corresponding Topological OverlapmodTOM = TOM[inModule, inModule];dimnames(modTOM) = list(modProbes, modProbes)## Export the network into edge and node list files Cytoscape can readcyt = exportNetworkToCytoscape(modTOM, edgeFile = paste(&quot;CytoscapeInput-edges-&quot;, paste(modules, collapse=&quot;-&quot;), &quot;.txt&quot;, sep=&quot;&quot;), nodeFile = paste(&quot;CytoscapeInput-nodes-&quot;, paste(modules, collapse=&quot;-&quot;), &quot;.txt&quot;, sep=&quot;&quot;), weighted = TRUE, threshold = 0.02, nodeNames = modProbes, altNodeNames = modGenes, nodeAttr = moduleColors[inModule]); 6.3 Network3d edges &lt;- read.table(&quot;CytoscapeInput-edges-brown-red.txt&quot;,header=T)nodes &lt;- read.table(&quot;CytoscapeInput-nodes-brown-red.txt&quot;,header=T,sep='\\t')colnames(nodes)= c(&quot;nodeName&quot;, &quot;altName&quot;, &quot;Group&quot;)edges$fromNode = match(edges$fromNode,nodes$nodeName)edges$toNode = match(edges$toNode,nodes$nodeName)Index &lt;- read.table(text = paste(unique(edges$fromNode),0,0,&quot;undirected&quot;,&quot;A&quot;,&quot;B&quot;,sep='\\t'),sep='\\t')colnames(Index) = colnames(edges)edges = rbind(Index,edges)forceNetwork(Links=edges, Nodes=nodes, NodeID=&quot;nodeName&quot;, #指定节点显示的标签 Source=&quot;fromNode&quot;, #指定Links文件中的源节点 Target=&quot;toNode&quot;, #指定Links文件中的靶节点 Value=&quot;weight&quot;, #设定基因间连线的宽度 fontSize=20, #设定节点标签的字号，单位为像素 Group=&quot;Group&quot;, #对节点进行分组，这里可根据基因的功能进行分组，配置不同颜色 opacity=0.8, #指定图像的不透明度 zoom=TRUE, #是否允许图像缩放 arrows=TRUE, #连线是否添加箭头，显示方向 opacityNoHover=0.7, #鼠标悬停前，节点标签的不透明度 legend=TRUE, #是否显示图例 height=600, #设置图像高度 width=600 #设置图像宽度 #Nodesize = &quot;Freq_l&quot; #radiusCalculation = &quot;d.nodesize&quot;)","link":"/2020/06/08/R/WGCNA_1/"},{"title":"Develop a Binary Tree in R","text":"Plot a network Rlibrary(igraph)##Create dataset.seed(1)data=matrix(sample(0:1, 100, replace=TRUE, prob=c(0.8,0.2)), nc=10)network=graph_from_adjacency_matrix(data , mode='undirected', diag=F )##Default networkpar(mar=c(0,0,0,0))plot(network)head(data) This is the data structure we’d like to have [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [1,] 0 0 1 0 1 0 1 0 0 0 [2,] 0 0 0 0 0 1 0 1 0 0 [3,] 0 0 0 0 0 0 0 0 0 0 [4,] 1 0 0 0 0 0 0 0 0 1 [5,] 0 0 0 1 0 0 0 0 0 0 [6,] 1 0 0 0 0 0 0 1 0 0 From List to Network-Data Matrix Let’s say, a list of data 1, 2, 3, 4 means the relationship of 1-&gt; 2 -&gt; 3 -&gt; 4. RList &lt;- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)List2DF &lt;- function(List){ tmp = c(List[-1],NA) TB = data.frame(&quot;A&quot;=List, &quot;B&quot; = tmp, V = 0) colnames(TB) = c(&quot;A&quot;, &quot;B&quot;, &quot;V&quot;) return(na.omit(TB))}DF2Net &lt;- function(TB){ AA = reshape( TB, timevar='A',idvar='B', direction='wide') colnames(AA) &lt;- c(matrix(t(data.frame(strsplit(colnames(AA),&quot;[.]&quot;)))[,2])) row.names(AA) = AA[,1] AA = AA[,-1] AA = AA+1 Element = unique(c(colnames(AA), rownames(AA))) AA = AA[match(Element, rownames(AA)),] rownames(AA) = Element AA = t(AA) AA = AA[match(Element, rownames(AA)),] rownames(AA) = Element AA[is.na(AA)]=0 return(AA)}print(DF2Net(List2DF(List))) 1 2 3 4 5 6 7 8 9 10 1 0 1 0 0 0 0 0 0 0 0 2 0 0 1 0 0 0 0 0 0 0 3 0 0 0 1 0 0 0 0 0 0 4 0 0 0 0 1 0 0 0 0 0 5 0 0 0 0 0 1 0 0 0 0 6 0 0 0 0 0 0 1 0 0 0 7 0 0 0 0 0 0 0 1 0 0 8 0 0 0 0 0 0 0 0 1 0 9 0 0 0 0 0 0 0 0 0 1 10 0 0 0 0 0 0 0 0 0 0 Rnetwork=graph_from_adjacency_matrix(data.matrix(AA), mode='undirected')l &lt;- layout_components(network)png(paste(&quot;network.png&quot;,sep=&quot;&quot;), width = 400, height = 400)plot(network,layout=l, vertex.size=1, vertex.label.cex=0.7, vertex.label =&quot;&quot;, vertex.frame.color=&quot;transparent&quot; )dev.off() © Karobben For loop to build a list Tree_grwoth &lt;- function(Growth_Turn = 10, Period = 2){ for (f in c(2:Growth_Turn)){ Main = c(&quot;A&quot;) Result = list(&quot;main&quot; = Main) Turns = f for(t in c(1:Turns)){ for(branch in names(Result)){ branch_tmp = c( Result[[branch]], paste( Result[[branch]][1],t, sep=&quot;-&quot;)) Result[[branch]] &lt;- branch_tmp # New branch if(length(branch_tmp) %% Period == 0){ print(&quot;New Branch&quot;) Result[branch_tmp[length(branch_tmp)]] = c(branch_tmp[length(branch_tmp)]) } } } } return(Result)}Result &lt;- Tree_grwoth(20, 5)head(summary(Result)) Length Class Mode main 21 -none- character A-4 17 -none- character A-4-8 13 -none- character A-9 12 -none- character A-4-8-12 9 -none- character A-4-13 8 -none- character Rhead(Result, 3) $main $main [1] \"A\" \"A-1\" \"A-2\" \"A-3\" \"A-4\" \"A-5\" \"A-6\" \"A-7\" \"A-8\" \"A-9\" \"A-10\" \"A-11\" \"A-12\" \"A-13\" \"A-14\" \"A-15\" [17] \"A-16\" \"A-17\" \"A-18\" \"A-19\" \"A-20\" $`A-4` [1] \"A-4\" \"A-4-5\" \"A-4-6\" \"A-4-7\" \"A-4-8\" \"A-4-9\" \"A-4-10\" \"A-4-11\" \"A-4-12\" \"A-4-13\" \"A-4-14\" \"A-4-15\" [13] \"A-4-16\" \"A-4-17\" \"A-4-18\" \"A-4-19\" \"A-4-20\" $`A-4-8` [1] \"A-4-8\" \"A-4-8-9\" \"A-4-8-10\" \"A-4-8-11\" \"A-4-8-12\" \"A-4-8-13\" \"A-4-8-14\" \"A-4-8-15\" \"A-4-8-16\" \"A-4-8-17\" [11] \"A-4-8-18\" \"A-4-8-19\" \"A-4-8-20\" Whole Pipeline Result &lt;- Tree_grwoth(100, 10)'''STATE &lt;- data.frame(summary(Result))STAT &lt;- STATE[STATE$Var2 == &quot;Length&quot;,]sum(as.numeric(str_remove_all(as.character(STAT$Freq),&quot; &quot;)) -1)'''TB &lt;- data.frame()for(List in Result){ TB_tmp &lt;- List2DF(List) TB &lt;- rbind(TB, TB_tmp)}AA &lt;- DF2Net(TB)network=graph_from_adjacency_matrix(data.matrix(AA), mode='undirected')l &lt;- layout_components(network)plot(network,layout=l, vertex.size=1, vertex.label.cex=0.7, vertex.label =&quot;&quot;, vertex.frame.color=&quot;transparent&quot; ) When I try Result &lt;- Tree_grwoth(135, 10): V(network)$color =&quot;steelblue&quot;for(i in c(1:100)){ png(paste(i,&quot;.png&quot;,sep=&quot;&quot;), width = 1920, height = 1080) plot(network,layout=head(l, i), vertex.size=1 / tanh(0.004 * i), vertex.label.cex=0.7, vertex.label =&quot;&quot;, vertex.frame.color=&quot;transparent&quot; ) dev.off()}","link":"/2021/04/20/R/binary-tree/"},{"title":"How to do anova in R","text":"Anova test, all you need to know and action in R pre { background-color:#38393d; color: #5fd381; } Citation: ANOVA Test: Definition, Types, Examples, SPSS; © Statistics How To ANOVA in R | A Complete Step-by-Step Guide with Examples; © scribbr In this post, I’ll show how to do ANOVA test in R. The result would be similar like Prim. If it is not, I’ll noted below. To be noticed, we should carefully select which protocol we use based on our data and purpose. For example, one-way ANOVA, two-way ANOVA, pairwise comparing based on the TukeyHSD test, control group pairwise comparing based on Dunnett Test, and finally, the repeat ANOVA test. As far as I know, we do not have a way to do ANOVA based on the summarized data set. However, we can simulate a table based on the summarized data and do the ANOVA test which could achieve the same result as the Prism, cheers! Talk is cheap, show me the code raw posts: Rebecca Bevans: ANOVA in R | A Complete Step-by-Step Guide with Examples Example data: Click to Download library(ggplot2)library(ggpubr)library(tidyverse)library(broom)library(AICcmodavg)crop.data &lt;- read.csv(&quot;~/Downloads/crop.data.csv&quot;, header = TRUE, colClasses = c(&quot;factor&quot;, &quot;factor&quot;, &quot;factor&quot;, &quot;numeric&quot;))summary(crop.data) density block fertilizer yield 1:48 1:24 1:32 Min. :175.4 2:48 2:24 2:32 1st Qu.:176.5 3:24 3:32 Median :177.1 4:24 Mean :177.0 3rd Qu.:177.4 Max. :179.1 one.way &lt;- aov(yield ~ fertilizer, data = crop.data)summary(one.way) One way anova one.way &lt;- aov(weight ~ Diet, data = ChickWeight)summary(one.way)TukeyHSD(one.way) summary(one.way) Df Sum Sq Mean Sq F value Pr(>F) Time 1 2042344 2042344 1349 F) Diet 3 155863 51954 11.504 2.57e-07 *** Chick 46 374243 8136 1.802 0.00136 ** Residuals 528 2384450 4516 Tukey multiple comparisons of means 95% family-wise confidence level Fit: aov(formula = weight ~ Diet * Chick, data = ChickWeight) $Diet diff lwr upr p adj 2-1 19.971212 0.3164389 39.62599 0.0447928 3-1 40.304545 20.6497722 59.95932 0.0000011 4-1 32.617257 12.8550000 52.37951 0.0001458 3-2 20.333333 -2.0257975 42.69246 0.0896286 4-2 12.646045 -9.8076279 35.09972 0.4678041 4-3 -7.687288 -30.1409612 14.76638 0.8140383 $Chick diff lwr upr p adj 16-18 12.71428571 -203.752079 229.180650 1.0000000 15-18 23.12500000 -190.313714 236.563714 1.0000000 13-18 30.83333333 -175.368054 237.034721 1.0000000 9-18 44.16666667 -162.034721 250.368054 1.0000000 20-18 41.41666667 -164.784721 247.618054 1.0000000 10-18 46.08333333 -160.118054 252.284721 1.0000000 8-18 55.00000000 -152.536038 262.536038 1.0000000 17-18 55.50000000 -150.701387 261.701387 1.0000000 Anova with Mean and sd table Reference: Dason, 2015 The best way to calculate the Anova table from the summary data in R is not to do the ANOVA directly, is to simulate a data table based on your summary data and run ANOVA after. Mean &lt;- c(212 ,193 ,211 ,221 ,199 ,195 )Sd &lt;- c(35 ,35 ,26 ,21 ,31 ,25)N &lt;- c(20,29,27,23,29,35)gen_data &lt;- function(means, sds, samplesizes){ n.grp &lt;- length(means) grps &lt;- factor(rep(1:n.grp, samplesizes)) dat &lt;- lapply(1:n.grp, function(i) {scale(rnorm(samplesizes[i]))*sds[i] + means[i]}) y &lt;- do.call(rbind, dat) out &lt;- data.frame(group = grps, y = y) out}simulated_data &lt;- gen_data(Mean, Sd,N)av &lt;- aov(y ~ group, data = simulated_data)summary(av)TukeyHSD(av) Df Sum Sq Mean Sq F value Pr(>F) group 5 16310 3262 3.85 0.00256 ** Residuals 157 133011 847 Tukey multiple comparisons of means 95% family-wise confidence level Fit: aov(formula = y ~ group, data = simulated_data) $group diff lwr upr p adj 2-1 -19 -43.409541 5.409541 0.2230739 3-1 -1 -25.775796 23.775796 0.9999970 4-1 9 -16.676208 34.676208 0.9135955 5-1 -13 -37.409541 11.409541 0.6412141 6-1 -17 -40.540078 6.540078 0.3012203 3-2 18 -4.458911 40.458911 0.1952944 4-2 28 4.551540 51.448460 0.0093845 5-2 6 -16.054213 28.054213 0.9697289 6-2 2 -19.087861 23.087861 0.9997892 4-3 10 -13.829491 33.829491 0.8310731 5-3 -12 -34.458911 10.458911 0.6379762 6-3 -16 -37.510748 5.510748 0.2694050 5-4 -22 -45.448460 1.448460 0.0795394 6-4 -26 -48.541958 -3.458042 0.0136716 6-5 -4 -25.087861 17.087861 0.9940591 DunnettTest for selected Control Group Dunnett’s test is kind of a multiple comparison procedure. Unlike Tukey’s test, it only compares your samples with the control group which could prevent the overestimation of the p-value because of non-related pairwise comparison. library(DescTools)Mean &lt;- c(182, 212 ,193 ,211 ,221 ,199 ,195 )Sd &lt;- c(21, 35 ,35 ,26 ,21 ,31 ,25)N &lt;- c(127, 20,29,27,23,29,35)gen_data &lt;- function(means, sds, samplesizes){ n.grp &lt;- length(means) grps &lt;- factor(rep(1:n.grp, samplesizes)) dat &lt;- lapply(1:n.grp, function(i) {scale(rnorm(samplesizes[i]))*sds[i] + means[i]}) y &lt;- do.call(rbind, dat) out &lt;- data.frame(group = grps, y = y) out}simulated_data &lt;- gen_data(Mean, Sd,N)av &lt;- aov(y ~ group, data = simulated_data)DunnettTest(x=simulated_data$y, g=simulated_data$group) Dunnett's test for comparing several treatments with a control : 95% family-wise confidence level $`1` diff lwr.ci upr.ci pval 2-1 30 13.58673988 46.41326 1.3e-05 *** 3-1 11 -3.04153165 25.04153 0.2062 4-1 29 14.54128620 43.45871 1.4e-06 *** 5-1 39 23.53916681 54.46083 8.7e-10 *** 6-1 17 2.95846835 31.04153 0.0091 ** 7-1 13 -0.02490811 26.02491 0.0505 . --- Signif. codes: 0 '\\***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 Two-way Anova Reference: scribbr.com When we needn’t to test any interaction between two groups, we could use the model W ~ C+G. Otherwise, W ~ C*G would be appropriate. TB &lt;- rbind(data.frame(C=&quot;S&quot;, G = &quot;M&quot;, W=c(191, 185, 169, 187, 175, 177, 182)),data.frame(C=&quot;S&quot;, G = &quot;W&quot;, W=c(189, 181, 176, 189, 199, 201, 191, 188)),data.frame(C=&quot;A&quot;, G = &quot;M&quot;, W=c(191, 193, 188, 176, 189, 201, 203)),data.frame(C=&quot;A&quot;, G = &quot;W&quot;, W=c(187, 181, 179, 190, 192, 179, 185)))two_way &lt;- aov(W ~ C*G, data=TB)two_way Call: aov(formula = W ~ C * G, data = TB) Terms: C G C:G Residuals Sum of Squares 57.1593 7.4347 420.1129 1479.5000 Deg. of Freedom 1 1 1 25 Residual standard error: 7.692854 Estimated effects may be unbalanced summary(two_way) Df Sum Sq Mean Sq F value Pr(>F) C 1 57.2 57.2 0.966 0.3351 G 1 7.4 7.4 0.126 0.7260 C:G 1 420.1 420.1 7.099 0.0133 * Residuals 25 1479.5 59.2 --- Signif. codes: 0 ‘\\***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 According to the results from summary, neither Row (all men vs all women) nor column (all scandanavians vs all Americans) are significant. However, the interaction (C:G) p-value is 0.013, which is significant. This indicates that the relationships between ‘G’ and ‘W’ depends on the ‘C’ method. codes from car: Reference: R Statistics and Research, 2018 library(car)Anova(lm( W ~ C*G, data=TB)) Anova Table (Type II tests) Response: W Sum Sq Df F value Pr(>F) C 58.48 1 0.9881 0.32972 G 7.43 1 0.1256 0.72598 C:G 420.11 1 7.0989 0.01331 * Residuals 1479.50 25 --- Signif. codes: 0 ‘\\***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Repeat ANOVA measurement You should different the repeated measure from other just like paired t test. Reference: Repeated Measures ANOVA in R Ten patients did the same test from 5 different companies. Save the data below as “123.txt”. Patient A B C D E 1 71 65 65 78 73 2 99 95 96 110 110 3 128 125 115 145 139 4 89 80 75 95 90 5 1290 1180 1145 1330 1450 6 61 60 56 59 72 7 945 935 918 990 956 8 72 75 70 79 81 9 220 208 204 229 217 10 145 134 130 155 159 # Read the dataTB &lt;- read.table(&quot;123.txt&quot;, header=T)head(TB) Patient A B C D E 1 1 71 65 65 78 73 2 2 99 95 96 110 110 3 3 128 125 115 145 139 4 4 89 80 75 95 90 5 5 1290 1180 1145 1330 1450 6 6 61 60 56 59 72 library(reshape2)library(ggplot2)TB$Patient = as.factor(TB$Patient)TB_g &lt;- melt(TB)ggplot(TB_g, aes(x= Patient, y = value, fill = variable)) + geom_bar(stat=&quot;identity&quot;, position = &quot;dodge&quot;)+ facet_wrap(~Patient, scale=&quot;free&quot;) + scale_fill_brewer(palette = &quot;Paired&quot;)+ theme_minimal() With normal One-way anova: one.way &lt;- aov(value~ variable, data = TB_g)summary(one.way)TukeyHSD(one.way) Df Sum Sq Mean Sq F value Pr(>F) variable 4 16091 4023 0.021 0.999 Residuals 45 8465019 188112 Tukey multiple comparisons of means 95% family-wise confidence level Fit: aov(formula = value ~ variable, data = TB_g) $variable diff lwr upr p adj B-A -16.3 -567.441 534.841 0.9999882 C-A -24.6 -575.741 526.541 0.9999393 D-A 15.0 -536.141 566.141 0.9999916 E-A 22.7 -528.441 573.841 0.9999559 C-B -8.3 -559.441 542.841 0.9999992 D-B 31.3 -519.841 582.441 0.9998416 E-B 39.0 -512.141 590.141 0.9996211 D-C 39.6 -511.541 590.741 0.9995975 E-C 47.3 -503.841 598.441 0.9991880 E-D 7.7 -543.441 558.841 0.9999994 P value is very close to 1 which means that there are no significant difference between 5 companies. This is worng because it treated all data as independent rather than repeated data There is how we should deal with the repeated data: library(tidyverse)library(rstatix)res.aov &lt;- anova_test(data = TB_g, dv = value, wid = Patient, within = variable)res.aov ANOVA Table (type III tests) $ANOVA Effect DFn DFd F p p","link":"/2022/02/04/R/anova-r/"},{"title":"circlize","text":"Quick Start install.packages('circlize')library(circlize)##Create datadata = data.frame( factor = sample(letters[1:8], 1000, replace = TRUE), x = rnorm(1000), y = runif(1000) )## Step1: Initialise the chart giving factor and x-axis.circos.initialize( factors=data$factor, x=data$x )## Step 2: Build the regions.circos.trackPlotRegion(factors = data$factor, y = data$y, panel.fun = function(x, y) { circos.axis() })## Step 3: Add pointscircos.trackPoints(data$factor, data$x, data$y, col = &quot;blue&quot;, pch = 16, cex = 0.5)## Step 4: Add pointscircos.trackPoints(data$factor, data$x, data$y, col = rgb(0.1,0.5,0.8,0.3), pch = 20, cex = 2) library(circlize)## Create datadata = data.frame( factor = sample(letters[1:8], 1000, replace = TRUE), x = rnorm(1000), y = runif(1000) )## General parameterscircos.par(&quot;track.height&quot; = 0.4) 1: scatter plot ## Initialize chartcircos.initialize(factors = data$factor, x = data$x )circos.trackPlotRegion(factors = data$factor, y=data$y, panel.fun = function(x, y) { circos.axis(labels.cex=0.5, labels.font=1, lwd=0.8, h=&quot;bottom&quot;, direction=&quot;inside&quot;) })circos.trackPoints(data$factor, data$x, data$y, col = rgb(0.1,0.5,0.8,0.3), pch=20) 2: lines ## Initialize chartcircos.initialize(factors = data$factor, x = data$x )## Build the regions.circos.trackPlotRegion(factors = data$factor, y=data$y, panel.fun = function(x, y) { circos.axis(labels.cex=0.5, labels.font=1, lwd=0.8, h=&quot;bottom&quot;, direction=&quot;inside&quot;) })circos.trackLines(data$factor, data$x[order(data$x)], data$y[order(data$x)], col = rgb(0.1,0.5,0.8,0.3), lwd=2) 3: abline (vertical lines) ## Initialize chartcircos.initialize(factors = data$factor, x = data$x )## Build the regions.circos.trackPlotRegion(factors = data$factor, y=data$y, panel.fun = function(x, y) { circos.axis(labels.cex=0.5, labels.font=1, lwd=0.8, h=&quot;bottom&quot;, direction=&quot;inside&quot;) })circos.trackLines(data$factor, data$x[order(data$x)], data$y[order(data$x)], col = rgb(0.1,0.5,0.8,0.3), lwd=2, type=&quot;h&quot;) 4: text ## Initialize chartcircos.initialize(factors = data$factor, x = data$x )## Build the regions.circos.trackPlotRegion(factors = data$factor, y=data$y, panel.fun = function(x, y) { circos.axis(labels.cex=0.5, labels.font=1, lwd=0.8, h=&quot;bottom&quot;, direction=&quot;inside&quot;) })circos.trackText(data$factor, data$x[order(data$x)], data$y[order(data$x)], labels=data$factor, col = rgb(0.9,0.2,0.8,0.3), cex=1) 5: histogram circos.initialize(factors = data$factor, x = data$x )circos.trackPlotRegion(factors = data$factor, panel.fun = function(x, y) { circos.axis(labels.cex=0.5, labels.font=1, lwd=4) })circos.trackHist(data$factor, data$x, bg.col = &quot;grey78&quot;, col = rgb(0.1,0.5,0.8,0.3)) Layer by layer library(circlize)##Create datadata = data.frame( factor = sample(letters[1:8], 1000, replace = TRUE), x = rnorm(1000), y = runif(1000) )##Initialize the plot.par(mar = c(1, 1, 1, 1) )circos.initialize(factors = data$factor, x = data$x )## Build the regions of track #1circos.trackPlotRegion(factors = data$factor, y=data$y, panel.fun = function(x, y) { circos.axis(labels.cex=0.5, labels.font=1, lwd=0.8) })## --&gt; Add a scatterplot on it:circos.trackPoints(data$factor, data$x, data$y, col = rgb(0.1,0.5,0.8,0.3), pch=20)## Build the regions of track #2:circos.trackPlotRegion(factors = data$factor, y=data$y, panel.fun = function(x, y) { circos.axis(labels=FALSE, major.tick=FALSE) })## --&gt; Add a scatterplot on itcircos.trackPoints(data$factor, data$x, data$y, col = rgb(0.9,0.5,0.8,0.3), pch=20, cex=2)## Add the couche #3 --&gt; don't forget you can custom the height of tracks!circos.par(&quot;track.height&quot; = 0.4)circos.trackPlotRegion(factors = data$factor, y=data$y, panel.fun = function(x, y) { circos.axis(labels=FALSE, major.tick=FALSE) })circos.trackLines(data$factor, data$x, data$y, col = rgb(0.9,0.5,0.1,0.3), pch=20, cex=2, type=&quot;h&quot;) Example 2 Source: https://www.jianshu.com/p/a87bcc1cb67b library(circlize)## 简单创建一个数据集set.seed(999)n &lt;- 1000a &lt;- data.frame(factors = sample(letters[1:8], n, replace = TRUE), x = rnorm(n), y = runif(n))##Layer 1par(mar = c(1, 1, 1, 1), lwd = 0.1, cex = 0.6)circos.par(track.height = 0.1)circos.initialize(factors = a$factors, x = a$x) #初始化，factors来控制track数目，初始化里只有x， 没有y。这一步相当于ggplot()circos.trackPlotRegion(factors = a$factors, y = a$y,panel.fun = function(x, y) {circos.axis()})col &lt;- rep(c(&quot;#FF0000&quot;, &quot;#00FF00&quot;), 4) #自定义一下颜色# 这里先解释一下，一个track有好几个cell，具体数目由factors决定的，向本数据集中factors有八个，因此绘制一个track，其包含八个cell。含有前缀circos.track的函数会在所有的cel里添加基本元素，而只有前缀circos.的函数可以在特定的track、cell里添加基本元素。具体看下演示。circos.trackPoints(a$factors, a$x, a$y, col = col, pch = 16, cex = 0.5) #所有的cell里都绘制点图circos.text(-1, 0.5, &quot;left&quot;, sector.index = &quot;a&quot;, track.index = 1) #在track 1中的标记为a的cell里添加circos.clear()##Layer 2par(mar = c(1, 1, 1, 1), lwd = 0.1, cex = 0.6)circos.par(track.height = 0.1)circos.initialize(factors = a$factors, x = a$x)circos.trackPlotRegion(factors = a$factors, y = a$y,panel.fun = function(x, y) {circos.axis()})col &lt;- rep(c(&quot;#FF0000&quot;, &quot;#00FF00&quot;), 4)circos.trackPoints(a$factors, a$x, a$y, col = col, pch = 16, cex = 0.5)circos.text(-1, 0.5, &quot;left&quot;, sector.index = &quot;a&quot;, track.index = 1)circos.text(1, 0.5, &quot;right&quot;, sector.index = &quot;a&quot;)bg.col &lt;- rep(c(&quot;#EFEFEF&quot;, &quot;#CCCCCC&quot;), 4)circos.trackHist(a$factors, a$x, bg.col = bg.col, col = NA)circos.clear()##Layer 3par(mar = c(1, 1, 1, 1), lwd = 0.1, cex = 0.6)circos.par(track.height = 0.1)circos.initialize(factors = a$factors, x = a$x)circos.trackPlotRegion(factors = a$factors, y = a$y, panel.fun = function(x, y) {circos.axis()})col &lt;- rep(c(&quot;#FF0000&quot;, &quot;#00FF00&quot;), 4)circos.trackPoints(a$factors, a$x, a$y, col = col, pch = 16, cex = 0.5)circos.text(-1, 0.5, &quot;left&quot;, sector.index = &quot;a&quot;, track.index = 1)circos.text(1, 0.5, &quot;right&quot;, sector.index = &quot;a&quot;)bg.col &lt;- rep(c(&quot;#EFEFEF&quot;, &quot;#CCCCCC&quot;), 4)circos.trackHist(a$factors, a$x, bg.col = bg.col, col = NA)circos.trackPlotRegion(factors = a$factors, x = a$x, y = a$y,panel.fun = function(x, y) { grey = c(&quot;#FFFFFF&quot;, &quot;#CCCCCC&quot;, &quot;#999999&quot;)sector.index = get.cell.meta.data(&quot;sector.index&quot;) #这个是第三个track，因为我们刚刚创建，这里这一步不用也可。 xlim = get.cell.meta.data(&quot;xlim&quot;) ylim = get.cell.meta.data(&quot;ylim&quot;)circos.text(mean(xlim), mean(ylim), sector.index)circos.points(x[1:10], y[1:10], col = &quot;red&quot;, pch = 16, cex = 0.6)circos.points(x[11:20], y[11:20], col = &quot;blue&quot;, cex = 0.6)})circos.clear() Connection set.seed(999)mat = matrix(sample(18, 18), 3, 6)rownames(mat) = paste0(&quot;S&quot;, 1:3)colnames(mat) = paste0(&quot;E&quot;, 1:6)df=melt(mat)df$X1=as.character(df$Var1)df$X2=as.character(df$Var2)##作图chordDiagram(mat)chordDiagram(df)circos.clear()##图形的精修和参数介绍chordDiagram(df, reduce = -1, #如果单个扇叶/整个环 &lt; reduce,则这个扇叶不展示 grid.col=sample(colors(),length(union(df$X1,df$X2)),replace = F), #扇叶的颜色，顺序和union(df[[1]],df[[2]])一样 col=colorRamp2(breaks=c(1,18),colors=c(&quot;blue&quot;,&quot;red&quot;)), #连线的颜色，也可以设置展示df中数值的大小 order = union(df$X2,df$X1), #扇叶展示的顺序 directional = 1, #连线的方向，1=第一列到第二列，2=双方向，-1=第二列到第一列，0=无方向 direction.type = &quot;arrows&quot;, #可以为“diffHeight”，也可以为“arrows” diffHeight = rep(convert_height(1,&quot;mm&quot;),length(union(df$X1,df$X2))), #正值代表出处比末尾凸出，负值代表出处比末尾凹进去 self.link = 1, #自己和自己相连的线，1=形似山 宽度代变数值大小，2=出和入的宽度相同并代表数值的大小 preAllocateTracks = 1, #预留出多少空的轨道 link.border = rep('grey',nrow(df)), #连线边界的颜色 link.lwd = rep(1,nrow(df)), #连线边界的宽度 link.lty = rep(3,nrow(df)), #设置连线边界的线型 link.sort = T, # 对连线依据大小排序 link.decreasing = T, #连线降序排序 link.arr.width = rep(0.1,nrow(df)), #连线方向用箭头表示时，箭头的宽度 link.arr.type = &quot;triangle&quot;, #箭头类型 link.arr.col = rep('grey',nrow(df)), #箭头的颜色 link.arr.lwd = rep(1,nrow(df)), #箭头的尾线宽度 link.arr.lty = rep(3,nrow(df)), #箭头尾线的线型 link.visible = c(rep(T,9),rep(F,9)) #连线是否画出 ) layout(matrix(1:9, 3, 3))for (i in 1:9) { factors = letters[1:8]par(mar = c(0.5, 0.5, 0.5, 0.5))circos.par(cell.padding = c(0, 0, 0, 0))circos.initialize(factors = factors, xlim = c(0, 1))circos.trackPlotRegion(ylim = c(0, 1), track.height = 0.05,bg.col = rand_color(8), bg.border = NA)## 绘制linksfor (i in 1:20) {se = sample(letters[1:8], 2)circos.link(se[1], runif(2), se[2], runif(2),col = rand_color(1, transparency = 0.4), border = NA)}}circos.clear() set.seed(1234)data &lt;- matrix(rnorm(100 * 10), nrow = 10, ncol = 100)col &lt;- colorRamp2(c(-2, 0, 2), c(&quot;green&quot;, &quot;black&quot;, &quot;red&quot;))factors &lt;- rep(letters[1:2], times = c(30, 70))data_list &lt;- list(a = data[, factors == &quot;a&quot;], b = data[, factors == &quot;b&quot;])dend_list &lt;- list(a = as.dendrogram(hclust(dist(t(data_list[[&quot;a&quot;]])))), b = as.dendrogram(hclust(dist(t(data_list[[&quot;b&quot;]])))))circos.par(cell.padding = c(0, 0, 0, 0), gap.degree = 5)circos.initialize(factors = factors, xlim = cbind(c(0, 0), table(factors)))circos.track(ylim = c(0, 10), bg.border = NA,panel.fun = function(x, y) { sector.index = get.cell.meta.data(&quot;sector.index&quot;)d = data_list[[sector.index]]dend = dend_list[[sector.index]]d2 = d[, order.dendrogram(dend)]col_data = col(d2)nr = nrow(d2)nc = ncol(d2)for (i in 1:nr) {circos.rect(1:nc - 1, rep(nr - i, nc), 1:nc, rep(nr - i + 1, nc),border = col_data[i, ], col = col_data[i, ]) }})max_height &lt;- max(sapply(dend_list, function(x) attr(x, &quot;height&quot;)))circos.track(ylim = c(0, max_height),bg.border = NA, track.height = 0.3,panel.fun = function(x, y) {sector.index = get.cell.meta.data(&quot;sector.index&quot;)dend = dend_list[[sector.index]]circos.dendrogram(dend, max_height = max_height)})circos.clear() More","link":"/2020/05/01/R/circlize/"},{"title":"WGCNA Tutorial 2","text":"WGCNA Tutorial 2 Official Website Paper: Peter Langfelder, 2008 Weighted correlation network analysis (WGCNA) can be used for finding clusters (modules) of highly correlated genes, for summarizing such clusters using the module eigengene or an intramodular hub gene, for relating modules to one another and to external sample traits (using eigengene network methodology), and for calculating module membership measures. Play list for Network Analysis Install ## Mirrors## options(&quot;repos&quot; = c(CRAN=&quot;https://mirrors.tuna.tsinghua.edu.cn/CRAN/&quot;))## options(BioC_mirror=&quot;https://mirrors.tuna.tsinghua.edu.cn/bioconductor&quot;)install.packages(&quot;BiocManager&quot;)BiocManager::install(&quot;WGCNA&quot;) Data: Female data Male data 1. Data Preparation 1.1 Loading DataSet The data sets contain roughly 130 samples each. Note that each row corresponds to a gene and column to a sample or auxiliary information. library(WGCNA)## Reading Dataoptions(stringsAsFactors = FALSE)##Read in the female liver data setfemData = read.csv(&quot;LiverFemale3600.csv&quot;)## Read in the male liver data setmaleData = read.csv(&quot;LiverMale3600.csv&quot;) 1.2 Groups in List ## We work with two sets:nSets = 2;## For easier labeling of plots, create a vector holding descriptive names of the two sets.setLabels = c(&quot;Female liver&quot;, &quot;Male liver&quot;)shortLabels = c(&quot;Female&quot;, &quot;Male&quot;)## Form multi-set expression data: columns starting from 9 contain actual expression data.multiExpr = vector(mode = &quot;list&quot;, length = nSets)multiExpr[[1]] = list(data = as.data.frame(t(femData[-c(1:8)])));names(multiExpr[[1]]$data) = femData$substanceBXH;rownames(multiExpr[[1]]$data) = names(femData)[-c(1:8)];multiExpr[[2]] = list(data = as.data.frame(t(maleData[-c(1:8)])));names(multiExpr[[2]]$data) = maleData$substanceBXH;rownames(multiExpr[[2]]$data) = names(maleData)[-c(1:8)];## Check that the data has the correct format for many functions operating on multiple sets:exprSize = checkSets(multiExpr) 1.3 Rudimentary data cleaning and outlier removal Check that all genes and samples have sufficiently low numbers of missing values. gsg = goodSamplesGenesMS(multiExpr, verbose = 3);gsg$allOKif (!gsg$allOK){ # Print information about the removed genes: if (sum(!gsg$goodGenes) &gt; 0) printFlush(paste(&quot;Removing genes:&quot;, paste(names(multiExpr[[1]]$data)[!gsg$goodGenes], collapse = &quot;, &quot;))) for (set in 1:exprSize$nSets) { if (sum(!gsg$goodSamples[[set]])) printFlush(paste(&quot;In set&quot;, setLabels[set], &quot;removing samples&quot;, paste(rownames(multiExpr[[set]]$data)[!gsg$goodSamples[[set]]], collapse = &quot;, &quot;))) # Remove the offending genes and samples multiExpr[[set]]$data = multiExpr[[set]]$data[gsg$goodSamples[[set]], gsg$goodGenes]; } # Update exprSize exprSize = checkSets(multiExpr)} 1.4 Cluster sampleTrees = list()for (set in 1:nSets){ sampleTrees[[set]] = hclust(dist(multiExpr[[set]]$data), method = &quot;average&quot;)}par(mfrow=c(2,1))par(mar = c(0, 4, 2, 0))for (set in 1:nSets) plot(sampleTrees[[set]], main = paste(&quot;Sample clustering on all genes in&quot;, setLabels[set]), xlab=&quot;&quot;, sub=&quot;&quot;, cex = 0.7) By inspection, there seems to be one outlier in the female data set, and no obvious outliers in the male set. We now remove the female outlier using a semi-automatic code that only requires a choice of a height cut 1.5 Remove Outlier ## Choose the &quot;base&quot; cut height for the female data setbaseHeight = 16## Adjust the cut height for the male data set for the number of samplescutHeights = c(16, 16*exprSize$nSamples[2]/exprSize$nSamples[1]);## Re-plot the dendrograms including the cut linespng(file = &quot;SampleClustering.png&quot;);par(mfrow=c(2,1))par(mar = c(0, 4, 2, 0))for (set in 1:nSets){ plot(sampleTrees[[set]], main = paste(&quot;Sample clustering on all genes in&quot;, setLabels[set]), xlab=&quot;&quot;, sub=&quot;&quot;, cex = 0.7); abline(h=cutHeights[set], col = &quot;red&quot;);}dev.off();## Removing outlierfor (set in 1:nSets){ # Find clusters cut by the line labels = cutreeStatic(sampleTrees[[set]], cutHeight = cutHeights[set]) # Keep the largest one (labeled by the number 1) keep = (labels==1) multiExpr[[set]]$data = multiExpr[[set]]$data[keep, ]}collectGarbage();## Check the size of the leftover dataexprSize = checkSets(multiExpr)exprSize 1.6 Loading Clinical Trait Data traitData = read.csv(&quot;ClinicalTraits.csv&quot;);## remove columns that hold information we do not need.allTraits = traitData[, -c(31, 16)];allTraits = allTraits[, c(2, 11:36) ];## See how big the traits are and what are the trait and sample namesdim(allTraits)names(allTraits)allTraits$Mice## Form a multi-set structure that will hold the clinical traits.Traits = vector(mode=&quot;list&quot;, length = nSets);for (set in 1:nSets){ setSamples = rownames(multiExpr[[set]]$data); traitRows = match(setSamples, allTraits$Mice); Traits[[set]] = list(data = allTraits[traitRows, -1]); rownames(Traits[[set]]$data) = allTraits[traitRows, 1];}collectGarbage();## Define data set dimensionsnGenes = exprSize$nGenes;nSamples = exprSize$nSamples; 2. Network Construction and Module Detection graph LR; START(Network construction) Net1(one-step network construction) Net2(Step-by-step network construction) Net3(automatic block-wise network construction) START-->|Minimum Effort|Net1; START-->|Customized/Alternate Methods|Net2; START-->|Large Data Set|Net3; 2.1 One-Step Network Construction and Module Detection ## Choose a set of soft-thresholding powerspowers = c(seq(4,10,by=1), seq(12,20, by=2));## Initialize a list to hold the results of scale-free analysispowerTables = vector(mode = &quot;list&quot;, length = nSets);## Call the network topology analysis function for each set in turnfor (set in 1:nSets) powerTables[[set]] = list(data = pickSoftThreshold(multiExpr[[set]]$data, powerVector=powers, verbose = 2)[[2]]);collectGarbage();## Plot the results:colors = c(&quot;black&quot;, &quot;red&quot;)## Will plot these columns of the returned scale free analysis tablesplotCols = c(2,5,6,7)colNames = c(&quot;Scale Free Topology Model Fit&quot;, &quot;Mean connectivity&quot;, &quot;Median connectivity&quot;,&quot;Max connectivity&quot;);## Get the minima and maxima of the plotted pointsylim = matrix(NA, nrow = 2, ncol = 4);for (set in 1:nSets){ for (col in 1:length(plotCols)) { ylim[1, col] = min(ylim[1, col], powerTables[[set]]$data[, plotCols[col]], na.rm = TRUE); ylim[2, col] = max(ylim[2, col], powerTables[[set]]$data[, plotCols[col]], na.rm = TRUE); }}## Plot the quantities in the chosen columns vs. the soft thresholding powersizeGrWindow(8, 6)png(file = &quot;scaleFreeAnalysis.png&quot;)par(mfcol = c(2,2));par(mar = c(4.2, 4.2 , 2.2, 0.5))cex1 = 0.7;for (col in 1:length(plotCols)) for (set in 1:nSets){ if (set==1) { plot(powerTables[[set]]$data[,1], -sign(powerTables[[set]]$data[,3])*powerTables[[set]]$data[,2], xlab=&quot;Soft Threshold (power)&quot;,ylab=colNames[col],type=&quot;n&quot;, ylim = ylim[, col], main = colNames[col]); addGrid(); } if (col==1) { text(powerTables[[set]]$data[,1], -sign(powerTables[[set]]$data[,3])*powerTables[[set]]$data[,2], labels=powers,cex=cex1,col=colors[set]); } else text(powerTables[[set]]$data[,1], powerTables[[set]]$data[,plotCols[col]], labels=powers,cex=cex1,col=colors[set]); if (col==1) { legend(&quot;bottomright&quot;, legend = setLabels, col = colors, pch = 20) ; } else legend(&quot;topright&quot;, legend = setLabels, col = colors, pch = 20) ;}dev.off(); 2.2 Network construction and consensus module detection Attention: We have chosen the soft thresholding power 6, minimum module size 30, the module detection sensitivity deepSplit 2, cut height for merging of modules 0.20 (implying that modules whose eigengenes are correlated above 1 − 0.2 = 0.8 will be merged), we requested that the function return numeric module labels rather than color labels, we have effectively turned off reassigning genes based on their module eigengene-based connectivity KME, and we have instructed the code to save the calculated consensus topological overlap. In this example most of them are left at their default value. We encourage the user to read the help file provided within the package in the R environment and experiment with tweaking the network construction and module detection parameters. The potential reward is, of course, better (biologically more relevant) results of the analysis. net = blockwiseConsensusModules( multiExpr, power = 6, minModuleSize = 30, deepSplit = 2, pamRespectsDendro = FALSE, mergeCutHeight = 0.25, numericLabels = TRUE, minKMEtoStay = 0, saveTOMs = TRUE, verbose = 5) 2.3 Model Extract consMEs = net$multiMEs;moduleLabels = net$colors;## Convert the numeric labels to color labelsmoduleColors = labels2colors(moduleLabels)consTree = net$dendrograms[[1]]sizeGrWindow(8,6);png(file = &quot;ConsensusDendrogram-auto.png&quot;, wi = 600, he = 340)plotDendroAndColors(consTree, moduleColors, &quot;Module colors&quot;, dendroLabels = FALSE, hang = 0.03, addGuide = TRUE, guideHang = 0.05, main = &quot;Consensus gene dendrogram and module colors&quot;)dev.off() 3. Relating the consensus modules to female set-specific modules 3.1 datExpr (WGCNA Tutorial 1, 1-2) femData = read.csv(&quot;LiverFemale3600.csv&quot;);datExpr0 = as.data.frame(t(femData[, -c(1:8)]));names(datExpr0) = femData$substanceBXH;rownames(datExpr0) = names(femData)[-c(1:8)];gsg = goodSamplesGenes(datExpr0, verbose = 3);gsg$allOKif (!gsg$allOK){ if (sum(!gsg$goodGenes)&gt;0) printFlush(paste(&quot;Removing genes:&quot;, paste(names(datExpr0)[!gsg$goodGenes], collapse = &quot;, &quot;))); if (sum(!gsg$goodSamples)&gt;0) printFlush(paste(&quot;Removing samples:&quot;, paste(rownames(datExpr0)[!gsg$goodSamples], collapse = &quot;, &quot;))); datExpr0 = datExpr0[gsg$goodSamples, gsg$goodGenes]}sampleTree = hclust(dist(datExpr0), method = &quot;average&quot;);clust = cutreeStatic(sampleTree, cutHeight = 15, minSize = 10)keepSamples = (clust==1)datExpr = datExpr0[keepSamples, ]nGenes = ncol(datExpr)nSamples = nrow(datExpr)traitData = read.csv(&quot;ClinicalTraits.csv&quot;);dim(traitData)names(traitData)allTraits = traitData[, -c(31, 16)];allTraits = allTraits[, c(2, 11:36) ];dim(allTraits)names(allTraits)femaleSamples = rownames(datExpr);traitRows = match(femaleSamples, allTraits$Mice);datTraits = allTraits[traitRows, -1];rownames(datTraits) = allTraits[traitRows, 1];collectGarbage()sampleTree2 = hclust(dist(datExpr), method = &quot;average&quot;)traitColors = numbers2colors(datTraits, signed = FALSE);powers = c(c(1:10), seq(from = 12, to=20, by=2))sft = pickSoftThreshold(datExpr, powerVector = powers, verbose = 5)net = blockwiseModules(datExpr, power = 6, TOMType = &quot;unsigned&quot;, minModuleSize = 30, reassignThreshold = 0, mergeCutHeight = 0.25, numericLabels = TRUE, pamRespectsDendro = FALSE, saveTOMs = TRUE, saveTOMFileBase = &quot;femaleMouseTOM&quot;, verbose = 3)moduleLabels = net$colorsmoduleColors = labels2colors(net$colors)MEs = net$MEs;geneTree = net$dendrograms[[1]] 3.2 Relating consensus modules to female set-specific modules femaleLabels = moduleLabels;femaleColors = moduleColors;femaleTree = geneTree;femaleMEs = orderMEs(MEs, greyName = &quot;ME0&quot;);## Isolate the module labels in the order they appear in ordered module eigengenesfemModuleLabels = substring(names(femaleMEs), 3)consModuleLabels = substring(names(consMEs[[1]]$data), 3)## Convert the numeric module labels to color labelsfemModules = labels2colors(as.numeric(femModuleLabels))consModules = labels2colors(as.numeric(consModuleLabels))## Numbers of female and consensus modulesnFemMods = length(femModules)nConsMods = length(consModules)## Initialize tables of p-values and of the corresponding countspTable = matrix(0, nrow = nFemMods, ncol = nConsMods);CountTbl = matrix(0, nrow = nFemMods, ncol = nConsMods);## Execute all pairwaise comparisonsfor (fmod in 1:nFemMods) for (cmod in 1:nConsMods) { femMembers = (femaleColors == femModules[fmod]); consMembers = (moduleColors == consModules[cmod]); pTable[fmod, cmod] = -log10(fisher.test(femMembers, consMembers, alternative = &quot;greater&quot;)$p.value); CountTbl[fmod, cmod] = sum(femaleColors == femModules[fmod] &amp; moduleColors == consModules[cmod]) }## Truncate p values smaller than 10^{-50} to 10^{-50}pTable[is.infinite(pTable)] = 1.3*max(pTable[is.finite(pTable)]);pTable[pTable&gt;50 ] = 50 ;## Marginal counts (really module sizes)femModTotals = apply(CountTbl, 1, sum)consModTotals = apply(CountTbl, 2, sum)## Actual plottingsizeGrWindow(10,7 );##png(file = &quot;ConsensusVsFemaleModules.png&quot;, wi = 500, he = 400);par(mfrow=c(1,1));par(cex = 1.0);par(mar=c(8, 10.4, 2.7, 1)+0.3);## Use function labeledHeatmap to produce the color-coded table with all the trimmingslabeledHeatmap(Matrix = pTable, xLabels = paste(&quot; &quot;, consModules), yLabels = paste(&quot; &quot;, femModules), colorLabels = TRUE, xSymbols = paste(&quot;Cons &quot;, consModules, &quot;: &quot;, consModTotals, sep=&quot;&quot;), ySymbols = paste(&quot;Fem &quot;, femModules, &quot;: &quot;, femModTotals, sep=&quot;&quot;), textMatrix = CountTbl, colors = greenWhiteRed(100)[50:100], main = &quot;Correspondence of Female set-specific and Female-Male consensus modules&quot;, cex.text = 1.0, cex.lab = 1.0, setStdMargins = FALSE); 4. Consensus module to traits 4.1 Correlation moduleTraitCor = list();moduleTraitPvalue = list();## Calculate the correlationsfor (set in 1:nSets){ moduleTraitCor[[set]] = cor(consMEs[[set]]$data, Traits[[set]]$data, use = &quot;p&quot;); moduleTraitPvalue[[set]] = corPvalueFisher(moduleTraitCor[[set]], exprSize$nSamples[set]);}## Convert numerical lables to colors for labeling of modules in the plotMEColors = labels2colors(as.numeric(substring(names(consMEs[[1]]$data), 3)));MEColorNames = paste(&quot;ME&quot;, MEColors, sep=&quot;&quot;);## Open a suitably sized window (the user should change the window size if necessary)sizeGrWindow(10,7)##png(file = &quot;ModuleTraitRelationships-female.png&quot;, wi = 800, he = 560);## Plot the module-trait relationship table for set number 1set = 1textMatrix = paste(signif(moduleTraitCor[[set]], 2), &quot;\\n(&quot;, signif(moduleTraitPvalue[[set]], 1), &quot;)&quot;, sep = &quot;&quot;);dim(textMatrix) = dim(moduleTraitCor[[set]])par(mar = c(6, 8.8, 3, 2.2));labeledHeatmap(Matrix = moduleTraitCor[[set]], xLabels = names(Traits[[set]]$data), yLabels = MEColorNames, ySymbols = MEColorNames, colorLabels = FALSE, colors = greenWhiteRed(50), textMatrix = textMatrix, setStdMargins = FALSE, cex.text = 0.5, zlim = c(-1,1), main = paste(&quot;Module--trait relationships in&quot;, setLabels[set]))##dev.off(); ## Plot the module-trait relationship table for set number 2set = 2textMatrix = paste(signif(moduleTraitCor[[set]], 2), &quot;\\n(&quot;, signif(moduleTraitPvalue[[set]], 1), &quot;)&quot;, sep = &quot;&quot;);dim(textMatrix) = dim(moduleTraitCor[[set]])sizeGrWindow(10,7)##png(file = &quot;ModuleTraitRelationships-male.png&quot;, wi = 800, he = 560);par(mar = c(6, 8.8, 3, 2.2));labeledHeatmap(Matrix = moduleTraitCor[[set]], xLabels = names(Traits[[set]]$data), yLabels = MEColorNames, ySymbols = MEColorNames, colorLabels = FALSE, colors = greenWhiteRed(50), textMatrix = textMatrix, setStdMargins = FALSE, cex.text = 0.5, zlim = c(-1,1), main = paste(&quot;Module--trait relationships in&quot;, setLabels[set]))dev.off(); ## Initialize matrices to hold the consensus correlation and p-valueconsensusCor = matrix(NA, nrow(moduleTraitCor[[1]]), ncol(moduleTraitCor[[1]]));consensusPvalue = matrix(NA, nrow(moduleTraitCor[[1]]), ncol(moduleTraitCor[[1]]));## Find consensus negative correlationsnegative = moduleTraitCor[[1]] &lt; 0 &amp; moduleTraitCor[[2]] &lt; 0;consensusCor[negative] = pmax(moduleTraitCor[[1]][negative], moduleTraitCor[[2]][negative]);consensusPvalue[negative] = pmax(moduleTraitPvalue[[1]][negative], moduleTraitPvalue[[2]][negative]);## Find consensus positive correlationspositive = moduleTraitCor[[1]] &gt; 0 &amp; moduleTraitCor[[2]] &gt; 0;consensusCor[positive] = pmin(moduleTraitCor[[1]][positive], moduleTraitCor[[2]][positive]);consensusPvalue[positive] = pmax(moduleTraitPvalue[[1]][positive], moduleTraitPvalue[[2]][positive]);textMatrix = paste(signif(consensusCor, 2), &quot;\\n(&quot;, signif(consensusPvalue, 1), &quot;)&quot;, sep = &quot;&quot;);dim(textMatrix) = dim(moduleTraitCor[[set]])sizeGrWindow(10,7)png(file = &quot;ModuleTraitRelationships-consensus.png&quot;, wi = 800, he = 560);par(mar = c(6, 8.8, 3, 2.2));labeledHeatmap(Matrix = consensusCor, xLabels = names(Traits[[set]]$data), yLabels = MEColorNames, ySymbols = MEColorNames, colorLabels = FALSE, colors = greenWhiteRed(50), textMatrix = textMatrix, setStdMargins = FALSE, cex.text = 0.5, zlim = c(-1,1), main = paste(&quot;Consensus module--trait relationships across\\n&quot;, paste(setLabels, collapse = &quot; and &quot;))) 4.2 Exporting results of the network analysis file = gzfile(description = &quot;GeneAnnotation.csv.gz&quot;);annot = read.csv(file = file);## Match probes in the data set to the probe IDs in the annotation fileprobes = names(multiExpr[[1]]$data)probes2annot = match(probes, annot$substanceBXH)consMEs.unord = multiSetMEs(multiExpr, universalColors = moduleLabels, excludeGrey = TRUE)GS = list();kME = list();for (set in 1:nSets){ GS[[set]] = corAndPvalue(multiExpr[[set]]$data, Traits[[set]]$data); kME[[set]] = corAndPvalue(multiExpr[[set]]$data, consMEs.unord[[set]]$data);}GS.metaZ = (GS[[1]]$Z + GS[[2]]$Z)/sqrt(2);kME.metaZ = (kME[[1]]$Z + kME[[2]]$Z)/sqrt(2);GS.metaP = 2*pnorm(abs(GS.metaZ), lower.tail = FALSE);kME.metaP = 2*pnorm(abs(kME.metaZ), lower.tail = FALSE);GSmat = rbind(GS[[1]]$cor, GS[[2]]$cor, GS[[1]]$p, GS[[2]]$p, GS.metaZ, GS.metaP);nTraits = checkSets(Traits)$nGenestraitNames = colnames(Traits[[1]]$data)dim(GSmat) = c(nGenes, 6*nTraits)rownames(GSmat) = probes;colnames(GSmat) = spaste( c(&quot;GS.set1.&quot;, &quot;GS.set2.&quot;, &quot;p.GS.set1.&quot;, &quot;p.GS.set2.&quot;, &quot;Z.GS.meta.&quot;, &quot;p.GS.meta&quot;), rep(traitNames, rep(6, nTraits)))## Same code for kME:kMEmat = rbind(kME[[1]]$cor, kME[[2]]$cor, kME[[1]]$p, kME[[2]]$p, kME.metaZ, kME.metaP);MEnames = colnames(consMEs.unord[[1]]$data);nMEs = checkSets(consMEs.unord)$nGenesdim(kMEmat) = c(nGenes, 6*nMEs)rownames(kMEmat) = probes;colnames(kMEmat) = spaste( c(&quot;kME.set1.&quot;, &quot;kME.set2.&quot;, &quot;p.kME.set1.&quot;, &quot;p.kME.set2.&quot;, &quot;Z.kME.meta.&quot;, &quot;p.kME.meta&quot;), rep(MEnames, rep(6, nMEs)))info = data.frame(Probe = probes, GeneSymbol = annot$gene_symbol[probes2annot], EntrezID = annot$LocusLinkID[probes2annot], ModuleLabel = moduleLabels, ModuleColor = labels2colors(moduleLabels), GSmat, kMEmat);write.csv(info, file = &quot;consensusAnalysis-CombinedNetworkResults.csv&quot;, row.names = FALSE, quote = FALSE); 5. Relationships among modules and traits ## Create a variable weight that will hold just the body weight of mice in both setsweight = vector(mode = &quot;list&quot;, length = nSets);for (set in 1:nSets){ weight[[set]] = list(data = as.data.frame(Traits[[set]]$data$weight_g)); names(weight[[set]]$data) = &quot;weight&quot;}## Recalculate consMEs to give them color namesconsMEsC = multiSetMEs(multiExpr, universalColors = moduleColors);## We add the weight trait to the eigengenes and order them by consesus hierarchical clustering:MET = consensusOrderMEs(addTraitToMEs(consMEsC, weight));sizeGrWindow(8,10);##png(file = &quot;EigengeneNetworks.png&quot;, width= 480, height = 600);par(cex = 0.9)plotEigengeneNetworks(MET, setLabels, marDendro = c(0,2,2,1), marHeatmap = c(3,3,2,1), zlimPreservation = c(0.5, 1), xLabelsAngle = 90)## dev.off();","link":"/2020/06/10/R/WGCNA_2/"},{"title":"Fonts family in R plot","text":"Switch Fonts in R library(showtext) reference: 王诗翔 2018 Quick Start library(showtext)showtext_auto() Checking local fonts font.paths()font.files()````&lt;pre&gt;'fond.paths()' is now renamed to 'font_paths()'The old version still works, but consider using the new function in future code [1] &quot;/home/ken/.fonts&quot; &quot;/usr/local/share/fonts&quot; &quot;/usr/local/share/fonts/conkycolors&quot; &quot;/usr/share/fonts&quot; [5] &quot;/usr/share/fonts/cmap&quot; &quot;/usr/share/fonts/cMap&quot; &quot;/usr/share/fonts/cmap/adobe-cns1&quot; &quot;/usr/share/fonts/cmap/adobe-gb1&quot; [9] &quot;/usr/share/fonts/cmap/adobe-japan1&quot; &quot;/usr/share/fonts/cmap/adobe-japan2&quot; &quot;/usr/share/fonts/cmap/adobe-korea1&quot; &quot;/usr/share/fonts/deepin-font-install&quot; [13] &quot;/usr/share/fonts/eot&quot; &quot;/usr/share/fonts/eot/font-awesome&quot; &quot;/usr/share/fonts/opentype&quot; &quot;/usr/share/fonts/opentype/cantarell&lt;/pre&gt;&lt;pre&gt;'font.files()' is now renamed to 'font_files()'The old version still works, but consider using the new function in future code path file family face1 /home/ken/.fonts AvantGarde_LT_Medium.ttf AvantGarde LT Medium Regular2 /home/ken/.fonts GE_Inspira.ttf GE Inspira Regular3 /home/ken/.fonts Ubuntu.ttf Ubuntu Regular4 /usr/local/share/fonts/conkycolors aClock_Hour.ttf aClock _Hour5 /usr/local/share/fonts/conkycolors aClock_Min.ttf aClock _Min&lt;/pre&gt;## Plot```rlibrary(showtext)font_add_google(&quot;Lobster&quot;, &quot;lobster&quot;)showtext_auto()plot(1, pch = 16, cex = 3)text(1, 1.1, &quot;A fancy dot&quot;, family = &quot;lobster&quot;, col = &quot;steelblue&quot;, cex = 3) © 王诗翔 2018","link":"/2020/09/03/R/fonts/"},{"title":"geom Extra Lines| Adding a line in ggplot","text":"geom_vline()geom_hline()geom_abline() library(ggplot2)library(patchwork)P1 &lt;- ggplot(mtcars)+ geom_point(aes(mpg, cyl)) + geom_vline( xintercept = 20) + ggtitle('vline') +theme_light()P2 &lt;- ggplot(mtcars)+ geom_point(aes(mpg, cyl)) +geom_hline( yintercept = 7) + ggtitle('hline') +theme_light()P3 &lt;- ggplot(mtcars, aes(wt, mpg)) + geom_point() + geom_abline(intercept = 25, slope = -1) + ggtitle(&quot;abline&quot;)+theme_light()P3|(P1/P2) More","link":"/2020/06/19/R/geom-Extra-Lines/"},{"title":"clusterProfiler","text":"clusterProfiler Tutorial: yulab Install BiocManager::install(&quot;clusterProfiler&quot;) Enrichment analysis and GSEA Enrichment analysis is a computational method used in bioinformatics to determine whether a given set of genes or proteins is enriched for specific functions, pathways, or biological processes. It involves comparing the input gene set to a reference database, such as Gene Ontology, KEGG, or Reactome, and identifying the over-represented terms using statistical methods. Gene Set Enrichment Analysis (GSEA) is a type of enrichment analysis that determines whether a particular gene set shows statistically significant differences between two biological states. Unlike traditional enrichment analysis, GSEA considers the entire gene set, rather than individual genes, and evaluates whether the gene set is significantly enriched at the top or bottom of a ranked list of genes based on their differential expression or correlation with a phenotype. GSEA is commonly used in transcriptomics and genomics studies to identify pathways or biological processes that are differentially regulated between disease and control samples. © ChatGPT Go ontology GO_1. Supported Organism For module species which added in OrgDb, we can turn the ID to GO_id; For other species, you can build your own OrgDb database by following GOSemSim. If genes are already annotated (in data.frame witch gene ID column followed by GO ID), we can use enricher() and geosGO() function to perform over-representation test. GO_2. Example for OrgDb species library(clusterProfiler)library(org.Hs.eg.db)data(geneList, package=&quot;DOSE&quot;)gene &lt;- names(geneList)[abs(geneList) &gt; 2]gene.df &lt;- bitr(gene, fromType = &quot;ENTREZID&quot;, toType = c(&quot;ENSEMBL&quot;, &quot;SYMBOL&quot;), OrgDb = org.Hs.eg.db)head(gene.df) ENTREZID ENSEMBL SYMBOL1 4312 ENSG00000196611 MMP12 8318 ENSG00000093009 CDC453 10874 ENSG00000109255 NMU4 55143 ENSG00000134690 CDCA85 55388 ENSG00000065328 MCM106 991 ENSG00000117399 CDC20 4312 8318 ACCNUM AAA35699 NP_001139410 ENTREZID ENSG00000196611 ENSG00000093009 ENSEMBL SYMBOL MMP1 CDC45 ggo &lt;- groupGO(gene = gene, OrgDb = org.Hs.eg.db, ont = &quot;CC&quot;, level = 3, readable = TRUE)head(ggo)barplot(ggo, showCategory = 20) ID Description Count GeneRatioGO:0005886 GO:0005886 plasma membrane 55 55/207GO:0005628 GO:0005628 prospore membrane 0 0/207GO:0005789 GO:0005789 endoplasmic reticulum membrane 8 8/207... GO_3. Over-Representation Test ego &lt;- enrichGO(gene = gene, universe = names(geneList), OrgDb = org.Hs.eg.db, ont = &quot;CC&quot;, pAdjustMethod = &quot;BH&quot;, pvalueCutoff = 0.01, qvalueCutoff = 0.05, readable = TRUE)head(ego) ego2 &lt;- enrichGO(gene = gene.df$ENSEMBL, OrgDb = org.Hs.eg.db, keyType = 'ENSEMBL', ont = &quot;CC&quot;, pAdjustMethod = &quot;BH&quot;, pvalueCutoff = 0.01, qvalueCutoff = 0.05)## turn ENSEMBL ID to Sambleego2_r &lt;- setReadable(ego2, OrgDb = org.Hs.eg.db)dotplot(ego2) ego ego2 GO_4 GO Gene Set Enrichment Analysis ego3 &lt;- gseGO(geneList = geneList, OrgDb = org.Hs.eg.db, ont = &quot;CC&quot;, nPerm = 1000, minGSSize = 100, maxGSSize = 500, pvalueCutoff = 0.05, verbose = FALSE)dotplot(ego3) ID Description setSize enrichmentScore NES pvalue p.adjust qvalues rank leading_edge GO:0031012 GO:0031012 extracellular matrix 427 -0.4868578 -2.138854 0.001231527 0.03095063 0.02171974 1797 tags=37%, list=14%, signal=33% GO:0099568 GO:0099568 cytoplasmic region 368 -0.3426037 -1.488559 0.001259446 0.03095063 0.02171974 2613 tags=28%, list=21%, signal=23% GO ontology for Non-module Species KEGG Enrichment KE_1. Over-Representation Test library(clusterProfiler)search_kegg_organism('ece', by='kegg_code')ecoli &lt;- search_kegg_organism('Escherichia coli', by='scientific_name')dim(ecoli) data(geneList, package=&quot;DOSE&quot;)gene &lt;- names(geneList)[abs(geneList) &gt; 2]kk &lt;- enrichKEGG(gene = gene, organism = 'hsa', pvalueCutoff = 0.05)head(kk) ID Description GeneRatio BgRatio pvalue p.adjust qvalue geneID Count hsa04110 hsa04110 Cell cycle 11/93 124/8031 1.590786e-07 3.213388e-05 3.148083e-05 8318/991/9133/890/983/4085/7272/1111/891/4174/9232 11 hsa04114 hsa04114 Oocyte meiosis 10/93 128/8031 1.960649e-06 1.980256e-04 1.940011e-04 991/9133/983/4085/51806/6790/891/9232/3708/5241 10 hsa04218 hsa04218 Cellular senescence 10/93 160/8031 1.450991e-05 9.375595e-04 9.185054e-04 2305/4605/9133/890/983/51806/1111/891/776/3708 10 hsa04061 hsa04061 Viral protein interaction with cytokine and cytokine receptor 8/93 100/8031 1.856553e-05 9.375595e-04 9.185054e-04 3627/10563/6373/4283/6362/6355/9547/1524 8 hsa03320 hsa03320 PPAR signaling pathway 7/93 77/8031 2.765640e-05 1.117319e-03 1.094611e-03 4312/9415/9370/5105/2167/3158/5346 7 hsa04914 hsa04914 Progesterone-mediated oocyte maturation 7/93 99/8031 1.392778e-04 4.689019e-03 4.593724e-03 9133/890/983/4085/6790/891/5241 7 KE_2. Gene Set Enrichment Analysis kk2 &lt;- gseKEGG(geneList = geneList, organism = 'hsa', nPerm = 1000, minGSSize = 120, pvalueCutoff = 0.05, verbose = FALSE)head(kk2) ID Description setSize enrichmentScore NES pvalue p.adjust qvalues rank leading_edgehsa04510 hsa04510 Focal adhesion 190 -0.4169068 -1.697372 0.001418440 0.0241065 0.01552815 2183 tags=27%, list=17%, signal=22%hsa03013 hsa03013 RNA transport 131 0.4116488 1.742019 0.003067485 0.0241065 0.01552815 3383 tags=40%, list=27%, signal=29%hsa05152 hsa05152 Tuberculosis 162 0.3745153 1.628558 0.003164557 0.0241065 0.01552815 2823 tags=34%, list=23%, signal=27%hsa04218 hsa04218 Cellular senescence 143 0.4153718 1.761689 0.003225806 0.0241065 0.01552815 1155 tags=17%, list=9%, signal=16%hsa05203 hsa05203 Viral carcinogenesis 164 0.3523856 1.535177 0.003246753 0.0241065 0.01552815 3112 tags=35%, list=25%, signal=26%hsa04062 hsa04062 Chemokine signaling pathway 165 0.3754101 1.632867 0.003300330 0.0241065 0.01552815 1298 tags=21%, list=10%, signal=19% kk kk2 KE_3. KEGG Module over-representation test mkk &lt;- enrichMKEGG(gene = gene, organism = 'hsa') KE_4. KEGG Module Gene Set Enrichment Analysis mkk2 &lt;- gseMKEGG(geneList = geneList, organism = 'hsa') A Pipeline Example Result from: edgeR species: dme library(clusterProfiler)library(org.Dm.eg.db)library(pathview)library(reshape2)library(stringr)library(ggplot2)library(enrichplot)args = commandArgs(trailingOnly=TRUE)SampleA= args[1]#&quot;G1F1&quot;SampleB= args[2]#&quot;G50F&quot;Pvalue = 0.01logFC= 2C_cut = 10Level= 2Sample_Dir = paste(SampleA,&quot;_VS_&quot;,SampleB,&quot;/&quot;,sep=&quot;&quot;)for(i in c(&quot;GO&quot;, &quot;KEGG&quot;, &quot;WIKI&quot;, &quot;Reactome&quot;)){ dir.create(i) dir.create(paste(i, Sample_Dir,sep='/'))}Gene_list &lt;- read.table(paste(&quot;RSEM_transcript/transcript.isoform.counts.matrix.&quot;, SampleA, &quot;_vs_&quot;, SampleB,&quot;.edgeR.DE_results&quot;, sep=&quot;&quot;))ENTREZID = bitr(row.names(Gene_list), fromType=&quot;FLYBASE&quot;, toType=&quot;ENTREZID&quot;, OrgDb=&quot;org.Dm.eg.db&quot;)FLYBASECG = bitr(row.names(Gene_list), fromType=&quot;FLYBASE&quot;, toType=&quot;FLYBASECG&quot;, OrgDb=&quot;org.Dm.eg.db&quot;)SYMBOL = bitr(row.names(Gene_list), fromType=&quot;FLYBASE&quot;, toType=&quot;SYMBOL&quot;, OrgDb=&quot;org.Dm.eg.db&quot;)Gene_list$ENTREZID &lt;- ENTREZID$ENTREZID[match(row.names(Gene_list), ENTREZID$FLYBASE)]Gene_list$FLYBASECG &lt;- FLYBASECG$FLYBASECG[match(row.names(Gene_list), FLYBASECG$FLYBASE)]Gene_list$SYMBOL &lt;- SYMBOL$SYMBOL[match(row.names(Gene_list), SYMBOL$FLYBASE)]KE2SY &lt;-function(kk_GSEA, COL){ if( nrow(kk_GSEA@result) &gt;0){ for(i in c(1:nrow(kk_GSEA@result))){ LIST &lt;- kk_GSEA@result[[COL]][i] kk_GSEA@result[[COL]][i] &lt;- paste(Gene_list$SYMBOL[match(str_remove(str_split(LIST, &quot;/&quot;)[[1]], &quot;Dmel_&quot;),Gene_list$FLYBASECG )], collapse = &quot;/&quot;) } } return(kk_GSEA)}EN2SY &lt;-function(WikiP_enrich, COL){ if(length(WikiP_enrich@result[[COL]])&gt;0){ for(i in c(1:length(WikiP_enrich@result[[COL]]))){ LIST &lt;- WikiP_enrich@result[[COL]][i] WikiP_enrich@result[[COL]][i] &lt;- paste(Gene_list$SYMBOL[match(str_remove(str_split(LIST, &quot;/&quot;)[[1]], &quot;Dmel_&quot;),Gene_list$ENTREZID )], collapse = &quot;/&quot;) } } return(WikiP_enrich)}ggsave_GO &lt;- function(NAME, LEN){ BASE = 3.8 RATE = 0.125 if (BASE + RATE*LEN &lt;= 40){ W = BASE + RATE*LEN }else{ W = 40 } ggsave(NAME , w = W, h = 8.35, limitsize = FALSE )}ggsave_GO_enrich &lt;- function(NAME, LEN){ BASE = 2 RATE = 0.1114 if (BASE + RATE*LEN &lt;= 40){ H = BASE + RATE*LEN }else{ H = 40 } ggsave(NAME , w = 10, h = H, limitsize = FALSE)}ridgeplot_save &lt;- function(NAME,LEN){ BASE = 1.02 RATE = 0.2 if (BASE + RATE*LEN &lt;= 40){ H = BASE + RATE*LEN }else{ H = 40 } ggsave(NAME , w = 10, h = H, limitsize = FALSE)}## GO ontologyTMP &lt;- Gene_list[abs(Gene_list$logFC) &gt;=2,]TMP &lt;- TMP[TMP$PValue &lt;= Pvalue,]sig_genes = TMP$ENTREZIDgooc &lt;- groupGO(gene = sig_genes, OrgDb = org.Dm.eg.db, ont = &quot;CC&quot;, level = Level, readable = TRUE)goom &lt;- groupGO(gene = sig_genes, OrgDb = org.Dm.eg.db, ont = &quot;MF&quot;, level = Level, readable = TRUE)goob &lt;- groupGO(gene = sig_genes, OrgDb = org.Dm.eg.db, ont = &quot;BP&quot;, level = Level, readable = TRUE)gooc@result$Group = &quot;CC&quot;goom@result$Group = &quot;MF&quot;goob@result$Group = &quot;BP&quot;GO_TB &lt;- rbind(gooc@result, goom@result, goob@result)GO_TB &lt;- GO_TB[GO_TB$Count!=0,]File_name = paste(&quot;Ontology&quot;, SampleA,SampleB,Pvalue, logFC, sep=&quot;_&quot; )write.csv(GO_TB, paste(&quot;GO/&quot;,Sample_Dir, File_name, &quot;.csv&quot;, sep=&quot;&quot; ), row.names=F)# [GO ontology plot]ggplot(GO_TB, aes(x=Description, y=Count, fill=Group)) + geom_bar(stat = 'identity') + facet_grid(~Group, scales = 'free', space = 'free') + theme_bw() + theme(axis.text.x = element_text(angle = 270, hjust = 0, vjust = .5), legend.position = 'none', panel.grid = element_blank(), strip.background = element_rect(fill = 'white'))ggsave_GO(paste(&quot;GO/&quot;, Sample_Dir, File_name, &quot;.png&quot;, sep=&quot;&quot; ), nrow(GO_TB))## OverrepresentationFile_name = paste(&quot;Enrichment&quot;, SampleA,SampleB,Pvalue, logFC, sep=&quot;_&quot; )ego &lt;- enrichGO(gene = sig_genes, universe = Gene_list$ENTREZID, OrgDb = org.Dm.eg.db, ont = &quot;All&quot;, pAdjustMethod = &quot;BH&quot;, pvalueCutoff = 0.01, qvalueCutoff = 0.05, readable = TRUE)head(ego)SIZE = as.numeric(as.character(as.data.frame(str_split_fixed(ego@result$GeneRatio, &quot;/&quot;,2))[[1]]))/as.numeric(as.character(as.data.frame(str_split_fixed(ego@result$BgRatio, &quot;/&quot;,2))[[1]]))ego@result$size = SIZEwrite.csv(ego, paste(&quot;GO/&quot;, Sample_Dir, File_name, &quot;.csv&quot;, sep=&quot;&quot; ), row.names=F)# [GO Enrichment plot]ggplot(ego@result, aes(x=Count, y=Description)) + geom_point(aes(size=size, color=pvalue)) + theme_bw() + facet_grid(ONTOLOGY~., space = 'free', scales = 'free')ggsave_GO_enrich(paste(&quot;GO/&quot;, Sample_Dir, File_name, &quot;.png&quot;, sep=&quot;&quot; ), nrow(ego@result))geneList &lt;- Gene_list$logFCnames(geneList) &lt;- Gene_list$ENTREZIDgeneList &lt;- sort(geneList, decreasing = T)for(GROUP in c(&quot;CC&quot;, &quot;BP&quot;, &quot;MF&quot;)){ egocc &lt;- enrichGO(gene = sig_genes, universe = Gene_list$ENTREZID, OrgDb = org.Dm.eg.db, ont = GROUP, pAdjustMethod = &quot;BH&quot;, pvalueCutoff = 0.01, qvalueCutoff = 0.05, readable = TRUE) write.csv(egocc, paste(&quot;GO/&quot;,Sample_Dir, File_name, &quot;_&quot;, GROUP, &quot;.csv&quot;, sep=&quot;&quot; ), row.names=F) # [GO Network category] Plot_and_Save &lt;-function(){ goplot(egocc) ggsave( paste(&quot;GO/&quot;,Sample_Dir, File_name, &quot;_&quot;, GROUP, &quot;_category&quot;, &quot;.png&quot;, sep=&quot;&quot; ), w = 20, h = 10.9 ) # [GO Network Genes] cnetplot(egocc, foldChange=geneList) ggsave( paste(&quot;GO/&quot;, Sample_Dir, File_name, &quot;_&quot;, GROUP, &quot;_genes&quot;, &quot;.png&quot;, sep=&quot;&quot; ), w = 20, h = 10.9 ) } try(Plot_and_Save(),silent=TRUE)}# GO Gene Set Enrichment AnalysisFile_name = paste(&quot;GSEA&quot;,Pvalue, logFC, sep=&quot;_&quot; )for(GROUP in c(&quot;CC&quot;, &quot;BP&quot;, &quot;MF&quot;)){ GOgse_CC &lt;- gseGO(geneList = geneList, OrgDb = org.Dm.eg.db, ont = GROUP, minGSSize = 100, maxGSSize = 500, eps = 1e-10, pvalueCutoff = 0.05, verbose = FALSE) write.csv(GOgse_CC, paste(&quot;GO/&quot;,Sample_Dir, File_name, &quot;_&quot;, GROUP, &quot;.csv&quot;, sep=&quot;&quot; ), row.names=F) ridgeplot(GOgse_CC) ridgeplot_save(paste(&quot;GO/&quot;,Sample_Dir, File_name, &quot;_&quot;, GROUP,&quot;_ridgeplot.png&quot;, sep=&quot;&quot; ), nrow(GOgse_CC@result)) Plot_and_Save &lt;-function(){ goplot(GOgse_CC) ggsave( paste(&quot;GO/&quot;,Sample_Dir, File_name, &quot;_&quot;, GROUP, &quot;_category&quot;, &quot;.png&quot;, sep=&quot;&quot; ), w = 20, h = 10.9 ) cnetplot(GOgse_CC, foldChange=geneList) ggsave( paste(&quot;GO/&quot;,Sample_Dir, File_name, &quot;_&quot;, GROUP, &quot;_genes&quot;, &quot;.png&quot;, sep=&quot;&quot; ), w = 20, h = 10.9 ) } try(Plot_and_Save(),silent=TRUE) # [GO GSEA upsetplot] upsetplot(GOgse_CC) ggsave( paste(&quot;GO/&quot;,Sample_Dir, File_name, &quot;_&quot;, GROUP, &quot;_upset&quot;, &quot;.png&quot;, sep=&quot;&quot; ), w = 20, h = 10.9 ) # [GO GSEA Escore] for (i in c(1:nrow(GOgse_CC@result))){ gseaplot2(GOgse_CC, geneSetID = i, title = GOgse_CC$Description[i], color = 'salmon', pvalue_table = TRUE) ggsave(paste(&quot;GO/&quot;,Sample_Dir, File_name, &quot;_&quot;, str_split(GOgse_CC@result$ID[i],&quot;:&quot;)[[1]][2], &quot;_GSEA&quot;, &quot;.png&quot;, sep=&quot;&quot; ), w = 7.5, h = 5) }}########################### KEGG ########################### gene set enrichment analysisFile_name = paste(&quot;GSEA&quot;,Pvalue, logFC, sep=&quot;_&quot; )geneList_kk &lt;- Gene_list$logFCnames(geneList_kk) &lt;- paste(&quot;Dmel&quot;, Gene_list$FLYBASECG, sep=&quot;_&quot;)geneList_kk &lt;- sort(geneList_kk, decreasing = T)kk_GSEA &lt;- gseKEGG(geneList = geneList_kk, organism = 'dme', minGSSize = 10, pvalueCutoff = 0.05, verbose = FALSE)for (i in c(1:nrow(kk_GSEA@result))){ gseaplot2(kk_GSEA, geneSetID = i, title = kk_GSEA$Description[i], color = 'salmon', pvalue_table = TRUE) ggsave(paste(&quot;KEGG/&quot;,Sample_Dir, File_name, &quot;_&quot;, kk_GSEA@result$ID[i], &quot;_GSEA&quot;, &quot;.png&quot;, sep=&quot;&quot; ), w = 7.5, h = 5)}kk_GSEA2 &lt;- KE2SY(kk_GSEA, &quot;core_enrichment&quot;)write.csv(kk_GSEA2, paste(&quot;KEGG/&quot;,Sample_Dir, File_name, &quot;.csv&quot;, sep=&quot;&quot; ), row.names=F)geneList_smb &lt;- Gene_list$logFCnames(geneList_smb) &lt;-Gene_list$SYMBOLgeneList_smb &lt;- sort(geneList_smb, decreasing = T)Plot_and_Save &lt;-function(){ cnetplot(kk_GSEA2, foldChange=geneList_smb) ggsave( paste(&quot;KEGG/&quot;,Sample_Dir, File_name, &quot;_genes&quot;, &quot;.png&quot;, sep=&quot;&quot; ), w = 20, h = 10.9 )}try(Plot_and_Save(),silent=TRUE)sig_genes_kk = paste(&quot;Dmel&quot;, TMP$FLYBASECG, sep=&quot;_&quot;)# over-representation analysisFile_name = paste(&quot;Enrichment&quot;, Pvalue, logFC, sep=&quot;_&quot; )kk_Enrich &lt;- enrichKEGG(gene = sig_genes_kk, universe = names(geneList_kk), organism = 'dme', pvalueCutoff = 0.05)write.csv(kk_Enrich, paste(&quot;KEGG/&quot;,Sample_Dir, File_name, &quot;.csv&quot;, sep=&quot;&quot; ), row.names=F)ggplot(kk_Enrich@result, aes(x=Count, y=Description)) + geom_point(aes(size=GeneRatio, color=pvalue)) + theme_bw()ggsave_GO_enrich(paste(&quot;KEGG/&quot;,Sample_Dir, File_name, &quot;.png&quot;, sep=&quot;&quot; ), nrow(kk_Enrich@result))Plot_and_Save &lt;-function(){ cnetplot(kk_Enrich, foldChange=geneList_kk) ggsave( paste(&quot;KEGG/&quot;,Sample_Dir, File_name, &quot;_genes&quot;, &quot;.png&quot;, sep=&quot;&quot; ), w = 20, h = 10.9 )}try(Plot_and_Save(),silent=TRUE)neList_kk &lt;- Gene_list$logFCnames(geneList_kk) &lt;-Gene_list$ENTREZIDgeneList_kk &lt;- sort(geneList_kk, decreasing = T)library(&quot;pathview&quot;)#dme04624 &lt;- pathview(gene.data = geneList_kk,# pathway.id = &quot;04624&quot;,# species = &quot;dme&quot;,# out.prefix = paste(&quot;KEGG/&quot;,Sample_Dir, sep=&quot;&quot;),# limit =2.5)## WikiPathwaysFile_name = paste(&quot;Enrichment&quot;, Pvalue, logFC, sep=&quot;_&quot; )WikiP_enrich &lt;- enrichWP(sig_genes, universe = names(geneList_kk), organism = &quot;Drosophila melanogaster&quot;)ggplot(WikiP_enrich@result, aes(x=Count, y=Description)) + geom_point(aes(size=GeneRatio, color=pvalue)) + theme_bw()ggsave_GO_enrich(paste(&quot;WIKI/&quot;,Sample_Dir, File_name, &quot;.png&quot;, sep=&quot;&quot; ), nrow(kk_Enrich@result))WikiP_enrich2 &lt;- EN2SY(WikiP_enrich, &quot;geneID&quot;)write.csv(WikiP_enrich2@result, paste(&quot;WIKI/&quot;,Sample_Dir, File_name, &quot;.csv&quot;, sep=&quot;&quot; ), row.names=F)Plot_and_Save &lt;-function(){ cnetplot(WikiP_enrich2, foldChange=geneList_smb) ggsave( paste(&quot;WIKI/&quot;,Sample_Dir, File_name, &quot;_genes&quot;, &quot;.png&quot;, sep=&quot;&quot; ), w = 20, h = 10.9 )}try(Plot_and_Save(),silent=TRUE)File_name = paste(&quot;GSEA&quot;,Pvalue, logFC, sep=&quot;_&quot; )WikiP_gse &lt;- gseWP(geneList, organism = &quot;Drosophila melanogaster&quot;)WikiP_gse2 &lt;- EN2SY(WikiP_gse, &quot;core_enrichment&quot;)if (nrow(WikiP_gse@result) &gt;0 ){ for (i in c(1:nrow(WikiP_gse@result))){ gseaplot2(WikiP_gse, geneSetID = i, title = WikiP_gse$Description[i], color = 'salmon', pvalue_table = TRUE) ggsave(paste(&quot;WIKI/&quot;,Sample_Dir, File_name, &quot;_&quot;, WikiP_gse@result$ID[i], &quot;_GSEA&quot;, &quot;.png&quot;, sep=&quot;&quot; ), w = 7.5, h = 5) }}write.csv(WikiP_gse2@result, paste(&quot;WIKI/&quot;,Sample_Dir, File_name, &quot;.csv&quot;, sep=&quot;&quot; ), row.names=F)Plot_and_Save &lt;-function(){ ridgeplot(WikiP_gse) ridgeplot_save(paste(&quot;WIKI/&quot;,Sample_Dir, File_name, &quot;_&quot;, GROUP,&quot;_ridgeplot.png&quot;, sep=&quot;&quot; ), nrow(WikiP_gse@result))}try(Plot_and_Save(),silent=TRUE)## Reactome Pathwaylibrary(ReactomePA)File_name = paste(&quot;Enrichment&quot;, Pvalue, logFC, sep=&quot;_&quot; )Reactome_enrich &lt;- enrichPathway(gene= sig_genes, pvalueCutoff = 0.05, readable=TRUE, organism =&quot;fly&quot;, universe = names(geneList))write.csv(Reactome_enrich, paste(&quot;Reactome/&quot;,Sample_Dir, File_name, &quot;.csv&quot;, sep=&quot;&quot; ), row.names=F)Reactome_enrich@result &lt;- Reactome_enrich@result[Reactome_enrich@result$pvalue&lt;=0.05,]ggplot(Reactome_enrich@result, aes(x=Count, y=Description)) + geom_point(aes(size=GeneRatio, color=pvalue)) + theme_bw()ggsave_GO_enrich(paste(&quot;Reactome/&quot;,Sample_Dir, File_name, &quot;.png&quot;, sep=&quot;&quot; ), nrow(kk_Enrich@result))File_name = paste(&quot;GSEA&quot;,Pvalue, logFC, sep=&quot;_&quot; )Reactome_gse &lt;- gsePathway(geneList, pvalueCutoff = 0.05, organism = &quot;fly&quot;, pAdjustMethod = &quot;BH&quot;)# [Reactome_gse ridgeplot]ridgeplot(Reactome_gse)ridgeplot_save(paste(&quot;Reactome/&quot;,Sample_Dir, File_name, &quot;_&quot;, GROUP,&quot;_ridgeplot.png&quot;, sep=&quot;&quot; ), nrow(Reactome_gse@result))write.csv(Reactome_gse, paste(&quot;Reactome/&quot;,Sample_Dir, File_name, &quot;.csv&quot;, sep=&quot;&quot; ), row.names=F)for (i in c(1:nrow(Reactome_gse@result))){ gseaplot2(Reactome_gse, geneSetID = i, title = Reactome_gse$Description[i], color = 'salmon', pvalue_table = TRUE) ggsave(paste(&quot;Reactome/&quot;,Sample_Dir, File_name, &quot;_&quot;, Reactome_gse@result$ID[i], &quot;_GSEA&quot;, &quot;.png&quot;, sep=&quot;&quot; ), w = 7.5, h = 5)} 123 123 GO ontology plot GO Enrichment plot GO Network category GO Network Genes GO GSEA upsetplot GO GSEA Escore pathview Reactome_gse ridgeplot ##################eg#############eg = bitr(x, fromType=&quot;SYMBOL&quot;, toType=&quot;ENTREZID&quot;, OrgDb=&quot;org.Hs.eg.db&quot;)eg = bitr(x, fromType=&quot;ENTREZID&quot;, toType=&quot;SYMBOL&quot;, OrgDb=&quot;org.Hs.eg.db&quot;)head(eg)gene &lt;- eg[[2]]barplot(ggio, drop=TRUE, showCategory=122)########################################################################bitr_kegg: converting biological IDs using KEGG APIdata(x)hg &lt;- x[[1]]head(hg)eg2np &lt;- bitr_kegg(hg, fromType='kegg', toType='ncbi-proteinid', organism='hsa')head(eg2np)bitr_kegg(&quot;Z5100&quot;, fromType=&quot;kegg&quot;, toType='ncbi-geneid', organism='ece')bitr_kegg(&quot;Z5100&quot;, fromType=&quot;kegg&quot;, toType='ncbi-proteinid', organism='ece')bitr_kegg(&quot;Z5100&quot;, fromType=&quot;kegg&quot;, toType='uniprot', organism='ece')############################################################################################ GO classification################################################################################gene &lt;- names(geneList)[abs(geneList) &gt; 2]gobp &lt;- groupGO(gene = gene, OrgDb = org.Hs.eg.db, ont = &quot;BP&quot;, level = 2, readable = TRUE)head(ggo)go &lt;- groupGO(gene = gene, OrgDb = org.Hs.eg.db, ont = &quot;BP&quot;, level = 2, readable = TRUE)barplot(go, drop=TRUE, showCategory=122)##############################GO over-representation test###############################ego1 &lt;- enrichGO(gene =gene, universe= names(geneList), ont = &quot;CC&quot;,pAdjustMethod = &quot;BH&quot;,pvalueCutoff = 0.01,qvalueCutoff = 0.05,readable = TRUE)ego2 &lt;- enrichGO(gene =gene, universe= names(geneList), ont = &quot;BP&quot;,pAdjustMethod = &quot;BH&quot;,pvalueCutoff = 0.01,qvalueCutoff = 0.05,readable = TRUE)ego3 &lt;- enrichGO(gene =gene, universe= names(geneList), ont = &quot;MF&quot;,pAdjustMethod = &quot;BH&quot;,pvalueCutoff = 0.01,qvalueCutoff = 0.05,readable = TRUE)head(ego)#######################################################################################################source(&quot;http://bioconductor.org/biocLite.R&quot;)library(clusterProfiler)library(org.Hs.eg.db)keytypes(org.Hs.eg.db)KEGGkk &lt;- enrichKEGG(gene = gene, organism = 'human', pvalueCutoff = 0.05)head(kk)barplot(kk, drop=TRUE, showCategory=122)kk2 &lt;- gseKEGG(geneList = geneList, organism = 'hsa', nPerm = 1000, minGSSize = 120, pvalueCutoff = 100,verbose = FALSE)ead(kk2)####kk2 &lt;- gseKEGG(geneList = geneList, organism = 'hsa', nPerm = 10, minGSSize = 10, pvalueCutoff = 100,verbose = FALSE)gseaplot(kk2, geneSetID = &quot;hsa05200&quot;)hsa05205hsa05165###############################################################################pathview##################################################################library(clusterProfiler)library(org.Hs.eg.db)library(&quot;pathview&quot;)hsa05418 p &lt;- pathview(gene.data = geneList, pathway.id = &quot;hsa04976&quot;, species = &quot;hsa&quot;, limit = list(gene=max(abs(geneList)), cpd=1))pathview(gene.data = geneList, pathway.id = &quot;hsa04976&quot;, species = &quot;hsa&quot;, limit = list(gene=max(5), cpd=1))pathview(gene.data = geneList, pathway.id = i, species = &quot;hsa&quot;, limit = list(gene=max(5), cpd=1))########################################################################geneList####################################################################d = read.csv(your_csv_file)d = read.table(&quot;geneList&quot;)### assume 1st column is ID### 2nd column is FC### feature 1: numeric vectorgeneList = d[,2]names(geneList) = as.character(d[,1]) ## feature 2: named vectorgeneList = sort(geneList, decreasing = TRUE) ## feature 3: decreasing orderhead(geneList)eg = bitr(x, fromType=&quot;ENTREZID&quot;, toType=&quot;SYMBOL&quot;, annoDb=&quot;org.Hs.eg.db&quot;) p &lt;- pathview(gene.data = geneList, pathway.id = &quot;hsa04668&quot;, species = &quot;hsa&quot;, limit = list(gene=max(abs(geneList)), cpd=1))gene &lt;- names(geneList)[abs(geneList) &gt; 2]gene.df &lt;- bitr(gene, fromType = &quot;ENTREZID&quot;, toType = c(&quot;ENSEMBL&quot;, &quot;SYMBOL&quot;), OrgDb = org.Hs.eg.db)head(gene.df)ego2 &lt;- enrichGO(gene = gene.df$ENSEMBL, OrgDb = org.Hs.eg.db, keytype = 'ENSEMBL', ont = &quot;CC&quot;, pAdjustMethod = &quot;BH&quot;, pvalueCutoff = 0.01, qvalueCutoff = 0.05)ego2 &lt;- setReadable(ego2, OrgDb = org.Hs.eg.db)biocLite(&quot;topGO&quot;)barplot(ggo, drop=TRUE, showCategory=12)################################################################################################################################geneList = d[,2]names(geneList) = as.character(d[,1]) ## feature 2: named vectorgeneList = sort(geneList, decreasing = TRUE) ## feature 3: decreasing orderhead(geneList)kk2 &lt;- gseKEGG(geneList = geneList, organism = 'hsa', nPerm = 1000, minGSSize = 120, pvalueCutoff = 0, verbose = FALSE)gseaplot(kk2, geneSetID = &quot;hsa04668&quot;)###########################write the results#######################write.csv(fortify(kk,showCategory=120),file=&quot;kk.matrix&quot;,quote=F,sep='\\t')##################################a &lt;- c(&quot;3&quot;,&quot;7&quot;,&quot;14&quot;,&quot;21&quot;)b &lt;- read.table(&quot;single_symol.matrix&quot;)for(i in a) { x &lt;- read.table(&quot;3&quot;) probes= x$V1 probes1=match(probes,x$V1) probes2=match(probes,b$V1) sum(is.na(probes1)) sum(is.na(probes1)) List=data.frame(FC=(x$V4[probes1]* -1),S=b$V2[probes2],Co=b$V1[probes2]) List=data.frame(Symbol=List$S, FC=List$FC ) A&lt;- List[order(List[,2],decreasing=F),] write.table(A,file=paste(i,&quot;-tesst.txt&quot;,sep=''),sep='\\t',quote=F,row.names=F) }for (i in b[[1]]) { probes= i probes1= match(probes,b$V1) c=b$V2[probes1] png(file=paste(i,&quot;-&quot;,c,&quot;-GSEA.png&quot;,sep=''),wi=400,he=400) gseaplot(kk2, geneSetID = i,title=paste(c,&quot;0dpeVs7dpe&quot;)) dev.off() } for (i in b[[1]]) { p &lt;- pathview(gene.data = geneList, pathway.id = i, species = &quot;hsa&quot;, limit = list(gene=max(abs(geneList)), cpd=1)) }geneList=data.frame(List=List$Symbol,FC=List$FC* -1) png(file=paste(i,&quot;-&quot;,title,&quot;.png&quot;,sep=''),wi=900,he=900) gseaplot(kk2, geneSetID = i,title= T) dev.off()}a &lt;- read.table(&quot;list&quot;) x &lt;- a[[1]]eg = bitr(x, fromType=&quot;ENTREZID&quot;, toType=&quot;SYMBOL&quot;, annoDb=&quot;org.Hs.eg.db&quot;)dim(eg)write.table(eg,file=&quot;&quot;,row.names=F,quote=F,sep='\\t') Error in installation config.status: creating src/Makevars.tmp config.status: creating src/Makevars config.status: creating src/config.h ** libs gfortran -fno-optimize-sibling-calls -fpic -g -O2 -c AMD/Source/amd.f -o AMD/Source/amd.o make: gfortran: No such file or directory make: *** [/usr/lib64/R/etc/Makeconf:195: AMD/Source/amd.o] Error 127 ERROR: compilation failed for package 'igraph' * removing '/home/karobben/R/x86_64-pc-linux-gnu-library/4.0/igraph' During startup - Warning message: problem: lack of gcc-fortran sudo pacman -S gcc-fortran Error in using fail to download KEGG data... Error in download.KEGG.Path(species) : 'species' should be one of organisms listed in 'http://www.genome.jp/kegg/catalog/org_list.html'... Calls: gseKEGG ... prepare_KEGG -> download_KEGG -> download.KEGG.Path In addition: Warning message: In download.file(url, method = method, ...) : URL 'https://rest.kegg.jp/link/hsa/pathway': status was 'Failure when receiving data from the peer' Execution halted This is such an annoying issue. The weird thing is that everything works fine when I use the code in the terminal, but as soon as I write the code into a script, it just doesn’t seem to work. The author suggests that the issue could be resolved by updating to the latest version. However, this would mean that I would also need to update either the Bioconductor or R base. I don’t want to update anything, I just want the job to be done. Thankfully, Slohr’s answer in 2022 provided a perfect solution to this problem. ## https://www.genome.jp/kegg/rest/keggapi.html## kegg_link('hsa', 'pathway')ttp_kegg_link &lt;- function(target_db, source_db) { url &lt;- paste0(&quot;https://rest.kegg.jp/link/&quot;, target_db, &quot;/&quot;, source_db, collapse=&quot;&quot;) local_mydownload &lt;- function (url, method, quiet = TRUE, ...) { if (capabilities(&quot;libcurl&quot;)) { dl &lt;- tryCatch(utils::download.file(url, quiet = quiet, method = &quot;libcurl&quot;, ...), error = function(e) NULL) } else { dl &lt;- tryCatch(downloader::download(url, quiet = TRUE, method = method, ...), error = function(e) NULL) } return(dl) } local_kegg_rest &lt;- function (rest_url) { message(&quot;Reading KEGG annotation online:\\n&quot;) f &lt;- tempfile() dl &lt;- local_mydownload(rest_url, destfile = f) if (is.null(dl)) { message(&quot;fail to download KEGG data...&quot;) return(NULL) } content &lt;- readLines(f) content %&lt;&gt;% strsplit(., &quot;\\t&quot;) %&gt;% do.call(&quot;rbind&quot;, .) res &lt;- data.frame(from = content[, 1], to = content[, 2]) return(res) } local_kegg_rest(url)}ttp_kegg_list &lt;- function(db) { url &lt;- paste0(&quot;https://rest.kegg.jp/list/&quot;, db, collapse=&quot;&quot;) local_mydownload &lt;- function (url, method, quiet = TRUE, ...) { if (capabilities(&quot;libcurl&quot;)) { dl &lt;- tryCatch(utils::download.file(url, quiet = quiet, method = &quot;libcurl&quot;, ...), error = function(e) NULL) } else { dl &lt;- tryCatch(downloader::download(url, quiet = TRUE, method = method, ...), error = function(e) NULL) } return(dl) } local_kegg_rest &lt;- function (rest_url) { message(&quot;Reading KEGG annotation online:\\n&quot;) f &lt;- tempfile() dl &lt;- local_mydownload(rest_url, destfile = f) if (is.null(dl)) { message(&quot;fail to download KEGG data...&quot;) return(NULL) } content &lt;- readLines(f) content %&lt;&gt;% strsplit(., &quot;\\t&quot;) %&gt;% do.call(&quot;rbind&quot;, .) res &lt;- data.frame(from = content[, 1], to = content[, 2]) return(res) } local_kegg_rest(url)}rlang::env_unlock(env = asNamespace('clusterProfiler'))rlang::env_binding_unlock(env = asNamespace('clusterProfiler'))assign('kegg_link', ttp_kegg_link, envir = asNamespace('clusterProfiler'))assign('kegg_list', ttp_kegg_list, envir = asNamespace('clusterProfiler'))rlang::env_binding_lock(env = asNamespace('clusterProfiler'))rlang::env_lock(asNamespace('clusterProfiler'))","link":"/2020/06/14/R/clusterProfiler/"},{"title":"Understanding the geom_point Function in ggplot2","text":"Introduction Data visualization is an essential aspect of data analysis, allowing us to understand patterns, trends, and relationships in our data. In R, one of the most popular packages for data visualization is ggplot2. Among its many functions, geom_point stands out as a fundamental tool for creating scatter plots. In this blog post, we’ll delve deep into the geom_point function, exploring its basic grammar and how to customize the appearance of points in your plots. Basic Grammar and Code Example The basic grammar of geom_point is straightforward. At its core, you need a dataset and aesthetic mappings. The x and y aesthetics are the most common mappings used with geom_point. Here’s a simple example: library(ggplot2)# Sample datadata &lt;- data.frame( x = rnorm(100), y = rnorm(100))# Basic scatter plotggplot(data, aes(x=x, y=y)) + geom_point() This code will produce a scatter plot with the x and y values from our sample data. Customizing Point Appearance Changing Point Color You can change the color of the points using the color argument inside the aes() function: ggplot(data, aes(x=x, y=y, color=&quot;white&quot;)) + geom_point() If you want to color points based on a variable, you can do so by mapping that variable to the color aesthetic: data$group &lt;- sample(c(&quot;A&quot;, &quot;B&quot;), 100, replace = TRUE)ggplot(data, aes(x=x, y=y, color=group)) + geom_point() + theme_bw() Show the name of group on the center of scatter points data_group &lt;- aggregate(cbind(x, y) ~ group, data=data, FUN=median)ggplot(data, aes(x=x, y=y, color=group)) + geom_point() + theme_bw() + geom_label(data = data_group, aes( label = group)) Changing Point Size To change the size of the points, use the size argument: ggplot(data, aes(x=x, y=y)) + geom_point(size=3) Changing Point Shape ggplot2 provides various shapes for points. You can change the shape using the shape argument: ggplot(data, aes(x=x, y=y)) + geom_point(shape=17) Shapes are represented by numbers. For example, 16 is a solid circle, 17 is a triangle, and so on. You can explore the ?points documentation in R to see a list of available shapes. Conclusion The geom_point function in ggplot2 offers a flexible and powerful way to create scatter plots in R. With just a few lines of code, you can produce a basic plot, and with a few more tweaks, you can customize it to your liking. As you continue your data visualization journey, remember that the key is not just to make plots look good, but to make them convey the right information effectively. pre { background-color:#38393d; color: #5fd381; }","link":"/2023/10/04/R/geom-point/"},{"title":"geom_bin2d | ggplot example2","text":"Quick Start library(ggplot2)library(ggthemes)world &lt;- map_data(&quot;world&quot;)ggplot(world, aes(long, lat)) + geom_bin2d() + theme_map() Arguments bins x=y=bins+1 library(patchwork)P1 &lt;- ggplot(world, aes( long, lat)) +geom_bin2d(bins = 10) + theme_map() + ggtitle('bins=10')+ theme(plot.title = element_text(hjust=0.5,size=20))P2 &lt;- ggplot(world, aes( long, lat)) +geom_bin2d(bins = 100) + theme_map() + ggtitle('bins=100')+ theme(plot.title = element_text(hjust=0.5,size=20))P1/P2 binwidth library(RColorBrewer)library(patchwork)colorRampPalette(rev(brewer.pal(n = 7,name = &quot;RdYlBu&quot;))) -&gt; ccP1 &lt;- ggplot(world, aes( long, lat)) +geom_bin2d(binwidth = c(0.1, 0.1))+ theme_map() +ggtitle('0.1 0.1')+ theme(plot.title = element_text(hjust=0.5,size=20))+ scale_fill_gradientn(colors=cc(100))P2 &lt;- ggplot(world, aes( long, lat)) +geom_bin2d(binwidth = c(0.1, 10))+ theme_map() +ggtitle('0.1 10')+ theme(plot.title = element_text(hjust=0.5,size=20))+ scale_fill_gradientn(colors=cc(100))P3 &lt;- ggplot(world, aes( long, lat)) +geom_bin2d(binwidth = c(10, 0.1))+ theme_map() +ggtitle('10 0.1')+ theme(plot.title = element_text(hjust=0.5,size=20))+ scale_fill_gradientn(colors=cc(100))P4 &lt;- ggplot(world, aes( long, lat)) +geom_bin2d(binwidth = c(10, 10))+ theme_map() +ggtitle('10 10')+ theme(plot.title = element_text(hjust=0.5,size=20))+ scale_fill_gradientn(colors=cc(100))(P1|P2)/(P4|P3) More","link":"/2020/06/19/R/geom_bin2d/"},{"title":"geom_bar | ggplot examples","text":"Here, we use mtcars as an example Quick Start library(ggplot2)library(patchwork)p1 &lt;- ggplot(mtcars) + ggtitle(&quot;Stat = identity&quot;) + # Adding Title # Main function for bar plot geom_bar(aes(cyl,disp, fill=drat), stat='identity') + # Adding a Theme theme_light()+ # Adjust the Position Title theme(plot.title = element_text(hjust = 0.5))p2 &lt;- ggplot(mtcars) + ggtitle(&quot;Stat = Summary&quot;) + geom_bar(aes(cyl, disp,fill=drat), stat='summary') + theme_light()+ theme(plot.title = element_text(hjust = 0.5))p1|p2## Saving the plotggsave(&quot;bar.png&quot;,w=5.95, h=2.68) ] State = identity p1 &lt;- ggplot(mtcars) + geom_bar(aes(cyl, disp,fill=drat), stat='identity', position = 'fill') + theme_light() + ggtitle(&quot;position = fill&quot;)+ theme(plot.title = element_text(hjust = 0.5))p2 &lt;- ggplot(mtcars) + geom_bar(aes(cyl, disp,fill=drat), stat='identity', position = 'identity') + theme_light() + ggtitle(&quot;position = identity&quot;)+ theme(plot.title = element_text(hjust = 0.5))p3 &lt;- ggplot(mtcars) + geom_bar(aes(cyl, disp,fill=drat), stat='identity', position = 'stack') + theme_light() + ggtitle(&quot;position = stack&quot;)+ theme(plot.title = element_text(hjust = 0.5))p4&lt;- ggplot(mtcars) + geom_bar(aes(cyl, disp,fill=drat), stat='identity', position = 'dodge') + theme_light() + ggtitle(&quot;position = dodge&quot;)+ theme(plot.title = element_text(hjust = 0.5))(p1|p2)/(p3|p4)ggsave(&quot;bar2.png&quot;,w=7.46, h=5.68) State = count ggplot(mtcars) + geom_bar(aes(cyl), fill='salmon') + theme_light()## The same as:ggplot(mtcars) + geom_bar(aes(cyl), fill='salmon', stat='count') + theme_light()ggsave(&quot;bar_salmon.png&quot;,w=3, h=2.76)ggplot(mtcars) + geom_bar(aes(cyl), fill='steelblue') + theme_light() + geom_text(aes(x=cyl, label=..count..), stat = 'count', vjust = - 0.2)ggsave(&quot;bar_steelblue.png&quot;,w=3, h=2.76) bar_salmon bar_steelblue library(ggplot2)ggplot(mtcars, aes(x=as.factor(gear), fill= as.factor(vs))) + geom_bar(position=&quot;fill&quot;) + geom_text( aes(label=paste( 100*signif(..count.. / tapply(..count.., ..x.., sum)[as.character(..x..)], digits=4), &quot;%&quot;)), stat=&quot;count&quot;, position=position_fill(vjust=0.5)) + labs(y=&quot;Proportion&quot;) + theme_bw()ggplot(mtcars, aes(x=as.factor(gear), fill= as.factor(vs))) + geom_bar(position=&quot;stack&quot;) + geom_text( aes(label=paste( 100*signif(..count.. / tapply(..count.., ..x.., sum)[as.character(..x..)], digits=4), &quot;%&quot;)), stat=&quot;count&quot;, position=position_stack(vjust=0.5)) + labs(y=&quot;Proportion&quot;) + theme_bw() Barplot fill Barplot Stack position Reference: Dwzb library(patchwork)p1 &lt;- ggplot(mpg,aes(x=class)) + geom_bar(aes(fill=factor(cyl)),position=&quot;stack&quot;)+ ggtitle(label='Stack')+ # position = stack (default) theme_light()p2 &lt;- ggplot(mpg,aes(x=class)) + geom_bar(aes(fill=factor(cyl)),position=&quot;stack&quot;)+ ggtitle(label='Stack + coord_flip()') + coord_flip()+ # Switch axis theme_light()p3 &lt;- ggplot(mpg,aes(x=class)) + geom_bar(aes(fill=factor(cyl)),position=&quot;dodge&quot;)+ ggtitle(label='Dodge')+ # 并排放置 theme_light()p4 &lt;- ggplot(mpg,aes(x=class)) + geom_bar(aes(fill=factor(cyl)),position=&quot;fill&quot;)+ ggtitle(label='Fill')+ # 填充显示比例 theme_light()(p1|p2)/(p3|p4)ggsave(&quot;bar4.png&quot;, w=6.56, h=4.8) polar axis library(ggthemes)p1 &lt;- ggplot(mpg,aes(x=class)) + geom_bar(aes(fill=factor(cyl)),position=&quot;stack&quot;)+ ggtitle(label='X_Stack') + coord_polar('x') + theme_map()+ theme(plot.title = element_text(hjust = 0.5))p2 &lt;- ggplot(mpg,aes(x=class)) + geom_bar(aes(fill=factor(cyl)),position=&quot;dodge&quot;)+ ggtitle(label='X_Dodge') + coord_polar('x') + theme_map()+ theme(plot.title = element_text(hjust = 0.5))p3 &lt;- ggplot(mpg,aes(x=class)) + geom_bar(aes(fill=factor(cyl)),position=&quot;fill&quot;)+ ggtitle(label='X_Fill') + coord_polar('x') + theme_map()+ theme(plot.title = element_text(hjust = 0.5))p11 &lt;- ggplot(mpg,aes(x=class)) + geom_bar(aes(fill=factor(cyl)),position=&quot;stack&quot;)+ ggtitle(label='Y_Stack') + coord_polar('y') + theme_map()+ theme(plot.title = element_text(hjust = 0.5))p22 &lt;- ggplot(mpg,aes(x=class)) + geom_bar(aes(fill=factor(cyl)),position=&quot;dodge&quot;)+ ggtitle(label='Y_Dodge') + coord_polar('y') + theme_map()+ theme(plot.title = element_text(hjust = 0.5))p33 &lt;- ggplot(mpg,aes(x=class)) + geom_bar(aes(fill=factor(cyl)),position=&quot;fill&quot;)+ ggtitle(label='Y_Fill') + coord_polar('y') + theme_map()+ theme(plot.title = element_text(hjust = 0.5))(p1|p11)/(p2|p22)/(p3|p33)ggsave(&quot;bar_fan.png&quot;, w=7.51, h=9.42 ) Pie plot Codes: Blog/语雀 More dismiss value when it equals zero reverse the fectors in a second","link":"/2021/01/16/R/geom_bar/"},{"title":"Edger","text":"Edger Example form Trinity Expression Differential Attention: Make sure Trinity is installed because this scripts needs few functions from re-packaged scripts. If you didn’t install the Trinity, please download heatmap.3.R misc_rnaseq_funcs pairs3.R vioplot2.R from Github, or paste them to your codes instead of source them. (I paste this three codes at the end of the page) This script is running the differential expression counts. So, make sure you are handling an appropriate matrix. library(cluster)library(Biobase)library(qvalue)library(fastcluster)options(stringsAsFactors = FALSE)NO_REUSE = F## try to reuse earlier-loaded data if possibleif (file.exists(&quot;diffExpr.P1e-5_C2.matrix.RData&quot;) &amp;&amp; ! NO_REUSE) { print('RESTORING DATA FROM EARLIER ANALYSIS') load(&quot;diffExpr.P1e-5_C2.matrix.RData&quot;)} else { # loading Count matrix print('Reading matrix file.') primary_data = read.table(&quot;diffExpr.P1e-5_C2.matrix&quot;, header=T, com='', row.names=1, check.names=F, sep='\\t') primary_data = as.matrix(primary_data)}## reading repackaged R function from scripts## similar like import File/lib.py in pythonsource(&quot;/home/ken/Biosoft/trinityrnaseq-Trinity-v2.8.4/Analysis/DifferentialExpression/R/heatmap.3.R&quot;)source(&quot;/home/ken/Biosoft/trinityrnaseq-Trinity-v2.8.4/Analysis/DifferentialExpression/R/misc_rnaseq_funcs.R&quot;)source(&quot;/home/ken/Biosoft/trinityrnaseq-Trinity-v2.8.4/Analysis/DifferentialExpression/R/pairs3.R&quot;)source(&quot;/home/ken/Biosoft/trinityrnaseq-Trinity-v2.8.4/Analysis/DifferentialExpression/R/vioplot2.R&quot;)data = primary_datamyheatcol = colorpanel(75, 'purple','black','yellow')sample_types = colnames(data)nsamples = length(sample_types)sample_colors = rainbow(nsamples)sample_type_list = list()for (i in 1:nsamples) { sample_type_list[[sample_types[i]]] = sample_types[i]}sample_factoring = colnames(data)for (i in 1:nsamples) { sample_type = sample_types[i] replicates_want = sample_type_list[[sample_type]] sample_factoring[ colnames(data) %in% replicates_want ] = sample_type}initial_matrix = data # store before doing various data transformationsdata = log2(data+1)sample_factoring = colnames(data)for (i in 1:nsamples) { sample_type = sample_types[i] replicates_want = sample_type_list[[sample_type]] sample_factoring[ colnames(data) %in% replicates_want ] = sample_type}sampleAnnotations = matrix(ncol=ncol(data),nrow=nsamples)for (i in 1:nsamples) { sampleAnnotations[i,] = colnames(data) %in% sample_type_list[[sample_types[i]]]}sampleAnnotations = apply(sampleAnnotations, 1:2, function(x) as.logical(x))sampleAnnotations = sample_matrix_to_color_assignments(sampleAnnotations, col=sample_colors)rownames(sampleAnnotations) = as.vector(sample_types)colnames(sampleAnnotations) = colnames(data)data = as.matrix(data) # convert to matrix## Centering rowsdata = t(scale(t(data), scale=F))write.table(data, file=&quot;diffExpr.P1e-5_C2.matrix.log2.centered.dat&quot;, quote=F, sep=' ');if (nrow(data) &lt; 2) { stop(&quot;**** Sorry, at least two rows are required for this matrix.&quot;);}if (ncol(data) &lt; 2) { stop(&quot;**** Sorry, at least two columns are required for this matrix.&quot;);}sample_cor = cor(data, method='pearson', use='pairwise.complete.obs')write.table(sample_cor, file=&quot;diffExpr.P1e-5_C2.matrix.log2.centered.sample_cor.dat&quot;, quote=F, sep=' ')sample_dist = dist(t(data), method='euclidean')hc_samples = hclust(sample_dist, method='complete')pdf(&quot;diffExpr.P1e-5_C2.matrix.log2.centered.sample_cor_matrix.pdf&quot;)sample_cor_for_plot = sample_corheatmap.3(sample_cor_for_plot, dendrogram='both', Rowv=as.dendrogram(hc_samples), Colv=as.dendrogram(hc_samples), col = myheatcol, scale='none', symm=TRUE, key=TRUE,density.info='none', trace='none', symkey=FALSE, symbreaks=F, margins=c(10,10), cexCol=1, cexRow=1, cex.main=0.75, main=paste(&quot;sample correlation matrix&quot;, &quot;diffExpr.P1e-5_C2.matrix.log2.centered&quot;) )dev.off()gene_cor = NULLgene_dist = dist(data, method='euclidean')if (nrow(data) &lt;= 1) { message('Too few genes to generate heatmap'); quit(status=0); }hc_genes = hclust(gene_dist, method='complete')heatmap_data = datapdf(&quot;diffExpr.P1e-5_C2.matrix.log2.centered.genes_vs_samples_heatmap.pdf&quot;)heatmap.3(heatmap_data, dendrogram='both', Rowv=as.dendrogram(hc_genes), Colv=as.dendrogram(hc_samples), col=myheatcol, scale=&quot;none&quot;, density.info=&quot;none&quot;, trace=&quot;none&quot;, key=TRUE, keysize=1.2, cexCol=1, margins=c(10,10), cex.main=0.75, main=paste(&quot;samples vs. features&quot;, &quot;diffExpr.P1e-5_C2.matrix.log2.centered&quot; ) )dev.off()##save(list=ls(all=TRUE), file=&quot;diffExpr.P1e-5_C2.matrix.RData&quot;) Test edgeR(out of date) ~/Biosoft/trinityrnaseq-Trinity-v2.8.4/Analysis/DifferentialExpression/run_DE_analysis.pl --matrix Intest.table --method edgeR --dispersion 0.1source(&quot;http://bioconductor.org/biocLite.R&quot;)library(&quot;limma&quot;)library(&quot;edgeR&quot;)x &lt;- read.delim(&quot;3.isoforms.results&quot;)y &lt;- estimateCommonDisp(y)y &lt;- DGEList(counts=5,group=1)y &lt;- calcNormFactors(y)y &lt;- estimateTagwiseDisp(y)y &lt;- estimateCommonDisp(y)source(&quot;http://bioconductor.org/biocLite.R&quot;)library(&quot;limma&quot;)library(&quot;edgeR&quot;)rawdata &lt;- read.delim(&quot;3.isoforms.results&quot;, check.names=FALSE, stringsAsFactors=FALSE)y &lt;- DGEList(counts=rawdata[,3:8], genes=rawdata[,1:2])y$samples$lib.size &lt;- colSums(y$counts)y &lt;- calcNormFactors(y)Patient &lt;- factor(c(8,8,33,33,51,51))Tissue &lt;- factor(c(&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;))data.frame(Sample=colnames(y),Patient,Tissue)design &lt;- model.matrix(~Patient+Tissue)rownames(design) &lt;- colnames(y)y &lt;- estimateGLMCommonDisp(y, design, verbose=TRUE)y &lt;- estimateGLMTrendedDisp(y, design)y &lt;- estimateGLMTagwiseDisp(y, design)fit &lt;- glmFit(y, design)lrt &lt;- glmLRT(fit); topTags(lrt)topTags(lrt)write.csv(topTags(lrt)$table, file=&quot;qqq&quot;)##############################################��Դ����������ģ�� edgeR�������裺https://www.tanboyu.com/edger-users-guide.html###########################################################################################################################################################################��׼��source(&quot;http://bioconductor.org/biocLite.R&quot;)library(&quot;limma&quot;)library(&quot;edgeR&quot;)rawdata &lt;- read.delim(&quot;3.isoforms.results&quot;, check.names=FALSE, stringsAsFactors=FALSE)y &lt;- DGEList(counts=rawdata[,2:6], genes=rawdata[,1])y$samples$lib.size &lt;- colSums(y$counts)y &lt;- calcNormFactors(y)Patient &lt;- factor(c(8,8,51,51))Tissue &lt;- factor(c(&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;))data.frame(Sample=colnames(y),Patient,Tissue)design &lt;- model.matrix(~Patient+Tissue)rownames(design) &lt;- colnames(y)y &lt;- estimateGLMCommonDisp(y, design, verbose=TRUE)y &lt;- estimateGLMTrendedDisp(y, design)y &lt;- estimateGLMTagwiseDisp(y, design)fit &lt;- glmFit(y, design)lrt &lt;- glmLRT(fit); topTags(lrt)topTags(lrt)##########################################################source(&quot;http://bioconductor.org/biocLite.R&quot;)library(&quot;limma&quot;)library(&quot;edgeR&quot;)rawdata &lt;- read.delim(&quot;3.isoforms.results&quot;, check.names=FALSE, stringsAsFactors=FALSE)y &lt;- DGEList(counts=rawdata[,5:8], genes=rawdata[,1])y$samples$lib.size &lt;- colSums(y$counts)y &lt;- calcNormFactors(y)Patient &lt;- factor(c(1,1,51,51))Tissue &lt;- factor(c(&quot;T&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;))data.frame(Sample=colnames(y),Patient,Tissue)design &lt;- model.matrix(~Patient+Tissue)rownames(design) &lt;- colnames(y)y &lt;- estimateGLMCommonDisp(y, design, verbose=TRUE)y &lt;- estimateGLMTrendedDisp(y, design)y &lt;- estimateGLMTagwiseDisp(y, design)fit &lt;- glmFit(y, design)lrt &lt;- glmLRT(fit); topTags(lrt)topTags(lrt)############################################################source(&quot;http://bioconductor.org/biocLite.R&quot;)library(&quot;limma&quot;)library(&quot;edgeR&quot;)rawdata &lt;- read.delim(&quot;3.isoforms.results&quot;, check.names=FALSE, stringsAsFactors=FALSE)y &lt;- DGEList(counts=rawdata[,5], genes=rawdata[,1])y$samples$lib.size &lt;- colSums(y$counts)y &lt;- calcNormFactors(y)Patient &lt;- factor(c(1,2))Tissue &lt;- factor(c(&quot;T&quot;,&quot;T&quot;))data.frame(Sample=colnames(y),Patient,Tissue)design &lt;- model.matrix(~Patient+Tissue)rownames(design) &lt;- colnames(y)y &lt;- estimateGLMCommonDisp(y, design, verbose=TRUE)y &lt;- estimateGLMTrendedDisp(y, design)y &lt;- estimateGLMTagwiseDisp(y, design)fit &lt;- glmFit(y, design)lrt &lt;- glmLRT(fit); topTags(lrt)topTags(lrt)------------------source(&quot;http://bioconductor.org/biocLite.R&quot;)library(&quot;limma&quot;)library(&quot;edgeR&quot;)rawdata &lt;- read.delim(&quot;6.matrix&quot;, check.names=FALSE, stringsAsFactors=FALSE)y &lt;- DGEList(counts=rawdata[,2:7], genes=rawdata[,1])head(rawdata)y$samples$lib.size &lt;- colSums(y$counts)y &lt;- calcNormFactors(y)Patient &lt;- factor(c(1,1,2,2,3,3))Tissue &lt;- factor(c(&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;))data.frame(Sample=colnames(y),Patient,Tissue)design &lt;- model.matrix(~Patient+Tissue)rownames(design) &lt;- colnames(y)y &lt;- estimateGLMCommonDisp(y, design, verbose=TRUE)y &lt;- estimateGLMTrendedDisp(y, design)y &lt;- estimateGLMTagwiseDisp(y, design)fit &lt;- glmFit(y, design)lrt &lt;- glmLRT(fit); topTags(lrt)topTags(lrt)write.table(topTags(lrt), file = &quot;6.txt&quot;,append =FALSE, quote = TRUE, sep = &quot; &quot;,eol = &quot;\\n&quot;, na = &quot;NA&quot;, dec = &quot;.&quot;,row.names = TRUE,col.names = TRUE, qmethod = c(&quot;escape&quot;, &quot;double&quot;),fileEncoding = &quot;&quot;)-------------------------------10matrixsource(&quot;http://bioconductor.org/biocLite.R&quot;)library(&quot;limma&quot;)library(&quot;edgeR&quot;)rawdata &lt;- read.delim(&quot;Intest.table&quot;, check.names=FALSE, stringsAsFactors=FALSE)y &lt;- DGEList(counts=rawdata[,2:101], genes=rawdata[,1])head(rawdata)y$samples$lib.size &lt;- colSums(y$counts)y &lt;- calcNormFactors(y)Patient &lt;- factor(c(1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,12,12,13,13,14,14,15,15,16,16,17,17,18,18,19,19,20,20,21,21,22,22,23,23,24,24,25,25,26,26,27,27,28,28,29,29,30,30,31,31,32,32,33,33,34,34,35,35,36,36,37,37,38,38,39,39,40,40,41,41,42,42,43,43,44,44,45,45,46,46,47,47,48,48,49,49,50,50))Tissue &lt;- factor(c(&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;,&quot;N&quot;,&quot;T&quot;))data.frame(Sample=colnames(y),Patient,Tissue)design &lt;- model.matrix(~Patient+Tissue)rownames(design) &lt;- colnames(y)y &lt;- estimateGLMCommonDisp(y, design, verbose=TRUE)y &lt;- estimateGLMTrendedDisp(y, design)y &lt;- estimateGLMTagwiseDisp(y, design)fit &lt;- glmFit(y, design)lrt &lt;- glmLRT(fit); topTags(lrt)topTags(lrt)write.table(topTags(lrt), file = &quot;a40.txt&quot;,append =FALSE, quote = TRUE, sep = &quot; &quot;,eol = &quot;\\n&quot;, na = &quot;NA&quot;, dec = &quot;.&quot;,row.names = TRUE,col.names = TRUE, qmethod = c(&quot;escape&quot;, &quot;double&quot;),fileEncoding = &quot;&quot;)#################################3linesource(&quot;http://bioconductor.org/biocLite.R&quot;)library(&quot;limma&quot;)library(&quot;edgeR&quot;)rawdata &lt;- read.delim(&quot;Intest.table&quot;, check.names=FALSE, stringsAsFactors=FALSE)y &lt;- DGEList(counts=rawdata[,2:4], genes=rawdata[,1])head(rawdata)y$samples$lib.size &lt;- colSums(y$counts)y &lt;- calcNormFactors(y)Patient &lt;- factor(c(1,2,3))Tissue &lt;- factor(c(&quot;N&quot;,&quot;T&quot;,&quot;T2&quot;))data.frame(Sample=colnames(y),Patient,Tissue)design &lt;- model.matrix(~Patient+Tissue)rownames(design) &lt;- colnames(y)y &lt;- estimateGLMCommonDisp(y, design, verbose=TRUE)y &lt;- estimateGLMTrendedDisp(y, design)y &lt;- estimateGLMTagwiseDisp(y, design)fit &lt;- glmFit(y, design)lrt &lt;- glmLRT(fit); topTags(lrt)topTags(lrt)write.table(topTags(lrt), file = &quot;a40.txt&quot;,append =FALSE, quote = TRUE, sep = &quot; &quot;,eol = &quot;\\n&quot;, na = &quot;NA&quot;, dec = &quot;.&quot;,row.names = TRUE,col.names = TRUE, qmethod = c(&quot;escape&quot;, &quot;double&quot;),fileEncoding = &quot;&quot;) Attachment heatmap.3.R ## From: https://github.com/trinityrnaseq/trinityrnaseq/blob/master/Analysis/DifferentialExpression/R/heatmap.3.R### pulled from here, and then tweaked slightly: http://www.biostars.org/p/18211/## CODEheatmap.3 &lt;- function(x, Rowv = TRUE, Colv = if (symm) &quot;Rowv&quot; else TRUE, distfun = dist, hclustfun = hclust, dendrogram = c(&quot;both&quot;,&quot;row&quot;, &quot;column&quot;, &quot;none&quot;), symm = FALSE, scale = c(&quot;none&quot;,&quot;row&quot;, &quot;column&quot;), na.rm = TRUE, revC = identical(Colv,&quot;Rowv&quot;), add.expr, breaks, symbreaks = max(x &lt; 0, na.rm = TRUE) || scale != &quot;none&quot;, col = &quot;heat.colors&quot;, colsep, rowsep, sepcolor = &quot;white&quot;, sepwidth = c(0.05, 0.05), cellnote, notecex = 1, notecol = &quot;cyan&quot;, na.color = par(&quot;bg&quot;), trace = c(&quot;none&quot;, &quot;column&quot;,&quot;row&quot;, &quot;both&quot;), tracecol = &quot;cyan&quot;, hline = median(breaks), vline = median(breaks), linecol = tracecol, margins = c(5,5), ColSideColors, RowSideColors, side.height.fraction=0.1, #cexRow = 0.2 + 1/log10(max(nr,2)), #cexCol = 0.2 + 1/log10(max(nc,2)), cexRow = 0.2, cexCol = 0.2, scaleRangeMin, scaleRangeMax, cex.main = 1, labRow = NULL, labCol = NULL, key = TRUE, keysize = 1.5, density.info = c(&quot;none&quot;, &quot;histogram&quot;, &quot;density&quot;), denscol = tracecol, symkey = max(x &lt; 0, na.rm = TRUE) || symbreaks, densadj = 0.25, main = NULL, xlab = NULL, ylab = NULL, lmat = NULL, lhei = NULL, lwid = NULL, NumColSideColors = 1, NumRowSideColors = 1, KeyValueName=&quot;Value&quot;,...){ invalid &lt;- function (x) { if (missing(x) || is.null(x) || length(x) == 0) return(TRUE) if (is.list(x)) return(all(sapply(x, invalid))) else if (is.vector(x)) return(all(is.na(x))) else return(FALSE) } x &lt;- as.matrix(x) scale01 &lt;- function(x, low = min(x), high = max(x)) { x &lt;- (x - low)/(high - low) x } retval &lt;- list() scale &lt;- if (symm &amp;&amp; missing(scale)) &quot;none&quot; else match.arg(scale) dendrogram &lt;- match.arg(dendrogram) trace &lt;- match.arg(trace) density.info &lt;- match.arg(density.info) if (length(col) == 1 &amp;&amp; is.character(col)) col &lt;- get(col, mode = &quot;function&quot;) if (!missing(breaks) &amp;&amp; (scale != &quot;none&quot;)) warning(&quot;Using scale=\\&quot;row\\&quot; or scale=\\&quot;column\\&quot; when breaks are&quot;, &quot;specified can produce unpredictable results.&quot;, &quot;Please consider using only one or the other.&quot;) if (is.null(Rowv) || is.na(Rowv)) Rowv &lt;- FALSE if (is.null(Colv) || is.na(Colv)) Colv &lt;- FALSE else if (Colv == &quot;Rowv&quot; &amp;&amp; !isTRUE(Rowv)) Colv &lt;- FALSE if (length(di &lt;- dim(x)) != 2 || !is.numeric(x)) stop(&quot;`x' must be a numeric matrix&quot;) nr &lt;- di[1] nc &lt;- di[2] if (nr &lt;= 1 || nc &lt;= 1) stop(&quot;`x' must have at least 2 rows and 2 columns&quot;) #print(paste(&quot;nr:&quot;, nr, &quot;nc:&quot;, nc, &quot;cexCol:&quot;, cexCol, &quot;cexRow:&quot;, cexRow)) #stop(&quot;debug&quot;) if (!is.numeric(margins) || length(margins) != 2) stop(&quot;`margins' must be a numeric vector of length 2&quot;) if (missing(cellnote)) cellnote &lt;- matrix(&quot;&quot;, ncol = ncol(x), nrow = nrow(x)) if (!inherits(Rowv, &quot;dendrogram&quot;)) { if (((!isTRUE(Rowv)) || (is.null(Rowv))) &amp;&amp; (dendrogram %in% c(&quot;both&quot;, &quot;row&quot;))) { if (is.logical(Colv) &amp;&amp; (Colv)) dendrogram &lt;- &quot;column&quot; else dedrogram &lt;- &quot;none&quot; warning(&quot;Discrepancy: Rowv is FALSE, while dendrogram is `&quot;, dendrogram, &quot;'. Omitting row dendogram.&quot;) } } if (!inherits(Colv, &quot;dendrogram&quot;)) { if (((!isTRUE(Colv)) || (is.null(Colv))) &amp;&amp; (dendrogram %in% c(&quot;both&quot;, &quot;column&quot;))) { if (is.logical(Rowv) &amp;&amp; (Rowv)) dendrogram &lt;- &quot;row&quot; else dendrogram &lt;- &quot;none&quot; warning(&quot;Discrepancy: Colv is FALSE, while dendrogram is `&quot;, dendrogram, &quot;'. Omitting column dendogram.&quot;) } } if (inherits(Rowv, &quot;dendrogram&quot;)) { ddr &lt;- Rowv rowInd &lt;- order.dendrogram(ddr) } else if (is.integer(Rowv)) { hcr &lt;- hclustfun(distfun(x)) ddr &lt;- as.dendrogram(hcr) ddr &lt;- reorder(ddr, Rowv) rowInd &lt;- order.dendrogram(ddr) if (nr != length(rowInd)) stop(&quot;row dendrogram ordering gave index of wrong length&quot;) } else if (isTRUE(Rowv)) { Rowv &lt;- rowMeans(x, na.rm = na.rm) hcr &lt;- hclustfun(distfun(x)) ddr &lt;- as.dendrogram(hcr) ddr &lt;- reorder(ddr, Rowv) rowInd &lt;- order.dendrogram(ddr) if (nr != length(rowInd)) stop(&quot;row dendrogram ordering gave index of wrong length&quot;) } else { rowInd &lt;- nr:1 } if (inherits(Colv, &quot;dendrogram&quot;)) { ddc &lt;- Colv colInd &lt;- order.dendrogram(ddc) } else if (identical(Colv, &quot;Rowv&quot;)) { if (nr != nc) stop(&quot;Colv = \\&quot;Rowv\\&quot; but nrow(x) != ncol(x)&quot;) if (exists(&quot;ddr&quot;)) { ddc &lt;- ddr colInd &lt;- order.dendrogram(ddc) } else colInd &lt;- rowInd } else if (is.integer(Colv)) { hcc &lt;- hclustfun(distfun(if (symm) x else t(x))) ddc &lt;- as.dendrogram(hcc) ddc &lt;- reorder(ddc, Colv) colInd &lt;- order.dendrogram(ddc) if (nc != length(colInd)) stop(&quot;column dendrogram ordering gave index of wrong length&quot;) } else if (isTRUE(Colv)) { Colv &lt;- colMeans(x, na.rm = na.rm) hcc &lt;- hclustfun(distfun(if (symm) x else t(x))) ddc &lt;- as.dendrogram(hcc) ddc &lt;- reorder(ddc, Colv) colInd &lt;- order.dendrogram(ddc) if (nc != length(colInd)) stop(&quot;column dendrogram ordering gave index of wrong length&quot;) } else { colInd &lt;- 1:nc } retval$rowInd &lt;- rowInd retval$colInd &lt;- colInd retval$call &lt;- match.call() x &lt;- x[rowInd, colInd] # rearrange matrix according to dendrograms x.unscaled &lt;- x cellnote &lt;- cellnote[rowInd, colInd] # also rearrange the cellnotes # get labels if (is.null(labRow)) labRow &lt;- if (is.null(rownames(x))) (1:nr)[rowInd] else rownames(x) else labRow &lt;- labRow[rowInd] if (is.null(labCol)) labCol &lt;- if (is.null(colnames(x))) (1:nc)[colInd] else colnames(x) else labCol &lt;- labCol[colInd] ## do scaling of matrix according to Z-scores if (scale == &quot;row&quot;) { retval$rowMeans &lt;- rm &lt;- rowMeans(x, na.rm = na.rm) x &lt;- sweep(x, 1, rm) retval$rowSDs &lt;- sx &lt;- apply(x, 1, sd, na.rm = na.rm) x &lt;- sweep(x, 1, sx, &quot;/&quot;) } else if (scale == &quot;column&quot;) { retval$colMeans &lt;- rm &lt;- colMeans(x, na.rm = na.rm) x &lt;- sweep(x, 2, rm) retval$colSDs &lt;- sx &lt;- apply(x, 2, sd, na.rm = na.rm) x &lt;- sweep(x, 2, sx, &quot;/&quot;) } # number of breaks if (missing(breaks) || is.null(breaks) || length(breaks) &lt; 1) { if (missing(col) || is.function(col)) breaks &lt;- 16 else breaks &lt;- length(col) + 1 } # set breakpoints if (length(breaks) == 1) { if (missing(scaleRangeMin)) scaleRangeMin = min(x, na.rm=na.rm) if (missing(scaleRangeMax)) scaleRangeMax = max(x, na.rm=na.rm) if (!symbreaks) { breaks &lt;- seq(scaleRangeMin, scaleRangeMax, length=breaks); } else { #extreme &lt;- max(abs(x), na.rm = TRUE) extreme = max(abs(c(scaleRangeMin,scaleRangeMax)), na.rm=na.rm) breaks &lt;- seq(-extreme, extreme, length = breaks) } } nbr &lt;- length(breaks) ncol &lt;- length(breaks) - 1 if (class(col) == &quot;function&quot;) col &lt;- col(ncol) min.breaks &lt;- min(breaks) max.breaks &lt;- max(breaks) # adjust for out-of-range given break settings x[x &lt; min.breaks] &lt;- min.breaks x[x &gt; max.breaks] &lt;- max.breaks # layout height if (missing(lhei) || is.null(lhei)) lhei &lt;- c(keysize, 4) # layout width if (missing(lwid) || is.null(lwid)) lwid &lt;- c(keysize, 4) # define the layout if (missing(lmat) || is.null(lmat)) { lmat &lt;- rbind(4:3, 2:1) if (!missing(ColSideColors)) { if (!is.character(ColSideColors) || ncol(ColSideColors) != nc) stop(&quot;'ColSideColors' must be a matrix of ncol(x) &quot;, nc, &quot; columns&quot;) lmat &lt;- rbind(lmat[1, ] + 1, c(NA, 1), lmat[2, ] + 1) #lhei=c(lhei[1], side.height.fraction*NumColSideColors, lhei[2]) side_height = min(side.height.fraction*nrow(ColSideColors), 1); lhei=c(lhei[1], side_height, lhei[2]) } if (!missing(RowSideColors)) { if (!is.character(RowSideColors) || nrow(RowSideColors) != nr) stop(&quot;'RowSideColors' must be a matrix of nrow(x) &quot;, nr, &quot; rows. It currently has &quot;, nrow(RowSideColors), &quot; rows.&quot;) lmat &lt;- cbind(lmat[, 1] + 1, c(rep(NA, nrow(lmat) - 1), 1), lmat[,2] + 1) #lwid &lt;- c(lwid[1], side.height.fraction*NumRowSideColors, lwid[2]) side_width = min(side.height.fraction*ncol(RowSideColors), 1); lwid &lt;- c(lwid[1], side_width, lwid[2]) } lmat[is.na(lmat)] &lt;- 0 } if (length(lhei) != nrow(lmat)) stop(&quot;lhei must have length = nrow(lmat) = &quot;, nrow(lmat)) if (length(lwid) != ncol(lmat)) stop(&quot;lwid must have length = ncol(lmat) =&quot;, ncol(lmat)) op &lt;- par(no.readonly = TRUE) on.exit(par(op)) layout(lmat, widths = lwid, heights = lhei, respect = FALSE) ########################################### ## Draw the colorbars for the annotations: ########################################### if (!missing(RowSideColors)) { if (!is.matrix(RowSideColors)){ par(mar = c(margins[1], 0, 0, 0.5)) image(rbind(1:nr), col = RowSideColors[rowInd], axes = FALSE) } else { par(mar = c(margins[1], 0, 0, 0.5)) rsc = t(RowSideColors[rowInd, , drop=F]) rsc.colors = matrix() rsc.names = names(table(rsc)) rsc.i = 1 for (rsc.name in rsc.names) { rsc.colors[rsc.i] = rsc.name rsc[rsc == rsc.name] = rsc.i rsc.i = rsc.i + 1 } # print(rsc) rsc = matrix(as.numeric(rsc), nrow = dim(rsc)[1]) #print(&quot;RSC: &quot;, rsc) #print(rsc.colors) image(1:nrow(rsc), 1:ncol(rsc), rsc, col = as.vector(rsc.colors), axes = FALSE, xlab=&quot;&quot;, ylab=&quot;&quot;) # add labels if (length(colnames(RowSideColors)) &gt; 0) { #axis(1, 0:(dim(rsc)[2] - 1)/(dim(rsc)[2] - 1), rownames(RowSideColors), las = 2, tick = FALSE) #axis(1, 0:(nrow(rsc)-1), colnames(RowSideColors), las = 2, tick = T) # ncol because transposed axis(1, 1:ncol(RowSideColors), labels=colnames(RowSideColors), las=2, cex.axis=0.5, tick=F, xlab=&quot;&quot;, ylab=&quot;&quot;) } } } if (!missing(ColSideColors)) { if (!is.matrix(ColSideColors)){ par(mar = c(0.5, 0, 0, margins[2])) image(cbind(1:nc), col = ColSideColors[colInd], axes = FALSE) } else { par(mar = c(0.5, 0, 0, margins[2])) csc = ColSideColors[, colInd, drop=F] csc.colors = matrix() csc.names = names(table(csc)) csc.i = 1 for (csc.name in csc.names) { csc.colors[csc.i] = csc.name csc[csc == csc.name] = csc.i csc.i = csc.i + 1 } csc = matrix(as.numeric(csc), nrow = dim(csc)[1]) #print(csc) image(1:nrow(t(csc)), 1:ncol(t(csc)), t(csc), col = as.vector(csc.colors), axes = FALSE, xlab=&quot;&quot;, ylab=&quot;&quot;) # add labels if (length(rownames(ColSideColors)) &gt; 0) { #axis(2, 0:(dim(csc)[2] - 1)/max(1,(dim(csc)[2] - 1)), colnames(ColSideColors), las = 2, tick = FALSE) axis(2, 1:(nrow(ColSideColors)), labels=rownames(ColSideColors), las = 2, tick = FALSE, cex.axis=0.5) } } } par(mar = c(margins[1], 0, 0, margins[2])) x &lt;- t(x) cellnote &lt;- t(cellnote) if (revC) { iy &lt;- nr:1 if (exists(&quot;ddr&quot;)) ddr &lt;- rev(ddr) x &lt;- x[, iy] cellnote &lt;- cellnote[, iy] } else iy &lt;- 1:nr # draw the central heatmap image(1:nc, 1:nr, x, xlim = 0.5 + c(0, nc), ylim = 0.5 + c(0, nr), axes = FALSE, xlab = &quot;&quot;, ylab = &quot;&quot;, col = col, breaks = breaks, ...) # store the matrix drawn retval$carpet &lt;- x # store the dendrograms if (exists(&quot;ddr&quot;)) retval$rowDendrogram &lt;- ddr if (exists(&quot;ddc&quot;)) retval$colDendrogram &lt;- ddc # store the breaks retval$breaks &lt;- breaks # store the colormap used retval$col &lt;- col # specially color in the na values if (!invalid(na.color) &amp; any(is.na(x))) { # load library(gplots) mmat &lt;- ifelse(is.na(x), 1, NA) image(1:nc, 1:nr, mmat, axes = FALSE, xlab = &quot;&quot;, ylab = &quot;&quot;, col = na.color, add = TRUE) } # X-axis column labels axis(1, 1:nc, labels = labCol, las = 2, line = -0.5, tick = 0, cex.axis = cexCol) # X-axis title if (!is.null(xlab)) mtext(xlab, side = 1, line = margins[1] - 1.25) # Y-axis row labeling axis(4, iy, labels = labRow, las = 2, line = -0.5, tick = 0, cex.axis = cexRow) # Y-axis title if (!is.null(ylab)) mtext(ylab, side = 4, line = margins[2] - 1.25) if (!missing(add.expr)) eval(substitute(add.expr)) if (!missing(colsep)) for (csep in colsep) rect(xleft = csep + 0.5, ybottom = rep(0, length(csep)), xright = csep + 0.5 + sepwidth[1], ytop = rep(ncol(x) + 1, csep), lty = 1, lwd = 1, col = sepcolor, border = sepcolor) if (!missing(rowsep)) for (rsep in rowsep) rect(xleft = 0, ybottom = (ncol(x) + 1 - rsep) - 0.5, xright = nrow(x) + 1, ytop = (ncol(x) + 1 - rsep) - 0.5 - sepwidth[2], lty = 1, lwd = 1, col = sepcolor, border = sepcolor) min.scale &lt;- min(breaks) max.scale &lt;- max(breaks) x.scaled &lt;- scale01(t(x), min.scale, max.scale) # column trace if (trace %in% c(&quot;both&quot;, &quot;column&quot;)) { retval$vline &lt;- vline vline.vals &lt;- scale01(vline, min.scale, max.scale) for (i in colInd) { if (!is.null(vline)) { abline(v = i - 0.5 + vline.vals, col = linecol, lty = 2) } xv &lt;- rep(i, nrow(x.scaled)) + x.scaled[, i] - 0.5 xv &lt;- c(xv[1], xv) yv &lt;- 1:length(xv) - 0.5 lines(x = xv, y = yv, lwd = 1, col = tracecol, type = &quot;s&quot;) } } # row trace if (trace %in% c(&quot;both&quot;, &quot;row&quot;)) { retval$hline &lt;- hline hline.vals &lt;- scale01(hline, min.scale, max.scale) for (i in rowInd) { if (!is.null(hline)) { abline(h = i + hline, col = linecol, lty = 2) } yv &lt;- rep(i, ncol(x.scaled)) + x.scaled[i, ] - 0.5 yv &lt;- rev(c(yv[1], yv)) xv &lt;- length(yv):1 - 0.5 lines(x = xv, y = yv, lwd = 1, col = tracecol, type = &quot;s&quot;) } } # add cell labels if (!missing(cellnote)) text(x = c(row(cellnote)), y = c(col(cellnote)), labels = c(cellnote), col = notecol, cex = notecex) ########################### ## Plot the row dendrogram ########################### par(mar = c(margins[1], 0, 0, 0)) if (dendrogram %in% c(&quot;both&quot;, &quot;row&quot;)) { plot(ddr, horiz = TRUE, axes = FALSE, yaxs = &quot;i&quot;, leaflab = &quot;none&quot;) } else plot.new() ############################# ## Plot the column dendrogram ############################# par(mar = c(0, 0, if (!is.null(main)) 5 else 0, margins[2])) if (dendrogram %in% c(&quot;both&quot;, &quot;column&quot;)) { plot(ddc, axes = FALSE, xaxs = &quot;i&quot;, leaflab = &quot;none&quot;) } else plot.new() if (!is.null(main)) title(main, cex.main=cex.main) #cex.main = 1.5 * op[[&quot;cex.main&quot;]]) ############################ ## Add the Color Chart ############################ if (key) { par(mar = c(5, 4, 2, 1), cex = 0.75) tmpbreaks &lt;- breaks if (symkey) { max.raw &lt;- max(abs(c(x, breaks)), na.rm = TRUE) min.raw &lt;- -max.raw tmpbreaks[1] &lt;- -max(abs(x), na.rm = TRUE) tmpbreaks[length(tmpbreaks)] &lt;- max(abs(x), na.rm = TRUE) } else { min.raw &lt;- min(c(x,breaks), na.rm = TRUE) max.raw &lt;- max(c(x,breaks), na.rm = TRUE) } message('for plotting:: min.raw: ', min.raw, ' max.raw: ', max.raw); z &lt;- seq(min.raw, max.raw, length = length(col)) image(z = matrix(z, ncol = 1), col = col, breaks = tmpbreaks, xaxt = &quot;n&quot;, yaxt = &quot;n&quot;) par(usr = c(0, 1, 0, 1)) lv &lt;- pretty(breaks) xv &lt;- scale01(as.numeric(lv), min.raw, max.raw) axis(1, at = xv, labels = lv) if (scale == &quot;row&quot;) mtext(side = 1, &quot;Row Z-Score&quot;, line = 2) else if (scale == &quot;column&quot;) mtext(side = 1, &quot;Column Z-Score&quot;, line = 2) else mtext(side = 1, KeyValueName, line = 2) if (density.info == &quot;density&quot;) { dens &lt;- density(x, adjust = densadj, na.rm = TRUE) omit &lt;- dens$x &lt; min(breaks) | dens$x &gt; max(breaks) dens$x &lt;- dens$x[-omit] dens$y &lt;- dens$y[-omit] dens$x &lt;- scale01(dens$x, min.raw, max.raw) lines(dens$x, dens$y/max(dens$y) * 0.95, col = denscol, lwd = 1) axis(2, at = pretty(dens$y)/max(dens$y) * 0.95, pretty(dens$y)) title(&quot;Color Key\\nand Density Plot&quot;) par(cex = 0.5) mtext(side = 2, &quot;Density&quot;, line = 2) } else if (density.info == &quot;histogram&quot;) { h &lt;- hist(x, plot = FALSE, breaks = breaks) hx &lt;- scale01(breaks, min.raw, max.raw) hy &lt;- c(h$counts, h$counts[length(h$counts)]) lines(hx, hy/max(hy) * 0.95, lwd = 1, type = &quot;s&quot;, col = denscol) axis(2, at = pretty(hy)/max(hy) * 0.95, pretty(hy)) title(&quot;Color Key\\nand Histogram&quot;) par(cex = 0.5) mtext(side = 2, &quot;Count&quot;, line = 2) } else title(&quot;Color Key&quot;) } else plot.new() retval$colorTable &lt;- data.frame(low = retval$breaks[-length(retval$breaks)], high = retval$breaks[-1], color = retval$col) invisible(retval)}## EXAMPLE USAGE## example of colsidecolors rowsidecolors (single column, single row)##mat &lt;- matrix(1:100, byrow=T, nrow=10)##column_annotation &lt;- sample(c(&quot;red&quot;, &quot;blue&quot;, &quot;green&quot;), 10, replace=T)##column_annotation &lt;- as.matrix(column_annotation)##colnames(column_annotation) &lt;- c(&quot;Variable X&quot;)##row_annotation &lt;- sample(c(&quot;red&quot;, &quot;blue&quot;, &quot;green&quot;), 10, replace=T)##row_annotation &lt;- as.matrix(t(row_annotation))##rownames(row_annotation) &lt;- c(&quot;Variable Y&quot;)##heatmap.3(mat, RowSideColors=row_annotation, ColSideColors=column_annotation)## multiple column and row##mat &lt;- matrix(1:100, byrow=T, nrow=10)##column_annotation &lt;- matrix(sample(c(&quot;red&quot;, &quot;blue&quot;, &quot;green&quot;), 20, replace=T), ncol=2)##colnames(column_annotation) &lt;- c(&quot;Variable X1&quot;, &quot;Variable X2&quot;)##row_annotation &lt;- matrix(sample(c(&quot;red&quot;, &quot;blue&quot;, &quot;green&quot;), 20, replace=T), nrow=2)##rownames(row_annotation) &lt;- c(&quot;Variable Y1&quot;, &quot;Variable Y2&quot;)##heatmap.3(mat, RowSideColors=row_annotation, ColSideColors=column_annotation)##---------------------------------------------------------------------------------##---------------------------------------------------------------------------------##---------------------------------------------------------------------------------## Borrowing the following from gplots (gplots isn't compatible with R 3.0 (yet), and so bypassing it for now).colorpanel = function (n, low, mid, high){ if (missing(mid) || missing(high)) { low &lt;- col2rgb(low) if (missing(high)) high &lt;- col2rgb(mid) else high &lt;- col2rgb(high) red &lt;- seq(low[1, 1], high[1, 1], length = n)/255 green &lt;- seq(low[3, 1], high[3, 1], length = n)/255 blue &lt;- seq(low[2, 1], high[2, 1], length = n)/255 } else { isodd &lt;- odd(n) if (isodd) { n &lt;- n + 1 } low &lt;- col2rgb(low) mid &lt;- col2rgb(mid) high &lt;- col2rgb(high) lower &lt;- floor(n/2) upper &lt;- n - lower red &lt;- c(seq(low[1, 1], mid[1, 1], length = lower), seq(mid[1, 1], high[1, 1], length = upper))/255 green &lt;- c(seq(low[3, 1], mid[3, 1], length = lower), seq(mid[3, 1], high[3, 1], length = upper))/255 blue &lt;- c(seq(low[2, 1], mid[2, 1], length = lower), seq(mid[2, 1], high[2, 1], length = upper))/255 if (isodd) { red &lt;- red[-(lower + 1)] green &lt;- green[-(lower + 1)] blue &lt;- blue[-(lower + 1)] } } rgb(red, blue, green)}greenred = function (n) { colorpanel(n, &quot;green&quot;, &quot;black&quot;, &quot;red&quot;)}odd = function (x) { x%%2 == 1}even = function (x) { x%%2 == 0} misc_rnaseq_funcs.R ## from https://github.com/trinityrnaseq/trinityrnaseq/blob/master/Analysis/DifferentialExpression/R/misc_rnaseq_funcs.Rplot_counts_matrix_log2_dist = function(matrix_file) { data = read.table(file=matrix_file, com='', row.names=1, header=T) conditions = colnames(data) colors = rainbow(length(conditions)) plot(density(log2(data[,1])), col=colors[1], main=matrix_file, xlab='log2(frag_counts)', ylab='density') for (i in 2:length(data[1,])) { points(density(log2(data[,i])), type='l', col=colors[i]) } legend('topright', conditions, col=colors, pch=15)}matrix_to_color_assignments = function(matrix_m, col=NULL, by=c(&quot;matrix&quot;, &quot;row&quot;, &quot;col&quot;)) { if (! is.matrix(matrix_m)) stop(&quot;Error, matrix_to_color_assignments() requires a matrix as parameter.&quot;) num_colors = 0 if (is.null(col)) { num_colors = min(nrow(matrix_m), ncol(matrix_m)) col = rainbow(num_colors) } else { num_colors = length(col) } by = match.arg(by) if (by == &quot;matrix&quot;) { min_val = min(matrix_m, na.rm=T) matrix_m = matrix_m - min_val max_val = max(matrix_m, na.rm=T) matrix_m = matrix_m / max_val * num_colors #print(matrix_m) matrix_m = apply(matrix_m, 1:2, function(x) ifelse (x&lt;1, as.character(col[1]), as.character(col[x]))); matrix_m = matrix(as.character(matrix_m), nrow=dim(matrix_m)[1]) } else { row_or_col_only_color_selector_func = function(x) { a = min(x, na.rm=T); b = max(x, na.rm=T); c = (x-a)/(b-a) * num_colors; c = round(c); c = ifelse (c&lt;1, 1, c); #print(paste(c(&quot;color selection: (a)&quot;, a, &quot; (b)&quot;, b, &quot; (c)&quot;, paste(c, sep=',')))); colors = as.character(col[c]); return(colors); } if (by == &quot;row&quot;) { matrix_m = apply(matrix_m, 1, row_or_col_only_color_selector_func); print(matrix_m) print(&quot;dim matrix_m after apply&quot;); print(dim(matrix_m)) matrix_m = t(matrix_m); print(&quot;dim matrix_m after transpose: &quot;); print(dim(matrix_m)) } else { # by column matrix_m = apply(matrix_m, 2, row_or_col_only_color_selector_func); } } #print(matrix_m) return(matrix_m)}sample_matrix_to_color_assignments = function(sampleAnnotationsMatrix, colors) { if (missing(colors)) colors = rainbow(nrow(sampleAnnotationsMatrix)) nsamples = nrow(sampleAnnotationsMatrix); if (length(colors) &lt; nrow(sampleAnnotationsMatrix)) stop(&quot;Error, only &quot;, length(colors), &quot; colors specified, but have &quot;, nsamples, &quot; samples&quot;); for (i in 1:nrow(sampleAnnotationsMatrix)) { c = colors[i] sampleAnnotationsMatrix[i,] = sapply(sampleAnnotationsMatrix[i,], function(x) ifelse( x, as.character(c), 'white')) } return(sampleAnnotationsMatrix);} pairs3.R ## from: https://github.com/trinityrnaseq/trinityrnaseq/blob/master/Analysis/DifferentialExpression/R/pairs3.R### snagged from: http://stackoverflow.com/questions/9680783/how-can-i-change-the-axis-position-for-pairs## modified to include function for modifying X/Y values.pairs3 &lt;- function (x, labels, XY_convert_fun = NULL, CustomColorFun = NULL, panel = points, ..., lower.panel = panel, upper.panel = panel, diag.panel = NULL, text.panel = textPanel, label.pos = 0.5 + has.diag/3, cex.labels = NULL, font.labels = 1, row1attop = TRUE, gap = 1) { textPanel &lt;- function(x = 0.5, y = 0.5, txt, cex, font) text(x, y, txt, cex = cex, font = font) localAxis &lt;- function(side, x, y, xpd, bg, col = NULL, main, oma, ...) { if (side%%2 == 1) Axis(x, side = side, xpd = NA, ...) else Axis(y, side = side, xpd = NA, ...) } localPlot &lt;- function(..., main, oma, font.main, cex.main) { plot(...) } localLowerPanel &lt;- function(..., main, oma, font.main, cex.main) lower.panel(...) localUpperPanel &lt;- function(..., main, oma, font.main, cex.main) upper.panel(...) localDiagPanel &lt;- function(..., main, oma, font.main, cex.main) diag.panel(...) dots &lt;- list(...) nmdots &lt;- names(dots) if (!is.matrix(x)) { x &lt;- as.data.frame(x) for (i in seq_along(names(x))) { if (is.factor(x[[i]]) || is.logical(x[[i]])) x[[i]] &lt;- as.numeric(x[[i]]) if (!is.numeric(unclass(x[[i]]))) stop(&quot;non-numeric argument to 'pairs'&quot;) } } else if (!is.numeric(x)) stop(&quot;non-numeric argument to 'pairs'&quot;) panel &lt;- match.fun(panel) if ((has.lower &lt;- !is.null(lower.panel)) &amp;&amp; !missing(lower.panel)) lower.panel &lt;- match.fun(lower.panel) if ((has.upper &lt;- !is.null(upper.panel)) &amp;&amp; !missing(upper.panel)) upper.panel &lt;- match.fun(upper.panel) if ((has.diag &lt;- !is.null(diag.panel)) &amp;&amp; !missing(diag.panel)) diag.panel &lt;- match.fun(diag.panel) if (row1attop) { tmp &lt;- lower.panel lower.panel &lt;- upper.panel upper.panel &lt;- tmp tmp &lt;- has.lower has.lower &lt;- has.upper has.upper &lt;- tmp } nc &lt;- ncol(x) if (nc &lt; 2) stop(&quot;only one column in the argument to 'pairs'&quot;) has.labs &lt;- TRUE if (missing(labels)) { labels &lt;- colnames(x) if (is.null(labels)) labels &lt;- paste(&quot;var&quot;, 1L:nc) } else if (is.null(labels)) has.labs &lt;- FALSE oma &lt;- if (&quot;oma&quot; %in% nmdots) dots$oma else NULL main &lt;- if (&quot;main&quot; %in% nmdots) dots$main else NULL if (is.null(oma)) { oma &lt;- c(4, 4, 4, 4) if (!is.null(main)) oma[3L] &lt;- 6 } opar &lt;- par(mfrow = c(nc, nc), mar = rep.int(gap/2, 4), oma = oma) on.exit(par(opar)) dev.hold() on.exit(dev.flush(), add = TRUE) for (i in if (row1attop) 1L:nc else nc:1L) for (j in 1L:nc) { #print(paste(i,&quot;vs&quot;, j)); xvals = x[,j] yvals = x[,i] if ( (i != j) &amp;&amp; ! is.null(XY_convert_fun)) { res = XY_convert_fun(xvals, yvals); xvals = res[['x']] yvals = res[['y']] } col='black' # default if (! is.null(CustomColorFun)) col=CustomColorFun(xvals,yvals) # get_list_from_ellipsis2 &lt;- function(...) as.list(substitute(list(...)))[-1L] # print(get_list_from_ellipsis2(...));stop(); localPlot(xvals, yvals, xlab = &quot;&quot;, ylab = &quot;&quot;,axes = F, #col=ifelse(abs(xvals-yvals)&gt;2, 'red', 'black'), type = &quot;n&quot;, ...) if (i == j || (i &lt; j &amp;&amp; has.lower) || (i &gt; j &amp;&amp; has.upper)) { box() # edited here... # if (i == 1 &amp;&amp; (!(j%%2) || !has.upper || !has.lower)) # localAxis(1 + 2 * row1attop, x[, j], x[, i], # ...) # draw x-axis if (i != j) #(i == nc &amp; j != nc) localAxis(1, xvals, yvals, ...) # draw y-axis if (j != i) #(j == 1 &amp; i != 1) localAxis(2, xvals, yvals, ...) # if (j == nc &amp;&amp; (i%%2 || !has.upper || !has.lower)) # localAxis(4, x[, j], x[, i], ...) mfg &lt;- par(&quot;mfg&quot;) if (i == j) { if (has.diag) localDiagPanel(as.vector(yvals), ...) if (has.labs) { par(usr = c(0, 1, 0, 1)) if (is.null(cex.labels)) { l.wid &lt;- strwidth(labels, &quot;user&quot;) cex.labels &lt;- max(0.8, min(2, 0.9/max(l.wid))) } text.panel(0.5, label.pos, labels[i], cex = cex.labels, font = font.labels) } } else if (i &lt; j) localLowerPanel(as.vector(xvals), as.vector(yvals), col=col, ...) else localUpperPanel(as.vector(xvals), as.vector(yvals), col=col, ...) if (any(par(&quot;mfg&quot;) != mfg)) stop(&quot;the 'panel' function made a new plot&quot;) } else par(new = FALSE) } if (!is.null(main)) { font.main &lt;- if (&quot;font.main&quot; %in% nmdots) dots$font.main else par(&quot;font.main&quot;) cex.main &lt;- if (&quot;cex.main&quot; %in% nmdots) dots$cex.main else par(&quot;cex.main&quot;) mtext(main, 3, 3, TRUE, 0.5, cex = cex.main, font = font.main) } invisible(NULL) }### Demo it:demo_pairs3 = function (custom_fun=F) { data(iris) xy_conv = function(x,y) { res = list(); res[['x']] = (x+y)/2; res[['y']] = x - y; return(res); } if (custom_fun) { pairs3(iris[1:4], XY_convert_fun = xy_conv, main = &quot;Anderson's Iris Data -- 3 species&quot;,pch = 21, bg = c(&quot;red&quot;, &quot;green3&quot;, &quot;blue&quot;)[unclass(iris$Species)]) } else { pairs3(iris[1:4], main = &quot;Anderson's Iris Data -- 3 species&quot;,pch = 21, bg = c(&quot;red&quot;, &quot;green3&quot;, &quot;blue&quot;)[unclass(iris$Species)]) }} vioplot2.R ## from: https://github.com/trinityrnaseq/trinityrnaseq/blob/master/Analysis/DifferentialExpression/R/vioplot2.R###################################################################################### From: https://stackoverflow.com/questions/22410606/violin-plot-with-list-input### and slightly modified to my liking here.vioplot2&lt;-function (x, ..., range = 1.5, h = NULL, ylim = NULL, names = NULL, horizontal = FALSE, col = c(&quot;magenta&quot;), border = &quot;black&quot;, lty = 1, lwd = 1, rectCol = &quot;black&quot;, colMed = &quot;white&quot;, pchMed = 19, at, add = FALSE, wex = 1, drawRect = TRUE){ library(sm) if(!is.list(x)){ datas &lt;- list(x, ...) } else{ datas&lt;-x } n &lt;- length(datas) if (missing(at)) at &lt;- 1:n upper &lt;- vector(mode = &quot;numeric&quot;, length = n) lower &lt;- vector(mode = &quot;numeric&quot;, length = n) q1 &lt;- vector(mode = &quot;numeric&quot;, length = n) q3 &lt;- vector(mode = &quot;numeric&quot;, length = n) med &lt;- vector(mode = &quot;numeric&quot;, length = n) base &lt;- vector(mode = &quot;list&quot;, length = n) height &lt;- vector(mode = &quot;list&quot;, length = n) baserange &lt;- c(Inf, -Inf) args &lt;- list(display = &quot;none&quot;) if (!(is.null(h))) args &lt;- c(args, h = h) for (i in 1:n) { data &lt;- datas[[i]] data.min &lt;- min(data) data.max &lt;- max(data) q1[i] &lt;- quantile(data, 0.25) q3[i] &lt;- quantile(data, 0.75) med[i] &lt;- median(data) iqd &lt;- q3[i] - q1[i] upper[i] &lt;- min(q3[i] + range * iqd, data.max) lower[i] &lt;- max(q1[i] - range * iqd, data.min) est.xlim &lt;- c(min(lower[i], data.min), max(upper[i], data.max)) smout &lt;- do.call(&quot;sm.density&quot;, c(list(data, xlim = est.xlim), args)) hscale &lt;- 0.4/max(smout$estimate) * wex base[[i]] &lt;- smout$eval.points height[[i]] &lt;- smout$estimate * hscale t &lt;- range(base[[i]]) baserange[1] &lt;- min(baserange[1], t[1]) baserange[2] &lt;- max(baserange[2], t[2]) } if (!add) { xlim &lt;- if (n == 1) at + c(-0.5, 0.5) else range(at) + min(diff(at))/2 * c(-1, 1) if (is.null(ylim)) { ylim &lt;- baserange } } if (is.null(names)) { label &lt;- 1:n } else { label &lt;- names } boxwidth &lt;- 0.05 * wex if (!add) plot.new() if (!horizontal) { if (!add) { plot.window(xlim = xlim, ylim = ylim) axis(2) axis(1, at = at, label = label) } box() for (i in 1:n) { polygon(c(at[i] - height[[i]], rev(at[i] + height[[i]])), c(base[[i]], rev(base[[i]])), col = col[i], border = border, lty = lty, lwd = lwd) if (drawRect) { lines(at[c(i, i)], c(lower[i], upper[i]), lwd = lwd, lty = lty) rect(at[i] - boxwidth/2, q1[i], at[i] + boxwidth/2, q3[i], col = rectCol) points(at[i], med[i], pch = pchMed, col = colMed) } } } else { if (!add) { plot.window(xlim = ylim, ylim = xlim) axis(1) axis(2, at = at, label = label) } box() for (i in 1:n) { polygon(c(base[[i]], rev(base[[i]])), c(at[i] - height[[i]], rev(at[i] + height[[i]])), col = col[i], border = border, lty = lty, lwd = lwd) if (drawRect) { lines(c(lower[i], upper[i]), at[c(i, i)], lwd = lwd, lty = lty) rect(q1[i], at[i] - boxwidth/2, q3[i], at[i] + boxwidth/2, col = rectCol) points(med[i], at[i], pch = pchMed, col = colMed) } } } invisible(list(upper = upper, lower = lower, median = med, q1 = q1, q3 = q3))}","link":"/2019/08/13/R/edgeR/"},{"title":"geom_boxplot | ggplot examples","text":"Quick Start library(ggplot2)library(patchwork)p1&lt;- ggplot(ChickWeight,aes(x=Time,y=weight)) + geom_boxplot()+ theme_light() + ggtitle(&quot;P1&quot;)ChickWeight$Time &lt;- factor(ChickWeight$Time)p2&lt;- ggplot(ChickWeight,aes(x=Time,y=weight)) + geom_boxplot()+ theme_light() + ggtitle(&quot;P2&quot;)ChickWeight$Diet &lt;- factor(ChickWeight$Diet)p3&lt;- ggplot(ChickWeight,aes(x=Time,y=weight)) + geom_boxplot(aes(fill=Diet))+ theme_light() + ggtitle(&quot;P3&quot;)p4&lt;- ggplot(ChickWeight,aes(x=Time,y=weight)) + geom_boxplot(aes(group=Diet, fill=Diet))+ theme_light() + ggtitle(&quot;P4&quot;)GGlay = 'ABBBBCCCCD'p1+p2+p3+p4 + plot_layout(design = GGlay)##ggsave('box1.png') As you can see, we can separate the box by call the axis.x Time as factors (p2). Add smooth line ggplot(ChickWeight,aes(x=Time,y=weight)) + geom_boxplot(aes(fill=Diet),alpha=0.4)+ theme_light() + ggtitle(&quot;P3&quot;)+ geom_smooth(aes(group=Diet),color='red')+ facet_wrap(~Diet)","link":"/2020/06/28/R/geom_boxplot/"},{"title":"geom_curve | ggplot","text":"Quick Start ggplot() + geom_curve( aes(x = 1, y = 1, xend= 6, yend = 6)) geom_segment draws a straight line between points (x, y) and (xend, yend). geom_curve draws a curved line. Arguments ncp p &lt;- ggplot()for(i in c(1:10)){ p &lt;- p+ geom_curve( aes(x = 1, y = 1, xend= 6, yend = 6),ncp = i)}p+ theme_light() curvature p &lt;- ggplot()for(i in c(-10:10)){ p &lt;- p+ geom_curve( aes(x = 1, y = 1, xend= 6, yend = 6), curvature = i*0.1)}p+ theme_light()+ expand_limits(x=c(0,10),y=c(0,6)) angle p &lt;- ggplot()for(i in c(1:9)){ p &lt;- p+ geom_curve( aes(x = 1, y = 1, xend= 6, yend = 6), angle = i*10)}p+ theme_light()+ expand_limits(x=c(0,10),y=c(0,6))","link":"/2020/06/19/R/geom_curve/"},{"title":"geom_hex | ggplot examples","text":"Quick Start library(ggthemes)library(ggplot2)library(patchwork)world &lt;- map_data(&quot;world&quot;)ggplot(world, aes(long, lat)) + geom_hex() + theme_map() Arguments bins ggplot(world, aes(long, lat)) + geom_hex(bins = 40) + theme_map()P1 &lt;-ggplot(world, aes(long, lat)) + geom_hex(bins = 20) + theme_map() + ggtitle('bins=20') P2 &lt;-ggplot(world, aes(long, lat)) + geom_hex(bins = 80) + theme_map() + ggtitle('bins=80') P1|P2 binwidth ggplot(world, aes(long, lat)) + geom_hex(binwidth = c(1, 10)) + theme_map() More","link":"/2020/06/19/R/geom_hex/"},{"title":"geom_pie | ggfan |ggplot examples","text":"Install ##install.packages(&quot;ggfan&quot;) # or##devtools::install_github(&quot;jasonhilton/ggfan&quot;) Quick Start Reference: library(ggplot2)df &lt;- data.frame( group = c(&quot;Male&quot;, &quot;Female&quot;, &quot;Child&quot;), value = c(25, 25, 50) )head(df) group value1 Male 252 Female 253 Child 50 library(ggplot2)library(ggthemes)pie &lt;- ggplot(df, aes(x=&quot;&quot;, y=value, fill=group))+ geom_bar(width = 1, stat = &quot;identity&quot;) + coord_polar(&quot;y&quot;, start=0) + theme_map()pieggsave(&quot;pie.png&quot;, w=3.17, h=2.92) pie + scale_fill_manual(values=c(&quot;#999999&quot;, &quot;#E69F00&quot;, &quot;#56B4E9&quot;))ggsave('pie2.png', wi=4.6, hei=3.76) pie + scale_fill_manual(values=c(&quot;#999999&quot;, &quot;#E69F00&quot;, &quot;#56B4E9&quot;)) + geom_text(aes(y = value/3 + c(0, cumsum(value)[-length(value)]), label = paste(value*100/sum(value),&quot;%&quot;, sep=''))) Ring pie pie + scale_fill_manual(values=c(&quot;#999999&quot;, &quot;#E69F00&quot;, &quot;#56B4E9&quot;)) + geom_text(aes(y = value/3 + c(0, cumsum(value)[-length(value)]), label = paste(value*100/sum(value),&quot;%&quot;, sep='')))+ expand_limits(x=c(-1,1)) Multi-layer TB = rbind(df,df)TB$Sub = c(10,15,15,15,10,35)TB$Group = c(rep(&quot;A&quot;,3),rep(&quot;B&quot;,3))ggplot(TB) + geom_bar(data=TB[1:3,],aes(x=&quot;A&quot;,y=value[1:3], fill=group),stat = 'identity') + geom_bar(aes(x=&quot;B&quot;,y =Sub, fill=Group),stat='identity')+ coord_polar('y') Rose Plot Reference: 九茶 library(ggplot2)dt = data.frame(A = c(2, 7, 4, 10, 1), B = c('B','A','C','D','E'))ggplot(dt, aes(x = B, y = log(1+A), fill = B)) + geom_bar(stat = &quot;identity&quot;, alpha = 0.7) + coord_polar() + theme_light() pie 3D For pie3D, you’d like to install plotrix first. install.packages(&quot;plotrix&quot;)library(&quot;plotrix&quot;)x &lt;-c(10,20,30,40,50)label &lt;-c(&quot;Alabama&quot;, &quot;Alaska&quot;, &quot;Arizona&quot;,&quot;Arkansas&quot;, &quot;California&quot;)pie3D(x,labels=label,explode=0.1,main=&quot;PieChart of Countries &quot;) More pie author: 陈娜 Pie Pie3D Fan © 陈娜 2015 SALVAGING THE PIE","link":"/2020/06/18/R/geom_pie/"},{"title":"geom_qq","text":"geom_qq QQ plot ggplot(mtcars,aes(sample=mpg)) + geom_qq(aes(color='qq')) + geom_point(aes(mpg,cyl,color='point'))+ geom_qq_line(aes(color='qqline'))+ theme_light() 我也没有搞懂是啥意思- -线马上,下次再来看 More","link":"/2020/06/18/R/geom_qq/"},{"title":"geom_quantile","text":"geom_quantile source:https://ggplot2.tidyverse.org/reference/geom_quantile.html Quick Start ggplot(mpg, aes(displ, hwy)) + geom_point()+ geom_quantile(quantiles=0.5) 回归直线吧 More","link":"/2020/06/19/R/geom_quantile/"},{"title":"geom_rangeframe","text":"geom_rangeframe library(ggthemes)library(patchwork)library(ggplot2)P1 &lt;- ggplot(mtcars,aes(wt,mpg))+ ggtitle('Has rangeframe')+ geom_point()+geom_rangeframe()+theme_tufte()+ theme(plot.title=element_text(hjust=0.5))P2 &lt;- ggplot(mtcars,aes(wt,mpg))+ ggtitle('No rangeframe')+ geom_point()+theme_tufte()+ theme(plot.title=element_text(hjust=0.5))P1|P2 More","link":"/2020/06/19/R/geom_rangeframe/"},{"title":"geom_rect | ggplot examples","text":"Quick Start mydata &lt;- data.frame( Lebal = c(&quot;Point1&quot;,&quot;Point2&quot;,&quot;Point3&quot;,&quot;Point4&quot;,&quot;Point5&quot;), xstart = c(5.5,15.7,19.5,37.2,36.9), xend = c(9.7,28.1,24.6,44.6,47.1), ystart = c(9.6,23.1,2.3,33.2,9.2), yend = c(16.1,36.2,11.7,38.5,15.3), size = c(12,48,30,11.5,28), class = c(&quot;A&quot;,&quot;A&quot;,&quot;A&quot;,&quot;C&quot;,&quot;C&quot;))ggplot(mydata)+ geom_rect(aes(xmin = xstart,xmax = xend ,ymin = ystart , ymax = yend , fill = class)) + scale_fill_wsj() + theme_map() More","link":"/2020/06/19/R/geom_rect/"},{"title":"geom_rug","text":"geom_rug Quick Inst library(ggplot2)library(patchworks)ggplot(mtcars,aes(wt,mpg))+ geom_point( color=&quot;grey50&quot;) + geom_rug() + theme_light() arguments outside ggplot(mtcars,aes(wt,mpg))+ geom_point( color=&quot;grey50&quot;) + theme_light()+geom_rug( outside = TRUE)+ coord_cartesian(clip = &quot;off&quot;) side library(patchwork)P1 &lt;- ggplot(mtcars,aes(wt,mpg))+ geom_point( color=&quot;grey50&quot;) + theme_light()+ geom_rug( sides='t', color='red') + ggtitle('t') +theme(plot.title = element_text(hjust = 0.5))P2 &lt;- ggplot(mtcars,aes(wt,mpg))+ geom_point( color=&quot;grey50&quot;) + theme_light()+ geom_rug( sides='r', color='red') + ggtitle('r') +theme(plot.title = element_text(hjust = 0.5))P3 &lt;- ggplot(mtcars,aes(wt,mpg))+ geom_point( color=&quot;grey50&quot;) + theme_light()+ geom_rug( sides='b', color='red') + ggtitle('b') +theme(plot.title = element_text(hjust = 0.5))P4 &lt;- ggplot(mtcars,aes(wt,mpg))+ geom_point( color=&quot;grey50&quot;) + theme_light()+ geom_rug( sides='l', color='red') + ggtitle('l') +theme(plot.title = element_text(hjust = 0.5))(P1|P2)/(P3|P4) length P1&lt;- ggplot(mtcars,aes(wt,mpg))+ geom_point( color=&quot;grey50&quot;) + theme_light()+ geom_rug()+ ggtitle('NA') + theme(plot.title = element_text(hjust = 0.5))P2&lt;- ggplot(mtcars,aes(wt,mpg))+ geom_point( color=&quot;grey50&quot;) + theme_light()+ geom_rug( length = unit(0.5, &quot;npc&quot;))+ ggtitle('0.5') + theme(plot.title = element_text(hjust = 0.5))P3&lt;- ggplot(mtcars,aes(wt,mpg))+ geom_point( color=&quot;grey50&quot;) + theme_light()+ geom_rug( length = unit(1, &quot;npc&quot;))+ ggtitle('1') + theme(plot.title = element_text(hjust = 0.5))P1/(P2|P3)","link":"/2020/06/19/R/geom_rug/"},{"title":"geom_segment | ggplot examples| vectors","text":"Quick Start library(ggplot2)library(ggtheme)ggplot(seals, aes(long, lat)) + theme_map() geom_segment(aes(xend = long + delta_long, yend = lat + delta_lat), arrow = arrow(length = unit(0.1,&quot;cm&quot;))) length P1 &lt;- ggplot(seals, aes(long, lat)) + theme_map()+ ggtitle('0.1')+ geom_segment(aes(xend = long + delta_long, yend = lat + delta_lat), arrow = arrow(length = unit(0.1,&quot;cm&quot;)))+ theme(plot.title = element_text(hjust = 0.5))P2 &lt;- ggplot(seals, aes(long, lat)) + theme_map()+ ggtitle('0.3')+ geom_segment(aes(xend = long + delta_long, yend = lat + delta_lat), arrow = arrow(length = unit(0.3,&quot;cm&quot;)))+ theme(plot.title = element_text(hjust = 0.5))P1|P2 Bar counts &lt;- as.data.frame(table(x = rpois(100,5)))counts$x &lt;- as.numeric(as.character(counts$x))ggplot(counts, aes(x, Freq)) + theme_light() geom_segment(aes(xend = x, yend = 0), size = 10, lineend = &quot;butt&quot;) geom_spoke df &lt;- expand.grid(x = 1:10, y=1:10)df$angle &lt;- runif(100, 0, 2*pi)df$speed &lt;- runif(100, 0, sqrt(0.1 * df$x))ggplot(df, aes(x, y)) + geom_point() + theme_light()+ geom_spoke(aes(angle = angle), radius = 0.5) ![NuUqfA.png](https://s1.ax1x.com/2020/06/19/NuUqfA.png) More","link":"/2020/06/19/R/geom_segment/"},{"title":"geom_sf | ggplot for maps","text":"Quick Start library(ggplot2)nc &lt;- sf::st_read(system.file(&quot;shape/nc.shp&quot;, package = &quot;sf&quot;), quiet = TRUE)ggplot(nc) + geom_sf(aes(fill = AREA))+ theme_light() This function needs “shp” data set. Coordinate information was in geometry column ggplot()nc &lt;- sf::st_read(system.file(&quot;shape/nc.shp&quot;, package = &quot;sf&quot;), quiet = TRUE)ggplot(nc) + geom_sf(aes(fill = AREA))world2 &lt;- sf::st_transform(world1, &quot;+proj=laea +y_0=0 +lon_0=155 +lat_0=-90 +ellps=WGS84 +no_defs&quot;) ggplot() + geom_sf(data = world2)+ theme_map() Arguments list coord_sf(xlim = NULL, ylim = NULL, expand = TRUE, crs = NULL, datum = sf::st_crs(4326), label_graticule = waiver(), label_axes = waiver(), ndiscr = 100, default = FALSE, clip = &quot;on&quot;)geom_sf(mapping = aes(), data = NULL, stat = &quot;sf&quot;, position = &quot;identity&quot;, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE, ...)geom_sf_label(mapping = aes(), data = NULL, stat = &quot;sf_coordinates&quot;, position = &quot;identity&quot;, ..., parse = FALSE, nudge_x = 0, nudge_y = 0, label.padding = unit(0.25, &quot;lines&quot;), label.r = unit(0.15, &quot;lines&quot;), label.size = 0.25, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE, fun.geometry = NULL)geom_sf_text(mapping = aes(), data = NULL, stat = &quot;sf_coordinates&quot;, position = &quot;identity&quot;, ..., parse = FALSE, nudge_x = 0, nudge_y = 0, check_overlap = FALSE, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE, fun.geometry = NULL)stat_sf(mapping = NULL, data = NULL, geom = &quot;rect&quot;, position = &quot;identity&quot;, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE, ...) China City Specific Date is comming from GuangchuangYulocation: https://github.com/GuangchuangYu/map_dataBut as you know, downloading Data from Github is preaty slow. Quick Start library(ggplot2)data &lt;- readRDS(&quot;cn_city_map.rds&quot;)ggplot(data) + geom_sf(aes(fill = OBJECTID))+ theme_light() Location for main City (Data is from skyme) City_loc = read.csv(text = &quot;城市,jd,wd北京,116.4666667,39.9上海,121.4833333,31.23333333天津,117.1833333,39.15重庆,106.5333333,29.53333333哈尔滨,126.6833333,45.75长春,125.3166667,43.86666667沈阳,123.4,41.83333333呼和浩特,111.8,40.81666667石家庄,114.4666667,38.03333333太原,112.5666667,37.86666667济南,117,36.63333333郑州,113.7,34.8西安,108.9,34.26666667兰州,103.8166667,36.05银川,106.2666667,38.33333333西宁,101.75,36.63333333乌鲁木齐,87.6,43.8合肥,117.3,31.85南京,118.8333333,32.03333333杭州,120.15,30.23333333长沙,113,28.18333333南昌,115.8666667,28.68333333武汉,114.35,30.61666667成都,104.0833333,30.65贵阳,106.7,26.58333333福州,119.3,26.08333333台北,121.5166667,25.05广州,113.25,23.13333333海口,110.3333333,20.03333333南宁,108.3333333,22.8昆明,102.6833333,25拉萨,91.16666667,29.66666667香港,114.1666667,22.3澳门,113.5,22.2&quot;) Pinning the cities library(ggrepel)ggplot(data) + geom_sf(aes(fill = OBJECTID))+ geom_point(data=City_loc,aes(x=jd,y=wd))+ geom_text_repel(data=City_loc,aes(x=jd,y=wd,label=城市))+ theme_light() More","link":"/2020/06/19/R/geom_sf/"},{"title":"geom_step | ggplot examples","text":"Quick Start library(ggplot2)d=data.frame(x=c(1,2,4,5,7,8,9), y=c(1,2,3,5,6,7,9))ggplot() + theme_light()+ geom_step(data=d, mapping=aes(x=x, y=y)) +geom_step(data=d, mapping=aes(x=x, y=y), direction=&quot;vh&quot;, linetype=3) +geom_point(data=d, mapping=aes(x=x, y=y), color=&quot;red&quot;) More","link":"/2020/06/19/R/geom_step/"},{"title":"geom_tile","text":"Quick Start library(ggplot2)df &lt;- data.frame( x = rep(c(2, 5, 7, 9, 12), 2), y = rep(c(1, 2), each = 5), z = factor(rep(1:5, each = 2)), w = rep(diff(c(0, 4, 6, 8, 10, 14)), 2))ggplot(df, aes(x, y)) + theme_light()+ geom_tile(aes(fill = z), colour = &quot;grey50&quot;) library(patchwork)P1 &lt;- ggplot(df, aes(x, y)) + theme_light()+ ggtitle('P1')+ geom_tile(aes(fill = z), colour = &quot;grey50&quot;)+ theme(plot.title = element_text(hjust = 0.5))P2 &lt;- ggplot(df, aes(x, y, width = w)) + theme_light()+ ggtitle('P2')+ theme(plot.title = element_text(hjust = 0.5))+ geom_tile(aes(fill = z), colour = &quot;grey50&quot;)P3 &lt;- ggplot(df, aes(x, y))+ geom_bar(aes(fill=z),stat='identity')+ theme_light()+ ggtitle('bar plot')+ theme(plot.title = element_text(hjust = 0.5))(P1|P2)/P3 More","link":"/2020/08/11/R/geom_tile/"},{"title":"geom_tufteboxplot | ggplot examples | Another boxplot","text":"Quick Start library(ggplot2)library(patchwork)p &lt;- ggplot(mtcars, aes(factor(cyl), mpg))### with a point for the median and lines for whiskersP1 &lt;- p + geom_tufteboxplot() + theme_light()+ ggtitle('P1')+ theme(plot.title = element_text(hjust = 0.5))### with a line for the interquartile range and points for whiskersP2 &lt;- p + geom_tufteboxplot(median.type = &quot;line&quot;, whisker.type = &quot;point&quot;, hoffset = 0)+ theme_light()+ ggtitle('P2')+theme(plot.title = element_text(hjust = 0.5))### with a wide line for the interquartile range and lines for whiskersP3 &lt;- p + geom_tufteboxplot(median.type = &quot;line&quot;, hoffset = 0, width = 3) + theme_light()+ ggtitle('P3')+theme(plot.title = element_text(hjust = 0.5))### with an offset line for the interquartile range and lines for whiskersP4 &lt;- p + geom_tufteboxplot(median.type = &quot;line&quot;) + theme_light()+ ggtitle('P4')+ theme(plot.title = element_text(hjust = 0.5))P5 &lt;- p + geom_point() + theme_light() + ggtitle('Scatter')+ theme(plot.title = element_text(hjust = 0.5))P6 &lt;- p + geom_boxplot()+ theme_light()+ ggtitle('Boxplot')+ theme(plot.title = element_text(hjust = 0.5))(P1|P2|P3)/(P5|P4|P6)","link":"/2020/08/13/R/geom_tufteboxplot/"},{"title":"geom_violin| ggplot examples","text":"Quick Start library(ggplot2)p &lt;- ggplot(mtcars, aes(factor(cyl), mpg))p + geom_violin()+ geom_point() + theme_light() scale p + geom_violin(scale = &quot;width&quot;)+ theme_light() draw_quantiles p + geom_violin(aes(fill = factor(cyl)),draw_quantiles = c(0.25, 0.5, 0.75))","link":"/2020/08/13/R/geom_violin/"},{"title":"ggalluvial (Picture needed)","text":"ggalluvial (Picture needed) vignette(topic = &quot;ggalluvial&quot;, package = &quot;ggalluvial&quot;)library(ggalluvial)titanic_wide &lt;- data.frame(Titanic)ggplot(data = titanic_wide,aes(axis1 = Class, axis2 = Sex, axis3 = Age,weight = Freq)) +scale_x_discrete(limits = c(&quot;Class&quot;, &quot;Sex&quot;, &quot;Age&quot;), expand = c(.1, .05)) +geom_alluvium(aes(fill = Survived)) +geom_stratum() + geom_text(stat = &quot;stratum&quot;, label.strata = TRUE) +theme_minimal() +ggtitle(&quot;passengers on the maiden voyage of the Titanic&quot;,&quot;stratified by demographics and survival&quot;)ggplot(as.data.frame(UCBAdmissions),aes(weight = Freq, axis1 = Gender, axis2 = Dept)) +geom_alluvium(aes(fill = Admit), width = 1/12) +geom_stratum(width = 1/12, fill = &quot;black&quot;, color = &quot;grey&quot;) +geom_label(stat = &quot;stratum&quot;, label.strata = TRUE) +scale_x_continuous(breaks = 1:2, labels = c(&quot;Gender&quot;, &quot;Dept&quot;)) +scale_fill_brewer(type = &quot;qual&quot;, palette = &quot;Set1&quot;) +ggtitle(&quot;UC Berkeley admissions and rejections, by sex and department&quot;)ggplot(as.data.frame(Titanic),aes(weight = Freq,axis1 = Survived, axis2 = Sex, axis3 = Class)) +geom_alluvium(aes(fill = Class),width = 0, knot.pos = 0, reverse = FALSE) +guides(fill = FALSE) +geom_stratum(width = 1/8, reverse = FALSE) +geom_text(stat = &quot;stratum&quot;, label.strata = TRUE, reverse = FALSE) +scale_x_continuous(breaks = 1:3, labels = c(&quot;Survived&quot;, &quot;Sex&quot;, &quot;Class&quot;)) +coord_flip() +ggtitle(&quot;Titanic survival by class and sex&quot;)5. 绘制非等高冲击图library('alluvial')data(Refugees, package = &quot;alluvial&quot;)country_regions &lt;- c(Afghanistan = &quot;Middle East&quot;,Burundi = &quot;Central Africa&quot;,Congo DRC = &quot;Central Africa&quot;,Iraq = &quot;Middle East&quot;,Myanmar = &quot;Southeast Asia&quot;,Palestine = &quot;Middle East&quot;,Somalia = &quot;Horn of Africa&quot;,Sudan = &quot;Central Africa&quot;,Syria = &quot;Middle East&quot;,Vietnam = &quot;Southeast Asia&quot;)Refugeescountry]ggplot(data = Refugees,aes(x = year, weight = refugees, alluvium = country)) +geom_alluvium(aes(fill = country, colour = country),alpha = .75, decreasing = FALSE) +scale_x_continuous(breaks = seq(2003, 2013, 2)) +theme(axis.text.x = element_text(angle = -30, hjust = 0)) +scale_fill_brewer(type = &quot;qual&quot;, palette = &quot;Set3&quot;) +scale_color_brewer(type = &quot;qual&quot;, palette = &quot;Set3&quot;) +facet_wrap(~ region, scales = &quot;fixed&quot;) +ggtitle(&quot;refugee volume by country and region of origin&quot;)###6. 等高非等量关系data(majors)majorscurriculum)ggplot(majors,aes(x = semester, stratum = curriculum, alluvium = student,fill = curriculum, label = curriculum)) +scale_fill_brewer(type = &quot;qual&quot;, palette = &quot;Set2&quot;) +geom_flow(stat = &quot;alluvium&quot;, lode.guidance = &quot;rightleft&quot;,color = &quot;darkgray&quot;) +geom_stratum() +theme(legend.position = &quot;bottom&quot;) +ggtitle(&quot;student curricula across several semesters&quot;)7. 工作状态时间变化图data(vaccinations)levels(vaccinationsresponse))ggplot(vaccinations,aes(x = survey, stratum = response, alluvium = subject,weight = freq,fill = response, label = response)) +geom_flow() +geom_stratum(alpha = .5) +geom_text(stat = &quot;stratum&quot;, size = 3) +theme(legend.position = &quot;none&quot;) +ggtitle(&quot;vaccination survey responses at three points in time&quot;)8. 分类学门水平相对丰度实战df=data.frame(Phylum=c(&quot;Ruminococcaceae&quot;,&quot;Bacteroidaceae&quot;,&quot;Eubacteriaceae&quot;,&quot;Lachnospiraceae&quot;,&quot;Porphyromonadaceae&quot;),GroupA=c(37.7397,31.34317,222.08827,5.08956,3.7393),GroupB=c(113.2191,94.02951,66.26481,15.26868,11.2179),GroupC=c(123.2191,94.02951,46.26481,35.26868,1.2179),GroupD=c(37.7397,31.34317,222.08827,5.08956,3.7393))数据转换长表格library(reshape2)melt_df = melt(df)绘制分组对应的分类学，有点像circosggplot(data = melt_df,aes(axis1 = Phylum, axis2 = variable,weight = value)) +scale_x_discrete(limits = c(&quot;Phylum&quot;, &quot;variable&quot;), expand = c(.1, .05)) +geom_alluvium(aes(fill = Phylum)) +geom_stratum() + geom_text(stat = &quot;stratum&quot;, label.strata = TRUE) +theme_minimal() +ggtitle(&quot;Phlyum abundance in each group&quot;) More","link":"/2020/06/19/R/ggalluvial/"},{"title":"R-gganimate | ggplot examples","text":"library(ggplot2)library(gganimate)ggplot(mtcars, aes(factor(cyl), mpg)) +geom_boxplot()TB= data.frame(Shrink(world,40),Group=1)Num=1for(i in c(1:36)){ tmp = data.frame(Shrink(world,40),Group=1) Num= Num+1 tmp$lat = tmp$lat +rnorm(nrow(tmp),0,1) tmp$Group=Num TB = rbind(TB,tmp)}## animation::ani.options(ani.width= 1000, ani.height=1000, ani.res = 1000)ggplot()+ geom_point(data=TB,aes(x=long, y=lat),size=0.3, color=&quot;#00518E&quot;) + theme_map() + coord_map(&quot;ortho&quot;, orientation = c(30, 100, 0)) + transition_time(Group)anim_save(&quot;map.gif&quot;) Here comes the gganimate code transition_states( gear, transition_length = 2, state_length = 1)enter_fade()exit_shrink()ease_aes('sine-in-out') Animate bar https://gganimate.com/ library(gapminder)ggplot(gapminder, aes(gdpPercap, lifeExp, size = pop, colour = country)) + geom_point(alpha = 0.7, show.legend = FALSE) + scale_colour_manual(values = country_colors) + scale_size(range = c(2, 12)) + scale_x_log10() + facet_wrap(~continent) Here comes the gganimate specific bits labs(title = 'Year: {frame_time}', x = 'GDP per capita', y = 'life expectancy') +transition_time(year) +ease_aes('linear') save anim_save(&quot;test.gif&quot;)d &lt;- trans_3d_2d(Ball[1:3]) dX4","link":"/2020/06/19/R/gganimate/"},{"title":"ggbio","text":"ggbio SNP plot from bam file To plot this plot, you need the By doing this, we need a genome vector we build by BSgenome. You can follow the instruction to build your own BSgenome library. Here what I use is pre-build and name as BSgenome.dme.BDGP6.32 Bam file was load by Rsamtools library(ggbio)library(Rsamtools)library(BSgenome.dme.BDGP6.32)# define the regions you'd like to checkwh &lt;- as(c(&quot;2R:24671294-24687896&quot;), &quot;GRanges&quot;)bam&lt;-BamFile(file=&quot;out.bam&quot;, index=&quot;out.bam.bai&quot;)autoplot(bam, which =wh, bsgenome =BSgenome.dme.BDGP6.32, stat = &quot;mismatch&quot;) GTF files For this plot, some gtf files can not call gene names. So, I’ll show an Alternative why to show symbols in the plot. Reference: girke.bioinformatics.ucr.edu; 2016 library(ggbio)library(rtracklayer)library(GenomicFeatures)library(clusterProfiler)library(org.Dm.eg.db)txdb &lt;- makeTxDbFromGFF(file=&quot;genom.gtf&quot;, format=&quot;gtf&quot;)Trans &lt;- transcriptsBy(txdb, &quot;gene&quot;)tmp &lt;- bitr(names(Trans), fromType=&quot;FLYBASE&quot;, toType=&quot;SYMBOL&quot;, OrgDb=&quot;org.Dm.eg.db&quot;)names(Trans)[!is.na(tmp[[2]][match(names(Trans), tmp[[1]])])] &lt;- tmp[[2]][match(names(Trans), tmp[[1]])][!is.na(tmp[[2]][match(names (Trans), tmp[[1]])])]P1 &lt;- autoplot(txdb, which= Trans$Mmp1)+ theme_bw()tmp = range(Trans$Mmp1)rg = c(tmp@ranges@start, tmp@ranges@start+tmp@ranges@width)wh = as(c(paste(tmp@seqnames@values, &quot;:&quot;, tmp@ranges@start, &quot;-&quot;, tmp@ranges@start+tmp@ranges@width, sep =&quot;&quot;)), &quot;GRanges&quot;)P2 &lt;- autoplot(bam, which =wh, bsgenome =BSgenome.dme.BDGP6.32, stat = &quot;mismatch&quot;) + theme_bw() + theme(legend.position=&quot;none&quot;)tracks(Coverage=P2, Transcripts=P1, heights = c(0.2, 0.1)) + ylab(&quot;&quot;) VCF file plot library(reshape2)library(VariantAnnotation)VCF &lt;- read.table(&quot;out.vcf&quot;)TB &lt;- VCF[VCF$V1== as.character(tmp@seqnames@values),]TB &lt;- TB[TB$V2&gt;=min(rg),]TB &lt;- TB[TB$V2&lt;=max(rg),]TB &lt;- TB[c(&quot;V2&quot;, &quot;V4&quot;, &quot;V5&quot;)]colnames(TB) &lt;- c(&quot;x&quot;, &quot;Ref&quot;, &quot;Alt&quot;)TB &lt;- melt(TB, id.vars = &quot;x&quot; )P1 &lt;- autoplot(txdb, which= Trans$Mmp1, gap.geom = &quot;chevron&quot;)+ theme_bw() + geom_text(aes(x=0, y=0, label=0,color=&quot;red&quot;))+ coord_cartesian(xlim =rg, expand = T)P2 &lt;- autoplot(bam, which =wh, bsgenome =BSgenome.dme.BDGP6.32, stat = &quot;mismatch&quot;) + theme_bw()P3 &lt;- ggplot() + geom_tile(data=TB,aes(x= x, y= variable, label=value, fill= value), width=(rg[2]-rg[1])/300) + coord_cartesian(xlim =rg, expand = T) + theme_bw()tracks(Coverage=P2, VCF = P3, Transcripts=P1, heights = c(0.2, 0.1, 0.2)) + ylab(&quot;&quot;) 3 in 1 function library(ggbio)library(reshape2)library(Rsamtools)library(rtracklayer)library(org.Dm.eg.db)library(GenomicFeatures)library(clusterProfiler)library(VariantAnnotation)library(BSgenome.dme.BDGP6.32)# read files: vcf, bam, gtfVCF &lt;- read.table(&quot;out.vcf&quot;) bam&lt;-BamFile(file=&quot;out.bam&quot;, index=&quot;out.bam.bai&quot;)txdb &lt;- makeTxDbFromGFF(file=&quot;genom.gtf&quot;, format=&quot;gtf&quot;)# Change the name of the Trans into SampleTrans &lt;- transcriptsBy(txdb, &quot;gene&quot;)tmp &lt;- bitr(names(Trans), fromType=&quot;FLYBASE&quot;, toType=&quot;SYMBOL&quot;, OrgDb=&quot;org.Dm.eg.db&quot;)names(Trans)[!is.na(tmp[[2]][match(names(Trans), tmp[[1]])])] &lt;- tmp[[2]][match(names(Trans), tmp[[1]])][!is.na(tmp[[2]][match(names (Trans), tmp[[1]])])]PLOT_3 &lt;- function(GENE){ tmp = range(Trans[GENE])[[1]] rg = c(tmp@ranges@start, tmp@ranges@start+tmp@ranges@width) wh = as(c(paste(tmp@seqnames@values, &quot;:&quot;, tmp@ranges@start, &quot;-&quot;, tmp@ranges@start+tmp@ranges@width, sep =&quot;&quot;)), &quot;GRanges&quot;) TB &lt;- VCF[VCF$V1== as.character(tmp@seqnames@values),] TB &lt;- TB[TB$V2&gt;=min(rg),] TB &lt;- TB[TB$V2&lt;=max(rg),] TB &lt;- TB[c(&quot;V2&quot;, &quot;V4&quot;, &quot;V5&quot;)] colnames(TB) &lt;- c(&quot;x&quot;, &quot;Ref&quot;, &quot;Alt&quot;) TB &lt;- melt(TB, id.vars = &quot;x&quot; ) P1 &lt;- autoplot(txdb, which= Trans[GENE][[1]], gap.geom = &quot;chevron&quot;)+ theme_bw() + geom_text(aes(x=0, y=0, label=0,color=&quot;red&quot;))+ coord_cartesian(xlim =rg, expand = T) P2 &lt;- autoplot(bam, which =wh, bsgenome =BSgenome.dme.BDGP6.32, stat = &quot;mismatch&quot;) + theme_bw() P3 &lt;- ggplot() + geom_tile(data=TB,aes(x= x, y= variable, label=value, fill= value), width=(rg[2]-rg[1])/300) + coord_cartesian(xlim =rg, expand = T) + theme_bw() tracks(Coverage=P2, VCF = P3, Transcripts=P1, heights = c(0.2, 0.1, 0.2)) + ylab(&quot;&quot;)}PLOT_3(&quot;Sin3A&quot;) Multiplot library(ggbio)library(stringr)library(reshape2)library(Rsamtools)library(rtracklayer)library(org.Dm.eg.db)library(GenomicFeatures)library(clusterProfiler)library(VariantAnnotation)library(BSgenome.dme.BDGP6.32)GTF= &quot;/media/ken/BackUP/Drosophila/Drosophila_melanogaster.BDGP6.32.104.chr.EGFP.GAL4.mCD8GFP.gtf&quot;txdb &lt;- makeTxDbFromGFF(file=GTF, format=&quot;gtf&quot;)# Change the name of the Trans into SampleTrans &lt;- transcriptsBy(txdb, &quot;gene&quot;)tmp &lt;- bitr(names(Trans), fromType=&quot;FLYBASE&quot;, toType=&quot;SYMBOL&quot;, OrgDb=&quot;org.Dm.eg.db&quot;)names(Trans)[!is.na(tmp[[2]][match(names(Trans), tmp[[1]])])] &lt;- tmp[[2]][match(names(Trans), tmp[[1]])][!is.na(tmp[[2]][match(names (Trans), tmp[[1]])])]BAM_Dir = &quot;/run/user/1000/gvfs/sftp:host=cypress1.tulane.edu,user=wliu15/lustre/project/wdeng7/wliu15/Bam/&quot;VCF_Dir = &quot;/run/user/1000/gvfs/sftp:host=cypress1.tulane.edu,user=wliu15/lustre/project/wdeng7/wliu15/vcf/&quot;Bam_list &lt;- c(&quot;wt_10day_1_S27Aligned.sortedByCoord.out.bam&quot;, &quot;G1F1_S31Aligned.sortedByCoord.out.bam&quot;, &quot;G50-FE_TUMOR-a_S37Aligned.sortedByCoord.out.bam&quot; )GENE = &quot;N&quot;RNA_plot &lt;- function(GENE){ tmp = range(Trans[GENE])[[1]] wh = as(c(paste(tmp@seqnames@values, &quot;:&quot;, tmp@ranges@start, &quot;-&quot;, tmp@ranges@start+tmp@ranges@width, sep =&quot;&quot;)), &quot;GRanges&quot;) rg = c(tmp@ranges@start, tmp@ranges@start+tmp@ranges@width) Result = c() Result2 = c() for (sample in Bam_list){ # read files: vcf, bam, gtf VCF &lt;- read.table(paste(VCF_Dir, sample, &quot;.vcf&quot;, sep='')) bam&lt;-BamFile(file=paste(BAM_Dir, sample, sep=&quot;&quot;), index=paste(BAM_Dir, sample, &quot;.bai&quot;, sep=&quot;&quot;)) P2 &lt;- autoplot(bam, which =wh, bsgenome =BSgenome.dme.BDGP6.32, stat = &quot;mismatch&quot;) + theme_bw() + guides(color=guide_legend(title=&quot;&quot;)) Result &lt;- c(Result, P2) TB &lt;- VCF[VCF$V1== as.character(tmp@seqnames@values),] TB &lt;- TB[TB$V2&gt;=min(rg),] TB &lt;- TB[TB$V2&lt;=max(rg),] TB &lt;- TB[c(&quot;V2&quot;, &quot;V4&quot;, &quot;V5&quot;)] colnames(TB) &lt;- c(&quot;x&quot;, &quot;Ref&quot;, &quot;Alt&quot;) TB &lt;- melt(TB, id.vars = &quot;x&quot; ) P3 &lt;- ggplot() + geom_tile(data=TB,aes(x= x, y= variable, label=value, fill= value), width=(rg[2]-rg[1])/300) + coord_cartesian(xlim =rg, expand = T) + theme_bw() Result2 &lt;- c(Result2, P3) } P1 &lt;- autoplot(txdb, which= wh)+ theme_bw() + geom_text(aes(x=0, y=0, label=0,color=&quot;red&quot;))+ coord_cartesian(xlim =rg, expand = T) tracks( c(Result,P1)) ggsave(paste(&quot;img/&quot;, GENE, '_RNA.png',sep= &quot;&quot;), w= 20 , h= 5.45)}ggsave(&quot;~/tmp/Mutation_GTF.png&quot;, w= 20 , h= 1.55) 0","link":"/2022/07/23/R/ggbio/"},{"title":"ggkaboom: minimal codes for ggplot","text":"ggkaboom ggkaboom is a ggplot extensions which compressed a set of code for statistics and quick graph. Install remotes::install_github(&quot;karobben/ggkaboom&quot;)library(ggkaboom) Kaboom_flow This is a flow chart which designed for show the dynamic change of the composition from each sample. Kaboom_flow(TB) A quick simulation data could be: A &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;, &quot;F&quot;, &quot;G&quot;, &quot;H&quot;, &quot;I&quot;, &quot;J&quot;, &quot;K&quot;, &quot;L&quot;, &quot;M&quot;)B &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;, &quot;F&quot;, &quot;K&quot;, &quot;L&quot;, &quot;M&quot;, &quot;N&quot;)C &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;, &quot;F&quot;, &quot;G&quot;, &quot;H&quot;, &quot;N&quot;,&quot;O&quot;)TB = data.frame(row.names = sort(unique(c(A,B,C))))Num = 0for(Col in list(A,B,C)){ Num = Num + 1 TB[paste(&quot;Group&quot;,Num, sep=&quot;_&quot;)] = 0 TB[paste(&quot;Group&quot;,Num, sep=&quot;_&quot;)][row.names(TB) %in% Col,] = 1}print(TB) Group_1 Group_2 Group_3 A 1 1 1 B 1 1 1 C 1 1 1 D 1 1 1 E 1 1 1 F 1 1 1 G 1 0 1 H 1 0 1 I 1 0 0 J 1 0 0 K 1 1 0 L 1 1 0 M 1 1 0 N 0 1 1 O 0 0 1 pre { background-color:#38393d; color: #5fd381; } Kaboom_break With this function, you can make as many breaks as you like by given y lims. remotes::install_github(&quot;karobben/ggkaboom&quot;)library(ggkaboom)data(cars)cars[1,2] =100000p &lt;- ggplot(cars,aes(x=speed,y=dist, fill=as.factor(speed))) + geom_bar(stat='identity')# For tow breakKaboom_break(p, c(0, 400, 10000, 120000), R=c(1, 4))# Three breaksKaboom_break(p, c(0, 15, 30, 400, 10000, 120000), R=c(1,4, 2))# Three breaks with changed gridKaboom_break(p, c(0, 15, 30, 400, 10000, 120000), R=c(1, 4, 2), panel.grid.scale = 'len', panel.grid.num = 6) Raw Plot With one break Two breaks with no panel.grid parameters With panel.grid parameters Other Parameters panel.grid = element_line(colour = 'grey'), panel.background = element_blank(), panel.border = element_blank(), panel.grid.num = 10, panel.grid.scale = F, legend.position = 'bottom', legend.direction = 'vertical' Kaboom_bar This main idea of Kaboom bar is using row data to calculate the mean, sd, and sem value for you. Mean sd sem Statistics for two set of observes facet; fill, inherit the factors from raw data color plate t-test and anova test Quick Examples Kaboom_bar(iris, &quot;Species&quot;)Kaboom_bar(ChickWeight[-3], 'Time', 'Diet', fill = &quot;Diet&quot;, Var = &quot;SEM&quot;)Kaboom_bar(midwest[c(1:10,200:210, 300:310), c(3:8,ncol(midwest))], &quot;state&quot;, &quot;category&quot;, Var = &quot;SEM&quot;, Facet_row = 'Variable', space = 'free', scales = 'free') iris ChickWeight midwest Kaboom_bar &lt;- function(data, x, Col= FALSE, Var=&quot;SD&quot;, fill = FALSE, Pos = &quot;dodge&quot;, BarW = .9, BarAl = .6, ErbW = .3, Plate = &quot;Set1&quot;, Facet = &quot;wrap&quot;, Facet_row = FALSE, scales = &quot;fixed&quot;, space=&quot;fixed&quot;, Vari_level= FALSE, Frow_level = FALSE) data: Data framex: Variable for X axis. The mean and sd/sem would calculated.Col: The second variable. The mean and sd/sem would be calculated based on the `x` and `Col`fill: Colors for the bar. Default is the VariableBarW: float. Width of the barBarAl: 0:1: Alpha of the barErbW: float: Width of the Error barPlate: &quot;Set1&quot;, &quot;Paired&quot;, ... Color Plate. Check all plate by `brewer.pal.info`Facet: &quot;wrap&quot;, &quot;grid&quot;: `facet_wrap` if there has `Col`.Facet_row: facet by a variable in row. No statistics.scales: as facet_grid(scales=...)space: as facet_grid(space=...) How to use different types of data with this function Due to some unpleasant reasons, the logic of this functions is kind of wired and jumping. Instead of insert more “wired” patches to confusing myself, I decided not rewrite this function but given more detailed descriptions and examples. Cheers! Tips 1: DO NOT CONTAIN “-” IN YOUR SAMPLE/GROUP NAMES, it would ruine the Tukey-test function. Tips 2: Assign all the character variables into factors. It would solve most of unpleasant errors. Tips 3: Sort your axis into a desire order. The final result would follows the order of the data rather than levels. Exp1: Two Columns Data","link":"/2022/02/28/R/ggkaboom/"},{"title":"Bubble + Tree plot in GGPLOT| Go plot, KEGG plot","text":"An exampel of GO Enrichment Term DEGs_In_Term PValue Type Up Down Sample Up_ratio Tissue 1 serine-type endopeptidase activity 37 0.0001363367 Molecular Function 15 22 Intestine BSFL10 -0.18918919 Intestine 2 immune response 26 0.0025766225 Biological Process 17 9 Intestine BSFL10 0.30769231 Intestine 3 chemokine receptor activity 9 0.0044977825 Molecular Function 9 0 Intestine BSFL10 1.00000000 Intestine 4 proline dehydrogenase activity 4 0.0305750853 Molecular Function 3 1 Intestine BSFL10 0.50000000 Intestine 5 tumor necrosis factor receptor binding 9 0.0305750853 Molecular Function 6 3 Intestine BSFL10 0.33333333 Intestine 6 extracellular region 85 0.0252513420 Cellular Component 40 45 Intestine BSFL20 -0.05882353 Intestine libraries library(ggplot2) # for main graph plotlibrary(reshape2) # convert the long sheet date to matrixlibrary(ggdendro) # convert hclust data to segment matrixlibrary(stringr) # string manipulating try bubule plot For focus on plot, I deleted the texts of axis. head(GO_TB) # the data.frame show aboveggplot(GO_TB, aes(Sample, Term, size = DEGs_In_Term, color =PValue)) + geom_point() + theme_bw() + facet_grid(Type ~ Tissue , scales = 'free', space = 'free')+ theme(axis.text = element_blank()) Clust the Dots # Convert the long sheet to a matrix for calculating the distance.GO_TB_matrix &lt;- dcast(GO_TB,Term~Sample, value.var = &quot;DEGs_In_Term&quot;)rownames(GO_TB_matrix) &lt;- GO_TB_matrix[[&quot;Term&quot;]]GO_TB_matrix = GO_TB_matrix [,-1]GO_TB_matrix[is.na(GO_TB_matrix)] = 0Segement = data.frame()Label = data.frame()Num = 0for( Level in unique(GO_TB$Type)){ GROUP = GO_TB$Term[GO_TB$Type == Level] hc &lt;- hclust(dist(GO_TB_matrix[row.names(GO_TB_matrix) %in% GROUP,])) dendr &lt;- dendro_data(hc, type=&quot;rectangle&quot;) # convert for ggplot S_tmp &lt;- segment(dendr) S_tmp$Level &lt;- Level L_tmp &lt;- label(dendr) Segement &lt;- rbind(Segement, S_tmp) Label &lt;- rbind(Label, L_tmp) }colnames(Segement)[5] = &quot;Type&quot;# Synchrony the LevelsGO_TB$Tissue = factor(GO_TB$Tissue, levels = c(&quot;hclust&quot;, as.character(unique(GO_TB$Tissue) )))Segement$Tissue = &quot;hclust&quot; Now, we can plot them together ggplot() + geom_point(data= GO_TB, aes(x =Sample, y= Term, size= DEGs_In_Term, color = Up_ratio)) + facet_grid(Type~Tissue, scales = 'free', switch = &quot;y&quot;)+ scale_color_gradient2(high = &quot;salmon&quot;,mid = &quot;grey&quot;, low = &quot;steelblue&quot;, name = &quot;Scaled Up-regulated ratio&quot;) + theme_bw() + theme( strip.text = element_text(face = &quot;bold&quot;), strip.background = element_rect(colour = &quot;black&quot;, fill = FALSE), axis.text = element_blank(), axis.ticks = element_blank(), plot.title = element_text(hjust = 0.5), legend.position = &quot;left&quot;) + labs(title=&quot;GO Enrichment&quot;, x=&quot;Samples&quot;, y=&quot;Categories&quot;, size = &quot;Counts&quot;)+ geom_segment(data = Segement, aes(x=-y, y=x, xend=-yend, yend=xend))+ scale_y_discrete(position = &quot;right&quot;) No facet Segement_order = data.frame()Label = data.frame()Num = 0for( Level in unique(GO_TB$Type)){ GROUP = GO_TB$Term[GO_TB$Type == Level] hc &lt;- hclust(dist(GO_TB_matrix[row.names(GO_TB_matrix) %in% GROUP,])) dendr &lt;- dendro_data(hc, type=&quot;rectangle&quot;) # convert for ggplot S_tmp &lt;- segment(dendr) S_tmp$Level &lt;- Level L_tmp &lt;- label(dendr) if(Num &gt;0){ Segement_order$x = Segement_order$x + nrow(L_tmp) Segement_order$xend = Segement_order$xen + nrow(L_tmp) Label$x = Label$x + nrow(L_tmp) } Segement_order &lt;- rbind(Segement_order, S_tmp) Label &lt;- rbind(Label, L_tmp) Num = Num +1 }Segement_order$label = NASegement_order$label[match(Label$x, Segement_order$x)] = as.character(Label$label)# Segement_order$label = factor(Segement_order$label, levels=Label_order)Segement_order$Level = factor(Segement_order$Level, levels=unique(Segement_order$Level))# a matrix for mark the backgroundTitl_list2 = data.frame()for(Level in unique(Segement_order$Level)){ Num = Segement_order$x[which(Segement_order$Level == Level)] Num_max = max(Num) Num_min = min(Num) print(Num_max) tmp &lt;- data.frame(y =(Num_max+Num_min)/2, height = Num_max-Num_min, label= Level) Titl_list2 = rbind(Titl_list2, tmp)}GO_PLOT &lt;- ggplot() + geom_point(data= GO_TB, aes(x =Sample, y= Term, size= DEGs_In_Term, color = Up_ratio)) + scale_color_gradient2(high = &quot;salmon&quot;,mid = &quot;grey&quot;, low = &quot;steelblue&quot;, name = &quot;Scaled Up-regulated ratio&quot;) + theme_bw() + theme( strip.text = element_text(face = &quot;bold&quot;), strip.background = element_rect(colour = &quot;black&quot;, fill = FALSE), axis.text = element_blank(), axis.ticks = element_blank(), axis.line.x = element_blank(), plot.title = element_text(hjust = 0.5), legend.position = &quot;left&quot;, panel.background = element_blank()) + labs(title=&quot;GO Enrichment&quot;, x=&quot;Samples&quot;, y=&quot;Categories&quot;, size = &quot;Counts&quot;)+ geom_segment(data = Segement_order, aes(x=-y/100, y=x, xend=-yend/100, yend=xend))+ scale_y_discrete(position = &quot;right&quot;) + geom_tile(data=Titl_list2, aes(x=3,width = 5, y =y, height = height+1,fill=label), alpha=.2)+ geom_tile(data=Titl_list2, aes(x=8,width = 5, y =y, height = height+1, fill=label), alpha=.1, )+ geom_tile(data=Titl_list2, aes(x=13,width = 5, y =y, height = height+1,fill=label), alpha=.2)print(GO_PLOT) Circle it GO_PLOT + coord_polar(theta = &quot;y&quot;, start = 0.1/pi)","link":"/2021/04/04/R/ggplot-bubble-tree/"},{"title":"ggtree | ggplot examples","text":"author’s post:https://cosx.org/2015/11/to-achieve-the-visualization-and-annotation-of-evolutionary-tree-using-ggtree Quick Start library(&quot;ggtree&quot;)tree &lt;- read.tree(&quot;file&quot;)ggplot(tree, aes(x, y)) + geom_tree() + theme_tree() + geom_tiplab(size=5, color=&quot;purple&quot;) +xlim(NA, 0.04) Installation source(&quot;https://bioconductor.org/biocLite.R&quot;)## biocLite(&quot;BiocUpgrade&quot;) # you may need thisBiocManager::install('ggree')","link":"/2020/08/13/R/ggtree/"},{"title":"ggupset examples | upset plot for ggplot extention","text":"Install Install from GitHub: const-ae/ggupset Quick start The result shown above. library(ggplot2)library(tidyverse, warn.conflicts = FALSE)library(ggupset)head(tidy_movies) # test datapng('123.png',w=670,h=290)tidy_movies %&gt;% distinct(title, year, length, .keep_all=TRUE) %&gt;% ggplot(aes(x=Genres)) + geom_bar() + scale_x_upset(n_intersections = 20)+ theme_bw()dev.off() Expression Matrix GeneID Intestine BSFL10 Intestine BSFL20 Intestine BSFL30 gene-COX1 0.1461 0.0000 0.0492 gene-LOC117245643 12.3222 11.6741 10.6068 gene-LOC117245646 0.0000 0.0000 0.0292 gene-LOC117245648 0.1160 0.0439 0.0521 gene-LOC117245649 0.0000 0.0000 0.0000 gene-LOC117245651 0.8456 0.8828 0.5239 Conversion Function Convert_up &lt;- function(TB){ TB_tmp = TB for(i in colnames(TB)){ TB_tmp[i] = i } TB_tmp[TB == 0] = &quot;&quot; TB_t &lt;- data.frame(t(TB_tmp), stringsAsFactors = F) TB_tmp$upset = as.list(TB_t) return(TB_tmp)} Expression &lt;- read.table(&quot;../allSample.expr.csv&quot;, header = T)TMP &lt;- Convert_up(Expression[,-1]) # remove the GeneIDggplot(data= TMP, aes(x=upset)) + geom_bar() + geom_text(stat='count', aes(label=after_stat(count)), vjust=-1) + scale_x_upset(n_intersections = 20) + scale_y_continuous(breaks = NULL, name = &quot;&quot;) + expand_limits(y=c(0,20000)) + theme(panel.background = element_blank(), axis.line = element_line())","link":"/2021/03/31/R/ggupset/"},{"title":"From igraph to ggplot2","text":"Turn igraph result to ggplot2 plot Why you want to turn igraph network polot to ggplot? Flexibility: ggplot is a very flexible and customizable plotting package that allows you to create high-quality, publication-ready plots with a high degree of control over the visual aesthetics of your plots. You can easily modify various aspects of the plot, such as the color, shape, and size of the nodes and edges, and the placement of the labels. Integration with igraph: ggplot works seamlessly with igraph, making it easy to create complex and informative visualizations of your network data. You can use ggplot to visualize network data in a variety of ways, including heatmaps, scatterplots, and bar charts. Consistency: ggplot provides a consistent grammar for building plots, which makes it easy to create plots with a consistent style and look across different datasets. This can be particularly useful if you are working with multiple datasets and want to create a consistent visual language for your plots. Reproducibility: ggplot produces code that can be easily reproduced, making it easier to share and collaborate on your work. You can also easily modify and update your plots as your data or analysis changes. Overall, using ggplot to plot igraph results can help you create informative, visually appealing, and reproducible visualizations of your network data. Basic idea of this post is from © Christopher Chizinski, 2014. It is an old post but all codes work just fine! install igraph install.packages('igraph') Errors libopenblas.so.0: cannot open shared object file: No such file or directory sudo apt-get install libopenblas-dev Example data for igraph library(stringr)library(reshape2)library(ggplot2)library(igraph)library(RColorBrewer)library(qgraph)library(ggthemes)# data cleandataUU &lt;- read.table(&quot;https://raw.githubusercontent.com/holtzy/data_to_viz/master/Example_dataset/13_AdjacencyUndirectedUnweighted.csv&quot;, header=TRUE)TB &lt;- na.omit(melt(dataUU))TB$from &lt;- str_replace_all(TB$from, ' ', '.')# width of the edgesset.seed(3)TB$value = runif(nrow(TB), min=0, max=10)# size of pointsdTB_size &lt;- as.data.frame(table(c(as.matrix(TB[1:2]))))network=graph_from_data_frame(TB[1:2] )set.seed(1)e &lt;- get.edgelist(network,names=FALSE)l &lt;- qgraph.layout.fruchtermanreingold(e,vcount=vcount(network), area=30*(vcount(network)^2), repulse.rad=(vcount(network)^4)) plot(network, layout=l, vertex.size=4, vertex.label=NA, edge.arrow.size= 0, ) ## convert the layout to a data.framefr.all.df &lt;- as.data.frame(l)## add in the species codesfr.all.df$species &lt;- V(network)$name## add size for each nodesfr.all.df$size &lt;- TB_size$Freq[match(fr.all.df$species, TB_size$Var1)]g &lt;- TB[1:2]colnames(g) &lt;-c('from', 'to')g$weight = TB[[3]]g$from.x &lt;- fr.all.df$V1[match(g$from, fr.all.df$species)] # match the from locations from the node data.frame we previously connectedg$from.y &lt;- fr.all.df$V2[match(g$from, fr.all.df$species)]g$to.x &lt;- fr.all.df$V1[match(g$to, fr.all.df$species)] # match the to locations from the node data.frame we previously connectedg$to.y &lt;- fr.all.df$V2[match(g$to, fr.all.df$species)]P &lt;-ggplot() + geom_segment(data=g,aes(x=from.x,xend = to.x, y=from.y,yend = to.y, size = weight),colour=&quot;black&quot;, alpha =.1 ) + geom_point(data=fr.all.df,aes(x=V1,y=V2)) + geom_text(data=fr.all.df,aes(x=V1,y=V2,label=&quot;&quot;)) + theme_map() + coord_fixed(ratio = 1) + coord_fixed(ratio = 1) include size of the dots and the weight of edges ggplot() + geom_segment(data=g,aes(x=from.x,xend = to.x, y=from.y,yend = to.y, size = weight), size = log(g$weight + 1)/2, colour=&quot;black&quot;, alpha =.1 ) + geom_point(data=fr.all.df,aes(x=V1,y=V2, size = size, color = size), alpha = .8) + geom_text(data=fr.all.df,aes(x=V1,y=V2,label=&quot;&quot;)) + theme_map() + coord_fixed(ratio = 1) + coord_fixed(ratio = 1) + scale_color_gradient(high = 'red', low = 'steelblue') pre { background-color:#38393d; color: #5fd381; }","link":"/2023/02/07/R/igraph-ggplot2/"},{"title":"jpeg: reading color from img","text":"jpeg: reading color from img 配色难题 ##Reading color from the image library(jpeg);library(reshape2)picture &lt;- readJPEG(&quot;~/Pictures/test.jpg&quot;)longImage &lt;- melt(picture)rgbImage &lt;- reshape(longImage, timevar='Var3',idvar=c('Var1','Var2'), direction='wide')colorColumns&lt;- rgbImage[, substr(colnames(rgbImage), 1, 5)== &quot;value&quot;]Color_B = data.frame(sort(table(rgb(colorColumns)),decreasing=T))[[1]]","link":"/2020/06/19/R/jpg_reading_c/"},{"title":"leaflet in R","text":"leaflet install.packages(&quot;leaflet&quot;) Quick start library(leaflet)m &lt;- leaflet()at &lt;- addTiles(m)addMarkers(at,lng=116.391, lat=39.912, popup=&quot;这里是北京&quot;) 中国区使用高德地图 install.packages(&quot;leafletCN&quot;)library(leafletCN)m &lt;- leaflet() %&gt;% amap()at &lt;- addTiles(m)addMarkers(at,lng=116.391, lat=39.912, popup=&quot;这里是北京&quot;) 结果差不多哦的， 但是加了 amap() 参数，加载速度， 会快很多。 two or more marks on the map We can make it by pipelines m &lt;- leaflet() %&gt;% amap()at &lt;- addTiles(m)addMarkers(at,lng=116.391, lat=39.912, popup=&quot;这里是北京&quot;)addMarkers(at,lng=116.391, lat=38.912, popup=&quot;这里是北京&quot;) adding lines m &lt;- leaflet() %&gt;% amap()m&lt;- setView(m,lng=116.38,lat=39.9,zoom=6)at &lt;- addTiles(m)addMarkers(at,lng=126.6623854637146, lat=45.73903109525129, popup=&quot;学校; 哈九中&quot;) %&gt;%addMarkers(at,lng=126.61242295716093, lat=45.7074338843242, popup=&quot;市图书馆&quot;) %&gt;%addMarkers(at,lng=126.47783875465393, lat=45.809739913121916, popup=&quot;赛信生物; 待定&quot;) %&gt;%addMarkers(at,lng=126.61695957183838, lat=45.721858584688206, popup=&quot;殷氏生物; 中兴街中关村基地一楼; 周二上午10点&quot;) %&gt;%addMarkers(at,lng=126.58702611923218, lat=45.69826679861071, popup=&quot;销售，E区 东南门; 哈西万达华宅E3栋1单元2401室; 周三上午9点&quot;), Reference: 大虾卢; R语言在线地图神器：Leaflet for R包（一）; 2016; CNDS","link":"/2020/08/15/R/leaflet/"},{"title":"Common Library for R","text":"Common Library for R library prepare # for unit and sf# cite: https://stackoverflow.com/questions/61733376/r-rgdal-install-fails-on-ubuntu-20-04-with-error-double-red-or-corruption-prevsudo apt install libudunits2-dev libspatialite-dev Packages from Cran 'dplyr', 'ellipse', 'fastcluster', &quot;reshape2&quot;,&quot;htmlwidgets&quot;, &quot;gapminder&quot;, &quot;httr&quot;, &quot;igraph&quot;,&quot;jiebaR&quot;, &quot;jpeg&quot;, &quot;htmlwidgets&quot;, &quot;jsonlite&quot;,&quot;magick&quot;, &quot;modelr&quot;, &quot;pacman&quot;, &quot;psych&quot;,&quot;randomForest&quot;, &quot;rayrender&quot;, &quot;readxl&quot;,&quot;rpart&quot;, &quot;Rwordseg&quot;, &quot;SnowballC&quot;, &quot;remotes&quot;, &quot;overlap&quot;, &quot;overlaping&quot;# Map data# relied libs: https://www.liujason.com/article/570.html# sudo apt-get install libgdal-dev libproj-dev gdal-bin -y&quot;sf&quot;, &quot;swirl&quot;, &quot;tidyr&quot;, &quot;tidyverse&quot;,&quot;tm&quot;, &quot;WGCNA&quot;, &quot;xgboost&quot;, &quot;fmsb&quot;,'rcmdcheck', 'devtools', &quot;rgl&quot;, &quot;forecast&quot;,# Math calculation: fourier ; pacman -S gcc-fortran# Plot&quot;patchwork&quot; ,&quot;networkD3&quot; ,&quot;ggplot2&quot; ,&quot;maps&quot; ,&quot;ggalluvial&quot;,'circlize' ,'cowplot' ,&quot;pheatmap&quot; ,&quot;GGally&quot; ,'ggplotify',&quot;ggthemes&quot; ,&quot;ggdendro&quot; ,&quot;ggrepel&quot;, &quot;ggnewscale&quot;, &quot;ggridges&quot;, &quot;ggvenn&quot;, &quot;svglite&quot;, &quot;showtext&quot;, &quot;remotes&quot;, &quot;venneuler&quot;,&quot;wordcloud2&quot; ,&quot;ggupset&quot; ,&quot;plotly&quot; ,&quot;plotrix&quot; ,'ggalt'# devtools::install_github(&quot;const-ae/ggupset&quot;)# Fonts showtext# Map data: ggalt## Biology&quot;BiocManager&quot;, &quot;seurat&quot;## Mathmatics&quot;deSolve&quot;, &quot;SciViews&quot; Install with for loop config for rJAVA: sudo R CMD javareconf Jim Chen, 2018 proj4: sudo apt-get install libproj-dev DirtStats, 2020 sf: sudo apt install libgdal-dev Gayan Kavirathne, 2018 magick: sudo add-apt-repository -y ppa:cran/imagemagick sudo apt-get update sudo apt-get install -y libmagick++-dev textshaping : sudo apt install libharfbuzz-dev libfribidi-dev List &lt;- c('dplyr', 'ellipse', 'fastcluster', &quot;reshape2&quot;, &quot;htmlwidgets&quot;, &quot;gapminder&quot;, &quot;httr&quot;, &quot;igraph&quot;, &quot;jiebaR&quot;, &quot;jpeg&quot;, &quot;htmlwidgets&quot;, &quot;jsonlite&quot;, &quot;magick&quot;, &quot;modelr&quot;, &quot;pacman&quot;, &quot;psych&quot;, &quot;randomForest&quot;, &quot;rayrender&quot;, &quot;readxl&quot;, &quot;rpart&quot;, &quot;Rwordseg&quot;, &quot;SnowballC&quot;, &quot;remotes&quot;, &quot;sf&quot;, &quot;swirl&quot;, &quot;tidyr&quot;, &quot;tidyverse&quot;, &quot;tm&quot;, &quot;WGCNA&quot;, &quot;xgboost&quot;, &quot;fmsb&quot;, &quot;venneuler&quot;, 'rcmdcheck', 'devtools', &quot;rgl&quot;, &quot;forecast&quot;, &quot;patchwork&quot; ,&quot;networkD3&quot; ,&quot;ggplot2&quot; ,&quot;maps&quot; ,&quot;ggalluvial&quot;, 'circlize' ,'cowplot' ,&quot;pheatmap&quot; ,&quot;GGally&quot; ,'ggplotify', &quot;ggthemes&quot; ,&quot;ggdendro&quot; ,&quot;ggrepel&quot;, &quot;ggnewscale&quot;, &quot;ggridges&quot;, &quot;ggvenn&quot;, &quot;svglite&quot;, &quot;showtext&quot;, &quot;remotes&quot;, &quot;wordcloud2&quot; ,&quot;ggupset&quot; ,&quot;plotly&quot; ,&quot;plotrix&quot; ,'ggalt', &quot;BiocManager&quot;, &quot;deSolve&quot;, &quot;SciViews&quot;, &quot;overlap&quot;)for(LIB in List){ if (!requireNamespace(LIB, quietly = TRUE)) install.packages(LIB)} sf udunits is required for sf (udunits) for manjaro install wget https://mirrors.tuna.tsinghua.edu.cn/arch4edu/x86_64/udunits-2.2.28-2-x86_64.pkg.tar.zstpacman -U udunits-2.2.28-2-x86_64.pkg.tar.zst gdal-config not found or not executable sudo pacman -S gdal Packages for Biology if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;)# For calculation&quot;edgeR&quot;, &quot;limma&quot;, &quot;qvalue&quot;, &quot;DESeq2&quot;,# Microarray&quot;GEOquery&quot;,# Seq data&quot;Biostrings&quot;, &quot;BSgenome&quot;,# Annotation and Enrichment&quot;clusterProfiler&quot;, &quot;pathview&quot;,&quot;org.Hs.eg.db&quot;, &quot;org.Dr.eg.db&quot;, &quot;org.Dm.eg.db&quot;, &quot;ReactomePA&quot;, &quot;meshes&quot;,# Plot&quot;ggtree&quot;, &quot;clue&quot;, &quot;ComplexHeatmap&quot;, 'ggtheme',# clue: for &quot;ComplexHeatmap&quot;# ComplexHeatmap: old version. New version can be found in Github# other NGS&quot;WGCNA&quot;,# Others&quot;Biobase&quot;, &quot;BiocManager&quot; Prerequisite: Rcurl: sudo apt-get install -y libcurl4-openssl-dev Mike Smith, 2016 ggforce: sudo apt -y install libfontconfig1-devjohnbester, 2020 XML: sudo apt-get install libxml2-dev ggtree: remotes::install_github(&quot;YuLab-SMU/ggtree&quot;) List &lt;- c(&quot;Biobase&quot;, &quot;edgeR&quot;, &quot;Biostrings&quot;, &quot;BSgenome&quot;, &quot;clusterProfiler&quot;, &quot;ggtree&quot;, &quot;meshes&quot;, &quot;pathview&quot;, &quot;limma&quot;, &quot;qvalue&quot;, &quot;org.Hs.eg.db&quot;, &quot;org.Dr.eg.db&quot;, &quot;org.Dm.eg.db&quot;,&quot;clue&quot;, &quot;ComplexHeatmap&quot;, &quot;GEOquery&quot;, &quot;WGCNA&quot;, &quot;ReactomePA&quot;, 'ggtheme', &quot;TCGAbiolinks&quot;)for(LIB in List){ if (!requireNamespace(LIB, quietly = TRUE)) BiocManager::install(LIB)} Packages from github &quot;tylermorganwall/coronaobj&quot;, &quot;jennybc/gapminder&quot;, 'pzhaonet/ncovr',# Plot GGplot&quot;hrbrmstr/ggalt&quot;, &quot;AckerDWM/gg3D&quot;, &quot;jayjacobs/ggcal&quot;,'ricardo-bion/ggradar', &quot;tylermorganwall/rayshader&quot;,&quot;mattflor/chorddiag&quot;, &quot;gaospecial/ggVennDiagram&quot;# 3D plot : gg3D, rayshader# Plot Others&quot;jokergoo/ComplexHeatmap&quot;# ggplot, regression function List &lt;- c(&quot;tylermorganwall/coronaobj&quot;, &quot;jennybc/gapminder&quot;, 'pzhaonet/ncovr', &quot;hrbrmstr/ggalt&quot;, &quot;AckerDWM/gg3D&quot;, &quot;jayjacobs/ggcal&quot;, 'ricardo-bion/ggradar', &quot;tylermorganwall/rayshader&quot;, &quot;mattflor/chorddiag&quot;, &quot;gaospecial/ggVennDiagram&quot;, &quot;jokergoo/ComplexHeatmap&quot;, &quot;Laurae2/Laurae&quot;)library(stringr)for(LIB in List){ if (!requireNamespace(str_split(LIB, '/')[[1]][2], quietly = TRUE)) remotes::install_github(LIB)} package with troubles Gayan Kavirathne sudo apt install libgdal-dev install.packages(&quot;AICcmodavg&quot;)","link":"/2020/02/14/R/library/"},{"title":"logistic regression in R","text":"Logistic regression in R Standard Logistic function for population growth $$ P(m)= \\frac{KP_{0}e^{rm}}{K + P_0(e^{rm} - 1)} $$ m: time point (x axis) r: α K: max Test Data reference: PriscillaBai 2018[1] ## Test Date setn&lt;-c(0.15,0.15,0.20,0.28,0.35,0.4,0.44,0.47,0.49,0.51,0.53,0.56,0.56,0.57,0.6,0.58,0.6,0.61,0.6, 0.58,0.54, 0.58)m = c(1:length(n))df&lt;-as.data.frame(cbind(m,n))## Regression Regression library(deSolve)### 估计参数初始值| estimateSS &lt;- getInitial(n ~ SSlogis(m, alpha, xmid, scale), data = df)K_start &lt;- SS[&quot;alpha&quot;]R_start &lt;- 1/SS[&quot;scale&quot;]P0_start &lt;- SS[&quot;alpha&quot;]/(exp(SS[&quot;xmid&quot;]/SS[&quot;scale&quot;])+1)### 拟合函数方程log_formula &lt;- formula(n ~ K*P0*exp(R*m)/(K + P0*(exp(R*m) - 1)))formu&lt;-nls(log_formula, start = list(K = K_start, R = R_start, P0 = P0_start))## Visualizationlibrary(ggplot2)ggplot() + geom_line(data=df,aes(m,predict(formu)))+ geom_point(aes(x=m,y=n))+ theme_bw() plot more We can check more information by: formu Nonlinear regression model model: n ~ K * P0 * exp(R * m)/(K + P0 * (exp(R * m) - 1)) data: parent.frame() K.alpha R.scale P0.alpha 0.58610 0.38294 0.09482 residual sum-of-squares: 0.006648 Number of iterations to convergence: 0 Achieved convergence tolerance: 1.708e-06 As a result, we can have the formula: $$ P(m)= \\frac{0.58610 * 0.09482 * e^{0.38294 * m}}{0.58610 + 0.09482(e^{0.38294 * m} - 1)} $$ K &lt;- SS[&quot;alpha&quot;] # K = 0.58610R &lt;- 1/SS[&quot;scale&quot;] # R = 0.38294P0 &lt;- SS[&quot;alpha&quot;]/(exp(SS[&quot;xmid&quot;]/SS[&quot;scale&quot;])+1) # P0 = 0.09482Log_r &lt;- function(m){ K * P0 * exp(R * m)/(K + P0 * (exp(R * m) - 1))}x=c(-20:40)ggplot() + geom_line(data=df,aes(m,predict(formu)))+ geom_point(aes(x=m,y=n))+ theme_bw()+ geom_line(aes(x=x,y=Log_r(x))) Slop calculation $$ \\frac{dP}{dm} = r×P(1-\\frac{P}K) $$ P = Log_r(SS['xmid'])Slope = R_start[[1]] * P *( 1 - P/K_start[[1]])ggplot() + geom_line(data=df,aes(m,predict(formu)))+ geom_point(aes(x=m,y=n))+ theme_bw()+ geom_line(aes(x=x,y=Log_r(x))) + geom_abline(intercept = Log_r(SS[&quot;xmid&quot;]) - SS[&quot;xmid&quot;]*Slope, slope = Slope, color='steelblue', size =2, linetype=4) + geom_point(aes(4.296, 0.293), color=&quot;salmon&quot;) Regression with binomial data library(ISwR)data(juul)juul$menarche &lt;- factor(juul$menarche, levels=c(1, 2), labels=c(&quot;No&quot;,&quot;Yes&quot;))juul$tanner &lt;- factor(juul$tanner, levels=c(1:5))juul.girl &lt;- subset(juul, age&gt;8 &amp; age&lt;20 &amp; complete.cases(menarche))# Note that this is a binomial data, we should use `binomial` arguments hereglm_menarche_age &lt;- glm(menarche~age, family=binomial, data=juul.girl)summary(glm_menarche_age) Call: glm(formula = menarche ~ age, family = binomial, data = juul.girl) Deviance Residuals: Min 1Q Median 3Q Max -2.32759 -0.18998 0.01253 0.12132 2.45922 Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept) -20.0132 2.0284 -9.867","link":"/2020/08/21/R/logistic_curve/"},{"title":"magick (Picture needed)","text":"magick (Picture needed) library(&quot;magick&quot;)tiger &lt;- image_read_svg('http://jeroen.github.io/images/tiger.svg', width = 400)print(tiger)##rewriteimage_write(tiger, path = &quot;tiger.png&quot;, format = &quot;png&quot;)##infimage_info(tiger_png)##Editimage_crop(image, &quot;100x150+50&quot;): crop out width:100px and height:150px starting +50px from the leftimage_scale(image, &quot;200&quot;): resize proportionally to width: 200pximage_scale(image, &quot;x200&quot;): resize proportionally to height: 200pximage_fill(image, &quot;blue&quot;, &quot;+100+200&quot;): flood fill with blue starting at the point at x:100, y:200image_border(frink, &quot;red&quot;, &quot;20x10&quot;): adds a border of 20px left+right and 10px top+bottomimg &lt;- image_resize(logo, &quot;300x300&quot;)img_blurred &lt;- image_convolve(img, kern)image_append(c(img, img_blurred))","link":"/2020/06/19/R/magick_png/"},{"title":"nCov visualization","text":"nCov visualization Github project: tylermorganwall/coronaobj Packages Install Install through remotes remotes::install_github(&quot;tylermorganwall/rayrender&quot;)remotes::install_github(&quot;tylermorganwall/coronaobj&quot;) (An extral data with 91.2MB is in inst/extdata. So, it may take a while to installing it) Install from local git clone https://github.com/tylermorganwall/rayrender.gitgit clone https://github.com/tylermorganwall/coronaobj.git install.packages(&quot;/home/ken/test/rayrender/&quot;,repos = NULL)install.packages(&quot;/home/ken/test/coronaobj/&quot;,repos = NULL) Start with coronaobj library(coronaobj)library(rayrender)write_corona_obj(&quot;defaults.obj&quot;) # write the obj file to localobj_model(&quot;defaults.obj&quot;, vertex_colors = TRUE) %&gt;% add_object(sphere(y=10,z=10,x=10, material=light(intensity=100))) %&gt;% add_object(sphere(y=10,z=10,x=-10, material=light(intensity=100))) %&gt;% render_scene(parallel=TRUE, samples = 1000, fov = 7, min_variance=0, focal_distance = 9.6, width=800,height=800) It takes me about 30min… ## above rightobj_model(&quot;defaults.obj&quot;, vertex_colors = TRUE) %&gt;% add_object(sphere(y=10,z=10,x=10, material=light(color=&quot;lightblue&quot;,intensity=160))) %&gt;% add_object(sphere(y=10,z=10,x=-10, material=light(color=&quot;orange&quot;,intensity=160))) %&gt;% add_object(sphere(y=-10,z=-5,material=light(color=&quot;purple&quot;, intensity = 160))) %&gt;% render_scene(parallel=TRUE, samples = 1000, fov = 7, min_variance=0, focal_distance = 9.6, aperture=0.5, width=800,height=800)","link":"/2020/06/10/R/nCov-visualization/"},{"title":"nCov(新冠状病毒数据获取与可视化)","text":"nCov(新冠状病毒数据获取与可视化) 1 Loading Packages library(&quot;httr&quot;)library(&quot;jsonlite&quot;) 2 Data acquiring base &lt;- 'https://lab.isaaclin.cn/nCoV/api/' # api 网址port &lt;- 'area' #接口get_raw &lt;- GET(paste0(base, port)) # 获取链接get_text &lt;- content(get_raw, &quot;text&quot;) # 获取数据ncov_area &lt;- fromJSON(get_text) #提取数据 3 Data remotes::install_github('pzhaonet/ncovr')library(&quot;ncovr&quot;)ncov &lt;- get_ncov() # Downloading the Date... It takes me about 10min 這一步可能會因爲網絡問題而下載數據失敗. 可以直接用瀏覽器下載RDS, 然後本地讀取下載地址: https://github.com/pzhaonet/ncov/raw/master/static/data-download/ncov.RDS讀取方式: ncov &lt;- readRDS(&quot;ncov.RDS&quot;) 讀取數據了, 就是喜聞樂見的, 清洗和可視化了 ## area dataTB = ncov$area## China中国 = TB[TB$countryName == &quot;中国&quot;,]中国$日期 = as.Date.POSIXct(中国$updateTime/1000)湖北 =中国[中国$provinceShortName=='湖北',] 这里的时间困惑了我很久. 表格里的时间, 举例: 1583295001876, 通过as.Date.POSIXct 转化以后,成了&quot;52142-08-15&quot;. 通过删除后面3位数, 876, 及可获得正确时间&quot;2020-03-04&quot;. 我也不知道为什么 library(ggplot2)ggplot(湖北)+ geom_point(aes(x=日期,y=confirmedCount)) + #Dot plot geom_smooth(aes(x=日期,y=confirmedCount,color = continentName)) + # Smooth line theme_light() 加上几个别的数据 ggplot(湖北)+ geom_smooth(aes(x=日期,y=confirmedCount))+ geom_smooth(aes(x=日期,y=deadCount))+ geom_smooth(aes(x=日期,y=curedCount))+ geom_point(aes(x=日期, y=confirmedCount, color='confirmed'))+ geom_point(aes(x=日期, y=deadCount, color='dead'))+ geom_point(aes(x=日期, y=curedCount,color= 'cured'))+ theme_light() 同样的方法看看别的省: ggplot(中国[中国$provinceShortName=='湖南',])+ geom_smooth(aes(x=日期,y=confirmedCount))+ geom_smooth(aes(x=日期,y=deadCount))+ geom_smooth(aes(x=日期,y=curedCount))+ geom_point(aes(x=日期, y=confirmedCount, color='confirmed'))+ geom_point(aes(x=日期, y=deadCount, color='dead'))+ geom_point(aes(x=日期, y=curedCount,color= 'cured'))+ theme_light() All Provinces ggplot(中国)+ geom_smooth(aes(x=日期,y=confirmedCount))+ geom_smooth(aes(x=日期,y=deadCount))+ geom_smooth(aes(x=日期,y=curedCount))+ geom_point(aes(x=日期, y=confirmedCount, color='confirmed'))+ geom_point(aes(x=日期, y=deadCount, color='dead'))+ geom_point(aes(x=日期, y=curedCount,color= 'cured'))+ theme_light() +facet_wrap(provinceShortName ~., scales = 'free') 4 map China city cn_city_map.rds is required:Specific Date is comming from GuangchuangYulocation: https://github.com/GuangchuangYu/map_dataBut as you know, downloading Data from Github is preaty slow. data &lt;- readRDS(&quot;cn_city_map.rds&quot;) Take 湖北 as an example: 湖北地图 &lt;- data[ data$ADMINCODE %in% 湖北$cities[[1]]$locationId,]ggplot(湖北地图) + geom_sf(aes(fill = OBJECTID))+ theme_light() Adding nCov information ## sort湖北地图 = 湖北地图[match(湖北$cities[[1]]$locationId,湖北地图$ADMINCODE),]## Graph Leftggplot(湖北地图) + geom_sf(aes(fill = 湖北$cities[[1]]$currentConfirmedCount))+ theme_light()## Log the count before fillggplot(湖北地图) + geom_sf(aes(fill = log(湖北$cities[[1]]$currentConfirmedCount)))+ theme_light() China Province Data is shared by : skymeDownload locaktion: Click Here! China &lt;- sf::st_read('bou2_4p.shp') Location for main City (Data is from skyme) City_loc = read.csv(text = &quot;城市,jd,wd北京,116.4666667,39.9上海,121.4833333,31.23333333天津,117.1833333,39.15重庆,106.5333333,29.53333333哈尔滨,126.6833333,45.75长春,125.3166667,43.86666667沈阳,123.4,41.83333333呼和浩特,111.8,40.81666667石家庄,114.4666667,38.03333333太原,112.5666667,37.86666667济南,117,36.63333333郑州,113.7,34.8西安,108.9,34.26666667兰州,103.8166667,36.05银川,106.2666667,38.33333333西宁,101.75,36.63333333乌鲁木齐,87.6,43.8合肥,117.3,31.85南京,118.8333333,32.03333333杭州,120.15,30.23333333长沙,113,28.18333333南昌,115.8666667,28.68333333武汉,114.35,30.61666667成都,104.0833333,30.65贵阳,106.7,26.58333333福州,119.3,26.08333333台北,121.5166667,25.05广州,113.25,23.13333333海口,110.3333333,20.03333333南宁,108.3333333,22.8昆明,102.6833333,25拉萨,91.16666667,29.66666667香港,114.1666667,22.3澳门,113.5,22.2&quot;) library(ggrepel)Today = 中国[中国$日期==&quot;2020-03-04&quot;,]Cities = data.frame()for( i in Today$cities){ Cities = rbind(Cities,i)}AAA = Cities[Cities$cityName %in% City_loc$城市,] AAA2 = City_loc[match(AAA$cityName, City_loc$城市),] ## now, Map data is in AAA, location of cites are in AAA2ggplot(China) + geom_sf(color='white')+ geom_text_repel(data=AAA2,aes(x=jd,y=wd,label=城市))+ geom_point(data=AAA2,aes(x=jd,y=wd, color=log(AAA$confirmedCount), size=AAA$confirmedCount),alpha=0.8)+ theme_light()+scale_color_gradient(low = &quot;white&quot;,high = &quot;red&quot;) 5 世界 TB$日期 = as.Date.POSIXct(TB$updateTime/1000)ggplot(TB)+ geom_smooth(aes(x=日期,y=confirmedCount))+ geom_smooth(aes(x=日期,y=deadCount))+ geom_smooth(aes(x=日期,y=curedCount))+ geom_point(aes(x=日期, y=confirmedCount, color='confirmed'))+ geom_point(aes(x=日期, y=deadCount, color='dead'))+ geom_point(aes(x=日期, y=curedCount,color= 'cured'))+ theme_light() +facet_wrap(countryName ~., scales = 'free') Keep the countries which aboves 1000 confiremed cases. TB2 &lt;- TB[TB$countryName %in% unique(TB$countryName[which(TB$confirmedCount&gt;1000)]),]ggplot(TB2)+ geom_smooth(aes(x=日期,y=confirmedCount))+ geom_smooth(aes(x=日期,y=deadCount))+ geom_smooth(aes(x=日期,y=curedCount))+ geom_point(aes(x=日期, y=confirmedCount, color='confirmed'))+ geom_point(aes(x=日期, y=deadCount, color='dead'))+ geom_point(aes(x=日期, y=curedCount,color= 'cured'))+ theme_light() +facet_wrap(countryName ~., scales = 'free')","link":"/2020/06/20/R/nCov/"},{"title":"Pathview","text":"Pathview An R package for mapping your genes and compounds to the KEGG pathways. Documentation: Bioconductor R Project Install &amp; Quick start ##切换至国内镜像options(BioC_mirror=&quot;https://mirrors.tuna.tsinghua.edu.cn/bioconductor&quot;)BiocManager::install('pathview') library(pathview)## Gene mapdata(gse16873.d)pv.out &lt;- pathview(gene.data = gse16873.d[, 1], pathway.id = &quot;04110&quot;, species = &quot;hsa&quot;, out.suffix = &quot;gse16873&quot;)pv.out &lt;- pathview(gene.data = gse16873.d[, 1], pathway.id = demo.paths$sel.paths[i], species = &quot;hsa&quot;, out.suffix = &quot;gse16873.2layer&quot;, kegg.native = T, same.layer = F)## compound mapdata(demo.paths)data(cpd.simtypes)sim.cpd.data=sim.mol.data(mol.type=&quot;cpd&quot;, nmol=3000)i &lt;- 3pv.out &lt;- pathview(gene.data = gse16873.d[, 1], cpd.data = sim.cpd.data, pathway.id = demo.paths$sel.paths[i], species = &quot;hsa&quot;, out.suffix = &quot;gse16873.cpd&quot;, keys.align = &quot;y&quot;, kegg.native = T, key.pos = demo.paths$kpos1[i]) Gene map Compound map Multi group Date require(org.Hs.eg.db)library(pathview)data(gse16873.d)data(demo.paths)sim.cpd.data=sim.mol.data(mol.type=&quot;cpd&quot;, nmol=3000)gse16873.t &lt;- apply(gse16873.d, 1, function(x) t.test(x, alternative = &quot;two.sided&quot;)$p.value)i &lt;- 3sim.cpd.data2 = matrix(sample(sim.cpd.data, 18000, replace = T), ncol = 6)rownames(sim.cpd.data2) = names(sim.cpd.data)colnames(sim.cpd.data2) = paste(&quot;exp&quot;, 1:6, sep = &quot;&quot;)pv.out &lt;- pathview(gene.data = gse16873.d[, 1:3], cpd.data = sim.cpd.data2[, 1:2], pathway.id = demo.paths$sel.paths[i], species = &quot;hsa&quot;, out.suffix = &quot;gse16873.cpd.3-2s.2layer&quot;, keys.align = &quot;y&quot;, kegg.native = T, match.data = F, multi.state = T, same.layer = F) Start with your data Genelist Examples of acquire ko id through KGG API: curl https://rest.kegg.jp/link/ko/dme:Dmel_CG7138+dme:Dmel_CG3936| sed 's/:/\\t/g'| awk '{print $2,$4}' Anno_TB = data.frame()for(i in c(1:(round(length(A)/200)+1))){ AA &lt;- paste(&quot;dme:Dmel_&quot;,A[c(((i-1)*200):(i*200))], sep = &quot;&quot;, collapse = &quot;+&quot;) Anno &lt;- read.table( paste(&quot;https://rest.kegg.jp/link/ko/&quot;, AA, sep = &quot;&quot;)) Anno_TB &lt;- rbind(Anno_TB, Anno)}Anno_TB[[1]] &lt;- as.data.frame(str_split_fixed(Anno_TB[[1]], &quot;_&quot;, 2))[[2]]Anno_TB[[2]] &lt;- as.data.frame(str_split_fixed(Anno_TB[[2]], &quot;:&quot;, 2))[[2]] Make your gene list echo &quot;ID FK18606 2K00457 -1K00815 -2&quot;&gt; gene.list run in R library(pathview)gene &lt;- read.table('gene.list',header=T)TB = matrix(gene[,2])rownames(TB)= gene[,1]pathview(gene.data = TB[, 1], pathway.id = &quot;00130&quot;, species = &quot;ko&quot;, out.suffix = &quot;test&quot;) Genes &amp; Compound","link":"/2020/05/26/R/pathview/"},{"title":"Pheatmap","text":"Pheatmap Quick Start Create a matrix test = matrix(rnorm(200), 20, 10)test[1:10, seq(1, 10, 2)] = test[1:10, seq(1, 10, 2)] + 3test[11:20, seq(2, 10, 2)] = test[11:20, seq(2, 10, 2)] + 2test[15:20, seq(2, 10, 2)] = test[15:20, seq(2, 10, 2)] + 4colnames(test) = paste(&quot;Test&quot;, 1:10, sep = &quot;&quot;)rownames(test) = paste(&quot;Gene&quot;, 1:20, sep = &quot;&quot;)## Check the matrixhead(test) Test1 Test2 Test3 Test4 Test5 Test6 Test7 Test8 Test9 Test10 Gene1 3.113742 0.61097912 2.256865 -0.08655622 2.824332 -0.3824264 2.826347 -0.8726526 2.264322 1.9392831 Gene2 0.973717 0.03505342 2.681469 0.14051028 4.208013 -0.9295952 2.699840 -0.8473697 2.077007 0.2552222 Gene3 3.068895 -1.40479792 1.695945 -1.02215630 2.410066 -1.0977577 1.115832 2.4075234 3.305659 -0.4305648 Gene4 1.739518 0.43744627 3.438071 0.88019288 2.531289 0.5330686 3.914910 -1.5281725 3.853844 0.2501110 Gene5 3.500457 -0.76045729 3.161374 -1.09123751 3.486412 -2.8363874 3.362371 -1.3717895 3.585826 1.4036547 Gene6 3.385101 -0.45133918 3.537412 -2.23503436 1.783411 0.9475567 3.016503 0.4012510 1.886079 0.2387753 library(pheatmap )## Draw heatmapspheatmap(t(test)) Arguments Quick View: pheatmap(mat, color = colorRampPalette(rev(brewer.pal(n = 7, name = \"RdYlBu\")))(100), kmeans_k = NA, breaks = NA, border_color = \"grey60\", cellwidth = NA, cellheight = NA, scale = \"none\", cluster_rows = TRUE, cluster_cols = TRUE, clustering_distance_rows = \"euclidean\", clustering_distance_cols = \"euclidean\", clustering_method = \"complete\", clustering_callback = identity2, cutree_rows = NA, cutree_cols = NA, treeheight_row = ifelse((class(cluster_rows) == \"hclust\") || cluster_rows, 50, 0), treeheight_col = ifelse((class(cluster_cols) == \"hclust\") || cluster_cols, 50, 0), legend = TRUE, legend_breaks = NA, legend_labels = NA, annotation_row = NA, annotation_col = NA, annotation = NA, annotation_colors = NA, annotation_legend = TRUE, annotation_names_row = TRUE, annotation_names_col = TRUE, drop_levels = TRUE, show_rownames = T, show_colnames = T, main = NA, fontsize = 10, fontsize_row = fontsize, fontsize_col = fontsize, angle_col = c(\"270\", \"0\", \"45\", \"90\", \"315\"), display_numbers = F, number_format = \"%.2f\", number_color = \"grey30\", fontsize_number = 0.8 * fontsize, gaps_row = NULL, gaps_col = NULL, labels_row = NULL, labels_col = NULL, filename = NA, width = NA, height = NA, silent = FALSE, na_col = \"#DDDDDD\", ...) Color pheatmap(test, color = colorRampPalette(c(&quot;red&quot;, &quot;white&quot;, &quot;black&quot;))(50)) Dendrogram cluster_rows = TRUE,cluster_cols = TRUE,clustering_distance_rows = &quot;euclidean&quot;,clustering_distance_cols = &quot;euclidean&quot;,clustering_method = &quot;complete&quot;,clustering_callback = identity2,cutree_rows = NA,cutree_cols = NA,treeheight_row = ifelse((class(cluster_rows) == &quot;hclust&quot;) || cluster_rows,50, 0),treeheight_col = ifelse((class(cluster_cols) == &quot;hclust&quot;) || cluster_cols, 50, 0), Disable dendrogram pheatmap(test, cluster_rows = F, cluster_cols = F) Cut trees the parameters: cutree_rows=int and cutree_cols=int for example: pheatmap(test, cutree_rows = 3, cutree_cols = 2) Group Annotation In pheatmap, we use a matrix to store the annotaiton tags. An example you can see at below is Group which its rownames inhereted from colnames of test Parameter about annotation annotation_row = NA, annotation_col = NA, annotation = NA, annotation_colors = NA, annotation_legend = TRUE, annotation_names_row = TRUE, annotation_names_col = TRUE, Example: ## Group annotationGroup = rep(c(&quot;A&quot;,&quot;B&quot;),5)Group = data.frame(Group)rownames(Group) = colnames(test)## Check the Grouphead(Group) Group Test1 A Test2 B Test3 A Test4 B Test5 A pheatmap(test, annotation_col=Group)## img left## assign the colorscolors=list(Group=c(A=&quot;red&quot;, B=&quot;black&quot;))pheatmap(test, annotation_col=Group, annotation_colors=colors)## img right Two or more Layers of annotation ## Annotation 1Group_2 = c(rep(&quot;A&quot;,10),rep(&quot;B&quot;,10))Group_2 = data.frame(Group_2)rownames(Group_2) = rownames(test)## Annotation 2Group_2$Phy = c(rep(&quot;甲&quot;,10),rep(&quot;乙&quot;,4),rep(&quot;丙&quot;,6))## Check the annotation matrixhead(Group_2) Group_2 Phy Gene1 A 甲 Gene2 A 甲 Gene3 A 甲 Gene4 A 甲 Gene5 A 甲 Gene6 A 甲 Display Numbers or Characters display_numbers is the parameter we’d like to add. pheatmap(test, display_numbers = T)## img at left Except for numbers, we can also adding characters, for example: ## make a new matrix with symbol or charactersTB_mark &lt;- testTB_mark[which(test&gt;=5)] = &quot;★&quot;TB_mark[which(test&lt;5)] = &quot;&quot;TB_mark[which(test&lt;=0)] = &quot;☆&quot;pheatmap(test, display_numbers = TB_mark)## img at right Labels Annotation labels_row = c(&quot;what a find day&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;,&quot;&quot;, &quot;&quot;, &quot;Il10&quot;, &quot;Il15&quot;, &quot;Il1b&quot;)## labels_row参数添加行标签pheatmap(test, labels_row = labels_row) Turn to ggplot install.packages('ggplotify')library(ggplotify)d &lt;- matrix(rnorm(100), ncol=10)library(pheatmap)p &lt;- pheatmap(d)g = as.ggplot(p) Heatmap for DEGs matrix reference: Trinity primary_data = read.table(&quot;diffExpr.P1e-5_C2.matrix&quot;, header=T, com='', row.names=1, check.names=F, sep='\\t')primary_data = as.matrix(primary_data)##transformationsdata = log2(primary_data+1)data = as.matrix(data) # convert to matrix## Centering rowsdata = data.frame(t(scale(t(data), scale=F))) pheatmap(data, scale = &quot;row&quot;, clustering_distance_row = &quot;correlation&quot;, fontsize=9, fontsize_row=6) #改变排序算法annotation&lt;-data.frame(Var1=factor(patientcolors,labels=c(&quot;class1&quot;,&quot;class2&quot;)),Var2=groups)pheatmap(data, annotation=annotation, fontsize=9, fontsize_row=6)geom_texttmap(data, cluster_row=FALSE, fontsize=9, fontsize_row=6) #关闭按行排序(aes(label = B, vjust = 1.1, hjust = -0.5, angle = 45), show_guide = FALSE) Parameters mat：用来画热图的数据参数，一般是一个矩阵，数据是基因表达值，行代表基因，列代表样本。 color：表示颜色，用来画热图的颜色，可以自己定义，默认值为colorRampPalette(rev(brewer.pal(n = 7, name =”RdYlBu”)))(100)，RdYlBu也就是Rd红色，Yi黄色，Bu蓝色的过度，则主调色为红黄蓝。 scale：是指对数值进行均一化处理，在基因表达量的数据中，有些基因表达量极低，有些基因表达量极高，因此把每个基因在不同处理和重复中的数据转换为平均值为0，方差为1的数据，可以看出每个基因在某个处理和重复中表达量是高还是低，一般选择做row均一化。 clustering_method：表示聚类方法，值可以是hclust的任何一种，如”ward.D”,”single”, “complete”, “average”, “mcquitty”, “median”, “centroid”, “ward.D2″。 cluster_rows：表示行是否聚类，值可以是FALSE或TRUE clustering_distance_rows：行距离度量的方法，如欧氏距离 cutree_rows：行聚类数 treeheight_row：行聚类树的高度，默认为50 gaps_row：对行进行分割，就不应对相应的行进行聚类 cluster_cols：表示列是否聚类，值可以是FALSE或TRUE clustering_distance_cols：列距离度量的方法 cutree_cols：列聚类数 treeheight_col：列聚类树的高度，默认为50 gaps_col：对列进行分割，就不应对相应的列进行聚类 legend：逻辑值，是否显示色度条，默认为T legend_breaks：显示多少个颜色数值段 legend_labels：对色度条上对应位置的字符进行修改 annotation_colors：对标签的颜色进行修改 annotation_legend：是否显示标签注释条 annotation_row：数据框格式，用来定义热图所在行的注释条 annotation_names_row：逻辑值，是否显示行标签名称 annotation_col：数据框格式，用来定义热图所在列的注释条 annotation_names_col：逻辑值，是否显示列标签名称 main：设置图的标题 fontsize：是设置所有除主图以外的标签的大小 number_color：字体的颜色 show_rownames：是否显示行名 fontsize_row：行名的字体大小 labels_row：X轴坐标名设置 show_colnames：是否显示列名 fontsize_col：列名的字体大小 labels_col：y轴坐标名设置 fontsize_number：小格子中数字大小 display_numbers：逻辑值，是否在小格子中显示数字 number_format：小格子中数字显示形式，但仅有在display_numbers=T时才能使用 na_col：设置小格子为缺失值时的颜色 cellwidth：表示每个小格子的宽度 cellheight：表示每个小格子的高度 filename：输出图画的文件名 width：输出图画的宽度 height：输出图画的高度 Reference: Davey1220 2018 More","link":"/2020/06/20/R/pheatmap/"},{"title":"Overlap calculation in R","text":"overlap overlap: The overlap package provides functions to calculate and visualize the overlap of two or more density distributions. The overlapEst function can be used to calculate the overlap of two density distributions, while the overlapPlot function can be used to visualize the overlap. library(overlap)library(ggplot2)# Generate two random lists of numbersset.seed(123)list1 &lt;- rnorm(100, mean = 5, sd = 1)list2 &lt;- rnorm(100, mean = 8, sd = 1)# Calculate overlap densityoverlapEst(list1, list2)ggplot() + geom_density(aes(list1, fill = &quot;list1&quot;), alpha = .5) + geom_density(aes(list2, fill = &quot;list2&quot;), alpha = .5) + theme_bw() Dhat1 Dhat4 Dhat5 0.2460298 NA NA overlapping library(overlapping)# Generate two random lists of numbersset.seed(123)list1 &lt;- rnorm(100, mean = 5, sd = 1)list2 &lt;- rnorm(100, mean = 8, sd = 1)# Calculate overlap densityoverlap(list(list1, list2)) $OV [1] 0.1431085 I personally believe that this result is more reliable. pre { background-color:#38393d; color: #5fd381; }","link":"/2023/02/14/R/r-overlap/"},{"title":"Reading ab1 file with R","text":"Reading ab1 file with R (sangerseqR) Install: Bioconductor ReadMe: PDF Install if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;)BiocManager::install(&quot;sangerseqR&quot;) Quick Start library(sangerseqR)A &lt;- read.abif(&quot;119DOWN-ST.119DOWN-F.11731873.C04.ab1&quot;)str(A) Formal class 'abif' [package \"sangerseqR\"] with 3 slots ..@ header :Formal class 'abifHeader' [package \"sangerseqR\"] with 9 slots .. .. ..@ abif : chr \"ABIF\" .. .. ..@ version : int 101 .. .. ..@ name : raw [1:4] 74 64 69 72 .. .. ..@ number : int 1 .. .. ..@ elementtype: int 1023 .. .. ..@ elementsize: int 28 .. .. ..@ numelements: int 118 .. .. ..@ dataoffset : int 259806 .. .. ..@ datahandle : int 0 ..@ directory:Formal class 'abifDirectory' [package \"sangerseqR\"] with 7 slots .. .. ..@ name : chr [1:118] \"AEPt\" \"AEPt\" \"APFN\" \"APXV\" ... .. .. ..@ tagnumber : int [1:118] 1 2 2 1 1 1 1 1 1 1 ... .. .. ..@ elementtype: int [1:118] 4 4 18 19 19 19 2 5 4 4 ... . . . Data Electronic Signal Matrix A@data$DATA.1A@data$DATA.2A@data$DATA.3A@data$DATA.4 Base Signal Matrix A@data$DATA.9A@data$DATA.10A@data$DATA.11A@data$DATA.12 Plot library(ggplot2)Y1 = head(A@data$DATA.9,3000)Y2 = head(A@data$DATA.10,3000)Y3 = head(A@data$DATA.11,3000)Y4 = head(A@data$DATA.12,3000)ggplot() + geom_path(aes(x=c(1:length(Y1)), y= Y1),color='salmon')+ geom_path(aes(x=c(1:length(Y2)), y= Y2),color='green')+ geom_path(aes(x=c(1:length(Y3)), y= Y3),color='blue')+ geom_path(aes(x=c(1:length(Y4)), y= Y4),color='black')+ theme_bw()ABI_plot &lt;- function(A, Head=0, Tail=1000, alpha = 0.7, Type=&quot;Base&quot;){ if(Type!=&quot;QS&quot;){ if(Type==&quot;Base&quot;){ Y1 = tail(head(A@data$DATA.9, Tail),Tail-Head) Y2 = tail(head(A@data$DATA.10, Tail),Tail-Head) Y3 = tail(head(A@data$DATA.11, Tail),Tail-Head) Y4 = tail(head(A@data$DATA.12, Tail),Tail-Head) } if(Type==&quot;Raw&quot;){ Y1 = tail(head(A@data$DATA.1, Tail),Tail-Head) Y2 = tail(head(A@data$DATA.2, Tail),Tail-Head) Y3 = tail(head(A@data$DATA.3, Tail),Tail-Head) Y4 = tail(head(A@data$DATA.4, Tail),Tail-Head) } P &lt;- ggplot() + geom_path(aes(x=c((Head+1):Tail), y= Y1, color = &quot;G&quot;), alpha = alpha)+ geom_path(aes(x=c((Head+1):Tail), y= Y2, color = &quot;A&quot;), alpha = alpha)+ geom_path(aes(x=c((Head+1):Tail), y= Y3, color = &quot;T&quot;), alpha = alpha)+ geom_path(aes(x=c((Head+1):Tail), y= Y4, color = &quot;C&quot;), alpha = alpha)+ theme_bw() + scale_color_manual(name = &quot;Group&quot;, values = c( &quot;A&quot; = &quot;green&quot;, &quot;T&quot; = &quot;salmon&quot;, &quot;G&quot; = &quot;black&quot;, &quot;C&quot; = &quot;blue&quot;), labels = c(&quot;A&quot;, &quot;T&quot;, &quot;G&quot;,&quot;C&quot;)) } if(Type==&quot;QS&quot;){ Y1 = tail(head(A@data$PCON.1, Tail),Tail-Head) Y2 = tail(head(strsplit(A@data$PBAS.1, &quot;&quot;, perl = TRUE)[[1]], Tail),Tail-Head) P &lt;- ggplot() + geom_bar(aes(x=c((Head+1):Tail), y= Y1, fill= Y1), stat = &quot;identity&quot;, alpha =1)+ scale_fill_gradient(low = &quot;white&quot;, high = &quot;Tomato3&quot;, limits = c(0,62)) + theme_bw()+ geom_text(aes(x=c((Head+1):Tail), y= -6, label = Y2)) } print(P)}# length per baseBS = length(A@data$DATA.9) / length(A@data$PCON.2)# if you want to see the base 100 to 120ABI_plot(A, BS*100, BS*120) Reading bases from the abi reference: 爱笑的小牙 ##Reading (after the ab1 file was base called)seq = readsangerseq('input.ab1')##读取碱基数据，0.33指的是将达到主峰0.33的次峰定义为杂合子峰bc = makeBaseCalls(seq, ratio = 0.33)##读主峰primarySeq(seq)##读次峰secondarySeq(seq) Intepretation install.packages(&quot;sangerseqR&quot;)library(sangerseqR)library(ggplot2)# read the abi fileA &lt;- read.abif(&quot;pcs2-myc-cenp-b_396-599_02-SP6.ab1&quot;)# plot the raw signal and the adjust signal for each time point for all 4 channels.ABI_plot(A, Tail = 14953, Type = &quot;Raw&quot;, alpha = .4)ABI_plot(A, Tail = 14953, Type = &quot;Base&quot;, alpha = .4) Raw Signal Corrected Base Read by Python Working Manual: Biopython from Bio import SeqIOrecord = SeqIO.read(&quot;55-Mn-fw-EM-28.ab1&quot;, &quot;abi&quot;)list(record.annotations.keys())dict_keys([&quot;DATA5&quot;, &quot;DATA8&quot;, &quot;RUNT1&quot;, &quot;phAR1&quot;, ..., &quot;DATA6&quot;]) Cluster 96 results are stored are HRB-1_s7346 file library(sangerseqR)library(reshape2)setwd(&quot;HRB-1_s7346/&quot;)List = dir()All = c()for(i in List){ A = read.abif(i) tmp = data.frame(A@data$DATA.1,A@data$DATA.2,A@data$DATA.3,A@data$DATA.4) tmp = data.frame(melt(t(data.frame(A@data$DATA.1,A@data$DATA.2,A@data$DATA.3,A@data$DATA.4)))$value) colnames(tmp) = A@data$TUBE.1 All = c(All, tmp)}TB = data.frame(All)","link":"/2020/09/20/R/r_ab1/"},{"title":"Linear Regression","text":"Regression in R pre { background-color:#38393d; color: #5fd381; } Reference: Multiple linear regression made simple; 2021 linear equation with one unknown test data: mpg form ggplot2 Quick start library(ggplot2)## calculating the modelmodel_mpg &lt;- lm(formula = hwy ~ displ, data = mpg)print(model_mpg) Call: lm(formula = hwy ~ displ, data = mpg) Coefficients: (Intercept) displ 35.698 -3.531 As we can see above, the function is $$ y = -3.531x+35.698 $$ summary(model_mpg) Call: lm(formula = hwy ~ displ, data = mpg) Residuals: Min 1Q Median 3Q Max -7.1039 -2.1646 -0.2242 2.0589 15.0105 Coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) 35.6977 0.7204 49.55 |t|) (Intercept) -429.900 239.097 -1.798 0.122 X 169.411 5.432 31.188 7.22e-08 *** --- Signif. codes: 0 ‘\\***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 383.6 on 6 degrees of freedom Multiple R-squared: 0.9939, Adjusted R-squared: 0.9928 F-statistic: 972.7 on 1 and 6 DF, p-value: 7.217e-08 We can see that the fitness was much better than before when we discard the 8th element. The R2 is larger than before and P-value is smaller than before. Seams we had a better result than before. Confidential intervals There is two way you can do for draw confidential intervals. One is using ggplot2. The functions geom_smooth could help you finish it very elegantly. Another way is to follow the steps from rpubs which calculate it by yourself. In ggplot Let’s see how can we achieve it with ggplot2. The threshold of the interval is 0.95 which could be changed in level = library(ggplot2)data(&quot;cars&quot;)ggplot(cars, aes(x=speed, y=dist)) + geom_point(color='#2980B9', size = 4) + geom_smooth(method=lm, color='salmon', fill= &quot;#ffa4a3&quot;, level = 0.95)+ theme_bw() Calculating confidence interval by yourself: Points from upper and lower side would be calculated and stored. reg.conf.intervals &lt;- function(x, y, CI=0.975) { n &lt;- length(y) # Find length of y to use as sample size lm.model &lt;- lm(y ~ x) # Fit linear model # Extract fitted coefficients from model object b0 &lt;- lm.model$coefficients[1] b1 &lt;- lm.model$coefficients[2] # Find SSE and MSE sse &lt;- sum((y - lm.model$fitted.values)^2) mse &lt;- sse / (n - 2) t.val &lt;- qt(CI, n - 2) # Calculate critical t-value # Fit linear model with extracted coefficients x_new &lt;- 1:max(x) y.fit &lt;- b1 * x_new + b0 # Find the standard error of the regression line se &lt;- sqrt(sum((y - y.fit)^2) / (n - 2)) * sqrt(1 / n + (x - mean(x))^2 / sum((x - mean(x))^2)) # Fit a new linear model that extends past the given data points (for plotting) x_new2 &lt;- 1:max(x + 100) y.fit2 &lt;- b1 * x_new2 + b0 # Warnings of mismatched lengths are suppressed slope.upper &lt;- suppressWarnings(y.fit2 + t.val * se) slope.lower &lt;- suppressWarnings(y.fit2 - t.val * se) # Collect the computed confidence bands into a data.frame and name the colums bands &lt;- data.frame(cbind(slope.lower, slope.upper)) colnames(bands) &lt;- c('Lower Confidence Band', 'Upper Confidence Band') # Plot the fitted linear regression line and the computed confidence bands plot(x, y, cex = 1.75, pch = 21, bg = 'gray') lines(y.fit2, col = 'black', lwd = 2) lines(bands[1], col = 'steelblue', lty = 2, lwd = 2) lines(bands[2], col = 'steelblue', lty = 2, lwd = 2) return(bands)}conf.intervals &lt;- reg.conf.intervals(cars$speed, cars$dist)head(conf.intervals) Lower Confidence Band Upper Confidence Band 1 -33.350170 6.056798 2 -29.417761 9.989207 3 -21.327925 9.764188 4 -17.395516 13.696597 5 -12.154300 16.320197 6 -6.971285 19.002000 Quadratic Equation Standard Equation: $$ y=ax^2+bx+c $$ model_mpg1 &lt;- lm(formula = hwy ~ I(displ^2), data = mpg)model_mpg2 &lt;- lm(formula = hwy ~ I(displ^2) + displ, data = mpg) model_mpg1: Call: lm(formula = hwy ~ I(displ^2), data = mpg) Coefficients: (Intercept) I(displ^2) 29.324 -0.429 model_mpg2: Call: lm(formula = hwy ~ I(displ^2) + displ, data = mpg) Coefficients: (Intercept) I(displ^2) displ 49.245 1.095 -11.760 plot Formula1 &lt;- function(x){ model_mpg1$coefficients[2]*x^2 + model_mpg1$coefficients[1]}Formula2 &lt;- function(x){ model_mpg2$coefficients[2]*x^2 + model_mpg2$coefficients[3]*x +model_mpg2$coefficients[1]}ggplot() + geom_point(data=mpg, aes(x=displ, y=hwy),color='salmon') + theme_light()+ # regression model geom_line(aes(x=x,y=Formula1(x)))ggsave('')ggplot() + geom_point(data=mpg, aes(x=displ, y=hwy),color='salmon') + theme_light()+ # regression model geom_line(aes(x=x,y=Formula2(x))) model_mpg1 model_mpg2 Formula $y=-0.429x^{2}+29.324$ $y=1.095x^{2} -11.760x + 49.245$ Plot cor cor() R2 谦瑞数据 2019 mylr = function(x,y){ x_mean = mean(x) y_mean = mean(y) xy_mean = mean(x*y) xx_mean = mean(x*x) yy_mean = mean(y*y) m = (x_mean*y_mean - xy_mean)/(x_mean^2 - xx_mean) b = y_mean - m*x_mean f = m*x+b# 线性回归方程 sst = sum((y-y_mean)^2) sse = sum((y-f)^2) ssr = sum((f-y_mean)^2) result = c(m,b,sst,sse,ssr) names(result) = c('m','b','sst','sse','ssr') result['ssr']/result['sst']}x = c(60,34,12,34,71,28,96,34,42,37)y = c(301,169,47,178,365,126,491,157,202,184) 一元多次回归方程自动扫描 T test and P value: 数据挖掘运爷 Functions: Click to see mylr = function(x,y){ x_mean = mean(x) y_mean = mean(y) xy_mean = mean(x*y) xx_mean = mean(x*x) yy_mean = mean(y*y) m = (x_mean*y_mean - xy_mean)/(x_mean^2 - xx_mean) b = y_mean - m*x_mean f = m*x+b# 线性回归方程 sst = sum((y-y_mean)^2) sse = sum((y-f)^2) ssr = sum((f-y_mean)^2) result = c(m,b,sst,sse,ssr) names(result) = c('m','b','sst','sse','ssr') result['ssr']/result['sst']}F_equation &lt;- function(X,Formula){ eval(parse(text = Formula))}LMEE &lt;- function(TB,Times){ colnames(TB)=c(&quot;X&quot;,&quot;Y&quot;) Group_X = &quot;X&quot; for(i in c(2:Times)){ X_i = paste(&quot;I(X^&quot;,i,&quot;)&quot;,sep=&quot;&quot;) Group_X = paste(Group_X,X_i,sep=&quot; + &quot;) } str_lm = paste(&quot;lm(Y ~&quot;,Group_X, ', data=TB)', sep=' ') model = eval(parse(text = str_lm)) Formula = model$coefficients[1] for(i in c(Times:1)){ X_tmp = paste(model$coefficients[i+1], &quot; * X^&quot;, i, sep=&quot;&quot;) Formula = paste(Formula,X_tmp,sep=&quot;+&quot;) } # T value tstats &lt;- coef(model) / sqrt(diag(vcov(model))) Tvalue = matrix(tstats)[2] # P value pvalue &lt;- 2 * pt(abs(tstats), df = df.residual(fit), lower.tail = FALSE) Pvalue &lt;- matrix(pvalue)[2] R2 = mylr(TB$Y,F_equation(TB$X,Formula)) result = c() result$R2 = R2[[1]] result$model = model result$Tvalue = Tvalue result$Pvalue = Pvalue result$Formula =Formula return(result)}MEES &lt;- function(TB, Times){ colnames(TB)=c(&quot;X&quot;,&quot;Y&quot;) Result_TB = data.frame() for(i in c(1:Times)){ Result_LMEE = LMEE(TB,i) Result_tmp = data.frame(Exp= i, P_value = Result_LMEE$Pvalue, R2= Result_LMEE$R2, F = Result_LMEE$Formula) Result_TB = rbind(Result_TB, Result_tmp) } return(Result_TB)}MEES_plot &lt;- function(TB,TB_input, BY = 1, header=&quot;test&quot;){ colnames(TB)=c(&quot;X&quot;,&quot;Y&quot;) TB_Nna = na.omit(TB_input) XX = seq(from=min(TB$X), to =max(TB$X), by = BY) for(i in c(1:nrow(TB_Nna))){ ggplot()+geom_point(data=TB,aes(x=X,y=Y))+ geom_line(aes(x=XX, y=F_equation(XX, as.character(TB_Nna$F[i])))) ggsave(paste(header,i,&quot;.png&quot;,sep=&quot;&quot;)) }} Usage: ##Test DataTB &lt;- head(ChickWeight)[c(2,1)]MEES(TB,4)MEES_plot(TB,MEES(TB,4)) Exp P_value R2 F ssr 1 5.100486e-02 0.9641461 $40.2380952380953 + 4.78571428571428 * X$ 1 2 5.100486e-02 0.9865977 43.5714285714286+0.250000000000001 * X^2+2.28571428571428 * X^1 11 3 1.550240e-08 0.9986254 41.904761904762+0.069444444444444 * X^3±0.791666666666658 * X^2+6.0912698412698 * X^1 12 4 3.012296e-02 0.9986254 41.904761904762+2.01944464079605e-16 * X^4+0.0694444444444399 * X^3±0.791666666666634 * X^2+6.09126984126975 * X^1 13 5 NaN 1.0000000 41.9999999999999±0.00625000000000004 * X^5+0.156250000000001 * X^4±1.29166666666667 * X^3+3.99999999999998 * X^2+0.516666666666805 * X^1 Logarithmic Regression Modle &lt;- lm(formula = hwy ~ log(displ,2) , data = mpg) Call: lm(formula = hwy ~ log(displ, exp(1)), data = mpg) Coefficients: (Intercept) log(displ, exp(1)) 38.21 -12.57 Modle &lt;- lm(formula = Y ~ log(X+1), data = TB)Formula &lt;- function(x){ Modle$coefficients[[2]] * log(x-1) + Modle$coefficients[[1]]}X= seq(0,5000, by=2)ggplot() + geom_point(data= TB, aes(x=X, y=Y)) + geom_point(aes(x=X, y= Formula(c(1:length(X)))), color=&quot;salmon&quot;) drc X &lt;- TB$XY &lt;- TB$Ylibrary(drc)mod1&lt;-drm(Y ~ X, fct=LL.2())summary(mod1)plot(X,Y)lines(seq(0,5000, by=2), predict(mod1, data.frame(X=seq(0,5000, by=2)))) Test: Google s","link":"/2020/08/21/R/regression/"},{"title":"Venn Plot in R","text":"ggvenn Reference: statisticsglobe.com library(ggvenn)set.seed(654925) # Create example listlist_venn &lt;- list(A = sort(sample(1:100, 20)), B = sort(sample(1:100, 20)), C = sort(sample(1:100, 20)), D = sort(sample(1:100, 20)))list_venn list_venn $A [1] 1 3 4 11 19 20 22 32 34 36 47 48 58 59 60 64 69 72 97 98 $B [1] 4 17 18 23 32 33 34 41 45 52 53 56 58 59 66 67 74 78 91 92 $C [1] 3 10 28 31 34 38 46 47 51 57 58 65 67 70 72 74 80 89 94 97 $D [1] 8 11 14 15 17 18 19 33 34 47 51 59 66 68 73 77 78 82 86 87 ggvenn(list_venn, c(&quot;A&quot;, &quot;C&quot;)) ggvenn(list_venn, c(&quot;A&quot;, &quot;C&quot;, &quot;D&quot;)) ggvenn(list_venn) Change the fill color ggvenn(list_venn, c(&quot;A&quot;, &quot;C&quot;)) + scale_fill_brewer( palette = 'Set1') Other related Posts: Alboukadel pre { background-color:#38393d; color: #5fd381; }","link":"/2022/10/17/R/venn/"},{"title":"worldcloud","text":"worldcloud There are some online service you can use (last check: 2022/05/01): wordclouds.com monkeylearn.com mentimeter.com Codes for Word Clouds: wordcloud2 documentation Word Clouds or tag clouds are graphic presentations that could present the frequency of the words in a photo. Basically, the size of the word has connected to the frequency of the word. The color was randomly assigned for giving a clear boundary for each word. It could be used as a graphic abstract of a single paper, or present the recent frequent-talked topics in a shocking way. In R, we can use split the words by space. But for other languages like Chinese, we can use library jiebaR to do the segmentation. In English, we’d also clean the results by deleting some “none-sense” words like “am”, “is”, and “are”. PS: for some reason, I can’t change the shape of the word cloud based on the image I was given. The example from the documentation also failed, too. So, I’ll try to achieve the result by using python. ([The codes for python(https://karobben.github.io/2020/06/23/Python/wordcloud/)) Talk is cheap, show me the code Reference: Céline Van den Rul; 2019 library(RColorBrewer)library(tm)library(wordcloud2)library(tidyr)## Read from file# text &lt;- readLines(&quot;&quot;)text &lt;- c(&quot;Word Clouds or tag clouds are graphic presentation which could present the frequency of the words in a photo. Basically, the size of the word is connected the frequency of the word. Color was random assigned for given a clear boundary of each word. It could be used as a graphic abstract of single paper, or present the recent frequent-talked topics in a shock way.In R, we can use split the words by space. But for other language like Chinese, we can use library `jiebaR` to do the segmentation. In English, we'd also clean the results by delete some 'none-sense' words like 'am', 'is', 'are'.&quot;) # past whatever you want in here# Create the doc for textsdocs &lt;- Corpus(VectorSource(text))docs &lt;- docs %&gt;% tm_map(removeNumbers) %&gt;% tm_map(removePunctuation) %&gt;% tm_map(stripWhitespace)docs &lt;- tm_map(docs, content_transformer(tolower))docs &lt;- tm_map(docs, removeWords, stopwords(&quot;english&quot;))# Create the matrixdtm &lt;- TermDocumentMatrix(docs)matrix &lt;- as.matrix(dtm)words &lt;- sort(rowSums(matrix),decreasing=TRUE)df &lt;- data.frame(word = names(words),freq=words)set.seed(1234) # for reproducibilitywordcloud2(df,color=&quot;random-light&quot;,backgroundColor = 'black') More Ancient codes Those codes are recorded before 2020. So, they may not works very well. library(SnowballC)library(Rwordseg)library(wordcloud2)library(tm)A &lt;- c(&quot;Large scale gene expression profiling during intestine and body wall regeneration in the sea cucumber Apostichopus japonicus&quot;) # past whatever you want in here##读入分词文件word = lapply(X = A, FUN = strsplit, &quot;\\\\s&quot;)word &lt;- wordStem(word[[1]])word1=unlist(word)##'''统计词频'''df=table(word1)df=sort(df,decreasing = T)df1 = data.frame(word = names(df), freq = df)df2 = data.frame(word = names(df), freq = df)Dele_list = c(&quot;al.,&quot;, &quot;#&quot;, &quot;was&quot;, &quot;a&quot;, &quot;The&quot;, &quot;et&quot;, &quot;were&quot;, &quot;that&quot;, &quot;is&quot;, &quot;on&quot;, &quot;are&quot;, &quot;this&quot;, &quot;as&quot;, &quot;in&quot;,&quot;been&quot;, &quot;have&quot;, &quot;has&quot;, &quot;the&quot;, &quot;and&quot;, &quot;of&quot;, &quot;to&quot;, &quot;for&quot;, &quot;with&quot;)df2[-which(df2$word == &quot;has&quot;),] -&gt; df2wordcloud2(df2,color=&quot;random-light&quot;,backgroundColor = 'black')####For multy English fileslibrary(wordcloud2)library(tm)##packageDescription('tm')txt &lt;- system.file(&quot;texts/txt&quot;,package=&quot;tm&quot;)##导入动态coporusmyData &lt;- Corpus(DirSource(txt),readerControl=list(language=&quot;en&quot;))myData &lt;- tm_map(myData,removePunctuation)myData &lt;- tm_map(myData,function(x)removeWords(x,stopwords()))tdm &lt;- TermDocumentMatrix(myData)m &lt;- as.matrix(tdm)v &lt;- sort(rowSums(m),decreasing=TRUE)d &lt;- data.frame(word=names(v),freq=v)wordcloud(d$word,d$freq,random.order=FALSE,color=brewer.pal(8,&quot;Dark2&quot;))wordcloud2(d,color=&quot;random-light&quot;,backgroundColor = 'black',size=0.7)####For Chinese fileslibrary(jiebaR)f &lt;- scan('test' ,sep='\\n',what='',encoding=&quot;GBK&quot;)seg &lt;- qseg[f] #使用qseg类型分词，并把结果保存到对象seg中seg &lt;- seg[nchar(seg)&gt;1] #去除字符长度小于2的词语seg &lt;- table(seg) #统计词频seg &lt;- seg[!grepl('[0-9]+',names(seg))] #去除数字seg &lt;- seg[!grepl('a-zA-Z',names(seg))] #去除字母length(seg) #查看处理完后剩余的词数seg &lt;- sort(seg, decreasing = TRUE)[1:100] #降序排序，并提取出现次数最多的前100个词语seg #查看100个词频最高的View(seg)data=data.frame(seg)datawordcloud(data$seg , data$Freq, colors = rainbow(100), random.order=F)x11()dev.off()## save as Htmllibrary(htmlwidgets)saveWidget(WC,&quot;1.html&quot;,selfcontained = F) A &lt;- readLines('test.txt')Result = &quot;&quot;for(i in A){ Result = paste(Result,i,sep=&quot; &quot;)}## Remove punctuations＆Numbers 去标点&amp;数字Result = gsub(&quot;[[:punct:]]|[[:digit:]]|^http:\\\\/\\\\/.*|^https:\\\\/\\\\/.*&quot;,&quot; &quot;,Result)word = lapply(X = Result, FUN = strsplit, &quot;\\\\s&quot;)word1=word[[1]][[1]]df=table(word1)df=sort(df,decreasing = T)TB = data.frame(t(t(df)))[c(1,3)]head(TB) ## word1 Freq##1 243##2 the 67##3 I 51##4 to 42##5 and 38##6 my 32wordcloud2(TB,color=&quot;random-light&quot;,backgroundColor = 'black')","link":"/2020/06/10/R/wordcloud/"},{"title":"FoldX","text":"Run the FoldX In this example, I am using the 7ekb as example # download the pdbwget https://files.rcsb.org/view/7ekb.pdb# Repair the PDB. After repaired it, you'll get the 7ekb_Repair.pdb for the next stepFoldX --command=RepairPDB --pdb=7ekb.pdb# calculate the free energy of the PDB FoldX --command=Stability --pdb=7ekb_Repair.pdb RepairPDB Why Repair PDB? According to ChatGPT4o, RepairPDB command in FoldX is a crucial step to ensure the quality and integrity of your PDB file before performing stability calculations or other analyses. Also, you could found more information from document Fix Structural Issues: Correcting Errors: PDB files obtained from experiments like X-ray crystallography or cryo-EM often have missing atoms, residues, or other structural issues that can affect downstream analyses. RepairPDB fixes these issues to ensure a complete and accurate structure. Adding Missing Atoms: The command can add missing atoms, such as hydrogen atoms, which are essential for energy calculations. Standardizing the Structure: Normalization: RepairPDB standardizes the structure to ensure that all residues and atoms are in the correct format and positions. This includes correcting bond lengths and angles to standard values. Removing Non-standard Residues: It can remove or correct non-standard residues and ligands that might interfere with calculations. Improving Energy Calculations: Optimizing Geometry: The command optimizes the geometry of the protein, ensuring that the atomic positions are energetically favorable. This leads to more accurate stability and free energy calculations. Minimizing Steric Clashes: It identifies and resolves steric clashes (where atoms are too close to each other), which can distort energy calculations. Ensuring Compatibility: Consistency: Running RepairPDB ensures that your PDB file is compatible with FoldX’s algorithms, reducing the risk of errors during subsequent steps. How does the Output looks like? Residue LYSH222 has high Energy, we mutate it to itself Repair Residue ID= LYSH222 BackHbond = -317.22 SideHbond = -137.87 Energy_VdW = -476.42 Electro = -15.23 Energy_SolvP = 628.80 Energy_SolvH = -624.90 Energy_vdwclash = 15.60 energy_torsion = 9.33 backbone_vdwclash= 143.43 Entropy_sidec = 245.04 Entropy_mainc = 632.72 water bonds = 0.00 helix dipole = -0.35 loop_entropy = 0.00 cis_bond = 4.50 disulfide = -13.95 kn electrostatic= -0.25 partial covalent interactions = 0.00 Energy_Ionisation = 1.07 Entropy Complex = 0.00 ----------------------------------------------------------- Total = -49.10 It took me 2m 48s. It only work in single thread and cannot move on multiple threads. I guess because it works by following the order of the AA and the Total is depending on the previous values. So, it can’t work on multiple threads. Here is the result of before and after repairing. The RMS=0.01 which means it almost the same. But the slightly different are mainly focus on the loos area. In the picture present below, the left panel with green structure is the raw pdb file from PDB database. The light blue structure on the right is the corrected by FoldX. Red structure is antigen. As I marked on the left panel, 2 beta-sheets and 1 alpha helix are deleted and become random loop. Those area from the antibody are very closing to the antigen. So, technically, random loop would make more sense to me. Stability Calculations After repaired the PDB file, you can get the result immediately. ******************************************** *** *** *** FoldX 5.1 (c) *** *** *** *** code by the FoldX Consortium *** *** *** *** Jesper Borg, Frederic Rousseau *** *** Joost Schymkowitz, Luis Serrano *** *** Peter Vanhee, Erik Verschueren *** *** Lies Baeten, Javier Delgado *** *** and Francois Stricher *** *** and any other of the 9! permutations *** *** based on an original concept by *** *** Raphael Guerois and Luis Serrano *** ******************************************** Stability >>> 1 models read: 7ekb_Repair.pdb BackHbond = -332.04 SideHbond = -163.29 Energy_VdW = -481.14 Electro = -17.42 Energy_SolvP = 626.91 Energy_SolvH = -633.28 Energy_vdwclash = 13.20 energy_torsion = 9.65 backbone_vdwclash= 144.57 Entropy_sidec = 259.27 Entropy_mainc = 634.24 water bonds = 0.00 helix dipole = -0.40 loop_entropy = 0.00 cis_bond = 4.50 disulfide = -13.95 kn electrostatic= -0.41 partial covalent interactions = 0.00 Energy_Ionisation = 1.14 Entropy Complex = 0.00 ----------------------------------------------------------- Total = -93.01 FINISHING STABILITY ANALYSIS OPTION Your file run OK End time of FoldX: Sat Jul 6 17:23:18 2024 Total time spend: 0.85 seconds. Mutation Energy Change Calculation With FoldX, you can predicted the mutations effects when you have the wild type structure. The command BuildModel could generate the new pdb structure with the ‘mutate_file’ you write. Here is an example of mutate_file: AA4P,FD4P; AA4F,QD4F; In this example, it would generate 2 new structures. For the first one, in chain A, the mutation is A4P, in chain D, the mutation is F4P. The “;” means the first mutate process is done. It would read the second line to create the another mutation file. You don’t need to calculate the mutation energy difference between before and after again. Because all they are saved in the file (*.fxout) as tsv format. For running it, you just need to run like: FoldX --command=BuildModel --pdb=protein_Repair.pdb --mutant-file=individual_list.txt An interesting thing is for the mutate-file, it has to start with “individual_list” or ‘mutate_file’ or you’ll get error. After the job is down, you’ll got 4 outputs: “Average_.fxout&quot;, &quot;Dif_.fxout”, “PdbList_.fxout&quot;, and &quot;Raw_.fxout”. Here is some details about those outputs: Average_*.fxout: This file contains the average energy values from multiple runs of the BuildModel command. FoldX often performs multiple simulations to generate an average value to improve reliability and account for variability in the calculations. It includes averaged energy terms like van der Waals interactions, electrostatics, solvation, and total energy for the mutated model. Dif_*.fxout: This file contains the differences in energy values between the wild-type and mutated proteins. It shows the ΔΔG (difference in free energy change) due to the introduced mutation(s), which helps in understanding the stability change caused by the mutation. PdbList_*.fxout: This file lists the PDB files generated during the mutation process. It includes the names of the mutated PDB files that FoldX generated, which you can further analyze or visualize using molecular visualization tools. Raw_*.fxout: This file contains the raw energy values for each individual run of the BuildModel command. It provides detailed energy components for each simulation, such as van der Waals interactions, electrostatics, solvation, and other energy terms for the mutated model. Notice For the mutate_file, you can't add any extra expressions like space in it. According to the PDB document, the SEQRES and ATOM records may include only a portion of the molecule. So if your sequence was extracted from the PDB file, the numbering of it may incorrect. For achieve the correct position, you may like to extract extract the sequence from cif format. BuildModel in Action Here, the test data is from Qi Wen Teo[1] CR9114 (4FQI) as example. I randomly choose 4FQI as the standard. In the paper, they mutated the resi through 93 to 102 (kabat numbering) which is 97 to 110. So, we could do it with a mutate_file. For FoldX, it only recognize the digital numbering. But in antibody (show below) sometimes was numbered by kabat numbering or something similar methods. So it may contain numbering like 100A, 100B, etc. They can’t recognized by FoldX and we need to renumbering them. Pymol is very complicated in this kind of task. But Biopython could handle it very well. You could using the script from Karobben/Bio_tools with code: python PDBreNumbering.py -i 4FQI_Repair.pdb -o renumbered.pdb ATOM 4942 CD1 TYR H 100 -17.095 54.149 -23.690 1.00 17.83 C C ATOM 4943 CD2 TYR H 100 -15.503 54.016 -21.927 1.00 17.51 C C ATOM 4944 CE1 TYR H 100 -16.055 54.246 -24.606 1.00 18.76 C C ATOM 4945 CE2 TYR H 100 -14.431 54.115 -22.848 1.00 20.56 C C ATOM 4946 CZ TYR H 100 -14.740 54.248 -24.173 1.00 21.30 C C ATOM 4947 OH TYR H 100 -13.735 54.378 -25.146 1.00 22.06 C O ATOM 4948 N TYR H 100A -19.396 56.114 -18.971 1.00 19.55 C N ATOM 4949 CA TYR H 100A -20.277 56.072 -17.797 1.00 21.40 C C ATOM 4950 C TYR H 100A -21.609 56.741 -18.067 1.00 25.46 C C ATOM 4951 O TYR H 100A -22.655 56.288 -17.527 1.00 25.98 C O ATOM 4952 CB TYR H 100A -19.611 56.821 -16.587 1.00 18.28 C C ATOM 4953 CG TYR H 100A -18.192 56.412 -16.276 1.00 19.12 C C ATOM 4954 CD1 TYR H 100A -17.753 55.092 -16.396 1.00 21.46 C C Script to create the mutate_file. In this script, the target region is from number 97-110 and the sequence is “ARHGNYYYYSGMDV”. WT = list(&quot;ARHGNYYYYSGMDV&quot;)All20 = list(&quot;ARNDCEQGHILKMFPSTWYV&quot;)Num = 96sublist = []for i in WT: Num += 1 for ii in All20: if i != ii: sublist += [f&quot;{i}H{Num}{ii};&quot;]with open(&quot;individual_list.txt&quot;, 'w') as F: F.write(&quot;\\n&quot;.join(sublist)) # repair the PDBFoldX --command=RepairPDB --pdb=4FQI.pdb# renumbering the resi for FoldXpython PDBreNumbering.py -i 4FQI_Repair.pdb -o renumbered.pdb# calculate the results FoldX --command=BuildModel --pdb=renumbered.pdb --mutant-file=individual_list.txt After that, the result is saved in the file Raw_renumbered.fxout. The table was started at line 9. We could use R to sorting and compare the experiment result. For the experiment result, you can download from nicwulab/CR9114_LC_CDRH3_screen library(ggplot2)library(reshape2)library(stringr)TB &lt;- read.csv('Raw_renumbered.fxout', skip = 8, sep = '\\t')TB$Type &lt;- &quot;Mute&quot;TB$Type[grep(&quot;WT_&quot;, TB$Pdb)] &lt;- &quot;WT&quot;TB &lt;- TB[c('Pdb', 'total.energy', 'Type')]TB$Pdb &lt;- str_remove(TB$Pdb, &quot;WT_&quot;)TBM &lt;- reshape(TB, idvar = 'Pdb', timevar = 'Type', direction = 'wide')colnames(TBM) &lt;- str_remove(colnames(TBM), 'total.energy.')Anno &lt;- read.csv('individual_list.txt', header = F)TBM$Anno &lt;- str_remove(Anno$V1, &quot;;&quot;)TBM$Diff = TBM$Mute - TBM$WTlibrary(scales)library(readr)library(tidyr)library(dplyr)library(gridExtra)aa_level &lt;- rev(c('E','D','R','K','H','Q','N','S','T','P','G','C','A','V','I','L','M','F','Y','W','_'))df &lt;- read_csv('CDRH3_KD_table_summary.csv') %&gt;% filter(grepl('CR9114',ID)) %&gt;% mutate(log10_Kd=log10(Kd)) %&gt;% filter((log10_Kd &lt; -8 &amp; p.value &lt; 0.2) | (log10_Kd &gt;= -8)) %&gt;% mutate(Mutation=gsub('CR9114_',&quot;&quot;,ID)) %&gt;% filter(Mutation != 'WT') %&gt;% mutate(resi=str_sub(Mutation,1,-2)) %&gt;% mutate(aa=str_sub(Mutation,-1,-1)) %&gt;% filter(aa %in% aa_level) %&gt;% mutate(aa=factor(aa,levels=aa_level)) %&gt;% complete(resi, aa) %&gt;% mutate(Pos=str_sub(resi,2,-1)) %&gt;% mutate(Pos=as.numeric(as.character(Pos))) %&gt;% arrange(Pos) %&gt;% mutate(resi=factor(resi,levels=unique(resi))) %&gt;% mutate(log10_Kd=case_when(str_sub(resi,1,1)==aa ~ log10(5.19e-10), TRUE ~ log10_Kd)) %&gt;% mutate(Mutation=paste(resi,aa,sep='')) %&gt;% select(Mutation, resi, Pos, aa, log10_Kd)df$Pos = df$Pos + 96df$Anno &lt;- paste(gsub(&quot;[0-9]&quot;, &quot;&quot;, df$resi), df$Pos, df$aa, sep = '')remove_second_letter &lt;- function(x) { paste0(substr(x, 1, 1), substr(x, 3, nchar(x)))}TBM$Anno &lt;- sapply( TBM$Anno, remove_second_letter)TBM$log10_K &lt;- df$log10_Kd[match(TBM$Anno, df$Anno)]TBMF &lt;- TBM[!is.na(TBM$log10_K),]ggplot(TBMF, aes(Diff, log10_K )) + geom_point() + geom_smooth(method = 'lm') + theme_bw()ggplot(TBMF[TBMF$Diff &lt;= 2,], aes(Diff, log10_K )) + geom_point() + geom_smooth(method = 'lm') + geom_vline( xintercept = 0, linetype = 4) + geom_hline( yintercept = -9.28, linetype = 4) + theme_bw() According to this plot, the correlation between experiments and the prediction is terrible. I think the main reason is because all those positions are located on CDRH3 region which not only they are random loop, but also the key site to determine the binding affinity of the antibody. So, the prediction result would be extrimly hard. But I think the result is not totally useless. At least when the Δ G of the complex predicted became more stable ($\\Delta_ {mutate} - \\Delta_ {wt} &lt; 0$), most of experiments results are very closing to the wild type. Mute WT Anno Diff log10_K -111.068 -110.525 D109E -0.543 -9.444906 -110.702 -110.512 D109Q -0.190 -9.422508 -110.532 -110.525 D109C -0.007 -9.343902 -111.447 -110.503 D109M -0.944 -9.296702 -112.243 -110.512 G100M -1.731 -9.222573 -111.185 -110.503 D109T -0.682 -9.180450 -110.902 -110.857 S106M -0.045 -9.170053 -111.330 -110.525 D109R -0.805 -9.156767 -112.243 -110.504 D109Y -1.739 -9.136677 -111.697 -110.893 G100I 0.804 -9.114074 -112.226 -110.512 G100K -1.714 -9.100179 -111.195 -110.525 G100C -0.670 -9.075721 -113.282 -110.512 G100R -2.770 -9.057495 -111.521 -111.362 Y104F -0.159 -9.040850 -110.971 -110.611 G107F -0.360 -9.038579 -111.158 -110.503 D109F -0.655 -9.028260 -110.824 -110.503 D109L -0.321 -9.026410 -112.106 -110.820 G100N -1.286 -8.995671 -111.164 -110.470 V110L -0.694 -8.978111 -111.718 -110.818 G100H -0.900 -8.869666 -111.044 -110.873 S106N -0.171 -8.545155 -110.944 -110.837 N101H -0.107 -8.423659 How it work? Here is the corrected version of your text: According to the documentation: This is the workhorse of the FoldX mutation engine. This command ensures that whenever you are mutating a protein, you always move the same neighbors in the WT and in the mutant, producing for each mutant PDB a corresponding PDB for its WT. Each mutation will move different neighbors, and therefore you need different WT references. From the experience above, I think it works under the assumption that the structure of the protein won’t change due to the point mutation. As shown below, even though the amino acid changed from Y to R, the position remains unchanged, and the RMSD is 0. So, I think it would be more reliable when this amino acid is in the alpha helix or beta sheet. When a point mutation happens in these regions, the rough structure remains relatively the same. However, when the mutation occurs in the loop region, the result would be less reliable. According to Yuan M, et al.[2], when the mutation only happens in the V gene of the antibody, the correct ratio was about 70%. But according to the test above, the result is inconsistent and lacks convinciveness. Interface Analysis # after repair the PDBFoldX --command=AnalyseComplex --pdb=4FQI_Repair.pdb --analyseComplexChains=A,B,H,L# output: Indiv_energies_4FQI_Repair_AC.fxout Interaction_4FQI_Repair_AC.fxout Interface_Residues_4FQI_Repair_AC.fxout Summary_4FQI_Repair_AC.fxout Indiv_energies_4FQI_Repair_AC: This file contains individual energy contributions of residues to the overall stability of the protein complex. To be notice, the total energy of the complex is not equals to the sum of individual total energy. Interaction_4FQI_Repair_AC: It records detailed interaction between each chain pairs. I think Interaction Energy is one of most important results from it. Summary_4FQI_Repair_AC.fxout: It contains only a few important columns from the Interaction_4FQI_Repair_AC.fxout. Interface_Residues_4FQI_Repair_AC.fxout: It records all residues in the interface in a list. Notice Before running AnalyseComplex, you should renumber the residues as well. Residue numbers like 100A and 100B in an antibody can both be shown as 100, leading to multiple entries like YH100 in the list. After renumbering the whole PDB with the script above, the results would become &quot;YH103, YH104, YH105&quot;. Additionally, the Interface_residues results may contain some unusual entries such as oA11. Technically, this means that in chain A, position 11, there is a non-typical residue, such as a Zn ion. pre { background-color:#38393d; color: #5fd381; } Teo Q W, Wang Y, Lv H, et al. Stringent and complex sequence constraints of an IGHV1-69 broadly neutralizing antibody to influenza HA stem[J]. Cell reports, 2023, 42(11). ↩︎ Yuan M, Feng Z, Lv H, et al. Widespread impact of immunoglobulin V-gene allelic polymorphisms on antibody reactivity[J]. Cell Reports, 2023, 42(10). ↩︎","link":"/2024/07/06/Bioinfor/foldx/"},{"title":"Understanding the Taylor Series and Its Applications in Machine Learning","text":"The Taylor Series is a fundamental mathematical tool that finds applications across various domains, including machine learning. In this post, we’ll explore what the Taylor Series is, how it is used in machine learning, and the significant impact it can have on optimizing machine learning models. Here are some good videos to explain the basic of the Taylor Series: Taylor series | Chapter 11, Essence of calculus, Visualization of the Taylor Series, 3 Applications of Taylor Series: Integrals, Limits, &amp; Series, and Dear Calculus 2 Students, This is why you’re learning Taylor Series What is the Taylor Series? The Taylor Series is a mathematical concept that allows us to approximate complex functions using an infinite sum of terms, calculated from the derivatives of the function at a specific point. It essentially breaks down a function into a polynomial that closely approximates the function near a given point. The general formula for the Taylor Series of a function $ f(x) $ around a point $ a $ is: $$ f(x) = \\sum_{n=0}^{\\infty} \\frac{f^{(n)}(a)}{n!} (x - a)^n $$ Where $ f^{(n)}(a) $ represents the $ n $-th derivative of $ f(x) $ at point $ a $, and $ n! $ is the factorial of $ n $. This approximation is particularly useful when dealing with functions that are difficult to compute directly, as it allows us to work with simpler polynomial expressions instead. Taylor Series for the Cosine Function The cosine function, $ \\cos(x) $, is a smooth and periodic function (line in black) that oscillates between -1 and 1. While it can be computed directly using trigonometric tables or built-in functions in programming languages, these computations can be resource-intensive, especially for small embedded systems or in scenarios requiring real-time processing. The Taylor Series provides a way to approximate $ \\cos(x) $ using a polynomial expansion around a specific point, typically $ x = 0 $ (the Maclaurin series, a special case of the Taylor Series). The Taylor Series for $ \\cos(x) $ is given by: $$ \\cos(x) = 1 - \\frac{x^2}{2!} + \\frac{x^4}{4!} - \\frac{x^6}{6!} + \\dots $$ This series can be written as: $$ \\cos(x) = \\sum_{n=0}^{\\infty} \\frac{(-1)^n}{(2n)!} x^{2n} $$ Where: $ (-1)^n $ alternates the sign of each term. $ (2n)! $ is the factorial of $ 2n $, ensuring that the series converges. $ x^{2n} $ means that only even powers of $ x $ are used, reflecting the symmetry of the cosine function. How the Approximation Works The beauty of the Taylor Series lies in its ability to approximate $ \\cos(x) $ with just a few terms, depending on the desired accuracy. First Few Terms: If you only take the first two terms (up to $ x^2 $), the approximation is: $$ \\cos(x) \\approx 1 - \\frac{x^2}{2} $$ This provides a reasonable approximation for $ \\cos(x) $ when $ x $ is close to 0, capturing the initial downward curve of the cosine function. Adding More Terms: As you include more terms (e.g., $ x^4 $, $ x^6 $), the approximation becomes increasingly accurate, even for values of $ x $ further from 0. Each additional term refines the curve, making the polynomial more closely match the actual cosine function. Practical Use and Computational Benefits In practical applications, such as in computer graphics, signal processing, or physics simulations, using the Taylor Series to approximate $ \\cos(x) $ can significantly reduce computational cost. Instead of performing the full trigonometric calculation, which might involve iterative or complex operations, a system can compute a few polynomial terms, which are far less demanding. Example: In embedded systems where processing power is limited, calculating $ \\cos(x) $ using the Taylor Series with just a few terms can save time and energy, which is crucial in battery-powered devices. Trade-off: There is always a trade-off between the number of terms used and the accuracy of the approximation. For most practical purposes, using 4 to 6 terms provides a good balance between accuracy and computational efficiency. Beyond Cosine: General Use in Trigonometric Functions The approach used to approximate $ \\cos(x) $ can also be applied to other trigonometric functions like $ \\sin(x) $ and $ \\tan(x) $. Each of these functions has its own Taylor Series expansion, enabling similar approximations and computational savings. Applications of Taylor Series in Machine Learning While the Taylor Series is a powerful mathematical tool on its own, its applications in machine learning are particularly noteworthy, especially in the context of optimization algorithms and model behavior analysis. 1. Gradient Descent and Optimization In machine learning, gradient descent is a widely used optimization technique that minimizes a loss function by iteratively adjusting model parameters. The Taylor Series plays a crucial role in understanding and improving this process. Basic Gradient Descent: Gradient descent uses the first-order Taylor approximation of the loss function to update parameters. However, the basic gradient descent approach can be slow and sensitive to the choice of the learning rate, often requiring careful tuning to avoid issues like overshooting or slow convergence. Newton’s Method Using Taylor Series: By incorporating the second-order Taylor expansion of the loss function, Newton’s method leverages the Hessian matrix (a matrix of second derivatives) to make more informed updates. This results in faster and more stable convergence, especially near the optimum, although it comes at the cost of increased computational complexity. Before vs. After Applying the Taylor Series: Before: Gradient descent can be slow and sensitive, requiring many iterations to reach a solution. After: Newton’s method, using the Taylor Series, accelerates convergence and provides more stability, particularly in challenging optimization landscapes. 2. Understanding Model Behavior The Taylor Series also helps in linearizing non-linear models, which is essential for understanding how small changes in input features affect the model’s output. Linearization of Non-Linear Models: By approximating non-linear functions (like activation functions in neural networks) with a Taylor Series, we can analyze the local behavior of these functions. This is particularly useful for sensitivity analysis, where understanding the impact of small input perturbations is crucial for model robustness. 3. Regularization and Generalization Regularization techniques, which are used to prevent overfitting in machine learning models, can also be viewed through the lens of the Taylor Series. By penalizing higher-order terms in the Taylor expansion, regularization methods like L2 regularization (Ridge) help in controlling model complexity and improving generalization. Real-World Example: Logistic Regression and Taylor Series To illustrate the practical application of the Taylor Series in machine learning, consider a logistic regression model used to classify emails as spam or not. The model uses a sigmoid function to predict probabilities, and the goal is to minimize the binary cross-entropy loss function. Without Taylor Series: Using basic gradient descent, the model may take many iterations to converge, with convergence being highly dependent on the chosen learning rate. With Taylor Series (Newton’s Method): By applying the Taylor Series, specifically the second-order approximation, the model can achieve faster and more stable convergence, even if each iteration is more computationally intensive. In this case, applying the Taylor Series through Newton’s method can drastically reduce the number of iterations required to reach an optimal solution, highlighting the power of this mathematical tool in machine learning optimization. Conclusion The Taylor Series is more than just a mathematical concept; it’s a powerful tool that underpins several key techniques in machine learning. From optimizing models with gradient descent to understanding the behavior of complex functions, the Taylor Series enables us to make more accurate and efficient decisions in model training and evaluation. Whether you’re dealing with logistic regression or deep learning, understanding and applying the Taylor Series can significantly enhance your machine learning practice. By incorporating second-order information through the Taylor Series, you can achieve faster convergence, better stability, and a deeper understanding of your models, ultimately leading to more robust and effective machine learning solutions. pre { background-color:#38393d; color: #5fd381; }","link":"/2024/08/09/AI/taylorseries/"},{"title":"DLVO theory: Atom Interaction","text":"DLVO Theory © J.H. Adair; 2001 DLVO theory is named after Derjaguin, Landau, Verwey, and Overbeek, who developed it in the 1940s. It describes the forces between charged surfaces interacting through a liquid medium. The theory combines two main types of forces: Van der Waals forces: These are attractive forces that arise from induced electrical interactions between molecules or atoms. Electrostatic double-layer forces: These are repulsive forces that occur due to the overlap of electrical double layers surrounding charged particles. The balance between these forces determines whether particles will aggregate (if the attractive forces dominate) or remain stable in suspension (if the repulsive forces dominate). This theory is widely used in colloid chemistry, environmental science, and materials science to understand and predict the stability of colloidal dispersions. The DLVO theory describes the interaction energy $ U_{total} $ between two colloidal particles as the sum of the Van der Waals attraction $ U_{VdW} $ and the electrostatic repulsion $ U_{elec} $. The general form of the DLVO potential is given by: $$ U_{total}(h) = U_{VdW}(h) + U_{elec}(h) $$ where $ h $ is the distance between the surfaces of the particles. Van der Waals Attraction ($ U_{VdW} $) The Van der Waals attraction energy between two spherical particles of radius $ R $ at a separation distance $ h $ is given by: $$ U_{VdW}(h) = - \\frac{A}{6} \\left( \\frac{2R^2}{h(2R + h)} + \\frac{2R^2}{(2R + h)^2} + \\ln \\left( \\frac{h}{2R + h} \\right) \\right) $$ $ A $: Hamaker constant (typically around $ 10^{-20} $ J for biological systems) $ R $: Radius of the amino acid (approx. $ 0.5 $ nm or $ 0.5 \\times 10^{-9} $ m) $ h $: Separation distance between the particles What if the atoms are different? $R^2= R_1 * R_2$ $2R = R_1 + R_2$ Electrostatic Repulsion ($ U_{elec} $) The electrostatic repulsion energy between two spherical particles with surface potential $ \\psi_0 $ and radius $ R $ in a medium with Debye length $ \\kappa^{-1} $ (which is related to the ionic strength of the medium) is given by: $$ U_{elec}(h) = 2 \\pi \\epsilon R \\psi_0^2 \\ln \\left( 1 + \\exp(-\\kappa h) \\right) $$ $ \\epsilon $: Permittivity of the medium (water, typically $ 80 \\times 8.854 \\times 10^{-12} $ F/m) $ \\psi_0 $: Surface potential (approx. $ 25 $ mV or $ 25 \\times 10^{-3} $ V) $ \\kappa $: Inverse Debye length (for a Debye length of $ 1 $ nm, $ \\kappa \\approx 10^9 $ m$^{-1}$) $ h $: Separation distance between the particles Total Interaction Energy Combining these two expressions, the total interaction energy is: $$ U_{total}(h) = - \\frac{A}{6} \\left( \\frac{2R^2}{h(2R + h)} + \\frac{2R^2}{(2R + h)^2} + \\ln \\left( \\frac{h}{2R + h} \\right) \\right) + 2 \\pi \\epsilon R \\psi_0^2 \\ln \\left( 1 + \\exp(-\\kappa h) \\right) $$ This equation allows us to predict whether the colloidal particles will repel each other and remain stable in suspension or attract each other and aggregate, depending on the balance of the attractive and repulsive forces. Separation Distance (h) If the radii $ R_1 $ and $ R_2 $ of two spherical particles are known, and the center-to-center distance between them is $ D $, the separation distance $ h $ is calculated as: $$ h = D - (R_1 + R_2) $$ For identical particles with the same radius $ R $, it simplifies to: $$ h = D - 2R $$ In the code snippet provided, the parameters can be categorized into constant parameters (those that remain the same across different residues) and variable parameters (those that may change depending on the specific residues or the system under consideration). Parameters Constant Parameters: $ A $ (Hamaker constant): Value: $ 1 \\times 10^{-20} $ J Description: This is a material-specific constant that depends on the nature of the interacting particles and the medium. For biological molecules in water, it’s often taken as a constant. $ \\epsilon $ (Permittivity of the medium): Value: $ 80 \\times 8.854 \\times 10^{-12} $ F/m (Permittivity of water) Description: The permittivity of the medium (usually water in biological contexts) is a constant based on the dielectric properties of the solvent. $ \\kappa $ (Inverse Debye length): Value: $ 1 \\times 10^9 $ m$^{-1}$ Description: The inverse Debye length is related to the ionic strength of the medium and is often considered constant under specific conditions, such as physiological ionic strength. Variable Parameters: $ R $ (Radius of the amino acid): Value: $ 0.5 \\times 10^{-9} $ m (0.5 nm) Description: The radius could vary slightly between different amino acids, especially when considering side chains. The value used here is an approximation and might need adjustment for specific residues. $ \\psi_0 $ (Surface potential): Value: $ 25 \\times 10^{-3} $ V (25 mV) Description: The surface potential can vary depending on the charge state of the amino acid side chains. For example, charged residues like lysine or aspartic acid will have different surface potentials compared to neutral residues like alanine. $ h $ (Separation distance): Value: Range from $ 0.1 \\times 10^{-9} $ m to $ 10 \\times 10^{-9} $ m Description: The separation distance between two residues or atoms is the primary variable in these calculations, often determined by the 3D structure of the protein or molecular complex being studied. Who to Know the R and h? To calculate the radius of amino acids such as valine (V) and phenylalanine (F), you’re generally referring to an approximation of the van der Waals (VDW) radius or the effective radius of the entire amino acid side chain. This radius can be used in models like DLVO theory to represent the size of the interacting particle. Methods to Determine the Radius: Van der Waals Radius of Atoms: The van der Waals radius is an inherent property of atoms and can be summed up to approximate the radius of a molecule or side chain. For example, the VDW radius for carbon is about 1.7 Å, and for hydrogen, it’s about 1.2 Å. Effective Radius from Crystal Structures: If you have a crystal structure or molecular model, you can measure the effective radius of the side chain by considering the spatial extent of the side chain atoms. This is often done using software tools that can calculate the solvent-accessible surface area (SASA) or by directly measuring distances in a molecular viewer. Using Approximate Values from Literature: For many applications, approximate radii for amino acids are available in the literature based on their typical side chain sizes. Approximate Radii for Valine (V) and Phenylalanine (F): Valine (V): Valine has a branched, non-polar side chain. Its effective radius is often approximated as ~3.0 Å (0.3 nm). Phenylalanine (F): Phenylalanine has a larger, aromatic side chain. Its effective radius is typically around ~3.5-4.0 Å (0.35-0.4 nm). These values are not exact but are generally used in theoretical calculations. Calculation Example: If you need to calculate the interaction between valine (V) and phenylalanine (F), you could use these approximate radii: Valine (V): $ R_V \\approx 0.3 $ nm Phenylalanine (F): $ R_F \\approx 0.35 $ nm The separation distance $ h $ would then be calculated based on the center-to-center distance $ D $ between the residues: $$ h = D - (R_V + R_F) $$ If $ D $ is known (from a crystal structure or a model), this formula gives the separation distance $ h $ between the residues’ surfaces. Tools for More Accurate Measurements: Molecular Visualization Software (e.g., PyMOL, Chimera): You can load a protein structure and measure the distance between specific atoms or calculate the van der Waals surface. Computational Tools: Software packages like CHARMM, AMBER, or GROMACS can provide detailed calculations based on molecular dynamics or energy minimization, giving more precise values for radii in specific contexts. Python Script import numpy as npimport matplotlib.pyplot as pltdef van_der_waals(h, A, R): &quot;&quot;&quot;Calculate Van der Waals attraction energy.&quot;&quot;&quot; term1 = (2 * R**2) / (h * (2 * R + h)) term2 = (2 * R**2) / (2 * R + h)**2 term3 = np.log(h / (2 * R + h)) return - (A / 6) * (term1 + term2 + term3)def electrostatic_repulsion(h, epsilon, R, psi_0, kappa): &quot;&quot;&quot;Calculate electrostatic repulsion energy.&quot;&quot;&quot; return 2 * np.pi * epsilon * R * psi_0**2 * np.log(1 + np.exp(-kappa * h))def dlvo_total(h, A, R, epsilon, psi_0, kappa): &quot;&quot;&quot;Calculate total DLVO interaction energy.&quot;&quot;&quot; return van_der_waals(h, A, R) + electrostatic_repulsion(h, epsilon, R, psi_0, kappa)# ParametersA = 1e-20 # Hamaker constant in JR = 1e-7 # Radius of particles in mepsilon = 80 * 8.854e-12 # Permittivity of water in F/mpsi_0 = 25e-3 # Surface potential in Vkappa = 1e8 # Inverse Debye length in 1/mh = np.linspace(5e-10, 1e-7, 400) # Separation distance in m# Calculate DLVO potentialU_vdw = van_der_waals(h, A, R)U_elec = electrostatic_repulsion(h, epsilon, R, psi_0, kappa)U_total = dlvo_total(h, A, R, epsilon, psi_0, kappa)# Plot resultsplt.figure(figsize=(10, 6))plt.plot(h * 1e9, U_vdw, label='Van der Waals Attraction', linestyle='-.')plt.plot(h * 1e9, U_elec, label='Electrostatic Repulsion', linestyle='-.')plt.plot(h * 1e9, U_total, label='Total DLVO Potential')plt.xlabel('Separation Distance (nm)')plt.ylabel('Interaction Energy (J)')plt.title('DLVO Theory Interaction Energy')plt.legend()plt.grid(True)plt.show() Simplified System Empirical Formula in the Context of Your Problem A general empirical formula for the interaction energy $ \\Delta G_{i,j} $ between two residues $ H_i $ and $ A_j $ might look like this: $$ \\Delta G_{i,j} = V_{\\text{LJ}}(r_{ij}) + V_{\\text{Coulomb}}(r_{ij}) $$ Where: $ r_{ij} $ is the distance between residue $ H_i $ and residue $ A_j $. $ V_{\\text{LJ}}(r_{ij}) $ represents the van der Waals interaction. $ V_{\\text{Coulomb}}(r_{ij}) $ represents the electrostatic interaction. Lennard-Jones Potential (van der Waals Interactions) The Lennard-Jones potential is a commonly used empirical formula to describe the van der Waals forces between two non-bonded atoms or molecules. It has the form: $$ V_{\\text{LJ}}( r ) = 4\\epsilon \\left[ \\left(\\frac{\\sigma}{r}\\right)^{12} - \\left(\\frac{\\sigma}{r}\\right)^{6} \\right] $$ $ V_{\\text{LJ}}( r ) $ is the potential energy as a function of distance $ r $ between two particles. $ \\epsilon $ is the depth of the potential well, representing the strength of the interaction. $ \\sigma $ is the distance at which the potential energy is zero (often related to the size of the atoms/molecules). $ r $ is the distance between the two particles. The term $ \\left(\\frac{\\sigma}{r}\\right)^{12} $ represents the repulsive interaction at short distances (due to Pauli exclusion principle), and the term $ \\left(\\frac{\\sigma}{r}\\right)^{6} $ represents the attractive van der Waals forces at longer distances. Coulomb’s Law (Electrostatic Interactions) Coulomb’s law describes the electrostatic interaction between two charged particles: $$ V_{\\text{Coulomb}}( r ) = \\frac{k_e \\cdot q_1 \\cdot q_2}{r} $$ $ V_{\\text{Coulomb}}( r ) $ is the potential energy between two charges. $ k_e $ is Coulomb’s constant ($ 8.9875 \\times 10^9 , \\text{N} \\cdot \\text{m}2/\\text{C}2 $ in vacuum). $ q_1 $ and $ q_2 $ are the charges of the two interacting particles. $ r $ is the distance between the two charges. Python Script from prody import *import numpy as np# Load the protein structurestructure = parsePDB('your_structure.pdb')# Select the side chains of the residues of interestresidue1_sidechain = structure.select('resid 10 and sidechain')residue2_sidechain = structure.select('resid 20 and sidechain')# Function to calculate interaction energy considering only side chainsdef calculate_interaction_energy(residue1, residue2, cutoff=5.0): &quot;&quot;&quot; Calculate the van der Waals and electrostatic interaction energy between two residues' side chains using a simple empirical formula. :param residue1: ProDy atom group for the first residue side chain :param residue2: ProDy atom group for the second residue side chain :param cutoff: Distance cutoff for interaction (in Å) :return: Tuple of (vdW energy, electrostatic energy) &quot;&quot;&quot; # van der Waals parameters (simplified example) epsilon = 0.1 # Depth of the potential well (kcal/mol) sigma = 3.5 # Distance at which the potential is zero (Å) # Coulomb constant (for electrostatic energy calculation) k_e = 8.9875517873681764e9 # N m² C⁻² (can be adjusted for unit compatibility) # Simplified charges for electrostatic calculation charge1 = np.sum([atom.getCharge() for atom in residue1]) charge2 = np.sum([atom.getCharge() for atom in residue2]) vdW_energy = 0.0 electrostatic_energy = 0.0 # Calculate pairwise interactions considering only side chains for atom1 in residue1: for atom2 in residue2: distance = np.linalg.norm(atom1.getCoords() - atom2.getCoords()) if distance &lt; cutoff: # van der Waals energy (Lennard-Jones potential) vdW_energy += 4 * epsilon * ((sigma / distance)**12 - (sigma / distance)**6) # Electrostatic energy (Coulomb's law) electrostatic_energy += k_e * (charge1 * charge2) / distance return vdW_energy, electrostatic_energy# Calculate interaction energyvdW_energy, electrostatic_energy = calculate_interaction_energy(residue1_sidechain, residue2_sidechain)print(f&quot;van der Waals Energy: {vdW_energy:.2f} kcal/mol&quot;)print(f&quot;Electrostatic Energy: {electrostatic_energy:.2f} kcal/mol&quot;) Codes for the plot h = np.linspace(3.3, 10, 400) # Separation distance in m# Plot resultsplt.figure(figsize=(10, 6))plt.plot(h, [0 for i in h], linestyle = '-.')plt.plot(h, [calculate_interaction_energy(i) for i in h], color = 'salmon')plt.xlabel('Separation Distance (Åm)')plt.ylabel('Interaction Energy')plt.title('Lennard-Jones Potential')plt.legend()plt.grid(True)plt.show() In this plot, it shows the change of the Lennard-Jones Potential with the change of the distance when the $\\sigma = 3.5$ pre { background-color:#38393d; color: #5fd381; }","link":"/2024/08/16/LearnNotes/DLVOtheory/"},{"title":"Kernel Density Estimation (KDE)","text":"Kernel Density Estimation (KDE) Kernel Density Estimation (KDE) is a non-parametric method to estimate the probability density function (PDF) of a random variable based on a finite set of data points. Unlike parametric methods, which assume that the underlying data follows a specific distribution (like normal, exponential, etc.), KDE makes no such assumptions and can model more complex data distributions. How KDE Works: Kernel Function: The kernel function is a smooth, continuous, symmetric function that is centered on each data point. The most commonly used kernel is the Gaussian (normal) kernel, but other kernels like Epanechnikov, triangular, and uniform can also be used. Bandwidth (Smoothing Parameter): The bandwidth is a crucial parameter that controls the smoothness of the KDE. It determines the width of the kernel functions. A smaller bandwidth leads to a more sensitive, less smooth estimate, while a larger bandwidth produces a smoother, less sensitive estimate. Summation of Kernels: KDE constructs the overall density estimate by summing the contributions of each kernel function across all data points. Each data point contributes a small “bump” to the estimate, and the sum of these bumps forms the estimated density function. KDE Formula: Given a set of $ n $ data points $ x_1, x_2, \\ldots, x_n $, the KDE at a point $ x $ is calculated as: $$ \\hat{f}(x) = \\frac{1}{n \\cdot h} \\sum_{i=1}^{n} K\\left(\\frac{x - x_i}{h}\\right) $$ Where: $ \\hat{f}(x) $ is the estimated density at point $ x $. $ n $ is the number of data points. $ h $ is the bandwidth. $ K $ is the kernel function. $ x_i $ are the observed data points. Example of KDE: Imagine you have a dataset of people’s heights. Rather than assuming the heights follow a specific distribution (like normal), KDE allows you to estimate the distribution directly from the data, which may reveal subtle features like bimodal distributions (e.g., a mix of two distinct groups). Advantages of KDE: Flexible: KDE doesn’t assume any specific form of the distribution, making it suitable for complex and unknown distributions. Smooth Estimation: It provides a smooth estimate of the density function, which can be more informative than histograms. Disadvantages of KDE: Choice of Bandwidth: The performance of KDE heavily depends on the choice of bandwidth. Too small a bandwidth can lead to overfitting, while too large a bandwidth can oversmooth important features. Computationally Intensive: KDE can be computationally intensive, especially for large datasets and high-dimensional data. Applications of KDE: Data Visualization: KDE is often used to visualize the distribution of data, particularly in one-dimensional and two-dimensional cases. Anomaly Detection: KDE can be used to detect outliers by identifying areas of low probability density. Density-Based Clustering: In clustering methods like DBSCAN, KDE can help define regions of high density. How Do It in Python import numpy as npfrom sklearn.neighbors import KernelDensityimport matplotlib.pyplot as pltimport seaborn as sns# Step 2: Prepare Your Data# Example list of valuesdata_list = [1.2, 2.3, 2.4, 2.5, 3.1, 3.6, 3.8, 4.0, 4.2, 5.0] * 30# Convert the list to a NumPy array and reshape it for the modeldata = np.array(data_list).reshape(-1, 1)# Step 3: Fit the Kernel Density Estimation Model# Fit the KDE modelkde = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(data)# Step 4: (Optional) Plot the Estimated Density# Define a range of valuesx_range = np.linspace(0, 6, 1000).reshape(-1, 1)# Estimate density for the entire rangelog_density = kde.score_samples(x_range)density = np.exp(log_density)# Plot the densitysns.kdeplot(data_list, bw_adjust=0.5)plt.plot(x_range, density)plt.title(&quot;Kernel Density Estimation&quot;)plt.xlabel(&quot;Value&quot;)plt.ylabel(&quot;Density&quot;)plt.show() Save and Load the Model import pickle# Fit the KDE model (assuming you have already done this)# kde = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(data)# Save the model to a filewith open('kde_model.pkl', 'wb') as file: pickle.dump(kde, file)# Load the model from the filewith open('kde_model.pkl', 'rb') as file: loaded_kde = pickle.load(file)# Value for which you want to estimate the densityvalue = 3.5# Estimate the density using the loaded modellog_density = loaded_kde.score_samples([[value]])density = np.exp(log_density)print(f&quot;Density of the value {value} using loaded model: {density[0]:.6f}&quot;) pre { background-color:#38393d; color: #5fd381; }","link":"/2024/08/16/AI/KernelDensityEstimation/"},{"title":"Support Vector Machine","text":"What is Support Vector Machine SVM was developed in the 1990s by Vladimir Vapnik and his colleagues. The development of SVM was rooted in statistical learning theory. It introduced the concept of finding the maximum margin hyperplane to separate classes effectively, with extensions to handle non-linear data through kernel functions. SVM gained popularity due to its ability to create powerful classifiers, especially in high-dimensional feature spaces. Compare to Random Forest Random Forest is an ensemble method that combines multiple decision trees to improve accuracy and reduce overfitting, handling both linear and non-linear data well. It’s good for large datasets and provides feature importance but is less interpretable. SVM finds the optimal hyperplane to separate classes by maximizing the margin. It works well for smaller, high-dimensional datasets but is computationally expensive for large datasets and harder to interpret. Compare to Linear Regression The decision function of Support Vector Machine (SVM) looks very similar to a linear function—and indeed, it shares common elements with linear regression. However, the main differences lie in their objectives and the way they handle data: Similarities Linear Function Form: Both SVM and Linear Regression use a linear function of the form: $$ f(x) = w_1 x_1 + w_2 x_2 + \\cdots + w_k x_k + b $$ Where $ w_i $ are the weights, $ x_i $ are the features, and $ b $ is the bias term. Weight Optimization: Both models optimize the weights ($ w $) to achieve their goals. Key Differences Objective Function: Linear Regression: The goal is to minimize the error (typically the mean squared error) between predicted and actual values. It aims to find the line (or hyperplane) that best fits the data points by minimizing the difference between predictions and true values. SVM: The goal is to maximize the margin between different classes. SVM seeks to find a hyperplane that not only separates the classes but does so with the largest possible gap between the nearest points of each class (called support vectors). This makes the decision boundary as robust as possible against errors or noise. Loss Function: Linear Regression: Uses squared loss to penalize errors, which means that even small deviations contribute to the overall loss. SVM: Uses a hinge loss function for classification, which penalizes misclassifications and ensures a margin of separation. The loss function focuses more on correctly classifying data points with maximum confidence. Problem Type: Linear Regression: Primarily used for regression problems, where the goal is to predict a continuous output. SVM: Primarily used for classification (though it can be adapted for regression as SVR), where the goal is to classify data points into different categories. In SVM, the function output is interpreted using a sign function, where: $$ f(x) = w^T x + b \\Rightarrow \\text{classify as } \\begin{cases} +1, &amp; \\text{if } f(x) &gt; 0 \\\\ -1, &amp; \\text{if } f(x) &lt; 0 \\end{cases} $$ Margin and Support Vectors: Linear Regression: There is no concept of a margin or support vectors in linear regression. It simply finds the line of best fit for all data points. SVM: Introduces the concept of margin, which is the distance between the hyperplane and the closest data points from each class. These closest points are called support vectors, and they are crucial to defining the decision boundary. Use of Kernels (Non-linearity): Linear Regression: Strictly a linear model. To handle non-linearity, you would have to explicitly add polynomial features or transform the features. SVM: Supports kernel tricks (such as polynomial or radial basis function kernels) to project data into higher dimensions, allowing it to separate data that isn’t linearly separable in its original space. This feature makes SVM more powerful for complex, non-linear classification problems. Summary Linear Regression: Minimizes prediction error for a best-fit line, used for regression. SVM: Maximizes the margin to find an optimal separating hyperplane, used for classification. While both use linear functions, SVM is fundamentally about classification and margin maximization, whereas linear regression focuses on minimizing the difference between predicted and actual continuous values. SVM also handles non-linearity more effectively through kernels, making it more versatile for complex datasets. Overview of SVM Decision Boundary: $w^T x + b$. Classification: $f(x) = sign(w^T x + b)$ Cost function: Training error cost + $\\lambda$ penalty Number of Features Decision Boundary Equation Classification Equation 1 Feature $ w_1 x_1 + b = 0 $ $ f(x) = \\text{sign}(w_1 x_1 + b) $ 2 Features $ w_1 x_1 + w_2 x_2 + b = 0 $ $ f(x) = \\text{sign}(w_1 x_1 + w_2 x_2 + b) $ $ k $ Features $ w_1 x_1 + w_2 x_2 + \\cdots + w_k x_k + b = 0 $ $ f(x) = \\text{sign}(w_1 x_1 + w_2 x_2 + \\cdots + w_k x_k + b) $ What does $w^T$ mean Explanation: A vector $ w $ is typically represented as a column vector, meaning it has multiple rows and a single column. $ w^T $ is the transpose of $ w $, which means converting a column vector into a row vector, or vice versa. Mathematical Notation: If $ w $ is a column vector with elements: $$ w = \\begin{bmatrix} w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_n \\end{bmatrix} $$ Then the transpose $ w^T $ is w row vector: $$ w^T = \\begin{bmatrix} w_1 &amp; w_2 &amp; \\cdots &amp; w_n \\end{bmatrix} $$ In SVM or machine learning, the transpose is often used to indicate a dot product operation when combined with another vector or matrix. For example, if you have: $w^T x $, it means you're calculating the dot product of vector $ w $ and vector $ x $, which is a scalar value used in calculating distances, projections, or in constructing decision boundaries in algorithms like SVM. Features $$ f(\\mathbf{x}) = \\text{sign}(\\mathbf{w}^T \\mathbf{x} + b) $$ where $$ \\mathbf{x} = \\begin{bmatrix} x_0 \\ x_1 \\end{bmatrix}, \\quad \\mathbf{w} = \\begin{bmatrix} w_0 \\ w_1 \\end{bmatrix}, \\quad \\text{and} \\quad b \\text{ is a scalar.} $$ Boundary The boundary condition is given by: $$ \\begin{bmatrix} w_0 &amp; w_1 \\end{bmatrix} \\begin{bmatrix} x_0 \\ x_1 \\end{bmatrix} + b = 0 $$ Solving for $ x_1 $: $$ w_0 x_0 + w_1 x_1 + b = 0 $$ $$ x_1 = -\\frac{w_0}{w_1} x_0 - \\frac{b}{w_1} $$ Classification The classification function is: $$ y = \\begin{cases} 1 &amp; \\text{if } x_1 \\geq -\\frac{w_0}{w_1}x_0 - \\frac{b}{w_1} \\\\ -1 &amp; \\text{if } x_1 &lt; -\\frac{w_0}{w_1}x_0 - \\frac{b}{w_1} \\end{cases} $$ Training Cost The training cost in SVM refers to the computational and resource-related costs involved in training the model, which is an important consideration when choosing an algorithm, especially for larger datasets. SVM’s training cost is influenced by its optimization problem, which involves finding the hyperplane that maximizes the margin while correctly classifying the training data (or with minimal misclassification for soft margins). Training Cost in SVM Optimization Complexity: SVM training involves solving a quadratic optimization problem to find the best hyperplane. This process is complex and takes more computation, especially with non-linear kernels. Time Complexity: Linear SVM: Training time is between $O(n * d)$ and $O(n^2 * d)$, where $ n $ is the number of data points and $ d $ is the number of features. Non-linear Kernel SVM: Training complexity is approximately $O(n^2)$ to $O(n^3)$, making it very expensive for large datasets. Memory Usage: With kernels, SVM stores a kernel matrix of size $ n \\times n $, which uses a lot of memory if $ n $ is large. Support Vectors: More support vectors means more computation during both training and prediction. Complex datasets often need more support vectors. Why Care About Training Cost? Scalability: SVM can become impractical for large datasets due to the high cost in terms of time and memory. Resources: It requires substantial CPU and memory, limiting its use on resource-constrained systems. Algorithm Selection: For small to medium datasets, SVM works well. For large datasets, other methods like Random Forest or SGD may be better. Reducing Training Cost Linear SVM: Use for linearly separable data—it has lower complexity. Approximations: Use SGDClassifier or kernel approximations for faster training. Data Subset: Train on a smaller subset of data to speed up training. Hinge Loss Condition Cost Function Description $y_i \\neq \\text{sign}(\\hat{y}_i)$ $C(y_ i, \\hat{y}_ i) = |y_ i| + 1$ Large $y_i = \\text{sign}(\\hat{y}_i)$ close $C(y_ i, \\hat{y}_ i) = |y_ i| + 1$ Medium $y_i = \\text{sign}(\\hat{y}_i)$ away $C(y_ i, \\hat{y}_ i) = 0$ No cost General Cost Function $C(y_ i, \\hat{y}_ i) = \\max(0, 1 - y_ i \\cdot \\hat{y}_ i)$ - Train a SVM Training Error $ \\frac{1}{N} \\sum_{i=1}^N C(y_i, \\hat{y}_ i)$ $ = \\frac{1}{N} \\sum_{i=1}^N \\max(0, 1 - y_ i \\cdot \\hat{y}_ i) $ $ = \\frac{1}{N} \\sum_{i=1}^N \\max(0, 1 - y_i \\cdot (\\mathbf{w}^T \\mathbf{x}_i + b)) $ Cost Function $$ S(\\mathbf{w}, b; \\lambda) = \\frac{1}{N} \\sum_{i=1}^N [\\max(0, 1 - y_i \\cdot (\\mathbf{w}^T \\mathbf{x}_i + b))] + \\frac{\\lambda}{2} \\mathbf{w}^T \\mathbf{w} $$ Stochastic Gradient Descent In training a Support Vector Machine (SVM), the primary objective is to minimize the cost function. This cost function often includes terms that measure the classification error and possibly a regularization term. The minimization of the cost function aims to find the best hyperplane that separates the classes while also considering the margin maximization between different classes and controlling model complexity to prevent overfitting. $$ \\mathbf{u} = \\begin{bmatrix} \\mathbf{w} \\ b \\end{bmatrix} $$ Minimize cost function: $$ g(\\mathbf{u}) = \\left[ \\frac{1}{N} \\sum_{i=1}^N g_i(\\mathbf{u}) \\right] + g_0(\\mathbf{u}) $$ where: $$ g_i(\\mathbf{u}) = \\max(0, 1 - y_i \\cdot (\\mathbf{w}^T \\mathbf{x}_i + b)) $$ and: $$ g_0(\\mathbf{u}) = \\frac{\\lambda}{2} \\mathbf{w}^T \\mathbf{w} $$ Iteratively, at step $(n)$: Compute descent direction $p^{(n)}$ and step size $\\eta$ Ensure that $g(u^{(n)} + \\eta p^{(n)}) \\leq g(u^{(n)})$ Update $u^{(n+1)} = u^{(n)} + \\eta p^{(n)}$ Descent direction: $$ p^{(n)} = -\\nabla g(\\mathbf{u}^{(n)}) $$ $$ = -\\left( \\frac{1}{N} \\sum_{i=1}^N \\nabla g_i(\\mathbf{u}) + \\nabla g_0(\\mathbf{u}) \\right) $$ Estimation through mean of batch: $$ p^{(n)}_ {N_ b} = -\\left( \\frac{1}{N_b} \\sum_ {j \\in \\text{batch}} \\nabla g_ j(\\mathbf{u}) + \\nabla g_ 0(\\mathbf{u}) \\right) $$ Epoch One pass on training set of size $N$ Each step sees a batch of $N_b$ items The dataset is covered in $\\frac{N}{N_b}$ steps Step size in epoch $e$: $\\eta^{(e)} = \\frac{m}{e + l}$ Constants $m$ and $l$: tune on small subsets Season Constant number of iterations, much smaller than epochs Each step sees a batch of $N_b$ items Step size in season $s$: $\\eta^{(s)} = \\frac{m}{s + l}$ Constants $m$ and $l$: tune on small subsets Full SGD Vector u and its gradient: $$ \\mathbf{u} = \\begin{bmatrix} u_1 \\\\ \\vdots \\\\ u_d \\end{bmatrix}, \\quad \\nabla g = \\begin{bmatrix} \\frac{\\partial g}{\\partial u_1} \\\\ \\vdots \\\\ \\frac{\\partial g}{\\partial u_d} \\end{bmatrix} $$ Batches of 1 sample at each training step: $$ N_b = 1 $$ Gradient of g(u): $$ \\nabla g(\\mathbf{u}) = \\nabla \\left( \\max(0, 1 - y_i \\cdot (\\mathbf{w}^T \\mathbf{x}_i + b)) + \\frac{\\lambda}{2} \\mathbf{w}^T \\mathbf{w} \\right) $$ Update rules for a and b: $$ \\begin{bmatrix} \\mathbf{w}^{(n+1)} \\ b^{(n+1)} \\end{bmatrix} = \\begin{bmatrix} \\mathbf{w}^{(n)} \\ b^{(n)} \\end{bmatrix} - \\eta \\begin{bmatrix} \\nabla_{\\mathbf{w}} \\ \\nabla_{b} \\end{bmatrix} $$ Condition for correct classification away from the boundary: $$ y_ i \\cdot (\\mathbf{w}^T \\mathbf{x}_ i + b) \\geq 1. \\quad \\text{Correct, away from boundary} $$ $$ \\nabla_ {\\mathbf{w}} (0 + \\frac{\\lambda}{2} \\mathbf{w}^T \\mathbf{w}) = \\lambda \\mathbf{w}, \\quad \\nabla_ {b}(0 + \\frac{\\lambda}{2} \\mathbf{w}^T \\mathbf{w}) = 0 $$ Condition for classification close to the boundary or incorrect: $$ y_ i \\cdot (\\mathbf{w}^T \\mathbf{x}_ i + b) &lt; 1. \\quad \\text{Correct, close to boundary, or incorrect} $$ $$ \\nabla_ {\\mathbf{w}} (1 - y_ i \\cdot (\\mathbf{w}^T \\mathbf{x}_ i + b) + \\frac{\\lambda}{2} \\mathbf{w}^T \\mathbf{w}) = -y_i \\mathbf{x}_ i + \\lambda \\mathbf{w} $$ $$ \\nabla_ {b} (1 - y_ i \\cdot (\\mathbf{w}^T \\mathbf{x}_ i + b) + \\frac{\\lambda}{2} \\mathbf{w}^T \\mathbf{w}) = -y_i $$ Stops Stop when predefined number of seasons or epochs error on held-out data items is smaller than some threshold other criteria Regularization Constant $ \\lambda $ Regularization constant $ \\lambda $ in $ g(\\mathbf{u}) = \\frac{1}{2} \\lambda \\mathbf{w}^T \\mathbf{w} $. Try at different scales (e.g., $ \\lambda \\in {10^{-4}, 10^{-3}, 10^{-2}, 10^{-1}, 1} $) Procedure for Cross-Validation: Split dataset into Test Set and Train Set for cross-validation. For each $ \\lambda_i $ in set to try, iteratively: Generate a new Fold from Train Set with a Cross-Validation Train Set and Validation Set. Using testing $ \\lambda_i $, apply Stochastic Gradient Descent (SGD) on Cross-Validation Train Set to find $ \\mathbf{w} $ and $ b $. Evaluate $ \\mathbf{w} $, $ b $, $ \\lambda_i $ on Validation Set and record error for current Fold. Cross-validation error for chosen $ \\lambda_i $ is average error over all the Folds. Using $ \\lambda $ with the lowest cross-validation error, apply SGD on whole training set to get final $ \\mathbf{w} $ and $ b $. pre { background-color:#38393d; color: #5fd381; }","link":"/2024/09/29/AI/supportvectormachine/"},{"title":"Random Forest","text":"Basic Architectures Bootstrap Sampling: Random subsets of the training data are created with replacement, known as bootstrap samples. Each subset is used to train an individual decision tree. Feature Randomness: For each tree, a random subset of features is considered at each split, reducing correlation among trees and improving generalization. Multiple Decision Trees: Multiple decision trees are grown independently using the bootstrap samples. Each tree makes a prediction for a given input. Ensemble Output: For classification, the output is typically based on majority voting across all trees, while for regression, the final output is an average of all tree predictions. Limitations Many different trees can lead to similar classifications The algorithm to build a decision tree grows each branch just deeply enough to perfectly classify the training examples potential overfit Randomness in identification of splits: features, thresholds better splits may have not been considered Addressed through Random Forests Basic of Random Forest Tree Expanding Random forest is build on number of decision trees. For avoiding the overfit, early stop is needed during the tree expanding. It stop when depth(branch_node) &gt;= max_depth (manual) size(dataset) &lt;= min_leave_size (manual) all elements in dataset in same class Decision Making The best decision made could be evaluate by the “entropy”. 2 classes: Here are the formulas from the image converted into Markdown format: $ \\text{Entropy}(S) = -P(A) \\log_2 P(A) - P(B) \\log_2 P(B) $ $ N = |A| + |B| $ $ P(A) = \\frac{|A|}{N}, \\quad P(B) = \\frac{|B|}{N} $ C classes: $ \\text{Entropy}(S) = - \\sum_{i=1}^C P_i \\log_2 P_i $ Each class $ i $ with probability $ P_i $. Information Gain Goal: The goal is to maximize Information Gain at each split, which corresponds to choosing features that result in subsets with the least entropy, making the data more pure (less mixed) after the split. In Random Forest and decision tree learning, the feature with the highest Information Gain is selected for splitting at each node. Definition: Information Gain measures the reduction in entropy (or uncertainty) after splitting a dataset. It helps to determine the best feature for splitting the data. Entropy Before Split: The initial dataset $ S $ has an entropy $ \\text{Entropy}(S) $, which quantifies the impurity or randomness in the dataset. Entropy After Split: When the dataset is split into subsets $ S_l $ and $ S_r $, each subset has its own entropy: $ \\text{Entropy}(S_l) $ and $ \\text{Entropy}(S_r) $. Weighted Entropy: The weighted average of the entropy of the subsets after the split is given by: $$ \\text{Entropy}_{\\text{after split}} = \\frac{|S_l|}{|S|} \\text{Entropy}(S_l) + \\frac{|S_r|}{|S|} \\text{Entropy}(S_r) $$ Information Gain Calculation: The Information Gain for the feature $ x^{(i)} $ is calculated as the difference between the entropy before and after the split: $$ \\text{Information Gain} = \\text{Entropy}(S) - \\text{Entropy}_{\\text{after split}} $$ The symbols $ |S| $, $ |S_l| $, and $ |S_r| $ represent the cardinalities or the sizes of the respective sets, meaning they indicate the number of elements in each set. Missing Values In splits, if an item misses the feature value that decide where it goes Estimate it based on other examples: mode or mean Consider only the examples in the corresponding branch Decision Tree in Random Forest For get the best “Decision” in each branch, iterating through all possible splits at each node can be computationally expensive, especially for large datasets and numerous features. However, decision trees (and Random Forests) use several optimization techniques to find the best split efficiently, while managing computational cost: 1. Feature and Threshold Selection Strategy Greedy Algorithm: Decision tree algorithms commonly use a greedy approach to split at each node. They do not explore all possible trees but instead make the locally optimal choice (the split that maximizes Information Gain or minimizes entropy) at each step. While this doesn’t guarantee a globally optimal tree, it is computationally efficient. Threshold Optimization: Rather than testing every possible threshold for each feature, the algorithm often considers a subset of thresholds. If the feature is numeric, thresholds are typically evaluated at points between consecutive, sorted feature values. 2. Random Forest Feature Subsampling In Random Forests, at each node, only a random subset of features is considered for splitting, rather than evaluating all features. This greatly reduces the number of calculations needed, enhances computational efficiency, and decorrelates the trees in the ensemble (increasing robustness). 3. Heuristics to Reduce Computation Best First Split: During the process, the split that gives the maximum Information Gain is stored, and the search for a better split continues until the end of the subset of considered thresholds. If no better split is found, the stored one is selected. Stopping Conditions: To further reduce resource usage, decision tree growth is often constrained by stopping criteria such as maximum depth, minimum number of samples per leaf, or if a split provides insufficient improvement. 4. Approximations for Efficiency Bin-based Thresholds: For numerical features, rather than considering every possible value as a split point, values can be grouped into bins. The potential split thresholds are then defined based on these bins. Pre-sorting Features: In some implementations, features are pre-sorted, so determining potential split points for numeric features can be faster. 5. Iterative Splitting and Best Split Finding For categorical features, the split can be done in subsets if there are many categories, or by considering binary splits. For numerical features, it evaluates splits between values. Yes, it does involve iteration, but the optimizations listed above ensure that this iteration is performed in a manageable and efficient way without explicitly iterating through every possible split for all features. Balancing Efficiency and Quality of Decision Trees The combination of the above techniques allows decision trees to strike a balance between: Finding Good Splits: Even if the splits aren’t absolutely perfect, they are often good enough to form a strong decision tree. Limiting Resource Waste: Efficient search heuristics and optimizations are used to reduce the exhaustive computational cost. In Random Forest: Choose $ m = \\sqrt{|x|} $ Features at Random Instead of evaluating all features for a potential split, a random subset of features is selected to reduce computation. The number of features selected ($ m $) is proportional to the square root of the total number of features ($ |x| $). This is a common technique in Random Forests to decorrelate individual decision trees and make the algorithm computationally efficient. It prevents overfitting by introducing randomness and limits the number of features under consideration at each node. Identify Candidate Splits for the Selected Feature $ x^{(i)} $ Feature Sorting: The feature values ($ x^{(i)} $) can be sorted to determine the best thresholds for splitting the dataset. Class Boundaries as Thresholds: The sorted feature values are evaluated to find boundaries between different classes. Sort Data Items According to Feature Value: All data points are sorted by their value for the feature $ x^{(i)} $. This allows easy identification of candidate split points. Adjacent Pairs in Different Classes: The algorithm looks for adjacent pairs of data points where one belongs to a different class than the other. This suggests a potential decision boundary. These pairs, $ (item_0, item_1) $, are identified since they may represent a significant change in class, making them good candidates for splitting. Threshold Midway Between $ item_0 $ and $ item_1 $: The threshold for the split is placed midway between these adjacent items from different classes. This ensures that the split captures the difference between the classes as effectively as possible. Randomly Select $ k $ Thresholds To further limit the number of potential splits to evaluate, the algorithm randomly selects $ k $ thresholds from the identified candidate thresholds. This further reduces computational cost while maintaining a good chance of finding an effective split. This random sampling balances computational efficiency with the quality of the splits, ensuring that the decision tree doesn’t become too computationally expensive. Summary The image explains a process that helps reduce the number of potential splits evaluated at each node: Random Subset of Features: Only a random $ m $ features are considered. Identifying Thresholds: For each selected feature, potential split thresholds are identified by analyzing class boundaries. Random Selection of Split Points: A random subset of the identified thresholds is evaluated. These steps are taken to avoid an exhaustive search, reduce computational resources, and prevent overfitting, particularly in Random Forests where multiple trees are built. Step-by-Step Explanation with Equations and Code Step 1: Choosing $ m = \\sqrt{|x|} $ Features at Random Suppose you have $ |x| $ features in your dataset. To decide the split, randomly select $ m $ features to evaluate, where: $$ m = \\sqrt{|x|} $$ Python Code Representation: import numpy as np# data from: https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database?resource=downloadimport pandas as pddata = pd.read_csv('/home/yiran/Downloads/diabetes.csv')features = d.columns[:-1]# Total number of featuresnum_features = len(features)# Choose m features at randomm = int(np.sqrt(num_features))selected_features = np.random.choice(features, m, replace=False) Step 2: Identify Candidate Splits for a Feature $ x^{(i)} $ For each feature selected, you need to determine possible thresholds to split the data. Steps in Code: Sort Feature Values: For the selected feature $ x^{(i)} $, sort the data points by their feature values. Identify Boundaries Between Classes: Find the pairs of data points that belong to different classes. Calculate candidate thresholds midway between these pairs. Equations for Finding Thresholds: Let $ x^{(i)}_j $ represent the feature value for data point $ j $. Sort all values of feature $ x^{(i)} $: $$ x^{(i)}_1, x^{(i)}_2, \\ldots, x^{(i)}_n \\quad \\text{where } x^{(i)}_1 &lt; x^{(i)}_2 &lt; \\ldots &lt; x^{(i)}_n $$ Identify the adjacent pairs that belong to different classes. For a pair of adjacent items $ (x^ {(i)}_ j, x^ {(i)}_ {j+1}) $ from different classes, the candidate threshold $ t_j $ is given by: $$ t_ j = \\frac{x^ {(i)}_ j + x^ {(i)}_ {j+1}}{2} $$ Python Code Representation: # Assume we have a data structure `data` which contains features and labels# We are focusing on the selected feature xidata = TB.T.to_dict()data = [data[i] for i in data]for feature in selected_features: # Sort data based on the selected feature's value sorted_data = sorted(data, key=lambda d: d[feature]) # Find candidate thresholds candidate_thresholds = [] for j in range(len(sorted_data) - 1): # If the class label changes between adjacent items if sorted_data[j]['Outcome'] != sorted_data[j + 1]['Outcome']: # Find the midpoint between two adjacent feature values threshold = (sorted_data[j][feature] + sorted_data[j + 1][feature]) / 2 candidate_thresholds.append(threshold) noteIn the code sorted_data = sorted(data, key=lambda d: d[feature]) feature_value_pairs = [(d, d[feature]) for d in data] # Step 2: Sort based on the feature value feature_value_pairs_sorted = sorted(feature_value_pairs, key=lambda pair: pair[1]) # Step 3: Extract the sorted data points sorted_data = [pair[0] for pair in feature_value_pairs_sorted] Step 3: Randomly Select $ k $ Thresholds Randomly pick $ k $ thresholds from the candidate thresholds identified in the previous step to reduce computation. Equation: Suppose $ T = { t_1, t_2, \\ldots, t_p } $ is the set of candidate thresholds. Select $ k $ thresholds randomly from $ T $: $$ T_{\\text{selected}} = { t_{i_1}, t_{i_2}, \\ldots, t_{i_k} }, \\quad \\text{where } i_j \\in {1, \\ldots, p} $$ Python Code Representation: some_predefined_k = 15# Number of thresholds to randomly selectk = min(len(candidate_thresholds), some_predefined_k)# Randomly select k thresholds from candidate_thresholdsselected_thresholds = np.random.choice(candidate_thresholds, k, replace=False) Step 4: Compute Information Gain for Each Split Iterate through the selected thresholds to compute the Information Gain and select the best one. Equation for Information Gain: For a given threshold $ t $, split the data into two subsets: $$ S_l = { x \\in S : x^{(i)} \\le t }, \\quad S_r = { x \\in S : x^{(i)} &gt; t } $$ Compute the weighted entropy after the split: $$ \\text{Entropy}_{\\text{after}} = \\frac{|S_l|}{|S|}\\text{Entropy}(S_l) + \\frac{|S_r|}{|S|}\\text{Entropy}(S_r) $$ Compute the Information Gain: $$ \\text{Information Gain} = \\text{Entropy}(S) - \\text{Entropy}_{\\text{after}} $$ Python Code Representation: def entropy(data): # Assume `data` has a function to calculate entropy labels = [d['Outcome'] for d in data] # Count the occurrences of each label label_counts = Counter(labels) total_count = len(data) # Calculate the entropy ent = 0 for count in label_counts.values(): # Calculate the probability of each label p = count / total_count # Add to entropy, using the formula -p * log2(p) if p &gt; 0: ent -= p * np.log2(p) return entbest_gain = -np.infbest_threshold = Nonefor threshold in selected_thresholds: # Split the data into left and right based on the threshold left_split = [d for d in sorted_data if d[feature] &lt;= threshold] right_split = [d for d in sorted_data if d[feature] &gt; threshold] # Calculate the weighted entropy of the two subsets p_left = len(left_split) / len(sorted_data) p_right = len(right_split) / len(sorted_data) entropy_after = p_left * entropy(left_split) + p_right * entropy(right_split) gain = entropy(sorted_data) - entropy_after # Update the best gain and threshold if gain &gt; best_gain: best_gain = gain best_threshold = threshold Summary Select Features Randomly: $ m = \\sqrt{|x|} $ features are selected randomly to evaluate. Determine Candidate Thresholds: For each feature, the data is sorted, and class boundaries are used to identify potential split points. Random Threshold Selection: From the candidate thresholds, a random subset is chosen to reduce computational cost. Calculate Information Gain: Evaluate the Information Gain for each threshold to find the best split. These steps ensure that the decision tree algorithm efficiently finds good splits without exhaustively considering all possible splits. The randomness helps reduce computational costs and enhances the model’s robustness, especially in Random Forests. Another Example Applied-Machine-Learning/ClassifyingImages.ipynb Quick ChatGPT example: # Step 1: Import Librariesfrom sklearn.ensemble import RandomForestClassifierfrom sklearn.datasets import load_irisfrom sklearn.model_selection import train_test_splitfrom sklearn.metrics import accuracy_score# Step 2: Load and Prepare Data# We'll use the Iris dataset as an exampleiris = load_iris()X, y = iris.data, iris.target# Split the data into training and test sets (80% train, 20% test)X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)# Step 3: Train the Random Forest Classifierclf = RandomForestClassifier(n_estimators=100, random_state=42) # 100 trees in the forestclf.fit(X_train, y_train)# Step 4: Make Predictions and Evaluatey_pred = clf.predict(X_test)# Calculate the accuracyaccuracy = accuracy_score(y_test, y_pred)print(f'Accuracy: {accuracy:.2f}') pre { background-color:#38393d; color: #5fd381; }","link":"/2024/09/29/AI/randomforest/"},{"title":"Softmax","text":"Softmax Key idea: $f_c(x) =$ posterior probability of cass $c$ A perceptron has a one-hot output vector, in which $f_c(x) = 1$ if the neural net thinks $c$ is the most likely value of $y$, and 0 otherwise A softmax computes $f_c(x) \\approx Pr(Y =c |x)$. The conditions for this to be true are: It needs to satisfy the axioms of probability: $$ 0 \\leq f_c(x) \\leq 1, \\quad \\sum_{c=1}^{v} f_c(x) = 1$$ The weight matrix, $W$, is trained using a loss function that encourages $f(x)$ to approximate posterior probability of the labels on some training dataset: $$f_c(x) \\approx \\Pr(Y = c|x)$$ Softmax satisfies the axioms of probability Axiom #1, probabilities are non-negative $(f_k(x) \\geq 0)$. There are many ways to do this, but one way that works is to choose: $$ f_c(x) \\propto \\exp(w_c^T x + b_c) $$ Axiom #2, probabilities should sum to one $(\\sum_{k=1}^{v} f_k(x) = 1)$. This can be done by normalizing: $$ f(x) = [f_1(x), …, f_v(x)]^T $$ $$ f_c(x) = \\frac{\\exp(w_c^T x + b_c)}{\\sum_{k=0}^{v-1} \\exp(w_k^T x + b_k)} $$ where $w_k^T$ is the $k^{th}$ row of the matrix $W$. The logistic sigmoid function For a two-class classifier, we don’t really need the vector label. If we define $w = w_2 - w_1$ and $b = b_2 - b_1$, then the softmax simplifies to: $$ f(Wx + b) = \\begin{bmatrix} \\text{Pr}(Y = 1|x) \\\\ \\text{Pr}(Y = 2|x) \\end{bmatrix} = \\begin{bmatrix} \\frac{1}{1+e^ {-(w^ Tx+b)}} \\\\ \\frac{e^ {-(w^ Tx+b)}}{1+e^ {-(w^ Tx+b)}} \\end{bmatrix} = \\begin{bmatrix} \\sigma(w^Tx + b) \\\\ 1 - \\sigma(w^Tx + b) \\end{bmatrix} $$ … so instead of the softmax, we use a scalar function called the logistic sigmoid function: $$ \\sigma(z) = \\frac{1}{1+e^{-z}} $$ This function is called sigmoid because it is S-shaped. For $z \\to -\\infty$, $\\sigma(z) \\to 0$ For $z \\to +\\infty$, $\\sigma(z) \\to 1$ Gradient descent Suppose we have training tokens $(x_i, y_i)$, and we have some initial class vectors $w_1$ and $w_2$. We want to update them as $$ w_1 \\leftarrow w_1 - \\eta \\frac{\\partial \\mathcal{L}}{\\partial w_1} $$ $$ w_2 \\leftarrow w_2 - \\eta \\frac{\\partial \\mathcal{L}}{\\partial w_2} $$ …where $\\mathcal{L}$ is some loss function. What loss function makes sense? Zero-one loss function The most obvious loss function for a classifier is its classification error rate, $$ \\mathcal{L} = \\frac{1}{n} \\sum_{i=1}^{n} \\ell(\\hat{f}(x_i), y_i) $$ Where $\\ell(\\hat{y}, y)$ is the zero-one loss function, $$ \\ell(f(x), y) = \\begin{cases} 0 &amp; \\text{if } f(x) = y \\\\ 1 &amp; \\text{if } f(x) \\neq y \\end{cases} $$ The problem with zero-one loss is that it’s not differentiable. A loss function that learns probabilities Suppose we have a softmax output, so we want $f_c(x) \\approx \\Pr(Y = c|x)$. We can train this by learning $W$ and $b$ to maximize the probability of the training corpus. If we assume all training tokens are independent, we get: $$ W, b = \\underset{W,b}{\\text{argmax}} \\prod_{i=1}^{n} \\Pr(Y = y_i|x_i) = \\underset{W,b}{\\text{argmax}} \\sum_{i=1}^{n} \\ln \\Pr(Y = y_i|x_i) $$ But remember that $f_c(x) \\approx \\Pr(Y = c|x)$! Therefore, maximizing the log probability of training data is the same as minimizing the cross entropy between the neural net and the ground truth: $$ W, b = \\underset{W,b}{\\text{argmin}} -\\frac{1}{n} \\sum_{i=1}^{n} \\mathcal{L}_ i, \\quad \\mathcal{L}_ i = - \\log f_ {y_ i}(x_ i) $$ Cross-entropy This loss function: $$ \\mathcal{L} = - \\ln f_{y}(x) $$ is called cross-entropy. It measures the difference in randomness between: Truth: $Y = y$ with probability 1.0, $\\ln(1.0) = 0$, minus the Neural net estimate: $Y = y$ with probability $f_{y}(x)$. Thus $$ \\mathcal{L} = 0 - \\ln f_{y}(x) $$ Gradient of the cross-entropy of the softmax Since we have these definitions: $$ \\mathcal{L} = - \\ln f_{y}(x), \\quad f_{y}(x) = \\frac{\\exp(z_{y})}{\\sum_{k=1}^{v} \\exp(z_{k})}, \\quad z_{c} = w_c^T x + b_c $$ Then: $$ \\frac{\\partial \\mathcal{L}}{\\partial w_c} = \\left( \\frac{\\partial \\mathcal{L}}{\\partial z_c} \\right) \\left( \\frac{\\partial z_c}{\\partial w_c} \\right) = \\left( \\frac{\\partial \\mathcal{L}}{\\partial z_c} \\right) x $$ …where: $$ \\frac{\\partial \\mathcal{L}}{\\partial z_c} = \\begin{cases} f_{c}(x_i) - 1 &amp; c = y \\\\ f_{c}(x_i) &amp; c \\neq y \\end{cases} $$ Similarity to linear regression For linear regression, we had: $$ \\frac{\\partial \\mathcal{L}}{\\partial w} = \\epsilon x, \\quad \\epsilon = f(x) - y $$ For the softmax classifier with cross-entropy loss, we have $$ \\frac{\\partial \\mathcal{L}}{\\partial w_c} = \\epsilon_c x $$ $$ \\epsilon_c = \\begin{cases} f_c(x_i) - 1 &amp; c = y \\text{ (output should be 1)} \\\\ f_c(x_i) &amp; \\text{otherwise (output should be 0)} \\end{cases} $$ Similarity to perceptron Suppose we have a training token $(x, y)$, and we have some initial class vectors $w_c$. Using softmax and cross-entropy loss, we can update the weight vectors as $$ w_c \\leftarrow w_c - \\eta \\epsilon_c x $$ …where $$ \\epsilon_c = \\begin{cases} f_c(x_i) - 1 &amp; c = y_i \\\\ f_c(x_i) &amp; \\text{otherwise} \\end{cases} $$ In other words, like a perceptron, $$ \\epsilon_c = \\begin{cases} \\epsilon_c &lt; 0 &amp; c = y_i \\\\ \\epsilon_c &gt; 0 &amp; \\text{otherwise} \\end{cases} $$ Outline Softmax: $$ f_c(x) = \\frac{\\exp(w_c^T x + b_c)}{\\sum_{k=1}^{v} \\exp(w_k^T x + b_k)} \\approx \\Pr(Y = c|x) $$ Cross-entropy: $$ \\mathcal{L} = - \\ln f_{y}(x) $$ Derivative of the cross-entropy of a softmax: $$ \\frac{\\partial \\mathcal{L}}{\\partial w_c} = \\epsilon_c x, \\quad \\epsilon_c = \\begin{cases} f_c(x_i) - 1 &amp; c = y \\text{ (output should be 1)} \\\\ f_c(x_i) &amp; \\text{otherwise (output should be 0)} \\end{cases} $$ Gradient descent: $$ w_c \\leftarrow w_c - \\eta \\epsilon_c x $$ pre { background-color:#38393d; color: #5fd381; }","link":"/2024/10/09/AI/softmax/"},{"title":"Protein Dock Overview","text":"Physical Based Docking 1982: Dock; Kuntz, Irwin D., et al.[1] (Rigid body-shape based) © Kuntz, Irwin D., et al. 1982[1:1] In this paper, Kuntz present a way of docking prediction by searching the steric overlap based on the knowing surface structure of 2 proteins. It originally developed by Irwin “Tack” Kuntz and colleagues at the University of California, San Francisco (UCSF), DOCK was initially used for small-molecule docking. However, it laid the foundation for the development of more advanced docking algorithms and software that could handle macromolecular docking. In the first generation of the Dock, it focus on 2 rigid bodies. It treat 2 proteins as one object. The goal of this program is to fix the 6 degree of freedom (3 transitions and 3 orientations) that determine the best relative position. For achieving this goal, three rules are followed: No overlap between 2 proteins all hydrogen are pared with N or O within 3.5 Å. all ligand atoms within the receptor binding cite. Dock families: 1994: Firstly extend the DOCK into DNA-protein Docking and by screening the Cambridge Crystallographic Database, they find that the protein CC-1065 has high score.[2] 1999: DREAM++[3]: It is a extent package for Dock. It use Dock to predict binding and evaluated the interaction and predicts the product, finally search to find the prohibits. 2001: DOCK 4.0[4]: It added incremental construction (to sample the internal degrees of freedom of the ligand) and random search. In the Dock4, the ligand is not rigid anymore. Ligands with rotatable-bonds generated multiple conformation by other model. 2006: DOCK 5.0[5]: anchoring: new scoring functions, sampling methods and analysis tools; energy minimizing was mentioned during the. scoring: energy scoring function based on the AMBERL: only intermolecular van der Waals (VDW) and electrostatic components in the function. main limitation: Ligands has lots of rotatable-bonds would cause lots of resource. During the test set, ligands with &gt; 7 rotatable bonds were removed. Some test data correction: using “Compute” and “Biopolymer” from Sybyl[6] to calculate the Gasteiger–Hückel partial electrostatic charges and add hydrogen for residues. 2009: DOCK 6[7]: In this version, it extents it’s abilities in RNA-ligands. But the rotatable-bonds from the ligands are still limited into 7~13. With the increasing of the RNA, the accuracy are decreased. update scoring in solvation energy: Hawkins–Cramer–Truhlar (HCT) generalized Born with solvent-accessible surface area (GB/SA) solvation scoring with optional salt screening Poisson–Boltzmann with solvent-accessible surface area (PB/SA) solvation scoring AMBER molecular mechanics with GB/SA solvation scoring and optional receptor flexibility other scoring: VDW: grid-based form of the Lennard-Jones potential electrostatic: Zap Tool Kit from OpenEye 2013: DOCK3.7[8]: DOCK4 DOCK5 DOCK6 incremental: anchor-and-grow The number ofrotatable-bonds hashugeeffects on success rate anchor-and-grow The “anchor-and-grow” conformational search algorithm. The algorithm performs the following steps: (1) DOCK perceives the molecule’s rotatable bonds, which it uses to identify an anchor segment and overlapping rigid layer segments. (2) Rigid docking is used to generate multiple poses of the anchor within the receptor. (3) The first layer atoms are added to each anchor pose, and multiple conformations of the layer 1 atoms are generated. An energy score within the context of the receptor is computed for each conformation. (4) The partially grown conformations are ranked by their score and are spatially clustered. The least energetically favorable and spatially diverse conformations are discarded. (5) The next rigid layer is added to each remaining conformation, generating a new set of conformations. (6) Once all layers have been added, the set of completely grown conformations and orientations is returned Compare to Other Related Tools MethodLigand sampling methoda Receptor sampling methoda Scoring functionb Solvation scoringc,d DOCK 4/5 ICSEMMDDD, GB, PBFlexX/FlexE ICSEEDNAGlideCE&nbsp;+&nbsp;MCTSMM&nbsp;+&nbsp;EDDSGOLD GAGAMM&nbsp;+&nbsp;EDNA aSampling methods are defined as Genetic Algorithm (GA), Conformational Expansion (CE), Monte Carlo (MC), incremental construction (IC), merged target structure ensemble (SE), torsional search (TS) bScoring functions are defined as either empirically derived (ED) or based on molecule mechanics (MM) cIf the package does not accommodate this option, the symbol NA (Not Available) is used dAdditional accuracy can be added to the scoring function using implicit solvent models. The most commonly used options are distance dependent dielectric (DDD), a parameterized desolvation term (DS), generalized Born (GB) and linearized Poisson Boltzmann (PB) 2003: ZDock Version iteration: ZDOCK 2.3/2.3.2 Scoring Function: Chen R, Li L, Weng Z. (2003) ZDOCK[9] ZDOCK 3.0/3.0.2 Scoring Function: Mintseris J, Pierce B, Wiehe K, Anderson R, Chen R, Weng Z. (2007)[10] M-ZDOCK: Pierce B, Tong W, Weng Z. (2005) M-ZDOCK[11] ZDOCK 3.0.2/2.3.2: Pierce BG, Hourai Y, Weng Z. (2011)[12] Online Server: Pierce BG, Wiehe K, Hwang H, Kim BH, Vreven T, Weng Z. (2014) ZDOCK Server[13] Abstract ZDock was developed for ubbound docking. It is based on pairwise shape complementarity (Docking) with desolvation and electrostatics (Scoring). In there test, it shows high success rate in the antibody-antigen docking test case. It is especially helpful in “large concave binding pocket”. Before the ZDock, there are: FTDOck: gird-based shape complementarity (GSC) and electrostatic using a Fast Fourier Transform (FFT) DOT: FFT-based computes Poission-Bolzmann electrostatics. HEX: evaluates overlapping surface skins and electrostatic complementarity with Fourier coorelation. GRAMM: low-resolutoin docking with the similar scoring as FTDOck; PPD: matches critial poitns by using geometric hashing. GIGGER: maximal surface mapping and favorable amino acid contacts by bit-mapping. DARWIN: molecular mechanics energy defined according to CHARMM. For ZDock: Optimizes desolvation (GSC), key scoring function. GSC = grid points surrounding the receptor corresponding to ligand atoms - clash penalty *FFT for electrostatics Novel pairwise shape complementarity function (PSC) by distance cut-off of receptor-ligand atom minus clash penalty. Favorable: Number of pair within cutoff Penalty: The clash penalty for core-core, surface-core, and surface-surface (99, 93, 9) DE: desolvation, estimated by atomic contact energy (ACE), which is a free energy change of breaking two protein atom-water contacts and forming a protein atom-protein atom contact and water-water contact. The sum of ACE is DE Version for scoring functions: ZDOCK1.3[14]: GSC+DE+ELEC ZDOCK2.1[15]: PSC ZDOCK2.2[9:1]: PSC+DE ZDOCK2.3[9:2]: PSC+DE+ELEC 2004: ClusPro ClusPro: a fully automated algorithm for protein–protein docking 2010: Hex Ultra-fast FFT protein docking on graphics processors Home page, Documentation Hex is extremely fast but lack of accuracy. I tried to sampling over 100,1000 but results even close to native structure. On the other hand, I didn’t find a way to mark the surface residues so we could focus on specific area. Although, GhatGPT said it could do constrained docking, but it seems we could only constrain the range angles of the receptor and the ligand. © SAMSON 2014: rDock rDock: a fast, versatile and open source program for docking ligands to proteins and nucleic acids 2018: InterEvDock Protein-Protein Docking Using Evolutionary Information Machine Learning Based Docking 2021: DeepRank Model Grpah Abstract Model Name © Chen, M., &amp; Zhou, X DeepRank © Réau, M. DeepRank-GNN © Crocioni, G. Deeprank2 DeepRank[16] is a open source framework designed to analyze 3D protein-protein interfaces by using deep learning to capture spatial and biochemical features. The paper presents DeepRank’s approach to transforming 3D structural data into 3D grids that a neural network can process. This setup allows DeepRank to identify interaction patterns, rank docking models, and predict binding affinities with high accuracy. It’s especially useful for discovering patterns in protein interfaces that might be overlooked with traditional scoring functions. In this model, it turn the pdb into sql for efficient processing. The interfacing residues cut-off is 5.5 Å. When find all interfacing atoms, they would be mapped into **3D grid using a Gaussian mapping. The target value is very flexible, too. You can using any kind of values, iRMSD, FNAT, or DockQ score for instance, as the target values (Predicted value). The data was stored as hdf5 format which keep the efficiency and small storage size. DeepRank family: DeepRank[16:1]: 2021, Chen, M., et al.; It mapped the protein interfacing into a 3D grid and using CNN to train the regression model. It established the foundation of the architectural of DeepRank. In the DeepRank, it use information both from atom-level and residue-level. From the atom level, it calculates the atom density, charges, electrostatic energy, and VDW contacts. In residue-level, it included number of residue-residue contacts, buried surface area, and Position specific scoring matrix (PSSM) DeepRank-GNN[17]: 2023, Réau, M. et al.; from the same team replace the 3D grid based CNN into GNN which could avoid rotation challenge in 3D grid. The input information is very similar to the DeepRank. Instead of 3D grid, it relies on the adjacent matrix to build the network. In this time, the cut-off became 8.5 Å. It has more rich features like Distance, residue half sphere exposure, Residue depth (from biopython, MSMS) Deeprank_GNN_ESM[18]: 2024, Xu, X., et al.; The PSSM calculating requires sequence alignment which consumes lots of time. For generate the graph efficiently, they replaced the PSSM with ESM embedding vectors. DeepRank2[19]: 2024, Crocioni, G., et al.; In the DeepRank2., it supports both 3D grid and graph network as inputs. It also integrated the Deep-Mut to do in silicon mutation screening. pre { background-color:#38393d; color: #5fd381; } Kuntz I D, Blaney J M, Oatley S J, et al. A geometric approach to macromolecule-ligand interactions[J]. Journal of molecular biology, 1982, 161(2): 269-288. ↩︎ ↩︎ Grootenhuis P D J, Roe D C, Kollman P A, et al. Finding potential DNA-binding compounds by using molecular shape[J]. Journal of Computer-Aided Molecular Design, 1994, 8: 731-750. ↩︎ Makino S, Ewing T J A, Kuntz I D. DREAM++: flexible docking program for virtual combinatorial libraries[J]. Journal of computer-aided molecular design, 1999, 13: 513-532. ↩︎ Ewing T J A, Makino S, Skillman A G, et al. DOCK 4.0: search strategies for automated molecular docking of flexible molecule databases[J]. Journal of computer-aided molecular design, 2001, 15: 411-428. ↩︎ Moustakas D T, Lang P T, Pegg S, et al. Development and validation of a modular, extensible docking program: DOCK 5[J]. Journal of computer-aided molecular design, 2006, 20: 601-619. ↩︎ S. Pérez, C. Meyer, A. Imberty. “Practical tools for accurate modeling of complex carbohydrates and their interactions with proteins” A. Pullman, J. Jortner, B. Pullman (Eds.), Modelling of Biomolecular Structures and Mechanisms, Kluwer Academic Publishers, Dordrecht (1996), pp. 425-454. ↩︎ Lang P T, Brozell S R, Mukherjee S, et al. DOCK 6: Combining techniques to model RNA–small molecule complexes[J]. Rna, 2009, 15(6): 1219-1230. ↩︎ Coleman R G, Carchia M, Sterling T, et al. Ligand pose and orientational sampling in molecular docking[J]. PloS one, 2013, 8(10): e75992. ↩︎ Chen, R., Li, L., &amp; Weng, Z. (2003). ZDOCK: an initial‐stage protein‐docking algorithm. Proteins: Structure, Function, and Bioinformatics, 52(1), 80-87. ↩︎ ↩︎ ↩︎ Mintseris, J., Pierce, B., Wiehe, K., Anderson, R., Chen, R., &amp; Weng, Z. (2007). Integrating statistical pair potentials into protein complex prediction. Proteins: Structure, Function, and Bioinformatics, 69(3), 511-520. ↩︎ Pierce, B., Tong, W., &amp; Weng, Z. (2005). M-ZDOCK: a grid-based approach for C n symmetric multimer docking. Bioinformatics, 21(8), 1472-1478. ↩︎ Pierce, B. G., Hourai, Y., &amp; Weng, Z. (2011). Accelerating protein docking in ZDOCK using an advanced 3D convolution library. PloS one, 6(9), e24657. ↩︎ Pierce, B. G., Wiehe, K., Hwang, H., Kim, B. H., Vreven, T., &amp; Weng, Z. (2014). ZDOCK server: interactive docking prediction of protein–protein complexes and symmetric multimers. Bioinformatics, 30(12), 1771-1773. ↩︎ Chen R, Weng Z. Docking unbound proteins using shape complementarity, desolvation, and electrostatics. Proteins 2002; 47: 281–294. ↩︎ Chen R, Weng Z. A novel shape complementarity scoring function for protein-protein docking. Proteins 2003; 51: 397–408. ↩︎ Renaud, N., Geng, C., Georgievska, S., Ambrosetti, F., Ridder, L., Marzella, D. F., … &amp; Xue, L. C. (2021). DeepRank: a deep learning framework for data mining 3D protein-protein interfaces. Nature communications, 12(1), 7068. ↩︎ ↩︎ Réau, M., Renaud, N., Xue, L. C., &amp; Bonvin, A. M. (2023). DeepRank-GNN: a graph neural network framework to learn patterns in protein–protein interfaces. Bioinformatics, 39(1), btac759. ↩︎ Xu, X., &amp; Bonvin, A. M. (2024). DeepRank-GNN-esm: a graph neural network for scoring protein–protein models using protein language model. Bioinformatics advances, 4(1), vbad191. ↩︎ Crocioni, G., Bodor, D. L., Baakman, C., Parizi, F. M., Rademaker, D. T., Ramakrishnan, G., … &amp; Xue, L. C. (2024). DeepRank2: Mining 3D Protein Structures with Geometric Deep Learning. Journal of Open Source Software, 9(94), 5983. ↩︎","link":"/2024/10/15/AI/proteindock/"},{"title":"NCBI Data Submit with FTP&#x2F;ASCP","text":"This post only talks about how to use the ascp to upload your sequencing data into NCBI. 3 Different Ways of Submit Your Data Cloud from Amazon S3 or Google Cloud If your data was stored in Amazon/Google Cloud at the beginning, you can easily and safely transfer them into NCBI. (I think so though I’ve never tried). FTP or ASCP I would recommend the second approach since our data was mostly stored in a Linux server. FTP and ASCP are very reliable. Especially for ftp, it is a very popular protocol. You could find a bunch of software like ‘FileZilla’ to upload through ftp. The best feature of ‘FileZilla’ is it supports resume interrupted transfer and lists the fail-up loaded files so you can upload them again with one click. So, no matter how many and how big the files are, it can help you upload them safely. The main limitation for FileZilla is that it can’t used in command form and so, is not suitable for the server. Web Browser Unless your data are very small, you would never want to try uploading them online. When to Upload Your Data You can upload your data whenever you want. It is better to upload your file before you start to fill the submission tables. In step 7, you could find the data/director you submitted and include them in the submission. But it seems like the NCBI would delete an inactivated file within 30 days. It is long enough to finish the submission. I prefer to use FileZilla to upload my data. But since now, all of my data are on the server and I don’t want to download them again, I give the ftp and use ascp. How to use the ASCP ASCP is very easy and works similarly to scp. In the Submission home page, select My submissions → Upload via Aspera command line or FTP → Aspera command line instructions to find the instructions. It would give you the download link and key for connecting to the NCBI server. After that, use it just like the scp. Shortcomings or suggestions for ascp Keep everything in 1 director: You’d like to upload all files into one directory. Because during the submission step 7 FILES, you could only select 1 directory. No sub-directories: You may want to upload the directory without subdirectories. Because in the submission portal, you can’t check files in subdirectories. So, it is hard to track back which filed upload failed. Keep ascp log: In the submission portal, you got only first 5 lines of uploaded files. So, remember to keep the ascp log to record the fail uploaded data. upload the data one by one: Strongly recommend to upload each fq or compressed file one by one with scripts. When you try to upload the entire directory, it may fail (I never get it done when upload a directory) After you upload your data, you can’t see them until you go to step 7 FILES in the submission portal. You can’t check them immediately even from the submission portal. It takes time for them to show in the Step 7 The good thing is it is easy to write a script to upload your data automatically. In the instructions, it suggest you to use those parameters: `-QT -l100m -k1` -Q: This option disables the real-time display of progress and transfer statistics during the transfer. Normally, ASCP displays ongoing statistics, such as speed and percentage of completion, but using -Q will suppress this output. -T: This option disables encryption of the data stream during transfer. ASCP by default uses encryption for data security, but -T turns this off, which might improve transfer speed but at the cost of security. -l100m: This sets the transfer speed limit to 100 megabits per second. You can adjust the value (e.g., 100m) to control how fast the transfer is allowed to go, helping to prevent network congestion or manage bandwidth usage. -k1: This option controls file resume behavior. The value 1 means that if a transfer is interrupted, ASCP will resume from the point where it left off (resumable transfer). The other possible values for -k are: 0: No resume. The transfer restarts from the beginning. 2: Sparse resume. ASCP resumes only the missing parts of the file. Personal Experience Upload your data into a specific directory Though we gave the argument -k1, it could still fail. In the log, it says: Partial Completion: 19711732K bytes transferred in 3695 seconds (43691K bits/sec), in 6 files, 4 directories; 3 files failed. Session Stop (Error: Disk write failed (server)) After you went to the step 7, you could see: Which means 2 directories are empty. In this case, you don’t need to worry too much. You can change the code a little bit and continue to upload could solve this problem. For example, you uploaded a directory named ALL_RNA with code ascp -i $key_file -QT -l100m -k1 -d ALL_RNA $AddressFromInstruction, the data in the directory ALL_RNA/SAMPLEX was failed to upload, you can use the code ascp -i $key_file -QT -l100m -k1 -d ALL_RNA/SAMPLEX $AddressFromInstruction/ALL_RNA to continue upload the directory SAMPLEX into the ALL_RNA in NCBI server ascp -i $key_file -QT -l100m -k1 -d ALL_RNA $AddressFromInstruction ascp -i $key_file -QT -l100m -k1 -d ALL_RNA/SAMPLEX $AddressFromInstruction/ALL_RNA Upload your date in the script When you have lots of data, one of the convenient ways I found is we could ascp each data independently. With a for loop, we could generate all codes into a script. When there are failed uploads, we just need to copy and paste the failed codes and run them again. Or we could also delete the code for the successfully uploaded one and run the entire script again. for i in $(find YourDirectories -name &quot;.fastq.gz&quot;); do echo ascp -i $key_file -QT -l100m -k1 -d $i $AddressFromInstructiondone &gt;&gt; ascp.shbash ascp.sh pre { background-color:#38393d; color: #5fd381; }","link":"/2024/10/17/Bioinfor/ncbisubmit/"},{"title":"Render Your Protein in Blender with Molecular Nodes","text":"Who to Install Molecular Nodes for Blender First, you should download Blender yourself. Instead of the latest version, opt for a stable version because the newest release may have bugs or be incompatible with Molecular Nodes. I tried version 4.40, but when I changed the style of the molecule to Ribbon or another style, Blender crashed and closed itself. Then, I switched to version 4.2.2, and it worked fine. As following the figure “Install the Extension”, you can find this plugin and install it. Once you down installation, you can find there is some thing new pops up like its show in figure “Update in Scene”. In this new module, you could download the pdb online or when you have pdb in the “Cache Downloads” directory, you could also load it with “Molecular Nodes”. When you load the molecular, it looks terrible. You need to follow the figure “Render By Cycles” and “Start Render” to get a normal view of molecular(“Atoms View”). Add a Pure Perfect Background Source: YouTube: EMPossible How to set: select “Render” → “Film” → “Transparent”“Render” → “Color Management” → “View Transform” → “Starndard” Set the Compositing. And that’s it. Go to rendering and it woud add an Perfectwhite at the background # codes for set a pure white background# Those codes only working on the first few steps.# I didn't figure how to use script to make the Geometry Nodes # So, After you run those 3 commands, you still need to started from step 3 in the second pictures to manually finish the Geometry Nodes setting.bpy.context.scene.render.engine = 'CYCLES'bpy.context.scene.cycles.device = 'GPU'bpy.context.space_data.shading.type = 'RENDERED'bpy.context.object.scale[0] = 3.5bpy.context.object.scale[1] = 3.5bpy.context.object.scale[2] = 3.5bpy.context.scene.render.film_transparent = Truebpy.context.scene.view_settings.view_transform = 'Standard'bpy.context.scene.use_nodes = True Different Colors in a Surface The key idea for given different color is by rendern multiple layers of color on the surface. By reverse select residues , we could delete the colors from selected layer and expose the color from inner layer. Final resutls show Multiple Style in One Object Like the example in the picture, it rendered both surface model and the stick model in one object. This is achieved by Join Geometry Customize the Color From The Surface For Customizing the surface color, there are 2 ways to do it. using pLDDT nodes from Color using the Color Attribute Map nodes from Color. In both case, they are actually using the same set of value stored in pdb or cif file. In the pdb format show below, the 11th column marked as white is the value for pLDDT. If you want to manage it with Color Attribute Map, the name of it is b_factor ATOM 4365 C ASP C 150 17.854 27.766 83.090 1.00 99.42 C C ATOM 4366 O ASP C 150 17.369 28.239 82.038 1.00 95.32 C O ATOM 4367 CB ASP C 150 19.712 26.091 82.521 1.00 98.18 C C ATOM 4368 CG ASP C 150 20.447 24.817 82.987 1.00 96.59 C C ATOM 4369 OD1 ASP C 150 20.121 24.255 84.056 1.00 96.78 C O ATOM 4370 OD2 ASP C 150 21.402 24.406 82.277 1.00 96.06 C O1- ATOM 4371 OXT ASP C 150 18.041 28.393 84.184 1.00 95.18 C O1- Watching List Select color pallet Trouble Shoot Dead Black in Transparent Dead Black Change Setting After Change pre { background-color:#38393d; color: #5fd381; }","link":"/2024/10/19/Bioinfor/blender-molecular-nodes/"},{"title":"HDF5 Data Format Introduction","text":"Structure of hdf5 Key Features of HDF5: Hierarchical Structure: HDF5 files are organized like a file system, with “groups” that act like directories and “datasets” that act like files. This allows for complex, hierarchical data storage. Efficient Storage: HDF5 is optimized for storing and retrieving large datasets. It uses compression techniques (like GZIP or SZIP) to reduce file size without losing data. Cross-platform Compatibility: The format is portable across different platforms and operating systems, meaning that HDF5 files can be used on Windows, macOS, Linux, etc. Self-describing Format: HDF5 files include metadata that describe the contents of the file. This makes it easy to understand the data structure without additional documentation. Multidimensional Data: HDF5 supports storing complex, multidimensional data (such as arrays, tables, images, etc.). Supports Many Data Types: It can store data in various types, such as integers, floats, strings, and more. /root (Group) /experiment1 (Group) /data (Dataset) /info (Dataset) /experiment2 (Group) /data (Dataset) /info (Dataset) Use Cases: Scientific Data: For example, storing results from simulations, satellite data, or genome sequences. Machine Learning: Large training datasets can be stored in HDF5 format for efficient access during training. Image Storage: Storing large collections of images or medical imaging data (e.g., MRI scans). Show all Names of Groups and Data import h5py# Open the file in read modewith h5py.File('file1.h5', 'r') as f: def print_hdf5_structure(group, indent=0): for key in group.keys(): item = group[key] print(&quot; &quot; * indent + f&quot;{key}: {type(item)}&quot;) if isinstance(item, h5py.Group): print_hdf5_structure(item, indent + 1) # Print structure from the root print_hdf5_structure(f) How to Merge Multiple hdf5 Files import h5pyimport numpy as np# Function to recursively copy/merge the structure and data from source_group to target_groupdef copy_and_merge(source_group, target_group): for key in source_group.keys(): item = source_group[key] # If the item is a group, we create the same group in the target and copy its contents if isinstance(item, h5py.Group): if key not in target_group: target_group.create_group(key) copy_and_merge(item, target_group[key]) # Recursive call to merge the group's contents # If the item is a dataset, we merge it elif isinstance(item, h5py.Dataset): # If the dataset doesn't exist in the target file, copy it if key not in target_group: target_group.create_dataset(key, data=item[:]) # If the dataset exists, concatenate the data along the first axis else: existing_data = target_group[key][:] new_data = item[:] # Concatenate datasets along the first axis merged_data = np.concatenate((existing_data, new_data), axis=0) # Delete the old dataset and replace it with the merged one del target_group[key] target_group.create_dataset(key, data=merged_data)# Function to merge multiple HDF5 files and save the result to a new filedef merge_multiple_hdf5(files, output_file): # Create a new HDF5 file to store the merged result with h5py.File(output_file, 'w') as target_file: for file in files: with h5py.File(file, 'r') as source_file: # Merge the contents of each source file into the target file copy_and_merge(source_file, target_file) print(f&quot;All files have been merged into {output_file}&quot;)# List of HDF5 files to be mergedfiles_to_merge = ['file1.h5', 'file2.h5', 'file3.h5'] # Add as many files as needed# Specify the output file where the merged data will be savedoutput_file = 'merged_output.h5'# Merge the files and save the resultmerge_multiple_hdf5(files_to_merge, output_file) Explanation of the Code: copy_and_merge function remains the same, recursively merging groups and datasets from the source to the target. merge_multiple_hdf5 function: Accepts a list of HDF5 files (files) and an output_file name. It creates a new HDF5 file (output_file) in write mode ('w'). It loops through each file in the list, opens it in read mode ('r'), and calls the copy_and_merge function to copy the contents into the newly created file. After all files are merged, it saves the result as output_file. !!! note Key Points: - Each dataset is merged by concatenating along the first axis. If you need to merge along a different axis or have more complex merging rules, we can adjust the code. - Make sure the datasets you’re merging are compatible (same dimensionality along non-concatenated axes). Change the Group Names To rename a group in an HDF5 file using h5py, you can’t directly change the group’s name. Instead, you can copy the group to a new group with the desired name, and then delete the original group. Here’s how you can rename the group “4skj” to “4skj_10086”: Step-by-Step Code: import h5pyimport shutil# Function to rename a group in an HDF5 filedef rename_group(hdf5_file, old_group_name, new_group_name): # Open the file in read/write mode with h5py.File(hdf5_file, 'r+') as f: # Check if the group exists if old_group_name in f: # Copy the old group to the new group f.copy(old_group_name, new_group_name) # Delete the old group del f[old_group_name] print(f&quot;Group '{old_group_name}' has been renamed to '{new_group_name}'&quot;) else: print(f&quot;Group '{old_group_name}' does not exist in the file.&quot;)# Rename the group in the HDF5 filehdf5_file = 'file1.h5' # Replace with your actual file pathold_group_name = '4skj' # Original group namenew_group_name = '4skj_10086' # New group namerename_group(hdf5_file, old_group_name, new_group_name) Check if the group exists: The script checks if the group &quot;4skj&quot; exists in the HDF5 file. Copy the group: It uses the f.copy() function to copy the group and its contents to a new group with the desired name (&quot;4skj_10086&quot;). Delete the old group: After copying, the original group is deleted with del f[old_group_name]. Save changes: Since the file is opened in 'r+' mode (read/write), all changes are saved automatically. pre { background-color:#38393d; color: #5fd381; }","link":"/2024/10/23/AI/hdf5/"}],"tags":[{"name":"Math","slug":"Math","link":"/tags/Math/"},{"name":"Algorithm","slug":"Algorithm","link":"/tags/Algorithm/"},{"name":"Machine Learning","slug":"Machine-Learning","link":"/tags/Machine-Learning/"},{"name":"Data Science","slug":"Data-Science","link":"/tags/Data-Science/"},{"name":"AI","slug":"AI","link":"/tags/AI/"},{"name":"3D","slug":"3D","link":"/tags/3D/"},{"name":"Protein Structure","slug":"Protein-Structure","link":"/tags/Protein-Structure/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"Software","slug":"Software","link":"/tags/Software/"},{"name":"Bioinformatics","slug":"Bioinformatics","link":"/tags/Bioinformatics/"},{"name":"NGS","slug":"NGS","link":"/tags/NGS/"},{"name":"ATAC-Seq","slug":"ATAC-Seq","link":"/tags/ATAC-Seq/"},{"name":"R","slug":"R","link":"/tags/R/"},{"name":"Biology","slug":"Biology","link":"/tags/Biology/"},{"name":"Cell","slug":"Cell","link":"/tags/Cell/"},{"name":"Wet","slug":"Wet","link":"/tags/Wet/"},{"name":"Database","slug":"Database","link":"/tags/Database/"},{"name":"Genome","slug":"Genome","link":"/tags/Genome/"},{"name":"Protocol","slug":"Protocol","link":"/tags/Protocol/"},{"name":"GO","slug":"GO","link":"/tags/GO/"},{"name":"Chip-Seq","slug":"Chip-Seq","link":"/tags/Chip-Seq/"},{"name":"Antibody","slug":"Antibody","link":"/tags/Antibody/"},{"name":"Immunology","slug":"Immunology","link":"/tags/Immunology/"},{"name":"WGS","slug":"WGS","link":"/tags/WGS/"},{"name":"Statistic","slug":"Statistic","link":"/tags/Statistic/"},{"name":"MateGenome","slug":"MateGenome","link":"/tags/MateGenome/"},{"name":"SNP","slug":"SNP","link":"/tags/SNP/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"PacBio","slug":"PacBio","link":"/tags/PacBio/"},{"name":"RNA-Seq","slug":"RNA-Seq","link":"/tags/RNA-Seq/"},{"name":"Translation","slug":"Translation","link":"/tags/Translation/"},{"name":"Bioinformatic","slug":"Bioinformatic","link":"/tags/Bioinformatic/"},{"name":"Protein","slug":"Protein","link":"/tags/Protein/"},{"name":"api","slug":"api","link":"/tags/api/"},{"name":"WGCNA","slug":"WGCNA","link":"/tags/WGCNA/"},{"name":"Trinity","slug":"Trinity","link":"/tags/Trinity/"},{"name":"Scripts","slug":"Scripts","link":"/tags/Scripts/"},{"name":"Biopython","slug":"Biopython","link":"/tags/Biopython/"},{"name":"Align","slug":"Align","link":"/tags/Align/"},{"name":"Image","slug":"Image","link":"/tags/Image/"},{"name":"Cluster","slug":"Cluster","link":"/tags/Cluster/"},{"name":"QC","slug":"QC","link":"/tags/QC/"},{"name":"Fasta","slug":"Fasta","link":"/tags/Fasta/"},{"name":"VCF","slug":"VCF","link":"/tags/VCF/"},{"name":"blast","slug":"blast","link":"/tags/blast/"},{"name":"Mysql","slug":"Mysql","link":"/tags/Mysql/"},{"name":"KEGG","slug":"KEGG","link":"/tags/KEGG/"},{"name":"miRNA-Seq","slug":"miRNA-Seq","link":"/tags/miRNA-Seq/"},{"name":"Pyvista","slug":"Pyvista","link":"/tags/Pyvista/"},{"name":"PyMol","slug":"PyMol","link":"/tags/PyMol/"},{"name":"Proteomic","slug":"Proteomic","link":"/tags/Proteomic/"},{"name":"Sanger Sequencing","slug":"Sanger-Sequencing","link":"/tags/Sanger-Sequencing/"},{"name":"scRNA-Seq","slug":"scRNA-Seq","link":"/tags/scRNA-Seq/"},{"name":"scATAC-Seq","slug":"scATAC-Seq","link":"/tags/scATAC-Seq/"},{"name":"Sequencing","slug":"Sequencing","link":"/tags/Sequencing/"},{"name":"GATK","slug":"GATK","link":"/tags/GATK/"},{"name":"TCGA","slug":"TCGA","link":"/tags/TCGA/"},{"name":"API","slug":"API","link":"/tags/API/"},{"name":"Web","slug":"Web","link":"/tags/Web/"},{"name":"BiliBili","slug":"BiliBili","link":"/tags/BiliBili/"},{"name":"Plot","slug":"Plot","link":"/tags/Plot/"},{"name":"nCov","slug":"nCov","link":"/tags/nCov/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"MarkDown","slug":"MarkDown","link":"/tags/MarkDown/"},{"name":"HTML","slug":"HTML","link":"/tags/HTML/"},{"name":"GitPage","slug":"GitPage","link":"/tags/GitPage/"},{"name":"Hexo Plugin","slug":"Hexo-Plugin","link":"/tags/Hexo-Plugin/"},{"name":"Graphviz","slug":"Graphviz","link":"/tags/Graphviz/"},{"name":"Kivy","slug":"Kivy","link":"/tags/Kivy/"},{"name":"Tools","slug":"Tools","link":"/tags/Tools/"},{"name":"IDE","slug":"IDE","link":"/tags/IDE/"},{"name":"Latex","slug":"Latex","link":"/tags/Latex/"},{"name":"OpenCV","slug":"OpenCV","link":"/tags/OpenCV/"},{"name":"Urwid","slug":"Urwid","link":"/tags/Urwid/"},{"name":"Crawler","slug":"Crawler","link":"/tags/Crawler/"},{"name":"Termux","slug":"Termux","link":"/tags/Termux/"},{"name":"Android","slug":"Android","link":"/tags/Android/"},{"name":"System","slug":"System","link":"/tags/System/"},{"name":"ggplot","slug":"ggplot","link":"/tags/ggplot/"},{"name":"Nutrition matrix","slug":"Nutrition-matrix","link":"/tags/Nutrition-matrix/"},{"name":"ggplot_splitbar","slug":"ggplot-splitbar","link":"/tags/ggplot-splitbar/"},{"name":"Others","slug":"Others","link":"/tags/Others/"},{"name":"Data","slug":"Data","link":"/tags/Data/"},{"name":"Yuque","slug":"Yuque","link":"/tags/Yuque/"},{"name":"Waque","slug":"Waque","link":"/tags/Waque/"},{"name":"bug","slug":"bug","link":"/tags/bug/"},{"name":"Deepin","slug":"Deepin","link":"/tags/Deepin/"},{"name":"Scripting","slug":"Scripting","link":"/tags/Scripting/"},{"name":"bash","slug":"bash","link":"/tags/bash/"},{"name":"CLI Tools","slug":"CLI-Tools","link":"/tags/CLI-Tools/"},{"name":"Conky","slug":"Conky","link":"/tags/Conky/"},{"name":"apt","slug":"apt","link":"/tags/apt/"},{"name":"RasperryPi","slug":"RasperryPi","link":"/tags/RasperryPi/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"Disk","slug":"Disk","link":"/tags/Disk/"},{"name":"Script","slug":"Script","link":"/tags/Script/"},{"name":"TUI","slug":"TUI","link":"/tags/TUI/"},{"name":"PDF","slug":"PDF","link":"/tags/PDF/"},{"name":"Matrix","slug":"Matrix","link":"/tags/Matrix/"},{"name":"Tensorflow","slug":"Tensorflow","link":"/tags/Tensorflow/"},{"name":"Transfer Learning","slug":"Transfer-Learning","link":"/tags/Transfer-Learning/"},{"name":"flybase","slug":"flybase","link":"/tags/flybase/"},{"name":"FTP","slug":"FTP","link":"/tags/FTP/"},{"name":"Jupyter Notebook","slug":"Jupyter-Notebook","link":"/tags/Jupyter-Notebook/"},{"name":"Network","slug":"Network","link":"/tags/Network/"},{"name":"orc","slug":"orc","link":"/tags/orc/"},{"name":"email","slug":"email","link":"/tags/email/"},{"name":"Regression","slug":"Regression","link":"/tags/Regression/"},{"name":"RNN","slug":"RNN","link":"/tags/RNN/"},{"name":"torch","slug":"torch","link":"/tags/torch/"},{"name":"Deep Learning","slug":"Deep-Learning","link":"/tags/Deep-Learning/"},{"name":"Video","slug":"Video","link":"/tags/Video/"},{"name":"Audio","slug":"Audio","link":"/tags/Audio/"},{"name":"WordCloud","slug":"WordCloud","link":"/tags/WordCloud/"},{"name":"Book","slug":"Book","link":"/tags/Book/"},{"name":"English","slug":"English","link":"/tags/English/"},{"name":"Fish","slug":"Fish","link":"/tags/Fish/"},{"name":"Vocabulary","slug":"Vocabulary","link":"/tags/Vocabulary/"},{"name":"Notes","slug":"Notes","link":"/tags/Notes/"},{"name":"Metabloism","slug":"Metabloism","link":"/tags/Metabloism/"},{"name":"Papers","slug":"Papers","link":"/tags/Papers/"},{"name":"Metabolism","slug":"Metabolism","link":"/tags/Metabolism/"},{"name":"Dme","slug":"Dme","link":"/tags/Dme/"},{"name":"Paper","slug":"Paper","link":"/tags/Paper/"},{"name":"Mice","slug":"Mice","link":"/tags/Mice/"},{"name":"Mind Plot","slug":"Mind-Plot","link":"/tags/Mind-Plot/"},{"name":"Classes","slug":"Classes","link":"/tags/Classes/"},{"name":"Biochemistry","slug":"Biochemistry","link":"/tags/Biochemistry/"},{"name":"UIUC Classes","slug":"UIUC-Classes","link":"/tags/UIUC-Classes/"},{"name":"Scientific American","slug":"Scientific-American","link":"/tags/Scientific-American/"},{"name":"Super Conductor","slug":"Super-Conductor","link":"/tags/Super-Conductor/"},{"name":"Physics","slug":"Physics","link":"/tags/Physics/"},{"name":"Cell Biology","slug":"Cell-Biology","link":"/tags/Cell-Biology/"},{"name":"Behavior","slug":"Behavior","link":"/tags/Behavior/"},{"name":"Distribution","slug":"Distribution","link":"/tags/Distribution/"},{"name":"Advanced Mathematics","slug":"Advanced-Mathematics","link":"/tags/Advanced-Mathematics/"},{"name":"Japanese","slug":"Japanese","link":"/tags/Japanese/"},{"name":"Aging","slug":"Aging","link":"/tags/Aging/"},{"name":"Cancer","slug":"Cancer","link":"/tags/Cancer/"},{"name":"Meta-omics","slug":"Meta-omics","link":"/tags/Meta-omics/"},{"name":"Synthetic Cell","slug":"Synthetic-Cell","link":"/tags/Synthetic-Cell/"},{"name":"Neuron","slug":"Neuron","link":"/tags/Neuron/"},{"name":"Tulane Classes","slug":"Tulane-Classes","link":"/tags/Tulane-Classes/"},{"name":"BioStatistics","slug":"BioStatistics","link":"/tags/BioStatistics/"},{"name":"Writing","slug":"Writing","link":"/tags/Writing/"},{"name":"map","slug":"map","link":"/tags/map/"},{"name":"Tutorials","slug":"Tutorials","link":"/tags/Tutorials/"},{"name":"Links","slug":"Links","link":"/tags/Links/"},{"name":"PCA","slug":"PCA","link":"/tags/PCA/"},{"name":"Interoperable Plot","slug":"Interoperable-Plot","link":"/tags/Interoperable-Plot/"},{"name":"Response Surface Methodology","slug":"Response-Surface-Methodology","link":"/tags/Response-Surface-Methodology/"},{"name":"ggkaboom","slug":"ggkaboom","link":"/tags/ggkaboom/"},{"name":"R packages","slug":"R-packages","link":"/tags/R-packages/"},{"name":"Logistic","slug":"Logistic","link":"/tags/Logistic/"},{"name":"abi","slug":"abi","link":"/tags/abi/"},{"name":"Python Plot","slug":"Python-Plot","link":"/tags/Python-Plot/"},{"name":"Python Seaborn","slug":"Python-Seaborn","link":"/tags/Python-Seaborn/"},{"name":"protein","slug":"protein","link":"/tags/protein/"},{"name":"dock","slug":"dock","link":"/tags/dock/"},{"name":"Biochmistry","slug":"Biochmistry","link":"/tags/Biochmistry/"}],"categories":[{"name":"Notes","slug":"Notes","link":"/categories/Notes/"},{"name":"Biology","slug":"Biology","link":"/categories/Biology/"},{"name":"Class","slug":"Notes/Class","link":"/categories/Notes/Class/"},{"name":"Bioinformatics","slug":"Biology/Bioinformatics","link":"/categories/Biology/Bioinformatics/"},{"name":"Statistic","slug":"Notes/Statistic","link":"/categories/Notes/Statistic/"},{"name":"UIUC","slug":"Notes/Class/UIUC","link":"/categories/Notes/Class/UIUC/"},{"name":"Wet Protocol","slug":"Biology/Wet-Protocol","link":"/categories/Biology/Wet-Protocol/"},{"name":"Biology","slug":"Notes/Biology","link":"/categories/Notes/Biology/"},{"name":"Database","slug":"Biology/Database","link":"/categories/Biology/Database/"},{"name":"Software","slug":"Biology/Bioinformatics/Software","link":"/categories/Biology/Bioinformatics/Software/"},{"name":"Chip-Seq","slug":"Biology/Bioinformatics/Chip-Seq","link":"/categories/Biology/Bioinformatics/Chip-Seq/"},{"name":"Protocol","slug":"Biology/Bioinformatics/Protocol","link":"/categories/Biology/Bioinformatics/Protocol/"},{"name":"others","slug":"Biology/Bioinformatics/others","link":"/categories/Biology/Bioinformatics/others/"},{"name":"others","slug":"Notes/Statistic/others","link":"/categories/Notes/Statistic/others/"},{"name":"AI","slug":"Notes/Class/UIUC/AI","link":"/categories/Notes/Class/UIUC/AI/"},{"name":"Database","slug":"Biology/Bioinformatics/Database","link":"/categories/Biology/Bioinformatics/Database/"},{"name":"Protein Structure","slug":"Biology/Bioinformatics/Protein-Structure","link":"/categories/Biology/Bioinformatics/Protein-Structure/"},{"name":"Proteomic","slug":"Biology/Bioinformatics/Proteomic","link":"/categories/Biology/Bioinformatics/Proteomic/"},{"name":"Single Cell","slug":"Biology/Bioinformatics/Single-Cell","link":"/categories/Biology/Bioinformatics/Single-Cell/"},{"name":"Python","slug":"Python","link":"/categories/Python/"},{"name":"WGS","slug":"Biology/Bioinformatics/WGS","link":"/categories/Biology/Bioinformatics/WGS/"},{"name":"others","slug":"others","link":"/categories/others/"},{"name":"Bioinformatic","slug":"Notes/Biology/Bioinformatic","link":"/categories/Notes/Biology/Bioinformatic/"},{"name":"R","slug":"R","link":"/categories/R/"},{"name":"Fasta&#x2F;q","slug":"Biology/Bioinformatics/Software/Fasta-q","link":"/categories/Biology/Bioinformatics/Software/Fasta-q/"},{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"List","slug":"Biology/Bioinformatics/Software/List","link":"/categories/Biology/Bioinformatics/Software/List/"},{"name":"Align","slug":"Biology/Bioinformatics/Software/Align","link":"/categories/Biology/Bioinformatics/Software/Align/"},{"name":"RNA-Seq","slug":"Biology/Bioinformatics/Protocol/RNA-Seq","link":"/categories/Biology/Bioinformatics/Protocol/RNA-Seq/"},{"name":"Data Scientists","slug":"Notes/Statistic/Data-Scientists","link":"/categories/Notes/Statistic/Data-Scientists/"},{"name":"more","slug":"Biology/Bioinformatics/Software/more","link":"/categories/Biology/Bioinformatics/Software/more/"},{"name":"Visualization","slug":"Biology/Bioinformatics/Software/Visualization","link":"/categories/Biology/Bioinformatics/Software/Visualization/"},{"name":"miRNA","slug":"Biology/Bioinformatics/Protocol/miRNA","link":"/categories/Biology/Bioinformatics/Protocol/miRNA/"},{"name":"Dna Methylation","slug":"Biology/Bioinformatics/Software/Dna-Methylation","link":"/categories/Biology/Bioinformatics/Software/Dna-Methylation/"},{"name":"De nove","slug":"Biology/Bioinformatics/Software/De-nove","link":"/categories/Biology/Bioinformatics/Software/De-nove/"},{"name":"SNP","slug":"Biology/Bioinformatics/Protocol/SNP","link":"/categories/Biology/Bioinformatics/Protocol/SNP/"},{"name":"Sam","slug":"Biology/Bioinformatics/Software/Sam","link":"/categories/Biology/Bioinformatics/Software/Sam/"},{"name":"Trans","slug":"Biology/Bioinformatics/Software/Trans","link":"/categories/Biology/Bioinformatics/Software/Trans/"},{"name":"Bioconda","slug":"Biology/Bioinformatics/Software/Bioconda","link":"/categories/Biology/Bioinformatics/Software/Bioconda/"},{"name":"Download","slug":"Biology/Bioinformatics/Software/Download","link":"/categories/Biology/Bioinformatics/Software/Download/"},{"name":"Distribution","slug":"Notes/Statistic/Distribution","link":"/categories/Notes/Statistic/Distribution/"},{"name":"API","slug":"Python/API","link":"/categories/Python/API/"},{"name":"others","slug":"Python/others","link":"/categories/Python/others/"},{"name":"Kivy","slug":"Python/Kivy","link":"/categories/Python/Kivy/"},{"name":"Blog","slug":"others/Blog","link":"/categories/others/Blog/"},{"name":"Annotation","slug":"Biology/Bioinformatics/Protocol/Annotation","link":"/categories/Biology/Bioinformatics/Protocol/Annotation/"},{"name":"Scripting","slug":"Python/Scripting","link":"/categories/Python/Scripting/"},{"name":"TUI","slug":"Python/TUI","link":"/categories/Python/TUI/"},{"name":"Data","slug":"Python/Data","link":"/categories/Python/Data/"},{"name":"OpenCV","slug":"Python/OpenCV","link":"/categories/Python/OpenCV/"},{"name":"Genome","slug":"Biology/Bioinformatics/Protocol/Genome","link":"/categories/Biology/Bioinformatics/Protocol/Genome/"},{"name":"Beginner","slug":"Python/Beginner","link":"/categories/Python/Beginner/"},{"name":"Plot","slug":"Python/Plot","link":"/categories/Python/Plot/"},{"name":"Alternative Splicing","slug":"Biology/Bioinformatics/Protocol/Alternative-Splicing","link":"/categories/Biology/Bioinformatics/Protocol/Alternative-Splicing/"},{"name":"GO","slug":"Biology/Bioinformatics/Protocol/GO","link":"/categories/Biology/Bioinformatics/Protocol/GO/"},{"name":"Book","slug":"Notes/Biology/Book","link":"/categories/Notes/Biology/Book/"},{"name":"English","slug":"Notes/English","link":"/categories/Notes/English/"},{"name":"Tools","slug":"others/Tools","link":"/categories/others/Tools/"},{"name":"others","slug":"Notes/others","link":"/categories/Notes/others/"},{"name":"else","slug":"others/else","link":"/categories/others/else/"},{"name":"Paper","slug":"Notes/Paper","link":"/categories/Notes/Paper/"},{"name":"Dme","slug":"Notes/Biology/Dme","link":"/categories/Notes/Biology/Dme/"},{"name":"Biochemistry","slug":"Notes/Class/UIUC/Biochemistry","link":"/categories/Notes/Class/UIUC/Biochemistry/"},{"name":"Cell Biology","slug":"Notes/Class/UIUC/Cell-Biology","link":"/categories/Notes/Class/UIUC/Cell-Biology/"},{"name":"Crawler","slug":"Python/Crawler","link":"/categories/Python/Crawler/"},{"name":"Immunity","slug":"Notes/Biology/Immunity","link":"/categories/Notes/Biology/Immunity/"},{"name":"others","slug":"Biology/others","link":"/categories/Biology/others/"},{"name":"Math","slug":"Notes/Class/Math","link":"/categories/Notes/Class/Math/"},{"name":"others","slug":"R/others","link":"/categories/R/others/"},{"name":"Biochemistry","slug":"Notes/Class/Biochemistry","link":"/categories/Notes/Class/Biochemistry/"},{"name":"Align","slug":"Biology/Bioinformatics/Protocol/Align","link":"/categories/Biology/Bioinformatics/Protocol/Align/"},{"name":"Data","slug":"R/Data","link":"/categories/R/Data/"},{"name":"Bio","slug":"R/Bio","link":"/categories/R/Bio/"},{"name":"Android","slug":"others/Android","link":"/categories/others/Android/"},{"name":"others","slug":"Linux/others","link":"/categories/Linux/others/"},{"name":"Plot","slug":"R/Plot","link":"/categories/R/Plot/"},{"name":"Bio","slug":"Python/Bio","link":"/categories/Python/Bio/"},{"name":"Software","slug":"Linux/Software","link":"/categories/Linux/Software/"},{"name":"Monitor: top\\Conky","slug":"Linux/Monitor-top-Conky","link":"/categories/Linux/Monitor-top-Conky/"},{"name":"RasperryPi","slug":"Linux/RasperryPi","link":"/categories/Linux/RasperryPi/"},{"name":"Bash","slug":"Linux/Bash","link":"/categories/Linux/Bash/"},{"name":"Arch","slug":"Linux/Arch","link":"/categories/Linux/Arch/"},{"name":"Termux","slug":"Linux/Termux","link":"/categories/Linux/Termux/"},{"name":"System","slug":"Linux/System","link":"/categories/Linux/System/"},{"name":"GitHub","slug":"Linux/GitHub","link":"/categories/Linux/GitHub/"},{"name":"Data","slug":"Linux/Data","link":"/categories/Linux/Data/"},{"name":"Ubuntu","slug":"Linux/Ubuntu","link":"/categories/Linux/Ubuntu/"},{"name":"GUI","slug":"Python/GUI","link":"/categories/Python/GUI/"},{"name":"Toolbox","slug":"Python/Kivy/Toolbox","link":"/categories/Python/Kivy/Toolbox/"},{"name":"Hexo","slug":"others/Blog/Hexo","link":"/categories/others/Blog/Hexo/"},{"name":"Module","slug":"Python/Scripting/Module","link":"/categories/Python/Scripting/Module/"},{"name":"others","slug":"Python/TUI/others","link":"/categories/Python/TUI/others/"},{"name":"Matrix","slug":"Python/Data/Matrix","link":"/categories/Python/Data/Matrix/"},{"name":"more","slug":"others/Blog/more","link":"/categories/others/Blog/more/"},{"name":"Machine Learning","slug":"Python/Data/Machine-Learning","link":"/categories/Python/Data/Machine-Learning/"},{"name":"Practice","slug":"Python/Scripting/Practice","link":"/categories/Python/Scripting/Practice/"},{"name":"HTML","slug":"others/Blog/HTML","link":"/categories/others/Blog/HTML/"},{"name":"Urwid","slug":"Python/TUI/Urwid","link":"/categories/Python/TUI/Urwid/"},{"name":"Biology","slug":"Notes/Paper/Biology","link":"/categories/Notes/Paper/Biology/"},{"name":"Machine Learning","slug":"R/Data/Machine-Learning","link":"/categories/R/Data/Machine-Learning/"},{"name":"Abi","slug":"R/Bio/Abi","link":"/categories/R/Bio/Abi/"},{"name":"DEG","slug":"R/Bio/DEG","link":"/categories/R/Bio/DEG/"},{"name":"GGPLOT","slug":"R/Plot/GGPLOT","link":"/categories/R/Plot/GGPLOT/"},{"name":"Sharing","slug":"others/Blog/Sharing","link":"/categories/others/Blog/Sharing/"},{"name":"Yuque","slug":"others/Blog/Yuque","link":"/categories/others/Blog/Yuque/"},{"name":"Beginner","slug":"Linux/Bash/Beginner","link":"/categories/Linux/Bash/Beginner/"},{"name":"More","slug":"Linux/Bash/More","link":"/categories/Linux/Bash/More/"},{"name":"awk&#x2F;grep&#x2F;sed","slug":"Linux/Bash/awk-grep-sed","link":"/categories/Linux/Bash/awk-grep-sed/"},{"name":"others","slug":"Python/GUI/others","link":"/categories/Python/GUI/others/"},{"name":"RNN","slug":"Python/Data/Machine-Learning/RNN","link":"/categories/Python/Data/Machine-Learning/RNN/"},{"name":"Deep Learning","slug":"Python/Data/Machine-Learning/Deep-Learning","link":"/categories/Python/Data/Machine-Learning/Deep-Learning/"},{"name":"Cell Biology","slug":"Notes/Class/Cell-Biology","link":"/categories/Notes/Class/Cell-Biology/"},{"name":"Python","slug":"Notes/Class/Python","link":"/categories/Notes/Class/Python/"},{"name":"Dme","slug":"Notes/Paper/Biology/Dme","link":"/categories/Notes/Paper/Biology/Dme/"},{"name":"Japanese","slug":"Notes/Japanese","link":"/categories/Notes/Japanese/"},{"name":"Paper","slug":"Paper","link":"/categories/Paper/"},{"name":"Diseases","slug":"Paper/Diseases","link":"/categories/Paper/Diseases/"},{"name":"Biology","slug":"Paper/Biology","link":"/categories/Paper/Biology/"},{"name":"Virus","slug":"Notes/Biology/Virus","link":"/categories/Notes/Biology/Virus/"},{"name":"Immunology","slug":"Paper/Biology/Immunology","link":"/categories/Paper/Biology/Immunology/"},{"name":"Genetics","slug":"Notes/Biology/Genetics","link":"/categories/Notes/Biology/Genetics/"},{"name":"Reading Notes","slug":"Notes/Paper/Biology/Reading-Notes","link":"/categories/Notes/Paper/Biology/Reading-Notes/"},{"name":"Tulane","slug":"Notes/Class/Tulane","link":"/categories/Notes/Class/Tulane/"},{"name":"Biochemistry","slug":"Notes/Class/Tulane/Biochemistry","link":"/categories/Notes/Class/Tulane/Biochemistry/"},{"name":"Bioinformatics","slug":"Notes/Class/Tulane/Bioinformatics","link":"/categories/Notes/Class/Tulane/Bioinformatics/"},{"name":"BioStatistics","slug":"Notes/Class/Tulane/BioStatistics","link":"/categories/Notes/Class/Tulane/BioStatistics/"},{"name":"Cell Biology","slug":"Notes/Class/Tulane/Cell-Biology","link":"/categories/Notes/Class/Tulane/Cell-Biology/"},{"name":"Beginner","slug":"R/Beginner","link":"/categories/R/Beginner/"},{"name":"Fasta","slug":"R/Bio/Fasta","link":"/categories/R/Bio/Fasta/"},{"name":"others","slug":"R/Plot/others","link":"/categories/R/Plot/others/"},{"name":"Data Clean","slug":"R/Data/Data-Clean","link":"/categories/R/Data/Data-Clean/"},{"name":"VisuaProtocol","slug":"R/Plot/VisuaProtocol","link":"/categories/R/Plot/VisuaProtocol/"},{"name":"Pack your pack","slug":"R/Pack-your-pack","link":"/categories/R/Pack-your-pack/"},{"name":"WGCNA","slug":"R/Bio/WGCNA","link":"/categories/R/Bio/WGCNA/"},{"name":"Blog","slug":"R/Plot/Blog","link":"/categories/R/Plot/Blog/"},{"name":"Statistic","slug":"R/Data/Statistic","link":"/categories/R/Data/Statistic/"},{"name":"Anno&#x2F;Enrich","slug":"R/Bio/Anno-Enrich","link":"/categories/R/Bio/Anno-Enrich/"},{"name":"Image","slug":"R/Image","link":"/categories/R/Image/"},{"name":"Maps","slug":"R/Plot/Maps","link":"/categories/R/Plot/Maps/"},{"name":"libraries","slug":"R/libraries","link":"/categories/R/libraries/"},{"name":"Heatmap","slug":"R/Plot/Heatmap","link":"/categories/R/Plot/Heatmap/"},{"name":"Data","slug":"Data","link":"/categories/Data/"},{"name":"Algorithm","slug":"R/Plot/Blog/Algorithm","link":"/categories/R/Plot/Blog/Algorithm/"},{"name":"Regression","slug":"R/Data/Statistic/Regression","link":"/categories/R/Data/Statistic/Regression/"},{"name":"Statistic","slug":"Data/Statistic","link":"/categories/Data/Statistic/"},{"name":"Machine Learning","slug":"Machine-Learning","link":"/categories/Machine-Learning/"},{"name":"other","slug":"Notes/other","link":"/categories/Notes/other/"},{"name":"Math","slug":"Machine-Learning/Math","link":"/categories/Machine-Learning/Math/"},{"name":"LM","slug":"Machine-Learning/LM","link":"/categories/Machine-Learning/LM/"},{"name":"Protein","slug":"Machine-Learning/LM/Protein","link":"/categories/Machine-Learning/LM/Protein/"},{"name":"Regression","slug":"Machine-Learning/Regression","link":"/categories/Machine-Learning/Regression/"},{"name":"Data Format","slug":"Machine-Learning/Data-Format","link":"/categories/Machine-Learning/Data-Format/"}]}